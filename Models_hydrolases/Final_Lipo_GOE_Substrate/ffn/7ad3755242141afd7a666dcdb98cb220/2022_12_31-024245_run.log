2022-12-31 13:59:54,028 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/7ad3755242141afd7a666dcdb98cb220/2022_12_31-024245",
  "seed": 3,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.95,
  "val_size": 0.05,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 3,
  "hidden_size": 90,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-12-31 13:59:54,036 INFO: Starting stage: BUILD FEATURIZERS
2022-12-31 13:59:54,038 INFO:   Creating esm representation model
2022-12-31 13:59:54,038 INFO:   Done esm representation model
2022-12-31 13:59:54,038 INFO: Done with stage: BUILD FEATURIZERS
2022-12-31 13:59:54,038 INFO: Starting stage: BUILDING DATASET
2022-12-31 13:59:54,092 INFO: Done with stage: BUILDING DATASET
2022-12-31 13:59:54,092 INFO: Starting stage: FEATURIZING DATA
2022-12-31 13:59:54,092 INFO:   Featurizing proteins
2022-12-31 13:59:54,094 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-12-31 13:59:54,121 INFO:   Loaded feature cache of size 489
2022-12-31 13:59:54,122 INFO:   Starting to pool ESM Embeddings
2022-12-31 13:59:54,230 INFO:   Featurizing molecules
2022-12-31 13:59:54,232 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2022-12-31 13:59:54,234 INFO:   Loaded feature cache of size 498
2022-12-31 13:59:55,582 INFO: Done with stage: FEATURIZING DATA
2022-12-31 13:59:55,582 INFO: Starting stage: RUNNING SPLITS
2022-12-31 13:59:55,591 INFO:   Leaving out SEQ value Fold_0
2022-12-31 13:59:55,605 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 13:59:55,605 INFO:   Starting stage: FEATURE SCALING
2022-12-31 13:59:56,267 INFO:   Done with stage: FEATURE SCALING
2022-12-31 13:59:56,267 INFO:   Starting stage: SCALING TARGETS
2022-12-31 13:59:56,334 INFO:   Done with stage: SCALING TARGETS
2022-12-31 13:59:56,334 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:59:56,334 INFO:     No hyperparam tuning for this model
2022-12-31 13:59:56,334 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 13:59:56,334 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 13:59:56,335 INFO:     None feature selector for col prot
2022-12-31 13:59:56,335 INFO:     None feature selector for col prot
2022-12-31 13:59:56,335 INFO:     None feature selector for col prot
2022-12-31 13:59:56,335 INFO:     None feature selector for col chem
2022-12-31 13:59:56,335 INFO:     None feature selector for col chem
2022-12-31 13:59:56,336 INFO:     None feature selector for col chem
2022-12-31 13:59:56,336 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 13:59:56,336 INFO:   Starting stage: BUILD MODEL
2022-12-31 13:59:56,337 INFO:     Number of params in model 223921
2022-12-31 13:59:56,338 INFO:   Done with stage: BUILD MODEL
2022-12-31 13:59:56,338 INFO:   Starting stage: TRAINING
2022-12-31 13:59:57,941 INFO:     Val loss before train {'Reaction outcome loss': 0.9830225745836894, 'Total loss': 0.9830225745836894}
2022-12-31 13:59:57,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:57,942 INFO:     Epoch: 0
2022-12-31 13:59:59,560 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6895603378613789, 'Total loss': 0.6895603378613789} | train loss {'Reaction outcome loss': 0.798658278453481, 'Total loss': 0.798658278453481}
2022-12-31 13:59:59,560 INFO:     Found new best model at epoch 0
2022-12-31 13:59:59,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 13:59:59,561 INFO:     Epoch: 1
2022-12-31 14:00:01,142 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5571772317091624, 'Total loss': 0.5571772317091624} | train loss {'Reaction outcome loss': 0.5887351420336154, 'Total loss': 0.5887351420336154}
2022-12-31 14:00:01,143 INFO:     Found new best model at epoch 1
2022-12-31 14:00:01,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:01,144 INFO:     Epoch: 2
2022-12-31 14:00:02,726 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5491525610287984, 'Total loss': 0.5491525610287984} | train loss {'Reaction outcome loss': 0.5309086676700648, 'Total loss': 0.5309086676700648}
2022-12-31 14:00:02,726 INFO:     Found new best model at epoch 2
2022-12-31 14:00:02,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:02,727 INFO:     Epoch: 3
2022-12-31 14:00:04,331 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5336480776468913, 'Total loss': 0.5336480776468913} | train loss {'Reaction outcome loss': 0.5045923912154012, 'Total loss': 0.5045923912154012}
2022-12-31 14:00:04,332 INFO:     Found new best model at epoch 3
2022-12-31 14:00:04,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:04,333 INFO:     Epoch: 4
2022-12-31 14:00:05,927 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4983773916959763, 'Total loss': 0.4983773916959763} | train loss {'Reaction outcome loss': 0.4939989752166874, 'Total loss': 0.4939989752166874}
2022-12-31 14:00:05,927 INFO:     Found new best model at epoch 4
2022-12-31 14:00:05,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:05,928 INFO:     Epoch: 5
2022-12-31 14:00:07,530 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5012800991535187, 'Total loss': 0.5012800991535187} | train loss {'Reaction outcome loss': 0.48029508318874864, 'Total loss': 0.48029508318874864}
2022-12-31 14:00:07,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:07,531 INFO:     Epoch: 6
2022-12-31 14:00:09,129 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4766778081655502, 'Total loss': 0.4766778081655502} | train loss {'Reaction outcome loss': 0.46457422232671536, 'Total loss': 0.46457422232671536}
2022-12-31 14:00:09,129 INFO:     Found new best model at epoch 6
2022-12-31 14:00:09,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:09,130 INFO:     Epoch: 7
2022-12-31 14:00:10,691 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48330506881078084, 'Total loss': 0.48330506881078084} | train loss {'Reaction outcome loss': 0.4604079467909677, 'Total loss': 0.4604079467909677}
2022-12-31 14:00:10,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:10,691 INFO:     Epoch: 8
2022-12-31 14:00:12,319 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4521292547384898, 'Total loss': 0.4521292547384898} | train loss {'Reaction outcome loss': 0.45065479144290255, 'Total loss': 0.45065479144290255}
2022-12-31 14:00:12,319 INFO:     Found new best model at epoch 8
2022-12-31 14:00:12,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:12,320 INFO:     Epoch: 9
2022-12-31 14:00:13,918 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47210697333017987, 'Total loss': 0.47210697333017987} | train loss {'Reaction outcome loss': 0.4438135326454491, 'Total loss': 0.4438135326454491}
2022-12-31 14:00:13,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:13,918 INFO:     Epoch: 10
2022-12-31 14:00:15,518 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5031053264935811, 'Total loss': 0.5031053264935811} | train loss {'Reaction outcome loss': 0.436464698105068, 'Total loss': 0.436464698105068}
2022-12-31 14:00:15,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:15,518 INFO:     Epoch: 11
2022-12-31 14:00:17,120 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44917794068654376, 'Total loss': 0.44917794068654376} | train loss {'Reaction outcome loss': 0.43374412753806885, 'Total loss': 0.43374412753806885}
2022-12-31 14:00:17,120 INFO:     Found new best model at epoch 11
2022-12-31 14:00:17,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:17,121 INFO:     Epoch: 12
2022-12-31 14:00:18,717 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44823814630508424, 'Total loss': 0.44823814630508424} | train loss {'Reaction outcome loss': 0.42706076074869204, 'Total loss': 0.42706076074869204}
2022-12-31 14:00:18,717 INFO:     Found new best model at epoch 12
2022-12-31 14:00:18,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:18,718 INFO:     Epoch: 13
2022-12-31 14:00:20,292 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4577733894189199, 'Total loss': 0.4577733894189199} | train loss {'Reaction outcome loss': 0.41752004874494925, 'Total loss': 0.41752004874494925}
2022-12-31 14:00:20,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:20,292 INFO:     Epoch: 14
2022-12-31 14:00:21,904 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4914598961671193, 'Total loss': 0.4914598961671193} | train loss {'Reaction outcome loss': 0.4204014547360249, 'Total loss': 0.4204014547360249}
2022-12-31 14:00:21,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:21,904 INFO:     Epoch: 15
2022-12-31 14:00:23,527 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4460681974887848, 'Total loss': 0.4460681974887848} | train loss {'Reaction outcome loss': 0.40715849731158427, 'Total loss': 0.40715849731158427}
2022-12-31 14:00:23,527 INFO:     Found new best model at epoch 15
2022-12-31 14:00:23,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:23,528 INFO:     Epoch: 16
2022-12-31 14:00:25,124 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4619797249635061, 'Total loss': 0.4619797249635061} | train loss {'Reaction outcome loss': 0.39715337922503224, 'Total loss': 0.39715337922503224}
2022-12-31 14:00:25,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:25,124 INFO:     Epoch: 17
2022-12-31 14:00:26,722 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45256931086381275, 'Total loss': 0.45256931086381275} | train loss {'Reaction outcome loss': 0.39545393983523053, 'Total loss': 0.39545393983523053}
2022-12-31 14:00:26,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:26,722 INFO:     Epoch: 18
2022-12-31 14:00:28,294 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44721959233284, 'Total loss': 0.44721959233284} | train loss {'Reaction outcome loss': 0.3916448972873635, 'Total loss': 0.3916448972873635}
2022-12-31 14:00:28,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:28,294 INFO:     Epoch: 19
2022-12-31 14:00:29,873 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.433731010556221, 'Total loss': 0.433731010556221} | train loss {'Reaction outcome loss': 0.3836562856213077, 'Total loss': 0.3836562856213077}
2022-12-31 14:00:29,874 INFO:     Found new best model at epoch 19
2022-12-31 14:00:29,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:29,875 INFO:     Epoch: 20
2022-12-31 14:00:31,472 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4840154985586802, 'Total loss': 0.4840154985586802} | train loss {'Reaction outcome loss': 0.3756067436256688, 'Total loss': 0.3756067436256688}
2022-12-31 14:00:31,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:31,473 INFO:     Epoch: 21
2022-12-31 14:00:33,070 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4342347800731659, 'Total loss': 0.4342347800731659} | train loss {'Reaction outcome loss': 0.3817158343864011, 'Total loss': 0.3817158343864011}
2022-12-31 14:00:33,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:33,070 INFO:     Epoch: 22
2022-12-31 14:00:34,666 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45382908880710604, 'Total loss': 0.45382908880710604} | train loss {'Reaction outcome loss': 0.3665131674908893, 'Total loss': 0.3665131674908893}
2022-12-31 14:00:34,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:34,666 INFO:     Epoch: 23
2022-12-31 14:00:36,262 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4292403678099314, 'Total loss': 0.4292403678099314} | train loss {'Reaction outcome loss': 0.35747959923285705, 'Total loss': 0.35747959923285705}
2022-12-31 14:00:36,263 INFO:     Found new best model at epoch 23
2022-12-31 14:00:36,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:36,264 INFO:     Epoch: 24
2022-12-31 14:00:37,825 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4374141429861387, 'Total loss': 0.4374141429861387} | train loss {'Reaction outcome loss': 0.3550589925476483, 'Total loss': 0.3550589925476483}
2022-12-31 14:00:37,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:37,825 INFO:     Epoch: 25
2022-12-31 14:00:39,424 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46531678636868795, 'Total loss': 0.46531678636868795} | train loss {'Reaction outcome loss': 0.35633890191604806, 'Total loss': 0.35633890191604806}
2022-12-31 14:00:39,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:39,425 INFO:     Epoch: 26
2022-12-31 14:00:41,032 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42227909763654076, 'Total loss': 0.42227909763654076} | train loss {'Reaction outcome loss': 0.3442862203051319, 'Total loss': 0.3442862203051319}
2022-12-31 14:00:41,032 INFO:     Found new best model at epoch 26
2022-12-31 14:00:41,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:41,033 INFO:     Epoch: 27
2022-12-31 14:00:42,626 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44110952615737914, 'Total loss': 0.44110952615737914} | train loss {'Reaction outcome loss': 0.33932782993430183, 'Total loss': 0.33932782993430183}
2022-12-31 14:00:42,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:42,627 INFO:     Epoch: 28
2022-12-31 14:00:44,237 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4280735462903976, 'Total loss': 0.4280735462903976} | train loss {'Reaction outcome loss': 0.33561853019199966, 'Total loss': 0.33561853019199966}
2022-12-31 14:00:44,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:44,237 INFO:     Epoch: 29
2022-12-31 14:00:45,831 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43667990565299986, 'Total loss': 0.43667990565299986} | train loss {'Reaction outcome loss': 0.3314716304778616, 'Total loss': 0.3314716304778616}
2022-12-31 14:00:45,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:45,832 INFO:     Epoch: 30
2022-12-31 14:00:47,392 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4134142835934957, 'Total loss': 0.4134142835934957} | train loss {'Reaction outcome loss': 0.3303101128001353, 'Total loss': 0.3303101128001353}
2022-12-31 14:00:47,392 INFO:     Found new best model at epoch 30
2022-12-31 14:00:47,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:47,393 INFO:     Epoch: 31
2022-12-31 14:00:49,006 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.449738946557045, 'Total loss': 0.449738946557045} | train loss {'Reaction outcome loss': 0.3228707600371305, 'Total loss': 0.3228707600371305}
2022-12-31 14:00:49,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:49,007 INFO:     Epoch: 32
2022-12-31 14:00:50,618 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44283929268519084, 'Total loss': 0.44283929268519084} | train loss {'Reaction outcome loss': 0.31923371105840354, 'Total loss': 0.31923371105840354}
2022-12-31 14:00:50,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:50,619 INFO:     Epoch: 33
2022-12-31 14:00:52,216 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4451714317003886, 'Total loss': 0.4451714317003886} | train loss {'Reaction outcome loss': 0.3098673264704126, 'Total loss': 0.3098673264704126}
2022-12-31 14:00:52,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:52,216 INFO:     Epoch: 34
2022-12-31 14:00:53,811 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41921228567759194, 'Total loss': 0.41921228567759194} | train loss {'Reaction outcome loss': 0.3083648376248695, 'Total loss': 0.3083648376248695}
2022-12-31 14:00:53,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:53,811 INFO:     Epoch: 35
2022-12-31 14:00:55,390 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41635078489780425, 'Total loss': 0.41635078489780425} | train loss {'Reaction outcome loss': 0.2990880073372261, 'Total loss': 0.2990880073372261}
2022-12-31 14:00:55,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:55,391 INFO:     Epoch: 36
2022-12-31 14:00:56,972 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41280856132507326, 'Total loss': 0.41280856132507326} | train loss {'Reaction outcome loss': 0.30585917949185265, 'Total loss': 0.30585917949185265}
2022-12-31 14:00:56,973 INFO:     Found new best model at epoch 36
2022-12-31 14:00:56,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:56,973 INFO:     Epoch: 37
2022-12-31 14:00:58,566 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4286582956711451, 'Total loss': 0.4286582956711451} | train loss {'Reaction outcome loss': 0.3008071059981982, 'Total loss': 0.3008071059981982}
2022-12-31 14:00:58,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:00:58,566 INFO:     Epoch: 38
2022-12-31 14:01:00,159 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4058428262670835, 'Total loss': 0.4058428262670835} | train loss {'Reaction outcome loss': 0.2915371144292774, 'Total loss': 0.2915371144292774}
2022-12-31 14:01:00,159 INFO:     Found new best model at epoch 38
2022-12-31 14:01:00,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:00,160 INFO:     Epoch: 39
2022-12-31 14:01:01,761 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4300024136900902, 'Total loss': 0.4300024136900902} | train loss {'Reaction outcome loss': 0.2895812265738681, 'Total loss': 0.2895812265738681}
2022-12-31 14:01:01,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:01,762 INFO:     Epoch: 40
2022-12-31 14:01:03,400 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4070550302664439, 'Total loss': 0.4070550302664439} | train loss {'Reaction outcome loss': 0.29204521139899453, 'Total loss': 0.29204521139899453}
2022-12-31 14:01:03,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:03,401 INFO:     Epoch: 41
2022-12-31 14:01:04,968 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46688578724861146, 'Total loss': 0.46688578724861146} | train loss {'Reaction outcome loss': 0.28325188655283423, 'Total loss': 0.28325188655283423}
2022-12-31 14:01:04,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:04,968 INFO:     Epoch: 42
2022-12-31 14:01:06,579 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3913780351479848, 'Total loss': 0.3913780351479848} | train loss {'Reaction outcome loss': 0.28220926042332317, 'Total loss': 0.28220926042332317}
2022-12-31 14:01:06,579 INFO:     Found new best model at epoch 42
2022-12-31 14:01:06,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:06,580 INFO:     Epoch: 43
2022-12-31 14:01:08,173 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41152819494406384, 'Total loss': 0.41152819494406384} | train loss {'Reaction outcome loss': 0.28194756602575055, 'Total loss': 0.28194756602575055}
2022-12-31 14:01:08,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:08,174 INFO:     Epoch: 44
2022-12-31 14:01:09,764 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44666812221209207, 'Total loss': 0.44666812221209207} | train loss {'Reaction outcome loss': 0.2707684209822735, 'Total loss': 0.2707684209822735}
2022-12-31 14:01:09,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:09,764 INFO:     Epoch: 45
2022-12-31 14:01:11,367 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4579337745904922, 'Total loss': 0.4579337745904922} | train loss {'Reaction outcome loss': 0.2695094891738542, 'Total loss': 0.2695094891738542}
2022-12-31 14:01:11,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:11,367 INFO:     Epoch: 46
2022-12-31 14:01:12,970 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44189221660296124, 'Total loss': 0.44189221660296124} | train loss {'Reaction outcome loss': 0.27518559975938484, 'Total loss': 0.27518559975938484}
2022-12-31 14:01:12,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:12,970 INFO:     Epoch: 47
2022-12-31 14:01:14,547 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40577493906021117, 'Total loss': 0.40577493906021117} | train loss {'Reaction outcome loss': 0.27293090224811883, 'Total loss': 0.27293090224811883}
2022-12-31 14:01:14,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:14,547 INFO:     Epoch: 48
2022-12-31 14:01:16,140 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44254929224650064, 'Total loss': 0.44254929224650064} | train loss {'Reaction outcome loss': 0.2641054507986311, 'Total loss': 0.2641054507986311}
2022-12-31 14:01:16,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:16,140 INFO:     Epoch: 49
2022-12-31 14:01:17,734 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4454071640968323, 'Total loss': 0.4454071640968323} | train loss {'Reaction outcome loss': 0.25717801767513976, 'Total loss': 0.25717801767513976}
2022-12-31 14:01:17,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:17,734 INFO:     Epoch: 50
2022-12-31 14:01:19,324 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4260850022236506, 'Total loss': 0.4260850022236506} | train loss {'Reaction outcome loss': 0.2592540463848865, 'Total loss': 0.2592540463848865}
2022-12-31 14:01:19,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:19,324 INFO:     Epoch: 51
2022-12-31 14:01:20,918 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45740427176157633, 'Total loss': 0.45740427176157633} | train loss {'Reaction outcome loss': 0.25191245005626384, 'Total loss': 0.25191245005626384}
2022-12-31 14:01:20,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:20,919 INFO:     Epoch: 52
2022-12-31 14:01:22,491 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39357010324796043, 'Total loss': 0.39357010324796043} | train loss {'Reaction outcome loss': 0.25375176382152154, 'Total loss': 0.25375176382152154}
2022-12-31 14:01:22,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:22,491 INFO:     Epoch: 53
2022-12-31 14:01:24,092 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4138859748840332, 'Total loss': 0.4138859748840332} | train loss {'Reaction outcome loss': 0.2496893463669952, 'Total loss': 0.2496893463669952}
2022-12-31 14:01:24,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:24,092 INFO:     Epoch: 54
2022-12-31 14:01:25,693 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4206715300679207, 'Total loss': 0.4206715300679207} | train loss {'Reaction outcome loss': 0.2508724031205743, 'Total loss': 0.2508724031205743}
2022-12-31 14:01:25,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:25,693 INFO:     Epoch: 55
2022-12-31 14:01:27,295 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38701834380626676, 'Total loss': 0.38701834380626676} | train loss {'Reaction outcome loss': 0.24934719849527973, 'Total loss': 0.24934719849527973}
2022-12-31 14:01:27,295 INFO:     Found new best model at epoch 55
2022-12-31 14:01:27,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:27,296 INFO:     Epoch: 56
2022-12-31 14:01:28,882 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4234463711579641, 'Total loss': 0.4234463711579641} | train loss {'Reaction outcome loss': 0.2502153247062649, 'Total loss': 0.2502153247062649}
2022-12-31 14:01:28,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:28,883 INFO:     Epoch: 57
2022-12-31 14:01:30,472 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4325541466474533, 'Total loss': 0.4325541466474533} | train loss {'Reaction outcome loss': 0.24766036570618005, 'Total loss': 0.24766036570618005}
2022-12-31 14:01:30,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:30,472 INFO:     Epoch: 58
2022-12-31 14:01:32,030 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43338996668656665, 'Total loss': 0.43338996668656665} | train loss {'Reaction outcome loss': 0.2422091642278673, 'Total loss': 0.2422091642278673}
2022-12-31 14:01:32,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:32,030 INFO:     Epoch: 59
2022-12-31 14:01:33,618 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4634627451499303, 'Total loss': 0.4634627451499303} | train loss {'Reaction outcome loss': 0.24837666612132128, 'Total loss': 0.24837666612132128}
2022-12-31 14:01:33,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:33,618 INFO:     Epoch: 60
2022-12-31 14:01:35,210 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4068597952524821, 'Total loss': 0.4068597952524821} | train loss {'Reaction outcome loss': 0.23816628265279882, 'Total loss': 0.23816628265279882}
2022-12-31 14:01:35,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:35,211 INFO:     Epoch: 61
2022-12-31 14:01:36,801 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4800832192103068, 'Total loss': 0.4800832192103068} | train loss {'Reaction outcome loss': 0.23673740252443068, 'Total loss': 0.23673740252443068}
2022-12-31 14:01:36,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:36,802 INFO:     Epoch: 62
2022-12-31 14:01:38,389 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4278324007987976, 'Total loss': 0.4278324007987976} | train loss {'Reaction outcome loss': 0.2388661910708134, 'Total loss': 0.2388661910708134}
2022-12-31 14:01:38,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:38,389 INFO:     Epoch: 63
2022-12-31 14:01:40,020 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4440578023592631, 'Total loss': 0.4440578023592631} | train loss {'Reaction outcome loss': 0.23658268020621367, 'Total loss': 0.23658268020621367}
2022-12-31 14:01:40,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:40,020 INFO:     Epoch: 64
2022-12-31 14:01:41,620 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41101038257280986, 'Total loss': 0.41101038257280986} | train loss {'Reaction outcome loss': 0.23655621154786466, 'Total loss': 0.23655621154786466}
2022-12-31 14:01:41,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:41,620 INFO:     Epoch: 65
2022-12-31 14:01:43,262 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4030052731434504, 'Total loss': 0.4030052731434504} | train loss {'Reaction outcome loss': 0.23212078513898254, 'Total loss': 0.23212078513898254}
2022-12-31 14:01:43,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:43,263 INFO:     Epoch: 66
2022-12-31 14:01:44,909 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41822550098101297, 'Total loss': 0.41822550098101297} | train loss {'Reaction outcome loss': 0.23043661797248619, 'Total loss': 0.23043661797248619}
2022-12-31 14:01:44,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:44,909 INFO:     Epoch: 67
2022-12-31 14:01:46,537 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4230223466952642, 'Total loss': 0.4230223466952642} | train loss {'Reaction outcome loss': 0.22977412333746097, 'Total loss': 0.22977412333746097}
2022-12-31 14:01:46,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:46,538 INFO:     Epoch: 68
2022-12-31 14:01:48,165 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.396633983651797, 'Total loss': 0.396633983651797} | train loss {'Reaction outcome loss': 0.2357036300794982, 'Total loss': 0.2357036300794982}
2022-12-31 14:01:48,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:48,165 INFO:     Epoch: 69
2022-12-31 14:01:49,795 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41616312265396116, 'Total loss': 0.41616312265396116} | train loss {'Reaction outcome loss': 0.2331011519791224, 'Total loss': 0.2331011519791224}
2022-12-31 14:01:49,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:49,795 INFO:     Epoch: 70
2022-12-31 14:01:51,415 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4276443970700105, 'Total loss': 0.4276443970700105} | train loss {'Reaction outcome loss': 0.22587082561637675, 'Total loss': 0.22587082561637675}
2022-12-31 14:01:51,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:51,415 INFO:     Epoch: 71
2022-12-31 14:01:53,041 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4153072665135066, 'Total loss': 0.4153072665135066} | train loss {'Reaction outcome loss': 0.2234569965100987, 'Total loss': 0.2234569965100987}
2022-12-31 14:01:53,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:53,041 INFO:     Epoch: 72
2022-12-31 14:01:54,678 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4661708960930506, 'Total loss': 0.4661708960930506} | train loss {'Reaction outcome loss': 0.22181394752865527, 'Total loss': 0.22181394752865527}
2022-12-31 14:01:54,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:54,679 INFO:     Epoch: 73
2022-12-31 14:01:56,324 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4253243923187256, 'Total loss': 0.4253243923187256} | train loss {'Reaction outcome loss': 0.21610257718643863, 'Total loss': 0.21610257718643863}
2022-12-31 14:01:56,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:56,325 INFO:     Epoch: 74
2022-12-31 14:01:57,962 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43816101749738057, 'Total loss': 0.43816101749738057} | train loss {'Reaction outcome loss': 0.2249714199098803, 'Total loss': 0.2249714199098803}
2022-12-31 14:01:57,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:57,963 INFO:     Epoch: 75
2022-12-31 14:01:59,571 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46129708687464394, 'Total loss': 0.46129708687464394} | train loss {'Reaction outcome loss': 0.22267022262235264, 'Total loss': 0.22267022262235264}
2022-12-31 14:01:59,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:01:59,571 INFO:     Epoch: 76
2022-12-31 14:02:01,205 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43818380733331047, 'Total loss': 0.43818380733331047} | train loss {'Reaction outcome loss': 0.21707165009945958, 'Total loss': 0.21707165009945958}
2022-12-31 14:02:01,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:01,205 INFO:     Epoch: 77
2022-12-31 14:02:02,833 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.387985098361969, 'Total loss': 0.387985098361969} | train loss {'Reaction outcome loss': 0.21890178214990613, 'Total loss': 0.21890178214990613}
2022-12-31 14:02:02,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:02,834 INFO:     Epoch: 78
2022-12-31 14:02:04,460 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46534859637419385, 'Total loss': 0.46534859637419385} | train loss {'Reaction outcome loss': 0.21080034831368225, 'Total loss': 0.21080034831368225}
2022-12-31 14:02:04,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:04,460 INFO:     Epoch: 79
2022-12-31 14:02:06,071 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4850188473860423, 'Total loss': 0.4850188473860423} | train loss {'Reaction outcome loss': 0.21241985793624604, 'Total loss': 0.21241985793624604}
2022-12-31 14:02:06,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:06,071 INFO:     Epoch: 80
2022-12-31 14:02:07,705 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3919881239533424, 'Total loss': 0.3919881239533424} | train loss {'Reaction outcome loss': 0.210961108945392, 'Total loss': 0.210961108945392}
2022-12-31 14:02:07,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:07,707 INFO:     Epoch: 81
2022-12-31 14:02:09,322 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44837899406751, 'Total loss': 0.44837899406751} | train loss {'Reaction outcome loss': 0.21023450757039117, 'Total loss': 0.21023450757039117}
2022-12-31 14:02:09,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:09,322 INFO:     Epoch: 82
2022-12-31 14:02:10,946 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41603992184003197, 'Total loss': 0.41603992184003197} | train loss {'Reaction outcome loss': 0.22179840044920152, 'Total loss': 0.22179840044920152}
2022-12-31 14:02:10,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:10,946 INFO:     Epoch: 83
2022-12-31 14:02:12,538 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4024786472320557, 'Total loss': 0.4024786472320557} | train loss {'Reaction outcome loss': 0.20686243568298035, 'Total loss': 0.20686243568298035}
2022-12-31 14:02:12,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:12,538 INFO:     Epoch: 84
2022-12-31 14:02:14,127 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42419950664043427, 'Total loss': 0.42419950664043427} | train loss {'Reaction outcome loss': 0.2126301984906524, 'Total loss': 0.2126301984906524}
2022-12-31 14:02:14,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:14,128 INFO:     Epoch: 85
2022-12-31 14:02:15,721 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40736071169376376, 'Total loss': 0.40736071169376376} | train loss {'Reaction outcome loss': 0.21517382658192472, 'Total loss': 0.21517382658192472}
2022-12-31 14:02:15,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:15,721 INFO:     Epoch: 86
2022-12-31 14:02:17,298 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43162972331047056, 'Total loss': 0.43162972331047056} | train loss {'Reaction outcome loss': 0.20470812359156135, 'Total loss': 0.20470812359156135}
2022-12-31 14:02:17,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:17,298 INFO:     Epoch: 87
2022-12-31 14:02:18,888 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40826778411865233, 'Total loss': 0.40826778411865233} | train loss {'Reaction outcome loss': 0.21090643172026116, 'Total loss': 0.21090643172026116}
2022-12-31 14:02:18,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:18,888 INFO:     Epoch: 88
2022-12-31 14:02:20,521 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4565525392691294, 'Total loss': 0.4565525392691294} | train loss {'Reaction outcome loss': 0.20716355388281327, 'Total loss': 0.20716355388281327}
2022-12-31 14:02:20,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:20,522 INFO:     Epoch: 89
2022-12-31 14:02:22,146 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3910212337970734, 'Total loss': 0.3910212337970734} | train loss {'Reaction outcome loss': 0.20702452727358092, 'Total loss': 0.20702452727358092}
2022-12-31 14:02:22,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:22,146 INFO:     Epoch: 90
2022-12-31 14:02:23,758 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3996641397476196, 'Total loss': 0.3996641397476196} | train loss {'Reaction outcome loss': 0.20621557039764774, 'Total loss': 0.20621557039764774}
2022-12-31 14:02:23,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:23,758 INFO:     Epoch: 91
2022-12-31 14:02:25,398 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39452381432056427, 'Total loss': 0.39452381432056427} | train loss {'Reaction outcome loss': 0.20217571424613723, 'Total loss': 0.20217571424613723}
2022-12-31 14:02:25,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:25,398 INFO:     Epoch: 92
2022-12-31 14:02:26,975 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41686930110057197, 'Total loss': 0.41686930110057197} | train loss {'Reaction outcome loss': 0.20341771135563816, 'Total loss': 0.20341771135563816}
2022-12-31 14:02:26,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:26,976 INFO:     Epoch: 93
2022-12-31 14:02:28,601 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44658981760342914, 'Total loss': 0.44658981760342914} | train loss {'Reaction outcome loss': 0.20307118546272263, 'Total loss': 0.20307118546272263}
2022-12-31 14:02:28,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:28,601 INFO:     Epoch: 94
2022-12-31 14:02:30,226 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3865565317372481, 'Total loss': 0.3865565317372481} | train loss {'Reaction outcome loss': 0.20463279563073927, 'Total loss': 0.20463279563073927}
2022-12-31 14:02:30,226 INFO:     Found new best model at epoch 94
2022-12-31 14:02:30,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:30,227 INFO:     Epoch: 95
2022-12-31 14:02:31,821 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4025560731689135, 'Total loss': 0.4025560731689135} | train loss {'Reaction outcome loss': 0.20356267350879345, 'Total loss': 0.20356267350879345}
2022-12-31 14:02:31,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:31,822 INFO:     Epoch: 96
2022-12-31 14:02:33,445 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4734507441520691, 'Total loss': 0.4734507441520691} | train loss {'Reaction outcome loss': 0.1968761301998581, 'Total loss': 0.1968761301998581}
2022-12-31 14:02:33,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:33,445 INFO:     Epoch: 97
2022-12-31 14:02:35,064 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3790807855625947, 'Total loss': 0.3790807855625947} | train loss {'Reaction outcome loss': 0.2074766674116527, 'Total loss': 0.2074766674116527}
2022-12-31 14:02:35,064 INFO:     Found new best model at epoch 97
2022-12-31 14:02:35,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:35,065 INFO:     Epoch: 98
2022-12-31 14:02:36,630 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42136544187863667, 'Total loss': 0.42136544187863667} | train loss {'Reaction outcome loss': 0.20258198099231328, 'Total loss': 0.20258198099231328}
2022-12-31 14:02:36,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:36,630 INFO:     Epoch: 99
2022-12-31 14:02:38,263 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4594597538312276, 'Total loss': 0.4594597538312276} | train loss {'Reaction outcome loss': 0.19754400405173117, 'Total loss': 0.19754400405173117}
2022-12-31 14:02:38,264 INFO:     Best model found after epoch 98 of 100.
2022-12-31 14:02:38,265 INFO:   Done with stage: TRAINING
2022-12-31 14:02:38,265 INFO:   Starting stage: EVALUATION
2022-12-31 14:02:38,406 INFO:   Done with stage: EVALUATION
2022-12-31 14:02:38,406 INFO:   Leaving out SEQ value Fold_1
2022-12-31 14:02:38,419 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 14:02:38,419 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:02:39,080 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:02:39,081 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:02:39,149 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:02:39,149 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:02:39,149 INFO:     No hyperparam tuning for this model
2022-12-31 14:02:39,149 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:02:39,149 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:02:39,150 INFO:     None feature selector for col prot
2022-12-31 14:02:39,150 INFO:     None feature selector for col prot
2022-12-31 14:02:39,150 INFO:     None feature selector for col prot
2022-12-31 14:02:39,151 INFO:     None feature selector for col chem
2022-12-31 14:02:39,151 INFO:     None feature selector for col chem
2022-12-31 14:02:39,151 INFO:     None feature selector for col chem
2022-12-31 14:02:39,151 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:02:39,151 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:02:39,153 INFO:     Number of params in model 223921
2022-12-31 14:02:39,156 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:02:39,156 INFO:   Starting stage: TRAINING
2022-12-31 14:02:39,200 INFO:     Val loss before train {'Reaction outcome loss': 1.0343959093093873, 'Total loss': 1.0343959093093873}
2022-12-31 14:02:39,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:39,200 INFO:     Epoch: 0
2022-12-31 14:02:40,839 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7301328818003336, 'Total loss': 0.7301328818003336} | train loss {'Reaction outcome loss': 0.8324707277875015, 'Total loss': 0.8324707277875015}
2022-12-31 14:02:40,839 INFO:     Found new best model at epoch 0
2022-12-31 14:02:40,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:40,840 INFO:     Epoch: 1
2022-12-31 14:02:42,442 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6187772452831268, 'Total loss': 0.6187772452831268} | train loss {'Reaction outcome loss': 0.6310957942319952, 'Total loss': 0.6310957942319952}
2022-12-31 14:02:42,442 INFO:     Found new best model at epoch 1
2022-12-31 14:02:42,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:42,443 INFO:     Epoch: 2
2022-12-31 14:02:44,026 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5524760802586873, 'Total loss': 0.5524760802586873} | train loss {'Reaction outcome loss': 0.5414081344635527, 'Total loss': 0.5414081344635527}
2022-12-31 14:02:44,026 INFO:     Found new best model at epoch 2
2022-12-31 14:02:44,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:44,027 INFO:     Epoch: 3
2022-12-31 14:02:45,614 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5859821299711864, 'Total loss': 0.5859821299711864} | train loss {'Reaction outcome loss': 0.5016518539042158, 'Total loss': 0.5016518539042158}
2022-12-31 14:02:45,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:45,615 INFO:     Epoch: 4
2022-12-31 14:02:47,229 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5073558886845907, 'Total loss': 0.5073558886845907} | train loss {'Reaction outcome loss': 0.49426164031298697, 'Total loss': 0.49426164031298697}
2022-12-31 14:02:47,229 INFO:     Found new best model at epoch 4
2022-12-31 14:02:47,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:47,230 INFO:     Epoch: 5
2022-12-31 14:02:48,833 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5030526091655095, 'Total loss': 0.5030526091655095} | train loss {'Reaction outcome loss': 0.48047314666589536, 'Total loss': 0.48047314666589536}
2022-12-31 14:02:48,834 INFO:     Found new best model at epoch 5
2022-12-31 14:02:48,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:48,835 INFO:     Epoch: 6
2022-12-31 14:02:50,446 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5139793018500011, 'Total loss': 0.5139793018500011} | train loss {'Reaction outcome loss': 0.47018638604187296, 'Total loss': 0.47018638604187296}
2022-12-31 14:02:50,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:50,446 INFO:     Epoch: 7
2022-12-31 14:02:52,048 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5340631107489268, 'Total loss': 0.5340631107489268} | train loss {'Reaction outcome loss': 0.4647658305998514, 'Total loss': 0.4647658305998514}
2022-12-31 14:02:52,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:52,048 INFO:     Epoch: 8
2022-12-31 14:02:53,645 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5161362965901692, 'Total loss': 0.5161362965901692} | train loss {'Reaction outcome loss': 0.46617856017057446, 'Total loss': 0.46617856017057446}
2022-12-31 14:02:53,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:53,646 INFO:     Epoch: 9
2022-12-31 14:02:55,239 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5096950451533, 'Total loss': 0.5096950451533} | train loss {'Reaction outcome loss': 0.46841334364717774, 'Total loss': 0.46841334364717774}
2022-12-31 14:02:55,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:55,240 INFO:     Epoch: 10
2022-12-31 14:02:56,871 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5183700303236644, 'Total loss': 0.5183700303236644} | train loss {'Reaction outcome loss': 0.4441781941720325, 'Total loss': 0.4441781941720325}
2022-12-31 14:02:56,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:56,871 INFO:     Epoch: 11
2022-12-31 14:02:58,482 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.507591023047765, 'Total loss': 0.507591023047765} | train loss {'Reaction outcome loss': 0.44143212358534767, 'Total loss': 0.44143212358534767}
2022-12-31 14:02:58,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:02:58,483 INFO:     Epoch: 12
2022-12-31 14:03:00,094 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5142703215281169, 'Total loss': 0.5142703215281169} | train loss {'Reaction outcome loss': 0.4300320514653256, 'Total loss': 0.4300320514653256}
2022-12-31 14:03:00,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:00,094 INFO:     Epoch: 13
2022-12-31 14:03:01,707 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5039700547854106, 'Total loss': 0.5039700547854106} | train loss {'Reaction outcome loss': 0.4213742696379811, 'Total loss': 0.4213742696379811}
2022-12-31 14:03:01,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:01,707 INFO:     Epoch: 14
2022-12-31 14:03:03,275 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5198033680518468, 'Total loss': 0.5198033680518468} | train loss {'Reaction outcome loss': 0.4251840375903724, 'Total loss': 0.4251840375903724}
2022-12-31 14:03:03,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:03,275 INFO:     Epoch: 15
2022-12-31 14:03:04,906 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4919338345527649, 'Total loss': 0.4919338345527649} | train loss {'Reaction outcome loss': 0.45524997112975607, 'Total loss': 0.45524997112975607}
2022-12-31 14:03:04,906 INFO:     Found new best model at epoch 15
2022-12-31 14:03:04,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:04,907 INFO:     Epoch: 16
2022-12-31 14:03:06,517 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4715423325697581, 'Total loss': 0.4715423325697581} | train loss {'Reaction outcome loss': 0.4391636793033536, 'Total loss': 0.4391636793033536}
2022-12-31 14:03:06,517 INFO:     Found new best model at epoch 16
2022-12-31 14:03:06,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:06,518 INFO:     Epoch: 17
2022-12-31 14:03:08,128 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5067462985714276, 'Total loss': 0.5067462985714276} | train loss {'Reaction outcome loss': 0.41383142186247784, 'Total loss': 0.41383142186247784}
2022-12-31 14:03:08,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:08,129 INFO:     Epoch: 18
2022-12-31 14:03:09,740 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5042329728603363, 'Total loss': 0.5042329728603363} | train loss {'Reaction outcome loss': 0.43753794179149513, 'Total loss': 0.43753794179149513}
2022-12-31 14:03:09,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:09,742 INFO:     Epoch: 19
2022-12-31 14:03:11,371 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4935387204090754, 'Total loss': 0.4935387204090754} | train loss {'Reaction outcome loss': 0.4030312558879023, 'Total loss': 0.4030312558879023}
2022-12-31 14:03:11,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:11,371 INFO:     Epoch: 20
2022-12-31 14:03:12,966 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47591144740581515, 'Total loss': 0.47591144740581515} | train loss {'Reaction outcome loss': 0.39166722909351886, 'Total loss': 0.39166722909351886}
2022-12-31 14:03:12,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:12,966 INFO:     Epoch: 21
2022-12-31 14:03:14,583 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.466490176320076, 'Total loss': 0.466490176320076} | train loss {'Reaction outcome loss': 0.37907865930827794, 'Total loss': 0.37907865930827794}
2022-12-31 14:03:14,583 INFO:     Found new best model at epoch 21
2022-12-31 14:03:14,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:14,584 INFO:     Epoch: 22
2022-12-31 14:03:16,199 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4876481393973033, 'Total loss': 0.4876481393973033} | train loss {'Reaction outcome loss': 0.3752495217444105, 'Total loss': 0.3752495217444105}
2022-12-31 14:03:16,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:16,200 INFO:     Epoch: 23
2022-12-31 14:03:17,814 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44126081963380176, 'Total loss': 0.44126081963380176} | train loss {'Reaction outcome loss': 0.37106321204075776, 'Total loss': 0.37106321204075776}
2022-12-31 14:03:17,814 INFO:     Found new best model at epoch 23
2022-12-31 14:03:17,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:17,815 INFO:     Epoch: 24
2022-12-31 14:03:19,428 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5059883534908295, 'Total loss': 0.5059883534908295} | train loss {'Reaction outcome loss': 0.37201466168398445, 'Total loss': 0.37201466168398445}
2022-12-31 14:03:19,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:19,428 INFO:     Epoch: 25
2022-12-31 14:03:20,998 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4696301301320394, 'Total loss': 0.4696301301320394} | train loss {'Reaction outcome loss': 0.372974623336315, 'Total loss': 0.372974623336315}
2022-12-31 14:03:20,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:20,998 INFO:     Epoch: 26
2022-12-31 14:03:22,610 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4595859666665395, 'Total loss': 0.4595859666665395} | train loss {'Reaction outcome loss': 0.36006718204547383, 'Total loss': 0.36006718204547383}
2022-12-31 14:03:22,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:22,610 INFO:     Epoch: 27
2022-12-31 14:03:24,223 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4458722571531932, 'Total loss': 0.4458722571531932} | train loss {'Reaction outcome loss': 0.3508899650819924, 'Total loss': 0.3508899650819924}
2022-12-31 14:03:24,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:24,224 INFO:     Epoch: 28
2022-12-31 14:03:25,868 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46050553818543755, 'Total loss': 0.46050553818543755} | train loss {'Reaction outcome loss': 0.35038708358280496, 'Total loss': 0.35038708358280496}
2022-12-31 14:03:25,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:25,868 INFO:     Epoch: 29
2022-12-31 14:03:27,504 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4457005192836126, 'Total loss': 0.4457005192836126} | train loss {'Reaction outcome loss': 0.34441172663165437, 'Total loss': 0.34441172663165437}
2022-12-31 14:03:27,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:27,504 INFO:     Epoch: 30
2022-12-31 14:03:29,095 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4488634685675303, 'Total loss': 0.4488634685675303} | train loss {'Reaction outcome loss': 0.34187101811150333, 'Total loss': 0.34187101811150333}
2022-12-31 14:03:29,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:29,096 INFO:     Epoch: 31
2022-12-31 14:03:30,701 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4580922037363052, 'Total loss': 0.4580922037363052} | train loss {'Reaction outcome loss': 0.3350015970274293, 'Total loss': 0.3350015970274293}
2022-12-31 14:03:30,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:30,701 INFO:     Epoch: 32
2022-12-31 14:03:32,341 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49959258834520975, 'Total loss': 0.49959258834520975} | train loss {'Reaction outcome loss': 0.3250980605679207, 'Total loss': 0.3250980605679207}
2022-12-31 14:03:32,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:32,342 INFO:     Epoch: 33
2022-12-31 14:03:33,954 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4703519413868586, 'Total loss': 0.4703519413868586} | train loss {'Reaction outcome loss': 0.32886331694865384, 'Total loss': 0.32886331694865384}
2022-12-31 14:03:33,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:33,954 INFO:     Epoch: 34
2022-12-31 14:03:35,560 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4658367683490117, 'Total loss': 0.4658367683490117} | train loss {'Reaction outcome loss': 0.3263451643321879, 'Total loss': 0.3263451643321879}
2022-12-31 14:03:35,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:35,560 INFO:     Epoch: 35
2022-12-31 14:03:37,166 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4630014896392822, 'Total loss': 0.4630014896392822} | train loss {'Reaction outcome loss': 0.31127685850715614, 'Total loss': 0.31127685850715614}
2022-12-31 14:03:37,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:37,166 INFO:     Epoch: 36
2022-12-31 14:03:38,760 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4452871799468994, 'Total loss': 0.4452871799468994} | train loss {'Reaction outcome loss': 0.3144446858621226, 'Total loss': 0.3144446858621226}
2022-12-31 14:03:38,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:38,760 INFO:     Epoch: 37
2022-12-31 14:03:40,358 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4608868281046549, 'Total loss': 0.4608868281046549} | train loss {'Reaction outcome loss': 0.30921901952799247, 'Total loss': 0.30921901952799247}
2022-12-31 14:03:40,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:40,359 INFO:     Epoch: 38
2022-12-31 14:03:41,965 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47122017443180086, 'Total loss': 0.47122017443180086} | train loss {'Reaction outcome loss': 0.3062412525220113, 'Total loss': 0.3062412525220113}
2022-12-31 14:03:41,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:41,965 INFO:     Epoch: 39
2022-12-31 14:03:43,575 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44313269257545473, 'Total loss': 0.44313269257545473} | train loss {'Reaction outcome loss': 0.3041710153667499, 'Total loss': 0.3041710153667499}
2022-12-31 14:03:43,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:43,576 INFO:     Epoch: 40
2022-12-31 14:03:45,180 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4615107556184133, 'Total loss': 0.4615107556184133} | train loss {'Reaction outcome loss': 0.3030205829940482, 'Total loss': 0.3030205829940482}
2022-12-31 14:03:45,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:45,181 INFO:     Epoch: 41
2022-12-31 14:03:46,792 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48640337884426116, 'Total loss': 0.48640337884426116} | train loss {'Reaction outcome loss': 0.29432102237942803, 'Total loss': 0.29432102237942803}
2022-12-31 14:03:46,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:46,792 INFO:     Epoch: 42
2022-12-31 14:03:48,366 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47346842487653096, 'Total loss': 0.47346842487653096} | train loss {'Reaction outcome loss': 0.3079750690123309, 'Total loss': 0.3079750690123309}
2022-12-31 14:03:48,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:48,366 INFO:     Epoch: 43
2022-12-31 14:03:49,979 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.467053551475207, 'Total loss': 0.467053551475207} | train loss {'Reaction outcome loss': 0.3361884484065872, 'Total loss': 0.3361884484065872}
2022-12-31 14:03:49,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:49,979 INFO:     Epoch: 44
2022-12-31 14:03:51,590 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45799426635106405, 'Total loss': 0.45799426635106405} | train loss {'Reaction outcome loss': 0.28794109754196234, 'Total loss': 0.28794109754196234}
2022-12-31 14:03:51,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:51,591 INFO:     Epoch: 45
2022-12-31 14:03:53,203 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44058067301909126, 'Total loss': 0.44058067301909126} | train loss {'Reaction outcome loss': 0.2878908950673497, 'Total loss': 0.2878908950673497}
2022-12-31 14:03:53,203 INFO:     Found new best model at epoch 45
2022-12-31 14:03:53,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:53,204 INFO:     Epoch: 46
2022-12-31 14:03:54,813 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47205307086308795, 'Total loss': 0.47205307086308795} | train loss {'Reaction outcome loss': 0.3297207920771578, 'Total loss': 0.3297207920771578}
2022-12-31 14:03:54,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:54,813 INFO:     Epoch: 47
2022-12-31 14:03:56,402 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45959553321202595, 'Total loss': 0.45959553321202595} | train loss {'Reaction outcome loss': 0.2859669767300754, 'Total loss': 0.2859669767300754}
2022-12-31 14:03:56,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:56,402 INFO:     Epoch: 48
2022-12-31 14:03:58,001 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45310419201850893, 'Total loss': 0.45310419201850893} | train loss {'Reaction outcome loss': 0.27405235638329084, 'Total loss': 0.27405235638329084}
2022-12-31 14:03:58,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:58,001 INFO:     Epoch: 49
2022-12-31 14:03:59,614 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4495653768380483, 'Total loss': 0.4495653768380483} | train loss {'Reaction outcome loss': 0.2824904917253424, 'Total loss': 0.2824904917253424}
2022-12-31 14:03:59,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:03:59,614 INFO:     Epoch: 50
2022-12-31 14:04:01,227 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4773377905289332, 'Total loss': 0.4773377905289332} | train loss {'Reaction outcome loss': 0.3042330327823394, 'Total loss': 0.3042330327823394}
2022-12-31 14:04:01,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:01,227 INFO:     Epoch: 51
2022-12-31 14:04:02,839 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4932833770910899, 'Total loss': 0.4932833770910899} | train loss {'Reaction outcome loss': 0.27650806627681723, 'Total loss': 0.27650806627681723}
2022-12-31 14:04:02,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:02,839 INFO:     Epoch: 52
2022-12-31 14:04:04,449 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4501468459765116, 'Total loss': 0.4501468459765116} | train loss {'Reaction outcome loss': 0.28066239984658803, 'Total loss': 0.28066239984658803}
2022-12-31 14:04:04,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:04,450 INFO:     Epoch: 53
2022-12-31 14:04:06,024 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47875214119752246, 'Total loss': 0.47875214119752246} | train loss {'Reaction outcome loss': 0.2727640288484627, 'Total loss': 0.2727640288484627}
2022-12-31 14:04:06,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:06,024 INFO:     Epoch: 54
2022-12-31 14:04:07,633 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4734097868204117, 'Total loss': 0.4734097868204117} | train loss {'Reaction outcome loss': 0.2669433179729875, 'Total loss': 0.2669433179729875}
2022-12-31 14:04:07,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:07,633 INFO:     Epoch: 55
2022-12-31 14:04:09,244 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4469163010517756, 'Total loss': 0.4469163010517756} | train loss {'Reaction outcome loss': 0.26072770720381505, 'Total loss': 0.26072770720381505}
2022-12-31 14:04:09,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:09,244 INFO:     Epoch: 56
2022-12-31 14:04:10,888 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45075668692588805, 'Total loss': 0.45075668692588805} | train loss {'Reaction outcome loss': 0.26128253592363815, 'Total loss': 0.26128253592363815}
2022-12-31 14:04:10,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:10,888 INFO:     Epoch: 57
2022-12-31 14:04:12,544 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4507303963104884, 'Total loss': 0.4507303963104884} | train loss {'Reaction outcome loss': 0.26281161015124427, 'Total loss': 0.26281161015124427}
2022-12-31 14:04:12,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:12,544 INFO:     Epoch: 58
2022-12-31 14:04:14,144 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46704448958237965, 'Total loss': 0.46704448958237965} | train loss {'Reaction outcome loss': 0.263618039502931, 'Total loss': 0.263618039502931}
2022-12-31 14:04:14,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:14,145 INFO:     Epoch: 59
2022-12-31 14:04:15,728 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47399381597836815, 'Total loss': 0.47399381597836815} | train loss {'Reaction outcome loss': 0.2628201504454225, 'Total loss': 0.2628201504454225}
2022-12-31 14:04:15,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:15,728 INFO:     Epoch: 60
2022-12-31 14:04:17,337 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5161792616049449, 'Total loss': 0.5161792616049449} | train loss {'Reaction outcome loss': 0.2537379781536309, 'Total loss': 0.2537379781536309}
2022-12-31 14:04:17,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:17,337 INFO:     Epoch: 61
2022-12-31 14:04:18,947 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45816966394583386, 'Total loss': 0.45816966394583386} | train loss {'Reaction outcome loss': 0.2596978332536916, 'Total loss': 0.2596978332536916}
2022-12-31 14:04:18,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:18,947 INFO:     Epoch: 62
2022-12-31 14:04:20,551 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4715085337559382, 'Total loss': 0.4715085337559382} | train loss {'Reaction outcome loss': 0.25223504605811037, 'Total loss': 0.25223504605811037}
2022-12-31 14:04:20,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:20,553 INFO:     Epoch: 63
2022-12-31 14:04:22,167 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4095020612080892, 'Total loss': 0.4095020612080892} | train loss {'Reaction outcome loss': 0.25511295453010907, 'Total loss': 0.25511295453010907}
2022-12-31 14:04:22,167 INFO:     Found new best model at epoch 63
2022-12-31 14:04:22,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:22,168 INFO:     Epoch: 64
2022-12-31 14:04:23,758 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4591217945019404, 'Total loss': 0.4591217945019404} | train loss {'Reaction outcome loss': 0.24845603069938396, 'Total loss': 0.24845603069938396}
2022-12-31 14:04:23,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:23,758 INFO:     Epoch: 65
2022-12-31 14:04:25,359 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47304110129674276, 'Total loss': 0.47304110129674276} | train loss {'Reaction outcome loss': 0.24646799183967127, 'Total loss': 0.24646799183967127}
2022-12-31 14:04:25,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:25,360 INFO:     Epoch: 66
2022-12-31 14:04:26,966 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4633579909801483, 'Total loss': 0.4633579909801483} | train loss {'Reaction outcome loss': 0.2490385442810214, 'Total loss': 0.2490385442810214}
2022-12-31 14:04:26,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:26,967 INFO:     Epoch: 67
2022-12-31 14:04:28,572 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45855699578921, 'Total loss': 0.45855699578921} | train loss {'Reaction outcome loss': 0.28490759912824287, 'Total loss': 0.28490759912824287}
2022-12-31 14:04:28,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:28,573 INFO:     Epoch: 68
2022-12-31 14:04:30,180 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4483982389171918, 'Total loss': 0.4483982389171918} | train loss {'Reaction outcome loss': 0.2495679600230516, 'Total loss': 0.2495679600230516}
2022-12-31 14:04:30,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:30,180 INFO:     Epoch: 69
2022-12-31 14:04:31,787 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46450119018554686, 'Total loss': 0.46450119018554686} | train loss {'Reaction outcome loss': 0.24336649092805127, 'Total loss': 0.24336649092805127}
2022-12-31 14:04:31,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:31,787 INFO:     Epoch: 70
2022-12-31 14:04:33,368 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45933014651139575, 'Total loss': 0.45933014651139575} | train loss {'Reaction outcome loss': 0.2766069971399122, 'Total loss': 0.2766069971399122}
2022-12-31 14:04:33,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:33,368 INFO:     Epoch: 71
2022-12-31 14:04:34,973 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4578356097141902, 'Total loss': 0.4578356097141902} | train loss {'Reaction outcome loss': 0.24020554073702416, 'Total loss': 0.24020554073702416}
2022-12-31 14:04:34,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:34,974 INFO:     Epoch: 72
2022-12-31 14:04:36,579 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4623009592294693, 'Total loss': 0.4623009592294693} | train loss {'Reaction outcome loss': 0.23406549710426075, 'Total loss': 0.23406549710426075}
2022-12-31 14:04:36,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:36,580 INFO:     Epoch: 73
2022-12-31 14:04:38,184 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48610629364848135, 'Total loss': 0.48610629364848135} | train loss {'Reaction outcome loss': 0.2396753745329013, 'Total loss': 0.2396753745329013}
2022-12-31 14:04:38,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:38,185 INFO:     Epoch: 74
2022-12-31 14:04:39,791 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4411684403816859, 'Total loss': 0.4411684403816859} | train loss {'Reaction outcome loss': 0.2305449112014764, 'Total loss': 0.2305449112014764}
2022-12-31 14:04:39,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:39,792 INFO:     Epoch: 75
2022-12-31 14:04:41,378 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4589768648147583, 'Total loss': 0.4589768648147583} | train loss {'Reaction outcome loss': 0.23493052826708424, 'Total loss': 0.23493052826708424}
2022-12-31 14:04:41,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:41,378 INFO:     Epoch: 76
2022-12-31 14:04:42,967 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4467039108276367, 'Total loss': 0.4467039108276367} | train loss {'Reaction outcome loss': 0.22992231393974458, 'Total loss': 0.22992231393974458}
2022-12-31 14:04:42,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:42,968 INFO:     Epoch: 77
2022-12-31 14:04:44,575 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43696460922559105, 'Total loss': 0.43696460922559105} | train loss {'Reaction outcome loss': 0.22558650331895636, 'Total loss': 0.22558650331895636}
2022-12-31 14:04:44,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:44,575 INFO:     Epoch: 78
2022-12-31 14:04:46,176 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45229999075333277, 'Total loss': 0.45229999075333277} | train loss {'Reaction outcome loss': 0.2226924845702909, 'Total loss': 0.2226924845702909}
2022-12-31 14:04:46,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:46,176 INFO:     Epoch: 79
2022-12-31 14:04:47,794 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4572362005710602, 'Total loss': 0.4572362005710602} | train loss {'Reaction outcome loss': 0.22875008383593726, 'Total loss': 0.22875008383593726}
2022-12-31 14:04:47,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:47,794 INFO:     Epoch: 80
2022-12-31 14:04:49,400 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4615149160226186, 'Total loss': 0.4615149160226186} | train loss {'Reaction outcome loss': 0.22851360118205566, 'Total loss': 0.22851360118205566}
2022-12-31 14:04:49,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:49,400 INFO:     Epoch: 81
2022-12-31 14:04:50,960 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4712841105957826, 'Total loss': 0.4712841105957826} | train loss {'Reaction outcome loss': 0.22309185261455886, 'Total loss': 0.22309185261455886}
2022-12-31 14:04:50,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:50,961 INFO:     Epoch: 82
2022-12-31 14:04:52,565 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4297642966111501, 'Total loss': 0.4297642966111501} | train loss {'Reaction outcome loss': 0.21843494674583885, 'Total loss': 0.21843494674583885}
2022-12-31 14:04:52,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:52,566 INFO:     Epoch: 83
2022-12-31 14:04:54,171 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5202170481284459, 'Total loss': 0.5202170481284459} | train loss {'Reaction outcome loss': 0.22523633462201426, 'Total loss': 0.22523633462201426}
2022-12-31 14:04:54,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:54,171 INFO:     Epoch: 84
2022-12-31 14:04:55,777 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4761625438928604, 'Total loss': 0.4761625438928604} | train loss {'Reaction outcome loss': 0.22398592987978508, 'Total loss': 0.22398592987978508}
2022-12-31 14:04:55,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:55,777 INFO:     Epoch: 85
2022-12-31 14:04:57,396 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4493398795525233, 'Total loss': 0.4493398795525233} | train loss {'Reaction outcome loss': 0.22103269913982923, 'Total loss': 0.22103269913982923}
2022-12-31 14:04:57,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:57,397 INFO:     Epoch: 86
2022-12-31 14:04:59,011 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47713050146897634, 'Total loss': 0.47713050146897634} | train loss {'Reaction outcome loss': 0.21802816271150915, 'Total loss': 0.21802816271150915}
2022-12-31 14:04:59,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:04:59,011 INFO:     Epoch: 87
2022-12-31 14:05:00,622 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46540457208951314, 'Total loss': 0.46540457208951314} | train loss {'Reaction outcome loss': 0.22057171602727318, 'Total loss': 0.22057171602727318}
2022-12-31 14:05:00,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:00,622 INFO:     Epoch: 88
2022-12-31 14:05:02,254 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44445761740207673, 'Total loss': 0.44445761740207673} | train loss {'Reaction outcome loss': 0.21385246746895986, 'Total loss': 0.21385246746895986}
2022-12-31 14:05:02,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:02,254 INFO:     Epoch: 89
2022-12-31 14:05:03,866 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44982298612594607, 'Total loss': 0.44982298612594607} | train loss {'Reaction outcome loss': 0.2132431569689947, 'Total loss': 0.2132431569689947}
2022-12-31 14:05:03,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:03,866 INFO:     Epoch: 90
2022-12-31 14:05:05,479 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4509120543797811, 'Total loss': 0.4509120543797811} | train loss {'Reaction outcome loss': 0.21233003732302916, 'Total loss': 0.21233003732302916}
2022-12-31 14:05:05,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:05,479 INFO:     Epoch: 91
2022-12-31 14:05:07,091 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4547070533037186, 'Total loss': 0.4547070533037186} | train loss {'Reaction outcome loss': 0.21521571925773786, 'Total loss': 0.21521571925773786}
2022-12-31 14:05:07,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:07,091 INFO:     Epoch: 92
2022-12-31 14:05:08,693 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43539724151293435, 'Total loss': 0.43539724151293435} | train loss {'Reaction outcome loss': 0.20781483004511625, 'Total loss': 0.20781483004511625}
2022-12-31 14:05:08,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:08,693 INFO:     Epoch: 93
2022-12-31 14:05:10,291 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46962619125843047, 'Total loss': 0.46962619125843047} | train loss {'Reaction outcome loss': 0.20683591640419394, 'Total loss': 0.20683591640419394}
2022-12-31 14:05:10,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:10,292 INFO:     Epoch: 94
2022-12-31 14:05:11,903 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4391695916652679, 'Total loss': 0.4391695916652679} | train loss {'Reaction outcome loss': 0.2140163108303133, 'Total loss': 0.2140163108303133}
2022-12-31 14:05:11,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:11,903 INFO:     Epoch: 95
2022-12-31 14:05:13,543 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.434410106142362, 'Total loss': 0.434410106142362} | train loss {'Reaction outcome loss': 0.20663445220882262, 'Total loss': 0.20663445220882262}
2022-12-31 14:05:13,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:13,544 INFO:     Epoch: 96
2022-12-31 14:05:15,164 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44546606838703157, 'Total loss': 0.44546606838703157} | train loss {'Reaction outcome loss': 0.20558270405445658, 'Total loss': 0.20558270405445658}
2022-12-31 14:05:15,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:15,164 INFO:     Epoch: 97
2022-12-31 14:05:16,789 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4300139367580414, 'Total loss': 0.4300139367580414} | train loss {'Reaction outcome loss': 0.20308218418790933, 'Total loss': 0.20308218418790933}
2022-12-31 14:05:16,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:16,790 INFO:     Epoch: 98
2022-12-31 14:05:18,374 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4570101002852122, 'Total loss': 0.4570101002852122} | train loss {'Reaction outcome loss': 0.2064030080948504, 'Total loss': 0.2064030080948504}
2022-12-31 14:05:18,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:18,374 INFO:     Epoch: 99
2022-12-31 14:05:20,014 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45137220273415246, 'Total loss': 0.45137220273415246} | train loss {'Reaction outcome loss': 0.1991575253331035, 'Total loss': 0.1991575253331035}
2022-12-31 14:05:20,014 INFO:     Best model found after epoch 64 of 100.
2022-12-31 14:05:20,015 INFO:   Done with stage: TRAINING
2022-12-31 14:05:20,015 INFO:   Starting stage: EVALUATION
2022-12-31 14:05:20,143 INFO:   Done with stage: EVALUATION
2022-12-31 14:05:20,143 INFO:   Leaving out SEQ value Fold_2
2022-12-31 14:05:20,156 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 14:05:20,156 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:05:20,818 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:05:20,818 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:05:20,888 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:05:20,888 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:05:20,888 INFO:     No hyperparam tuning for this model
2022-12-31 14:05:20,889 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:05:20,889 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:05:20,889 INFO:     None feature selector for col prot
2022-12-31 14:05:20,889 INFO:     None feature selector for col prot
2022-12-31 14:05:20,889 INFO:     None feature selector for col prot
2022-12-31 14:05:20,890 INFO:     None feature selector for col chem
2022-12-31 14:05:20,890 INFO:     None feature selector for col chem
2022-12-31 14:05:20,890 INFO:     None feature selector for col chem
2022-12-31 14:05:20,890 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:05:20,890 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:05:20,892 INFO:     Number of params in model 223921
2022-12-31 14:05:20,895 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:05:20,895 INFO:   Starting stage: TRAINING
2022-12-31 14:05:20,941 INFO:     Val loss before train {'Reaction outcome loss': 0.9751269320646921, 'Total loss': 0.9751269320646921}
2022-12-31 14:05:20,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:20,942 INFO:     Epoch: 0
2022-12-31 14:05:22,537 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6606202443440755, 'Total loss': 0.6606202443440755} | train loss {'Reaction outcome loss': 0.8427335012963403, 'Total loss': 0.8427335012963403}
2022-12-31 14:05:22,538 INFO:     Found new best model at epoch 0
2022-12-31 14:05:22,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:22,539 INFO:     Epoch: 1
2022-12-31 14:05:24,135 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5230475962162018, 'Total loss': 0.5230475962162018} | train loss {'Reaction outcome loss': 0.6120761873084547, 'Total loss': 0.6120761873084547}
2022-12-31 14:05:24,135 INFO:     Found new best model at epoch 1
2022-12-31 14:05:24,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:24,136 INFO:     Epoch: 2
2022-12-31 14:05:25,733 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47124823853373526, 'Total loss': 0.47124823853373526} | train loss {'Reaction outcome loss': 0.5350458022657332, 'Total loss': 0.5350458022657332}
2022-12-31 14:05:25,733 INFO:     Found new best model at epoch 2
2022-12-31 14:05:25,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:25,734 INFO:     Epoch: 3
2022-12-31 14:05:27,294 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4722654938697815, 'Total loss': 0.4722654938697815} | train loss {'Reaction outcome loss': 0.5069920978757925, 'Total loss': 0.5069920978757925}
2022-12-31 14:05:27,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:27,295 INFO:     Epoch: 4
2022-12-31 14:05:28,888 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4742757419745127, 'Total loss': 0.4742757419745127} | train loss {'Reaction outcome loss': 0.49550719220778006, 'Total loss': 0.49550719220778006}
2022-12-31 14:05:28,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:28,889 INFO:     Epoch: 5
2022-12-31 14:05:30,483 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48495891491572063, 'Total loss': 0.48495891491572063} | train loss {'Reaction outcome loss': 0.4879140772007324, 'Total loss': 0.4879140772007324}
2022-12-31 14:05:30,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:30,484 INFO:     Epoch: 6
2022-12-31 14:05:32,077 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4667704274257024, 'Total loss': 0.4667704274257024} | train loss {'Reaction outcome loss': 0.4753064763742489, 'Total loss': 0.4753064763742489}
2022-12-31 14:05:32,077 INFO:     Found new best model at epoch 6
2022-12-31 14:05:32,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:32,078 INFO:     Epoch: 7
2022-12-31 14:05:33,718 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4569899121920268, 'Total loss': 0.4569899121920268} | train loss {'Reaction outcome loss': 0.46942293851366845, 'Total loss': 0.46942293851366845}
2022-12-31 14:05:33,718 INFO:     Found new best model at epoch 7
2022-12-31 14:05:33,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:33,719 INFO:     Epoch: 8
2022-12-31 14:05:35,329 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5189839859803518, 'Total loss': 0.5189839859803518} | train loss {'Reaction outcome loss': 0.4625458304698651, 'Total loss': 0.4625458304698651}
2022-12-31 14:05:35,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:35,330 INFO:     Epoch: 9
2022-12-31 14:05:36,913 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4377016693353653, 'Total loss': 0.4377016693353653} | train loss {'Reaction outcome loss': 0.4496240353027543, 'Total loss': 0.4496240353027543}
2022-12-31 14:05:36,913 INFO:     Found new best model at epoch 9
2022-12-31 14:05:36,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:36,914 INFO:     Epoch: 10
2022-12-31 14:05:38,505 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4322265863418579, 'Total loss': 0.4322265863418579} | train loss {'Reaction outcome loss': 0.44466352326311037, 'Total loss': 0.44466352326311037}
2022-12-31 14:05:38,505 INFO:     Found new best model at epoch 10
2022-12-31 14:05:38,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:38,506 INFO:     Epoch: 11
2022-12-31 14:05:40,098 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46265273094177245, 'Total loss': 0.46265273094177245} | train loss {'Reaction outcome loss': 0.4367661593829865, 'Total loss': 0.4367661593829865}
2022-12-31 14:05:40,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:40,098 INFO:     Epoch: 12
2022-12-31 14:05:41,691 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4296916325887044, 'Total loss': 0.4296916325887044} | train loss {'Reaction outcome loss': 0.43528313154265996, 'Total loss': 0.43528313154265996}
2022-12-31 14:05:41,692 INFO:     Found new best model at epoch 12
2022-12-31 14:05:41,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:41,693 INFO:     Epoch: 13
2022-12-31 14:05:43,331 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43597090045611064, 'Total loss': 0.43597090045611064} | train loss {'Reaction outcome loss': 0.4293768541280167, 'Total loss': 0.4293768541280167}
2022-12-31 14:05:43,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:43,331 INFO:     Epoch: 14
2022-12-31 14:05:44,893 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4066182551284631, 'Total loss': 0.4066182551284631} | train loss {'Reaction outcome loss': 0.4239109199999016, 'Total loss': 0.4239109199999016}
2022-12-31 14:05:44,893 INFO:     Found new best model at epoch 14
2022-12-31 14:05:44,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:44,894 INFO:     Epoch: 15
2022-12-31 14:05:46,478 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4687175353368123, 'Total loss': 0.4687175353368123} | train loss {'Reaction outcome loss': 0.41239086243804995, 'Total loss': 0.41239086243804995}
2022-12-31 14:05:46,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:46,478 INFO:     Epoch: 16
2022-12-31 14:05:48,068 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41139653126398723, 'Total loss': 0.41139653126398723} | train loss {'Reaction outcome loss': 0.4082371379375021, 'Total loss': 0.4082371379375021}
2022-12-31 14:05:48,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:48,069 INFO:     Epoch: 17
2022-12-31 14:05:49,659 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4009048044681549, 'Total loss': 0.4009048044681549} | train loss {'Reaction outcome loss': 0.4047277902454247, 'Total loss': 0.4047277902454247}
2022-12-31 14:05:49,659 INFO:     Found new best model at epoch 17
2022-12-31 14:05:49,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:49,660 INFO:     Epoch: 18
2022-12-31 14:05:51,258 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4186025003592173, 'Total loss': 0.4186025003592173} | train loss {'Reaction outcome loss': 0.4021136231529407, 'Total loss': 0.4021136231529407}
2022-12-31 14:05:51,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:51,258 INFO:     Epoch: 19
2022-12-31 14:05:52,853 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40596861640612286, 'Total loss': 0.40596861640612286} | train loss {'Reaction outcome loss': 0.39023526577831624, 'Total loss': 0.39023526577831624}
2022-12-31 14:05:52,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:52,853 INFO:     Epoch: 20
2022-12-31 14:05:54,416 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4417931000391642, 'Total loss': 0.4417931000391642} | train loss {'Reaction outcome loss': 0.3860486558068803, 'Total loss': 0.3860486558068803}
2022-12-31 14:05:54,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:54,416 INFO:     Epoch: 21
2022-12-31 14:05:56,010 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4180546969175339, 'Total loss': 0.4180546969175339} | train loss {'Reaction outcome loss': 0.38091246756441866, 'Total loss': 0.38091246756441866}
2022-12-31 14:05:56,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:56,010 INFO:     Epoch: 22
2022-12-31 14:05:57,606 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42262534499168397, 'Total loss': 0.42262534499168397} | train loss {'Reaction outcome loss': 0.3723170430887313, 'Total loss': 0.3723170430887313}
2022-12-31 14:05:57,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:57,607 INFO:     Epoch: 23
2022-12-31 14:05:59,201 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4481622596581777, 'Total loss': 0.4481622596581777} | train loss {'Reaction outcome loss': 0.36943982787184665, 'Total loss': 0.36943982787184665}
2022-12-31 14:05:59,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:05:59,202 INFO:     Epoch: 24
2022-12-31 14:06:00,796 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39977337916692096, 'Total loss': 0.39977337916692096} | train loss {'Reaction outcome loss': 0.36608546336382736, 'Total loss': 0.36608546336382736}
2022-12-31 14:06:00,796 INFO:     Found new best model at epoch 24
2022-12-31 14:06:00,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:00,797 INFO:     Epoch: 25
2022-12-31 14:06:02,367 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39409947395324707, 'Total loss': 0.39409947395324707} | train loss {'Reaction outcome loss': 0.35804411064792463, 'Total loss': 0.35804411064792463}
2022-12-31 14:06:02,367 INFO:     Found new best model at epoch 25
2022-12-31 14:06:02,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:02,368 INFO:     Epoch: 26
2022-12-31 14:06:03,944 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43330492774645485, 'Total loss': 0.43330492774645485} | train loss {'Reaction outcome loss': 0.36224191712263304, 'Total loss': 0.36224191712263304}
2022-12-31 14:06:03,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:03,945 INFO:     Epoch: 27
2022-12-31 14:06:05,539 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42481228013833366, 'Total loss': 0.42481228013833366} | train loss {'Reaction outcome loss': 0.3515333073152291, 'Total loss': 0.3515333073152291}
2022-12-31 14:06:05,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:05,539 INFO:     Epoch: 28
2022-12-31 14:06:07,134 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41251734644174576, 'Total loss': 0.41251734644174576} | train loss {'Reaction outcome loss': 0.3395886269735766, 'Total loss': 0.3395886269735766}
2022-12-31 14:06:07,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:07,134 INFO:     Epoch: 29
2022-12-31 14:06:08,729 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4127090319991112, 'Total loss': 0.4127090319991112} | train loss {'Reaction outcome loss': 0.33670886866611877, 'Total loss': 0.33670886866611877}
2022-12-31 14:06:08,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:08,729 INFO:     Epoch: 30
2022-12-31 14:06:10,325 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38703453838825225, 'Total loss': 0.38703453838825225} | train loss {'Reaction outcome loss': 0.3261468275398998, 'Total loss': 0.3261468275398998}
2022-12-31 14:06:10,325 INFO:     Found new best model at epoch 30
2022-12-31 14:06:10,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:10,326 INFO:     Epoch: 31
2022-12-31 14:06:11,892 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.35661108841498695, 'Total loss': 0.35661108841498695} | train loss {'Reaction outcome loss': 0.3232940798523007, 'Total loss': 0.3232940798523007}
2022-12-31 14:06:11,892 INFO:     Found new best model at epoch 31
2022-12-31 14:06:11,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:11,893 INFO:     Epoch: 32
2022-12-31 14:06:13,484 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4289305071036021, 'Total loss': 0.4289305071036021} | train loss {'Reaction outcome loss': 0.32526047091126004, 'Total loss': 0.32526047091126004}
2022-12-31 14:06:13,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:13,484 INFO:     Epoch: 33
2022-12-31 14:06:15,081 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40473121404647827, 'Total loss': 0.40473121404647827} | train loss {'Reaction outcome loss': 0.315933165553234, 'Total loss': 0.315933165553234}
2022-12-31 14:06:15,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:15,081 INFO:     Epoch: 34
2022-12-31 14:06:16,676 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4332749158143997, 'Total loss': 0.4332749158143997} | train loss {'Reaction outcome loss': 0.3135227080802996, 'Total loss': 0.3135227080802996}
2022-12-31 14:06:16,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:16,677 INFO:     Epoch: 35
2022-12-31 14:06:18,272 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39917045533657075, 'Total loss': 0.39917045533657075} | train loss {'Reaction outcome loss': 0.3054889057227325, 'Total loss': 0.3054889057227325}
2022-12-31 14:06:18,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:18,272 INFO:     Epoch: 36
2022-12-31 14:06:19,868 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41953884859879814, 'Total loss': 0.41953884859879814} | train loss {'Reaction outcome loss': 0.30638186988376437, 'Total loss': 0.30638186988376437}
2022-12-31 14:06:19,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:19,868 INFO:     Epoch: 37
2022-12-31 14:06:21,429 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3867654139796893, 'Total loss': 0.3867654139796893} | train loss {'Reaction outcome loss': 0.3039570143889813, 'Total loss': 0.3039570143889813}
2022-12-31 14:06:21,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:21,429 INFO:     Epoch: 38
2022-12-31 14:06:23,024 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3879506958027681, 'Total loss': 0.3879506958027681} | train loss {'Reaction outcome loss': 0.3024622736287204, 'Total loss': 0.3024622736287204}
2022-12-31 14:06:23,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:23,024 INFO:     Epoch: 39
2022-12-31 14:06:24,619 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40796187122662864, 'Total loss': 0.40796187122662864} | train loss {'Reaction outcome loss': 0.28482703101776896, 'Total loss': 0.28482703101776896}
2022-12-31 14:06:24,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:24,619 INFO:     Epoch: 40
2022-12-31 14:06:26,218 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4516300956408183, 'Total loss': 0.4516300956408183} | train loss {'Reaction outcome loss': 0.2900504922091743, 'Total loss': 0.2900504922091743}
2022-12-31 14:06:26,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:26,218 INFO:     Epoch: 41
2022-12-31 14:06:27,813 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4292690267165502, 'Total loss': 0.4292690267165502} | train loss {'Reaction outcome loss': 0.2901322088125861, 'Total loss': 0.2901322088125861}
2022-12-31 14:06:27,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:27,813 INFO:     Epoch: 42
2022-12-31 14:06:29,388 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3914010336001714, 'Total loss': 0.3914010336001714} | train loss {'Reaction outcome loss': 0.27850015645662507, 'Total loss': 0.27850015645662507}
2022-12-31 14:06:29,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:29,390 INFO:     Epoch: 43
2022-12-31 14:06:30,966 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3752695510784785, 'Total loss': 0.3752695510784785} | train loss {'Reaction outcome loss': 0.27944626006887946, 'Total loss': 0.27944626006887946}
2022-12-31 14:06:30,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:30,967 INFO:     Epoch: 44
2022-12-31 14:06:32,562 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3991627097129822, 'Total loss': 0.3991627097129822} | train loss {'Reaction outcome loss': 0.28304518212055985, 'Total loss': 0.28304518212055985}
2022-12-31 14:06:32,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:32,562 INFO:     Epoch: 45
2022-12-31 14:06:34,158 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4318387806415558, 'Total loss': 0.4318387806415558} | train loss {'Reaction outcome loss': 0.2655397396493744, 'Total loss': 0.2655397396493744}
2022-12-31 14:06:34,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:34,158 INFO:     Epoch: 46
2022-12-31 14:06:35,754 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38314733604590095, 'Total loss': 0.38314733604590095} | train loss {'Reaction outcome loss': 0.26778470963621753, 'Total loss': 0.26778470963621753}
2022-12-31 14:06:35,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:35,755 INFO:     Epoch: 47
2022-12-31 14:06:37,350 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39497121473153435, 'Total loss': 0.39497121473153435} | train loss {'Reaction outcome loss': 0.2653790764619798, 'Total loss': 0.2653790764619798}
2022-12-31 14:06:37,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:37,351 INFO:     Epoch: 48
2022-12-31 14:06:38,911 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.393469911813736, 'Total loss': 0.393469911813736} | train loss {'Reaction outcome loss': 0.2637274503544137, 'Total loss': 0.2637274503544137}
2022-12-31 14:06:38,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:38,912 INFO:     Epoch: 49
2022-12-31 14:06:40,518 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3926487028598785, 'Total loss': 0.3926487028598785} | train loss {'Reaction outcome loss': 0.26521023570290414, 'Total loss': 0.26521023570290414}
2022-12-31 14:06:40,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:40,518 INFO:     Epoch: 50
2022-12-31 14:06:42,119 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3999071389436722, 'Total loss': 0.3999071389436722} | train loss {'Reaction outcome loss': 0.26313647619643055, 'Total loss': 0.26313647619643055}
2022-12-31 14:06:42,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:42,119 INFO:     Epoch: 51
2022-12-31 14:06:43,721 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4566961963971456, 'Total loss': 0.4566961963971456} | train loss {'Reaction outcome loss': 0.2637023328097312, 'Total loss': 0.2637023328097312}
2022-12-31 14:06:43,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:43,722 INFO:     Epoch: 52
2022-12-31 14:06:45,323 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3956309288740158, 'Total loss': 0.3956309288740158} | train loss {'Reaction outcome loss': 0.2567101228562603, 'Total loss': 0.2567101228562603}
2022-12-31 14:06:45,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:45,323 INFO:     Epoch: 53
2022-12-31 14:06:46,924 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38385913769404095, 'Total loss': 0.38385913769404095} | train loss {'Reaction outcome loss': 0.244013187199176, 'Total loss': 0.244013187199176}
2022-12-31 14:06:46,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:46,924 INFO:     Epoch: 54
2022-12-31 14:06:48,488 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42324182838201524, 'Total loss': 0.42324182838201524} | train loss {'Reaction outcome loss': 0.2515124854710185, 'Total loss': 0.2515124854710185}
2022-12-31 14:06:48,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:48,489 INFO:     Epoch: 55
2022-12-31 14:06:50,090 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3878851334253947, 'Total loss': 0.3878851334253947} | train loss {'Reaction outcome loss': 0.24648172205020658, 'Total loss': 0.24648172205020658}
2022-12-31 14:06:50,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:50,091 INFO:     Epoch: 56
2022-12-31 14:06:51,692 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43425132806102434, 'Total loss': 0.43425132806102434} | train loss {'Reaction outcome loss': 0.251824129161326, 'Total loss': 0.251824129161326}
2022-12-31 14:06:51,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:51,692 INFO:     Epoch: 57
2022-12-31 14:06:53,294 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39573582212130226, 'Total loss': 0.39573582212130226} | train loss {'Reaction outcome loss': 0.23908575947631847, 'Total loss': 0.23908575947631847}
2022-12-31 14:06:53,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:53,294 INFO:     Epoch: 58
2022-12-31 14:06:54,897 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39186654140551885, 'Total loss': 0.39186654140551885} | train loss {'Reaction outcome loss': 0.2502063147232428, 'Total loss': 0.2502063147232428}
2022-12-31 14:06:54,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:54,897 INFO:     Epoch: 59
2022-12-31 14:06:56,482 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4190617799758911, 'Total loss': 0.4190617799758911} | train loss {'Reaction outcome loss': 0.24263991474177374, 'Total loss': 0.24263991474177374}
2022-12-31 14:06:56,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:56,482 INFO:     Epoch: 60
2022-12-31 14:06:58,060 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.38283059895038607, 'Total loss': 0.38283059895038607} | train loss {'Reaction outcome loss': 0.24236628712042346, 'Total loss': 0.24236628712042346}
2022-12-31 14:06:58,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:58,060 INFO:     Epoch: 61
2022-12-31 14:06:59,661 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3610414364685615, 'Total loss': 0.3610414364685615} | train loss {'Reaction outcome loss': 0.24469214881132373, 'Total loss': 0.24469214881132373}
2022-12-31 14:06:59,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:06:59,661 INFO:     Epoch: 62
2022-12-31 14:07:01,305 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43015203475952146, 'Total loss': 0.43015203475952146} | train loss {'Reaction outcome loss': 0.23927555938725506, 'Total loss': 0.23927555938725506}
2022-12-31 14:07:01,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:01,306 INFO:     Epoch: 63
2022-12-31 14:07:02,920 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40093770424524944, 'Total loss': 0.40093770424524944} | train loss {'Reaction outcome loss': 0.23226460353249595, 'Total loss': 0.23226460353249595}
2022-12-31 14:07:02,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:02,921 INFO:     Epoch: 64
2022-12-31 14:07:04,521 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4111991504828135, 'Total loss': 0.4111991504828135} | train loss {'Reaction outcome loss': 0.23437672272160814, 'Total loss': 0.23437672272160814}
2022-12-31 14:07:04,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:04,521 INFO:     Epoch: 65
2022-12-31 14:07:06,080 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40304281612237297, 'Total loss': 0.40304281612237297} | train loss {'Reaction outcome loss': 0.23762623991667134, 'Total loss': 0.23762623991667134}
2022-12-31 14:07:06,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:06,080 INFO:     Epoch: 66
2022-12-31 14:07:07,680 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42025482257207236, 'Total loss': 0.42025482257207236} | train loss {'Reaction outcome loss': 0.23200355688512544, 'Total loss': 0.23200355688512544}
2022-12-31 14:07:07,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:07,681 INFO:     Epoch: 67
2022-12-31 14:07:09,290 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.35499350527922313, 'Total loss': 0.35499350527922313} | train loss {'Reaction outcome loss': 0.22998957030284098, 'Total loss': 0.22998957030284098}
2022-12-31 14:07:09,290 INFO:     Found new best model at epoch 67
2022-12-31 14:07:09,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:09,291 INFO:     Epoch: 68
2022-12-31 14:07:10,890 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3894145240386327, 'Total loss': 0.3894145240386327} | train loss {'Reaction outcome loss': 0.23116931197789561, 'Total loss': 0.23116931197789561}
2022-12-31 14:07:10,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:10,890 INFO:     Epoch: 69
2022-12-31 14:07:12,490 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43272091646989186, 'Total loss': 0.43272091646989186} | train loss {'Reaction outcome loss': 0.2255436263487234, 'Total loss': 0.2255436263487234}
2022-12-31 14:07:12,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:12,490 INFO:     Epoch: 70
2022-12-31 14:07:14,091 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39623973816633223, 'Total loss': 0.39623973816633223} | train loss {'Reaction outcome loss': 0.228552637587646, 'Total loss': 0.228552637587646}
2022-12-31 14:07:14,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:14,091 INFO:     Epoch: 71
2022-12-31 14:07:15,276 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41931706269582114, 'Total loss': 0.41931706269582114} | train loss {'Reaction outcome loss': 0.2248061913382876, 'Total loss': 0.2248061913382876}
2022-12-31 14:07:15,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:15,276 INFO:     Epoch: 72
2022-12-31 14:07:16,353 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41997687220573426, 'Total loss': 0.41997687220573426} | train loss {'Reaction outcome loss': 0.21972424064800417, 'Total loss': 0.21972424064800417}
2022-12-31 14:07:16,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:16,353 INFO:     Epoch: 73
2022-12-31 14:07:17,524 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3978618671496709, 'Total loss': 0.3978618671496709} | train loss {'Reaction outcome loss': 0.22237409274656694, 'Total loss': 0.22237409274656694}
2022-12-31 14:07:17,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:17,524 INFO:     Epoch: 74
2022-12-31 14:07:18,713 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.396504275004069, 'Total loss': 0.396504275004069} | train loss {'Reaction outcome loss': 0.22472081655438567, 'Total loss': 0.22472081655438567}
2022-12-31 14:07:18,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:18,713 INFO:     Epoch: 75
2022-12-31 14:07:20,252 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4457843025525411, 'Total loss': 0.4457843025525411} | train loss {'Reaction outcome loss': 0.2246230940569888, 'Total loss': 0.2246230940569888}
2022-12-31 14:07:20,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:20,253 INFO:     Epoch: 76
2022-12-31 14:07:21,880 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37270212123791374, 'Total loss': 0.37270212123791374} | train loss {'Reaction outcome loss': 0.2250701296979036, 'Total loss': 0.2250701296979036}
2022-12-31 14:07:21,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:21,880 INFO:     Epoch: 77
2022-12-31 14:07:23,476 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3842111974954605, 'Total loss': 0.3842111974954605} | train loss {'Reaction outcome loss': 0.21521212201183423, 'Total loss': 0.21521212201183423}
2022-12-31 14:07:23,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:23,476 INFO:     Epoch: 78
2022-12-31 14:07:25,111 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3457474534710248, 'Total loss': 0.3457474534710248} | train loss {'Reaction outcome loss': 0.21177358514605424, 'Total loss': 0.21177358514605424}
2022-12-31 14:07:25,111 INFO:     Found new best model at epoch 78
2022-12-31 14:07:25,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:25,114 INFO:     Epoch: 79
2022-12-31 14:07:26,742 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.35808093945185343, 'Total loss': 0.35808093945185343} | train loss {'Reaction outcome loss': 0.21628477149250688, 'Total loss': 0.21628477149250688}
2022-12-31 14:07:26,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:26,742 INFO:     Epoch: 80
2022-12-31 14:07:28,327 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37843793382247287, 'Total loss': 0.37843793382247287} | train loss {'Reaction outcome loss': 0.21443279224001008, 'Total loss': 0.21443279224001008}
2022-12-31 14:07:28,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:28,327 INFO:     Epoch: 81
2022-12-31 14:07:29,927 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42601092408100766, 'Total loss': 0.42601092408100766} | train loss {'Reaction outcome loss': 0.2182078148091669, 'Total loss': 0.2182078148091669}
2022-12-31 14:07:29,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:29,927 INFO:     Epoch: 82
2022-12-31 14:07:31,548 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4110364268223445, 'Total loss': 0.4110364268223445} | train loss {'Reaction outcome loss': 0.22218241810034484, 'Total loss': 0.22218241810034484}
2022-12-31 14:07:31,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:31,549 INFO:     Epoch: 83
2022-12-31 14:07:33,161 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3967970609664917, 'Total loss': 0.3967970609664917} | train loss {'Reaction outcome loss': 0.21562421904883652, 'Total loss': 0.21562421904883652}
2022-12-31 14:07:33,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:33,161 INFO:     Epoch: 84
2022-12-31 14:07:34,786 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4300713102022807, 'Total loss': 0.4300713102022807} | train loss {'Reaction outcome loss': 0.20876404220722752, 'Total loss': 0.20876404220722752}
2022-12-31 14:07:34,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:34,786 INFO:     Epoch: 85
2022-12-31 14:07:36,412 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3905523806810379, 'Total loss': 0.3905523806810379} | train loss {'Reaction outcome loss': 0.21209404461645273, 'Total loss': 0.21209404461645273}
2022-12-31 14:07:36,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:36,413 INFO:     Epoch: 86
2022-12-31 14:07:38,027 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38974733650684357, 'Total loss': 0.38974733650684357} | train loss {'Reaction outcome loss': 0.20646003933944107, 'Total loss': 0.20646003933944107}
2022-12-31 14:07:38,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:38,028 INFO:     Epoch: 87
2022-12-31 14:07:39,666 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4094260146220525, 'Total loss': 0.4094260146220525} | train loss {'Reaction outcome loss': 0.2118066569906233, 'Total loss': 0.2118066569906233}
2022-12-31 14:07:39,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:39,667 INFO:     Epoch: 88
2022-12-31 14:07:41,259 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3910284916559855, 'Total loss': 0.3910284916559855} | train loss {'Reaction outcome loss': 0.20889340060670952, 'Total loss': 0.20889340060670952}
2022-12-31 14:07:41,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:41,260 INFO:     Epoch: 89
2022-12-31 14:07:42,888 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4129914969205856, 'Total loss': 0.4129914969205856} | train loss {'Reaction outcome loss': 0.2063152221996924, 'Total loss': 0.2063152221996924}
2022-12-31 14:07:42,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:42,889 INFO:     Epoch: 90
2022-12-31 14:07:44,517 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3806036919355392, 'Total loss': 0.3806036919355392} | train loss {'Reaction outcome loss': 0.21470256624641, 'Total loss': 0.21470256624641}
2022-12-31 14:07:44,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:44,517 INFO:     Epoch: 91
2022-12-31 14:07:46,133 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3631082614262899, 'Total loss': 0.3631082614262899} | train loss {'Reaction outcome loss': 0.2057652653437176, 'Total loss': 0.2057652653437176}
2022-12-31 14:07:46,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:46,133 INFO:     Epoch: 92
2022-12-31 14:07:47,742 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37918045471111933, 'Total loss': 0.37918045471111933} | train loss {'Reaction outcome loss': 0.2081500671926763, 'Total loss': 0.2081500671926763}
2022-12-31 14:07:47,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:47,742 INFO:     Epoch: 93
2022-12-31 14:07:49,342 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40064120590686797, 'Total loss': 0.40064120590686797} | train loss {'Reaction outcome loss': 0.20763390554514313, 'Total loss': 0.20763390554514313}
2022-12-31 14:07:49,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:49,342 INFO:     Epoch: 94
2022-12-31 14:07:50,929 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41332189440727235, 'Total loss': 0.41332189440727235} | train loss {'Reaction outcome loss': 0.20514976096786422, 'Total loss': 0.20514976096786422}
2022-12-31 14:07:50,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:50,929 INFO:     Epoch: 95
2022-12-31 14:07:52,574 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3930471574266752, 'Total loss': 0.3930471574266752} | train loss {'Reaction outcome loss': 0.2007267418771218, 'Total loss': 0.2007267418771218}
2022-12-31 14:07:52,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:52,575 INFO:     Epoch: 96
2022-12-31 14:07:54,189 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4080975885192553, 'Total loss': 0.4080975885192553} | train loss {'Reaction outcome loss': 0.20198102759013137, 'Total loss': 0.20198102759013137}
2022-12-31 14:07:54,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:54,189 INFO:     Epoch: 97
2022-12-31 14:07:55,771 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36250744592398404, 'Total loss': 0.36250744592398404} | train loss {'Reaction outcome loss': 0.2044954293376797, 'Total loss': 0.2044954293376797}
2022-12-31 14:07:55,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:55,772 INFO:     Epoch: 98
2022-12-31 14:07:57,406 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3759783064325651, 'Total loss': 0.3759783064325651} | train loss {'Reaction outcome loss': 0.19413535451796246, 'Total loss': 0.19413535451796246}
2022-12-31 14:07:57,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:57,407 INFO:     Epoch: 99
2022-12-31 14:07:59,009 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3627876934905847, 'Total loss': 0.3627876934905847} | train loss {'Reaction outcome loss': 0.20061808624287775, 'Total loss': 0.20061808624287775}
2022-12-31 14:07:59,009 INFO:     Best model found after epoch 79 of 100.
2022-12-31 14:07:59,010 INFO:   Done with stage: TRAINING
2022-12-31 14:07:59,010 INFO:   Starting stage: EVALUATION
2022-12-31 14:07:59,149 INFO:   Done with stage: EVALUATION
2022-12-31 14:07:59,150 INFO:   Leaving out SEQ value Fold_3
2022-12-31 14:07:59,163 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2022-12-31 14:07:59,163 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:07:59,802 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:07:59,802 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:07:59,870 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:07:59,870 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:07:59,870 INFO:     No hyperparam tuning for this model
2022-12-31 14:07:59,870 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:07:59,870 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:07:59,871 INFO:     None feature selector for col prot
2022-12-31 14:07:59,871 INFO:     None feature selector for col prot
2022-12-31 14:07:59,871 INFO:     None feature selector for col prot
2022-12-31 14:07:59,871 INFO:     None feature selector for col chem
2022-12-31 14:07:59,872 INFO:     None feature selector for col chem
2022-12-31 14:07:59,872 INFO:     None feature selector for col chem
2022-12-31 14:07:59,872 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:07:59,872 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:07:59,873 INFO:     Number of params in model 223921
2022-12-31 14:07:59,877 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:07:59,877 INFO:   Starting stage: TRAINING
2022-12-31 14:07:59,921 INFO:     Val loss before train {'Reaction outcome loss': 1.0143401384353639, 'Total loss': 1.0143401384353639}
2022-12-31 14:07:59,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:07:59,921 INFO:     Epoch: 0
2022-12-31 14:08:01,536 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6083863218625386, 'Total loss': 0.6083863218625386} | train loss {'Reaction outcome loss': 0.8110420011066423, 'Total loss': 0.8110420011066423}
2022-12-31 14:08:01,536 INFO:     Found new best model at epoch 0
2022-12-31 14:08:01,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:01,537 INFO:     Epoch: 1
2022-12-31 14:08:03,176 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.489064958691597, 'Total loss': 0.489064958691597} | train loss {'Reaction outcome loss': 0.5819906998714398, 'Total loss': 0.5819906998714398}
2022-12-31 14:08:03,176 INFO:     Found new best model at epoch 1
2022-12-31 14:08:03,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:03,177 INFO:     Epoch: 2
2022-12-31 14:08:04,777 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4641847262779872, 'Total loss': 0.4641847262779872} | train loss {'Reaction outcome loss': 0.5136612112121829, 'Total loss': 0.5136612112121829}
2022-12-31 14:08:04,777 INFO:     Found new best model at epoch 2
2022-12-31 14:08:04,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:04,778 INFO:     Epoch: 3
2022-12-31 14:08:06,393 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4928397516409556, 'Total loss': 0.4928397516409556} | train loss {'Reaction outcome loss': 0.4892577432178483, 'Total loss': 0.4892577432178483}
2022-12-31 14:08:06,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:06,393 INFO:     Epoch: 4
2022-12-31 14:08:07,992 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.3779578313231468, 'Total loss': 0.3779578313231468} | train loss {'Reaction outcome loss': 0.47242025371187285, 'Total loss': 0.47242025371187285}
2022-12-31 14:08:07,993 INFO:     Found new best model at epoch 4
2022-12-31 14:08:07,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:07,994 INFO:     Epoch: 5
2022-12-31 14:08:09,569 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3844237516323725, 'Total loss': 0.3844237516323725} | train loss {'Reaction outcome loss': 0.46538707602947843, 'Total loss': 0.46538707602947843}
2022-12-31 14:08:09,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:09,570 INFO:     Epoch: 6
2022-12-31 14:08:11,170 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4093156516551971, 'Total loss': 0.4093156516551971} | train loss {'Reaction outcome loss': 0.4493733272231373, 'Total loss': 0.4493733272231373}
2022-12-31 14:08:11,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:11,170 INFO:     Epoch: 7
2022-12-31 14:08:12,764 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40292370518048604, 'Total loss': 0.40292370518048604} | train loss {'Reaction outcome loss': 0.4377103823742303, 'Total loss': 0.4377103823742303}
2022-12-31 14:08:12,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:12,764 INFO:     Epoch: 8
2022-12-31 14:08:14,334 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.38946084020038446, 'Total loss': 0.38946084020038446} | train loss {'Reaction outcome loss': 0.43421297839316936, 'Total loss': 0.43421297839316936}
2022-12-31 14:08:14,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:14,334 INFO:     Epoch: 9
2022-12-31 14:08:15,919 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4205988943576813, 'Total loss': 0.4205988943576813} | train loss {'Reaction outcome loss': 0.4304901026601721, 'Total loss': 0.4304901026601721}
2022-12-31 14:08:15,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:15,919 INFO:     Epoch: 10
2022-12-31 14:08:17,512 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.37262681921323143, 'Total loss': 0.37262681921323143} | train loss {'Reaction outcome loss': 0.4236211671710454, 'Total loss': 0.4236211671710454}
2022-12-31 14:08:17,512 INFO:     Found new best model at epoch 10
2022-12-31 14:08:17,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:17,513 INFO:     Epoch: 11
2022-12-31 14:08:19,100 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4062152067820231, 'Total loss': 0.4062152067820231} | train loss {'Reaction outcome loss': 0.4175653071641042, 'Total loss': 0.4175653071641042}
2022-12-31 14:08:19,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:19,100 INFO:     Epoch: 12
2022-12-31 14:08:20,690 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3844867835442225, 'Total loss': 0.3844867835442225} | train loss {'Reaction outcome loss': 0.4150941986659356, 'Total loss': 0.4150941986659356}
2022-12-31 14:08:20,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:20,690 INFO:     Epoch: 13
2022-12-31 14:08:22,273 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39610331257184345, 'Total loss': 0.39610331257184345} | train loss {'Reaction outcome loss': 0.4039717739193642, 'Total loss': 0.4039717739193642}
2022-12-31 14:08:22,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:22,273 INFO:     Epoch: 14
2022-12-31 14:08:23,841 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3986274684468905, 'Total loss': 0.3986274684468905} | train loss {'Reaction outcome loss': 0.4018734065863919, 'Total loss': 0.4018734065863919}
2022-12-31 14:08:23,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:23,842 INFO:     Epoch: 15
2022-12-31 14:08:25,425 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4027652621269226, 'Total loss': 0.4027652621269226} | train loss {'Reaction outcome loss': 0.4015428960543277, 'Total loss': 0.4015428960543277}
2022-12-31 14:08:25,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:25,425 INFO:     Epoch: 16
2022-12-31 14:08:26,992 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3578230495254199, 'Total loss': 0.3578230495254199} | train loss {'Reaction outcome loss': 0.38953360937178355, 'Total loss': 0.38953360937178355}
2022-12-31 14:08:26,993 INFO:     Found new best model at epoch 16
2022-12-31 14:08:26,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:26,994 INFO:     Epoch: 17
2022-12-31 14:08:28,576 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.36993238975604376, 'Total loss': 0.36993238975604376} | train loss {'Reaction outcome loss': 0.3833753290514005, 'Total loss': 0.3833753290514005}
2022-12-31 14:08:28,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:28,577 INFO:     Epoch: 18
2022-12-31 14:08:30,159 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44944589932759604, 'Total loss': 0.44944589932759604} | train loss {'Reaction outcome loss': 0.37521625831173355, 'Total loss': 0.37521625831173355}
2022-12-31 14:08:30,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:30,160 INFO:     Epoch: 19
2022-12-31 14:08:31,741 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38999454279740653, 'Total loss': 0.38999454279740653} | train loss {'Reaction outcome loss': 0.3735568900334879, 'Total loss': 0.3735568900334879}
2022-12-31 14:08:31,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:31,741 INFO:     Epoch: 20
2022-12-31 14:08:33,321 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.36844346125920613, 'Total loss': 0.36844346125920613} | train loss {'Reaction outcome loss': 0.3610878329985256, 'Total loss': 0.3610878329985256}
2022-12-31 14:08:33,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:33,321 INFO:     Epoch: 21
2022-12-31 14:08:34,916 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.33648948520421984, 'Total loss': 0.33648948520421984} | train loss {'Reaction outcome loss': 0.3582366572699864, 'Total loss': 0.3582366572699864}
2022-12-31 14:08:34,917 INFO:     Found new best model at epoch 21
2022-12-31 14:08:34,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:34,918 INFO:     Epoch: 22
2022-12-31 14:08:36,524 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3756774286429087, 'Total loss': 0.3756774286429087} | train loss {'Reaction outcome loss': 0.3606807080362116, 'Total loss': 0.3606807080362116}
2022-12-31 14:08:36,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:36,524 INFO:     Epoch: 23
2022-12-31 14:08:38,111 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3377505637705326, 'Total loss': 0.3377505637705326} | train loss {'Reaction outcome loss': 0.3482109353056253, 'Total loss': 0.3482109353056253}
2022-12-31 14:08:38,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:38,111 INFO:     Epoch: 24
2022-12-31 14:08:39,695 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3947374314069748, 'Total loss': 0.3947374314069748} | train loss {'Reaction outcome loss': 0.3500287563323535, 'Total loss': 0.3500287563323535}
2022-12-31 14:08:39,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:39,695 INFO:     Epoch: 25
2022-12-31 14:08:41,282 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3432443380355835, 'Total loss': 0.3432443380355835} | train loss {'Reaction outcome loss': 0.3399171447347011, 'Total loss': 0.3399171447347011}
2022-12-31 14:08:41,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:41,282 INFO:     Epoch: 26
2022-12-31 14:08:42,908 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3518029421567917, 'Total loss': 0.3518029421567917} | train loss {'Reaction outcome loss': 0.33750905555662636, 'Total loss': 0.33750905555662636}
2022-12-31 14:08:42,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:42,909 INFO:     Epoch: 27
2022-12-31 14:08:44,498 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.34074020410577455, 'Total loss': 0.34074020410577455} | train loss {'Reaction outcome loss': 0.33422351372857817, 'Total loss': 0.33422351372857817}
2022-12-31 14:08:44,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:44,498 INFO:     Epoch: 28
2022-12-31 14:08:46,074 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.35327686071395875, 'Total loss': 0.35327686071395875} | train loss {'Reaction outcome loss': 0.32960746374077465, 'Total loss': 0.32960746374077465}
2022-12-31 14:08:46,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:46,075 INFO:     Epoch: 29
2022-12-31 14:08:47,704 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.36053977310657503, 'Total loss': 0.36053977310657503} | train loss {'Reaction outcome loss': 0.32344185940343956, 'Total loss': 0.32344185940343956}
2022-12-31 14:08:47,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:47,704 INFO:     Epoch: 30
2022-12-31 14:08:49,283 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.350331524014473, 'Total loss': 0.350331524014473} | train loss {'Reaction outcome loss': 0.32126974425797533, 'Total loss': 0.32126974425797533}
2022-12-31 14:08:49,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:49,284 INFO:     Epoch: 31
2022-12-31 14:08:50,847 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.34766201774279276, 'Total loss': 0.34766201774279276} | train loss {'Reaction outcome loss': 0.3158927665837796, 'Total loss': 0.3158927665837796}
2022-12-31 14:08:50,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:50,847 INFO:     Epoch: 32
2022-12-31 14:08:52,432 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.34056637982527416, 'Total loss': 0.34056637982527416} | train loss {'Reaction outcome loss': 0.3052842727831369, 'Total loss': 0.3052842727831369}
2022-12-31 14:08:52,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:52,432 INFO:     Epoch: 33
2022-12-31 14:08:54,002 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41194801926612856, 'Total loss': 0.41194801926612856} | train loss {'Reaction outcome loss': 0.3022249504181512, 'Total loss': 0.3022249504181512}
2022-12-31 14:08:54,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:54,002 INFO:     Epoch: 34
2022-12-31 14:08:55,610 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.33487536137302715, 'Total loss': 0.33487536137302715} | train loss {'Reaction outcome loss': 0.30848431411264565, 'Total loss': 0.30848431411264565}
2022-12-31 14:08:55,610 INFO:     Found new best model at epoch 34
2022-12-31 14:08:55,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:55,611 INFO:     Epoch: 35
2022-12-31 14:08:57,238 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3622425556182861, 'Total loss': 0.3622425556182861} | train loss {'Reaction outcome loss': 0.29935458009698296, 'Total loss': 0.29935458009698296}
2022-12-31 14:08:57,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:57,238 INFO:     Epoch: 36
2022-12-31 14:08:58,825 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.361307962735494, 'Total loss': 0.361307962735494} | train loss {'Reaction outcome loss': 0.29239209043033887, 'Total loss': 0.29239209043033887}
2022-12-31 14:08:58,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:08:58,825 INFO:     Epoch: 37
2022-12-31 14:09:00,388 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.32075780630111694, 'Total loss': 0.32075780630111694} | train loss {'Reaction outcome loss': 0.2903275126488226, 'Total loss': 0.2903275126488226}
2022-12-31 14:09:00,388 INFO:     Found new best model at epoch 37
2022-12-31 14:09:00,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:00,389 INFO:     Epoch: 38
2022-12-31 14:09:01,970 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.34639079372088116, 'Total loss': 0.34639079372088116} | train loss {'Reaction outcome loss': 0.28777248673553396, 'Total loss': 0.28777248673553396}
2022-12-31 14:09:01,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:01,971 INFO:     Epoch: 39
2022-12-31 14:09:03,554 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.29861040810743966, 'Total loss': 0.29861040810743966} | train loss {'Reaction outcome loss': 0.2922603502402226, 'Total loss': 0.2922603502402226}
2022-12-31 14:09:03,554 INFO:     Found new best model at epoch 39
2022-12-31 14:09:03,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:03,555 INFO:     Epoch: 40
2022-12-31 14:09:05,138 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3538559456666311, 'Total loss': 0.3538559456666311} | train loss {'Reaction outcome loss': 0.28629314545473267, 'Total loss': 0.28629314545473267}
2022-12-31 14:09:05,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:05,138 INFO:     Epoch: 41
2022-12-31 14:09:06,722 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3216113358736038, 'Total loss': 0.3216113358736038} | train loss {'Reaction outcome loss': 0.28011101619014, 'Total loss': 0.28011101619014}
2022-12-31 14:09:06,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:06,723 INFO:     Epoch: 42
2022-12-31 14:09:08,284 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.31229849383234976, 'Total loss': 0.31229849383234976} | train loss {'Reaction outcome loss': 0.2698379751308598, 'Total loss': 0.2698379751308598}
2022-12-31 14:09:08,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:08,284 INFO:     Epoch: 43
2022-12-31 14:09:09,920 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.32000577449798584, 'Total loss': 0.32000577449798584} | train loss {'Reaction outcome loss': 0.2725463285904749, 'Total loss': 0.2725463285904749}
2022-12-31 14:09:09,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:09,920 INFO:     Epoch: 44
2022-12-31 14:09:11,556 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3745844016472499, 'Total loss': 0.3745844016472499} | train loss {'Reaction outcome loss': 0.26571926173523785, 'Total loss': 0.26571926173523785}
2022-12-31 14:09:11,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:11,556 INFO:     Epoch: 45
2022-12-31 14:09:13,140 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3191476027170817, 'Total loss': 0.3191476027170817} | train loss {'Reaction outcome loss': 0.26987496964166086, 'Total loss': 0.26987496964166086}
2022-12-31 14:09:13,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:13,140 INFO:     Epoch: 46
2022-12-31 14:09:14,728 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.347750294705232, 'Total loss': 0.347750294705232} | train loss {'Reaction outcome loss': 0.2664486750156182, 'Total loss': 0.2664486750156182}
2022-12-31 14:09:14,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:14,729 INFO:     Epoch: 47
2022-12-31 14:09:16,311 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3314554437994957, 'Total loss': 0.3314554437994957} | train loss {'Reaction outcome loss': 0.2619842480029567, 'Total loss': 0.2619842480029567}
2022-12-31 14:09:16,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:16,311 INFO:     Epoch: 48
2022-12-31 14:09:17,877 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.30586514125267666, 'Total loss': 0.30586514125267666} | train loss {'Reaction outcome loss': 0.25590335693196614, 'Total loss': 0.25590335693196614}
2022-12-31 14:09:17,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:17,877 INFO:     Epoch: 49
2022-12-31 14:09:19,461 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.34610092441240947, 'Total loss': 0.34610092441240947} | train loss {'Reaction outcome loss': 0.26252769291180966, 'Total loss': 0.26252769291180966}
2022-12-31 14:09:19,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:19,461 INFO:     Epoch: 50
2022-12-31 14:09:21,030 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3543633113304774, 'Total loss': 0.3543633113304774} | train loss {'Reaction outcome loss': 0.25768584169007536, 'Total loss': 0.25768584169007536}
2022-12-31 14:09:21,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:21,031 INFO:     Epoch: 51
2022-12-31 14:09:22,614 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36486110389232634, 'Total loss': 0.36486110389232634} | train loss {'Reaction outcome loss': 0.2525027273050973, 'Total loss': 0.2525027273050973}
2022-12-31 14:09:22,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:22,614 INFO:     Epoch: 52
2022-12-31 14:09:24,200 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.35124124189217887, 'Total loss': 0.35124124189217887} | train loss {'Reaction outcome loss': 0.24593331160305612, 'Total loss': 0.24593331160305612}
2022-12-31 14:09:24,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:24,200 INFO:     Epoch: 53
2022-12-31 14:09:25,791 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3342403839031855, 'Total loss': 0.3342403839031855} | train loss {'Reaction outcome loss': 0.25053440204845584, 'Total loss': 0.25053440204845584}
2022-12-31 14:09:25,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:25,791 INFO:     Epoch: 54
2022-12-31 14:09:27,383 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3498616228501002, 'Total loss': 0.3498616228501002} | train loss {'Reaction outcome loss': 0.2484598552251434, 'Total loss': 0.2484598552251434}
2022-12-31 14:09:27,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:27,383 INFO:     Epoch: 55
2022-12-31 14:09:29,006 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.360167104502519, 'Total loss': 0.360167104502519} | train loss {'Reaction outcome loss': 0.24649393065004332, 'Total loss': 0.24649393065004332}
2022-12-31 14:09:29,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:29,006 INFO:     Epoch: 56
2022-12-31 14:09:30,615 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3371976912021637, 'Total loss': 0.3371976912021637} | train loss {'Reaction outcome loss': 0.23470442692622048, 'Total loss': 0.23470442692622048}
2022-12-31 14:09:30,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:30,615 INFO:     Epoch: 57
2022-12-31 14:09:32,232 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3067498506046832, 'Total loss': 0.3067498506046832} | train loss {'Reaction outcome loss': 0.24017471457209535, 'Total loss': 0.24017471457209535}
2022-12-31 14:09:32,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:32,232 INFO:     Epoch: 58
2022-12-31 14:09:33,832 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.35494912465413414, 'Total loss': 0.35494912465413414} | train loss {'Reaction outcome loss': 0.2422590414646367, 'Total loss': 0.2422590414646367}
2022-12-31 14:09:33,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:33,833 INFO:     Epoch: 59
2022-12-31 14:09:35,438 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37452363669872285, 'Total loss': 0.37452363669872285} | train loss {'Reaction outcome loss': 0.23448463726610055, 'Total loss': 0.23448463726610055}
2022-12-31 14:09:35,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:35,438 INFO:     Epoch: 60
2022-12-31 14:09:37,037 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3320116425553958, 'Total loss': 0.3320116425553958} | train loss {'Reaction outcome loss': 0.2320410298712799, 'Total loss': 0.2320410298712799}
2022-12-31 14:09:37,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:37,038 INFO:     Epoch: 61
2022-12-31 14:09:38,639 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.28653582421441876, 'Total loss': 0.28653582421441876} | train loss {'Reaction outcome loss': 0.2272705579265897, 'Total loss': 0.2272705579265897}
2022-12-31 14:09:38,639 INFO:     Found new best model at epoch 61
2022-12-31 14:09:38,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:38,640 INFO:     Epoch: 62
2022-12-31 14:09:40,233 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3620407432317734, 'Total loss': 0.3620407432317734} | train loss {'Reaction outcome loss': 0.23631414883800977, 'Total loss': 0.23631414883800977}
2022-12-31 14:09:40,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:40,233 INFO:     Epoch: 63
2022-12-31 14:09:41,857 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38916815519332887, 'Total loss': 0.38916815519332887} | train loss {'Reaction outcome loss': 0.2306387020254377, 'Total loss': 0.2306387020254377}
2022-12-31 14:09:41,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:41,857 INFO:     Epoch: 64
2022-12-31 14:09:43,477 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.2811815068125725, 'Total loss': 0.2811815068125725} | train loss {'Reaction outcome loss': 0.23066736611355496, 'Total loss': 0.23066736611355496}
2022-12-31 14:09:43,477 INFO:     Found new best model at epoch 64
2022-12-31 14:09:43,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:43,478 INFO:     Epoch: 65
2022-12-31 14:09:45,069 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3194242159525553, 'Total loss': 0.3194242159525553} | train loss {'Reaction outcome loss': 0.22241936709278184, 'Total loss': 0.22241936709278184}
2022-12-31 14:09:45,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:45,069 INFO:     Epoch: 66
2022-12-31 14:09:46,678 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3876711308956146, 'Total loss': 0.3876711308956146} | train loss {'Reaction outcome loss': 0.22719747955288835, 'Total loss': 0.22719747955288835}
2022-12-31 14:09:46,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:46,679 INFO:     Epoch: 67
2022-12-31 14:09:48,252 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.32660904129346213, 'Total loss': 0.32660904129346213} | train loss {'Reaction outcome loss': 0.22046097999651715, 'Total loss': 0.22046097999651715}
2022-12-31 14:09:48,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:48,253 INFO:     Epoch: 68
2022-12-31 14:09:49,874 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.34823814729849495, 'Total loss': 0.34823814729849495} | train loss {'Reaction outcome loss': 0.22015506965262863, 'Total loss': 0.22015506965262863}
2022-12-31 14:09:49,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:49,875 INFO:     Epoch: 69
2022-12-31 14:09:51,493 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3448133041461309, 'Total loss': 0.3448133041461309} | train loss {'Reaction outcome loss': 0.21707592775351006, 'Total loss': 0.21707592775351006}
2022-12-31 14:09:51,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:51,494 INFO:     Epoch: 70
2022-12-31 14:09:53,117 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.34000196158885954, 'Total loss': 0.34000196158885954} | train loss {'Reaction outcome loss': 0.2251748152049705, 'Total loss': 0.2251748152049705}
2022-12-31 14:09:53,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:53,118 INFO:     Epoch: 71
2022-12-31 14:09:54,706 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3229522779583931, 'Total loss': 0.3229522779583931} | train loss {'Reaction outcome loss': 0.22017479106453952, 'Total loss': 0.22017479106453952}
2022-12-31 14:09:54,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:54,706 INFO:     Epoch: 72
2022-12-31 14:09:56,313 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3516179849704107, 'Total loss': 0.3516179849704107} | train loss {'Reaction outcome loss': 0.21542432869877323, 'Total loss': 0.21542432869877323}
2022-12-31 14:09:56,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:56,314 INFO:     Epoch: 73
2022-12-31 14:09:57,904 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.34554899235566455, 'Total loss': 0.34554899235566455} | train loss {'Reaction outcome loss': 0.21502382896593136, 'Total loss': 0.21502382896593136}
2022-12-31 14:09:57,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:57,905 INFO:     Epoch: 74
2022-12-31 14:09:59,524 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3458541174729665, 'Total loss': 0.3458541174729665} | train loss {'Reaction outcome loss': 0.21128179480723788, 'Total loss': 0.21128179480723788}
2022-12-31 14:09:59,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:09:59,525 INFO:     Epoch: 75
2022-12-31 14:10:01,136 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3857526232798894, 'Total loss': 0.3857526232798894} | train loss {'Reaction outcome loss': 0.21093891510169444, 'Total loss': 0.21093891510169444}
2022-12-31 14:10:01,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:01,136 INFO:     Epoch: 76
2022-12-31 14:10:02,755 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.35770028630892436, 'Total loss': 0.35770028630892436} | train loss {'Reaction outcome loss': 0.20969009560247628, 'Total loss': 0.20969009560247628}
2022-12-31 14:10:02,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:02,756 INFO:     Epoch: 77
2022-12-31 14:10:04,350 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.30959953491886455, 'Total loss': 0.30959953491886455} | train loss {'Reaction outcome loss': 0.20755987160416436, 'Total loss': 0.20755987160416436}
2022-12-31 14:10:04,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:04,351 INFO:     Epoch: 78
2022-12-31 14:10:05,971 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.33189954062302907, 'Total loss': 0.33189954062302907} | train loss {'Reaction outcome loss': 0.21615235344592715, 'Total loss': 0.21615235344592715}
2022-12-31 14:10:05,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:05,972 INFO:     Epoch: 79
2022-12-31 14:10:07,550 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3008356406663855, 'Total loss': 0.3008356406663855} | train loss {'Reaction outcome loss': 0.2099550317120618, 'Total loss': 0.2099550317120618}
2022-12-31 14:10:07,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:07,551 INFO:     Epoch: 80
2022-12-31 14:10:09,145 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.33541563947995506, 'Total loss': 0.33541563947995506} | train loss {'Reaction outcome loss': 0.2062919545794985, 'Total loss': 0.2062919545794985}
2022-12-31 14:10:09,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:09,146 INFO:     Epoch: 81
2022-12-31 14:10:10,766 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3447179486354192, 'Total loss': 0.3447179486354192} | train loss {'Reaction outcome loss': 0.2044702466797235, 'Total loss': 0.2044702466797235}
2022-12-31 14:10:10,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:10,766 INFO:     Epoch: 82
2022-12-31 14:10:12,352 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3239342903097471, 'Total loss': 0.3239342903097471} | train loss {'Reaction outcome loss': 0.20252652407187377, 'Total loss': 0.20252652407187377}
2022-12-31 14:10:12,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:12,353 INFO:     Epoch: 83
2022-12-31 14:10:13,974 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3338693529367447, 'Total loss': 0.3338693529367447} | train loss {'Reaction outcome loss': 0.20671095484627128, 'Total loss': 0.20671095484627128}
2022-12-31 14:10:13,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:13,974 INFO:     Epoch: 84
2022-12-31 14:10:15,584 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.2897314682602882, 'Total loss': 0.2897314682602882} | train loss {'Reaction outcome loss': 0.20438928995281458, 'Total loss': 0.20438928995281458}
2022-12-31 14:10:15,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:15,584 INFO:     Epoch: 85
2022-12-31 14:10:17,168 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.33188563684622446, 'Total loss': 0.33188563684622446} | train loss {'Reaction outcome loss': 0.19594047921692534, 'Total loss': 0.19594047921692534}
2022-12-31 14:10:17,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:17,168 INFO:     Epoch: 86
2022-12-31 14:10:18,767 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3314619595805804, 'Total loss': 0.3314619595805804} | train loss {'Reaction outcome loss': 0.2027783720200792, 'Total loss': 0.2027783720200792}
2022-12-31 14:10:18,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:18,767 INFO:     Epoch: 87
2022-12-31 14:10:20,360 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3023156163593133, 'Total loss': 0.3023156163593133} | train loss {'Reaction outcome loss': 0.194877148526841, 'Total loss': 0.194877148526841}
2022-12-31 14:10:20,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:20,361 INFO:     Epoch: 88
2022-12-31 14:10:21,939 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.32863391786813734, 'Total loss': 0.32863391786813734} | train loss {'Reaction outcome loss': 0.20122209821597456, 'Total loss': 0.20122209821597456}
2022-12-31 14:10:21,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:21,939 INFO:     Epoch: 89
2022-12-31 14:10:23,557 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.33196343878904977, 'Total loss': 0.33196343878904977} | train loss {'Reaction outcome loss': 0.20281290748531197, 'Total loss': 0.20281290748531197}
2022-12-31 14:10:23,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:23,558 INFO:     Epoch: 90
2022-12-31 14:10:25,142 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3423585375150045, 'Total loss': 0.3423585375150045} | train loss {'Reaction outcome loss': 0.1966966697980557, 'Total loss': 0.1966966697980557}
2022-12-31 14:10:25,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:25,142 INFO:     Epoch: 91
2022-12-31 14:10:26,739 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.37343824207782744, 'Total loss': 0.37343824207782744} | train loss {'Reaction outcome loss': 0.19223715072133443, 'Total loss': 0.19223715072133443}
2022-12-31 14:10:26,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:26,740 INFO:     Epoch: 92
2022-12-31 14:10:28,359 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.28596656819184624, 'Total loss': 0.28596656819184624} | train loss {'Reaction outcome loss': 0.1962195168768238, 'Total loss': 0.1962195168768238}
2022-12-31 14:10:28,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:28,360 INFO:     Epoch: 93
2022-12-31 14:10:29,965 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.399332128961881, 'Total loss': 0.399332128961881} | train loss {'Reaction outcome loss': 0.19553775513524058, 'Total loss': 0.19553775513524058}
2022-12-31 14:10:29,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:29,965 INFO:     Epoch: 94
2022-12-31 14:10:31,571 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3495171904563904, 'Total loss': 0.3495171904563904} | train loss {'Reaction outcome loss': 0.19591116339545628, 'Total loss': 0.19591116339545628}
2022-12-31 14:10:31,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:31,571 INFO:     Epoch: 95
2022-12-31 14:10:33,194 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.36217797646919886, 'Total loss': 0.36217797646919886} | train loss {'Reaction outcome loss': 0.193281544750467, 'Total loss': 0.193281544750467}
2022-12-31 14:10:33,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:33,194 INFO:     Epoch: 96
2022-12-31 14:10:34,774 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3303044299284617, 'Total loss': 0.3303044299284617} | train loss {'Reaction outcome loss': 0.1914069253274298, 'Total loss': 0.1914069253274298}
2022-12-31 14:10:34,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:34,775 INFO:     Epoch: 97
2022-12-31 14:10:36,391 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3141747012734413, 'Total loss': 0.3141747012734413} | train loss {'Reaction outcome loss': 0.18456694398185314, 'Total loss': 0.18456694398185314}
2022-12-31 14:10:36,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:36,392 INFO:     Epoch: 98
2022-12-31 14:10:38,012 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3557116637627284, 'Total loss': 0.3557116637627284} | train loss {'Reaction outcome loss': 0.18849829932145526, 'Total loss': 0.18849829932145526}
2022-12-31 14:10:38,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:38,013 INFO:     Epoch: 99
2022-12-31 14:10:39,585 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.36682222386201224, 'Total loss': 0.36682222386201224} | train loss {'Reaction outcome loss': 0.19093386997293502, 'Total loss': 0.19093386997293502}
2022-12-31 14:10:39,586 INFO:     Best model found after epoch 65 of 100.
2022-12-31 14:10:39,586 INFO:   Done with stage: TRAINING
2022-12-31 14:10:39,586 INFO:   Starting stage: EVALUATION
2022-12-31 14:10:39,731 INFO:   Done with stage: EVALUATION
2022-12-31 14:10:39,731 INFO:   Leaving out SEQ value Fold_4
2022-12-31 14:10:39,744 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 14:10:39,744 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:10:40,401 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:10:40,401 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:10:40,471 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:10:40,471 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:10:40,471 INFO:     No hyperparam tuning for this model
2022-12-31 14:10:40,471 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:10:40,471 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:10:40,472 INFO:     None feature selector for col prot
2022-12-31 14:10:40,472 INFO:     None feature selector for col prot
2022-12-31 14:10:40,472 INFO:     None feature selector for col prot
2022-12-31 14:10:40,472 INFO:     None feature selector for col chem
2022-12-31 14:10:40,472 INFO:     None feature selector for col chem
2022-12-31 14:10:40,473 INFO:     None feature selector for col chem
2022-12-31 14:10:40,473 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:10:40,473 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:10:40,474 INFO:     Number of params in model 223921
2022-12-31 14:10:40,478 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:10:40,478 INFO:   Starting stage: TRAINING
2022-12-31 14:10:40,523 INFO:     Val loss before train {'Reaction outcome loss': 1.0939977208773295, 'Total loss': 1.0939977208773295}
2022-12-31 14:10:40,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:40,524 INFO:     Epoch: 0
2022-12-31 14:10:42,178 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7124971508979797, 'Total loss': 0.7124971508979797} | train loss {'Reaction outcome loss': 0.8176394365188004, 'Total loss': 0.8176394365188004}
2022-12-31 14:10:42,178 INFO:     Found new best model at epoch 0
2022-12-31 14:10:42,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:42,179 INFO:     Epoch: 1
2022-12-31 14:10:43,781 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5223576486110687, 'Total loss': 0.5223576486110687} | train loss {'Reaction outcome loss': 0.6081105804313784, 'Total loss': 0.6081105804313784}
2022-12-31 14:10:43,781 INFO:     Found new best model at epoch 1
2022-12-31 14:10:43,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:43,782 INFO:     Epoch: 2
2022-12-31 14:10:45,427 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4781017104784648, 'Total loss': 0.4781017104784648} | train loss {'Reaction outcome loss': 0.5320218263760857, 'Total loss': 0.5320218263760857}
2022-12-31 14:10:45,427 INFO:     Found new best model at epoch 2
2022-12-31 14:10:45,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:45,428 INFO:     Epoch: 3
2022-12-31 14:10:47,062 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4990510145823161, 'Total loss': 0.4990510145823161} | train loss {'Reaction outcome loss': 0.5070714239506439, 'Total loss': 0.5070714239506439}
2022-12-31 14:10:47,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:47,063 INFO:     Epoch: 4
2022-12-31 14:10:48,681 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47186463276545204, 'Total loss': 0.47186463276545204} | train loss {'Reaction outcome loss': 0.49133596445123356, 'Total loss': 0.49133596445123356}
2022-12-31 14:10:48,681 INFO:     Found new best model at epoch 4
2022-12-31 14:10:48,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:48,682 INFO:     Epoch: 5
2022-12-31 14:10:50,295 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4565027723709742, 'Total loss': 0.4565027723709742} | train loss {'Reaction outcome loss': 0.4875363495952036, 'Total loss': 0.4875363495952036}
2022-12-31 14:10:50,295 INFO:     Found new best model at epoch 5
2022-12-31 14:10:50,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:50,296 INFO:     Epoch: 6
2022-12-31 14:10:51,893 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4766809721787771, 'Total loss': 0.4766809721787771} | train loss {'Reaction outcome loss': 0.47766806635089504, 'Total loss': 0.47766806635089504}
2022-12-31 14:10:51,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:51,894 INFO:     Epoch: 7
2022-12-31 14:10:53,539 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4442884802818298, 'Total loss': 0.4442884802818298} | train loss {'Reaction outcome loss': 0.46052096179430035, 'Total loss': 0.46052096179430035}
2022-12-31 14:10:53,539 INFO:     Found new best model at epoch 7
2022-12-31 14:10:53,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:53,540 INFO:     Epoch: 8
2022-12-31 14:10:55,157 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4197765161593755, 'Total loss': 0.4197765161593755} | train loss {'Reaction outcome loss': 0.45335108554665593, 'Total loss': 0.45335108554665593}
2022-12-31 14:10:55,157 INFO:     Found new best model at epoch 8
2022-12-31 14:10:55,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:55,158 INFO:     Epoch: 9
2022-12-31 14:10:56,772 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4457353850205739, 'Total loss': 0.4457353850205739} | train loss {'Reaction outcome loss': 0.45493537166592013, 'Total loss': 0.45493537166592013}
2022-12-31 14:10:56,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:56,772 INFO:     Epoch: 10
2022-12-31 14:10:58,382 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44411979913711547, 'Total loss': 0.44411979913711547} | train loss {'Reaction outcome loss': 0.44207926126588404, 'Total loss': 0.44207926126588404}
2022-12-31 14:10:58,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:10:58,383 INFO:     Epoch: 11
2022-12-31 14:11:00,023 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4335956414540609, 'Total loss': 0.4335956414540609} | train loss {'Reaction outcome loss': 0.43716891941384994, 'Total loss': 0.43716891941384994}
2022-12-31 14:11:00,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:00,023 INFO:     Epoch: 12
2022-12-31 14:11:01,632 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4367105429371198, 'Total loss': 0.4367105429371198} | train loss {'Reaction outcome loss': 0.4306764101065578, 'Total loss': 0.4306764101065578}
2022-12-31 14:11:01,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:01,632 INFO:     Epoch: 13
2022-12-31 14:11:03,274 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42773960133393607, 'Total loss': 0.42773960133393607} | train loss {'Reaction outcome loss': 0.4214670975048068, 'Total loss': 0.4214670975048068}
2022-12-31 14:11:03,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:03,275 INFO:     Epoch: 14
2022-12-31 14:11:04,923 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49235104223092396, 'Total loss': 0.49235104223092396} | train loss {'Reaction outcome loss': 0.43765467043588124, 'Total loss': 0.43765467043588124}
2022-12-31 14:11:04,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:04,923 INFO:     Epoch: 15
2022-12-31 14:11:06,558 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39150216182072956, 'Total loss': 0.39150216182072956} | train loss {'Reaction outcome loss': 0.48118114239279774, 'Total loss': 0.48118114239279774}
2022-12-31 14:11:06,558 INFO:     Found new best model at epoch 15
2022-12-31 14:11:06,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:06,559 INFO:     Epoch: 16
2022-12-31 14:11:08,200 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4144829839468002, 'Total loss': 0.4144829839468002} | train loss {'Reaction outcome loss': 0.42234483496345027, 'Total loss': 0.42234483496345027}
2022-12-31 14:11:08,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:08,200 INFO:     Epoch: 17
2022-12-31 14:11:09,838 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3905929068724314, 'Total loss': 0.3905929068724314} | train loss {'Reaction outcome loss': 0.4119390902958095, 'Total loss': 0.4119390902958095}
2022-12-31 14:11:09,838 INFO:     Found new best model at epoch 17
2022-12-31 14:11:09,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:09,839 INFO:     Epoch: 18
2022-12-31 14:11:11,461 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42402980228265125, 'Total loss': 0.42402980228265125} | train loss {'Reaction outcome loss': 0.40271202850398485, 'Total loss': 0.40271202850398485}
2022-12-31 14:11:11,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:11,462 INFO:     Epoch: 19
2022-12-31 14:11:13,119 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3945890814065933, 'Total loss': 0.3945890814065933} | train loss {'Reaction outcome loss': 0.3942823648845871, 'Total loss': 0.3942823648845871}
2022-12-31 14:11:13,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:13,119 INFO:     Epoch: 20
2022-12-31 14:11:14,767 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40907498598098757, 'Total loss': 0.40907498598098757} | train loss {'Reaction outcome loss': 0.39369431233195507, 'Total loss': 0.39369431233195507}
2022-12-31 14:11:14,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:14,767 INFO:     Epoch: 21
2022-12-31 14:11:16,397 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4109235515197118, 'Total loss': 0.4109235515197118} | train loss {'Reaction outcome loss': 0.38966995255390613, 'Total loss': 0.38966995255390613}
2022-12-31 14:11:16,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:16,397 INFO:     Epoch: 22
2022-12-31 14:11:18,044 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4477615217367808, 'Total loss': 0.4477615217367808} | train loss {'Reaction outcome loss': 0.3845756309093449, 'Total loss': 0.3845756309093449}
2022-12-31 14:11:18,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:18,044 INFO:     Epoch: 23
2022-12-31 14:11:19,654 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4065286179383596, 'Total loss': 0.4065286179383596} | train loss {'Reaction outcome loss': 0.37582546210699325, 'Total loss': 0.37582546210699325}
2022-12-31 14:11:19,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:19,654 INFO:     Epoch: 24
2022-12-31 14:11:21,302 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3982041577498118, 'Total loss': 0.3982041577498118} | train loss {'Reaction outcome loss': 0.36855497483528504, 'Total loss': 0.36855497483528504}
2022-12-31 14:11:21,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:21,302 INFO:     Epoch: 25
2022-12-31 14:11:22,942 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3931126246849696, 'Total loss': 0.3931126246849696} | train loss {'Reaction outcome loss': 0.36883135386270244, 'Total loss': 0.36883135386270244}
2022-12-31 14:11:22,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:22,942 INFO:     Epoch: 26
2022-12-31 14:11:24,588 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4119362433751424, 'Total loss': 0.4119362433751424} | train loss {'Reaction outcome loss': 0.3627583139737987, 'Total loss': 0.3627583139737987}
2022-12-31 14:11:24,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:24,588 INFO:     Epoch: 27
2022-12-31 14:11:26,193 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4077753772338231, 'Total loss': 0.4077753772338231} | train loss {'Reaction outcome loss': 0.36294814707482304, 'Total loss': 0.36294814707482304}
2022-12-31 14:11:26,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:26,193 INFO:     Epoch: 28
2022-12-31 14:11:27,816 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3968660255273183, 'Total loss': 0.3968660255273183} | train loss {'Reaction outcome loss': 0.34783208055381215, 'Total loss': 0.34783208055381215}
2022-12-31 14:11:27,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:27,817 INFO:     Epoch: 29
2022-12-31 14:11:29,410 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39948844015598295, 'Total loss': 0.39948844015598295} | train loss {'Reaction outcome loss': 0.3506111593838875, 'Total loss': 0.3506111593838875}
2022-12-31 14:11:29,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:29,410 INFO:     Epoch: 30
2022-12-31 14:11:31,024 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4292050530513128, 'Total loss': 0.4292050530513128} | train loss {'Reaction outcome loss': 0.3473192631980688, 'Total loss': 0.3473192631980688}
2022-12-31 14:11:31,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:31,024 INFO:     Epoch: 31
2022-12-31 14:11:32,636 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3613504280646642, 'Total loss': 0.3613504280646642} | train loss {'Reaction outcome loss': 0.33695984982882626, 'Total loss': 0.33695984982882626}
2022-12-31 14:11:32,636 INFO:     Found new best model at epoch 31
2022-12-31 14:11:32,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:32,637 INFO:     Epoch: 32
2022-12-31 14:11:34,240 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39509700338045756, 'Total loss': 0.39509700338045756} | train loss {'Reaction outcome loss': 0.3402793696825055, 'Total loss': 0.3402793696825055}
2022-12-31 14:11:34,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:34,241 INFO:     Epoch: 33
2022-12-31 14:11:35,854 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41151628096898396, 'Total loss': 0.41151628096898396} | train loss {'Reaction outcome loss': 0.3343668229569195, 'Total loss': 0.3343668229569195}
2022-12-31 14:11:35,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:35,854 INFO:     Epoch: 34
2022-12-31 14:11:37,459 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4137307008107503, 'Total loss': 0.4137307008107503} | train loss {'Reaction outcome loss': 0.33298701158576255, 'Total loss': 0.33298701158576255}
2022-12-31 14:11:37,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:37,460 INFO:     Epoch: 35
2022-12-31 14:11:39,067 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4001399834950765, 'Total loss': 0.4001399834950765} | train loss {'Reaction outcome loss': 0.3256902991426245, 'Total loss': 0.3256902991426245}
2022-12-31 14:11:39,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:39,067 INFO:     Epoch: 36
2022-12-31 14:11:40,688 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3994724074999491, 'Total loss': 0.3994724074999491} | train loss {'Reaction outcome loss': 0.3185699674544647, 'Total loss': 0.3185699674544647}
2022-12-31 14:11:40,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:40,688 INFO:     Epoch: 37
2022-12-31 14:11:42,300 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4139348308245341, 'Total loss': 0.4139348308245341} | train loss {'Reaction outcome loss': 0.31985093871776044, 'Total loss': 0.31985093871776044}
2022-12-31 14:11:42,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:42,301 INFO:     Epoch: 38
2022-12-31 14:11:43,905 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.37603814552227655, 'Total loss': 0.37603814552227655} | train loss {'Reaction outcome loss': 0.31283097808667715, 'Total loss': 0.31283097808667715}
2022-12-31 14:11:43,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:43,905 INFO:     Epoch: 39
2022-12-31 14:11:45,536 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39741043746471405, 'Total loss': 0.39741043746471405} | train loss {'Reaction outcome loss': 0.3146313199228472, 'Total loss': 0.3146313199228472}
2022-12-31 14:11:45,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:45,536 INFO:     Epoch: 40
2022-12-31 14:11:46,964 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3902567187945048, 'Total loss': 0.3902567187945048} | train loss {'Reaction outcome loss': 0.31102158036251704, 'Total loss': 0.31102158036251704}
2022-12-31 14:11:46,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:46,965 INFO:     Epoch: 41
2022-12-31 14:11:48,025 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4054133415222168, 'Total loss': 0.4054133415222168} | train loss {'Reaction outcome loss': 0.30062666003578814, 'Total loss': 0.30062666003578814}
2022-12-31 14:11:48,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:48,025 INFO:     Epoch: 42
2022-12-31 14:11:49,077 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41040532290935516, 'Total loss': 0.41040532290935516} | train loss {'Reaction outcome loss': 0.299248207194319, 'Total loss': 0.299248207194319}
2022-12-31 14:11:49,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:49,078 INFO:     Epoch: 43
2022-12-31 14:11:50,137 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3615951379140218, 'Total loss': 0.3615951379140218} | train loss {'Reaction outcome loss': 0.30052238554302335, 'Total loss': 0.30052238554302335}
2022-12-31 14:11:50,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:50,138 INFO:     Epoch: 44
2022-12-31 14:11:51,202 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.36670659681161244, 'Total loss': 0.36670659681161244} | train loss {'Reaction outcome loss': 0.30886542114118737, 'Total loss': 0.30886542114118737}
2022-12-31 14:11:51,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:51,202 INFO:     Epoch: 45
2022-12-31 14:11:52,799 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42532892525196075, 'Total loss': 0.42532892525196075} | train loss {'Reaction outcome loss': 0.29298047738932614, 'Total loss': 0.29298047738932614}
2022-12-31 14:11:52,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:52,799 INFO:     Epoch: 46
2022-12-31 14:11:54,407 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3873498578866323, 'Total loss': 0.3873498578866323} | train loss {'Reaction outcome loss': 0.3504154129304748, 'Total loss': 0.3504154129304748}
2022-12-31 14:11:54,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:54,407 INFO:     Epoch: 47
2022-12-31 14:11:56,033 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.36299617489178976, 'Total loss': 0.36299617489178976} | train loss {'Reaction outcome loss': 0.2985009397852464, 'Total loss': 0.2985009397852464}
2022-12-31 14:11:56,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:56,033 INFO:     Epoch: 48
2022-12-31 14:11:57,655 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41136038601398467, 'Total loss': 0.41136038601398467} | train loss {'Reaction outcome loss': 0.2909231537470486, 'Total loss': 0.2909231537470486}
2022-12-31 14:11:57,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:57,655 INFO:     Epoch: 49
2022-12-31 14:11:59,275 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37772454718748727, 'Total loss': 0.37772454718748727} | train loss {'Reaction outcome loss': 0.2872208585638715, 'Total loss': 0.2872208585638715}
2022-12-31 14:11:59,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:11:59,275 INFO:     Epoch: 50
2022-12-31 14:12:00,873 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4231313645839691, 'Total loss': 0.4231313645839691} | train loss {'Reaction outcome loss': 0.2848231850758843, 'Total loss': 0.2848231850758843}
2022-12-31 14:12:00,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:00,874 INFO:     Epoch: 51
2022-12-31 14:12:02,483 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41520819465319314, 'Total loss': 0.41520819465319314} | train loss {'Reaction outcome loss': 0.32018364434960583, 'Total loss': 0.32018364434960583}
2022-12-31 14:12:02,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:02,484 INFO:     Epoch: 52
2022-12-31 14:12:04,095 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4200394888718923, 'Total loss': 0.4200394888718923} | train loss {'Reaction outcome loss': 0.2823623724010152, 'Total loss': 0.2823623724010152}
2022-12-31 14:12:04,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:04,095 INFO:     Epoch: 53
2022-12-31 14:12:05,706 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40287738144397733, 'Total loss': 0.40287738144397733} | train loss {'Reaction outcome loss': 0.27477373675429734, 'Total loss': 0.27477373675429734}
2022-12-31 14:12:05,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:05,706 INFO:     Epoch: 54
2022-12-31 14:12:07,343 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.394140217701594, 'Total loss': 0.394140217701594} | train loss {'Reaction outcome loss': 0.27178821323162783, 'Total loss': 0.27178821323162783}
2022-12-31 14:12:07,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:07,344 INFO:     Epoch: 55
2022-12-31 14:12:08,965 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41390182947119075, 'Total loss': 0.41390182947119075} | train loss {'Reaction outcome loss': 0.2744885717883058, 'Total loss': 0.2744885717883058}
2022-12-31 14:12:08,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:08,966 INFO:     Epoch: 56
2022-12-31 14:12:10,579 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36939258575439454, 'Total loss': 0.36939258575439454} | train loss {'Reaction outcome loss': 0.27383419627026806, 'Total loss': 0.27383419627026806}
2022-12-31 14:12:10,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:10,579 INFO:     Epoch: 57
2022-12-31 14:12:12,196 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4143113056818644, 'Total loss': 0.4143113056818644} | train loss {'Reaction outcome loss': 0.26941992002336873, 'Total loss': 0.26941992002336873}
2022-12-31 14:12:12,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:12,196 INFO:     Epoch: 58
2022-12-31 14:12:13,809 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3660898541410764, 'Total loss': 0.3660898541410764} | train loss {'Reaction outcome loss': 0.27813909439435625, 'Total loss': 0.27813909439435625}
2022-12-31 14:12:13,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:13,810 INFO:     Epoch: 59
2022-12-31 14:12:15,424 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.395280584692955, 'Total loss': 0.395280584692955} | train loss {'Reaction outcome loss': 0.262843394368563, 'Total loss': 0.262843394368563}
2022-12-31 14:12:15,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:15,424 INFO:     Epoch: 60
2022-12-31 14:12:17,033 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4021594603856405, 'Total loss': 0.4021594603856405} | train loss {'Reaction outcome loss': 0.2631574808740128, 'Total loss': 0.2631574808740128}
2022-12-31 14:12:17,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:17,034 INFO:     Epoch: 61
2022-12-31 14:12:18,657 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3941321631272634, 'Total loss': 0.3941321631272634} | train loss {'Reaction outcome loss': 0.2651211202930057, 'Total loss': 0.2651211202930057}
2022-12-31 14:12:18,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:18,657 INFO:     Epoch: 62
2022-12-31 14:12:20,278 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4129704475402832, 'Total loss': 0.4129704475402832} | train loss {'Reaction outcome loss': 0.25391729140951147, 'Total loss': 0.25391729140951147}
2022-12-31 14:12:20,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:20,278 INFO:     Epoch: 63
2022-12-31 14:12:21,900 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39609216650327045, 'Total loss': 0.39609216650327045} | train loss {'Reaction outcome loss': 0.2573197715429832, 'Total loss': 0.2573197715429832}
2022-12-31 14:12:21,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:21,901 INFO:     Epoch: 64
2022-12-31 14:12:23,545 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38017769952615105, 'Total loss': 0.38017769952615105} | train loss {'Reaction outcome loss': 0.25131048153992236, 'Total loss': 0.25131048153992236}
2022-12-31 14:12:23,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:23,545 INFO:     Epoch: 65
2022-12-31 14:12:25,189 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40439111590385435, 'Total loss': 0.40439111590385435} | train loss {'Reaction outcome loss': 0.2533999257788494, 'Total loss': 0.2533999257788494}
2022-12-31 14:12:25,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:25,189 INFO:     Epoch: 66
2022-12-31 14:12:26,815 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40569913884003955, 'Total loss': 0.40569913884003955} | train loss {'Reaction outcome loss': 0.2565920168189737, 'Total loss': 0.2565920168189737}
2022-12-31 14:12:26,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:26,816 INFO:     Epoch: 67
2022-12-31 14:12:28,443 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43692928155263266, 'Total loss': 0.43692928155263266} | train loss {'Reaction outcome loss': 0.2468250174745175, 'Total loss': 0.2468250174745175}
2022-12-31 14:12:28,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:28,444 INFO:     Epoch: 68
2022-12-31 14:12:30,086 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37025883148113886, 'Total loss': 0.37025883148113886} | train loss {'Reaction outcome loss': 0.24832730408440734, 'Total loss': 0.24832730408440734}
2022-12-31 14:12:30,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:30,086 INFO:     Epoch: 69
2022-12-31 14:12:31,708 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4124235838651657, 'Total loss': 0.4124235838651657} | train loss {'Reaction outcome loss': 0.2632271155337061, 'Total loss': 0.2632271155337061}
2022-12-31 14:12:31,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:31,709 INFO:     Epoch: 70
2022-12-31 14:12:33,347 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37458334962526957, 'Total loss': 0.37458334962526957} | train loss {'Reaction outcome loss': 0.24229352558059072, 'Total loss': 0.24229352558059072}
2022-12-31 14:12:33,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:33,348 INFO:     Epoch: 71
2022-12-31 14:12:34,972 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4667024364074071, 'Total loss': 0.4667024364074071} | train loss {'Reaction outcome loss': 0.24556187416116396, 'Total loss': 0.24556187416116396}
2022-12-31 14:12:34,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:34,973 INFO:     Epoch: 72
2022-12-31 14:12:36,599 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3983095427354177, 'Total loss': 0.3983095427354177} | train loss {'Reaction outcome loss': 0.27778375687320594, 'Total loss': 0.27778375687320594}
2022-12-31 14:12:36,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:36,599 INFO:     Epoch: 73
2022-12-31 14:12:38,216 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40450233419736226, 'Total loss': 0.40450233419736226} | train loss {'Reaction outcome loss': 0.3185920451369779, 'Total loss': 0.3185920451369779}
2022-12-31 14:12:38,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:38,216 INFO:     Epoch: 74
2022-12-31 14:12:39,859 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38998202482859295, 'Total loss': 0.38998202482859295} | train loss {'Reaction outcome loss': 0.26497429313831555, 'Total loss': 0.26497429313831555}
2022-12-31 14:12:39,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:39,859 INFO:     Epoch: 75
2022-12-31 14:12:41,495 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37772026906410855, 'Total loss': 0.37772026906410855} | train loss {'Reaction outcome loss': 0.24741958209547127, 'Total loss': 0.24741958209547127}
2022-12-31 14:12:41,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:41,495 INFO:     Epoch: 76
2022-12-31 14:12:43,109 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3864555766185125, 'Total loss': 0.3864555766185125} | train loss {'Reaction outcome loss': 0.2434605548324475, 'Total loss': 0.2434605548324475}
2022-12-31 14:12:43,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:43,109 INFO:     Epoch: 77
2022-12-31 14:12:44,730 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3609742770592372, 'Total loss': 0.3609742770592372} | train loss {'Reaction outcome loss': 0.25173473672644386, 'Total loss': 0.25173473672644386}
2022-12-31 14:12:44,730 INFO:     Found new best model at epoch 77
2022-12-31 14:12:44,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:44,731 INFO:     Epoch: 78
2022-12-31 14:12:46,327 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41163732409477233, 'Total loss': 0.41163732409477233} | train loss {'Reaction outcome loss': 0.2805026205205122, 'Total loss': 0.2805026205205122}
2022-12-31 14:12:46,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:46,327 INFO:     Epoch: 79
2022-12-31 14:12:47,934 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.374971778690815, 'Total loss': 0.374971778690815} | train loss {'Reaction outcome loss': 0.24872957025671485, 'Total loss': 0.24872957025671485}
2022-12-31 14:12:47,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:47,934 INFO:     Epoch: 80
2022-12-31 14:12:49,560 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3742610236008962, 'Total loss': 0.3742610236008962} | train loss {'Reaction outcome loss': 0.23684622583159184, 'Total loss': 0.23684622583159184}
2022-12-31 14:12:49,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:49,561 INFO:     Epoch: 81
2022-12-31 14:12:51,204 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38149486084779105, 'Total loss': 0.38149486084779105} | train loss {'Reaction outcome loss': 0.2304852766455556, 'Total loss': 0.2304852766455556}
2022-12-31 14:12:51,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:51,204 INFO:     Epoch: 82
2022-12-31 14:12:52,818 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41038741568724313, 'Total loss': 0.41038741568724313} | train loss {'Reaction outcome loss': 0.23172119837371333, 'Total loss': 0.23172119837371333}
2022-12-31 14:12:52,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:52,819 INFO:     Epoch: 83
2022-12-31 14:12:54,439 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4126570423444112, 'Total loss': 0.4126570423444112} | train loss {'Reaction outcome loss': 0.2296796861793036, 'Total loss': 0.2296796861793036}
2022-12-31 14:12:54,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:54,440 INFO:     Epoch: 84
2022-12-31 14:12:56,041 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.39205191532770794, 'Total loss': 0.39205191532770794} | train loss {'Reaction outcome loss': 0.23519024728001028, 'Total loss': 0.23519024728001028}
2022-12-31 14:12:56,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:56,042 INFO:     Epoch: 85
2022-12-31 14:12:57,647 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4536447082956632, 'Total loss': 0.4536447082956632} | train loss {'Reaction outcome loss': 0.2420570400300557, 'Total loss': 0.2420570400300557}
2022-12-31 14:12:57,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:57,647 INFO:     Epoch: 86
2022-12-31 14:12:59,253 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38765192876259486, 'Total loss': 0.38765192876259486} | train loss {'Reaction outcome loss': 0.2269542270160176, 'Total loss': 0.2269542270160176}
2022-12-31 14:12:59,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:12:59,253 INFO:     Epoch: 87
2022-12-31 14:13:00,888 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4086602787176768, 'Total loss': 0.4086602787176768} | train loss {'Reaction outcome loss': 0.2176597951269191, 'Total loss': 0.2176597951269191}
2022-12-31 14:13:00,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:00,888 INFO:     Epoch: 88
2022-12-31 14:13:02,491 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42799037098884585, 'Total loss': 0.42799037098884585} | train loss {'Reaction outcome loss': 0.22910797668062488, 'Total loss': 0.22910797668062488}
2022-12-31 14:13:02,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:02,491 INFO:     Epoch: 89
2022-12-31 14:13:04,117 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40312811036904656, 'Total loss': 0.40312811036904656} | train loss {'Reaction outcome loss': 0.22207234318341143, 'Total loss': 0.22207234318341143}
2022-12-31 14:13:04,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:04,118 INFO:     Epoch: 90
2022-12-31 14:13:05,734 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40902009308338166, 'Total loss': 0.40902009308338166} | train loss {'Reaction outcome loss': 0.22228128202888014, 'Total loss': 0.22228128202888014}
2022-12-31 14:13:05,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:05,734 INFO:     Epoch: 91
2022-12-31 14:13:07,358 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3925580598413944, 'Total loss': 0.3925580598413944} | train loss {'Reaction outcome loss': 0.21954752604685474, 'Total loss': 0.21954752604685474}
2022-12-31 14:13:07,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:07,358 INFO:     Epoch: 92
2022-12-31 14:13:08,990 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3932634284098943, 'Total loss': 0.3932634284098943} | train loss {'Reaction outcome loss': 0.22036619950929467, 'Total loss': 0.22036619950929467}
2022-12-31 14:13:08,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:08,991 INFO:     Epoch: 93
2022-12-31 14:13:10,622 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41144753297170006, 'Total loss': 0.41144753297170006} | train loss {'Reaction outcome loss': 0.21872610542788237, 'Total loss': 0.21872610542788237}
2022-12-31 14:13:10,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:10,622 INFO:     Epoch: 94
2022-12-31 14:13:12,233 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3976020872592926, 'Total loss': 0.3976020872592926} | train loss {'Reaction outcome loss': 0.2164095695163427, 'Total loss': 0.2164095695163427}
2022-12-31 14:13:12,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:12,233 INFO:     Epoch: 95
2022-12-31 14:13:13,858 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37104238048195837, 'Total loss': 0.37104238048195837} | train loss {'Reaction outcome loss': 0.21430780935802235, 'Total loss': 0.21430780935802235}
2022-12-31 14:13:13,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:13,858 INFO:     Epoch: 96
2022-12-31 14:13:15,496 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4006390780210495, 'Total loss': 0.4006390780210495} | train loss {'Reaction outcome loss': 0.21095681135826136, 'Total loss': 0.21095681135826136}
2022-12-31 14:13:15,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:15,497 INFO:     Epoch: 97
2022-12-31 14:13:17,137 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41145605345567066, 'Total loss': 0.41145605345567066} | train loss {'Reaction outcome loss': 0.2126781125409542, 'Total loss': 0.2126781125409542}
2022-12-31 14:13:17,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:17,137 INFO:     Epoch: 98
2022-12-31 14:13:18,763 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4222463299830755, 'Total loss': 0.4222463299830755} | train loss {'Reaction outcome loss': 0.20653803605404575, 'Total loss': 0.20653803605404575}
2022-12-31 14:13:18,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:18,764 INFO:     Epoch: 99
2022-12-31 14:13:20,386 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37959468017021814, 'Total loss': 0.37959468017021814} | train loss {'Reaction outcome loss': 0.20838175649860996, 'Total loss': 0.20838175649860996}
2022-12-31 14:13:20,386 INFO:     Best model found after epoch 78 of 100.
2022-12-31 14:13:20,387 INFO:   Done with stage: TRAINING
2022-12-31 14:13:20,387 INFO:   Starting stage: EVALUATION
2022-12-31 14:13:20,514 INFO:   Done with stage: EVALUATION
2022-12-31 14:13:20,514 INFO:   Leaving out SEQ value Fold_5
2022-12-31 14:13:20,526 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 14:13:20,527 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:13:21,181 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:13:21,182 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:13:21,252 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:13:21,252 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:13:21,252 INFO:     No hyperparam tuning for this model
2022-12-31 14:13:21,252 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:13:21,252 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:13:21,253 INFO:     None feature selector for col prot
2022-12-31 14:13:21,253 INFO:     None feature selector for col prot
2022-12-31 14:13:21,253 INFO:     None feature selector for col prot
2022-12-31 14:13:21,254 INFO:     None feature selector for col chem
2022-12-31 14:13:21,254 INFO:     None feature selector for col chem
2022-12-31 14:13:21,254 INFO:     None feature selector for col chem
2022-12-31 14:13:21,254 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:13:21,254 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:13:21,256 INFO:     Number of params in model 223921
2022-12-31 14:13:21,259 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:13:21,259 INFO:   Starting stage: TRAINING
2022-12-31 14:13:21,303 INFO:     Val loss before train {'Reaction outcome loss': 1.0561159173647563, 'Total loss': 1.0561159173647563}
2022-12-31 14:13:21,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:21,303 INFO:     Epoch: 0
2022-12-31 14:13:22,916 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7530543406804403, 'Total loss': 0.7530543406804403} | train loss {'Reaction outcome loss': 0.8301303035012729, 'Total loss': 0.8301303035012729}
2022-12-31 14:13:22,916 INFO:     Found new best model at epoch 0
2022-12-31 14:13:22,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:22,917 INFO:     Epoch: 1
2022-12-31 14:13:24,558 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5739720702171326, 'Total loss': 0.5739720702171326} | train loss {'Reaction outcome loss': 0.609400848986284, 'Total loss': 0.609400848986284}
2022-12-31 14:13:24,558 INFO:     Found new best model at epoch 1
2022-12-31 14:13:24,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:24,559 INFO:     Epoch: 2
2022-12-31 14:13:26,190 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5754646003246308, 'Total loss': 0.5754646003246308} | train loss {'Reaction outcome loss': 0.533586961968019, 'Total loss': 0.533586961968019}
2022-12-31 14:13:26,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:26,190 INFO:     Epoch: 3
2022-12-31 14:13:27,815 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5985814511775971, 'Total loss': 0.5985814511775971} | train loss {'Reaction outcome loss': 0.5083554353102269, 'Total loss': 0.5083554353102269}
2022-12-31 14:13:27,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:27,816 INFO:     Epoch: 4
2022-12-31 14:13:29,419 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5745113611221313, 'Total loss': 0.5745113611221313} | train loss {'Reaction outcome loss': 0.4937714787180691, 'Total loss': 0.4937714787180691}
2022-12-31 14:13:29,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:29,419 INFO:     Epoch: 5
2022-12-31 14:13:31,040 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5620544572671254, 'Total loss': 0.5620544572671254} | train loss {'Reaction outcome loss': 0.4856214130633052, 'Total loss': 0.4856214130633052}
2022-12-31 14:13:31,040 INFO:     Found new best model at epoch 5
2022-12-31 14:13:31,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:31,041 INFO:     Epoch: 6
2022-12-31 14:13:32,683 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5197445541620255, 'Total loss': 0.5197445541620255} | train loss {'Reaction outcome loss': 0.4747365036088487, 'Total loss': 0.4747365036088487}
2022-12-31 14:13:32,683 INFO:     Found new best model at epoch 6
2022-12-31 14:13:32,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:32,684 INFO:     Epoch: 7
2022-12-31 14:13:34,303 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5057134588559469, 'Total loss': 0.5057134588559469} | train loss {'Reaction outcome loss': 0.47036843520143756, 'Total loss': 0.47036843520143756}
2022-12-31 14:13:34,303 INFO:     Found new best model at epoch 7
2022-12-31 14:13:34,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:34,304 INFO:     Epoch: 8
2022-12-31 14:13:35,955 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5403478682041168, 'Total loss': 0.5403478682041168} | train loss {'Reaction outcome loss': 0.4799944470650044, 'Total loss': 0.4799944470650044}
2022-12-31 14:13:35,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:35,956 INFO:     Epoch: 9
2022-12-31 14:13:37,604 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.54119846423467, 'Total loss': 0.54119846423467} | train loss {'Reaction outcome loss': 0.5463639810897302, 'Total loss': 0.5463639810897302}
2022-12-31 14:13:37,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:37,604 INFO:     Epoch: 10
2022-12-31 14:13:39,211 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5819968402385711, 'Total loss': 0.5819968402385711} | train loss {'Reaction outcome loss': 0.4699175508449907, 'Total loss': 0.4699175508449907}
2022-12-31 14:13:39,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:39,211 INFO:     Epoch: 11
2022-12-31 14:13:40,829 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5530118008454641, 'Total loss': 0.5530118008454641} | train loss {'Reaction outcome loss': 0.4650503260123989, 'Total loss': 0.4650503260123989}
2022-12-31 14:13:40,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:40,829 INFO:     Epoch: 12
2022-12-31 14:13:42,477 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5057102312644323, 'Total loss': 0.5057102312644323} | train loss {'Reaction outcome loss': 0.4486316300429188, 'Total loss': 0.4486316300429188}
2022-12-31 14:13:42,477 INFO:     Found new best model at epoch 12
2022-12-31 14:13:42,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:42,478 INFO:     Epoch: 13
2022-12-31 14:13:44,119 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4929757684469223, 'Total loss': 0.4929757684469223} | train loss {'Reaction outcome loss': 0.43924881488783285, 'Total loss': 0.43924881488783285}
2022-12-31 14:13:44,119 INFO:     Found new best model at epoch 13
2022-12-31 14:13:44,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:44,120 INFO:     Epoch: 14
2022-12-31 14:13:45,752 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5289349089066188, 'Total loss': 0.5289349089066188} | train loss {'Reaction outcome loss': 0.4273993183902559, 'Total loss': 0.4273993183902559}
2022-12-31 14:13:45,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:45,753 INFO:     Epoch: 15
2022-12-31 14:13:47,372 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49578712979952494, 'Total loss': 0.49578712979952494} | train loss {'Reaction outcome loss': 0.42570784636705683, 'Total loss': 0.42570784636705683}
2022-12-31 14:13:47,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:47,373 INFO:     Epoch: 16
2022-12-31 14:13:49,003 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5117407739162445, 'Total loss': 0.5117407739162445} | train loss {'Reaction outcome loss': 0.4246087045947839, 'Total loss': 0.4246087045947839}
2022-12-31 14:13:49,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:49,004 INFO:     Epoch: 17
2022-12-31 14:13:50,607 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5148409356673559, 'Total loss': 0.5148409356673559} | train loss {'Reaction outcome loss': 0.41972046536292235, 'Total loss': 0.41972046536292235}
2022-12-31 14:13:50,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:50,607 INFO:     Epoch: 18
2022-12-31 14:13:52,236 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5612920761108399, 'Total loss': 0.5612920761108399} | train loss {'Reaction outcome loss': 0.4114539754413325, 'Total loss': 0.4114539754413325}
2022-12-31 14:13:52,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:52,237 INFO:     Epoch: 19
2022-12-31 14:13:53,858 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4756625364224116, 'Total loss': 0.4756625364224116} | train loss {'Reaction outcome loss': 0.41024490645614226, 'Total loss': 0.41024490645614226}
2022-12-31 14:13:53,858 INFO:     Found new best model at epoch 19
2022-12-31 14:13:53,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:53,859 INFO:     Epoch: 20
2022-12-31 14:13:55,484 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.504818328221639, 'Total loss': 0.504818328221639} | train loss {'Reaction outcome loss': 0.4136031450521525, 'Total loss': 0.4136031450521525}
2022-12-31 14:13:55,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:55,484 INFO:     Epoch: 21
2022-12-31 14:13:57,094 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4866960823535919, 'Total loss': 0.4866960823535919} | train loss {'Reaction outcome loss': 0.38985348631610145, 'Total loss': 0.38985348631610145}
2022-12-31 14:13:57,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:57,094 INFO:     Epoch: 22
2022-12-31 14:13:58,703 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48526898423830667, 'Total loss': 0.48526898423830667} | train loss {'Reaction outcome loss': 0.3870134109857263, 'Total loss': 0.3870134109857263}
2022-12-31 14:13:58,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:13:58,704 INFO:     Epoch: 23
2022-12-31 14:14:00,351 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5373059342304866, 'Total loss': 0.5373059342304866} | train loss {'Reaction outcome loss': 0.38246728352986387, 'Total loss': 0.38246728352986387}
2022-12-31 14:14:00,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:00,351 INFO:     Epoch: 24
2022-12-31 14:14:01,999 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.49536697268486024, 'Total loss': 0.49536697268486024} | train loss {'Reaction outcome loss': 0.37565696142458666, 'Total loss': 0.37565696142458666}
2022-12-31 14:14:02,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:02,000 INFO:     Epoch: 25
2022-12-31 14:14:03,616 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46119521657625834, 'Total loss': 0.46119521657625834} | train loss {'Reaction outcome loss': 0.37014576063180965, 'Total loss': 0.37014576063180965}
2022-12-31 14:14:03,616 INFO:     Found new best model at epoch 25
2022-12-31 14:14:03,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:03,617 INFO:     Epoch: 26
2022-12-31 14:14:05,251 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5000328997770945, 'Total loss': 0.5000328997770945} | train loss {'Reaction outcome loss': 0.3777730759044272, 'Total loss': 0.3777730759044272}
2022-12-31 14:14:05,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:05,252 INFO:     Epoch: 27
2022-12-31 14:14:06,868 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48108417391777036, 'Total loss': 0.48108417391777036} | train loss {'Reaction outcome loss': 0.39383199548456765, 'Total loss': 0.39383199548456765}
2022-12-31 14:14:06,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:06,868 INFO:     Epoch: 28
2022-12-31 14:14:08,494 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5010738650957743, 'Total loss': 0.5010738650957743} | train loss {'Reaction outcome loss': 0.36519172579468484, 'Total loss': 0.36519172579468484}
2022-12-31 14:14:08,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:08,494 INFO:     Epoch: 29
2022-12-31 14:14:10,135 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5074810365835826, 'Total loss': 0.5074810365835826} | train loss {'Reaction outcome loss': 0.3579406641234738, 'Total loss': 0.3579406641234738}
2022-12-31 14:14:10,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:10,136 INFO:     Epoch: 30
2022-12-31 14:14:11,772 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47170399129390717, 'Total loss': 0.47170399129390717} | train loss {'Reaction outcome loss': 0.3572820607113881, 'Total loss': 0.3572820607113881}
2022-12-31 14:14:11,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:11,772 INFO:     Epoch: 31
2022-12-31 14:14:13,413 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5196895519892375, 'Total loss': 0.5196895519892375} | train loss {'Reaction outcome loss': 0.3578720548721849, 'Total loss': 0.3578720548721849}
2022-12-31 14:14:13,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:13,413 INFO:     Epoch: 32
2022-12-31 14:14:15,035 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4672640005747477, 'Total loss': 0.4672640005747477} | train loss {'Reaction outcome loss': 0.34231542462341324, 'Total loss': 0.34231542462341324}
2022-12-31 14:14:15,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:15,036 INFO:     Epoch: 33
2022-12-31 14:14:16,676 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4679421246051788, 'Total loss': 0.4679421246051788} | train loss {'Reaction outcome loss': 0.3403021689072889, 'Total loss': 0.3403021689072889}
2022-12-31 14:14:16,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:16,677 INFO:     Epoch: 34
2022-12-31 14:14:18,309 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.49660083949565886, 'Total loss': 0.49660083949565886} | train loss {'Reaction outcome loss': 0.3361654075527348, 'Total loss': 0.3361654075527348}
2022-12-31 14:14:18,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:18,309 INFO:     Epoch: 35
2022-12-31 14:14:19,937 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5156875580549241, 'Total loss': 0.5156875580549241} | train loss {'Reaction outcome loss': 0.3358173378054862, 'Total loss': 0.3358173378054862}
2022-12-31 14:14:19,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:19,937 INFO:     Epoch: 36
2022-12-31 14:14:21,577 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4782185673713684, 'Total loss': 0.4782185673713684} | train loss {'Reaction outcome loss': 0.3266236571784037, 'Total loss': 0.3266236571784037}
2022-12-31 14:14:21,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:21,578 INFO:     Epoch: 37
2022-12-31 14:14:23,221 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5033580303192139, 'Total loss': 0.5033580303192139} | train loss {'Reaction outcome loss': 0.3281250426518744, 'Total loss': 0.3281250426518744}
2022-12-31 14:14:23,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:23,221 INFO:     Epoch: 38
2022-12-31 14:14:24,846 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45933720966180164, 'Total loss': 0.45933720966180164} | train loss {'Reaction outcome loss': 0.336660998036572, 'Total loss': 0.336660998036572}
2022-12-31 14:14:24,846 INFO:     Found new best model at epoch 38
2022-12-31 14:14:24,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:24,847 INFO:     Epoch: 39
2022-12-31 14:14:26,463 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46237811048825583, 'Total loss': 0.46237811048825583} | train loss {'Reaction outcome loss': 0.3143846276840465, 'Total loss': 0.3143846276840465}
2022-12-31 14:14:26,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:26,463 INFO:     Epoch: 40
2022-12-31 14:14:28,099 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5040148198604584, 'Total loss': 0.5040148198604584} | train loss {'Reaction outcome loss': 0.3097423765077796, 'Total loss': 0.3097423765077796}
2022-12-31 14:14:28,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:28,099 INFO:     Epoch: 41
2022-12-31 14:14:29,734 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4469129145145416, 'Total loss': 0.4469129145145416} | train loss {'Reaction outcome loss': 0.31216719187796116, 'Total loss': 0.31216719187796116}
2022-12-31 14:14:29,734 INFO:     Found new best model at epoch 41
2022-12-31 14:14:29,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:29,735 INFO:     Epoch: 42
2022-12-31 14:14:31,376 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.49935185015201566, 'Total loss': 0.49935185015201566} | train loss {'Reaction outcome loss': 0.334545014824919, 'Total loss': 0.334545014824919}
2022-12-31 14:14:31,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:31,376 INFO:     Epoch: 43
2022-12-31 14:14:32,990 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47536160945892336, 'Total loss': 0.47536160945892336} | train loss {'Reaction outcome loss': 0.31649570993107295, 'Total loss': 0.31649570993107295}
2022-12-31 14:14:32,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:32,991 INFO:     Epoch: 44
2022-12-31 14:14:34,593 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45824004809061686, 'Total loss': 0.45824004809061686} | train loss {'Reaction outcome loss': 0.31077518811503396, 'Total loss': 0.31077518811503396}
2022-12-31 14:14:34,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:34,594 INFO:     Epoch: 45
2022-12-31 14:14:36,214 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5047203143437703, 'Total loss': 0.5047203143437703} | train loss {'Reaction outcome loss': 0.30052181168634823, 'Total loss': 0.30052181168634823}
2022-12-31 14:14:36,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:36,215 INFO:     Epoch: 46
2022-12-31 14:14:37,827 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4832917034626007, 'Total loss': 0.4832917034626007} | train loss {'Reaction outcome loss': 0.29286990038868366, 'Total loss': 0.29286990038868366}
2022-12-31 14:14:37,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:37,827 INFO:     Epoch: 47
2022-12-31 14:14:39,439 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43955944379170736, 'Total loss': 0.43955944379170736} | train loss {'Reaction outcome loss': 0.303178567385328, 'Total loss': 0.303178567385328}
2022-12-31 14:14:39,439 INFO:     Found new best model at epoch 47
2022-12-31 14:14:39,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:39,440 INFO:     Epoch: 48
2022-12-31 14:14:41,062 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45350892345110577, 'Total loss': 0.45350892345110577} | train loss {'Reaction outcome loss': 0.29209639502527274, 'Total loss': 0.29209639502527274}
2022-12-31 14:14:41,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:41,062 INFO:     Epoch: 49
2022-12-31 14:14:42,664 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46027842660744983, 'Total loss': 0.46027842660744983} | train loss {'Reaction outcome loss': 0.29015012547640345, 'Total loss': 0.29015012547640345}
2022-12-31 14:14:42,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:42,664 INFO:     Epoch: 50
2022-12-31 14:14:44,261 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4604518234729767, 'Total loss': 0.4604518234729767} | train loss {'Reaction outcome loss': 0.3015848659046426, 'Total loss': 0.3015848659046426}
2022-12-31 14:14:44,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:44,261 INFO:     Epoch: 51
2022-12-31 14:14:45,889 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49815436999003093, 'Total loss': 0.49815436999003093} | train loss {'Reaction outcome loss': 0.3475574886669283, 'Total loss': 0.3475574886669283}
2022-12-31 14:14:45,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:45,889 INFO:     Epoch: 52
2022-12-31 14:14:47,525 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4250189701716105, 'Total loss': 0.4250189701716105} | train loss {'Reaction outcome loss': 0.31081936445759534, 'Total loss': 0.31081936445759534}
2022-12-31 14:14:47,525 INFO:     Found new best model at epoch 52
2022-12-31 14:14:47,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:47,526 INFO:     Epoch: 53
2022-12-31 14:14:49,160 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44810490707556405, 'Total loss': 0.44810490707556405} | train loss {'Reaction outcome loss': 0.30376305533708003, 'Total loss': 0.30376305533708003}
2022-12-31 14:14:49,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:49,160 INFO:     Epoch: 54
2022-12-31 14:14:50,770 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48976332346598306, 'Total loss': 0.48976332346598306} | train loss {'Reaction outcome loss': 0.29112226242769806, 'Total loss': 0.29112226242769806}
2022-12-31 14:14:50,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:50,770 INFO:     Epoch: 55
2022-12-31 14:14:52,363 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48043847978115084, 'Total loss': 0.48043847978115084} | train loss {'Reaction outcome loss': 0.27686353808646835, 'Total loss': 0.27686353808646835}
2022-12-31 14:14:52,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:52,365 INFO:     Epoch: 56
2022-12-31 14:14:53,959 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4869862655798594, 'Total loss': 0.4869862655798594} | train loss {'Reaction outcome loss': 0.26625077156147553, 'Total loss': 0.26625077156147553}
2022-12-31 14:14:53,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:53,959 INFO:     Epoch: 57
2022-12-31 14:14:55,587 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43829224109649656, 'Total loss': 0.43829224109649656} | train loss {'Reaction outcome loss': 0.27359125583324634, 'Total loss': 0.27359125583324634}
2022-12-31 14:14:55,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:55,588 INFO:     Epoch: 58
2022-12-31 14:14:57,236 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46959450443585715, 'Total loss': 0.46959450443585715} | train loss {'Reaction outcome loss': 0.2704520804311019, 'Total loss': 0.2704520804311019}
2022-12-31 14:14:57,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:57,237 INFO:     Epoch: 59
2022-12-31 14:14:58,886 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4847927808761597, 'Total loss': 0.4847927808761597} | train loss {'Reaction outcome loss': 0.2675841130667191, 'Total loss': 0.2675841130667191}
2022-12-31 14:14:58,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:14:58,887 INFO:     Epoch: 60
2022-12-31 14:15:00,507 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4624958237012227, 'Total loss': 0.4624958237012227} | train loss {'Reaction outcome loss': 0.2612721922038042, 'Total loss': 0.2612721922038042}
2022-12-31 14:15:00,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:00,507 INFO:     Epoch: 61
2022-12-31 14:15:02,147 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5340064446131388, 'Total loss': 0.5340064446131388} | train loss {'Reaction outcome loss': 0.25987331394065655, 'Total loss': 0.25987331394065655}
2022-12-31 14:15:02,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:02,148 INFO:     Epoch: 62
2022-12-31 14:15:03,742 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4600684255361557, 'Total loss': 0.4600684255361557} | train loss {'Reaction outcome loss': 0.2602245001682499, 'Total loss': 0.2602245001682499}
2022-12-31 14:15:03,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:03,742 INFO:     Epoch: 63
2022-12-31 14:15:05,358 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5215470731258393, 'Total loss': 0.5215470731258393} | train loss {'Reaction outcome loss': 0.2611791757542802, 'Total loss': 0.2611791757542802}
2022-12-31 14:15:05,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:05,359 INFO:     Epoch: 64
2022-12-31 14:15:06,979 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.494130394856135, 'Total loss': 0.494130394856135} | train loss {'Reaction outcome loss': 0.254830987066152, 'Total loss': 0.254830987066152}
2022-12-31 14:15:06,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:06,979 INFO:     Epoch: 65
2022-12-31 14:15:08,617 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4501319189866384, 'Total loss': 0.4501319189866384} | train loss {'Reaction outcome loss': 0.2513843264373397, 'Total loss': 0.2513843264373397}
2022-12-31 14:15:08,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:08,618 INFO:     Epoch: 66
2022-12-31 14:15:10,218 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46420155664285023, 'Total loss': 0.46420155664285023} | train loss {'Reaction outcome loss': 0.25017394591291586, 'Total loss': 0.25017394591291586}
2022-12-31 14:15:10,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:10,218 INFO:     Epoch: 67
2022-12-31 14:15:11,817 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42766008377075193, 'Total loss': 0.42766008377075193} | train loss {'Reaction outcome loss': 0.24677191576606972, 'Total loss': 0.24677191576606972}
2022-12-31 14:15:11,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:11,818 INFO:     Epoch: 68
2022-12-31 14:15:13,456 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5001012563705445, 'Total loss': 0.5001012563705445} | train loss {'Reaction outcome loss': 0.250066503862162, 'Total loss': 0.250066503862162}
2022-12-31 14:15:13,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:13,456 INFO:     Epoch: 69
2022-12-31 14:15:15,107 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4697365621725718, 'Total loss': 0.4697365621725718} | train loss {'Reaction outcome loss': 0.2504084511325556, 'Total loss': 0.2504084511325556}
2022-12-31 14:15:15,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:15,108 INFO:     Epoch: 70
2022-12-31 14:15:16,748 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5099662641684214, 'Total loss': 0.5099662641684214} | train loss {'Reaction outcome loss': 0.24583959712417444, 'Total loss': 0.24583959712417444}
2022-12-31 14:15:16,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:16,749 INFO:     Epoch: 71
2022-12-31 14:15:18,382 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5043795009454092, 'Total loss': 0.5043795009454092} | train loss {'Reaction outcome loss': 0.2464940760055206, 'Total loss': 0.2464940760055206}
2022-12-31 14:15:18,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:18,382 INFO:     Epoch: 72
2022-12-31 14:15:19,976 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5082336127758026, 'Total loss': 0.5082336127758026} | train loss {'Reaction outcome loss': 0.24053856763119888, 'Total loss': 0.24053856763119888}
2022-12-31 14:15:19,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:19,976 INFO:     Epoch: 73
2022-12-31 14:15:21,588 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4928104410568873, 'Total loss': 0.4928104410568873} | train loss {'Reaction outcome loss': 0.23952279922862849, 'Total loss': 0.23952279922862849}
2022-12-31 14:15:21,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:21,588 INFO:     Epoch: 74
2022-12-31 14:15:23,214 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.483005361755689, 'Total loss': 0.483005361755689} | train loss {'Reaction outcome loss': 0.2586606341495138, 'Total loss': 0.2586606341495138}
2022-12-31 14:15:23,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:23,214 INFO:     Epoch: 75
2022-12-31 14:15:24,822 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43935484687487286, 'Total loss': 0.43935484687487286} | train loss {'Reaction outcome loss': 0.2378077920782717, 'Total loss': 0.2378077920782717}
2022-12-31 14:15:24,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:24,822 INFO:     Epoch: 76
2022-12-31 14:15:26,428 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4949364682038625, 'Total loss': 0.4949364682038625} | train loss {'Reaction outcome loss': 0.23515483894911798, 'Total loss': 0.23515483894911798}
2022-12-31 14:15:26,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:26,428 INFO:     Epoch: 77
2022-12-31 14:15:28,032 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5011924842993418, 'Total loss': 0.5011924842993418} | train loss {'Reaction outcome loss': 0.23358796880178936, 'Total loss': 0.23358796880178936}
2022-12-31 14:15:28,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:28,034 INFO:     Epoch: 78
2022-12-31 14:15:29,668 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4540006756782532, 'Total loss': 0.4540006756782532} | train loss {'Reaction outcome loss': 0.23581850748725128, 'Total loss': 0.23581850748725128}
2022-12-31 14:15:29,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:29,668 INFO:     Epoch: 79
2022-12-31 14:15:31,273 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47769844929377236, 'Total loss': 0.47769844929377236} | train loss {'Reaction outcome loss': 0.23670692956479994, 'Total loss': 0.23670692956479994}
2022-12-31 14:15:31,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:31,273 INFO:     Epoch: 80
2022-12-31 14:15:32,877 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4805852770805359, 'Total loss': 0.4805852770805359} | train loss {'Reaction outcome loss': 0.23307100606515355, 'Total loss': 0.23307100606515355}
2022-12-31 14:15:32,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:32,877 INFO:     Epoch: 81
2022-12-31 14:15:34,482 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.461220313111941, 'Total loss': 0.461220313111941} | train loss {'Reaction outcome loss': 0.2273093862575057, 'Total loss': 0.2273093862575057}
2022-12-31 14:15:34,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:34,483 INFO:     Epoch: 82
2022-12-31 14:15:36,088 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5203606287638346, 'Total loss': 0.5203606287638346} | train loss {'Reaction outcome loss': 0.22533578176280836, 'Total loss': 0.22533578176280836}
2022-12-31 14:15:36,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:36,089 INFO:     Epoch: 83
2022-12-31 14:15:37,695 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5148102104663849, 'Total loss': 0.5148102104663849} | train loss {'Reaction outcome loss': 0.2292150357970968, 'Total loss': 0.2292150357970968}
2022-12-31 14:15:37,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:37,695 INFO:     Epoch: 84
2022-12-31 14:15:39,306 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5021375338236491, 'Total loss': 0.5021375338236491} | train loss {'Reaction outcome loss': 0.23806920463513065, 'Total loss': 0.23806920463513065}
2022-12-31 14:15:39,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:39,306 INFO:     Epoch: 85
2022-12-31 14:15:40,944 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4561497062444687, 'Total loss': 0.4561497062444687} | train loss {'Reaction outcome loss': 0.2363849671193115, 'Total loss': 0.2363849671193115}
2022-12-31 14:15:40,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:40,945 INFO:     Epoch: 86
2022-12-31 14:15:42,560 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4801989098389943, 'Total loss': 0.4801989098389943} | train loss {'Reaction outcome loss': 0.27384323799043964, 'Total loss': 0.27384323799043964}
2022-12-31 14:15:42,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:42,560 INFO:     Epoch: 87
2022-12-31 14:15:44,164 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4751146733760834, 'Total loss': 0.4751146733760834} | train loss {'Reaction outcome loss': 0.23365926613748172, 'Total loss': 0.23365926613748172}
2022-12-31 14:15:44,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:44,165 INFO:     Epoch: 88
2022-12-31 14:15:45,753 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4728382428487142, 'Total loss': 0.4728382428487142} | train loss {'Reaction outcome loss': 0.22560441548394275, 'Total loss': 0.22560441548394275}
2022-12-31 14:15:45,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:45,753 INFO:     Epoch: 89
2022-12-31 14:15:47,381 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46621204117933907, 'Total loss': 0.46621204117933907} | train loss {'Reaction outcome loss': 0.22636699215729386, 'Total loss': 0.22636699215729386}
2022-12-31 14:15:47,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:47,382 INFO:     Epoch: 90
2022-12-31 14:15:49,008 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44543065627415973, 'Total loss': 0.44543065627415973} | train loss {'Reaction outcome loss': 0.2227089597499403, 'Total loss': 0.2227089597499403}
2022-12-31 14:15:49,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:49,008 INFO:     Epoch: 91
2022-12-31 14:15:50,651 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4921567181746165, 'Total loss': 0.4921567181746165} | train loss {'Reaction outcome loss': 0.22691607484728962, 'Total loss': 0.22691607484728962}
2022-12-31 14:15:50,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:50,652 INFO:     Epoch: 92
2022-12-31 14:15:52,287 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4925767699877421, 'Total loss': 0.4925767699877421} | train loss {'Reaction outcome loss': 0.2192087026677378, 'Total loss': 0.2192087026677378}
2022-12-31 14:15:52,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:52,287 INFO:     Epoch: 93
2022-12-31 14:15:53,906 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45063501298427583, 'Total loss': 0.45063501298427583} | train loss {'Reaction outcome loss': 0.2239864446911151, 'Total loss': 0.2239864446911151}
2022-12-31 14:15:53,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:53,907 INFO:     Epoch: 94
2022-12-31 14:15:55,522 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4719696521759033, 'Total loss': 0.4719696521759033} | train loss {'Reaction outcome loss': 0.2531182746771146, 'Total loss': 0.2531182746771146}
2022-12-31 14:15:55,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:55,523 INFO:     Epoch: 95
2022-12-31 14:15:57,141 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47895527283350625, 'Total loss': 0.47895527283350625} | train loss {'Reaction outcome loss': 0.23362741633436468, 'Total loss': 0.23362741633436468}
2022-12-31 14:15:57,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:57,141 INFO:     Epoch: 96
2022-12-31 14:15:58,774 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44875530401865643, 'Total loss': 0.44875530401865643} | train loss {'Reaction outcome loss': 0.21922146765164274, 'Total loss': 0.21922146765164274}
2022-12-31 14:15:58,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:15:58,776 INFO:     Epoch: 97
2022-12-31 14:16:00,414 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48207543790340424, 'Total loss': 0.48207543790340424} | train loss {'Reaction outcome loss': 0.2146713074146554, 'Total loss': 0.2146713074146554}
2022-12-31 14:16:00,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:00,414 INFO:     Epoch: 98
2022-12-31 14:16:02,038 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4818185125788053, 'Total loss': 0.4818185125788053} | train loss {'Reaction outcome loss': 0.22255063949800705, 'Total loss': 0.22255063949800705}
2022-12-31 14:16:02,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:02,038 INFO:     Epoch: 99
2022-12-31 14:16:03,644 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4981518228848775, 'Total loss': 0.4981518228848775} | train loss {'Reaction outcome loss': 0.21602098314611215, 'Total loss': 0.21602098314611215}
2022-12-31 14:16:03,644 INFO:     Best model found after epoch 53 of 100.
2022-12-31 14:16:03,644 INFO:   Done with stage: TRAINING
2022-12-31 14:16:03,644 INFO:   Starting stage: EVALUATION
2022-12-31 14:16:03,772 INFO:   Done with stage: EVALUATION
2022-12-31 14:16:03,772 INFO:   Leaving out SEQ value Fold_6
2022-12-31 14:16:03,785 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 14:16:03,785 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:16:04,437 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:16:04,437 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:16:04,509 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:16:04,509 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:16:04,509 INFO:     No hyperparam tuning for this model
2022-12-31 14:16:04,509 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:16:04,509 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:16:04,510 INFO:     None feature selector for col prot
2022-12-31 14:16:04,510 INFO:     None feature selector for col prot
2022-12-31 14:16:04,510 INFO:     None feature selector for col prot
2022-12-31 14:16:04,510 INFO:     None feature selector for col chem
2022-12-31 14:16:04,511 INFO:     None feature selector for col chem
2022-12-31 14:16:04,511 INFO:     None feature selector for col chem
2022-12-31 14:16:04,511 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:16:04,511 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:16:04,512 INFO:     Number of params in model 223921
2022-12-31 14:16:04,516 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:16:04,516 INFO:   Starting stage: TRAINING
2022-12-31 14:16:04,562 INFO:     Val loss before train {'Reaction outcome loss': 1.0503204266230266, 'Total loss': 1.0503204266230266}
2022-12-31 14:16:04,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:04,563 INFO:     Epoch: 0
2022-12-31 14:16:06,165 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6968651036421458, 'Total loss': 0.6968651036421458} | train loss {'Reaction outcome loss': 0.8042383723310615, 'Total loss': 0.8042383723310615}
2022-12-31 14:16:06,166 INFO:     Found new best model at epoch 0
2022-12-31 14:16:06,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:06,167 INFO:     Epoch: 1
2022-12-31 14:16:07,794 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5584022045135498, 'Total loss': 0.5584022045135498} | train loss {'Reaction outcome loss': 0.6045750784099317, 'Total loss': 0.6045750784099317}
2022-12-31 14:16:07,794 INFO:     Found new best model at epoch 1
2022-12-31 14:16:07,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:07,795 INFO:     Epoch: 2
2022-12-31 14:16:09,452 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5339835345745086, 'Total loss': 0.5339835345745086} | train loss {'Reaction outcome loss': 0.53330472100943, 'Total loss': 0.53330472100943}
2022-12-31 14:16:09,452 INFO:     Found new best model at epoch 2
2022-12-31 14:16:09,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:09,453 INFO:     Epoch: 3
2022-12-31 14:16:11,096 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49783971707026164, 'Total loss': 0.49783971707026164} | train loss {'Reaction outcome loss': 0.5082162402381966, 'Total loss': 0.5082162402381966}
2022-12-31 14:16:11,096 INFO:     Found new best model at epoch 3
2022-12-31 14:16:11,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:11,097 INFO:     Epoch: 4
2022-12-31 14:16:12,739 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49682742754618325, 'Total loss': 0.49682742754618325} | train loss {'Reaction outcome loss': 0.4950896053430406, 'Total loss': 0.4950896053430406}
2022-12-31 14:16:12,739 INFO:     Found new best model at epoch 4
2022-12-31 14:16:12,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:12,740 INFO:     Epoch: 5
2022-12-31 14:16:14,347 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49144651293754577, 'Total loss': 0.49144651293754577} | train loss {'Reaction outcome loss': 0.48268819812833186, 'Total loss': 0.48268819812833186}
2022-12-31 14:16:14,347 INFO:     Found new best model at epoch 5
2022-12-31 14:16:14,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:14,348 INFO:     Epoch: 6
2022-12-31 14:16:15,973 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4681277891000112, 'Total loss': 0.4681277891000112} | train loss {'Reaction outcome loss': 0.47082451050462276, 'Total loss': 0.47082451050462276}
2022-12-31 14:16:15,973 INFO:     Found new best model at epoch 6
2022-12-31 14:16:15,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:15,974 INFO:     Epoch: 7
2022-12-31 14:16:17,616 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47939888139565784, 'Total loss': 0.47939888139565784} | train loss {'Reaction outcome loss': 0.4597699693286462, 'Total loss': 0.4597699693286462}
2022-12-31 14:16:17,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:17,616 INFO:     Epoch: 8
2022-12-31 14:16:19,259 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4990781943003337, 'Total loss': 0.4990781943003337} | train loss {'Reaction outcome loss': 0.45090348814153497, 'Total loss': 0.45090348814153497}
2022-12-31 14:16:19,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:19,260 INFO:     Epoch: 9
2022-12-31 14:16:20,900 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45764530897140504, 'Total loss': 0.45764530897140504} | train loss {'Reaction outcome loss': 0.44176394782879724, 'Total loss': 0.44176394782879724}
2022-12-31 14:16:20,900 INFO:     Found new best model at epoch 9
2022-12-31 14:16:20,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:20,901 INFO:     Epoch: 10
2022-12-31 14:16:22,519 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45061141848564146, 'Total loss': 0.45061141848564146} | train loss {'Reaction outcome loss': 0.43582083526931514, 'Total loss': 0.43582083526931514}
2022-12-31 14:16:22,520 INFO:     Found new best model at epoch 10
2022-12-31 14:16:22,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:22,520 INFO:     Epoch: 11
2022-12-31 14:16:24,142 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4476866702238719, 'Total loss': 0.4476866702238719} | train loss {'Reaction outcome loss': 0.4340651954662068, 'Total loss': 0.4340651954662068}
2022-12-31 14:16:24,142 INFO:     Found new best model at epoch 11
2022-12-31 14:16:24,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:24,143 INFO:     Epoch: 12
2022-12-31 14:16:25,794 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4428300470113754, 'Total loss': 0.4428300470113754} | train loss {'Reaction outcome loss': 0.42176205775152475, 'Total loss': 0.42176205775152475}
2022-12-31 14:16:25,794 INFO:     Found new best model at epoch 12
2022-12-31 14:16:25,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:25,795 INFO:     Epoch: 13
2022-12-31 14:16:27,429 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4419486920038859, 'Total loss': 0.4419486920038859} | train loss {'Reaction outcome loss': 0.418658032959549, 'Total loss': 0.418658032959549}
2022-12-31 14:16:27,429 INFO:     Found new best model at epoch 13
2022-12-31 14:16:27,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:27,430 INFO:     Epoch: 14
2022-12-31 14:16:29,051 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44565518101056417, 'Total loss': 0.44565518101056417} | train loss {'Reaction outcome loss': 0.4096247015608347, 'Total loss': 0.4096247015608347}
2022-12-31 14:16:29,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:29,052 INFO:     Epoch: 15
2022-12-31 14:16:30,672 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45152814586957296, 'Total loss': 0.45152814586957296} | train loss {'Reaction outcome loss': 0.4070303581574333, 'Total loss': 0.4070303581574333}
2022-12-31 14:16:30,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:30,672 INFO:     Epoch: 16
2022-12-31 14:16:32,295 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45334699749946594, 'Total loss': 0.45334699749946594} | train loss {'Reaction outcome loss': 0.3992417730955871, 'Total loss': 0.3992417730955871}
2022-12-31 14:16:32,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:32,295 INFO:     Epoch: 17
2022-12-31 14:16:33,917 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4666616479555766, 'Total loss': 0.4666616479555766} | train loss {'Reaction outcome loss': 0.391784211573618, 'Total loss': 0.391784211573618}
2022-12-31 14:16:33,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:33,917 INFO:     Epoch: 18
2022-12-31 14:16:35,568 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4564582109451294, 'Total loss': 0.4564582109451294} | train loss {'Reaction outcome loss': 0.3853496185870377, 'Total loss': 0.3853496185870377}
2022-12-31 14:16:35,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:35,568 INFO:     Epoch: 19
2022-12-31 14:16:37,218 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45637355248133343, 'Total loss': 0.45637355248133343} | train loss {'Reaction outcome loss': 0.37842628179582016, 'Total loss': 0.37842628179582016}
2022-12-31 14:16:37,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:37,218 INFO:     Epoch: 20
2022-12-31 14:16:38,875 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40534568031628926, 'Total loss': 0.40534568031628926} | train loss {'Reaction outcome loss': 0.37740918219304687, 'Total loss': 0.37740918219304687}
2022-12-31 14:16:38,876 INFO:     Found new best model at epoch 20
2022-12-31 14:16:38,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:38,877 INFO:     Epoch: 21
2022-12-31 14:16:40,479 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47220005591710407, 'Total loss': 0.47220005591710407} | train loss {'Reaction outcome loss': 0.37212805347752487, 'Total loss': 0.37212805347752487}
2022-12-31 14:16:40,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:40,479 INFO:     Epoch: 22
2022-12-31 14:16:42,085 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45910488069057465, 'Total loss': 0.45910488069057465} | train loss {'Reaction outcome loss': 0.3668477508619374, 'Total loss': 0.3668477508619374}
2022-12-31 14:16:42,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:42,085 INFO:     Epoch: 23
2022-12-31 14:16:43,704 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4566125681002935, 'Total loss': 0.4566125681002935} | train loss {'Reaction outcome loss': 0.35541619212511216, 'Total loss': 0.35541619212511216}
2022-12-31 14:16:43,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:43,705 INFO:     Epoch: 24
2022-12-31 14:16:45,340 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4545149823029836, 'Total loss': 0.4545149823029836} | train loss {'Reaction outcome loss': 0.35573993798089804, 'Total loss': 0.35573993798089804}
2022-12-31 14:16:45,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:45,340 INFO:     Epoch: 25
2022-12-31 14:16:46,963 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4086933801571528, 'Total loss': 0.4086933801571528} | train loss {'Reaction outcome loss': 0.3499228508087272, 'Total loss': 0.3499228508087272}
2022-12-31 14:16:46,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:46,963 INFO:     Epoch: 26
2022-12-31 14:16:48,595 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4564370314280192, 'Total loss': 0.4564370314280192} | train loss {'Reaction outcome loss': 0.3401837795031415, 'Total loss': 0.3401837795031415}
2022-12-31 14:16:48,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:48,596 INFO:     Epoch: 27
2022-12-31 14:16:50,220 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44722157915433247, 'Total loss': 0.44722157915433247} | train loss {'Reaction outcome loss': 0.34269864171313036, 'Total loss': 0.34269864171313036}
2022-12-31 14:16:50,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:50,220 INFO:     Epoch: 28
2022-12-31 14:16:51,846 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4178420225779215, 'Total loss': 0.4178420225779215} | train loss {'Reaction outcome loss': 0.3381631242292883, 'Total loss': 0.3381631242292883}
2022-12-31 14:16:51,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:51,846 INFO:     Epoch: 29
2022-12-31 14:16:53,480 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4581253588199615, 'Total loss': 0.4581253588199615} | train loss {'Reaction outcome loss': 0.3323711601459162, 'Total loss': 0.3323711601459162}
2022-12-31 14:16:53,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:53,481 INFO:     Epoch: 30
2022-12-31 14:16:55,136 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47088733116785686, 'Total loss': 0.47088733116785686} | train loss {'Reaction outcome loss': 0.32848027160236554, 'Total loss': 0.32848027160236554}
2022-12-31 14:16:55,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:55,136 INFO:     Epoch: 31
2022-12-31 14:16:56,782 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44455295701821645, 'Total loss': 0.44455295701821645} | train loss {'Reaction outcome loss': 0.3137923524267837, 'Total loss': 0.3137923524267837}
2022-12-31 14:16:56,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:56,782 INFO:     Epoch: 32
2022-12-31 14:16:58,383 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.458716893196106, 'Total loss': 0.458716893196106} | train loss {'Reaction outcome loss': 0.31944303982470873, 'Total loss': 0.31944303982470873}
2022-12-31 14:16:58,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:16:58,383 INFO:     Epoch: 33
2022-12-31 14:17:00,008 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4463954339424769, 'Total loss': 0.4463954339424769} | train loss {'Reaction outcome loss': 0.3088780471295226, 'Total loss': 0.3088780471295226}
2022-12-31 14:17:00,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:00,009 INFO:     Epoch: 34
2022-12-31 14:17:01,630 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45494770507017773, 'Total loss': 0.45494770507017773} | train loss {'Reaction outcome loss': 0.31264993610257275, 'Total loss': 0.31264993610257275}
2022-12-31 14:17:01,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:01,630 INFO:     Epoch: 35
2022-12-31 14:17:03,255 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4407234191894531, 'Total loss': 0.4407234191894531} | train loss {'Reaction outcome loss': 0.3055610821619361, 'Total loss': 0.3055610821619361}
2022-12-31 14:17:03,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:03,255 INFO:     Epoch: 36
2022-12-31 14:17:04,897 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42261998256047567, 'Total loss': 0.42261998256047567} | train loss {'Reaction outcome loss': 0.30202245055311205, 'Total loss': 0.30202245055311205}
2022-12-31 14:17:04,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:04,898 INFO:     Epoch: 37
2022-12-31 14:17:06,523 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.398993115623792, 'Total loss': 0.398993115623792} | train loss {'Reaction outcome loss': 0.29262171730076364, 'Total loss': 0.29262171730076364}
2022-12-31 14:17:06,523 INFO:     Found new best model at epoch 37
2022-12-31 14:17:06,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:06,524 INFO:     Epoch: 38
2022-12-31 14:17:08,158 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39305152197678883, 'Total loss': 0.39305152197678883} | train loss {'Reaction outcome loss': 0.2953572128277393, 'Total loss': 0.2953572128277393}
2022-12-31 14:17:08,158 INFO:     Found new best model at epoch 38
2022-12-31 14:17:08,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:08,159 INFO:     Epoch: 39
2022-12-31 14:17:09,785 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47721641063690184, 'Total loss': 0.47721641063690184} | train loss {'Reaction outcome loss': 0.28762911332751007, 'Total loss': 0.28762911332751007}
2022-12-31 14:17:09,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:09,785 INFO:     Epoch: 40
2022-12-31 14:17:11,424 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43842246135075885, 'Total loss': 0.43842246135075885} | train loss {'Reaction outcome loss': 0.2835011892155189, 'Total loss': 0.2835011892155189}
2022-12-31 14:17:11,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:11,425 INFO:     Epoch: 41
2022-12-31 14:17:13,054 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4691225508848826, 'Total loss': 0.4691225508848826} | train loss {'Reaction outcome loss': 0.2821398014438066, 'Total loss': 0.2821398014438066}
2022-12-31 14:17:13,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:13,054 INFO:     Epoch: 42
2022-12-31 14:17:14,685 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4402532617251078, 'Total loss': 0.4402532617251078} | train loss {'Reaction outcome loss': 0.28079176942955714, 'Total loss': 0.28079176942955714}
2022-12-31 14:17:14,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:14,685 INFO:     Epoch: 43
2022-12-31 14:17:16,330 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4462059756120046, 'Total loss': 0.4462059756120046} | train loss {'Reaction outcome loss': 0.2770088512168034, 'Total loss': 0.2770088512168034}
2022-12-31 14:17:16,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:16,330 INFO:     Epoch: 44
2022-12-31 14:17:17,941 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40062606434027354, 'Total loss': 0.40062606434027354} | train loss {'Reaction outcome loss': 0.27508550191076225, 'Total loss': 0.27508550191076225}
2022-12-31 14:17:17,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:17,942 INFO:     Epoch: 45
2022-12-31 14:17:19,546 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.444814329346021, 'Total loss': 0.444814329346021} | train loss {'Reaction outcome loss': 0.27163768055367987, 'Total loss': 0.27163768055367987}
2022-12-31 14:17:19,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:19,547 INFO:     Epoch: 46
2022-12-31 14:17:21,164 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4534184048573176, 'Total loss': 0.4534184048573176} | train loss {'Reaction outcome loss': 0.2727019262066387, 'Total loss': 0.2727019262066387}
2022-12-31 14:17:21,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:21,164 INFO:     Epoch: 47
2022-12-31 14:17:22,784 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4494372030099233, 'Total loss': 0.4494372030099233} | train loss {'Reaction outcome loss': 0.2674273912414962, 'Total loss': 0.2674273912414962}
2022-12-31 14:17:22,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:22,785 INFO:     Epoch: 48
2022-12-31 14:17:24,405 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4245093206564585, 'Total loss': 0.4245093206564585} | train loss {'Reaction outcome loss': 0.266367674384952, 'Total loss': 0.266367674384952}
2022-12-31 14:17:24,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:24,405 INFO:     Epoch: 49
2022-12-31 14:17:26,019 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4187138001124064, 'Total loss': 0.4187138001124064} | train loss {'Reaction outcome loss': 0.2641432069860641, 'Total loss': 0.2641432069860641}
2022-12-31 14:17:26,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:26,020 INFO:     Epoch: 50
2022-12-31 14:17:27,651 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4445637901624044, 'Total loss': 0.4445637901624044} | train loss {'Reaction outcome loss': 0.26569435737408453, 'Total loss': 0.26569435737408453}
2022-12-31 14:17:27,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:27,652 INFO:     Epoch: 51
2022-12-31 14:17:29,268 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4354660113652547, 'Total loss': 0.4354660113652547} | train loss {'Reaction outcome loss': 0.25942804820378335, 'Total loss': 0.25942804820378335}
2022-12-31 14:17:29,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:29,269 INFO:     Epoch: 52
2022-12-31 14:17:30,909 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4067568230132262, 'Total loss': 0.4067568230132262} | train loss {'Reaction outcome loss': 0.25312586977324764, 'Total loss': 0.25312586977324764}
2022-12-31 14:17:30,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:30,911 INFO:     Epoch: 53
2022-12-31 14:17:32,528 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4161962370077769, 'Total loss': 0.4161962370077769} | train loss {'Reaction outcome loss': 0.2607633233581424, 'Total loss': 0.2607633233581424}
2022-12-31 14:17:32,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:32,528 INFO:     Epoch: 54
2022-12-31 14:17:34,150 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45324941525856655, 'Total loss': 0.45324941525856655} | train loss {'Reaction outcome loss': 0.25373470625883837, 'Total loss': 0.25373470625883837}
2022-12-31 14:17:34,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:34,151 INFO:     Epoch: 55
2022-12-31 14:17:35,768 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40178924798965454, 'Total loss': 0.40178924798965454} | train loss {'Reaction outcome loss': 0.2490144762402192, 'Total loss': 0.2490144762402192}
2022-12-31 14:17:35,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:35,768 INFO:     Epoch: 56
2022-12-31 14:17:37,377 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41657025218009947, 'Total loss': 0.41657025218009947} | train loss {'Reaction outcome loss': 0.2536206274202584, 'Total loss': 0.2536206274202584}
2022-12-31 14:17:37,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:37,377 INFO:     Epoch: 57
2022-12-31 14:17:38,991 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42408347527186074, 'Total loss': 0.42408347527186074} | train loss {'Reaction outcome loss': 0.24910134177937404, 'Total loss': 0.24910134177937404}
2022-12-31 14:17:38,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:38,991 INFO:     Epoch: 58
2022-12-31 14:17:40,607 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4584623863299688, 'Total loss': 0.4584623863299688} | train loss {'Reaction outcome loss': 0.24038878158541793, 'Total loss': 0.24038878158541793}
2022-12-31 14:17:40,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:40,607 INFO:     Epoch: 59
2022-12-31 14:17:42,227 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4386461059252421, 'Total loss': 0.4386461059252421} | train loss {'Reaction outcome loss': 0.2501253560992355, 'Total loss': 0.2501253560992355}
2022-12-31 14:17:42,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:42,227 INFO:     Epoch: 60
2022-12-31 14:17:43,827 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45549011081457136, 'Total loss': 0.45549011081457136} | train loss {'Reaction outcome loss': 0.24587255464833135, 'Total loss': 0.24587255464833135}
2022-12-31 14:17:43,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:43,827 INFO:     Epoch: 61
2022-12-31 14:17:45,433 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4131357312202454, 'Total loss': 0.4131357312202454} | train loss {'Reaction outcome loss': 0.2452646709494427, 'Total loss': 0.2452646709494427}
2022-12-31 14:17:45,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:45,433 INFO:     Epoch: 62
2022-12-31 14:17:47,049 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4158305247624715, 'Total loss': 0.4158305247624715} | train loss {'Reaction outcome loss': 0.2397746461366273, 'Total loss': 0.2397746461366273}
2022-12-31 14:17:47,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:47,050 INFO:     Epoch: 63
2022-12-31 14:17:48,698 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.441517798602581, 'Total loss': 0.441517798602581} | train loss {'Reaction outcome loss': 0.23659617656888945, 'Total loss': 0.23659617656888945}
2022-12-31 14:17:48,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:48,699 INFO:     Epoch: 64
2022-12-31 14:17:50,344 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45948494374752047, 'Total loss': 0.45948494374752047} | train loss {'Reaction outcome loss': 0.23531134012373775, 'Total loss': 0.23531134012373775}
2022-12-31 14:17:50,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:50,345 INFO:     Epoch: 65
2022-12-31 14:17:51,991 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44710674285888674, 'Total loss': 0.44710674285888674} | train loss {'Reaction outcome loss': 0.23444186566592554, 'Total loss': 0.23444186566592554}
2022-12-31 14:17:51,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:51,991 INFO:     Epoch: 66
2022-12-31 14:17:53,591 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3927658716837565, 'Total loss': 0.3927658716837565} | train loss {'Reaction outcome loss': 0.2452554355647805, 'Total loss': 0.2452554355647805}
2022-12-31 14:17:53,591 INFO:     Found new best model at epoch 66
2022-12-31 14:17:53,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:53,592 INFO:     Epoch: 67
2022-12-31 14:17:55,199 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4039891267816226, 'Total loss': 0.4039891267816226} | train loss {'Reaction outcome loss': 0.2332604483092735, 'Total loss': 0.2332604483092735}
2022-12-31 14:17:55,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:55,199 INFO:     Epoch: 68
2022-12-31 14:17:56,844 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4351506436864535, 'Total loss': 0.4351506436864535} | train loss {'Reaction outcome loss': 0.23147274932356732, 'Total loss': 0.23147274932356732}
2022-12-31 14:17:56,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:56,844 INFO:     Epoch: 69
2022-12-31 14:17:58,458 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42892629901568097, 'Total loss': 0.42892629901568097} | train loss {'Reaction outcome loss': 0.23011514367636576, 'Total loss': 0.23011514367636576}
2022-12-31 14:17:58,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:17:58,458 INFO:     Epoch: 70
2022-12-31 14:18:00,071 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43582780013481776, 'Total loss': 0.43582780013481776} | train loss {'Reaction outcome loss': 0.22728717505313215, 'Total loss': 0.22728717505313215}
2022-12-31 14:18:00,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:00,072 INFO:     Epoch: 71
2022-12-31 14:18:01,675 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4064105267326037, 'Total loss': 0.4064105267326037} | train loss {'Reaction outcome loss': 0.23298774584993343, 'Total loss': 0.23298774584993343}
2022-12-31 14:18:01,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:01,676 INFO:     Epoch: 72
2022-12-31 14:18:03,277 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4276672929525375, 'Total loss': 0.4276672929525375} | train loss {'Reaction outcome loss': 0.23258385844259702, 'Total loss': 0.23258385844259702}
2022-12-31 14:18:03,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:03,277 INFO:     Epoch: 73
2022-12-31 14:18:04,873 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47193034887313845, 'Total loss': 0.47193034887313845} | train loss {'Reaction outcome loss': 0.2280955784197641, 'Total loss': 0.2280955784197641}
2022-12-31 14:18:04,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:04,873 INFO:     Epoch: 74
2022-12-31 14:18:06,486 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46664587457974754, 'Total loss': 0.46664587457974754} | train loss {'Reaction outcome loss': 0.22485704628569125, 'Total loss': 0.22485704628569125}
2022-12-31 14:18:06,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:06,486 INFO:     Epoch: 75
2022-12-31 14:18:08,099 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4324098606904348, 'Total loss': 0.4324098606904348} | train loss {'Reaction outcome loss': 0.2241547521042372, 'Total loss': 0.2241547521042372}
2022-12-31 14:18:08,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:08,100 INFO:     Epoch: 76
2022-12-31 14:18:09,712 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40957455535729725, 'Total loss': 0.40957455535729725} | train loss {'Reaction outcome loss': 0.22056575491351987, 'Total loss': 0.22056575491351987}
2022-12-31 14:18:09,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:09,712 INFO:     Epoch: 77
2022-12-31 14:18:11,307 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40932914465665815, 'Total loss': 0.40932914465665815} | train loss {'Reaction outcome loss': 0.22253710947365968, 'Total loss': 0.22253710947365968}
2022-12-31 14:18:11,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:11,307 INFO:     Epoch: 78
2022-12-31 14:18:12,914 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44386481841405234, 'Total loss': 0.44386481841405234} | train loss {'Reaction outcome loss': 0.22733099867559511, 'Total loss': 0.22733099867559511}
2022-12-31 14:18:12,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:12,915 INFO:     Epoch: 79
2022-12-31 14:18:14,541 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41653591791788735, 'Total loss': 0.41653591791788735} | train loss {'Reaction outcome loss': 0.2228001056756784, 'Total loss': 0.2228001056756784}
2022-12-31 14:18:14,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:14,542 INFO:     Epoch: 80
2022-12-31 14:18:16,159 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43958771526813506, 'Total loss': 0.43958771526813506} | train loss {'Reaction outcome loss': 0.21295297852572767, 'Total loss': 0.21295297852572767}
2022-12-31 14:18:16,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:16,160 INFO:     Epoch: 81
2022-12-31 14:18:17,777 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4490286332865556, 'Total loss': 0.4490286332865556} | train loss {'Reaction outcome loss': 0.21654932522332626, 'Total loss': 0.21654932522332626}
2022-12-31 14:18:17,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:17,777 INFO:     Epoch: 82
2022-12-31 14:18:19,392 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4498802254597346, 'Total loss': 0.4498802254597346} | train loss {'Reaction outcome loss': 0.21558393162106995, 'Total loss': 0.21558393162106995}
2022-12-31 14:18:19,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:19,392 INFO:     Epoch: 83
2022-12-31 14:18:21,019 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44333910048007963, 'Total loss': 0.44333910048007963} | train loss {'Reaction outcome loss': 0.22082393217011478, 'Total loss': 0.22082393217011478}
2022-12-31 14:18:21,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:21,020 INFO:     Epoch: 84
2022-12-31 14:18:22,638 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.438668151696523, 'Total loss': 0.438668151696523} | train loss {'Reaction outcome loss': 0.21721277966261557, 'Total loss': 0.21721277966261557}
2022-12-31 14:18:22,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:22,638 INFO:     Epoch: 85
2022-12-31 14:18:24,283 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4439449727535248, 'Total loss': 0.4439449727535248} | train loss {'Reaction outcome loss': 0.2186659634153658, 'Total loss': 0.2186659634153658}
2022-12-31 14:18:24,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:24,283 INFO:     Epoch: 86
2022-12-31 14:18:25,906 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45068053404490155, 'Total loss': 0.45068053404490155} | train loss {'Reaction outcome loss': 0.21362748561890976, 'Total loss': 0.21362748561890976}
2022-12-31 14:18:25,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:25,906 INFO:     Epoch: 87
2022-12-31 14:18:27,545 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3994148830572764, 'Total loss': 0.3994148830572764} | train loss {'Reaction outcome loss': 0.20783056843259273, 'Total loss': 0.20783056843259273}
2022-12-31 14:18:27,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:27,546 INFO:     Epoch: 88
2022-12-31 14:18:29,148 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4260242034991582, 'Total loss': 0.4260242034991582} | train loss {'Reaction outcome loss': 0.2124579688601384, 'Total loss': 0.2124579688601384}
2022-12-31 14:18:29,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:29,148 INFO:     Epoch: 89
2022-12-31 14:18:30,781 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4437213659286499, 'Total loss': 0.4437213659286499} | train loss {'Reaction outcome loss': 0.21462099349953315, 'Total loss': 0.21462099349953315}
2022-12-31 14:18:30,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:30,781 INFO:     Epoch: 90
2022-12-31 14:18:32,425 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4765982290108999, 'Total loss': 0.4765982290108999} | train loss {'Reaction outcome loss': 0.20912495608834905, 'Total loss': 0.20912495608834905}
2022-12-31 14:18:32,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:32,427 INFO:     Epoch: 91
2022-12-31 14:18:34,072 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47418513894081116, 'Total loss': 0.47418513894081116} | train loss {'Reaction outcome loss': 0.21242965049100265, 'Total loss': 0.21242965049100265}
2022-12-31 14:18:34,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:34,072 INFO:     Epoch: 92
2022-12-31 14:18:35,740 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46967610518137615, 'Total loss': 0.46967610518137615} | train loss {'Reaction outcome loss': 0.20586109248121076, 'Total loss': 0.20586109248121076}
2022-12-31 14:18:35,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:35,741 INFO:     Epoch: 93
2022-12-31 14:18:37,404 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4389034271240234, 'Total loss': 0.4389034271240234} | train loss {'Reaction outcome loss': 0.20566943063928547, 'Total loss': 0.20566943063928547}
2022-12-31 14:18:37,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:37,404 INFO:     Epoch: 94
2022-12-31 14:18:39,049 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3940777376294136, 'Total loss': 0.3940777376294136} | train loss {'Reaction outcome loss': 0.20885423479420184, 'Total loss': 0.20885423479420184}
2022-12-31 14:18:39,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:39,050 INFO:     Epoch: 95
2022-12-31 14:18:40,677 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45328179995218915, 'Total loss': 0.45328179995218915} | train loss {'Reaction outcome loss': 0.20490931032312906, 'Total loss': 0.20490931032312906}
2022-12-31 14:18:40,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:40,678 INFO:     Epoch: 96
2022-12-31 14:18:42,339 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4451082090536753, 'Total loss': 0.4451082090536753} | train loss {'Reaction outcome loss': 0.20936426172362446, 'Total loss': 0.20936426172362446}
2022-12-31 14:18:42,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:42,339 INFO:     Epoch: 97
2022-12-31 14:18:43,969 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4393611684441566, 'Total loss': 0.4393611684441566} | train loss {'Reaction outcome loss': 0.20554916286968797, 'Total loss': 0.20554916286968797}
2022-12-31 14:18:43,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:43,969 INFO:     Epoch: 98
2022-12-31 14:18:45,627 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4102086385091146, 'Total loss': 0.4102086385091146} | train loss {'Reaction outcome loss': 0.20006253199134064, 'Total loss': 0.20006253199134064}
2022-12-31 14:18:45,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:45,628 INFO:     Epoch: 99
2022-12-31 14:18:47,248 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4660637507836024, 'Total loss': 0.4660637507836024} | train loss {'Reaction outcome loss': 0.21179154090287453, 'Total loss': 0.21179154090287453}
2022-12-31 14:18:47,248 INFO:     Best model found after epoch 67 of 100.
2022-12-31 14:18:47,248 INFO:   Done with stage: TRAINING
2022-12-31 14:18:47,248 INFO:   Starting stage: EVALUATION
2022-12-31 14:18:47,371 INFO:   Done with stage: EVALUATION
2022-12-31 14:18:47,371 INFO:   Leaving out SEQ value Fold_7
2022-12-31 14:18:47,384 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 14:18:47,384 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:18:48,037 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:18:48,038 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:18:48,105 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:18:48,106 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:18:48,106 INFO:     No hyperparam tuning for this model
2022-12-31 14:18:48,106 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:18:48,106 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:18:48,106 INFO:     None feature selector for col prot
2022-12-31 14:18:48,107 INFO:     None feature selector for col prot
2022-12-31 14:18:48,107 INFO:     None feature selector for col prot
2022-12-31 14:18:48,107 INFO:     None feature selector for col chem
2022-12-31 14:18:48,107 INFO:     None feature selector for col chem
2022-12-31 14:18:48,107 INFO:     None feature selector for col chem
2022-12-31 14:18:48,107 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:18:48,107 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:18:48,109 INFO:     Number of params in model 223921
2022-12-31 14:18:48,113 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:18:48,113 INFO:   Starting stage: TRAINING
2022-12-31 14:18:48,156 INFO:     Val loss before train {'Reaction outcome loss': 0.9978372514247894, 'Total loss': 0.9978372514247894}
2022-12-31 14:18:48,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:48,157 INFO:     Epoch: 0
2022-12-31 14:18:49,767 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6892468790213268, 'Total loss': 0.6892468790213268} | train loss {'Reaction outcome loss': 0.8159871971592361, 'Total loss': 0.8159871971592361}
2022-12-31 14:18:49,767 INFO:     Found new best model at epoch 0
2022-12-31 14:18:49,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:49,768 INFO:     Epoch: 1
2022-12-31 14:18:51,412 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5345132788022359, 'Total loss': 0.5345132788022359} | train loss {'Reaction outcome loss': 0.5996487553406885, 'Total loss': 0.5996487553406885}
2022-12-31 14:18:51,413 INFO:     Found new best model at epoch 1
2022-12-31 14:18:51,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:51,414 INFO:     Epoch: 2
2022-12-31 14:18:53,062 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.522475395600001, 'Total loss': 0.522475395600001} | train loss {'Reaction outcome loss': 0.5325510776264296, 'Total loss': 0.5325510776264296}
2022-12-31 14:18:53,062 INFO:     Found new best model at epoch 2
2022-12-31 14:18:53,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:53,063 INFO:     Epoch: 3
2022-12-31 14:18:54,713 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4626885692278544, 'Total loss': 0.4626885692278544} | train loss {'Reaction outcome loss': 0.5030656791953505, 'Total loss': 0.5030656791953505}
2022-12-31 14:18:54,714 INFO:     Found new best model at epoch 3
2022-12-31 14:18:54,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:54,715 INFO:     Epoch: 4
2022-12-31 14:18:56,318 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47823862234751385, 'Total loss': 0.47823862234751385} | train loss {'Reaction outcome loss': 0.4887619088741316, 'Total loss': 0.4887619088741316}
2022-12-31 14:18:56,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:56,318 INFO:     Epoch: 5
2022-12-31 14:18:57,960 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4259751329819361, 'Total loss': 0.4259751329819361} | train loss {'Reaction outcome loss': 0.47765545305852697, 'Total loss': 0.47765545305852697}
2022-12-31 14:18:57,960 INFO:     Found new best model at epoch 5
2022-12-31 14:18:57,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:57,961 INFO:     Epoch: 6
2022-12-31 14:18:59,566 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4575068732102712, 'Total loss': 0.4575068732102712} | train loss {'Reaction outcome loss': 0.47110822112501965, 'Total loss': 0.47110822112501965}
2022-12-31 14:18:59,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:18:59,566 INFO:     Epoch: 7
2022-12-31 14:19:01,184 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4483993927637736, 'Total loss': 0.4483993927637736} | train loss {'Reaction outcome loss': 0.4601062914167625, 'Total loss': 0.4601062914167625}
2022-12-31 14:19:01,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:01,185 INFO:     Epoch: 8
2022-12-31 14:19:02,801 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4703656256198883, 'Total loss': 0.4703656256198883} | train loss {'Reaction outcome loss': 0.4772705081040445, 'Total loss': 0.4772705081040445}
2022-12-31 14:19:02,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:02,802 INFO:     Epoch: 9
2022-12-31 14:19:04,420 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42063960010806717, 'Total loss': 0.42063960010806717} | train loss {'Reaction outcome loss': 0.4780583039088094, 'Total loss': 0.4780583039088094}
2022-12-31 14:19:04,420 INFO:     Found new best model at epoch 9
2022-12-31 14:19:04,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:04,421 INFO:     Epoch: 10
2022-12-31 14:19:06,031 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45463048815727236, 'Total loss': 0.45463048815727236} | train loss {'Reaction outcome loss': 0.43756017545103165, 'Total loss': 0.43756017545103165}
2022-12-31 14:19:06,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:06,031 INFO:     Epoch: 11
2022-12-31 14:19:07,657 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42380640308062234, 'Total loss': 0.42380640308062234} | train loss {'Reaction outcome loss': 0.43211659860236873, 'Total loss': 0.43211659860236873}
2022-12-31 14:19:07,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:07,657 INFO:     Epoch: 12
2022-12-31 14:19:09,268 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4281678895155589, 'Total loss': 0.4281678895155589} | train loss {'Reaction outcome loss': 0.4243051799991087, 'Total loss': 0.4243051799991087}
2022-12-31 14:19:09,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:09,269 INFO:     Epoch: 13
2022-12-31 14:19:10,889 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42404392262299856, 'Total loss': 0.42404392262299856} | train loss {'Reaction outcome loss': 0.4206315165375481, 'Total loss': 0.4206315165375481}
2022-12-31 14:19:10,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:10,889 INFO:     Epoch: 14
2022-12-31 14:19:12,518 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41065785189469656, 'Total loss': 0.41065785189469656} | train loss {'Reaction outcome loss': 0.4154176885123783, 'Total loss': 0.4154176885123783}
2022-12-31 14:19:12,518 INFO:     Found new best model at epoch 14
2022-12-31 14:19:12,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:12,519 INFO:     Epoch: 15
2022-12-31 14:19:14,120 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4136633574962616, 'Total loss': 0.4136633574962616} | train loss {'Reaction outcome loss': 0.40983350420593406, 'Total loss': 0.40983350420593406}
2022-12-31 14:19:14,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:14,120 INFO:     Epoch: 16
2022-12-31 14:19:15,756 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39928718358278276, 'Total loss': 0.39928718358278276} | train loss {'Reaction outcome loss': 0.41048925291692867, 'Total loss': 0.41048925291692867}
2022-12-31 14:19:15,756 INFO:     Found new best model at epoch 16
2022-12-31 14:19:15,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:15,757 INFO:     Epoch: 17
2022-12-31 14:19:17,358 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39387767215569813, 'Total loss': 0.39387767215569813} | train loss {'Reaction outcome loss': 0.4184714776828237, 'Total loss': 0.4184714776828237}
2022-12-31 14:19:17,358 INFO:     Found new best model at epoch 17
2022-12-31 14:19:17,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:17,359 INFO:     Epoch: 18
2022-12-31 14:19:18,968 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39613458116849265, 'Total loss': 0.39613458116849265} | train loss {'Reaction outcome loss': 0.395742813373268, 'Total loss': 0.395742813373268}
2022-12-31 14:19:18,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:18,968 INFO:     Epoch: 19
2022-12-31 14:19:20,618 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4248092254002889, 'Total loss': 0.4248092254002889} | train loss {'Reaction outcome loss': 0.38522283764787985, 'Total loss': 0.38522283764787985}
2022-12-31 14:19:20,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:20,619 INFO:     Epoch: 20
2022-12-31 14:19:22,265 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39316263000170387, 'Total loss': 0.39316263000170387} | train loss {'Reaction outcome loss': 0.3828729313776585, 'Total loss': 0.3828729313776585}
2022-12-31 14:19:22,266 INFO:     Found new best model at epoch 20
2022-12-31 14:19:22,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:22,267 INFO:     Epoch: 21
2022-12-31 14:19:23,901 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40607242782910663, 'Total loss': 0.40607242782910663} | train loss {'Reaction outcome loss': 0.3810999045499425, 'Total loss': 0.3810999045499425}
2022-12-31 14:19:23,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:23,902 INFO:     Epoch: 22
2022-12-31 14:19:25,527 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44107411603132884, 'Total loss': 0.44107411603132884} | train loss {'Reaction outcome loss': 0.3765082686566635, 'Total loss': 0.3765082686566635}
2022-12-31 14:19:25,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:25,527 INFO:     Epoch: 23
2022-12-31 14:19:27,194 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.429389422138532, 'Total loss': 0.429389422138532} | train loss {'Reaction outcome loss': 0.366544457668143, 'Total loss': 0.366544457668143}
2022-12-31 14:19:27,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:27,194 INFO:     Epoch: 24
2022-12-31 14:19:28,839 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42983633081118267, 'Total loss': 0.42983633081118267} | train loss {'Reaction outcome loss': 0.36216262946128036, 'Total loss': 0.36216262946128036}
2022-12-31 14:19:28,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:28,840 INFO:     Epoch: 25
2022-12-31 14:19:30,479 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40194040139516196, 'Total loss': 0.40194040139516196} | train loss {'Reaction outcome loss': 0.35864498479919427, 'Total loss': 0.35864498479919427}
2022-12-31 14:19:30,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:30,479 INFO:     Epoch: 26
2022-12-31 14:19:32,125 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.36813259025414785, 'Total loss': 0.36813259025414785} | train loss {'Reaction outcome loss': 0.35369620248591394, 'Total loss': 0.35369620248591394}
2022-12-31 14:19:32,125 INFO:     Found new best model at epoch 26
2022-12-31 14:19:32,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:32,126 INFO:     Epoch: 27
2022-12-31 14:19:33,742 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4189785977204641, 'Total loss': 0.4189785977204641} | train loss {'Reaction outcome loss': 0.3501256998034491, 'Total loss': 0.3501256998034491}
2022-12-31 14:19:33,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:33,743 INFO:     Epoch: 28
2022-12-31 14:19:35,344 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3887823273738225, 'Total loss': 0.3887823273738225} | train loss {'Reaction outcome loss': 0.3429788830386394, 'Total loss': 0.3429788830386394}
2022-12-31 14:19:35,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:35,344 INFO:     Epoch: 29
2022-12-31 14:19:36,990 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38824368715286256, 'Total loss': 0.38824368715286256} | train loss {'Reaction outcome loss': 0.33879168673852755, 'Total loss': 0.33879168673852755}
2022-12-31 14:19:36,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:36,990 INFO:     Epoch: 30
2022-12-31 14:19:38,620 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39014193216959636, 'Total loss': 0.39014193216959636} | train loss {'Reaction outcome loss': 0.3325493618828224, 'Total loss': 0.3325493618828224}
2022-12-31 14:19:38,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:38,620 INFO:     Epoch: 31
2022-12-31 14:19:40,231 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40112816194693246, 'Total loss': 0.40112816194693246} | train loss {'Reaction outcome loss': 0.3311430897590691, 'Total loss': 0.3311430897590691}
2022-12-31 14:19:40,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:40,232 INFO:     Epoch: 32
2022-12-31 14:19:41,835 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3958433856566747, 'Total loss': 0.3958433856566747} | train loss {'Reaction outcome loss': 0.3364706181999519, 'Total loss': 0.3364706181999519}
2022-12-31 14:19:41,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:41,835 INFO:     Epoch: 33
2022-12-31 14:19:43,442 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4052908500035604, 'Total loss': 0.4052908500035604} | train loss {'Reaction outcome loss': 0.32304800534114725, 'Total loss': 0.32304800534114725}
2022-12-31 14:19:43,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:43,442 INFO:     Epoch: 34
2022-12-31 14:19:45,078 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.404728335638841, 'Total loss': 0.404728335638841} | train loss {'Reaction outcome loss': 0.31824818856430415, 'Total loss': 0.31824818856430415}
2022-12-31 14:19:45,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:45,078 INFO:     Epoch: 35
2022-12-31 14:19:46,705 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39689392149448394, 'Total loss': 0.39689392149448394} | train loss {'Reaction outcome loss': 0.3164875774063926, 'Total loss': 0.3164875774063926}
2022-12-31 14:19:46,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:46,706 INFO:     Epoch: 36
2022-12-31 14:19:48,314 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4229754994312922, 'Total loss': 0.4229754994312922} | train loss {'Reaction outcome loss': 0.31354391276566446, 'Total loss': 0.31354391276566446}
2022-12-31 14:19:48,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:48,314 INFO:     Epoch: 37
2022-12-31 14:19:49,944 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4186074763536453, 'Total loss': 0.4186074763536453} | train loss {'Reaction outcome loss': 0.31815804562607364, 'Total loss': 0.31815804562607364}
2022-12-31 14:19:49,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:49,944 INFO:     Epoch: 38
2022-12-31 14:19:51,560 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4123734017213186, 'Total loss': 0.4123734017213186} | train loss {'Reaction outcome loss': 0.3009330157217556, 'Total loss': 0.3009330157217556}
2022-12-31 14:19:51,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:51,560 INFO:     Epoch: 39
2022-12-31 14:19:53,183 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38571075002352395, 'Total loss': 0.38571075002352395} | train loss {'Reaction outcome loss': 0.3157586458314588, 'Total loss': 0.3157586458314588}
2022-12-31 14:19:53,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:53,184 INFO:     Epoch: 40
2022-12-31 14:19:54,826 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4105045398076375, 'Total loss': 0.4105045398076375} | train loss {'Reaction outcome loss': 0.29800325352698565, 'Total loss': 0.29800325352698565}
2022-12-31 14:19:54,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:54,826 INFO:     Epoch: 41
2022-12-31 14:19:56,459 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4030753900607427, 'Total loss': 0.4030753900607427} | train loss {'Reaction outcome loss': 0.3025935683466926, 'Total loss': 0.3025935683466926}
2022-12-31 14:19:56,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:56,459 INFO:     Epoch: 42
2022-12-31 14:19:58,080 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.37295315861701966, 'Total loss': 0.37295315861701966} | train loss {'Reaction outcome loss': 0.3229629512343967, 'Total loss': 0.3229629512343967}
2022-12-31 14:19:58,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:58,080 INFO:     Epoch: 43
2022-12-31 14:19:59,678 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4476881186167399, 'Total loss': 0.4476881186167399} | train loss {'Reaction outcome loss': 0.29836209540835756, 'Total loss': 0.29836209540835756}
2022-12-31 14:19:59,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:19:59,678 INFO:     Epoch: 44
2022-12-31 14:20:01,318 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40495839565992353, 'Total loss': 0.40495839565992353} | train loss {'Reaction outcome loss': 0.36373137693474256, 'Total loss': 0.36373137693474256}
2022-12-31 14:20:01,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:01,318 INFO:     Epoch: 45
2022-12-31 14:20:02,935 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38023815403381983, 'Total loss': 0.38023815403381983} | train loss {'Reaction outcome loss': 0.29466486542356585, 'Total loss': 0.29466486542356585}
2022-12-31 14:20:02,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:02,935 INFO:     Epoch: 46
2022-12-31 14:20:04,564 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39293622275193535, 'Total loss': 0.39293622275193535} | train loss {'Reaction outcome loss': 0.2996327543523217, 'Total loss': 0.2996327543523217}
2022-12-31 14:20:04,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:04,565 INFO:     Epoch: 47
2022-12-31 14:20:06,192 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40277786950270333, 'Total loss': 0.40277786950270333} | train loss {'Reaction outcome loss': 0.29255258776011295, 'Total loss': 0.29255258776011295}
2022-12-31 14:20:06,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:06,192 INFO:     Epoch: 48
2022-12-31 14:20:07,810 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.394908074537913, 'Total loss': 0.394908074537913} | train loss {'Reaction outcome loss': 0.274789994933467, 'Total loss': 0.274789994933467}
2022-12-31 14:20:07,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:07,810 INFO:     Epoch: 49
2022-12-31 14:20:09,408 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37746992856264117, 'Total loss': 0.37746992856264117} | train loss {'Reaction outcome loss': 0.27501687345601816, 'Total loss': 0.27501687345601816}
2022-12-31 14:20:09,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:09,408 INFO:     Epoch: 50
2022-12-31 14:20:11,012 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4413691331942876, 'Total loss': 0.4413691331942876} | train loss {'Reaction outcome loss': 0.2718005838763455, 'Total loss': 0.2718005838763455}
2022-12-31 14:20:11,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:11,013 INFO:     Epoch: 51
2022-12-31 14:20:12,629 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3971353232860565, 'Total loss': 0.3971353232860565} | train loss {'Reaction outcome loss': 0.3281705463979987, 'Total loss': 0.3281705463979987}
2022-12-31 14:20:12,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:12,630 INFO:     Epoch: 52
2022-12-31 14:20:14,268 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.400111989180247, 'Total loss': 0.400111989180247} | train loss {'Reaction outcome loss': 0.2797963090132976, 'Total loss': 0.2797963090132976}
2022-12-31 14:20:14,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:14,269 INFO:     Epoch: 53
2022-12-31 14:20:15,894 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3826905349890391, 'Total loss': 0.3826905349890391} | train loss {'Reaction outcome loss': 0.267844401097492, 'Total loss': 0.267844401097492}
2022-12-31 14:20:15,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:15,894 INFO:     Epoch: 54
2022-12-31 14:20:17,525 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4233856697877248, 'Total loss': 0.4233856697877248} | train loss {'Reaction outcome loss': 0.26589579086183296, 'Total loss': 0.26589579086183296}
2022-12-31 14:20:17,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:17,525 INFO:     Epoch: 55
2022-12-31 14:20:19,135 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3870414674282074, 'Total loss': 0.3870414674282074} | train loss {'Reaction outcome loss': 0.27064859960228205, 'Total loss': 0.27064859960228205}
2022-12-31 14:20:19,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:19,135 INFO:     Epoch: 56
2022-12-31 14:20:20,735 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42890599767367044, 'Total loss': 0.42890599767367044} | train loss {'Reaction outcome loss': 0.26992690671856207, 'Total loss': 0.26992690671856207}
2022-12-31 14:20:20,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:20,735 INFO:     Epoch: 57
2022-12-31 14:20:22,347 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.419151837627093, 'Total loss': 0.419151837627093} | train loss {'Reaction outcome loss': 0.2693655157638828, 'Total loss': 0.2693655157638828}
2022-12-31 14:20:22,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:22,347 INFO:     Epoch: 58
2022-12-31 14:20:23,971 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4252410799264908, 'Total loss': 0.4252410799264908} | train loss {'Reaction outcome loss': 0.2614789141065347, 'Total loss': 0.2614789141065347}
2022-12-31 14:20:23,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:23,972 INFO:     Epoch: 59
2022-12-31 14:20:25,617 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40750278159976006, 'Total loss': 0.40750278159976006} | train loss {'Reaction outcome loss': 0.2542873079820192, 'Total loss': 0.2542873079820192}
2022-12-31 14:20:25,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:25,618 INFO:     Epoch: 60
2022-12-31 14:20:27,236 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42738662362098695, 'Total loss': 0.42738662362098695} | train loss {'Reaction outcome loss': 0.25448245516782414, 'Total loss': 0.25448245516782414}
2022-12-31 14:20:27,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:27,236 INFO:     Epoch: 61
2022-12-31 14:20:28,873 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4369192530711492, 'Total loss': 0.4369192530711492} | train loss {'Reaction outcome loss': 0.25732740940715093, 'Total loss': 0.25732740940715093}
2022-12-31 14:20:28,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:28,873 INFO:     Epoch: 62
2022-12-31 14:20:30,510 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4180631438891093, 'Total loss': 0.4180631438891093} | train loss {'Reaction outcome loss': 0.2667175077738753, 'Total loss': 0.2667175077738753}
2022-12-31 14:20:30,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:30,511 INFO:     Epoch: 63
2022-12-31 14:20:32,156 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4115987837314606, 'Total loss': 0.4115987837314606} | train loss {'Reaction outcome loss': 0.30796401002916735, 'Total loss': 0.30796401002916735}
2022-12-31 14:20:32,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:32,156 INFO:     Epoch: 64
2022-12-31 14:20:33,798 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4370491325855255, 'Total loss': 0.4370491325855255} | train loss {'Reaction outcome loss': 0.2725705996027513, 'Total loss': 0.2725705996027513}
2022-12-31 14:20:33,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:33,798 INFO:     Epoch: 65
2022-12-31 14:20:35,442 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4102606952190399, 'Total loss': 0.4102606952190399} | train loss {'Reaction outcome loss': 0.2579613448246876, 'Total loss': 0.2579613448246876}
2022-12-31 14:20:35,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:35,443 INFO:     Epoch: 66
2022-12-31 14:20:37,059 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4481295416752497, 'Total loss': 0.4481295416752497} | train loss {'Reaction outcome loss': 0.25403383037115895, 'Total loss': 0.25403383037115895}
2022-12-31 14:20:37,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:37,059 INFO:     Epoch: 67
2022-12-31 14:20:38,685 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41358938614527385, 'Total loss': 0.41358938614527385} | train loss {'Reaction outcome loss': 0.24822180303812458, 'Total loss': 0.24822180303812458}
2022-12-31 14:20:38,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:38,685 INFO:     Epoch: 68
2022-12-31 14:20:40,336 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42623582084973655, 'Total loss': 0.42623582084973655} | train loss {'Reaction outcome loss': 0.24684310160523307, 'Total loss': 0.24684310160523307}
2022-12-31 14:20:40,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:40,336 INFO:     Epoch: 69
2022-12-31 14:20:41,980 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4022331674893697, 'Total loss': 0.4022331674893697} | train loss {'Reaction outcome loss': 0.2446702355991347, 'Total loss': 0.2446702355991347}
2022-12-31 14:20:41,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:41,981 INFO:     Epoch: 70
2022-12-31 14:20:43,630 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3890025243163109, 'Total loss': 0.3890025243163109} | train loss {'Reaction outcome loss': 0.24462367447794994, 'Total loss': 0.24462367447794994}
2022-12-31 14:20:43,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:43,630 INFO:     Epoch: 71
2022-12-31 14:20:45,265 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43644753893216454, 'Total loss': 0.43644753893216454} | train loss {'Reaction outcome loss': 0.24153659819208387, 'Total loss': 0.24153659819208387}
2022-12-31 14:20:45,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:45,265 INFO:     Epoch: 72
2022-12-31 14:20:46,889 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4056125650803248, 'Total loss': 0.4056125650803248} | train loss {'Reaction outcome loss': 0.2385763498757075, 'Total loss': 0.2385763498757075}
2022-12-31 14:20:46,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:46,889 INFO:     Epoch: 73
2022-12-31 14:20:48,506 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4312054102619489, 'Total loss': 0.4312054102619489} | train loss {'Reaction outcome loss': 0.23661336959238446, 'Total loss': 0.23661336959238446}
2022-12-31 14:20:48,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:48,506 INFO:     Epoch: 74
2022-12-31 14:20:50,139 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4263812308510145, 'Total loss': 0.4263812308510145} | train loss {'Reaction outcome loss': 0.23894754636094676, 'Total loss': 0.23894754636094676}
2022-12-31 14:20:50,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:50,139 INFO:     Epoch: 75
2022-12-31 14:20:51,768 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39653866390387216, 'Total loss': 0.39653866390387216} | train loss {'Reaction outcome loss': 0.2355825919253023, 'Total loss': 0.2355825919253023}
2022-12-31 14:20:51,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:51,768 INFO:     Epoch: 76
2022-12-31 14:20:53,412 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4056161200006803, 'Total loss': 0.4056161200006803} | train loss {'Reaction outcome loss': 0.2317069975551272, 'Total loss': 0.2317069975551272}
2022-12-31 14:20:53,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:53,412 INFO:     Epoch: 77
2022-12-31 14:20:55,023 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42457337975502013, 'Total loss': 0.42457337975502013} | train loss {'Reaction outcome loss': 0.2335529961107512, 'Total loss': 0.2335529961107512}
2022-12-31 14:20:55,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:55,024 INFO:     Epoch: 78
2022-12-31 14:20:56,641 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4360485831896464, 'Total loss': 0.4360485831896464} | train loss {'Reaction outcome loss': 0.2295207164682232, 'Total loss': 0.2295207164682232}
2022-12-31 14:20:56,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:56,642 INFO:     Epoch: 79
2022-12-31 14:20:58,252 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41328297803799313, 'Total loss': 0.41328297803799313} | train loss {'Reaction outcome loss': 0.2300856562846673, 'Total loss': 0.2300856562846673}
2022-12-31 14:20:58,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:58,252 INFO:     Epoch: 80
2022-12-31 14:20:59,861 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4139677499731382, 'Total loss': 0.4139677499731382} | train loss {'Reaction outcome loss': 0.23160282892944373, 'Total loss': 0.23160282892944373}
2022-12-31 14:20:59,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:20:59,861 INFO:     Epoch: 81
2022-12-31 14:21:01,473 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39949642022450765, 'Total loss': 0.39949642022450765} | train loss {'Reaction outcome loss': 0.22112475472596893, 'Total loss': 0.22112475472596893}
2022-12-31 14:21:01,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:01,474 INFO:     Epoch: 82
2022-12-31 14:21:03,088 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3987864414850871, 'Total loss': 0.3987864414850871} | train loss {'Reaction outcome loss': 0.2325361044942469, 'Total loss': 0.2325361044942469}
2022-12-31 14:21:03,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:03,088 INFO:     Epoch: 83
2022-12-31 14:21:04,711 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41439227759838104, 'Total loss': 0.41439227759838104} | train loss {'Reaction outcome loss': 0.2230596282347308, 'Total loss': 0.2230596282347308}
2022-12-31 14:21:04,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:04,711 INFO:     Epoch: 84
2022-12-31 14:21:06,325 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43953243096669514, 'Total loss': 0.43953243096669514} | train loss {'Reaction outcome loss': 0.22491647873792556, 'Total loss': 0.22491647873792556}
2022-12-31 14:21:06,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:06,325 INFO:     Epoch: 85
2022-12-31 14:21:07,961 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4704168995221456, 'Total loss': 0.4704168995221456} | train loss {'Reaction outcome loss': 0.22126375650227798, 'Total loss': 0.22126375650227798}
2022-12-31 14:21:07,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:07,962 INFO:     Epoch: 86
2022-12-31 14:21:09,590 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4267117609580358, 'Total loss': 0.4267117609580358} | train loss {'Reaction outcome loss': 0.23235081243910827, 'Total loss': 0.23235081243910827}
2022-12-31 14:21:09,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:09,590 INFO:     Epoch: 87
2022-12-31 14:21:11,239 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4312852541605631, 'Total loss': 0.4312852541605631} | train loss {'Reaction outcome loss': 0.22819715921186667, 'Total loss': 0.22819715921186667}
2022-12-31 14:21:11,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:11,241 INFO:     Epoch: 88
2022-12-31 14:21:12,862 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4454362442096074, 'Total loss': 0.4454362442096074} | train loss {'Reaction outcome loss': 0.2121949320405121, 'Total loss': 0.2121949320405121}
2022-12-31 14:21:12,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:12,862 INFO:     Epoch: 89
2022-12-31 14:21:14,468 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4480488657951355, 'Total loss': 0.4480488657951355} | train loss {'Reaction outcome loss': 0.22707648647854617, 'Total loss': 0.22707648647854617}
2022-12-31 14:21:14,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:14,468 INFO:     Epoch: 90
2022-12-31 14:21:16,064 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4120573326945305, 'Total loss': 0.4120573326945305} | train loss {'Reaction outcome loss': 0.22273409762757196, 'Total loss': 0.22273409762757196}
2022-12-31 14:21:16,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:16,064 INFO:     Epoch: 91
2022-12-31 14:21:17,679 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44110575517018635, 'Total loss': 0.44110575517018635} | train loss {'Reaction outcome loss': 0.21875541315387018, 'Total loss': 0.21875541315387018}
2022-12-31 14:21:17,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:17,680 INFO:     Epoch: 92
2022-12-31 14:21:19,295 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43549836377302803, 'Total loss': 0.43549836377302803} | train loss {'Reaction outcome loss': 0.22215870590340617, 'Total loss': 0.22215870590340617}
2022-12-31 14:21:19,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:19,296 INFO:     Epoch: 93
2022-12-31 14:21:20,907 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4162412822246552, 'Total loss': 0.4162412822246552} | train loss {'Reaction outcome loss': 0.3555394803862209, 'Total loss': 0.3555394803862209}
2022-12-31 14:21:20,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:20,908 INFO:     Epoch: 94
2022-12-31 14:21:22,506 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43686354358990986, 'Total loss': 0.43686354358990986} | train loss {'Reaction outcome loss': 0.2609285925147191, 'Total loss': 0.2609285925147191}
2022-12-31 14:21:22,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:22,506 INFO:     Epoch: 95
2022-12-31 14:21:24,106 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41409263809521996, 'Total loss': 0.41409263809521996} | train loss {'Reaction outcome loss': 0.23273762953602642, 'Total loss': 0.23273762953602642}
2022-12-31 14:21:24,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:24,106 INFO:     Epoch: 96
2022-12-31 14:21:25,751 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4085686405499776, 'Total loss': 0.4085686405499776} | train loss {'Reaction outcome loss': 0.22043908103639126, 'Total loss': 0.22043908103639126}
2022-12-31 14:21:25,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:25,751 INFO:     Epoch: 97
2022-12-31 14:21:27,392 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4428052683671316, 'Total loss': 0.4428052683671316} | train loss {'Reaction outcome loss': 0.22495338535409773, 'Total loss': 0.22495338535409773}
2022-12-31 14:21:27,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:27,392 INFO:     Epoch: 98
2022-12-31 14:21:29,006 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4300175249576569, 'Total loss': 0.4300175249576569} | train loss {'Reaction outcome loss': 0.21365728901203154, 'Total loss': 0.21365728901203154}
2022-12-31 14:21:29,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:29,006 INFO:     Epoch: 99
2022-12-31 14:21:30,630 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40455106099446614, 'Total loss': 0.40455106099446614} | train loss {'Reaction outcome loss': 0.20971465427029887, 'Total loss': 0.20971465427029887}
2022-12-31 14:21:30,631 INFO:     Best model found after epoch 27 of 100.
2022-12-31 14:21:30,631 INFO:   Done with stage: TRAINING
2022-12-31 14:21:30,631 INFO:   Starting stage: EVALUATION
2022-12-31 14:21:30,758 INFO:   Done with stage: EVALUATION
2022-12-31 14:21:30,759 INFO:   Leaving out SEQ value Fold_8
2022-12-31 14:21:30,771 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 14:21:30,771 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:21:31,434 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:21:31,435 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:21:31,504 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:21:31,504 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:21:31,504 INFO:     No hyperparam tuning for this model
2022-12-31 14:21:31,504 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:21:31,504 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:21:31,505 INFO:     None feature selector for col prot
2022-12-31 14:21:31,505 INFO:     None feature selector for col prot
2022-12-31 14:21:31,505 INFO:     None feature selector for col prot
2022-12-31 14:21:31,505 INFO:     None feature selector for col chem
2022-12-31 14:21:31,506 INFO:     None feature selector for col chem
2022-12-31 14:21:31,506 INFO:     None feature selector for col chem
2022-12-31 14:21:31,506 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:21:31,506 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:21:31,507 INFO:     Number of params in model 223921
2022-12-31 14:21:31,511 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:21:31,511 INFO:   Starting stage: TRAINING
2022-12-31 14:21:31,556 INFO:     Val loss before train {'Reaction outcome loss': 1.0902758638064067, 'Total loss': 1.0902758638064067}
2022-12-31 14:21:31,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:31,556 INFO:     Epoch: 0
2022-12-31 14:21:33,162 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7064385255177815, 'Total loss': 0.7064385255177815} | train loss {'Reaction outcome loss': 0.8079704877917087, 'Total loss': 0.8079704877917087}
2022-12-31 14:21:33,162 INFO:     Found new best model at epoch 0
2022-12-31 14:21:33,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:33,163 INFO:     Epoch: 1
2022-12-31 14:21:34,784 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5738718191782634, 'Total loss': 0.5738718191782634} | train loss {'Reaction outcome loss': 0.5801189978630534, 'Total loss': 0.5801189978630534}
2022-12-31 14:21:34,785 INFO:     Found new best model at epoch 1
2022-12-31 14:21:34,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:34,786 INFO:     Epoch: 2
2022-12-31 14:21:36,411 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5203039824962616, 'Total loss': 0.5203039824962616} | train loss {'Reaction outcome loss': 0.5148647804391513, 'Total loss': 0.5148647804391513}
2022-12-31 14:21:36,411 INFO:     Found new best model at epoch 2
2022-12-31 14:21:36,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:36,412 INFO:     Epoch: 3
2022-12-31 14:21:38,047 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5092788815498352, 'Total loss': 0.5092788815498352} | train loss {'Reaction outcome loss': 0.4884658868992802, 'Total loss': 0.4884658868992802}
2022-12-31 14:21:38,047 INFO:     Found new best model at epoch 3
2022-12-31 14:21:38,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:38,048 INFO:     Epoch: 4
2022-12-31 14:21:39,672 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5073010663191477, 'Total loss': 0.5073010663191477} | train loss {'Reaction outcome loss': 0.47567640901257413, 'Total loss': 0.47567640901257413}
2022-12-31 14:21:39,672 INFO:     Found new best model at epoch 4
2022-12-31 14:21:39,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:39,673 INFO:     Epoch: 5
2022-12-31 14:21:41,321 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5158406913280487, 'Total loss': 0.5158406913280487} | train loss {'Reaction outcome loss': 0.46252737907080876, 'Total loss': 0.46252737907080876}
2022-12-31 14:21:41,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:41,321 INFO:     Epoch: 6
2022-12-31 14:21:42,923 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.501418940226237, 'Total loss': 0.501418940226237} | train loss {'Reaction outcome loss': 0.4573077889502264, 'Total loss': 0.4573077889502264}
2022-12-31 14:21:42,923 INFO:     Found new best model at epoch 6
2022-12-31 14:21:42,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:42,924 INFO:     Epoch: 7
2022-12-31 14:21:44,541 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5014147450526555, 'Total loss': 0.5014147450526555} | train loss {'Reaction outcome loss': 0.44862547586756063, 'Total loss': 0.44862547586756063}
2022-12-31 14:21:44,542 INFO:     Found new best model at epoch 7
2022-12-31 14:21:44,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:44,543 INFO:     Epoch: 8
2022-12-31 14:21:46,157 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49480867783228555, 'Total loss': 0.49480867783228555} | train loss {'Reaction outcome loss': 0.43898260109261056, 'Total loss': 0.43898260109261056}
2022-12-31 14:21:46,158 INFO:     Found new best model at epoch 8
2022-12-31 14:21:46,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:46,159 INFO:     Epoch: 9
2022-12-31 14:21:47,778 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49452217618624367, 'Total loss': 0.49452217618624367} | train loss {'Reaction outcome loss': 0.43328905449877575, 'Total loss': 0.43328905449877575}
2022-12-31 14:21:47,778 INFO:     Found new best model at epoch 9
2022-12-31 14:21:47,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:47,779 INFO:     Epoch: 10
2022-12-31 14:21:49,379 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47764639655749, 'Total loss': 0.47764639655749} | train loss {'Reaction outcome loss': 0.42864980201643726, 'Total loss': 0.42864980201643726}
2022-12-31 14:21:49,379 INFO:     Found new best model at epoch 10
2022-12-31 14:21:49,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:49,380 INFO:     Epoch: 11
2022-12-31 14:21:50,983 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48515523672103883, 'Total loss': 0.48515523672103883} | train loss {'Reaction outcome loss': 0.4229134914031528, 'Total loss': 0.4229134914031528}
2022-12-31 14:21:50,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:50,984 INFO:     Epoch: 12
2022-12-31 14:21:52,600 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48821634948253634, 'Total loss': 0.48821634948253634} | train loss {'Reaction outcome loss': 0.41512844937480314, 'Total loss': 0.41512844937480314}
2022-12-31 14:21:52,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:52,601 INFO:     Epoch: 13
2022-12-31 14:21:54,248 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5168954541285833, 'Total loss': 0.5168954541285833} | train loss {'Reaction outcome loss': 0.4134809363243382, 'Total loss': 0.4134809363243382}
2022-12-31 14:21:54,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:54,249 INFO:     Epoch: 14
2022-12-31 14:21:55,881 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48478723963101705, 'Total loss': 0.48478723963101705} | train loss {'Reaction outcome loss': 0.40531044208616124, 'Total loss': 0.40531044208616124}
2022-12-31 14:21:55,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:55,881 INFO:     Epoch: 15
2022-12-31 14:21:57,486 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49178656538327536, 'Total loss': 0.49178656538327536} | train loss {'Reaction outcome loss': 0.39716643697518306, 'Total loss': 0.39716643697518306}
2022-12-31 14:21:57,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:57,486 INFO:     Epoch: 16
2022-12-31 14:21:59,096 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5080233375231425, 'Total loss': 0.5080233375231425} | train loss {'Reaction outcome loss': 0.3972632489049478, 'Total loss': 0.3972632489049478}
2022-12-31 14:21:59,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:21:59,096 INFO:     Epoch: 17
2022-12-31 14:22:00,724 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48659689525763195, 'Total loss': 0.48659689525763195} | train loss {'Reaction outcome loss': 0.38625131590486866, 'Total loss': 0.38625131590486866}
2022-12-31 14:22:00,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:00,724 INFO:     Epoch: 18
2022-12-31 14:22:02,348 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45701955556869506, 'Total loss': 0.45701955556869506} | train loss {'Reaction outcome loss': 0.3805173758941867, 'Total loss': 0.3805173758941867}
2022-12-31 14:22:02,348 INFO:     Found new best model at epoch 18
2022-12-31 14:22:02,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:02,349 INFO:     Epoch: 19
2022-12-31 14:22:03,968 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4512265036503474, 'Total loss': 0.4512265036503474} | train loss {'Reaction outcome loss': 0.3754752166972694, 'Total loss': 0.3754752166972694}
2022-12-31 14:22:03,968 INFO:     Found new best model at epoch 19
2022-12-31 14:22:03,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:03,969 INFO:     Epoch: 20
2022-12-31 14:22:05,607 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49099720517794293, 'Total loss': 0.49099720517794293} | train loss {'Reaction outcome loss': 0.368691937802931, 'Total loss': 0.368691937802931}
2022-12-31 14:22:05,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:05,607 INFO:     Epoch: 21
2022-12-31 14:22:07,216 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47156075239181516, 'Total loss': 0.47156075239181516} | train loss {'Reaction outcome loss': 0.37288643374017, 'Total loss': 0.37288643374017}
2022-12-31 14:22:07,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:07,217 INFO:     Epoch: 22
2022-12-31 14:22:08,834 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4712006956338882, 'Total loss': 0.4712006956338882} | train loss {'Reaction outcome loss': 0.3571866927298613, 'Total loss': 0.3571866927298613}
2022-12-31 14:22:08,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:08,834 INFO:     Epoch: 23
2022-12-31 14:22:10,480 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4978527545928955, 'Total loss': 0.4978527545928955} | train loss {'Reaction outcome loss': 0.36074587966345706, 'Total loss': 0.36074587966345706}
2022-12-31 14:22:10,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:10,481 INFO:     Epoch: 24
2022-12-31 14:22:12,128 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45621291597684227, 'Total loss': 0.45621291597684227} | train loss {'Reaction outcome loss': 0.3542842776497779, 'Total loss': 0.3542842776497779}
2022-12-31 14:22:12,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:12,129 INFO:     Epoch: 25
2022-12-31 14:22:13,761 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46655369897683463, 'Total loss': 0.46655369897683463} | train loss {'Reaction outcome loss': 0.35095616009099817, 'Total loss': 0.35095616009099817}
2022-12-31 14:22:13,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:13,761 INFO:     Epoch: 26
2022-12-31 14:22:15,414 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4828015148639679, 'Total loss': 0.4828015148639679} | train loss {'Reaction outcome loss': 0.34083784551827057, 'Total loss': 0.34083784551827057}
2022-12-31 14:22:15,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:15,414 INFO:     Epoch: 27
2022-12-31 14:22:17,042 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48477229873339334, 'Total loss': 0.48477229873339334} | train loss {'Reaction outcome loss': 0.3427196909481868, 'Total loss': 0.3427196909481868}
2022-12-31 14:22:17,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:17,043 INFO:     Epoch: 28
2022-12-31 14:22:18,675 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5150909145673116, 'Total loss': 0.5150909145673116} | train loss {'Reaction outcome loss': 0.3315461979849459, 'Total loss': 0.3315461979849459}
2022-12-31 14:22:18,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:18,675 INFO:     Epoch: 29
2022-12-31 14:22:20,318 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5101836899916331, 'Total loss': 0.5101836899916331} | train loss {'Reaction outcome loss': 0.33222178197617136, 'Total loss': 0.33222178197617136}
2022-12-31 14:22:20,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:20,318 INFO:     Epoch: 30
2022-12-31 14:22:21,976 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46135936478773754, 'Total loss': 0.46135936478773754} | train loss {'Reaction outcome loss': 0.3245709934793009, 'Total loss': 0.3245709934793009}
2022-12-31 14:22:21,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:21,978 INFO:     Epoch: 31
2022-12-31 14:22:23,628 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4528380254904429, 'Total loss': 0.4528380254904429} | train loss {'Reaction outcome loss': 0.3198480098794083, 'Total loss': 0.3198480098794083}
2022-12-31 14:22:23,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:23,628 INFO:     Epoch: 32
2022-12-31 14:22:25,114 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4567673643430074, 'Total loss': 0.4567673643430074} | train loss {'Reaction outcome loss': 0.318068484967366, 'Total loss': 0.318068484967366}
2022-12-31 14:22:25,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:25,114 INFO:     Epoch: 33
2022-12-31 14:22:26,213 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4470860302448273, 'Total loss': 0.4470860302448273} | train loss {'Reaction outcome loss': 0.31123551441228775, 'Total loss': 0.31123551441228775}
2022-12-31 14:22:26,214 INFO:     Found new best model at epoch 33
2022-12-31 14:22:26,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:26,215 INFO:     Epoch: 34
2022-12-31 14:22:27,308 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46806373993555705, 'Total loss': 0.46806373993555705} | train loss {'Reaction outcome loss': 0.3158400101244234, 'Total loss': 0.3158400101244234}
2022-12-31 14:22:27,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:27,308 INFO:     Epoch: 35
2022-12-31 14:22:28,395 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45350922346115113, 'Total loss': 0.45350922346115113} | train loss {'Reaction outcome loss': 0.3082123367310861, 'Total loss': 0.3082123367310861}
2022-12-31 14:22:28,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:28,395 INFO:     Epoch: 36
2022-12-31 14:22:29,518 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48353258868058524, 'Total loss': 0.48353258868058524} | train loss {'Reaction outcome loss': 0.30202462879221365, 'Total loss': 0.30202462879221365}
2022-12-31 14:22:29,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:29,518 INFO:     Epoch: 37
2022-12-31 14:22:31,167 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4657657235860825, 'Total loss': 0.4657657235860825} | train loss {'Reaction outcome loss': 0.29490869906512407, 'Total loss': 0.29490869906512407}
2022-12-31 14:22:31,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:31,167 INFO:     Epoch: 38
2022-12-31 14:22:32,798 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4571144243081411, 'Total loss': 0.4571144243081411} | train loss {'Reaction outcome loss': 0.2929314552312078, 'Total loss': 0.2929314552312078}
2022-12-31 14:22:32,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:32,798 INFO:     Epoch: 39
2022-12-31 14:22:34,400 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.505935917297999, 'Total loss': 0.505935917297999} | train loss {'Reaction outcome loss': 0.2931734855397729, 'Total loss': 0.2931734855397729}
2022-12-31 14:22:34,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:34,400 INFO:     Epoch: 40
2022-12-31 14:22:36,020 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4542317455013593, 'Total loss': 0.4542317455013593} | train loss {'Reaction outcome loss': 0.289706651276038, 'Total loss': 0.289706651276038}
2022-12-31 14:22:36,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:36,021 INFO:     Epoch: 41
2022-12-31 14:22:37,642 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46651129722595214, 'Total loss': 0.46651129722595214} | train loss {'Reaction outcome loss': 0.2833181063674848, 'Total loss': 0.2833181063674848}
2022-12-31 14:22:37,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:37,642 INFO:     Epoch: 42
2022-12-31 14:22:39,257 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4505845179160436, 'Total loss': 0.4505845179160436} | train loss {'Reaction outcome loss': 0.2818040676576351, 'Total loss': 0.2818040676576351}
2022-12-31 14:22:39,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:39,257 INFO:     Epoch: 43
2022-12-31 14:22:40,909 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4526472647984823, 'Total loss': 0.4526472647984823} | train loss {'Reaction outcome loss': 0.280911165292943, 'Total loss': 0.280911165292943}
2022-12-31 14:22:40,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:40,910 INFO:     Epoch: 44
2022-12-31 14:22:42,545 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4882841736078262, 'Total loss': 0.4882841736078262} | train loss {'Reaction outcome loss': 0.2756465239322573, 'Total loss': 0.2756465239322573}
2022-12-31 14:22:42,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:42,545 INFO:     Epoch: 45
2022-12-31 14:22:44,157 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4371827165285746, 'Total loss': 0.4371827165285746} | train loss {'Reaction outcome loss': 0.28287534254337476, 'Total loss': 0.28287534254337476}
2022-12-31 14:22:44,157 INFO:     Found new best model at epoch 45
2022-12-31 14:22:44,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:44,158 INFO:     Epoch: 46
2022-12-31 14:22:45,797 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45001213749249774, 'Total loss': 0.45001213749249774} | train loss {'Reaction outcome loss': 0.27086023445701773, 'Total loss': 0.27086023445701773}
2022-12-31 14:22:45,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:45,797 INFO:     Epoch: 47
2022-12-31 14:22:47,415 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48305845657984414, 'Total loss': 0.48305845657984414} | train loss {'Reaction outcome loss': 0.2665812196983327, 'Total loss': 0.2665812196983327}
2022-12-31 14:22:47,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:47,415 INFO:     Epoch: 48
2022-12-31 14:22:49,040 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44704057822624843, 'Total loss': 0.44704057822624843} | train loss {'Reaction outcome loss': 0.2668634057582931, 'Total loss': 0.2668634057582931}
2022-12-31 14:22:49,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:49,040 INFO:     Epoch: 49
2022-12-31 14:22:50,668 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4756913036108017, 'Total loss': 0.4756913036108017} | train loss {'Reaction outcome loss': 0.26365674198319333, 'Total loss': 0.26365674198319333}
2022-12-31 14:22:50,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:50,668 INFO:     Epoch: 50
2022-12-31 14:22:52,270 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4451644241809845, 'Total loss': 0.4451644241809845} | train loss {'Reaction outcome loss': 0.26399877207481476, 'Total loss': 0.26399877207481476}
2022-12-31 14:22:52,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:52,270 INFO:     Epoch: 51
2022-12-31 14:22:53,887 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46343472103277844, 'Total loss': 0.46343472103277844} | train loss {'Reaction outcome loss': 0.2574567682368661, 'Total loss': 0.2574567682368661}
2022-12-31 14:22:53,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:53,888 INFO:     Epoch: 52
2022-12-31 14:22:55,503 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.436644118030866, 'Total loss': 0.436644118030866} | train loss {'Reaction outcome loss': 0.2528574487012861, 'Total loss': 0.2528574487012861}
2022-12-31 14:22:55,504 INFO:     Found new best model at epoch 52
2022-12-31 14:22:55,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:55,504 INFO:     Epoch: 53
2022-12-31 14:22:57,104 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46635793447494506, 'Total loss': 0.46635793447494506} | train loss {'Reaction outcome loss': 0.25518480739438576, 'Total loss': 0.25518480739438576}
2022-12-31 14:22:57,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:57,104 INFO:     Epoch: 54
2022-12-31 14:22:58,721 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44383248885472615, 'Total loss': 0.44383248885472615} | train loss {'Reaction outcome loss': 0.24743339770376035, 'Total loss': 0.24743339770376035}
2022-12-31 14:22:58,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:22:58,723 INFO:     Epoch: 55
2022-12-31 14:23:00,376 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.507179343700409, 'Total loss': 0.507179343700409} | train loss {'Reaction outcome loss': 0.2555700581157681, 'Total loss': 0.2555700581157681}
2022-12-31 14:23:00,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:00,376 INFO:     Epoch: 56
2022-12-31 14:23:01,996 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4803049713373184, 'Total loss': 0.4803049713373184} | train loss {'Reaction outcome loss': 0.25282026757234, 'Total loss': 0.25282026757234}
2022-12-31 14:23:01,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:01,997 INFO:     Epoch: 57
2022-12-31 14:23:03,628 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4776570881406466, 'Total loss': 0.4776570881406466} | train loss {'Reaction outcome loss': 0.2517320067900828, 'Total loss': 0.2517320067900828}
2022-12-31 14:23:03,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:03,628 INFO:     Epoch: 58
2022-12-31 14:23:05,248 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46764526267846424, 'Total loss': 0.46764526267846424} | train loss {'Reaction outcome loss': 0.24472229529696682, 'Total loss': 0.24472229529696682}
2022-12-31 14:23:05,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:05,249 INFO:     Epoch: 59
2022-12-31 14:23:06,851 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4602787454922994, 'Total loss': 0.4602787454922994} | train loss {'Reaction outcome loss': 0.23889817013018613, 'Total loss': 0.23889817013018613}
2022-12-31 14:23:06,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:06,851 INFO:     Epoch: 60
2022-12-31 14:23:08,472 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47827888230482735, 'Total loss': 0.47827888230482735} | train loss {'Reaction outcome loss': 0.24672423542514174, 'Total loss': 0.24672423542514174}
2022-12-31 14:23:08,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:08,473 INFO:     Epoch: 61
2022-12-31 14:23:10,093 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4762341618537903, 'Total loss': 0.4762341618537903} | train loss {'Reaction outcome loss': 0.24022132031861626, 'Total loss': 0.24022132031861626}
2022-12-31 14:23:10,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:10,093 INFO:     Epoch: 62
2022-12-31 14:23:11,711 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5035189648469289, 'Total loss': 0.5035189648469289} | train loss {'Reaction outcome loss': 0.23531196666511603, 'Total loss': 0.23531196666511603}
2022-12-31 14:23:11,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:11,711 INFO:     Epoch: 63
2022-12-31 14:23:13,329 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4768898278474808, 'Total loss': 0.4768898278474808} | train loss {'Reaction outcome loss': 0.23867425825514088, 'Total loss': 0.23867425825514088}
2022-12-31 14:23:13,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:13,329 INFO:     Epoch: 64
2022-12-31 14:23:14,931 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43956682880719505, 'Total loss': 0.43956682880719505} | train loss {'Reaction outcome loss': 0.2388410803858554, 'Total loss': 0.2388410803858554}
2022-12-31 14:23:14,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:14,931 INFO:     Epoch: 65
2022-12-31 14:23:16,580 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43571656246980034, 'Total loss': 0.43571656246980034} | train loss {'Reaction outcome loss': 0.23545581801031257, 'Total loss': 0.23545581801031257}
2022-12-31 14:23:16,580 INFO:     Found new best model at epoch 65
2022-12-31 14:23:16,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:16,581 INFO:     Epoch: 66
2022-12-31 14:23:18,232 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4784790962934494, 'Total loss': 0.4784790962934494} | train loss {'Reaction outcome loss': 0.23310965988179838, 'Total loss': 0.23310965988179838}
2022-12-31 14:23:18,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:18,233 INFO:     Epoch: 67
2022-12-31 14:23:19,860 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44731530249118806, 'Total loss': 0.44731530249118806} | train loss {'Reaction outcome loss': 0.23834589303266054, 'Total loss': 0.23834589303266054}
2022-12-31 14:23:19,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:19,861 INFO:     Epoch: 68
2022-12-31 14:23:21,507 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47221593658129374, 'Total loss': 0.47221593658129374} | train loss {'Reaction outcome loss': 0.231683713447854, 'Total loss': 0.231683713447854}
2022-12-31 14:23:21,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:21,507 INFO:     Epoch: 69
2022-12-31 14:23:23,132 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45161407589912417, 'Total loss': 0.45161407589912417} | train loss {'Reaction outcome loss': 0.2239663190063802, 'Total loss': 0.2239663190063802}
2022-12-31 14:23:23,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:23,132 INFO:     Epoch: 70
2022-12-31 14:23:24,745 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4860994815826416, 'Total loss': 0.4860994815826416} | train loss {'Reaction outcome loss': 0.22542330189624848, 'Total loss': 0.22542330189624848}
2022-12-31 14:23:24,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:24,746 INFO:     Epoch: 71
2022-12-31 14:23:26,370 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43309934437274933, 'Total loss': 0.43309934437274933} | train loss {'Reaction outcome loss': 0.22858294361818998, 'Total loss': 0.22858294361818998}
2022-12-31 14:23:26,370 INFO:     Found new best model at epoch 71
2022-12-31 14:23:26,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:26,371 INFO:     Epoch: 72
2022-12-31 14:23:27,995 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46199183265368143, 'Total loss': 0.46199183265368143} | train loss {'Reaction outcome loss': 0.23302118291923715, 'Total loss': 0.23302118291923715}
2022-12-31 14:23:27,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:27,995 INFO:     Epoch: 73
2022-12-31 14:23:29,598 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45300087134043376, 'Total loss': 0.45300087134043376} | train loss {'Reaction outcome loss': 0.22618460506604252, 'Total loss': 0.22618460506604252}
2022-12-31 14:23:29,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:29,598 INFO:     Epoch: 74
2022-12-31 14:23:31,228 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47953218619028726, 'Total loss': 0.47953218619028726} | train loss {'Reaction outcome loss': 0.21878447573268886, 'Total loss': 0.21878447573268886}
2022-12-31 14:23:31,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:31,228 INFO:     Epoch: 75
2022-12-31 14:23:32,841 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4478991617759069, 'Total loss': 0.4478991617759069} | train loss {'Reaction outcome loss': 0.22562149406615847, 'Total loss': 0.22562149406615847}
2022-12-31 14:23:32,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:32,842 INFO:     Epoch: 76
2022-12-31 14:23:34,470 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4293922831614812, 'Total loss': 0.4293922831614812} | train loss {'Reaction outcome loss': 0.22597455253508547, 'Total loss': 0.22597455253508547}
2022-12-31 14:23:34,471 INFO:     Found new best model at epoch 76
2022-12-31 14:23:34,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:34,472 INFO:     Epoch: 77
2022-12-31 14:23:36,118 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5028248687585195, 'Total loss': 0.5028248687585195} | train loss {'Reaction outcome loss': 0.21829075929086778, 'Total loss': 0.21829075929086778}
2022-12-31 14:23:36,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:36,118 INFO:     Epoch: 78
2022-12-31 14:23:37,742 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48061713576316833, 'Total loss': 0.48061713576316833} | train loss {'Reaction outcome loss': 0.22380721581501328, 'Total loss': 0.22380721581501328}
2022-12-31 14:23:37,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:37,743 INFO:     Epoch: 79
2022-12-31 14:23:39,364 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45544809897740685, 'Total loss': 0.45544809897740685} | train loss {'Reaction outcome loss': 0.21741569804747182, 'Total loss': 0.21741569804747182}
2022-12-31 14:23:39,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:39,365 INFO:     Epoch: 80
2022-12-31 14:23:41,011 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4504424015680949, 'Total loss': 0.4504424015680949} | train loss {'Reaction outcome loss': 0.2243487293620187, 'Total loss': 0.2243487293620187}
2022-12-31 14:23:41,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:41,011 INFO:     Epoch: 81
2022-12-31 14:23:42,630 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.454538294672966, 'Total loss': 0.454538294672966} | train loss {'Reaction outcome loss': 0.21431049433560362, 'Total loss': 0.21431049433560362}
2022-12-31 14:23:42,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:42,630 INFO:     Epoch: 82
2022-12-31 14:23:44,261 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46079529424508414, 'Total loss': 0.46079529424508414} | train loss {'Reaction outcome loss': 0.21207205743767618, 'Total loss': 0.21207205743767618}
2022-12-31 14:23:44,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:44,261 INFO:     Epoch: 83
2022-12-31 14:23:45,882 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4697309205929438, 'Total loss': 0.4697309205929438} | train loss {'Reaction outcome loss': 0.21005873017295495, 'Total loss': 0.21005873017295495}
2022-12-31 14:23:45,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:45,883 INFO:     Epoch: 84
2022-12-31 14:23:47,491 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5047312339146932, 'Total loss': 0.5047312339146932} | train loss {'Reaction outcome loss': 0.2124666483544943, 'Total loss': 0.2124666483544943}
2022-12-31 14:23:47,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:47,491 INFO:     Epoch: 85
2022-12-31 14:23:49,144 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49752179682254793, 'Total loss': 0.49752179682254793} | train loss {'Reaction outcome loss': 0.20756546956645022, 'Total loss': 0.20756546956645022}
2022-12-31 14:23:49,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:49,145 INFO:     Epoch: 86
2022-12-31 14:23:50,796 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4593610088030497, 'Total loss': 0.4593610088030497} | train loss {'Reaction outcome loss': 0.21762982626791896, 'Total loss': 0.21762982626791896}
2022-12-31 14:23:50,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:50,796 INFO:     Epoch: 87
2022-12-31 14:23:52,418 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4452586144208908, 'Total loss': 0.4452586144208908} | train loss {'Reaction outcome loss': 0.20754623141422168, 'Total loss': 0.20754623141422168}
2022-12-31 14:23:52,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:52,419 INFO:     Epoch: 88
2022-12-31 14:23:54,067 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48628403842449186, 'Total loss': 0.48628403842449186} | train loss {'Reaction outcome loss': 0.2051885058491454, 'Total loss': 0.2051885058491454}
2022-12-31 14:23:54,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:54,068 INFO:     Epoch: 89
2022-12-31 14:23:55,695 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4254124939441681, 'Total loss': 0.4254124939441681} | train loss {'Reaction outcome loss': 0.20862868940289592, 'Total loss': 0.20862868940289592}
2022-12-31 14:23:55,695 INFO:     Found new best model at epoch 89
2022-12-31 14:23:55,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:55,696 INFO:     Epoch: 90
2022-12-31 14:23:57,311 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4463167687257131, 'Total loss': 0.4463167687257131} | train loss {'Reaction outcome loss': 0.21005456328445823, 'Total loss': 0.21005456328445823}
2022-12-31 14:23:57,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:57,311 INFO:     Epoch: 91
2022-12-31 14:23:58,928 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46858708957831063, 'Total loss': 0.46858708957831063} | train loss {'Reaction outcome loss': 0.20823181148732775, 'Total loss': 0.20823181148732775}
2022-12-31 14:23:58,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:23:58,928 INFO:     Epoch: 92
2022-12-31 14:24:00,528 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46873007516066234, 'Total loss': 0.46873007516066234} | train loss {'Reaction outcome loss': 0.2017251857983399, 'Total loss': 0.2017251857983399}
2022-12-31 14:24:00,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:00,528 INFO:     Epoch: 93
2022-12-31 14:24:02,177 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45924681921799976, 'Total loss': 0.45924681921799976} | train loss {'Reaction outcome loss': 0.208337208975631, 'Total loss': 0.208337208975631}
2022-12-31 14:24:02,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:02,177 INFO:     Epoch: 94
2022-12-31 14:24:03,829 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4534525106350581, 'Total loss': 0.4534525106350581} | train loss {'Reaction outcome loss': 0.20064699401009814, 'Total loss': 0.20064699401009814}
2022-12-31 14:24:03,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:03,830 INFO:     Epoch: 95
2022-12-31 14:24:05,440 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46213225821654, 'Total loss': 0.46213225821654} | train loss {'Reaction outcome loss': 0.20472630062090091, 'Total loss': 0.20472630062090091}
2022-12-31 14:24:05,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:05,442 INFO:     Epoch: 96
2022-12-31 14:24:07,069 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43998163839181265, 'Total loss': 0.43998163839181265} | train loss {'Reaction outcome loss': 0.20379197703748403, 'Total loss': 0.20379197703748403}
2022-12-31 14:24:07,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:07,070 INFO:     Epoch: 97
2022-12-31 14:24:08,700 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4385562717914581, 'Total loss': 0.4385562717914581} | train loss {'Reaction outcome loss': 0.20291044989715093, 'Total loss': 0.20291044989715093}
2022-12-31 14:24:08,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:08,700 INFO:     Epoch: 98
2022-12-31 14:24:10,332 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5042247980833053, 'Total loss': 0.5042247980833053} | train loss {'Reaction outcome loss': 0.20729331693037106, 'Total loss': 0.20729331693037106}
2022-12-31 14:24:10,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:10,332 INFO:     Epoch: 99
2022-12-31 14:24:11,970 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4451443692048391, 'Total loss': 0.4451443692048391} | train loss {'Reaction outcome loss': 0.20127643047014945, 'Total loss': 0.20127643047014945}
2022-12-31 14:24:11,970 INFO:     Best model found after epoch 90 of 100.
2022-12-31 14:24:11,970 INFO:   Done with stage: TRAINING
2022-12-31 14:24:11,971 INFO:   Starting stage: EVALUATION
2022-12-31 14:24:12,093 INFO:   Done with stage: EVALUATION
2022-12-31 14:24:12,093 INFO:   Leaving out SEQ value Fold_9
2022-12-31 14:24:12,106 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 14:24:12,106 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:24:12,755 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:24:12,755 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:24:12,824 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:24:12,824 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:24:12,824 INFO:     No hyperparam tuning for this model
2022-12-31 14:24:12,825 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:24:12,825 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:24:12,825 INFO:     None feature selector for col prot
2022-12-31 14:24:12,825 INFO:     None feature selector for col prot
2022-12-31 14:24:12,826 INFO:     None feature selector for col prot
2022-12-31 14:24:12,826 INFO:     None feature selector for col chem
2022-12-31 14:24:12,826 INFO:     None feature selector for col chem
2022-12-31 14:24:12,826 INFO:     None feature selector for col chem
2022-12-31 14:24:12,826 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:24:12,826 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:24:12,828 INFO:     Number of params in model 223921
2022-12-31 14:24:12,832 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:24:12,832 INFO:   Starting stage: TRAINING
2022-12-31 14:24:12,876 INFO:     Val loss before train {'Reaction outcome loss': 0.9291725873947143, 'Total loss': 0.9291725873947143}
2022-12-31 14:24:12,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:12,876 INFO:     Epoch: 0
2022-12-31 14:24:14,501 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5944768150647481, 'Total loss': 0.5944768150647481} | train loss {'Reaction outcome loss': 0.8133819487335879, 'Total loss': 0.8133819487335879}
2022-12-31 14:24:14,501 INFO:     Found new best model at epoch 0
2022-12-31 14:24:14,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:14,502 INFO:     Epoch: 1
2022-12-31 14:24:16,144 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.46901898384094237, 'Total loss': 0.46901898384094237} | train loss {'Reaction outcome loss': 0.5960126874786852, 'Total loss': 0.5960126874786852}
2022-12-31 14:24:16,144 INFO:     Found new best model at epoch 1
2022-12-31 14:24:16,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:16,145 INFO:     Epoch: 2
2022-12-31 14:24:17,768 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47506357630093893, 'Total loss': 0.47506357630093893} | train loss {'Reaction outcome loss': 0.5300042388241214, 'Total loss': 0.5300042388241214}
2022-12-31 14:24:17,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:17,768 INFO:     Epoch: 3
2022-12-31 14:24:19,388 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.43350792229175567, 'Total loss': 0.43350792229175567} | train loss {'Reaction outcome loss': 0.5118090806777726, 'Total loss': 0.5118090806777726}
2022-12-31 14:24:19,388 INFO:     Found new best model at epoch 3
2022-12-31 14:24:19,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:19,389 INFO:     Epoch: 4
2022-12-31 14:24:21,017 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43893413146336874, 'Total loss': 0.43893413146336874} | train loss {'Reaction outcome loss': 0.4939408633683132, 'Total loss': 0.4939408633683132}
2022-12-31 14:24:21,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:21,017 INFO:     Epoch: 5
2022-12-31 14:24:22,627 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4178521573543549, 'Total loss': 0.4178521573543549} | train loss {'Reaction outcome loss': 0.4778735871134252, 'Total loss': 0.4778735871134252}
2022-12-31 14:24:22,627 INFO:     Found new best model at epoch 5
2022-12-31 14:24:22,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:22,628 INFO:     Epoch: 6
2022-12-31 14:24:24,253 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4267106791337331, 'Total loss': 0.4267106791337331} | train loss {'Reaction outcome loss': 0.4694528231659521, 'Total loss': 0.4694528231659521}
2022-12-31 14:24:24,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:24,254 INFO:     Epoch: 7
2022-12-31 14:24:25,880 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43286442359288535, 'Total loss': 0.43286442359288535} | train loss {'Reaction outcome loss': 0.4638341639984386, 'Total loss': 0.4638341639984386}
2022-12-31 14:24:25,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:25,880 INFO:     Epoch: 8
2022-12-31 14:24:27,487 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4259938468535741, 'Total loss': 0.4259938468535741} | train loss {'Reaction outcome loss': 0.45623964055135363, 'Total loss': 0.45623964055135363}
2022-12-31 14:24:27,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:27,488 INFO:     Epoch: 9
2022-12-31 14:24:29,140 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4054578334093094, 'Total loss': 0.4054578334093094} | train loss {'Reaction outcome loss': 0.44724018645846025, 'Total loss': 0.44724018645846025}
2022-12-31 14:24:29,140 INFO:     Found new best model at epoch 9
2022-12-31 14:24:29,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:29,141 INFO:     Epoch: 10
2022-12-31 14:24:30,789 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3930575589338938, 'Total loss': 0.3930575589338938} | train loss {'Reaction outcome loss': 0.44478019743835023, 'Total loss': 0.44478019743835023}
2022-12-31 14:24:30,789 INFO:     Found new best model at epoch 10
2022-12-31 14:24:30,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:30,790 INFO:     Epoch: 11
2022-12-31 14:24:32,410 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41559000263611473, 'Total loss': 0.41559000263611473} | train loss {'Reaction outcome loss': 0.43569003863239975, 'Total loss': 0.43569003863239975}
2022-12-31 14:24:32,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:32,411 INFO:     Epoch: 12
2022-12-31 14:24:34,049 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4048430919647217, 'Total loss': 0.4048430919647217} | train loss {'Reaction outcome loss': 0.433936174703419, 'Total loss': 0.433936174703419}
2022-12-31 14:24:34,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:34,049 INFO:     Epoch: 13
2022-12-31 14:24:35,671 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4066305329402288, 'Total loss': 0.4066305329402288} | train loss {'Reaction outcome loss': 0.42810425243007577, 'Total loss': 0.42810425243007577}
2022-12-31 14:24:35,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:35,671 INFO:     Epoch: 14
2022-12-31 14:24:37,280 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39123549064000446, 'Total loss': 0.39123549064000446} | train loss {'Reaction outcome loss': 0.42029431567187775, 'Total loss': 0.42029431567187775}
2022-12-31 14:24:37,281 INFO:     Found new best model at epoch 14
2022-12-31 14:24:37,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:37,282 INFO:     Epoch: 15
2022-12-31 14:24:38,908 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4016060431798299, 'Total loss': 0.4016060431798299} | train loss {'Reaction outcome loss': 0.4133624311818973, 'Total loss': 0.4133624311818973}
2022-12-31 14:24:38,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:38,909 INFO:     Epoch: 16
2022-12-31 14:24:40,517 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40712714890638985, 'Total loss': 0.40712714890638985} | train loss {'Reaction outcome loss': 0.41155079889383556, 'Total loss': 0.41155079889383556}
2022-12-31 14:24:40,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:40,519 INFO:     Epoch: 17
2022-12-31 14:24:42,136 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4236331065495809, 'Total loss': 0.4236331065495809} | train loss {'Reaction outcome loss': 0.401033260762046, 'Total loss': 0.401033260762046}
2022-12-31 14:24:42,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:42,136 INFO:     Epoch: 18
2022-12-31 14:24:43,783 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4199185103178024, 'Total loss': 0.4199185103178024} | train loss {'Reaction outcome loss': 0.4004826891884907, 'Total loss': 0.4004826891884907}
2022-12-31 14:24:43,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:43,783 INFO:     Epoch: 19
2022-12-31 14:24:45,414 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4090020174781481, 'Total loss': 0.4090020174781481} | train loss {'Reaction outcome loss': 0.3936774385588694, 'Total loss': 0.3936774385588694}
2022-12-31 14:24:45,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:45,415 INFO:     Epoch: 20
2022-12-31 14:24:47,045 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39360606869061787, 'Total loss': 0.39360606869061787} | train loss {'Reaction outcome loss': 0.3891607986137755, 'Total loss': 0.3891607986137755}
2022-12-31 14:24:47,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:47,046 INFO:     Epoch: 21
2022-12-31 14:24:48,693 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4067487776279449, 'Total loss': 0.4067487776279449} | train loss {'Reaction outcome loss': 0.38003674250378505, 'Total loss': 0.38003674250378505}
2022-12-31 14:24:48,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:48,693 INFO:     Epoch: 22
2022-12-31 14:24:50,317 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3928971787293752, 'Total loss': 0.3928971787293752} | train loss {'Reaction outcome loss': 0.37826505712223396, 'Total loss': 0.37826505712223396}
2022-12-31 14:24:50,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:50,317 INFO:     Epoch: 23
2022-12-31 14:24:51,975 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4203150510787964, 'Total loss': 0.4203150510787964} | train loss {'Reaction outcome loss': 0.3717493601277847, 'Total loss': 0.3717493601277847}
2022-12-31 14:24:51,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:51,975 INFO:     Epoch: 24
2022-12-31 14:24:53,594 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38831191062927245, 'Total loss': 0.38831191062927245} | train loss {'Reaction outcome loss': 0.36731219991019487, 'Total loss': 0.36731219991019487}
2022-12-31 14:24:53,594 INFO:     Found new best model at epoch 24
2022-12-31 14:24:53,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:53,595 INFO:     Epoch: 25
2022-12-31 14:24:55,207 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4125791867574056, 'Total loss': 0.4125791867574056} | train loss {'Reaction outcome loss': 0.3615337122729324, 'Total loss': 0.3615337122729324}
2022-12-31 14:24:55,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:55,207 INFO:     Epoch: 26
2022-12-31 14:24:56,838 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.37643654545148214, 'Total loss': 0.37643654545148214} | train loss {'Reaction outcome loss': 0.35769506202277723, 'Total loss': 0.35769506202277723}
2022-12-31 14:24:56,838 INFO:     Found new best model at epoch 26
2022-12-31 14:24:56,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:56,839 INFO:     Epoch: 27
2022-12-31 14:24:58,491 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3686661014954249, 'Total loss': 0.3686661014954249} | train loss {'Reaction outcome loss': 0.3464087233323913, 'Total loss': 0.3464087233323913}
2022-12-31 14:24:58,492 INFO:     Found new best model at epoch 27
2022-12-31 14:24:58,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:24:58,493 INFO:     Epoch: 28
2022-12-31 14:25:00,120 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.36652347445487976, 'Total loss': 0.36652347445487976} | train loss {'Reaction outcome loss': 0.34436374374191253, 'Total loss': 0.34436374374191253}
2022-12-31 14:25:00,120 INFO:     Found new best model at epoch 28
2022-12-31 14:25:00,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:00,121 INFO:     Epoch: 29
2022-12-31 14:25:01,759 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3744195982813835, 'Total loss': 0.3744195982813835} | train loss {'Reaction outcome loss': 0.3385313727795432, 'Total loss': 0.3385313727795432}
2022-12-31 14:25:01,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:01,759 INFO:     Epoch: 30
2022-12-31 14:25:03,373 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3959335202972094, 'Total loss': 0.3959335202972094} | train loss {'Reaction outcome loss': 0.3352871264199918, 'Total loss': 0.3352871264199918}
2022-12-31 14:25:03,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:03,374 INFO:     Epoch: 31
2022-12-31 14:25:04,988 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3631327370802561, 'Total loss': 0.3631327370802561} | train loss {'Reaction outcome loss': 0.33080089331641527, 'Total loss': 0.33080089331641527}
2022-12-31 14:25:04,988 INFO:     Found new best model at epoch 31
2022-12-31 14:25:04,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:04,989 INFO:     Epoch: 32
2022-12-31 14:25:06,614 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39000840733448666, 'Total loss': 0.39000840733448666} | train loss {'Reaction outcome loss': 0.32391795459529554, 'Total loss': 0.32391795459529554}
2022-12-31 14:25:06,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:06,614 INFO:     Epoch: 33
2022-12-31 14:25:08,222 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.34052109718322754, 'Total loss': 0.34052109718322754} | train loss {'Reaction outcome loss': 0.31790427430549684, 'Total loss': 0.31790427430549684}
2022-12-31 14:25:08,222 INFO:     Found new best model at epoch 33
2022-12-31 14:25:08,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:08,223 INFO:     Epoch: 34
2022-12-31 14:25:09,840 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3705296789606412, 'Total loss': 0.3705296789606412} | train loss {'Reaction outcome loss': 0.3147528601359805, 'Total loss': 0.3147528601359805}
2022-12-31 14:25:09,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:09,841 INFO:     Epoch: 35
2022-12-31 14:25:11,456 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3468890801072121, 'Total loss': 0.3468890801072121} | train loss {'Reaction outcome loss': 0.3071089121193662, 'Total loss': 0.3071089121193662}
2022-12-31 14:25:11,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:11,457 INFO:     Epoch: 36
2022-12-31 14:25:13,064 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.35150210360685985, 'Total loss': 0.35150210360685985} | train loss {'Reaction outcome loss': 0.30439380429927193, 'Total loss': 0.30439380429927193}
2022-12-31 14:25:13,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:13,064 INFO:     Epoch: 37
2022-12-31 14:25:14,713 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40572335521380104, 'Total loss': 0.40572335521380104} | train loss {'Reaction outcome loss': 0.30426666968996346, 'Total loss': 0.30426666968996346}
2022-12-31 14:25:14,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:14,713 INFO:     Epoch: 38
2022-12-31 14:25:16,337 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38240467409292855, 'Total loss': 0.38240467409292855} | train loss {'Reaction outcome loss': 0.29939994990610475, 'Total loss': 0.29939994990610475}
2022-12-31 14:25:16,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:16,337 INFO:     Epoch: 39
2022-12-31 14:25:17,951 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3588561475276947, 'Total loss': 0.3588561475276947} | train loss {'Reaction outcome loss': 0.29416589245253955, 'Total loss': 0.29416589245253955}
2022-12-31 14:25:17,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:17,952 INFO:     Epoch: 40
2022-12-31 14:25:19,567 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.36387614607810975, 'Total loss': 0.36387614607810975} | train loss {'Reaction outcome loss': 0.28909071147549453, 'Total loss': 0.28909071147549453}
2022-12-31 14:25:19,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:19,567 INFO:     Epoch: 41
2022-12-31 14:25:21,228 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3850026100873947, 'Total loss': 0.3850026100873947} | train loss {'Reaction outcome loss': 0.2915260635504654, 'Total loss': 0.2915260635504654}
2022-12-31 14:25:21,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:21,229 INFO:     Epoch: 42
2022-12-31 14:25:22,882 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38531834483146665, 'Total loss': 0.38531834483146665} | train loss {'Reaction outcome loss': 0.28865410817874465, 'Total loss': 0.28865410817874465}
2022-12-31 14:25:22,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:22,882 INFO:     Epoch: 43
2022-12-31 14:25:24,547 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.35386759986480076, 'Total loss': 0.35386759986480076} | train loss {'Reaction outcome loss': 0.29133052712420693, 'Total loss': 0.29133052712420693}
2022-12-31 14:25:24,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:24,547 INFO:     Epoch: 44
2022-12-31 14:25:26,198 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.36158447340130806, 'Total loss': 0.36158447340130806} | train loss {'Reaction outcome loss': 0.28050173642887105, 'Total loss': 0.28050173642887105}
2022-12-31 14:25:26,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:26,199 INFO:     Epoch: 45
2022-12-31 14:25:27,826 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4010569299260775, 'Total loss': 0.4010569299260775} | train loss {'Reaction outcome loss': 0.2826865986796493, 'Total loss': 0.2826865986796493}
2022-12-31 14:25:27,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:27,826 INFO:     Epoch: 46
2022-12-31 14:25:29,474 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39576691488424937, 'Total loss': 0.39576691488424937} | train loss {'Reaction outcome loss': 0.27405157760592574, 'Total loss': 0.27405157760592574}
2022-12-31 14:25:29,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:29,474 INFO:     Epoch: 47
2022-12-31 14:25:31,109 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.36647156476974485, 'Total loss': 0.36647156476974485} | train loss {'Reaction outcome loss': 0.2725313531658495, 'Total loss': 0.2725313531658495}
2022-12-31 14:25:31,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:31,110 INFO:     Epoch: 48
2022-12-31 14:25:32,751 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3360584264000257, 'Total loss': 0.3360584264000257} | train loss {'Reaction outcome loss': 0.271091911793831, 'Total loss': 0.271091911793831}
2022-12-31 14:25:32,751 INFO:     Found new best model at epoch 48
2022-12-31 14:25:32,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:32,752 INFO:     Epoch: 49
2022-12-31 14:25:34,391 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.32785380482673643, 'Total loss': 0.32785380482673643} | train loss {'Reaction outcome loss': 0.26252889116748573, 'Total loss': 0.26252889116748573}
2022-12-31 14:25:34,391 INFO:     Found new best model at epoch 49
2022-12-31 14:25:34,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:34,392 INFO:     Epoch: 50
2022-12-31 14:25:36,009 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3809376190106074, 'Total loss': 0.3809376190106074} | train loss {'Reaction outcome loss': 0.267236921196595, 'Total loss': 0.267236921196595}
2022-12-31 14:25:36,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:36,009 INFO:     Epoch: 51
2022-12-31 14:25:37,645 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3672855168581009, 'Total loss': 0.3672855168581009} | train loss {'Reaction outcome loss': 0.260409197154781, 'Total loss': 0.260409197154781}
2022-12-31 14:25:37,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:37,645 INFO:     Epoch: 52
2022-12-31 14:25:39,295 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38229066332181294, 'Total loss': 0.38229066332181294} | train loss {'Reaction outcome loss': 0.2655726071137814, 'Total loss': 0.2655726071137814}
2022-12-31 14:25:39,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:39,296 INFO:     Epoch: 53
2022-12-31 14:25:40,912 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37984025180339814, 'Total loss': 0.37984025180339814} | train loss {'Reaction outcome loss': 0.26152886883338866, 'Total loss': 0.26152886883338866}
2022-12-31 14:25:40,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:40,912 INFO:     Epoch: 54
2022-12-31 14:25:42,535 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3758275379737218, 'Total loss': 0.3758275379737218} | train loss {'Reaction outcome loss': 0.2512900890641264, 'Total loss': 0.2512900890641264}
2022-12-31 14:25:42,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:42,536 INFO:     Epoch: 55
2022-12-31 14:25:44,150 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3491376839578152, 'Total loss': 0.3491376839578152} | train loss {'Reaction outcome loss': 0.257804210099395, 'Total loss': 0.257804210099395}
2022-12-31 14:25:44,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:44,151 INFO:     Epoch: 56
2022-12-31 14:25:45,781 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.35147459705670675, 'Total loss': 0.35147459705670675} | train loss {'Reaction outcome loss': 0.25004276845752116, 'Total loss': 0.25004276845752116}
2022-12-31 14:25:45,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:45,781 INFO:     Epoch: 57
2022-12-31 14:25:47,412 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.380591182410717, 'Total loss': 0.380591182410717} | train loss {'Reaction outcome loss': 0.24373981043266046, 'Total loss': 0.24373981043266046}
2022-12-31 14:25:47,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:47,412 INFO:     Epoch: 58
2022-12-31 14:25:49,029 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.36038600901762646, 'Total loss': 0.36038600901762646} | train loss {'Reaction outcome loss': 0.2459879575115679, 'Total loss': 0.2459879575115679}
2022-12-31 14:25:49,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:49,030 INFO:     Epoch: 59
2022-12-31 14:25:50,661 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.34942672749360404, 'Total loss': 0.34942672749360404} | train loss {'Reaction outcome loss': 0.24686918961765103, 'Total loss': 0.24686918961765103}
2022-12-31 14:25:50,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:50,662 INFO:     Epoch: 60
2022-12-31 14:25:52,306 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.348879474401474, 'Total loss': 0.348879474401474} | train loss {'Reaction outcome loss': 0.24512129685831413, 'Total loss': 0.24512129685831413}
2022-12-31 14:25:52,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:52,306 INFO:     Epoch: 61
2022-12-31 14:25:53,916 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37251376708348594, 'Total loss': 0.37251376708348594} | train loss {'Reaction outcome loss': 0.2453641921671827, 'Total loss': 0.2453641921671827}
2022-12-31 14:25:53,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:53,917 INFO:     Epoch: 62
2022-12-31 14:25:55,584 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38646308506528537, 'Total loss': 0.38646308506528537} | train loss {'Reaction outcome loss': 0.2446742809380973, 'Total loss': 0.2446742809380973}
2022-12-31 14:25:55,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:55,584 INFO:     Epoch: 63
2022-12-31 14:25:57,255 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.33438969453175865, 'Total loss': 0.33438969453175865} | train loss {'Reaction outcome loss': 0.23747713923696362, 'Total loss': 0.23747713923696362}
2022-12-31 14:25:57,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:57,255 INFO:     Epoch: 64
2022-12-31 14:25:58,915 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37357826431592306, 'Total loss': 0.37357826431592306} | train loss {'Reaction outcome loss': 0.23842144208129779, 'Total loss': 0.23842144208129779}
2022-12-31 14:25:58,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:25:58,915 INFO:     Epoch: 65
2022-12-31 14:26:00,579 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37578910067677496, 'Total loss': 0.37578910067677496} | train loss {'Reaction outcome loss': 0.2485988073266155, 'Total loss': 0.2485988073266155}
2022-12-31 14:26:00,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:00,580 INFO:     Epoch: 66
2022-12-31 14:26:02,200 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37981600761413575, 'Total loss': 0.37981600761413575} | train loss {'Reaction outcome loss': 0.23545934707733268, 'Total loss': 0.23545934707733268}
2022-12-31 14:26:02,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:02,201 INFO:     Epoch: 67
2022-12-31 14:26:03,845 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.35350049336751305, 'Total loss': 0.35350049336751305} | train loss {'Reaction outcome loss': 0.2320210265015867, 'Total loss': 0.2320210265015867}
2022-12-31 14:26:03,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:03,846 INFO:     Epoch: 68
2022-12-31 14:26:05,515 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3757580111424128, 'Total loss': 0.3757580111424128} | train loss {'Reaction outcome loss': 0.23683897751494434, 'Total loss': 0.23683897751494434}
2022-12-31 14:26:05,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:05,516 INFO:     Epoch: 69
2022-12-31 14:26:07,182 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3398946133752664, 'Total loss': 0.3398946133752664} | train loss {'Reaction outcome loss': 0.233673741738396, 'Total loss': 0.233673741738396}
2022-12-31 14:26:07,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:07,182 INFO:     Epoch: 70
2022-12-31 14:26:08,818 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.36033782064914704, 'Total loss': 0.36033782064914704} | train loss {'Reaction outcome loss': 0.2321370653001195, 'Total loss': 0.2321370653001195}
2022-12-31 14:26:08,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:08,818 INFO:     Epoch: 71
2022-12-31 14:26:10,488 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38083916157484055, 'Total loss': 0.38083916157484055} | train loss {'Reaction outcome loss': 0.22324634623118686, 'Total loss': 0.22324634623118686}
2022-12-31 14:26:10,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:10,488 INFO:     Epoch: 72
2022-12-31 14:26:12,134 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38408601880073545, 'Total loss': 0.38408601880073545} | train loss {'Reaction outcome loss': 0.22831084299496365, 'Total loss': 0.22831084299496365}
2022-12-31 14:26:12,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:12,134 INFO:     Epoch: 73
2022-12-31 14:26:13,797 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.35518413136402766, 'Total loss': 0.35518413136402766} | train loss {'Reaction outcome loss': 0.2346058427171264, 'Total loss': 0.2346058427171264}
2022-12-31 14:26:13,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:13,798 INFO:     Epoch: 74
2022-12-31 14:26:15,453 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37025386889775597, 'Total loss': 0.37025386889775597} | train loss {'Reaction outcome loss': 0.22472652154117284, 'Total loss': 0.22472652154117284}
2022-12-31 14:26:15,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:15,454 INFO:     Epoch: 75
2022-12-31 14:26:17,094 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.35354919334252677, 'Total loss': 0.35354919334252677} | train loss {'Reaction outcome loss': 0.22560603613376834, 'Total loss': 0.22560603613376834}
2022-12-31 14:26:17,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:17,094 INFO:     Epoch: 76
2022-12-31 14:26:18,709 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3664400657018026, 'Total loss': 0.3664400657018026} | train loss {'Reaction outcome loss': 0.2291666294989388, 'Total loss': 0.2291666294989388}
2022-12-31 14:26:18,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:18,710 INFO:     Epoch: 77
2022-12-31 14:26:20,322 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36312492390473683, 'Total loss': 0.36312492390473683} | train loss {'Reaction outcome loss': 0.22298913317251723, 'Total loss': 0.22298913317251723}
2022-12-31 14:26:20,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:20,323 INFO:     Epoch: 78
2022-12-31 14:26:21,921 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.35392619570096334, 'Total loss': 0.35392619570096334} | train loss {'Reaction outcome loss': 0.2295944120681135, 'Total loss': 0.2295944120681135}
2022-12-31 14:26:21,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:21,921 INFO:     Epoch: 79
2022-12-31 14:26:23,534 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.36694384813308717, 'Total loss': 0.36694384813308717} | train loss {'Reaction outcome loss': 0.22198284055284537, 'Total loss': 0.22198284055284537}
2022-12-31 14:26:23,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:23,534 INFO:     Epoch: 80
2022-12-31 14:26:25,146 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.342843242486318, 'Total loss': 0.342843242486318} | train loss {'Reaction outcome loss': 0.2213357258117371, 'Total loss': 0.2213357258117371}
2022-12-31 14:26:25,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:25,146 INFO:     Epoch: 81
2022-12-31 14:26:26,745 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3524263918399811, 'Total loss': 0.3524263918399811} | train loss {'Reaction outcome loss': 0.2189965152084182, 'Total loss': 0.2189965152084182}
2022-12-31 14:26:26,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:26,745 INFO:     Epoch: 82
2022-12-31 14:26:28,358 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39839481711387636, 'Total loss': 0.39839481711387636} | train loss {'Reaction outcome loss': 0.21852343616879374, 'Total loss': 0.21852343616879374}
2022-12-31 14:26:28,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:28,358 INFO:     Epoch: 83
2022-12-31 14:26:29,978 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3603418658177058, 'Total loss': 0.3603418658177058} | train loss {'Reaction outcome loss': 0.21424369056732645, 'Total loss': 0.21424369056732645}
2022-12-31 14:26:29,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:29,978 INFO:     Epoch: 84
2022-12-31 14:26:31,588 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40392148594061533, 'Total loss': 0.40392148594061533} | train loss {'Reaction outcome loss': 0.21478300039330328, 'Total loss': 0.21478300039330328}
2022-12-31 14:26:31,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:31,588 INFO:     Epoch: 85
2022-12-31 14:26:33,202 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.36227577924728394, 'Total loss': 0.36227577924728394} | train loss {'Reaction outcome loss': 0.2152879503942246, 'Total loss': 0.2152879503942246}
2022-12-31 14:26:33,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:33,203 INFO:     Epoch: 86
2022-12-31 14:26:34,836 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3295203367869059, 'Total loss': 0.3295203367869059} | train loss {'Reaction outcome loss': 0.22147538779229464, 'Total loss': 0.22147538779229464}
2022-12-31 14:26:34,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:34,836 INFO:     Epoch: 87
2022-12-31 14:26:36,447 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.34428430907428265, 'Total loss': 0.34428430907428265} | train loss {'Reaction outcome loss': 0.2135002818429298, 'Total loss': 0.2135002818429298}
2022-12-31 14:26:36,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:36,447 INFO:     Epoch: 88
2022-12-31 14:26:38,060 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38444504539171853, 'Total loss': 0.38444504539171853} | train loss {'Reaction outcome loss': 0.22312690747989214, 'Total loss': 0.22312690747989214}
2022-12-31 14:26:38,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:38,061 INFO:     Epoch: 89
2022-12-31 14:26:39,659 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3412346839904785, 'Total loss': 0.3412346839904785} | train loss {'Reaction outcome loss': 0.21769261152049801, 'Total loss': 0.21769261152049801}
2022-12-31 14:26:39,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:39,660 INFO:     Epoch: 90
2022-12-31 14:26:41,304 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3462765276432037, 'Total loss': 0.3462765276432037} | train loss {'Reaction outcome loss': 0.20735082669109645, 'Total loss': 0.20735082669109645}
2022-12-31 14:26:41,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:41,304 INFO:     Epoch: 91
2022-12-31 14:26:42,934 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3775527666012446, 'Total loss': 0.3775527666012446} | train loss {'Reaction outcome loss': 0.2089643709778463, 'Total loss': 0.2089643709778463}
2022-12-31 14:26:42,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:42,934 INFO:     Epoch: 92
2022-12-31 14:26:44,543 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4268710806965828, 'Total loss': 0.4268710806965828} | train loss {'Reaction outcome loss': 0.20638015752638075, 'Total loss': 0.20638015752638075}
2022-12-31 14:26:44,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:44,543 INFO:     Epoch: 93
2022-12-31 14:26:46,188 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3984436124563217, 'Total loss': 0.3984436124563217} | train loss {'Reaction outcome loss': 0.21083141572181713, 'Total loss': 0.21083141572181713}
2022-12-31 14:26:46,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:46,188 INFO:     Epoch: 94
2022-12-31 14:26:47,800 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.35850813587506614, 'Total loss': 0.35850813587506614} | train loss {'Reaction outcome loss': 0.20419720444653439, 'Total loss': 0.20419720444653439}
2022-12-31 14:26:47,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:47,800 INFO:     Epoch: 95
2022-12-31 14:26:49,404 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38884031772613525, 'Total loss': 0.38884031772613525} | train loss {'Reaction outcome loss': 0.2087776260114265, 'Total loss': 0.2087776260114265}
2022-12-31 14:26:49,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:49,406 INFO:     Epoch: 96
2022-12-31 14:26:51,019 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3875694324572881, 'Total loss': 0.3875694324572881} | train loss {'Reaction outcome loss': 0.20410458410044438, 'Total loss': 0.20410458410044438}
2022-12-31 14:26:51,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:51,019 INFO:     Epoch: 97
2022-12-31 14:26:52,635 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.32409365276495616, 'Total loss': 0.32409365276495616} | train loss {'Reaction outcome loss': 0.2079837294867, 'Total loss': 0.2079837294867}
2022-12-31 14:26:52,636 INFO:     Found new best model at epoch 97
2022-12-31 14:26:52,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:52,637 INFO:     Epoch: 98
2022-12-31 14:26:54,266 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.34438385963439944, 'Total loss': 0.34438385963439944} | train loss {'Reaction outcome loss': 0.20805666453141167, 'Total loss': 0.20805666453141167}
2022-12-31 14:26:54,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:54,266 INFO:     Epoch: 99
2022-12-31 14:26:55,889 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.35267540663480756, 'Total loss': 0.35267540663480756} | train loss {'Reaction outcome loss': 0.20526881094026758, 'Total loss': 0.20526881094026758}
2022-12-31 14:26:55,890 INFO:     Best model found after epoch 98 of 100.
2022-12-31 14:26:55,890 INFO:   Done with stage: TRAINING
2022-12-31 14:26:55,890 INFO:   Starting stage: EVALUATION
2022-12-31 14:26:56,012 INFO:   Done with stage: EVALUATION
2022-12-31 14:26:56,021 INFO:   Leaving out SEQ value Fold_0
2022-12-31 14:26:56,034 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 14:26:56,034 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:26:56,680 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:26:56,680 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:26:56,749 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:26:56,749 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:26:56,749 INFO:     No hyperparam tuning for this model
2022-12-31 14:26:56,749 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:26:56,749 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:26:56,750 INFO:     None feature selector for col prot
2022-12-31 14:26:56,750 INFO:     None feature selector for col prot
2022-12-31 14:26:56,750 INFO:     None feature selector for col prot
2022-12-31 14:26:56,751 INFO:     None feature selector for col chem
2022-12-31 14:26:56,751 INFO:     None feature selector for col chem
2022-12-31 14:26:56,751 INFO:     None feature selector for col chem
2022-12-31 14:26:56,751 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:26:56,751 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:26:56,753 INFO:     Number of params in model 223921
2022-12-31 14:26:56,756 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:26:56,756 INFO:   Starting stage: TRAINING
2022-12-31 14:26:56,799 INFO:     Val loss before train {'Reaction outcome loss': 1.0261377175649007, 'Total loss': 1.0261377175649007}
2022-12-31 14:26:56,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:56,799 INFO:     Epoch: 0
2022-12-31 14:26:57,926 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6647198836008708, 'Total loss': 0.6647198836008708} | train loss {'Reaction outcome loss': 0.8099796447875726, 'Total loss': 0.8099796447875726}
2022-12-31 14:26:57,926 INFO:     Found new best model at epoch 0
2022-12-31 14:26:57,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:57,927 INFO:     Epoch: 1
2022-12-31 14:26:58,979 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5547992487748464, 'Total loss': 0.5547992487748464} | train loss {'Reaction outcome loss': 0.593535068098211, 'Total loss': 0.593535068098211}
2022-12-31 14:26:58,979 INFO:     Found new best model at epoch 1
2022-12-31 14:26:58,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:26:58,980 INFO:     Epoch: 2
2022-12-31 14:27:00,031 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5398248394330343, 'Total loss': 0.5398248394330343} | train loss {'Reaction outcome loss': 0.5259099927914404, 'Total loss': 0.5259099927914404}
2022-12-31 14:27:00,031 INFO:     Found new best model at epoch 2
2022-12-31 14:27:00,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:00,032 INFO:     Epoch: 3
2022-12-31 14:27:01,093 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4919249713420868, 'Total loss': 0.4919249713420868} | train loss {'Reaction outcome loss': 0.49642737846087365, 'Total loss': 0.49642737846087365}
2022-12-31 14:27:01,093 INFO:     Found new best model at epoch 3
2022-12-31 14:27:01,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:01,094 INFO:     Epoch: 4
2022-12-31 14:27:02,464 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4949800233046214, 'Total loss': 0.4949800233046214} | train loss {'Reaction outcome loss': 0.4849982318760705, 'Total loss': 0.4849982318760705}
2022-12-31 14:27:02,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:02,464 INFO:     Epoch: 5
2022-12-31 14:27:04,099 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48836045861244204, 'Total loss': 0.48836045861244204} | train loss {'Reaction outcome loss': 0.46982889731217475, 'Total loss': 0.46982889731217475}
2022-12-31 14:27:04,099 INFO:     Found new best model at epoch 5
2022-12-31 14:27:04,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:04,100 INFO:     Epoch: 6
2022-12-31 14:27:05,734 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4862323313951492, 'Total loss': 0.4862323313951492} | train loss {'Reaction outcome loss': 0.4609040706044566, 'Total loss': 0.4609040706044566}
2022-12-31 14:27:05,734 INFO:     Found new best model at epoch 6
2022-12-31 14:27:05,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:05,735 INFO:     Epoch: 7
2022-12-31 14:27:07,362 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5248674690723419, 'Total loss': 0.5248674690723419} | train loss {'Reaction outcome loss': 0.4540836485306712, 'Total loss': 0.4540836485306712}
2022-12-31 14:27:07,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:07,362 INFO:     Epoch: 8
2022-12-31 14:27:08,967 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46796499788761137, 'Total loss': 0.46796499788761137} | train loss {'Reaction outcome loss': 0.454035260599025, 'Total loss': 0.454035260599025}
2022-12-31 14:27:08,967 INFO:     Found new best model at epoch 8
2022-12-31 14:27:08,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:08,968 INFO:     Epoch: 9
2022-12-31 14:27:10,567 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48324927886327107, 'Total loss': 0.48324927886327107} | train loss {'Reaction outcome loss': 0.4460038121273048, 'Total loss': 0.4460038121273048}
2022-12-31 14:27:10,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:10,568 INFO:     Epoch: 10
2022-12-31 14:27:12,173 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46399942139784495, 'Total loss': 0.46399942139784495} | train loss {'Reaction outcome loss': 0.43842531098936594, 'Total loss': 0.43842531098936594}
2022-12-31 14:27:12,174 INFO:     Found new best model at epoch 10
2022-12-31 14:27:12,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:12,175 INFO:     Epoch: 11
2022-12-31 14:27:13,808 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4590217709541321, 'Total loss': 0.4590217709541321} | train loss {'Reaction outcome loss': 0.4313717798268708, 'Total loss': 0.4313717798268708}
2022-12-31 14:27:13,808 INFO:     Found new best model at epoch 11
2022-12-31 14:27:13,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:13,809 INFO:     Epoch: 12
2022-12-31 14:27:15,419 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4564049611488978, 'Total loss': 0.4564049611488978} | train loss {'Reaction outcome loss': 0.42826124231745727, 'Total loss': 0.42826124231745727}
2022-12-31 14:27:15,419 INFO:     Found new best model at epoch 12
2022-12-31 14:27:15,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:15,420 INFO:     Epoch: 13
2022-12-31 14:27:17,036 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4361023435990016, 'Total loss': 0.4361023435990016} | train loss {'Reaction outcome loss': 0.4183674872628529, 'Total loss': 0.4183674872628529}
2022-12-31 14:27:17,036 INFO:     Found new best model at epoch 13
2022-12-31 14:27:17,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:17,037 INFO:     Epoch: 14
2022-12-31 14:27:18,667 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46684078574180604, 'Total loss': 0.46684078574180604} | train loss {'Reaction outcome loss': 0.4168551577268726, 'Total loss': 0.4168551577268726}
2022-12-31 14:27:18,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:18,667 INFO:     Epoch: 15
2022-12-31 14:27:20,247 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4800762474536896, 'Total loss': 0.4800762474536896} | train loss {'Reaction outcome loss': 0.4082516841046567, 'Total loss': 0.4082516841046567}
2022-12-31 14:27:20,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:20,247 INFO:     Epoch: 16
2022-12-31 14:27:21,855 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4540006458759308, 'Total loss': 0.4540006458759308} | train loss {'Reaction outcome loss': 0.40525003639559676, 'Total loss': 0.40525003639559676}
2022-12-31 14:27:21,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:21,856 INFO:     Epoch: 17
2022-12-31 14:27:23,452 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4448185960451762, 'Total loss': 0.4448185960451762} | train loss {'Reaction outcome loss': 0.3925044980362384, 'Total loss': 0.3925044980362384}
2022-12-31 14:27:23,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:23,452 INFO:     Epoch: 18
2022-12-31 14:27:25,077 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4502280433972677, 'Total loss': 0.4502280433972677} | train loss {'Reaction outcome loss': 0.38688541160230216, 'Total loss': 0.38688541160230216}
2022-12-31 14:27:25,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:25,078 INFO:     Epoch: 19
2022-12-31 14:27:26,680 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4593020667632421, 'Total loss': 0.4593020667632421} | train loss {'Reaction outcome loss': 0.39174318252416857, 'Total loss': 0.39174318252416857}
2022-12-31 14:27:26,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:26,681 INFO:     Epoch: 20
2022-12-31 14:27:28,292 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4541174709796906, 'Total loss': 0.4541174709796906} | train loss {'Reaction outcome loss': 0.3846663516150774, 'Total loss': 0.3846663516150774}
2022-12-31 14:27:28,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:28,292 INFO:     Epoch: 21
2022-12-31 14:27:29,895 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4423300196727117, 'Total loss': 0.4423300196727117} | train loss {'Reaction outcome loss': 0.3772502515981667, 'Total loss': 0.3772502515981667}
2022-12-31 14:27:29,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:29,895 INFO:     Epoch: 22
2022-12-31 14:27:31,524 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48260348439216616, 'Total loss': 0.48260348439216616} | train loss {'Reaction outcome loss': 0.3714246051589938, 'Total loss': 0.3714246051589938}
2022-12-31 14:27:31,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:31,525 INFO:     Epoch: 23
2022-12-31 14:27:33,127 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4418550282716751, 'Total loss': 0.4418550282716751} | train loss {'Reaction outcome loss': 0.3666932175248644, 'Total loss': 0.3666932175248644}
2022-12-31 14:27:33,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:33,127 INFO:     Epoch: 24
2022-12-31 14:27:34,747 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4394880473613739, 'Total loss': 0.4394880473613739} | train loss {'Reaction outcome loss': 0.36356305665452116, 'Total loss': 0.36356305665452116}
2022-12-31 14:27:34,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:34,747 INFO:     Epoch: 25
2022-12-31 14:27:36,333 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4590704351663589, 'Total loss': 0.4590704351663589} | train loss {'Reaction outcome loss': 0.36097167633528254, 'Total loss': 0.36097167633528254}
2022-12-31 14:27:36,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:36,334 INFO:     Epoch: 26
2022-12-31 14:27:37,926 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45828585922718046, 'Total loss': 0.45828585922718046} | train loss {'Reaction outcome loss': 0.3583600173303246, 'Total loss': 0.3583600173303246}
2022-12-31 14:27:37,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:37,926 INFO:     Epoch: 27
2022-12-31 14:27:39,538 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.410125724474589, 'Total loss': 0.410125724474589} | train loss {'Reaction outcome loss': 0.3521724855595261, 'Total loss': 0.3521724855595261}
2022-12-31 14:27:39,538 INFO:     Found new best model at epoch 27
2022-12-31 14:27:39,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:39,539 INFO:     Epoch: 28
2022-12-31 14:27:41,150 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43242907226085664, 'Total loss': 0.43242907226085664} | train loss {'Reaction outcome loss': 0.3464794239831449, 'Total loss': 0.3464794239831449}
2022-12-31 14:27:41,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:41,150 INFO:     Epoch: 29
2022-12-31 14:27:42,761 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3985909690459569, 'Total loss': 0.3985909690459569} | train loss {'Reaction outcome loss': 0.33602705453760434, 'Total loss': 0.33602705453760434}
2022-12-31 14:27:42,762 INFO:     Found new best model at epoch 29
2022-12-31 14:27:42,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:42,763 INFO:     Epoch: 30
2022-12-31 14:27:44,379 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41862604320049285, 'Total loss': 0.41862604320049285} | train loss {'Reaction outcome loss': 0.3366082773890591, 'Total loss': 0.3366082773890591}
2022-12-31 14:27:44,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:44,380 INFO:     Epoch: 31
2022-12-31 14:27:45,980 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47868119875590004, 'Total loss': 0.47868119875590004} | train loss {'Reaction outcome loss': 0.32819865036239154, 'Total loss': 0.32819865036239154}
2022-12-31 14:27:45,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:45,980 INFO:     Epoch: 32
2022-12-31 14:27:47,555 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4129887521266937, 'Total loss': 0.4129887521266937} | train loss {'Reaction outcome loss': 0.32718002611268177, 'Total loss': 0.32718002611268177}
2022-12-31 14:27:47,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:47,555 INFO:     Epoch: 33
2022-12-31 14:27:49,175 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4055978318055471, 'Total loss': 0.4055978318055471} | train loss {'Reaction outcome loss': 0.324044884665169, 'Total loss': 0.324044884665169}
2022-12-31 14:27:49,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:49,176 INFO:     Epoch: 34
2022-12-31 14:27:50,770 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39029096712668737, 'Total loss': 0.39029096712668737} | train loss {'Reaction outcome loss': 0.3201472439470082, 'Total loss': 0.3201472439470082}
2022-12-31 14:27:50,770 INFO:     Found new best model at epoch 34
2022-12-31 14:27:50,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:50,771 INFO:     Epoch: 35
2022-12-31 14:27:52,368 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3976478467384974, 'Total loss': 0.3976478467384974} | train loss {'Reaction outcome loss': 0.31288176584635335, 'Total loss': 0.31288176584635335}
2022-12-31 14:27:52,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:52,368 INFO:     Epoch: 36
2022-12-31 14:27:53,962 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4026094347238541, 'Total loss': 0.4026094347238541} | train loss {'Reaction outcome loss': 0.3080552598311953, 'Total loss': 0.3080552598311953}
2022-12-31 14:27:53,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:53,962 INFO:     Epoch: 37
2022-12-31 14:27:55,561 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41510894472400345, 'Total loss': 0.41510894472400345} | train loss {'Reaction outcome loss': 0.31037192517062173, 'Total loss': 0.31037192517062173}
2022-12-31 14:27:55,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:55,561 INFO:     Epoch: 38
2022-12-31 14:27:57,157 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42934287786483766, 'Total loss': 0.42934287786483766} | train loss {'Reaction outcome loss': 0.3035687228297665, 'Total loss': 0.3035687228297665}
2022-12-31 14:27:57,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:57,157 INFO:     Epoch: 39
2022-12-31 14:27:58,778 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4119335949420929, 'Total loss': 0.4119335949420929} | train loss {'Reaction outcome loss': 0.2968911984323585, 'Total loss': 0.2968911984323585}
2022-12-31 14:27:58,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:27:58,778 INFO:     Epoch: 40
2022-12-31 14:28:00,396 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38248499830563865, 'Total loss': 0.38248499830563865} | train loss {'Reaction outcome loss': 0.29598886930268176, 'Total loss': 0.29598886930268176}
2022-12-31 14:28:00,397 INFO:     Found new best model at epoch 40
2022-12-31 14:28:00,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:00,398 INFO:     Epoch: 41
2022-12-31 14:28:02,034 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3832554991046588, 'Total loss': 0.3832554991046588} | train loss {'Reaction outcome loss': 0.2910419087857008, 'Total loss': 0.2910419087857008}
2022-12-31 14:28:02,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:02,034 INFO:     Epoch: 42
2022-12-31 14:28:03,652 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4247518002986908, 'Total loss': 0.4247518002986908} | train loss {'Reaction outcome loss': 0.2873401763393496, 'Total loss': 0.2873401763393496}
2022-12-31 14:28:03,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:03,652 INFO:     Epoch: 43
2022-12-31 14:28:05,271 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4328035404284795, 'Total loss': 0.4328035404284795} | train loss {'Reaction outcome loss': 0.2837328434697468, 'Total loss': 0.2837328434697468}
2022-12-31 14:28:05,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:05,272 INFO:     Epoch: 44
2022-12-31 14:28:06,899 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42954526444276175, 'Total loss': 0.42954526444276175} | train loss {'Reaction outcome loss': 0.28920860428118356, 'Total loss': 0.28920860428118356}
2022-12-31 14:28:06,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:06,900 INFO:     Epoch: 45
2022-12-31 14:28:08,521 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4216671178738276, 'Total loss': 0.4216671178738276} | train loss {'Reaction outcome loss': 0.2837415629875486, 'Total loss': 0.2837415629875486}
2022-12-31 14:28:08,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:08,521 INFO:     Epoch: 46
2022-12-31 14:28:10,117 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43028272887070973, 'Total loss': 0.43028272887070973} | train loss {'Reaction outcome loss': 0.273414715471929, 'Total loss': 0.273414715471929}
2022-12-31 14:28:10,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:10,118 INFO:     Epoch: 47
2022-12-31 14:28:11,714 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4267809828122457, 'Total loss': 0.4267809828122457} | train loss {'Reaction outcome loss': 0.2718474270544783, 'Total loss': 0.2718474270544783}
2022-12-31 14:28:11,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:11,714 INFO:     Epoch: 48
2022-12-31 14:28:13,306 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4153679301341375, 'Total loss': 0.4153679301341375} | train loss {'Reaction outcome loss': 0.27661370906135896, 'Total loss': 0.27661370906135896}
2022-12-31 14:28:13,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:13,307 INFO:     Epoch: 49
2022-12-31 14:28:14,921 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4055685788393021, 'Total loss': 0.4055685788393021} | train loss {'Reaction outcome loss': 0.2754461274203593, 'Total loss': 0.2754461274203593}
2022-12-31 14:28:14,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:14,921 INFO:     Epoch: 50
2022-12-31 14:28:16,553 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3924535552660624, 'Total loss': 0.3924535552660624} | train loss {'Reaction outcome loss': 0.2673377397531358, 'Total loss': 0.2673377397531358}
2022-12-31 14:28:16,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:16,554 INFO:     Epoch: 51
2022-12-31 14:28:18,161 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4004153490066528, 'Total loss': 0.4004153490066528} | train loss {'Reaction outcome loss': 0.2634069397229783, 'Total loss': 0.2634069397229783}
2022-12-31 14:28:18,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:18,161 INFO:     Epoch: 52
2022-12-31 14:28:19,765 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4170561263958613, 'Total loss': 0.4170561263958613} | train loss {'Reaction outcome loss': 0.26244767828688137, 'Total loss': 0.26244767828688137}
2022-12-31 14:28:19,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:19,766 INFO:     Epoch: 53
2022-12-31 14:28:21,341 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3792261799176534, 'Total loss': 0.3792261799176534} | train loss {'Reaction outcome loss': 0.2626733142529091, 'Total loss': 0.2626733142529091}
2022-12-31 14:28:21,342 INFO:     Found new best model at epoch 53
2022-12-31 14:28:21,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:21,343 INFO:     Epoch: 54
2022-12-31 14:28:22,939 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40184922417004904, 'Total loss': 0.40184922417004904} | train loss {'Reaction outcome loss': 0.25690340392128397, 'Total loss': 0.25690340392128397}
2022-12-31 14:28:22,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:22,940 INFO:     Epoch: 55
2022-12-31 14:28:24,519 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38904626965522765, 'Total loss': 0.38904626965522765} | train loss {'Reaction outcome loss': 0.24900611925761412, 'Total loss': 0.24900611925761412}
2022-12-31 14:28:24,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:24,519 INFO:     Epoch: 56
2022-12-31 14:28:26,117 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3919869730869929, 'Total loss': 0.3919869730869929} | train loss {'Reaction outcome loss': 0.25232078150648923, 'Total loss': 0.25232078150648923}
2022-12-31 14:28:26,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:26,117 INFO:     Epoch: 57
2022-12-31 14:28:27,743 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3788680166006088, 'Total loss': 0.3788680166006088} | train loss {'Reaction outcome loss': 0.25445383755884465, 'Total loss': 0.25445383755884465}
2022-12-31 14:28:27,743 INFO:     Found new best model at epoch 57
2022-12-31 14:28:27,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:27,744 INFO:     Epoch: 58
2022-12-31 14:28:29,346 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3977813849846522, 'Total loss': 0.3977813849846522} | train loss {'Reaction outcome loss': 0.24764263633992115, 'Total loss': 0.24764263633992115}
2022-12-31 14:28:29,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:29,346 INFO:     Epoch: 59
2022-12-31 14:28:30,942 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39560676316420235, 'Total loss': 0.39560676316420235} | train loss {'Reaction outcome loss': 0.2507599867662809, 'Total loss': 0.2507599867662809}
2022-12-31 14:28:30,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:30,943 INFO:     Epoch: 60
2022-12-31 14:28:32,532 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36573779086271924, 'Total loss': 0.36573779086271924} | train loss {'Reaction outcome loss': 0.2445644266957784, 'Total loss': 0.2445644266957784}
2022-12-31 14:28:32,533 INFO:     Found new best model at epoch 60
2022-12-31 14:28:32,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:32,534 INFO:     Epoch: 61
2022-12-31 14:28:34,131 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40326064825057983, 'Total loss': 0.40326064825057983} | train loss {'Reaction outcome loss': 0.24397052279299627, 'Total loss': 0.24397052279299627}
2022-12-31 14:28:34,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:34,131 INFO:     Epoch: 62
2022-12-31 14:28:35,737 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40069117546081545, 'Total loss': 0.40069117546081545} | train loss {'Reaction outcome loss': 0.24390763420965114, 'Total loss': 0.24390763420965114}
2022-12-31 14:28:35,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:35,737 INFO:     Epoch: 63
2022-12-31 14:28:37,339 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3971965253353119, 'Total loss': 0.3971965253353119} | train loss {'Reaction outcome loss': 0.24106660547809008, 'Total loss': 0.24106660547809008}
2022-12-31 14:28:37,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:37,340 INFO:     Epoch: 64
2022-12-31 14:28:38,948 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3835246821244558, 'Total loss': 0.3835246821244558} | train loss {'Reaction outcome loss': 0.23732614658609794, 'Total loss': 0.23732614658609794}
2022-12-31 14:28:38,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:38,949 INFO:     Epoch: 65
2022-12-31 14:28:40,537 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4068823799490929, 'Total loss': 0.4068823799490929} | train loss {'Reaction outcome loss': 0.23793598833446303, 'Total loss': 0.23793598833446303}
2022-12-31 14:28:40,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:40,538 INFO:     Epoch: 66
2022-12-31 14:28:42,125 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39953000446160636, 'Total loss': 0.39953000446160636} | train loss {'Reaction outcome loss': 0.23617928426875903, 'Total loss': 0.23617928426875903}
2022-12-31 14:28:42,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:42,125 INFO:     Epoch: 67
2022-12-31 14:28:43,722 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4048530419667562, 'Total loss': 0.4048530419667562} | train loss {'Reaction outcome loss': 0.2314221312353102, 'Total loss': 0.2314221312353102}
2022-12-31 14:28:43,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:43,722 INFO:     Epoch: 68
2022-12-31 14:28:45,320 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3646849105755488, 'Total loss': 0.3646849105755488} | train loss {'Reaction outcome loss': 0.2315255751439037, 'Total loss': 0.2315255751439037}
2022-12-31 14:28:45,320 INFO:     Found new best model at epoch 68
2022-12-31 14:28:45,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:45,321 INFO:     Epoch: 69
2022-12-31 14:28:46,914 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.37882184982299805, 'Total loss': 0.37882184982299805} | train loss {'Reaction outcome loss': 0.23263844151566498, 'Total loss': 0.23263844151566498}
2022-12-31 14:28:46,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:46,914 INFO:     Epoch: 70
2022-12-31 14:28:48,491 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39873140056927997, 'Total loss': 0.39873140056927997} | train loss {'Reaction outcome loss': 0.2276402125406983, 'Total loss': 0.2276402125406983}
2022-12-31 14:28:48,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:48,491 INFO:     Epoch: 71
2022-12-31 14:28:50,128 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4155316412448883, 'Total loss': 0.4155316412448883} | train loss {'Reaction outcome loss': 0.22616911293381323, 'Total loss': 0.22616911293381323}
2022-12-31 14:28:50,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:50,129 INFO:     Epoch: 72
2022-12-31 14:28:51,745 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37604920168717704, 'Total loss': 0.37604920168717704} | train loss {'Reaction outcome loss': 0.2310136652680753, 'Total loss': 0.2310136652680753}
2022-12-31 14:28:51,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:51,746 INFO:     Epoch: 73
2022-12-31 14:28:53,379 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4048493226369222, 'Total loss': 0.4048493226369222} | train loss {'Reaction outcome loss': 0.21985783553716257, 'Total loss': 0.21985783553716257}
2022-12-31 14:28:53,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:53,380 INFO:     Epoch: 74
2022-12-31 14:28:55,015 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3949576586484909, 'Total loss': 0.3949576586484909} | train loss {'Reaction outcome loss': 0.2258060463350674, 'Total loss': 0.2258060463350674}
2022-12-31 14:28:55,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:55,015 INFO:     Epoch: 75
2022-12-31 14:28:56,631 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39142503043015797, 'Total loss': 0.39142503043015797} | train loss {'Reaction outcome loss': 0.2245074392561495, 'Total loss': 0.2245074392561495}
2022-12-31 14:28:56,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:56,631 INFO:     Epoch: 76
2022-12-31 14:28:58,211 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3800792912642161, 'Total loss': 0.3800792912642161} | train loss {'Reaction outcome loss': 0.21742365601044283, 'Total loss': 0.21742365601044283}
2022-12-31 14:28:58,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:58,211 INFO:     Epoch: 77
2022-12-31 14:28:59,798 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37322332759698235, 'Total loss': 0.37322332759698235} | train loss {'Reaction outcome loss': 0.21904025209836497, 'Total loss': 0.21904025209836497}
2022-12-31 14:28:59,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:28:59,798 INFO:     Epoch: 78
2022-12-31 14:29:01,394 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39013942579428357, 'Total loss': 0.39013942579428357} | train loss {'Reaction outcome loss': 0.2136813803324408, 'Total loss': 0.2136813803324408}
2022-12-31 14:29:01,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:01,395 INFO:     Epoch: 79
2022-12-31 14:29:02,991 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42245046198368075, 'Total loss': 0.42245046198368075} | train loss {'Reaction outcome loss': 0.2184494850123777, 'Total loss': 0.2184494850123777}
2022-12-31 14:29:02,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:02,991 INFO:     Epoch: 80
2022-12-31 14:29:04,586 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3570690184831619, 'Total loss': 0.3570690184831619} | train loss {'Reaction outcome loss': 0.2219137303721513, 'Total loss': 0.2219137303721513}
2022-12-31 14:29:04,586 INFO:     Found new best model at epoch 80
2022-12-31 14:29:04,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:04,587 INFO:     Epoch: 81
2022-12-31 14:29:06,181 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3684541253993909, 'Total loss': 0.3684541253993909} | train loss {'Reaction outcome loss': 0.20704350455317402, 'Total loss': 0.20704350455317402}
2022-12-31 14:29:06,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:06,181 INFO:     Epoch: 82
2022-12-31 14:29:07,785 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3810129056374232, 'Total loss': 0.3810129056374232} | train loss {'Reaction outcome loss': 0.20999233383195895, 'Total loss': 0.20999233383195895}
2022-12-31 14:29:07,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:07,786 INFO:     Epoch: 83
2022-12-31 14:29:09,380 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39161325891812643, 'Total loss': 0.39161325891812643} | train loss {'Reaction outcome loss': 0.21127420007149234, 'Total loss': 0.21127420007149234}
2022-12-31 14:29:09,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:09,381 INFO:     Epoch: 84
2022-12-31 14:29:10,977 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3970425317684809, 'Total loss': 0.3970425317684809} | train loss {'Reaction outcome loss': 0.20678474460422558, 'Total loss': 0.20678474460422558}
2022-12-31 14:29:10,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:10,977 INFO:     Epoch: 85
2022-12-31 14:29:12,574 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4345266103744507, 'Total loss': 0.4345266103744507} | train loss {'Reaction outcome loss': 0.20924584159668344, 'Total loss': 0.20924584159668344}
2022-12-31 14:29:12,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:12,575 INFO:     Epoch: 86
2022-12-31 14:29:14,204 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3783824925621351, 'Total loss': 0.3783824925621351} | train loss {'Reaction outcome loss': 0.20379949146269882, 'Total loss': 0.20379949146269882}
2022-12-31 14:29:14,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:14,204 INFO:     Epoch: 87
2022-12-31 14:29:15,808 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.37671436071395875, 'Total loss': 0.37671436071395875} | train loss {'Reaction outcome loss': 0.2062008122192954, 'Total loss': 0.2062008122192954}
2022-12-31 14:29:15,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:15,808 INFO:     Epoch: 88
2022-12-31 14:29:17,435 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39413150198136765, 'Total loss': 0.39413150198136765} | train loss {'Reaction outcome loss': 0.20655724092175926, 'Total loss': 0.20655724092175926}
2022-12-31 14:29:17,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:17,436 INFO:     Epoch: 89
2022-12-31 14:29:19,028 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38807936360438666, 'Total loss': 0.38807936360438666} | train loss {'Reaction outcome loss': 0.20343642850426863, 'Total loss': 0.20343642850426863}
2022-12-31 14:29:19,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:19,028 INFO:     Epoch: 90
2022-12-31 14:29:20,625 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40209600726763406, 'Total loss': 0.40209600726763406} | train loss {'Reaction outcome loss': 0.20785511043058694, 'Total loss': 0.20785511043058694}
2022-12-31 14:29:20,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:20,626 INFO:     Epoch: 91
2022-12-31 14:29:22,222 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4146222581466039, 'Total loss': 0.4146222581466039} | train loss {'Reaction outcome loss': 0.2073725197654571, 'Total loss': 0.2073725197654571}
2022-12-31 14:29:22,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:22,222 INFO:     Epoch: 92
2022-12-31 14:29:23,819 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.38123582154512403, 'Total loss': 0.38123582154512403} | train loss {'Reaction outcome loss': 0.20418863058307746, 'Total loss': 0.20418863058307746}
2022-12-31 14:29:23,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:23,819 INFO:     Epoch: 93
2022-12-31 14:29:25,420 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3856214871009191, 'Total loss': 0.3856214871009191} | train loss {'Reaction outcome loss': 0.1985862430858079, 'Total loss': 0.1985862430858079}
2022-12-31 14:29:25,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:25,421 INFO:     Epoch: 94
2022-12-31 14:29:27,009 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3959560131033262, 'Total loss': 0.3959560131033262} | train loss {'Reaction outcome loss': 0.20209165162536025, 'Total loss': 0.20209165162536025}
2022-12-31 14:29:27,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:27,009 INFO:     Epoch: 95
2022-12-31 14:29:28,643 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3738989422718684, 'Total loss': 0.3738989422718684} | train loss {'Reaction outcome loss': 0.20638647917522132, 'Total loss': 0.20638647917522132}
2022-12-31 14:29:28,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:28,643 INFO:     Epoch: 96
2022-12-31 14:29:30,257 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37376544177532195, 'Total loss': 0.37376544177532195} | train loss {'Reaction outcome loss': 0.19673733418657832, 'Total loss': 0.19673733418657832}
2022-12-31 14:29:30,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:30,258 INFO:     Epoch: 97
2022-12-31 14:29:31,881 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36215997536977135, 'Total loss': 0.36215997536977135} | train loss {'Reaction outcome loss': 0.20001015323384183, 'Total loss': 0.20001015323384183}
2022-12-31 14:29:31,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:31,881 INFO:     Epoch: 98
2022-12-31 14:29:33,471 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.35237312614917754, 'Total loss': 0.35237312614917754} | train loss {'Reaction outcome loss': 0.20309776436863808, 'Total loss': 0.20309776436863808}
2022-12-31 14:29:33,471 INFO:     Found new best model at epoch 98
2022-12-31 14:29:33,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:33,472 INFO:     Epoch: 99
2022-12-31 14:29:35,083 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40022494792938235, 'Total loss': 0.40022494792938235} | train loss {'Reaction outcome loss': 0.19146702069462868, 'Total loss': 0.19146702069462868}
2022-12-31 14:29:35,083 INFO:     Best model found after epoch 99 of 100.
2022-12-31 14:29:35,083 INFO:   Done with stage: TRAINING
2022-12-31 14:29:35,083 INFO:   Starting stage: EVALUATION
2022-12-31 14:29:35,219 INFO:   Done with stage: EVALUATION
2022-12-31 14:29:35,219 INFO:   Leaving out SEQ value Fold_1
2022-12-31 14:29:35,232 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 14:29:35,232 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:29:35,876 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:29:35,876 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:29:35,944 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:29:35,944 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:29:35,945 INFO:     No hyperparam tuning for this model
2022-12-31 14:29:35,945 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:29:35,945 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:29:35,945 INFO:     None feature selector for col prot
2022-12-31 14:29:35,946 INFO:     None feature selector for col prot
2022-12-31 14:29:35,946 INFO:     None feature selector for col prot
2022-12-31 14:29:35,946 INFO:     None feature selector for col chem
2022-12-31 14:29:35,946 INFO:     None feature selector for col chem
2022-12-31 14:29:35,946 INFO:     None feature selector for col chem
2022-12-31 14:29:35,946 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:29:35,946 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:29:35,948 INFO:     Number of params in model 223921
2022-12-31 14:29:35,951 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:29:35,951 INFO:   Starting stage: TRAINING
2022-12-31 14:29:35,995 INFO:     Val loss before train {'Reaction outcome loss': 0.9979280710220337, 'Total loss': 0.9979280710220337}
2022-12-31 14:29:35,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:35,996 INFO:     Epoch: 0
2022-12-31 14:29:37,637 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.669890284538269, 'Total loss': 0.669890284538269} | train loss {'Reaction outcome loss': 0.8079295145334119, 'Total loss': 0.8079295145334119}
2022-12-31 14:29:37,638 INFO:     Found new best model at epoch 0
2022-12-31 14:29:37,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:37,639 INFO:     Epoch: 1
2022-12-31 14:29:39,274 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5802892953157425, 'Total loss': 0.5802892953157425} | train loss {'Reaction outcome loss': 0.6050366758212556, 'Total loss': 0.6050366758212556}
2022-12-31 14:29:39,274 INFO:     Found new best model at epoch 1
2022-12-31 14:29:39,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:39,275 INFO:     Epoch: 2
2022-12-31 14:29:40,905 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.562059470017751, 'Total loss': 0.562059470017751} | train loss {'Reaction outcome loss': 0.5380875006535627, 'Total loss': 0.5380875006535627}
2022-12-31 14:29:40,905 INFO:     Found new best model at epoch 2
2022-12-31 14:29:40,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:40,906 INFO:     Epoch: 3
2022-12-31 14:29:42,524 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5332790176073711, 'Total loss': 0.5332790176073711} | train loss {'Reaction outcome loss': 0.500171900393754, 'Total loss': 0.500171900393754}
2022-12-31 14:29:42,524 INFO:     Found new best model at epoch 3
2022-12-31 14:29:42,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:42,525 INFO:     Epoch: 4
2022-12-31 14:29:44,132 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5183468749125798, 'Total loss': 0.5183468749125798} | train loss {'Reaction outcome loss': 0.49191153092976037, 'Total loss': 0.49191153092976037}
2022-12-31 14:29:44,133 INFO:     Found new best model at epoch 4
2022-12-31 14:29:44,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:44,134 INFO:     Epoch: 5
2022-12-31 14:29:45,737 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49934032758076985, 'Total loss': 0.49934032758076985} | train loss {'Reaction outcome loss': 0.48058948083950653, 'Total loss': 0.48058948083950653}
2022-12-31 14:29:45,737 INFO:     Found new best model at epoch 5
2022-12-31 14:29:45,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:45,738 INFO:     Epoch: 6
2022-12-31 14:29:47,362 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4931913256645203, 'Total loss': 0.4931913256645203} | train loss {'Reaction outcome loss': 0.4688228597171115, 'Total loss': 0.4688228597171115}
2022-12-31 14:29:47,362 INFO:     Found new best model at epoch 6
2022-12-31 14:29:47,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:47,363 INFO:     Epoch: 7
2022-12-31 14:29:48,976 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5237131853898366, 'Total loss': 0.5237131853898366} | train loss {'Reaction outcome loss': 0.4619473580026279, 'Total loss': 0.4619473580026279}
2022-12-31 14:29:48,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:48,976 INFO:     Epoch: 8
2022-12-31 14:29:50,572 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46885321935017904, 'Total loss': 0.46885321935017904} | train loss {'Reaction outcome loss': 0.4550801427477468, 'Total loss': 0.4550801427477468}
2022-12-31 14:29:50,572 INFO:     Found new best model at epoch 8
2022-12-31 14:29:50,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:50,573 INFO:     Epoch: 9
2022-12-31 14:29:52,155 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49452218413352966, 'Total loss': 0.49452218413352966} | train loss {'Reaction outcome loss': 0.44295493225111576, 'Total loss': 0.44295493225111576}
2022-12-31 14:29:52,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:52,155 INFO:     Epoch: 10
2022-12-31 14:29:53,739 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4859819928805033, 'Total loss': 0.4859819928805033} | train loss {'Reaction outcome loss': 0.43948641326958243, 'Total loss': 0.43948641326958243}
2022-12-31 14:29:53,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:53,739 INFO:     Epoch: 11
2022-12-31 14:29:55,339 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4841547191143036, 'Total loss': 0.4841547191143036} | train loss {'Reaction outcome loss': 0.4345214148289966, 'Total loss': 0.4345214148289966}
2022-12-31 14:29:55,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:55,339 INFO:     Epoch: 12
2022-12-31 14:29:56,958 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46066224773724873, 'Total loss': 0.46066224773724873} | train loss {'Reaction outcome loss': 0.42557265022157753, 'Total loss': 0.42557265022157753}
2022-12-31 14:29:56,959 INFO:     Found new best model at epoch 12
2022-12-31 14:29:56,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:56,959 INFO:     Epoch: 13
2022-12-31 14:29:58,556 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4682411601146062, 'Total loss': 0.4682411601146062} | train loss {'Reaction outcome loss': 0.42749742282568104, 'Total loss': 0.42749742282568104}
2022-12-31 14:29:58,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:29:58,556 INFO:     Epoch: 14
2022-12-31 14:30:00,170 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48332723677158357, 'Total loss': 0.48332723677158357} | train loss {'Reaction outcome loss': 0.4180082147465135, 'Total loss': 0.4180082147465135}
2022-12-31 14:30:00,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:00,170 INFO:     Epoch: 15
2022-12-31 14:30:01,789 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4588555946946144, 'Total loss': 0.4588555946946144} | train loss {'Reaction outcome loss': 0.4105934127349488, 'Total loss': 0.4105934127349488}
2022-12-31 14:30:01,789 INFO:     Found new best model at epoch 15
2022-12-31 14:30:01,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:01,790 INFO:     Epoch: 16
2022-12-31 14:30:03,407 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5025732407967249, 'Total loss': 0.5025732407967249} | train loss {'Reaction outcome loss': 0.4060813854754406, 'Total loss': 0.4060813854754406}
2022-12-31 14:30:03,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:03,407 INFO:     Epoch: 17
2022-12-31 14:30:05,039 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44048724273840584, 'Total loss': 0.44048724273840584} | train loss {'Reaction outcome loss': 0.3954491345551762, 'Total loss': 0.3954491345551762}
2022-12-31 14:30:05,039 INFO:     Found new best model at epoch 17
2022-12-31 14:30:05,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:05,040 INFO:     Epoch: 18
2022-12-31 14:30:06,675 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46125143667062124, 'Total loss': 0.46125143667062124} | train loss {'Reaction outcome loss': 0.3909683390962381, 'Total loss': 0.3909683390962381}
2022-12-31 14:30:06,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:06,675 INFO:     Epoch: 19
2022-12-31 14:30:08,308 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4507049600283305, 'Total loss': 0.4507049600283305} | train loss {'Reaction outcome loss': 0.38695911013514456, 'Total loss': 0.38695911013514456}
2022-12-31 14:30:08,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:08,308 INFO:     Epoch: 20
2022-12-31 14:30:09,920 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4688459495703379, 'Total loss': 0.4688459495703379} | train loss {'Reaction outcome loss': 0.37464335772895463, 'Total loss': 0.37464335772895463}
2022-12-31 14:30:09,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:09,920 INFO:     Epoch: 21
2022-12-31 14:30:11,555 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4762731601794561, 'Total loss': 0.4762731601794561} | train loss {'Reaction outcome loss': 0.37461644318634574, 'Total loss': 0.37461644318634574}
2022-12-31 14:30:11,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:11,555 INFO:     Epoch: 22
2022-12-31 14:30:13,155 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4510659803946813, 'Total loss': 0.4510659803946813} | train loss {'Reaction outcome loss': 0.3682756772550353, 'Total loss': 0.3682756772550353}
2022-12-31 14:30:13,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:13,156 INFO:     Epoch: 23
2022-12-31 14:30:14,786 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47826816042264303, 'Total loss': 0.47826816042264303} | train loss {'Reaction outcome loss': 0.3668003083499026, 'Total loss': 0.3668003083499026}
2022-12-31 14:30:14,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:14,786 INFO:     Epoch: 24
2022-12-31 14:30:16,418 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4456167648235957, 'Total loss': 0.4456167648235957} | train loss {'Reaction outcome loss': 0.35904639410058947, 'Total loss': 0.35904639410058947}
2022-12-31 14:30:16,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:16,419 INFO:     Epoch: 25
2022-12-31 14:30:18,038 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4242609332005183, 'Total loss': 0.4242609332005183} | train loss {'Reaction outcome loss': 0.35317744170553494, 'Total loss': 0.35317744170553494}
2022-12-31 14:30:18,038 INFO:     Found new best model at epoch 25
2022-12-31 14:30:18,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:18,039 INFO:     Epoch: 26
2022-12-31 14:30:19,645 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4832622448603312, 'Total loss': 0.4832622448603312} | train loss {'Reaction outcome loss': 0.3515804197883954, 'Total loss': 0.3515804197883954}
2022-12-31 14:30:19,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:19,646 INFO:     Epoch: 27
2022-12-31 14:30:21,255 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47226961453755695, 'Total loss': 0.47226961453755695} | train loss {'Reaction outcome loss': 0.34196412914099483, 'Total loss': 0.34196412914099483}
2022-12-31 14:30:21,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:21,255 INFO:     Epoch: 28
2022-12-31 14:30:22,894 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46070159673690797, 'Total loss': 0.46070159673690797} | train loss {'Reaction outcome loss': 0.3394992290350207, 'Total loss': 0.3394992290350207}
2022-12-31 14:30:22,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:22,894 INFO:     Epoch: 29
2022-12-31 14:30:24,529 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42118092874685925, 'Total loss': 0.42118092874685925} | train loss {'Reaction outcome loss': 0.3331156127753049, 'Total loss': 0.3331156127753049}
2022-12-31 14:30:24,529 INFO:     Found new best model at epoch 29
2022-12-31 14:30:24,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:24,530 INFO:     Epoch: 30
2022-12-31 14:30:26,146 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44425889253616335, 'Total loss': 0.44425889253616335} | train loss {'Reaction outcome loss': 0.32470423151759337, 'Total loss': 0.32470423151759337}
2022-12-31 14:30:26,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:26,147 INFO:     Epoch: 31
2022-12-31 14:30:27,771 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4496694068113963, 'Total loss': 0.4496694068113963} | train loss {'Reaction outcome loss': 0.3253303612208497, 'Total loss': 0.3253303612208497}
2022-12-31 14:30:27,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:27,772 INFO:     Epoch: 32
2022-12-31 14:30:29,358 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4782561371723811, 'Total loss': 0.4782561371723811} | train loss {'Reaction outcome loss': 0.3198084008410899, 'Total loss': 0.3198084008410899}
2022-12-31 14:30:29,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:29,358 INFO:     Epoch: 33
2022-12-31 14:30:30,951 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44693774580955503, 'Total loss': 0.44693774580955503} | train loss {'Reaction outcome loss': 0.3206116391794525, 'Total loss': 0.3206116391794525}
2022-12-31 14:30:30,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:30,952 INFO:     Epoch: 34
2022-12-31 14:30:32,556 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47315002282460533, 'Total loss': 0.47315002282460533} | train loss {'Reaction outcome loss': 0.3084203003477441, 'Total loss': 0.3084203003477441}
2022-12-31 14:30:32,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:32,557 INFO:     Epoch: 35
2022-12-31 14:30:34,155 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4753074645996094, 'Total loss': 0.4753074645996094} | train loss {'Reaction outcome loss': 0.305012086719057, 'Total loss': 0.305012086719057}
2022-12-31 14:30:34,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:34,155 INFO:     Epoch: 36
2022-12-31 14:30:35,766 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4467158317565918, 'Total loss': 0.4467158317565918} | train loss {'Reaction outcome loss': 0.30131920507300075, 'Total loss': 0.30131920507300075}
2022-12-31 14:30:35,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:35,766 INFO:     Epoch: 37
2022-12-31 14:30:37,357 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5078928351402283, 'Total loss': 0.5078928351402283} | train loss {'Reaction outcome loss': 0.29817654235954705, 'Total loss': 0.29817654235954705}
2022-12-31 14:30:37,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:37,358 INFO:     Epoch: 38
2022-12-31 14:30:38,978 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4258917570114136, 'Total loss': 0.4258917570114136} | train loss {'Reaction outcome loss': 0.2914609740603797, 'Total loss': 0.2914609740603797}
2022-12-31 14:30:38,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:38,979 INFO:     Epoch: 39
2022-12-31 14:30:40,571 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44509526491165163, 'Total loss': 0.44509526491165163} | train loss {'Reaction outcome loss': 0.2933273994683349, 'Total loss': 0.2933273994683349}
2022-12-31 14:30:40,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:40,571 INFO:     Epoch: 40
2022-12-31 14:30:42,183 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5010382533073425, 'Total loss': 0.5010382533073425} | train loss {'Reaction outcome loss': 0.2823493553828584, 'Total loss': 0.2823493553828584}
2022-12-31 14:30:42,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:42,183 INFO:     Epoch: 41
2022-12-31 14:30:43,793 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4702956040700277, 'Total loss': 0.4702956040700277} | train loss {'Reaction outcome loss': 0.2814017782789947, 'Total loss': 0.2814017782789947}
2022-12-31 14:30:43,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:43,793 INFO:     Epoch: 42
2022-12-31 14:30:45,412 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47588985562324526, 'Total loss': 0.47588985562324526} | train loss {'Reaction outcome loss': 0.2773692671780604, 'Total loss': 0.2773692671780604}
2022-12-31 14:30:45,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:45,412 INFO:     Epoch: 43
2022-12-31 14:30:47,015 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4364028851191203, 'Total loss': 0.4364028851191203} | train loss {'Reaction outcome loss': 0.2789822169885474, 'Total loss': 0.2789822169885474}
2022-12-31 14:30:47,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:47,016 INFO:     Epoch: 44
2022-12-31 14:30:48,632 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4037207156419754, 'Total loss': 0.4037207156419754} | train loss {'Reaction outcome loss': 0.2752290988871216, 'Total loss': 0.2752290988871216}
2022-12-31 14:30:48,632 INFO:     Found new best model at epoch 44
2022-12-31 14:30:48,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:48,633 INFO:     Epoch: 45
2022-12-31 14:30:50,266 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46038115620613096, 'Total loss': 0.46038115620613096} | train loss {'Reaction outcome loss': 0.27278440268914195, 'Total loss': 0.27278440268914195}
2022-12-31 14:30:50,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:50,267 INFO:     Epoch: 46
2022-12-31 14:30:51,900 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4248991717894872, 'Total loss': 0.4248991717894872} | train loss {'Reaction outcome loss': 0.27048809883477043, 'Total loss': 0.27048809883477043}
2022-12-31 14:30:51,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:51,900 INFO:     Epoch: 47
2022-12-31 14:30:53,536 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47048869480689365, 'Total loss': 0.47048869480689365} | train loss {'Reaction outcome loss': 0.273126670288561, 'Total loss': 0.273126670288561}
2022-12-31 14:30:53,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:53,537 INFO:     Epoch: 48
2022-12-31 14:30:55,175 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47283613781134287, 'Total loss': 0.47283613781134287} | train loss {'Reaction outcome loss': 0.26792716796435145, 'Total loss': 0.26792716796435145}
2022-12-31 14:30:55,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:55,176 INFO:     Epoch: 49
2022-12-31 14:30:56,793 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4669604202111562, 'Total loss': 0.4669604202111562} | train loss {'Reaction outcome loss': 0.26533376017626187, 'Total loss': 0.26533376017626187}
2022-12-31 14:30:56,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:56,794 INFO:     Epoch: 50
2022-12-31 14:30:58,407 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4674561599890391, 'Total loss': 0.4674561599890391} | train loss {'Reaction outcome loss': 0.2637118766641747, 'Total loss': 0.2637118766641747}
2022-12-31 14:30:58,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:30:58,407 INFO:     Epoch: 51
2022-12-31 14:31:00,041 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4930278102556864, 'Total loss': 0.4930278102556864} | train loss {'Reaction outcome loss': 0.2593744000977408, 'Total loss': 0.2593744000977408}
2022-12-31 14:31:00,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:00,042 INFO:     Epoch: 52
2022-12-31 14:31:01,673 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42456388771533965, 'Total loss': 0.42456388771533965} | train loss {'Reaction outcome loss': 0.2545713136502861, 'Total loss': 0.2545713136502861}
2022-12-31 14:31:01,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:01,673 INFO:     Epoch: 53
2022-12-31 14:31:03,306 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4534802863995234, 'Total loss': 0.4534802863995234} | train loss {'Reaction outcome loss': 0.25803185159163755, 'Total loss': 0.25803185159163755}
2022-12-31 14:31:03,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:03,306 INFO:     Epoch: 54
2022-12-31 14:31:04,897 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44364223976929984, 'Total loss': 0.44364223976929984} | train loss {'Reaction outcome loss': 0.2547774392717185, 'Total loss': 0.2547774392717185}
2022-12-31 14:31:04,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:04,897 INFO:     Epoch: 55
2022-12-31 14:31:06,514 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4888541032870611, 'Total loss': 0.4888541032870611} | train loss {'Reaction outcome loss': 0.2469433487943598, 'Total loss': 0.2469433487943598}
2022-12-31 14:31:06,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:06,514 INFO:     Epoch: 56
2022-12-31 14:31:08,155 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4982974340518316, 'Total loss': 0.4982974340518316} | train loss {'Reaction outcome loss': 0.24809906241504381, 'Total loss': 0.24809906241504381}
2022-12-31 14:31:08,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:08,155 INFO:     Epoch: 57
2022-12-31 14:31:09,793 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45598647197087605, 'Total loss': 0.45598647197087605} | train loss {'Reaction outcome loss': 0.24585804744304096, 'Total loss': 0.24585804744304096}
2022-12-31 14:31:09,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:09,794 INFO:     Epoch: 58
2022-12-31 14:31:11,428 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4372851034005483, 'Total loss': 0.4372851034005483} | train loss {'Reaction outcome loss': 0.24272928745859731, 'Total loss': 0.24272928745859731}
2022-12-31 14:31:11,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:11,428 INFO:     Epoch: 59
2022-12-31 14:31:13,064 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48045833508173624, 'Total loss': 0.48045833508173624} | train loss {'Reaction outcome loss': 0.2396491614788988, 'Total loss': 0.2396491614788988}
2022-12-31 14:31:13,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:13,064 INFO:     Epoch: 60
2022-12-31 14:31:14,678 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44911333719889324, 'Total loss': 0.44911333719889324} | train loss {'Reaction outcome loss': 0.2421306882216765, 'Total loss': 0.2421306882216765}
2022-12-31 14:31:14,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:14,678 INFO:     Epoch: 61
2022-12-31 14:31:16,266 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4906982292731603, 'Total loss': 0.4906982292731603} | train loss {'Reaction outcome loss': 0.23867534235609275, 'Total loss': 0.23867534235609275}
2022-12-31 14:31:16,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:16,266 INFO:     Epoch: 62
2022-12-31 14:31:17,889 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4676216185092926, 'Total loss': 0.4676216185092926} | train loss {'Reaction outcome loss': 0.23679073460155378, 'Total loss': 0.23679073460155378}
2022-12-31 14:31:17,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:17,889 INFO:     Epoch: 63
2022-12-31 14:31:19,513 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4796838104724884, 'Total loss': 0.4796838104724884} | train loss {'Reaction outcome loss': 0.2430752079090933, 'Total loss': 0.2430752079090933}
2022-12-31 14:31:19,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:19,513 INFO:     Epoch: 64
2022-12-31 14:31:21,120 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4589889188607534, 'Total loss': 0.4589889188607534} | train loss {'Reaction outcome loss': 0.23299832251874636, 'Total loss': 0.23299832251874636}
2022-12-31 14:31:21,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:21,120 INFO:     Epoch: 65
2022-12-31 14:31:22,704 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5147867778937022, 'Total loss': 0.5147867778937022} | train loss {'Reaction outcome loss': 0.23112239802840853, 'Total loss': 0.23112239802840853}
2022-12-31 14:31:22,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:22,704 INFO:     Epoch: 66
2022-12-31 14:31:24,295 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45675821900367736, 'Total loss': 0.45675821900367736} | train loss {'Reaction outcome loss': 0.22457493553413962, 'Total loss': 0.22457493553413962}
2022-12-31 14:31:24,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:24,295 INFO:     Epoch: 67
2022-12-31 14:31:25,882 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44539947956800463, 'Total loss': 0.44539947956800463} | train loss {'Reaction outcome loss': 0.23407235534956855, 'Total loss': 0.23407235534956855}
2022-12-31 14:31:25,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:25,883 INFO:     Epoch: 68
2022-12-31 14:31:27,518 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5041726658741633, 'Total loss': 0.5041726658741633} | train loss {'Reaction outcome loss': 0.2323742452261113, 'Total loss': 0.2323742452261113}
2022-12-31 14:31:27,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:27,519 INFO:     Epoch: 69
2022-12-31 14:31:29,135 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48394855062166847, 'Total loss': 0.48394855062166847} | train loss {'Reaction outcome loss': 0.23321328922956638, 'Total loss': 0.23321328922956638}
2022-12-31 14:31:29,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:29,135 INFO:     Epoch: 70
2022-12-31 14:31:30,743 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46373676260312396, 'Total loss': 0.46373676260312396} | train loss {'Reaction outcome loss': 0.224730488538307, 'Total loss': 0.224730488538307}
2022-12-31 14:31:30,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:30,744 INFO:     Epoch: 71
2022-12-31 14:31:32,354 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47848436534404754, 'Total loss': 0.47848436534404754} | train loss {'Reaction outcome loss': 0.22389310970902443, 'Total loss': 0.22389310970902443}
2022-12-31 14:31:32,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:32,355 INFO:     Epoch: 72
2022-12-31 14:31:33,937 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47237211267153423, 'Total loss': 0.47237211267153423} | train loss {'Reaction outcome loss': 0.22039000974138723, 'Total loss': 0.22039000974138723}
2022-12-31 14:31:33,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:33,938 INFO:     Epoch: 73
2022-12-31 14:31:35,535 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.452351642648379, 'Total loss': 0.452351642648379} | train loss {'Reaction outcome loss': 0.22803312972405532, 'Total loss': 0.22803312972405532}
2022-12-31 14:31:35,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:35,535 INFO:     Epoch: 74
2022-12-31 14:31:37,169 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4672722746928533, 'Total loss': 0.4672722746928533} | train loss {'Reaction outcome loss': 0.22271594881032505, 'Total loss': 0.22271594881032505}
2022-12-31 14:31:37,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:37,170 INFO:     Epoch: 75
2022-12-31 14:31:38,799 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.489010485013326, 'Total loss': 0.489010485013326} | train loss {'Reaction outcome loss': 0.21795494895238077, 'Total loss': 0.21795494895238077}
2022-12-31 14:31:38,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:38,800 INFO:     Epoch: 76
2022-12-31 14:31:40,441 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4929245442152023, 'Total loss': 0.4929245442152023} | train loss {'Reaction outcome loss': 0.21865292949887521, 'Total loss': 0.21865292949887521}
2022-12-31 14:31:40,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:40,441 INFO:     Epoch: 77
2022-12-31 14:31:42,059 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44326421320438386, 'Total loss': 0.44326421320438386} | train loss {'Reaction outcome loss': 0.22202347034085407, 'Total loss': 0.22202347034085407}
2022-12-31 14:31:42,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:42,059 INFO:     Epoch: 78
2022-12-31 14:31:43,661 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46109210650126137, 'Total loss': 0.46109210650126137} | train loss {'Reaction outcome loss': 0.22163275679587013, 'Total loss': 0.22163275679587013}
2022-12-31 14:31:43,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:43,661 INFO:     Epoch: 79
2022-12-31 14:31:45,269 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4443463961283366, 'Total loss': 0.4443463961283366} | train loss {'Reaction outcome loss': 0.2112309340333199, 'Total loss': 0.2112309340333199}
2022-12-31 14:31:45,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:45,269 INFO:     Epoch: 80
2022-12-31 14:31:46,886 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4804677337408066, 'Total loss': 0.4804677337408066} | train loss {'Reaction outcome loss': 0.20763470242683688, 'Total loss': 0.20763470242683688}
2022-12-31 14:31:46,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:46,886 INFO:     Epoch: 81
2022-12-31 14:31:48,486 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4559241731961568, 'Total loss': 0.4559241731961568} | train loss {'Reaction outcome loss': 0.2113128347308749, 'Total loss': 0.2113128347308749}
2022-12-31 14:31:48,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:48,486 INFO:     Epoch: 82
2022-12-31 14:31:50,072 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5278773347536723, 'Total loss': 0.5278773347536723} | train loss {'Reaction outcome loss': 0.21278895739547526, 'Total loss': 0.21278895739547526}
2022-12-31 14:31:50,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:50,072 INFO:     Epoch: 83
2022-12-31 14:31:51,680 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45439106424649556, 'Total loss': 0.45439106424649556} | train loss {'Reaction outcome loss': 0.21020179929510846, 'Total loss': 0.21020179929510846}
2022-12-31 14:31:51,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:51,680 INFO:     Epoch: 84
2022-12-31 14:31:53,292 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4817248453696569, 'Total loss': 0.4817248453696569} | train loss {'Reaction outcome loss': 0.20567159626605738, 'Total loss': 0.20567159626605738}
2022-12-31 14:31:53,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:53,292 INFO:     Epoch: 85
2022-12-31 14:31:54,921 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42806699872016907, 'Total loss': 0.42806699872016907} | train loss {'Reaction outcome loss': 0.22078342011783028, 'Total loss': 0.22078342011783028}
2022-12-31 14:31:54,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:54,921 INFO:     Epoch: 86
2022-12-31 14:31:56,540 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.453921976685524, 'Total loss': 0.453921976685524} | train loss {'Reaction outcome loss': 0.2058779389196395, 'Total loss': 0.2058779389196395}
2022-12-31 14:31:56,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:56,540 INFO:     Epoch: 87
2022-12-31 14:31:58,162 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4739266296227773, 'Total loss': 0.4739266296227773} | train loss {'Reaction outcome loss': 0.20318319112823827, 'Total loss': 0.20318319112823827}
2022-12-31 14:31:58,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:58,163 INFO:     Epoch: 88
2022-12-31 14:31:59,759 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4725387990474701, 'Total loss': 0.4725387990474701} | train loss {'Reaction outcome loss': 0.20280399091242657, 'Total loss': 0.20280399091242657}
2022-12-31 14:31:59,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:31:59,759 INFO:     Epoch: 89
2022-12-31 14:32:01,368 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4354760895172755, 'Total loss': 0.4354760895172755} | train loss {'Reaction outcome loss': 0.20597545429384403, 'Total loss': 0.20597545429384403}
2022-12-31 14:32:01,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:01,369 INFO:     Epoch: 90
2022-12-31 14:32:02,977 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5756795058647791, 'Total loss': 0.5756795058647791} | train loss {'Reaction outcome loss': 0.200561861939266, 'Total loss': 0.200561861939266}
2022-12-31 14:32:02,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:02,977 INFO:     Epoch: 91
2022-12-31 14:32:04,582 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4689769446849823, 'Total loss': 0.4689769446849823} | train loss {'Reaction outcome loss': 0.2058262899246094, 'Total loss': 0.2058262899246094}
2022-12-31 14:32:04,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:04,582 INFO:     Epoch: 92
2022-12-31 14:32:06,202 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49847444196542107, 'Total loss': 0.49847444196542107} | train loss {'Reaction outcome loss': 0.20671713001767758, 'Total loss': 0.20671713001767758}
2022-12-31 14:32:06,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:06,202 INFO:     Epoch: 93
2022-12-31 14:32:07,802 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5122800588607788, 'Total loss': 0.5122800588607788} | train loss {'Reaction outcome loss': 0.2018368646985151, 'Total loss': 0.2018368646985151}
2022-12-31 14:32:07,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:07,803 INFO:     Epoch: 94
2022-12-31 14:32:09,394 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4613188564777374, 'Total loss': 0.4613188564777374} | train loss {'Reaction outcome loss': 0.20438070994305568, 'Total loss': 0.20438070994305568}
2022-12-31 14:32:09,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:09,394 INFO:     Epoch: 95
2022-12-31 14:32:10,986 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5072735081116359, 'Total loss': 0.5072735081116359} | train loss {'Reaction outcome loss': 0.2012564102119773, 'Total loss': 0.2012564102119773}
2022-12-31 14:32:10,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:10,986 INFO:     Epoch: 96
2022-12-31 14:32:12,619 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5157818416754405, 'Total loss': 0.5157818416754405} | train loss {'Reaction outcome loss': 0.20247052425015583, 'Total loss': 0.20247052425015583}
2022-12-31 14:32:12,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:12,620 INFO:     Epoch: 97
2022-12-31 14:32:14,221 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5196040138602257, 'Total loss': 0.5196040138602257} | train loss {'Reaction outcome loss': 0.19824788937290763, 'Total loss': 0.19824788937290763}
2022-12-31 14:32:14,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:14,221 INFO:     Epoch: 98
2022-12-31 14:32:15,830 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4611161589622498, 'Total loss': 0.4611161589622498} | train loss {'Reaction outcome loss': 0.1940048314957288, 'Total loss': 0.1940048314957288}
2022-12-31 14:32:15,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:15,830 INFO:     Epoch: 99
2022-12-31 14:32:17,416 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4696891923745473, 'Total loss': 0.4696891923745473} | train loss {'Reaction outcome loss': 0.19929614241649635, 'Total loss': 0.19929614241649635}
2022-12-31 14:32:17,416 INFO:     Best model found after epoch 45 of 100.
2022-12-31 14:32:17,417 INFO:   Done with stage: TRAINING
2022-12-31 14:32:17,417 INFO:   Starting stage: EVALUATION
2022-12-31 14:32:17,550 INFO:   Done with stage: EVALUATION
2022-12-31 14:32:17,550 INFO:   Leaving out SEQ value Fold_2
2022-12-31 14:32:17,563 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 14:32:17,563 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:32:18,205 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:32:18,205 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:32:18,273 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:32:18,273 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:32:18,273 INFO:     No hyperparam tuning for this model
2022-12-31 14:32:18,273 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:32:18,273 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:32:18,274 INFO:     None feature selector for col prot
2022-12-31 14:32:18,274 INFO:     None feature selector for col prot
2022-12-31 14:32:18,274 INFO:     None feature selector for col prot
2022-12-31 14:32:18,275 INFO:     None feature selector for col chem
2022-12-31 14:32:18,275 INFO:     None feature selector for col chem
2022-12-31 14:32:18,275 INFO:     None feature selector for col chem
2022-12-31 14:32:18,275 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:32:18,275 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:32:18,277 INFO:     Number of params in model 223921
2022-12-31 14:32:18,280 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:32:18,280 INFO:   Starting stage: TRAINING
2022-12-31 14:32:18,326 INFO:     Val loss before train {'Reaction outcome loss': 0.8169081568717956, 'Total loss': 0.8169081568717956}
2022-12-31 14:32:18,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:18,326 INFO:     Epoch: 0
2022-12-31 14:32:19,906 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5829243659973145, 'Total loss': 0.5829243659973145} | train loss {'Reaction outcome loss': 0.8286661052660191, 'Total loss': 0.8286661052660191}
2022-12-31 14:32:19,907 INFO:     Found new best model at epoch 0
2022-12-31 14:32:19,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:19,908 INFO:     Epoch: 1
2022-12-31 14:32:21,500 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5112713098526, 'Total loss': 0.5112713098526} | train loss {'Reaction outcome loss': 0.6093753890130983, 'Total loss': 0.6093753890130983}
2022-12-31 14:32:21,501 INFO:     Found new best model at epoch 1
2022-12-31 14:32:21,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:21,502 INFO:     Epoch: 2
2022-12-31 14:32:23,097 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5069335679213206, 'Total loss': 0.5069335679213206} | train loss {'Reaction outcome loss': 0.5349634770071987, 'Total loss': 0.5349634770071987}
2022-12-31 14:32:23,098 INFO:     Found new best model at epoch 2
2022-12-31 14:32:23,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:23,099 INFO:     Epoch: 3
2022-12-31 14:32:24,685 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5016277407606443, 'Total loss': 0.5016277407606443} | train loss {'Reaction outcome loss': 0.5094395116681144, 'Total loss': 0.5094395116681144}
2022-12-31 14:32:24,685 INFO:     Found new best model at epoch 3
2022-12-31 14:32:24,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:24,686 INFO:     Epoch: 4
2022-12-31 14:32:26,258 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4947206020355225, 'Total loss': 0.4947206020355225} | train loss {'Reaction outcome loss': 0.498935769929554, 'Total loss': 0.498935769929554}
2022-12-31 14:32:26,258 INFO:     Found new best model at epoch 4
2022-12-31 14:32:26,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:26,259 INFO:     Epoch: 5
2022-12-31 14:32:27,884 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5112006068229675, 'Total loss': 0.5112006068229675} | train loss {'Reaction outcome loss': 0.4808698523612249, 'Total loss': 0.4808698523612249}
2022-12-31 14:32:27,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:27,885 INFO:     Epoch: 6
2022-12-31 14:32:29,477 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4853303670883179, 'Total loss': 0.4853303670883179} | train loss {'Reaction outcome loss': 0.4728449232136019, 'Total loss': 0.4728449232136019}
2022-12-31 14:32:29,477 INFO:     Found new best model at epoch 6
2022-12-31 14:32:29,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:29,478 INFO:     Epoch: 7
2022-12-31 14:32:31,118 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48896385033925377, 'Total loss': 0.48896385033925377} | train loss {'Reaction outcome loss': 0.46896567684171836, 'Total loss': 0.46896567684171836}
2022-12-31 14:32:31,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:31,119 INFO:     Epoch: 8
2022-12-31 14:32:32,726 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5025685131549835, 'Total loss': 0.5025685131549835} | train loss {'Reaction outcome loss': 0.46421544559490985, 'Total loss': 0.46421544559490985}
2022-12-31 14:32:32,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:32,727 INFO:     Epoch: 9
2022-12-31 14:32:34,321 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4857076108455658, 'Total loss': 0.4857076108455658} | train loss {'Reaction outcome loss': 0.45422863769225585, 'Total loss': 0.45422863769225585}
2022-12-31 14:32:34,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:34,321 INFO:     Epoch: 10
2022-12-31 14:32:35,916 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49402671058972675, 'Total loss': 0.49402671058972675} | train loss {'Reaction outcome loss': 0.4414104156660073, 'Total loss': 0.4414104156660073}
2022-12-31 14:32:35,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:35,916 INFO:     Epoch: 11
2022-12-31 14:32:37,502 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47982633610566455, 'Total loss': 0.47982633610566455} | train loss {'Reaction outcome loss': 0.4429014427485047, 'Total loss': 0.4429014427485047}
2022-12-31 14:32:37,503 INFO:     Found new best model at epoch 11
2022-12-31 14:32:37,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:37,503 INFO:     Epoch: 12
2022-12-31 14:32:39,113 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49757036566734314, 'Total loss': 0.49757036566734314} | train loss {'Reaction outcome loss': 0.43662382791930937, 'Total loss': 0.43662382791930937}
2022-12-31 14:32:39,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:39,114 INFO:     Epoch: 13
2022-12-31 14:32:40,724 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46729436963796617, 'Total loss': 0.46729436963796617} | train loss {'Reaction outcome loss': 0.4300421642160023, 'Total loss': 0.4300421642160023}
2022-12-31 14:32:40,724 INFO:     Found new best model at epoch 13
2022-12-31 14:32:40,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:40,725 INFO:     Epoch: 14
2022-12-31 14:32:42,322 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.464868825674057, 'Total loss': 0.464868825674057} | train loss {'Reaction outcome loss': 0.4210933058798968, 'Total loss': 0.4210933058798968}
2022-12-31 14:32:42,322 INFO:     Found new best model at epoch 14
2022-12-31 14:32:42,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:42,323 INFO:     Epoch: 15
2022-12-31 14:32:43,920 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48110550343990327, 'Total loss': 0.48110550343990327} | train loss {'Reaction outcome loss': 0.41568608996850664, 'Total loss': 0.41568608996850664}
2022-12-31 14:32:43,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:43,920 INFO:     Epoch: 16
2022-12-31 14:32:45,529 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4828404535849889, 'Total loss': 0.4828404535849889} | train loss {'Reaction outcome loss': 0.4185696487407108, 'Total loss': 0.4185696487407108}
2022-12-31 14:32:45,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:45,530 INFO:     Epoch: 17
2022-12-31 14:32:47,111 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4575563907623291, 'Total loss': 0.4575563907623291} | train loss {'Reaction outcome loss': 0.4067119918900095, 'Total loss': 0.4067119918900095}
2022-12-31 14:32:47,111 INFO:     Found new best model at epoch 17
2022-12-31 14:32:47,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:47,112 INFO:     Epoch: 18
2022-12-31 14:32:48,710 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4707583159208298, 'Total loss': 0.4707583159208298} | train loss {'Reaction outcome loss': 0.3987267722031136, 'Total loss': 0.3987267722031136}
2022-12-31 14:32:48,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:48,710 INFO:     Epoch: 19
2022-12-31 14:32:50,323 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44467796583970387, 'Total loss': 0.44467796583970387} | train loss {'Reaction outcome loss': 0.4014336983690332, 'Total loss': 0.4014336983690332}
2022-12-31 14:32:50,323 INFO:     Found new best model at epoch 19
2022-12-31 14:32:50,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:50,324 INFO:     Epoch: 20
2022-12-31 14:32:51,918 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4378301382064819, 'Total loss': 0.4378301382064819} | train loss {'Reaction outcome loss': 0.3898658975685909, 'Total loss': 0.3898658975685909}
2022-12-31 14:32:51,918 INFO:     Found new best model at epoch 20
2022-12-31 14:32:51,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:51,919 INFO:     Epoch: 21
2022-12-31 14:32:53,500 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4734198520580927, 'Total loss': 0.4734198520580927} | train loss {'Reaction outcome loss': 0.38130511327104255, 'Total loss': 0.38130511327104255}
2022-12-31 14:32:53,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:53,501 INFO:     Epoch: 22
2022-12-31 14:32:55,102 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4397778401772181, 'Total loss': 0.4397778401772181} | train loss {'Reaction outcome loss': 0.3798937032019699, 'Total loss': 0.3798937032019699}
2022-12-31 14:32:55,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:55,102 INFO:     Epoch: 23
2022-12-31 14:32:56,689 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43958076735337576, 'Total loss': 0.43958076735337576} | train loss {'Reaction outcome loss': 0.3759652664919039, 'Total loss': 0.3759652664919039}
2022-12-31 14:32:56,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:56,690 INFO:     Epoch: 24
2022-12-31 14:32:58,317 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4558059051632881, 'Total loss': 0.4558059051632881} | train loss {'Reaction outcome loss': 0.3682656514393541, 'Total loss': 0.3682656514393541}
2022-12-31 14:32:58,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:58,317 INFO:     Epoch: 25
2022-12-31 14:32:59,930 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4412263721227646, 'Total loss': 0.4412263721227646} | train loss {'Reaction outcome loss': 0.3647514160299476, 'Total loss': 0.3647514160299476}
2022-12-31 14:32:59,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:32:59,931 INFO:     Epoch: 26
2022-12-31 14:33:01,531 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43977006276448566, 'Total loss': 0.43977006276448566} | train loss {'Reaction outcome loss': 0.36161155245461307, 'Total loss': 0.36161155245461307}
2022-12-31 14:33:01,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:01,531 INFO:     Epoch: 27
2022-12-31 14:33:03,118 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43553603887557985, 'Total loss': 0.43553603887557985} | train loss {'Reaction outcome loss': 0.3488073148611155, 'Total loss': 0.3488073148611155}
2022-12-31 14:33:03,118 INFO:     Found new best model at epoch 27
2022-12-31 14:33:03,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:03,119 INFO:     Epoch: 28
2022-12-31 14:33:04,702 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46878875692685446, 'Total loss': 0.46878875692685446} | train loss {'Reaction outcome loss': 0.3488868915445202, 'Total loss': 0.3488868915445202}
2022-12-31 14:33:04,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:04,702 INFO:     Epoch: 29
2022-12-31 14:33:06,299 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4368375321229299, 'Total loss': 0.4368375321229299} | train loss {'Reaction outcome loss': 0.34552392361501416, 'Total loss': 0.34552392361501416}
2022-12-31 14:33:06,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:06,299 INFO:     Epoch: 30
2022-12-31 14:33:07,893 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4241514394680659, 'Total loss': 0.4241514394680659} | train loss {'Reaction outcome loss': 0.33810932609515315, 'Total loss': 0.33810932609515315}
2022-12-31 14:33:07,894 INFO:     Found new best model at epoch 30
2022-12-31 14:33:07,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:07,895 INFO:     Epoch: 31
2022-12-31 14:33:09,490 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45661421567201615, 'Total loss': 0.45661421567201615} | train loss {'Reaction outcome loss': 0.3441380142019345, 'Total loss': 0.3441380142019345}
2022-12-31 14:33:09,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:09,490 INFO:     Epoch: 32
2022-12-31 14:33:11,089 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42677798867225647, 'Total loss': 0.42677798867225647} | train loss {'Reaction outcome loss': 0.3324138921149921, 'Total loss': 0.3324138921149921}
2022-12-31 14:33:11,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:11,089 INFO:     Epoch: 33
2022-12-31 14:33:12,691 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4292785286903381, 'Total loss': 0.4292785286903381} | train loss {'Reaction outcome loss': 0.3303321944856709, 'Total loss': 0.3303321944856709}
2022-12-31 14:33:12,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:12,691 INFO:     Epoch: 34
2022-12-31 14:33:14,273 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4088700527946154, 'Total loss': 0.4088700527946154} | train loss {'Reaction outcome loss': 0.32014602072018405, 'Total loss': 0.32014602072018405}
2022-12-31 14:33:14,274 INFO:     Found new best model at epoch 34
2022-12-31 14:33:14,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:14,275 INFO:     Epoch: 35
2022-12-31 14:33:15,877 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47971152464548744, 'Total loss': 0.47971152464548744} | train loss {'Reaction outcome loss': 0.3212289855757476, 'Total loss': 0.3212289855757476}
2022-12-31 14:33:15,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:15,877 INFO:     Epoch: 36
2022-12-31 14:33:17,493 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43333504324158034, 'Total loss': 0.43333504324158034} | train loss {'Reaction outcome loss': 0.3167449454794, 'Total loss': 0.3167449454794}
2022-12-31 14:33:17,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:17,493 INFO:     Epoch: 37
2022-12-31 14:33:19,119 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4826482782761256, 'Total loss': 0.4826482782761256} | train loss {'Reaction outcome loss': 0.30655177363327574, 'Total loss': 0.30655177363327574}
2022-12-31 14:33:19,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:19,119 INFO:     Epoch: 38
2022-12-31 14:33:20,708 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4493519286314646, 'Total loss': 0.4493519286314646} | train loss {'Reaction outcome loss': 0.3067519281864603, 'Total loss': 0.3067519281864603}
2022-12-31 14:33:20,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:20,708 INFO:     Epoch: 39
2022-12-31 14:33:22,299 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4227230240901311, 'Total loss': 0.4227230240901311} | train loss {'Reaction outcome loss': 0.30900724909026106, 'Total loss': 0.30900724909026106}
2022-12-31 14:33:22,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:22,299 INFO:     Epoch: 40
2022-12-31 14:33:23,880 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3937290353079637, 'Total loss': 0.3937290353079637} | train loss {'Reaction outcome loss': 0.3046237195367778, 'Total loss': 0.3046237195367778}
2022-12-31 14:33:23,880 INFO:     Found new best model at epoch 40
2022-12-31 14:33:23,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:23,881 INFO:     Epoch: 41
2022-12-31 14:33:25,477 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4515993674596151, 'Total loss': 0.4515993674596151} | train loss {'Reaction outcome loss': 0.29297689475364735, 'Total loss': 0.29297689475364735}
2022-12-31 14:33:25,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:25,477 INFO:     Epoch: 42
2022-12-31 14:33:27,073 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46209535201390584, 'Total loss': 0.46209535201390584} | train loss {'Reaction outcome loss': 0.2889115475254618, 'Total loss': 0.2889115475254618}
2022-12-31 14:33:27,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:27,074 INFO:     Epoch: 43
2022-12-31 14:33:28,668 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4243131975332896, 'Total loss': 0.4243131975332896} | train loss {'Reaction outcome loss': 0.3010739855086192, 'Total loss': 0.3010739855086192}
2022-12-31 14:33:28,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:28,668 INFO:     Epoch: 44
2022-12-31 14:33:30,254 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41117007633050284, 'Total loss': 0.41117007633050284} | train loss {'Reaction outcome loss': 0.28561105187845864, 'Total loss': 0.28561105187845864}
2022-12-31 14:33:30,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:30,254 INFO:     Epoch: 45
2022-12-31 14:33:31,862 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44792921940485636, 'Total loss': 0.44792921940485636} | train loss {'Reaction outcome loss': 0.2862033634258932, 'Total loss': 0.2862033634258932}
2022-12-31 14:33:31,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:31,863 INFO:     Epoch: 46
2022-12-31 14:33:33,511 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40643459757169087, 'Total loss': 0.40643459757169087} | train loss {'Reaction outcome loss': 0.2831295522223244, 'Total loss': 0.2831295522223244}
2022-12-31 14:33:33,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:33,512 INFO:     Epoch: 47
2022-12-31 14:33:35,148 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41924987733364105, 'Total loss': 0.41924987733364105} | train loss {'Reaction outcome loss': 0.28289324153665, 'Total loss': 0.28289324153665}
2022-12-31 14:33:35,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:35,148 INFO:     Epoch: 48
2022-12-31 14:33:36,775 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43885205686092377, 'Total loss': 0.43885205686092377} | train loss {'Reaction outcome loss': 0.2800589832084956, 'Total loss': 0.2800589832084956}
2022-12-31 14:33:36,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:36,776 INFO:     Epoch: 49
2022-12-31 14:33:38,368 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4150925825039546, 'Total loss': 0.4150925825039546} | train loss {'Reaction outcome loss': 0.27182011841881626, 'Total loss': 0.27182011841881626}
2022-12-31 14:33:38,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:38,369 INFO:     Epoch: 50
2022-12-31 14:33:39,962 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42830299735069277, 'Total loss': 0.42830299735069277} | train loss {'Reaction outcome loss': 0.2676487488624377, 'Total loss': 0.2676487488624377}
2022-12-31 14:33:39,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:39,962 INFO:     Epoch: 51
2022-12-31 14:33:41,575 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4653218040863673, 'Total loss': 0.4653218040863673} | train loss {'Reaction outcome loss': 0.2695875395116679, 'Total loss': 0.2695875395116679}
2022-12-31 14:33:41,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:41,576 INFO:     Epoch: 52
2022-12-31 14:33:43,212 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.411271137992541, 'Total loss': 0.411271137992541} | train loss {'Reaction outcome loss': 0.26692877167105783, 'Total loss': 0.26692877167105783}
2022-12-31 14:33:43,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:43,212 INFO:     Epoch: 53
2022-12-31 14:33:44,840 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3924660988152027, 'Total loss': 0.3924660988152027} | train loss {'Reaction outcome loss': 0.2694943625711914, 'Total loss': 0.2694943625711914}
2022-12-31 14:33:44,841 INFO:     Found new best model at epoch 53
2022-12-31 14:33:44,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:44,842 INFO:     Epoch: 54
2022-12-31 14:33:46,428 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4314031114180883, 'Total loss': 0.4314031114180883} | train loss {'Reaction outcome loss': 0.25945254447682325, 'Total loss': 0.25945254447682325}
2022-12-31 14:33:46,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:46,428 INFO:     Epoch: 55
2022-12-31 14:33:48,036 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4483006939291954, 'Total loss': 0.4483006939291954} | train loss {'Reaction outcome loss': 0.25469968628970696, 'Total loss': 0.25469968628970696}
2022-12-31 14:33:48,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:48,037 INFO:     Epoch: 56
2022-12-31 14:33:49,644 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4419903467098872, 'Total loss': 0.4419903467098872} | train loss {'Reaction outcome loss': 0.2591303720824666, 'Total loss': 0.2591303720824666}
2022-12-31 14:33:49,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:49,645 INFO:     Epoch: 57
2022-12-31 14:33:51,248 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42881785134474437, 'Total loss': 0.42881785134474437} | train loss {'Reaction outcome loss': 0.25307524995707764, 'Total loss': 0.25307524995707764}
2022-12-31 14:33:51,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:51,248 INFO:     Epoch: 58
2022-12-31 14:33:52,874 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48157772024472556, 'Total loss': 0.48157772024472556} | train loss {'Reaction outcome loss': 0.2585767519834277, 'Total loss': 0.2585767519834277}
2022-12-31 14:33:52,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:52,874 INFO:     Epoch: 59
2022-12-31 14:33:54,494 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43740698297818503, 'Total loss': 0.43740698297818503} | train loss {'Reaction outcome loss': 0.2581783172029715, 'Total loss': 0.2581783172029715}
2022-12-31 14:33:54,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:54,494 INFO:     Epoch: 60
2022-12-31 14:33:56,097 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44270724256833394, 'Total loss': 0.44270724256833394} | train loss {'Reaction outcome loss': 0.246945620401875, 'Total loss': 0.246945620401875}
2022-12-31 14:33:56,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:56,097 INFO:     Epoch: 61
2022-12-31 14:33:57,679 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46097747087478635, 'Total loss': 0.46097747087478635} | train loss {'Reaction outcome loss': 0.2467967227319658, 'Total loss': 0.2467967227319658}
2022-12-31 14:33:57,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:57,680 INFO:     Epoch: 62
2022-12-31 14:33:59,258 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45371245642503105, 'Total loss': 0.45371245642503105} | train loss {'Reaction outcome loss': 0.24787702165789657, 'Total loss': 0.24787702165789657}
2022-12-31 14:33:59,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:33:59,259 INFO:     Epoch: 63
2022-12-31 14:34:00,851 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43884945611159004, 'Total loss': 0.43884945611159004} | train loss {'Reaction outcome loss': 0.242080209619833, 'Total loss': 0.242080209619833}
2022-12-31 14:34:00,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:00,851 INFO:     Epoch: 64
2022-12-31 14:34:02,440 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4764376044273376, 'Total loss': 0.4764376044273376} | train loss {'Reaction outcome loss': 0.24430849092360926, 'Total loss': 0.24430849092360926}
2022-12-31 14:34:02,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:02,440 INFO:     Epoch: 65
2022-12-31 14:34:04,066 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4509617745876312, 'Total loss': 0.4509617745876312} | train loss {'Reaction outcome loss': 0.2397341621193639, 'Total loss': 0.2397341621193639}
2022-12-31 14:34:04,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:04,066 INFO:     Epoch: 66
2022-12-31 14:34:05,696 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43861290415128074, 'Total loss': 0.43861290415128074} | train loss {'Reaction outcome loss': 0.24001079045181528, 'Total loss': 0.24001079045181528}
2022-12-31 14:34:05,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:05,696 INFO:     Epoch: 67
2022-12-31 14:34:07,303 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4347892145315806, 'Total loss': 0.4347892145315806} | train loss {'Reaction outcome loss': 0.2378231270354746, 'Total loss': 0.2378231270354746}
2022-12-31 14:34:07,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:07,303 INFO:     Epoch: 68
2022-12-31 14:34:08,893 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47775914271672565, 'Total loss': 0.47775914271672565} | train loss {'Reaction outcome loss': 0.23714758768241048, 'Total loss': 0.23714758768241048}
2022-12-31 14:34:08,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:08,894 INFO:     Epoch: 69
2022-12-31 14:34:10,483 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4551212390263875, 'Total loss': 0.4551212390263875} | train loss {'Reaction outcome loss': 0.23537376203877858, 'Total loss': 0.23537376203877858}
2022-12-31 14:34:10,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:10,483 INFO:     Epoch: 70
2022-12-31 14:34:12,071 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44743868509928386, 'Total loss': 0.44743868509928386} | train loss {'Reaction outcome loss': 0.2336682191616668, 'Total loss': 0.2336682191616668}
2022-12-31 14:34:12,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:12,072 INFO:     Epoch: 71
2022-12-31 14:34:13,659 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4479858338832855, 'Total loss': 0.4479858338832855} | train loss {'Reaction outcome loss': 0.23903553376158515, 'Total loss': 0.23903553376158515}
2022-12-31 14:34:13,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:13,660 INFO:     Epoch: 72
2022-12-31 14:34:15,231 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44035046696662905, 'Total loss': 0.44035046696662905} | train loss {'Reaction outcome loss': 0.2294623490811868, 'Total loss': 0.2294623490811868}
2022-12-31 14:34:15,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:15,232 INFO:     Epoch: 73
2022-12-31 14:34:16,809 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41643341978391013, 'Total loss': 0.41643341978391013} | train loss {'Reaction outcome loss': 0.2312003276941977, 'Total loss': 0.2312003276941977}
2022-12-31 14:34:16,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:16,809 INFO:     Epoch: 74
2022-12-31 14:34:18,391 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45050094922383627, 'Total loss': 0.45050094922383627} | train loss {'Reaction outcome loss': 0.23063451231835963, 'Total loss': 0.23063451231835963}
2022-12-31 14:34:18,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:18,392 INFO:     Epoch: 75
2022-12-31 14:34:19,983 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4119364539782206, 'Total loss': 0.4119364539782206} | train loss {'Reaction outcome loss': 0.226484912164482, 'Total loss': 0.226484912164482}
2022-12-31 14:34:19,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:19,983 INFO:     Epoch: 76
2022-12-31 14:34:21,575 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4347386380036672, 'Total loss': 0.4347386380036672} | train loss {'Reaction outcome loss': 0.22013735820303906, 'Total loss': 0.22013735820303906}
2022-12-31 14:34:21,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:21,575 INFO:     Epoch: 77
2022-12-31 14:34:23,204 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4458394048114618, 'Total loss': 0.4458394048114618} | train loss {'Reaction outcome loss': 0.2205451885886463, 'Total loss': 0.2205451885886463}
2022-12-31 14:34:23,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:23,205 INFO:     Epoch: 78
2022-12-31 14:34:24,798 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43825795079270996, 'Total loss': 0.43825795079270996} | train loss {'Reaction outcome loss': 0.22291807796901617, 'Total loss': 0.22291807796901617}
2022-12-31 14:34:24,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:24,799 INFO:     Epoch: 79
2022-12-31 14:34:26,374 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4425377974907557, 'Total loss': 0.4425377974907557} | train loss {'Reaction outcome loss': 0.22439729016710877, 'Total loss': 0.22439729016710877}
2022-12-31 14:34:26,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:26,374 INFO:     Epoch: 80
2022-12-31 14:34:27,963 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44047255416711173, 'Total loss': 0.44047255416711173} | train loss {'Reaction outcome loss': 0.2220528181915209, 'Total loss': 0.2220528181915209}
2022-12-31 14:34:27,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:27,964 INFO:     Epoch: 81
2022-12-31 14:34:29,575 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4206759269038836, 'Total loss': 0.4206759269038836} | train loss {'Reaction outcome loss': 0.22549050081957936, 'Total loss': 0.22549050081957936}
2022-12-31 14:34:29,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:29,575 INFO:     Epoch: 82
2022-12-31 14:34:31,214 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46580849289894105, 'Total loss': 0.46580849289894105} | train loss {'Reaction outcome loss': 0.22758497075338066, 'Total loss': 0.22758497075338066}
2022-12-31 14:34:31,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:31,214 INFO:     Epoch: 83
2022-12-31 14:34:32,830 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46624367237091063, 'Total loss': 0.46624367237091063} | train loss {'Reaction outcome loss': 0.2279404528275296, 'Total loss': 0.2279404528275296}
2022-12-31 14:34:32,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:32,830 INFO:     Epoch: 84
2022-12-31 14:34:34,431 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4578496893246969, 'Total loss': 0.4578496893246969} | train loss {'Reaction outcome loss': 0.2177144968609288, 'Total loss': 0.2177144968609288}
2022-12-31 14:34:34,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:34,432 INFO:     Epoch: 85
2022-12-31 14:34:36,033 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45541990250349046, 'Total loss': 0.45541990250349046} | train loss {'Reaction outcome loss': 0.21456182866115056, 'Total loss': 0.21456182866115056}
2022-12-31 14:34:36,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:36,034 INFO:     Epoch: 86
2022-12-31 14:34:37,657 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4421299914518992, 'Total loss': 0.4421299914518992} | train loss {'Reaction outcome loss': 0.2143044481463321, 'Total loss': 0.2143044481463321}
2022-12-31 14:34:37,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:37,658 INFO:     Epoch: 87
2022-12-31 14:34:39,280 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.423746265967687, 'Total loss': 0.423746265967687} | train loss {'Reaction outcome loss': 0.21636715719617916, 'Total loss': 0.21636715719617916}
2022-12-31 14:34:39,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:39,281 INFO:     Epoch: 88
2022-12-31 14:34:40,910 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4322717626889547, 'Total loss': 0.4322717626889547} | train loss {'Reaction outcome loss': 0.21207620939683347, 'Total loss': 0.21207620939683347}
2022-12-31 14:34:40,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:40,910 INFO:     Epoch: 89
2022-12-31 14:34:42,510 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4713999792933464, 'Total loss': 0.4713999792933464} | train loss {'Reaction outcome loss': 0.2105719734993064, 'Total loss': 0.2105719734993064}
2022-12-31 14:34:42,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:42,510 INFO:     Epoch: 90
2022-12-31 14:34:44,125 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45996829569339753, 'Total loss': 0.45996829569339753} | train loss {'Reaction outcome loss': 0.21898571681572404, 'Total loss': 0.21898571681572404}
2022-12-31 14:34:44,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:44,125 INFO:     Epoch: 91
2022-12-31 14:34:45,717 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46827226181825005, 'Total loss': 0.46827226181825005} | train loss {'Reaction outcome loss': 0.20586132956839306, 'Total loss': 0.20586132956839306}
2022-12-31 14:34:45,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:45,717 INFO:     Epoch: 92
2022-12-31 14:34:47,302 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4810333788394928, 'Total loss': 0.4810333788394928} | train loss {'Reaction outcome loss': 0.21138219418679619, 'Total loss': 0.21138219418679619}
2022-12-31 14:34:47,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:47,302 INFO:     Epoch: 93
2022-12-31 14:34:48,903 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44996643463770547, 'Total loss': 0.44996643463770547} | train loss {'Reaction outcome loss': 0.21500575932377314, 'Total loss': 0.21500575932377314}
2022-12-31 14:34:48,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:48,903 INFO:     Epoch: 94
2022-12-31 14:34:50,542 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4135905481874943, 'Total loss': 0.4135905481874943} | train loss {'Reaction outcome loss': 0.21167911222757219, 'Total loss': 0.21167911222757219}
2022-12-31 14:34:50,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:50,542 INFO:     Epoch: 95
2022-12-31 14:34:52,158 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.451264880100886, 'Total loss': 0.451264880100886} | train loss {'Reaction outcome loss': 0.20670595774665856, 'Total loss': 0.20670595774665856}
2022-12-31 14:34:52,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:52,158 INFO:     Epoch: 96
2022-12-31 14:34:53,762 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42986602783203126, 'Total loss': 0.42986602783203126} | train loss {'Reaction outcome loss': 0.21135137841487542, 'Total loss': 0.21135137841487542}
2022-12-31 14:34:53,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:53,762 INFO:     Epoch: 97
2022-12-31 14:34:55,392 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4672630846500397, 'Total loss': 0.4672630846500397} | train loss {'Reaction outcome loss': 0.20466817747596855, 'Total loss': 0.20466817747596855}
2022-12-31 14:34:55,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:55,393 INFO:     Epoch: 98
2022-12-31 14:34:56,993 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4502551625172297, 'Total loss': 0.4502551625172297} | train loss {'Reaction outcome loss': 0.20853610354520025, 'Total loss': 0.20853610354520025}
2022-12-31 14:34:56,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:56,993 INFO:     Epoch: 99
2022-12-31 14:34:58,581 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4242169042428335, 'Total loss': 0.4242169042428335} | train loss {'Reaction outcome loss': 0.20859913365581098, 'Total loss': 0.20859913365581098}
2022-12-31 14:34:58,582 INFO:     Best model found after epoch 54 of 100.
2022-12-31 14:34:58,582 INFO:   Done with stage: TRAINING
2022-12-31 14:34:58,582 INFO:   Starting stage: EVALUATION
2022-12-31 14:34:58,721 INFO:   Done with stage: EVALUATION
2022-12-31 14:34:58,722 INFO:   Leaving out SEQ value Fold_3
2022-12-31 14:34:58,735 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 14:34:58,735 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:34:59,375 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:34:59,375 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:34:59,443 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:34:59,443 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:34:59,444 INFO:     No hyperparam tuning for this model
2022-12-31 14:34:59,444 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:34:59,444 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:34:59,444 INFO:     None feature selector for col prot
2022-12-31 14:34:59,445 INFO:     None feature selector for col prot
2022-12-31 14:34:59,445 INFO:     None feature selector for col prot
2022-12-31 14:34:59,445 INFO:     None feature selector for col chem
2022-12-31 14:34:59,445 INFO:     None feature selector for col chem
2022-12-31 14:34:59,445 INFO:     None feature selector for col chem
2022-12-31 14:34:59,445 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:34:59,445 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:34:59,447 INFO:     Number of params in model 223921
2022-12-31 14:34:59,450 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:34:59,450 INFO:   Starting stage: TRAINING
2022-12-31 14:34:59,496 INFO:     Val loss before train {'Reaction outcome loss': 1.0698775768280029, 'Total loss': 1.0698775768280029}
2022-12-31 14:34:59,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:34:59,496 INFO:     Epoch: 0
2022-12-31 14:35:01,075 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6599285821119945, 'Total loss': 0.6599285821119945} | train loss {'Reaction outcome loss': 0.8043950066898332, 'Total loss': 0.8043950066898332}
2022-12-31 14:35:01,075 INFO:     Found new best model at epoch 0
2022-12-31 14:35:01,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:01,076 INFO:     Epoch: 1
2022-12-31 14:35:02,663 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5806714018185933, 'Total loss': 0.5806714018185933} | train loss {'Reaction outcome loss': 0.5782233471180493, 'Total loss': 0.5782233471180493}
2022-12-31 14:35:02,664 INFO:     Found new best model at epoch 1
2022-12-31 14:35:02,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:02,664 INFO:     Epoch: 2
2022-12-31 14:35:04,284 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5185609598954518, 'Total loss': 0.5185609598954518} | train loss {'Reaction outcome loss': 0.512691705654829, 'Total loss': 0.512691705654829}
2022-12-31 14:35:04,284 INFO:     Found new best model at epoch 2
2022-12-31 14:35:04,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:04,285 INFO:     Epoch: 3
2022-12-31 14:35:05,907 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.504425714413325, 'Total loss': 0.504425714413325} | train loss {'Reaction outcome loss': 0.49035330831786217, 'Total loss': 0.49035330831786217}
2022-12-31 14:35:05,907 INFO:     Found new best model at epoch 3
2022-12-31 14:35:05,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:05,908 INFO:     Epoch: 4
2022-12-31 14:35:07,529 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.492992976307869, 'Total loss': 0.492992976307869} | train loss {'Reaction outcome loss': 0.4744892405011715, 'Total loss': 0.4744892405011715}
2022-12-31 14:35:07,529 INFO:     Found new best model at epoch 4
2022-12-31 14:35:07,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:07,530 INFO:     Epoch: 5
2022-12-31 14:35:09,151 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4833275149265925, 'Total loss': 0.4833275149265925} | train loss {'Reaction outcome loss': 0.46103741435995904, 'Total loss': 0.46103741435995904}
2022-12-31 14:35:09,151 INFO:     Found new best model at epoch 5
2022-12-31 14:35:09,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:09,152 INFO:     Epoch: 6
2022-12-31 14:35:10,731 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5363075852394104, 'Total loss': 0.5363075852394104} | train loss {'Reaction outcome loss': 0.45088869768566703, 'Total loss': 0.45088869768566703}
2022-12-31 14:35:10,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:10,732 INFO:     Epoch: 7
2022-12-31 14:35:12,322 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49367737273375195, 'Total loss': 0.49367737273375195} | train loss {'Reaction outcome loss': 0.44773154012558664, 'Total loss': 0.44773154012558664}
2022-12-31 14:35:12,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:12,322 INFO:     Epoch: 8
2022-12-31 14:35:13,931 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4830495556195577, 'Total loss': 0.4830495556195577} | train loss {'Reaction outcome loss': 0.4395815311989068, 'Total loss': 0.4395815311989068}
2022-12-31 14:35:13,931 INFO:     Found new best model at epoch 8
2022-12-31 14:35:13,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:13,932 INFO:     Epoch: 9
2022-12-31 14:35:15,524 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4865949511528015, 'Total loss': 0.4865949511528015} | train loss {'Reaction outcome loss': 0.42859760041420275, 'Total loss': 0.42859760041420275}
2022-12-31 14:35:15,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:15,526 INFO:     Epoch: 10
2022-12-31 14:35:17,119 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4797847966353099, 'Total loss': 0.4797847966353099} | train loss {'Reaction outcome loss': 0.4286848134719409, 'Total loss': 0.4286848134719409}
2022-12-31 14:35:17,119 INFO:     Found new best model at epoch 10
2022-12-31 14:35:17,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:17,120 INFO:     Epoch: 11
2022-12-31 14:35:18,713 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4523426433404287, 'Total loss': 0.4523426433404287} | train loss {'Reaction outcome loss': 0.4195436026095907, 'Total loss': 0.4195436026095907}
2022-12-31 14:35:18,713 INFO:     Found new best model at epoch 11
2022-12-31 14:35:18,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:18,714 INFO:     Epoch: 12
2022-12-31 14:35:20,318 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4643078108628591, 'Total loss': 0.4643078108628591} | train loss {'Reaction outcome loss': 0.41260440805892806, 'Total loss': 0.41260440805892806}
2022-12-31 14:35:20,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:20,319 INFO:     Epoch: 13
2022-12-31 14:35:21,908 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47039573192596434, 'Total loss': 0.47039573192596434} | train loss {'Reaction outcome loss': 0.40777857844536997, 'Total loss': 0.40777857844536997}
2022-12-31 14:35:21,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:21,909 INFO:     Epoch: 14
2022-12-31 14:35:23,500 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46300031542778014, 'Total loss': 0.46300031542778014} | train loss {'Reaction outcome loss': 0.40333746460986225, 'Total loss': 0.40333746460986225}
2022-12-31 14:35:23,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:23,500 INFO:     Epoch: 15
2022-12-31 14:35:25,116 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45966935257116953, 'Total loss': 0.45966935257116953} | train loss {'Reaction outcome loss': 0.40089067085322005, 'Total loss': 0.40089067085322005}
2022-12-31 14:35:25,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:25,116 INFO:     Epoch: 16
2022-12-31 14:35:26,730 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46676621635754906, 'Total loss': 0.46676621635754906} | train loss {'Reaction outcome loss': 0.3953517238735716, 'Total loss': 0.3953517238735716}
2022-12-31 14:35:26,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:26,730 INFO:     Epoch: 17
2022-12-31 14:35:28,309 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5195005128781001, 'Total loss': 0.5195005128781001} | train loss {'Reaction outcome loss': 0.3842727508082058, 'Total loss': 0.3842727508082058}
2022-12-31 14:35:28,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:28,309 INFO:     Epoch: 18
2022-12-31 14:35:29,896 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4385981837908427, 'Total loss': 0.4385981837908427} | train loss {'Reaction outcome loss': 0.38254318790230557, 'Total loss': 0.38254318790230557}
2022-12-31 14:35:29,897 INFO:     Found new best model at epoch 18
2022-12-31 14:35:29,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:29,897 INFO:     Epoch: 19
2022-12-31 14:35:31,504 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48417607496182125, 'Total loss': 0.48417607496182125} | train loss {'Reaction outcome loss': 0.3763022582991656, 'Total loss': 0.3763022582991656}
2022-12-31 14:35:31,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:31,505 INFO:     Epoch: 20
2022-12-31 14:35:33,100 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4664617538452148, 'Total loss': 0.4664617538452148} | train loss {'Reaction outcome loss': 0.3699966222866551, 'Total loss': 0.3699966222866551}
2022-12-31 14:35:33,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:33,100 INFO:     Epoch: 21
2022-12-31 14:35:34,705 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4630681037902832, 'Total loss': 0.4630681037902832} | train loss {'Reaction outcome loss': 0.3719561028229448, 'Total loss': 0.3719561028229448}
2022-12-31 14:35:34,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:34,706 INFO:     Epoch: 22
2022-12-31 14:35:36,326 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5139417002598444, 'Total loss': 0.5139417002598444} | train loss {'Reaction outcome loss': 0.357488862866529, 'Total loss': 0.357488862866529}
2022-12-31 14:35:36,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:36,326 INFO:     Epoch: 23
2022-12-31 14:35:37,923 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4473438153664271, 'Total loss': 0.4473438153664271} | train loss {'Reaction outcome loss': 0.3585449734245574, 'Total loss': 0.3585449734245574}
2022-12-31 14:35:37,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:37,923 INFO:     Epoch: 24
2022-12-31 14:35:39,520 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4267412612835566, 'Total loss': 0.4267412612835566} | train loss {'Reaction outcome loss': 0.35499569118677915, 'Total loss': 0.35499569118677915}
2022-12-31 14:35:39,520 INFO:     Found new best model at epoch 24
2022-12-31 14:35:39,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:39,521 INFO:     Epoch: 25
2022-12-31 14:35:41,148 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44843414922555286, 'Total loss': 0.44843414922555286} | train loss {'Reaction outcome loss': 0.3493600153933951, 'Total loss': 0.3493600153933951}
2022-12-31 14:35:41,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:41,149 INFO:     Epoch: 26
2022-12-31 14:35:42,767 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4366482079029083, 'Total loss': 0.4366482079029083} | train loss {'Reaction outcome loss': 0.3435109834640454, 'Total loss': 0.3435109834640454}
2022-12-31 14:35:42,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:42,768 INFO:     Epoch: 27
2022-12-31 14:35:44,393 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43962953289349876, 'Total loss': 0.43962953289349876} | train loss {'Reaction outcome loss': 0.336412714855684, 'Total loss': 0.336412714855684}
2022-12-31 14:35:44,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:44,393 INFO:     Epoch: 28
2022-12-31 14:35:45,994 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4779549260934194, 'Total loss': 0.4779549260934194} | train loss {'Reaction outcome loss': 0.3352536377821104, 'Total loss': 0.3352536377821104}
2022-12-31 14:35:45,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:45,995 INFO:     Epoch: 29
2022-12-31 14:35:47,610 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46043094992637634, 'Total loss': 0.46043094992637634} | train loss {'Reaction outcome loss': 0.3255432074302773, 'Total loss': 0.3255432074302773}
2022-12-31 14:35:47,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:47,610 INFO:     Epoch: 30
2022-12-31 14:35:49,197 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4290976017713547, 'Total loss': 0.4290976017713547} | train loss {'Reaction outcome loss': 0.3256092690231599, 'Total loss': 0.3256092690231599}
2022-12-31 14:35:49,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:49,197 INFO:     Epoch: 31
2022-12-31 14:35:50,828 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4098180194695791, 'Total loss': 0.4098180194695791} | train loss {'Reaction outcome loss': 0.3277875296089239, 'Total loss': 0.3277875296089239}
2022-12-31 14:35:50,828 INFO:     Found new best model at epoch 31
2022-12-31 14:35:50,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:50,829 INFO:     Epoch: 32
2022-12-31 14:35:52,447 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48511964579423267, 'Total loss': 0.48511964579423267} | train loss {'Reaction outcome loss': 0.31828207869232794, 'Total loss': 0.31828207869232794}
2022-12-31 14:35:52,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:52,448 INFO:     Epoch: 33
2022-12-31 14:35:54,050 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.411401829123497, 'Total loss': 0.411401829123497} | train loss {'Reaction outcome loss': 0.3122574135033421, 'Total loss': 0.3122574135033421}
2022-12-31 14:35:54,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:54,050 INFO:     Epoch: 34
2022-12-31 14:35:55,646 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39658137162526447, 'Total loss': 0.39658137162526447} | train loss {'Reaction outcome loss': 0.305094902795968, 'Total loss': 0.305094902795968}
2022-12-31 14:35:55,647 INFO:     Found new best model at epoch 34
2022-12-31 14:35:55,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:55,648 INFO:     Epoch: 35
2022-12-31 14:35:57,242 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4380330135424932, 'Total loss': 0.4380330135424932} | train loss {'Reaction outcome loss': 0.3049895890712083, 'Total loss': 0.3049895890712083}
2022-12-31 14:35:57,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:57,242 INFO:     Epoch: 36
2022-12-31 14:35:58,870 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42777012586593627, 'Total loss': 0.42777012586593627} | train loss {'Reaction outcome loss': 0.30003275716806943, 'Total loss': 0.30003275716806943}
2022-12-31 14:35:58,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:35:58,870 INFO:     Epoch: 37
2022-12-31 14:36:00,497 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.440398504336675, 'Total loss': 0.440398504336675} | train loss {'Reaction outcome loss': 0.29605732555927594, 'Total loss': 0.29605732555927594}
2022-12-31 14:36:00,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:00,497 INFO:     Epoch: 38
2022-12-31 14:36:02,111 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41373245120048524, 'Total loss': 0.41373245120048524} | train loss {'Reaction outcome loss': 0.29658905351227455, 'Total loss': 0.29658905351227455}
2022-12-31 14:36:02,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:02,112 INFO:     Epoch: 39
2022-12-31 14:36:03,706 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4149317170182864, 'Total loss': 0.4149317170182864} | train loss {'Reaction outcome loss': 0.28810007204966886, 'Total loss': 0.28810007204966886}
2022-12-31 14:36:03,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:03,706 INFO:     Epoch: 40
2022-12-31 14:36:05,309 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3783358221873641, 'Total loss': 0.3783358221873641} | train loss {'Reaction outcome loss': 0.2877405337535609, 'Total loss': 0.2877405337535609}
2022-12-31 14:36:05,310 INFO:     Found new best model at epoch 40
2022-12-31 14:36:05,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:05,311 INFO:     Epoch: 41
2022-12-31 14:36:06,936 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4521981914838155, 'Total loss': 0.4521981914838155} | train loss {'Reaction outcome loss': 0.2911857060146528, 'Total loss': 0.2911857060146528}
2022-12-31 14:36:06,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:06,936 INFO:     Epoch: 42
2022-12-31 14:36:08,576 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38980720068017644, 'Total loss': 0.38980720068017644} | train loss {'Reaction outcome loss': 0.2869116142255701, 'Total loss': 0.2869116142255701}
2022-12-31 14:36:08,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:08,576 INFO:     Epoch: 43
2022-12-31 14:36:10,176 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4542282670736313, 'Total loss': 0.4542282670736313} | train loss {'Reaction outcome loss': 0.28283683721388897, 'Total loss': 0.28283683721388897}
2022-12-31 14:36:10,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:10,176 INFO:     Epoch: 44
2022-12-31 14:36:11,770 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38501676321029665, 'Total loss': 0.38501676321029665} | train loss {'Reaction outcome loss': 0.27607032149047644, 'Total loss': 0.27607032149047644}
2022-12-31 14:36:11,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:11,770 INFO:     Epoch: 45
2022-12-31 14:36:13,379 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4178319354852041, 'Total loss': 0.4178319354852041} | train loss {'Reaction outcome loss': 0.2807378838377776, 'Total loss': 0.2807378838377776}
2022-12-31 14:36:13,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:13,379 INFO:     Epoch: 46
2022-12-31 14:36:14,993 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38165352766712507, 'Total loss': 0.38165352766712507} | train loss {'Reaction outcome loss': 0.26920938677403516, 'Total loss': 0.26920938677403516}
2022-12-31 14:36:14,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:14,993 INFO:     Epoch: 47
2022-12-31 14:36:16,590 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.388695686062177, 'Total loss': 0.388695686062177} | train loss {'Reaction outcome loss': 0.2707565814775207, 'Total loss': 0.2707565814775207}
2022-12-31 14:36:16,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:16,591 INFO:     Epoch: 48
2022-12-31 14:36:18,199 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38973434766133624, 'Total loss': 0.38973434766133624} | train loss {'Reaction outcome loss': 0.2696053256918659, 'Total loss': 0.2696053256918659}
2022-12-31 14:36:18,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:18,199 INFO:     Epoch: 49
2022-12-31 14:36:19,820 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4532869756221771, 'Total loss': 0.4532869756221771} | train loss {'Reaction outcome loss': 0.26769859175924415, 'Total loss': 0.26769859175924415}
2022-12-31 14:36:19,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:19,821 INFO:     Epoch: 50
2022-12-31 14:36:21,437 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41557085116704306, 'Total loss': 0.41557085116704306} | train loss {'Reaction outcome loss': 0.2618791821238759, 'Total loss': 0.2618791821238759}
2022-12-31 14:36:21,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:21,437 INFO:     Epoch: 51
2022-12-31 14:36:23,025 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3925094867746035, 'Total loss': 0.3925094867746035} | train loss {'Reaction outcome loss': 0.25995977227695477, 'Total loss': 0.25995977227695477}
2022-12-31 14:36:23,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:23,026 INFO:     Epoch: 52
2022-12-31 14:36:24,616 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41274310648441315, 'Total loss': 0.41274310648441315} | train loss {'Reaction outcome loss': 0.2501415920140215, 'Total loss': 0.2501415920140215}
2022-12-31 14:36:24,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:24,617 INFO:     Epoch: 53
2022-12-31 14:36:26,220 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4106646051009496, 'Total loss': 0.4106646051009496} | train loss {'Reaction outcome loss': 0.2534381236348833, 'Total loss': 0.2534381236348833}
2022-12-31 14:36:26,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:26,220 INFO:     Epoch: 54
2022-12-31 14:36:27,835 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3878557821114858, 'Total loss': 0.3878557821114858} | train loss {'Reaction outcome loss': 0.26446274238137096, 'Total loss': 0.26446274238137096}
2022-12-31 14:36:27,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:27,836 INFO:     Epoch: 55
2022-12-31 14:36:29,440 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43209852476914723, 'Total loss': 0.43209852476914723} | train loss {'Reaction outcome loss': 0.2451327611374986, 'Total loss': 0.2451327611374986}
2022-12-31 14:36:29,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:29,440 INFO:     Epoch: 56
2022-12-31 14:36:31,028 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45328598519166313, 'Total loss': 0.45328598519166313} | train loss {'Reaction outcome loss': 0.2500258827779865, 'Total loss': 0.2500258827779865}
2022-12-31 14:36:31,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:31,028 INFO:     Epoch: 57
2022-12-31 14:36:32,606 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.422878127420942, 'Total loss': 0.422878127420942} | train loss {'Reaction outcome loss': 0.2515911731336798, 'Total loss': 0.2515911731336798}
2022-12-31 14:36:32,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:32,606 INFO:     Epoch: 58
2022-12-31 14:36:34,207 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4022450357675552, 'Total loss': 0.4022450357675552} | train loss {'Reaction outcome loss': 0.24565276786029994, 'Total loss': 0.24565276786029994}
2022-12-31 14:36:34,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:34,207 INFO:     Epoch: 59
2022-12-31 14:36:35,827 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.36437733968098956, 'Total loss': 0.36437733968098956} | train loss {'Reaction outcome loss': 0.2430408753475154, 'Total loss': 0.2430408753475154}
2022-12-31 14:36:35,827 INFO:     Found new best model at epoch 59
2022-12-31 14:36:35,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:35,828 INFO:     Epoch: 60
2022-12-31 14:36:37,444 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4327527423699697, 'Total loss': 0.4327527423699697} | train loss {'Reaction outcome loss': 0.24159652048264776, 'Total loss': 0.24159652048264776}
2022-12-31 14:36:37,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:37,444 INFO:     Epoch: 61
2022-12-31 14:36:39,064 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44922253092130027, 'Total loss': 0.44922253092130027} | train loss {'Reaction outcome loss': 0.23955153486258163, 'Total loss': 0.23955153486258163}
2022-12-31 14:36:39,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:39,064 INFO:     Epoch: 62
2022-12-31 14:36:40,674 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4045436312754949, 'Total loss': 0.4045436312754949} | train loss {'Reaction outcome loss': 0.2403726338685214, 'Total loss': 0.2403726338685214}
2022-12-31 14:36:40,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:40,674 INFO:     Epoch: 63
2022-12-31 14:36:42,275 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4621993025143941, 'Total loss': 0.4621993025143941} | train loss {'Reaction outcome loss': 0.23470328912231048, 'Total loss': 0.23470328912231048}
2022-12-31 14:36:42,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:42,275 INFO:     Epoch: 64
2022-12-31 14:36:43,876 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46330726544062295, 'Total loss': 0.46330726544062295} | train loss {'Reaction outcome loss': 0.23164708593061992, 'Total loss': 0.23164708593061992}
2022-12-31 14:36:43,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:43,876 INFO:     Epoch: 65
2022-12-31 14:36:45,503 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4386097490787506, 'Total loss': 0.4386097490787506} | train loss {'Reaction outcome loss': 0.23378189181697456, 'Total loss': 0.23378189181697456}
2022-12-31 14:36:45,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:45,503 INFO:     Epoch: 66
2022-12-31 14:36:47,112 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4395551532506943, 'Total loss': 0.4395551532506943} | train loss {'Reaction outcome loss': 0.22741811620173874, 'Total loss': 0.22741811620173874}
2022-12-31 14:36:47,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:47,112 INFO:     Epoch: 67
2022-12-31 14:36:48,732 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4148477097352346, 'Total loss': 0.4148477097352346} | train loss {'Reaction outcome loss': 0.23021084744305836, 'Total loss': 0.23021084744305836}
2022-12-31 14:36:48,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:48,732 INFO:     Epoch: 68
2022-12-31 14:36:50,329 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4042051166296005, 'Total loss': 0.4042051166296005} | train loss {'Reaction outcome loss': 0.22817694084657417, 'Total loss': 0.22817694084657417}
2022-12-31 14:36:50,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:50,330 INFO:     Epoch: 69
2022-12-31 14:36:51,913 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3520005782445272, 'Total loss': 0.3520005782445272} | train loss {'Reaction outcome loss': 0.2268906137991301, 'Total loss': 0.2268906137991301}
2022-12-31 14:36:51,913 INFO:     Found new best model at epoch 69
2022-12-31 14:36:51,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:51,914 INFO:     Epoch: 70
2022-12-31 14:36:53,540 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3948477566242218, 'Total loss': 0.3948477566242218} | train loss {'Reaction outcome loss': 0.2213579811660689, 'Total loss': 0.2213579811660689}
2022-12-31 14:36:53,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:53,541 INFO:     Epoch: 71
2022-12-31 14:36:55,138 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4129288583993912, 'Total loss': 0.4129288583993912} | train loss {'Reaction outcome loss': 0.2250228403306706, 'Total loss': 0.2250228403306706}
2022-12-31 14:36:55,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:55,138 INFO:     Epoch: 72
2022-12-31 14:36:56,760 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4484205454587936, 'Total loss': 0.4484205454587936} | train loss {'Reaction outcome loss': 0.22457548580558856, 'Total loss': 0.22457548580558856}
2022-12-31 14:36:56,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:56,760 INFO:     Epoch: 73
2022-12-31 14:36:58,390 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4085497786601385, 'Total loss': 0.4085497786601385} | train loss {'Reaction outcome loss': 0.21625689431451833, 'Total loss': 0.21625689431451833}
2022-12-31 14:36:58,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:58,390 INFO:     Epoch: 74
2022-12-31 14:36:59,980 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39742853144804635, 'Total loss': 0.39742853144804635} | train loss {'Reaction outcome loss': 0.22203575314155646, 'Total loss': 0.22203575314155646}
2022-12-31 14:36:59,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:36:59,981 INFO:     Epoch: 75
2022-12-31 14:37:01,563 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4392592320839564, 'Total loss': 0.4392592320839564} | train loss {'Reaction outcome loss': 0.21800342467596462, 'Total loss': 0.21800342467596462}
2022-12-31 14:37:01,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:01,564 INFO:     Epoch: 76
2022-12-31 14:37:03,159 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42102188666661583, 'Total loss': 0.42102188666661583} | train loss {'Reaction outcome loss': 0.22073143283621624, 'Total loss': 0.22073143283621624}
2022-12-31 14:37:03,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:03,159 INFO:     Epoch: 77
2022-12-31 14:37:04,756 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4061551292737325, 'Total loss': 0.4061551292737325} | train loss {'Reaction outcome loss': 0.22323396956486688, 'Total loss': 0.22323396956486688}
2022-12-31 14:37:04,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:04,757 INFO:     Epoch: 78
2022-12-31 14:37:06,353 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4041607374946276, 'Total loss': 0.4041607374946276} | train loss {'Reaction outcome loss': 0.21392609060301884, 'Total loss': 0.21392609060301884}
2022-12-31 14:37:06,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:06,353 INFO:     Epoch: 79
2022-12-31 14:37:07,942 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40152687231699624, 'Total loss': 0.40152687231699624} | train loss {'Reaction outcome loss': 0.22291732602667458, 'Total loss': 0.22291732602667458}
2022-12-31 14:37:07,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:07,942 INFO:     Epoch: 80
2022-12-31 14:37:09,521 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3899051288763682, 'Total loss': 0.3899051288763682} | train loss {'Reaction outcome loss': 0.21120781452145987, 'Total loss': 0.21120781452145987}
2022-12-31 14:37:09,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:09,521 INFO:     Epoch: 81
2022-12-31 14:37:11,138 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38654998938242596, 'Total loss': 0.38654998938242596} | train loss {'Reaction outcome loss': 0.2141051148729665, 'Total loss': 0.2141051148729665}
2022-12-31 14:37:11,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:11,138 INFO:     Epoch: 82
2022-12-31 14:37:12,734 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4038963884115219, 'Total loss': 0.4038963884115219} | train loss {'Reaction outcome loss': 0.21297319572514448, 'Total loss': 0.21297319572514448}
2022-12-31 14:37:12,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:12,734 INFO:     Epoch: 83
2022-12-31 14:37:14,329 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41108616987864177, 'Total loss': 0.41108616987864177} | train loss {'Reaction outcome loss': 0.21308745772683577, 'Total loss': 0.21308745772683577}
2022-12-31 14:37:14,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:14,329 INFO:     Epoch: 84
2022-12-31 14:37:15,924 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38917150696118674, 'Total loss': 0.38917150696118674} | train loss {'Reaction outcome loss': 0.2052392538921778, 'Total loss': 0.2052392538921778}
2022-12-31 14:37:15,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:15,924 INFO:     Epoch: 85
2022-12-31 14:37:17,509 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4062879333893458, 'Total loss': 0.4062879333893458} | train loss {'Reaction outcome loss': 0.2097182639127413, 'Total loss': 0.2097182639127413}
2022-12-31 14:37:17,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:17,509 INFO:     Epoch: 86
2022-12-31 14:37:19,093 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3757877459128698, 'Total loss': 0.3757877459128698} | train loss {'Reaction outcome loss': 0.21381100185979635, 'Total loss': 0.21381100185979635}
2022-12-31 14:37:19,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:19,093 INFO:     Epoch: 87
2022-12-31 14:37:20,689 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.35915453508496287, 'Total loss': 0.35915453508496287} | train loss {'Reaction outcome loss': 0.20523538145035397, 'Total loss': 0.20523538145035397}
2022-12-31 14:37:20,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:20,689 INFO:     Epoch: 88
2022-12-31 14:37:22,285 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4218575576941172, 'Total loss': 0.4218575576941172} | train loss {'Reaction outcome loss': 0.2052932628140454, 'Total loss': 0.2052932628140454}
2022-12-31 14:37:22,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:22,286 INFO:     Epoch: 89
2022-12-31 14:37:23,881 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4094484637180964, 'Total loss': 0.4094484637180964} | train loss {'Reaction outcome loss': 0.2019181389117702, 'Total loss': 0.2019181389117702}
2022-12-31 14:37:23,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:23,881 INFO:     Epoch: 90
2022-12-31 14:37:25,477 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3946614960829417, 'Total loss': 0.3946614960829417} | train loss {'Reaction outcome loss': 0.2006876957074026, 'Total loss': 0.2006876957074026}
2022-12-31 14:37:25,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:25,477 INFO:     Epoch: 91
2022-12-31 14:37:27,083 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.37425661981105807, 'Total loss': 0.37425661981105807} | train loss {'Reaction outcome loss': 0.21144039209781987, 'Total loss': 0.21144039209781987}
2022-12-31 14:37:27,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:27,083 INFO:     Epoch: 92
2022-12-31 14:37:28,665 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3796450267235438, 'Total loss': 0.3796450267235438} | train loss {'Reaction outcome loss': 0.20093869217313254, 'Total loss': 0.20093869217313254}
2022-12-31 14:37:28,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:28,666 INFO:     Epoch: 93
2022-12-31 14:37:30,268 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41058677385250725, 'Total loss': 0.41058677385250725} | train loss {'Reaction outcome loss': 0.20156671811959573, 'Total loss': 0.20156671811959573}
2022-12-31 14:37:30,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:30,269 INFO:     Epoch: 94
2022-12-31 14:37:31,909 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42101984371741613, 'Total loss': 0.42101984371741613} | train loss {'Reaction outcome loss': 0.1961904092770302, 'Total loss': 0.1961904092770302}
2022-12-31 14:37:31,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:31,909 INFO:     Epoch: 95
2022-12-31 14:37:33,535 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35729204714298246, 'Total loss': 0.35729204714298246} | train loss {'Reaction outcome loss': 0.19500979025858445, 'Total loss': 0.19500979025858445}
2022-12-31 14:37:33,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:33,535 INFO:     Epoch: 96
2022-12-31 14:37:35,069 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3993683060010274, 'Total loss': 0.3993683060010274} | train loss {'Reaction outcome loss': 0.20928299632401037, 'Total loss': 0.20928299632401037}
2022-12-31 14:37:35,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:35,069 INFO:     Epoch: 97
2022-12-31 14:37:36,150 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3758422334988912, 'Total loss': 0.3758422334988912} | train loss {'Reaction outcome loss': 0.20289750395840778, 'Total loss': 0.20289750395840778}
2022-12-31 14:37:36,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:36,150 INFO:     Epoch: 98
2022-12-31 14:37:37,214 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4022183117767175, 'Total loss': 0.4022183117767175} | train loss {'Reaction outcome loss': 0.2049625162581057, 'Total loss': 0.2049625162581057}
2022-12-31 14:37:37,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:37,214 INFO:     Epoch: 99
2022-12-31 14:37:38,279 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3746551553408305, 'Total loss': 0.3746551553408305} | train loss {'Reaction outcome loss': 0.19458307599778468, 'Total loss': 0.19458307599778468}
2022-12-31 14:37:38,279 INFO:     Best model found after epoch 70 of 100.
2022-12-31 14:37:38,279 INFO:   Done with stage: TRAINING
2022-12-31 14:37:38,279 INFO:   Starting stage: EVALUATION
2022-12-31 14:37:38,418 INFO:   Done with stage: EVALUATION
2022-12-31 14:37:38,418 INFO:   Leaving out SEQ value Fold_4
2022-12-31 14:37:38,431 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 14:37:38,431 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:37:39,079 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:37:39,080 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:37:39,150 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:37:39,150 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:37:39,150 INFO:     No hyperparam tuning for this model
2022-12-31 14:37:39,150 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:37:39,150 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:37:39,151 INFO:     None feature selector for col prot
2022-12-31 14:37:39,151 INFO:     None feature selector for col prot
2022-12-31 14:37:39,151 INFO:     None feature selector for col prot
2022-12-31 14:37:39,152 INFO:     None feature selector for col chem
2022-12-31 14:37:39,152 INFO:     None feature selector for col chem
2022-12-31 14:37:39,152 INFO:     None feature selector for col chem
2022-12-31 14:37:39,152 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:37:39,152 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:37:39,154 INFO:     Number of params in model 223921
2022-12-31 14:37:39,157 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:37:39,157 INFO:   Starting stage: TRAINING
2022-12-31 14:37:39,192 INFO:     Val loss before train {'Reaction outcome loss': 0.9627968589464824, 'Total loss': 0.9627968589464824}
2022-12-31 14:37:39,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:39,192 INFO:     Epoch: 0
2022-12-31 14:37:40,610 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6968492468198141, 'Total loss': 0.6968492468198141} | train loss {'Reaction outcome loss': 0.8111298807721207, 'Total loss': 0.8111298807721207}
2022-12-31 14:37:40,610 INFO:     Found new best model at epoch 0
2022-12-31 14:37:40,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:40,611 INFO:     Epoch: 1
2022-12-31 14:37:42,248 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6545545597871144, 'Total loss': 0.6545545597871144} | train loss {'Reaction outcome loss': 0.5909776615275852, 'Total loss': 0.5909776615275852}
2022-12-31 14:37:42,248 INFO:     Found new best model at epoch 1
2022-12-31 14:37:42,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:42,249 INFO:     Epoch: 2
2022-12-31 14:37:43,843 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6195902963479359, 'Total loss': 0.6195902963479359} | train loss {'Reaction outcome loss': 0.5482503726430561, 'Total loss': 0.5482503726430561}
2022-12-31 14:37:43,844 INFO:     Found new best model at epoch 2
2022-12-31 14:37:43,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:43,844 INFO:     Epoch: 3
2022-12-31 14:37:45,466 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6208970487117768, 'Total loss': 0.6208970487117768} | train loss {'Reaction outcome loss': 0.5092299154055291, 'Total loss': 0.5092299154055291}
2022-12-31 14:37:45,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:45,466 INFO:     Epoch: 4
2022-12-31 14:37:47,072 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6374497791131337, 'Total loss': 0.6374497791131337} | train loss {'Reaction outcome loss': 0.4943989529881788, 'Total loss': 0.4943989529881788}
2022-12-31 14:37:47,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:47,073 INFO:     Epoch: 5
2022-12-31 14:37:48,669 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5638008614381155, 'Total loss': 0.5638008614381155} | train loss {'Reaction outcome loss': 0.4835219603062243, 'Total loss': 0.4835219603062243}
2022-12-31 14:37:48,669 INFO:     Found new best model at epoch 5
2022-12-31 14:37:48,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:48,670 INFO:     Epoch: 6
2022-12-31 14:37:50,295 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5987225453058879, 'Total loss': 0.5987225453058879} | train loss {'Reaction outcome loss': 0.4636525841560533, 'Total loss': 0.4636525841560533}
2022-12-31 14:37:50,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:50,296 INFO:     Epoch: 7
2022-12-31 14:37:51,917 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5771513680617014, 'Total loss': 0.5771513680617014} | train loss {'Reaction outcome loss': 0.4591257103003453, 'Total loss': 0.4591257103003453}
2022-12-31 14:37:51,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:51,917 INFO:     Epoch: 8
2022-12-31 14:37:53,520 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5878866056601206, 'Total loss': 0.5878866056601206} | train loss {'Reaction outcome loss': 0.45304957627777714, 'Total loss': 0.45304957627777714}
2022-12-31 14:37:53,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:53,520 INFO:     Epoch: 9
2022-12-31 14:37:55,132 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5384333233038584, 'Total loss': 0.5384333233038584} | train loss {'Reaction outcome loss': 0.44718714508324914, 'Total loss': 0.44718714508324914}
2022-12-31 14:37:55,132 INFO:     Found new best model at epoch 9
2022-12-31 14:37:55,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:55,133 INFO:     Epoch: 10
2022-12-31 14:37:56,744 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5645012557506561, 'Total loss': 0.5645012557506561} | train loss {'Reaction outcome loss': 0.43788747354478075, 'Total loss': 0.43788747354478075}
2022-12-31 14:37:56,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:56,744 INFO:     Epoch: 11
2022-12-31 14:37:58,351 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5832839339971543, 'Total loss': 0.5832839339971543} | train loss {'Reaction outcome loss': 0.4337194165133912, 'Total loss': 0.4337194165133912}
2022-12-31 14:37:58,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:58,351 INFO:     Epoch: 12
2022-12-31 14:37:59,989 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5686999440193177, 'Total loss': 0.5686999440193177} | train loss {'Reaction outcome loss': 0.44292083285003225, 'Total loss': 0.44292083285003225}
2022-12-31 14:37:59,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:37:59,990 INFO:     Epoch: 13
2022-12-31 14:38:01,607 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5565790096918742, 'Total loss': 0.5565790096918742} | train loss {'Reaction outcome loss': 0.42826308358622633, 'Total loss': 0.42826308358622633}
2022-12-31 14:38:01,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:01,608 INFO:     Epoch: 14
2022-12-31 14:38:03,217 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5446955482165019, 'Total loss': 0.5446955482165019} | train loss {'Reaction outcome loss': 0.4213343857925898, 'Total loss': 0.4213343857925898}
2022-12-31 14:38:03,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:03,217 INFO:     Epoch: 15
2022-12-31 14:38:04,836 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.530235348145167, 'Total loss': 0.530235348145167} | train loss {'Reaction outcome loss': 0.412884435252003, 'Total loss': 0.412884435252003}
2022-12-31 14:38:04,836 INFO:     Found new best model at epoch 15
2022-12-31 14:38:04,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:04,837 INFO:     Epoch: 16
2022-12-31 14:38:06,471 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5222931643327077, 'Total loss': 0.5222931643327077} | train loss {'Reaction outcome loss': 0.4038760988682886, 'Total loss': 0.4038760988682886}
2022-12-31 14:38:06,472 INFO:     Found new best model at epoch 16
2022-12-31 14:38:06,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:06,473 INFO:     Epoch: 17
2022-12-31 14:38:08,088 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5727948864301046, 'Total loss': 0.5727948864301046} | train loss {'Reaction outcome loss': 0.3994035791619208, 'Total loss': 0.3994035791619208}
2022-12-31 14:38:08,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:08,088 INFO:     Epoch: 18
2022-12-31 14:38:09,693 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5669919470945994, 'Total loss': 0.5669919470945994} | train loss {'Reaction outcome loss': 0.403029128909111, 'Total loss': 0.403029128909111}
2022-12-31 14:38:09,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:09,693 INFO:     Epoch: 19
2022-12-31 14:38:11,286 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5304302593072255, 'Total loss': 0.5304302593072255} | train loss {'Reaction outcome loss': 0.42742097477594804, 'Total loss': 0.42742097477594804}
2022-12-31 14:38:11,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:11,287 INFO:     Epoch: 20
2022-12-31 14:38:12,892 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5201673110326132, 'Total loss': 0.5201673110326132} | train loss {'Reaction outcome loss': 0.38339440052168094, 'Total loss': 0.38339440052168094}
2022-12-31 14:38:12,892 INFO:     Found new best model at epoch 20
2022-12-31 14:38:12,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:12,893 INFO:     Epoch: 21
2022-12-31 14:38:14,501 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5243092576662699, 'Total loss': 0.5243092576662699} | train loss {'Reaction outcome loss': 0.37463826385151217, 'Total loss': 0.37463826385151217}
2022-12-31 14:38:14,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:14,501 INFO:     Epoch: 22
2022-12-31 14:38:16,096 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5535213649272919, 'Total loss': 0.5535213649272919} | train loss {'Reaction outcome loss': 0.3713488426612879, 'Total loss': 0.3713488426612879}
2022-12-31 14:38:16,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:16,096 INFO:     Epoch: 23
2022-12-31 14:38:17,779 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5356800218423208, 'Total loss': 0.5356800218423208} | train loss {'Reaction outcome loss': 0.36586014454445354, 'Total loss': 0.36586014454445354}
2022-12-31 14:38:17,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:17,779 INFO:     Epoch: 24
2022-12-31 14:38:19,410 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5130693038304647, 'Total loss': 0.5130693038304647} | train loss {'Reaction outcome loss': 0.35954580523484503, 'Total loss': 0.35954580523484503}
2022-12-31 14:38:19,411 INFO:     Found new best model at epoch 24
2022-12-31 14:38:19,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:19,412 INFO:     Epoch: 25
2022-12-31 14:38:21,019 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5166322628657023, 'Total loss': 0.5166322628657023} | train loss {'Reaction outcome loss': 0.3536856893611991, 'Total loss': 0.3536856893611991}
2022-12-31 14:38:21,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:21,019 INFO:     Epoch: 26
2022-12-31 14:38:22,631 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5509305377801259, 'Total loss': 0.5509305377801259} | train loss {'Reaction outcome loss': 0.34803245944709965, 'Total loss': 0.34803245944709965}
2022-12-31 14:38:22,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:22,632 INFO:     Epoch: 27
2022-12-31 14:38:24,246 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5024297932783762, 'Total loss': 0.5024297932783762} | train loss {'Reaction outcome loss': 0.3387891394676695, 'Total loss': 0.3387891394676695}
2022-12-31 14:38:24,247 INFO:     Found new best model at epoch 27
2022-12-31 14:38:24,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:24,248 INFO:     Epoch: 28
2022-12-31 14:38:25,856 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.49237768749396005, 'Total loss': 0.49237768749396005} | train loss {'Reaction outcome loss': 0.3354678218737177, 'Total loss': 0.3354678218737177}
2022-12-31 14:38:25,856 INFO:     Found new best model at epoch 28
2022-12-31 14:38:25,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:25,857 INFO:     Epoch: 29
2022-12-31 14:38:27,475 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.544272251923879, 'Total loss': 0.544272251923879} | train loss {'Reaction outcome loss': 0.3344545805070927, 'Total loss': 0.3344545805070927}
2022-12-31 14:38:27,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:27,476 INFO:     Epoch: 30
2022-12-31 14:38:29,068 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5152107278505961, 'Total loss': 0.5152107278505961} | train loss {'Reaction outcome loss': 0.33093459850204165, 'Total loss': 0.33093459850204165}
2022-12-31 14:38:29,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:29,069 INFO:     Epoch: 31
2022-12-31 14:38:30,678 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49698728223641714, 'Total loss': 0.49698728223641714} | train loss {'Reaction outcome loss': 0.32223298092899116, 'Total loss': 0.32223298092899116}
2022-12-31 14:38:30,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:30,679 INFO:     Epoch: 32
2022-12-31 14:38:32,299 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4918020327885946, 'Total loss': 0.4918020327885946} | train loss {'Reaction outcome loss': 0.3181532789722964, 'Total loss': 0.3181532789722964}
2022-12-31 14:38:32,299 INFO:     Found new best model at epoch 32
2022-12-31 14:38:32,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:32,300 INFO:     Epoch: 33
2022-12-31 14:38:33,901 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5074683507283528, 'Total loss': 0.5074683507283528} | train loss {'Reaction outcome loss': 0.31650814349236694, 'Total loss': 0.31650814349236694}
2022-12-31 14:38:33,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:33,901 INFO:     Epoch: 34
2022-12-31 14:38:35,508 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5484631220499675, 'Total loss': 0.5484631220499675} | train loss {'Reaction outcome loss': 0.3139338238954382, 'Total loss': 0.3139338238954382}
2022-12-31 14:38:35,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:35,509 INFO:     Epoch: 35
2022-12-31 14:38:37,123 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5093949019908905, 'Total loss': 0.5093949019908905} | train loss {'Reaction outcome loss': 0.3064918596359928, 'Total loss': 0.3064918596359928}
2022-12-31 14:38:37,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:37,123 INFO:     Epoch: 36
2022-12-31 14:38:38,722 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5088247497876485, 'Total loss': 0.5088247497876485} | train loss {'Reaction outcome loss': 0.3024804125931384, 'Total loss': 0.3024804125931384}
2022-12-31 14:38:38,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:38,722 INFO:     Epoch: 37
2022-12-31 14:38:40,334 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5059443414211273, 'Total loss': 0.5059443414211273} | train loss {'Reaction outcome loss': 0.30056020687671675, 'Total loss': 0.30056020687671675}
2022-12-31 14:38:40,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:40,334 INFO:     Epoch: 38
2022-12-31 14:38:41,952 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.504784764846166, 'Total loss': 0.504784764846166} | train loss {'Reaction outcome loss': 0.29290636553280597, 'Total loss': 0.29290636553280597}
2022-12-31 14:38:41,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:41,952 INFO:     Epoch: 39
2022-12-31 14:38:43,556 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5590700447559357, 'Total loss': 0.5590700447559357} | train loss {'Reaction outcome loss': 0.30163529134638933, 'Total loss': 0.30163529134638933}
2022-12-31 14:38:43,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:43,556 INFO:     Epoch: 40
2022-12-31 14:38:45,170 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48923692603905994, 'Total loss': 0.48923692603905994} | train loss {'Reaction outcome loss': 0.3134289037409252, 'Total loss': 0.3134289037409252}
2022-12-31 14:38:45,170 INFO:     Found new best model at epoch 40
2022-12-31 14:38:45,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:45,171 INFO:     Epoch: 41
2022-12-31 14:38:46,767 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4897119174400965, 'Total loss': 0.4897119174400965} | train loss {'Reaction outcome loss': 0.2805845916627468, 'Total loss': 0.2805845916627468}
2022-12-31 14:38:46,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:46,767 INFO:     Epoch: 42
2022-12-31 14:38:48,374 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5720119376977285, 'Total loss': 0.5720119376977285} | train loss {'Reaction outcome loss': 0.28312583482297865, 'Total loss': 0.28312583482297865}
2022-12-31 14:38:48,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:48,374 INFO:     Epoch: 43
2022-12-31 14:38:49,984 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5136058111985524, 'Total loss': 0.5136058111985524} | train loss {'Reaction outcome loss': 0.2740705809218512, 'Total loss': 0.2740705809218512}
2022-12-31 14:38:49,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:49,984 INFO:     Epoch: 44
2022-12-31 14:38:51,592 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4970034490029017, 'Total loss': 0.4970034490029017} | train loss {'Reaction outcome loss': 0.2845521827052901, 'Total loss': 0.2845521827052901}
2022-12-31 14:38:51,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:51,593 INFO:     Epoch: 45
2022-12-31 14:38:53,212 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.533047882715861, 'Total loss': 0.533047882715861} | train loss {'Reaction outcome loss': 0.2806353143416767, 'Total loss': 0.2806353143416767}
2022-12-31 14:38:53,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:53,212 INFO:     Epoch: 46
2022-12-31 14:38:54,840 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5277739763259888, 'Total loss': 0.5277739763259888} | train loss {'Reaction outcome loss': 0.2683947239698761, 'Total loss': 0.2683947239698761}
2022-12-31 14:38:54,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:54,841 INFO:     Epoch: 47
2022-12-31 14:38:56,438 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.49533904194831846, 'Total loss': 0.49533904194831846} | train loss {'Reaction outcome loss': 0.26986993940047704, 'Total loss': 0.26986993940047704}
2022-12-31 14:38:56,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:56,439 INFO:     Epoch: 48
2022-12-31 14:38:58,047 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5968817412853241, 'Total loss': 0.5968817412853241} | train loss {'Reaction outcome loss': 0.27518702967875247, 'Total loss': 0.27518702967875247}
2022-12-31 14:38:58,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:58,047 INFO:     Epoch: 49
2022-12-31 14:38:59,656 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5380996704101563, 'Total loss': 0.5380996704101563} | train loss {'Reaction outcome loss': 0.3285576997389438, 'Total loss': 0.3285576997389438}
2022-12-31 14:38:59,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:38:59,657 INFO:     Epoch: 50
2022-12-31 14:39:01,259 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49195309380690255, 'Total loss': 0.49195309380690255} | train loss {'Reaction outcome loss': 0.2726248886058296, 'Total loss': 0.2726248886058296}
2022-12-31 14:39:01,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:01,260 INFO:     Epoch: 51
2022-12-31 14:39:02,893 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4890577594439189, 'Total loss': 0.4890577594439189} | train loss {'Reaction outcome loss': 0.284866314475843, 'Total loss': 0.284866314475843}
2022-12-31 14:39:02,893 INFO:     Found new best model at epoch 51
2022-12-31 14:39:02,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:02,894 INFO:     Epoch: 52
2022-12-31 14:39:04,518 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5538491388161977, 'Total loss': 0.5538491388161977} | train loss {'Reaction outcome loss': 0.2928001411888492, 'Total loss': 0.2928001411888492}
2022-12-31 14:39:04,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:04,519 INFO:     Epoch: 53
2022-12-31 14:39:06,124 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5073419948418935, 'Total loss': 0.5073419948418935} | train loss {'Reaction outcome loss': 0.26600685792104545, 'Total loss': 0.26600685792104545}
2022-12-31 14:39:06,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:06,125 INFO:     Epoch: 54
2022-12-31 14:39:07,733 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5419034451246262, 'Total loss': 0.5419034451246262} | train loss {'Reaction outcome loss': 0.25551526209987374, 'Total loss': 0.25551526209987374}
2022-12-31 14:39:07,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:07,733 INFO:     Epoch: 55
2022-12-31 14:39:09,371 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5084708789984386, 'Total loss': 0.5084708789984386} | train loss {'Reaction outcome loss': 0.25345227368745615, 'Total loss': 0.25345227368745615}
2022-12-31 14:39:09,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:09,371 INFO:     Epoch: 56
2022-12-31 14:39:10,987 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49929909308751425, 'Total loss': 0.49929909308751425} | train loss {'Reaction outcome loss': 0.2518806686233459, 'Total loss': 0.2518806686233459}
2022-12-31 14:39:10,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:10,987 INFO:     Epoch: 57
2022-12-31 14:39:12,628 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47315703133742015, 'Total loss': 0.47315703133742015} | train loss {'Reaction outcome loss': 0.253877592035652, 'Total loss': 0.253877592035652}
2022-12-31 14:39:12,629 INFO:     Found new best model at epoch 57
2022-12-31 14:39:12,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:12,630 INFO:     Epoch: 58
2022-12-31 14:39:14,246 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5051958521207174, 'Total loss': 0.5051958521207174} | train loss {'Reaction outcome loss': 0.2499571290757993, 'Total loss': 0.2499571290757993}
2022-12-31 14:39:14,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:14,246 INFO:     Epoch: 59
2022-12-31 14:39:15,874 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5042993783950805, 'Total loss': 0.5042993783950805} | train loss {'Reaction outcome loss': 0.24437990156508496, 'Total loss': 0.24437990156508496}
2022-12-31 14:39:15,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:15,875 INFO:     Epoch: 60
2022-12-31 14:39:17,486 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5125932772954305, 'Total loss': 0.5125932772954305} | train loss {'Reaction outcome loss': 0.24762343866836012, 'Total loss': 0.24762343866836012}
2022-12-31 14:39:17,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:17,486 INFO:     Epoch: 61
2022-12-31 14:39:19,089 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5114421884218852, 'Total loss': 0.5114421884218852} | train loss {'Reaction outcome loss': 0.24182250842723507, 'Total loss': 0.24182250842723507}
2022-12-31 14:39:19,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:19,089 INFO:     Epoch: 62
2022-12-31 14:39:20,720 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49168150971333185, 'Total loss': 0.49168150971333185} | train loss {'Reaction outcome loss': 0.23991316835362458, 'Total loss': 0.23991316835362458}
2022-12-31 14:39:20,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:20,720 INFO:     Epoch: 63
2022-12-31 14:39:22,331 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4907227019468943, 'Total loss': 0.4907227019468943} | train loss {'Reaction outcome loss': 0.2387825645290423, 'Total loss': 0.2387825645290423}
2022-12-31 14:39:22,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:22,331 INFO:     Epoch: 64
2022-12-31 14:39:23,928 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5210792203744252, 'Total loss': 0.5210792203744252} | train loss {'Reaction outcome loss': 0.24403857598751885, 'Total loss': 0.24403857598751885}
2022-12-31 14:39:23,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:23,928 INFO:     Epoch: 65
2022-12-31 14:39:25,539 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5187561055024464, 'Total loss': 0.5187561055024464} | train loss {'Reaction outcome loss': 0.23360800161216225, 'Total loss': 0.23360800161216225}
2022-12-31 14:39:25,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:25,540 INFO:     Epoch: 66
2022-12-31 14:39:27,144 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4861404796441396, 'Total loss': 0.4861404796441396} | train loss {'Reaction outcome loss': 0.23473137716317308, 'Total loss': 0.23473137716317308}
2022-12-31 14:39:27,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:27,144 INFO:     Epoch: 67
2022-12-31 14:39:28,746 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5317674667264024, 'Total loss': 0.5317674667264024} | train loss {'Reaction outcome loss': 0.24792124725122383, 'Total loss': 0.24792124725122383}
2022-12-31 14:39:28,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:28,746 INFO:     Epoch: 68
2022-12-31 14:39:30,384 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49985671738783516, 'Total loss': 0.49985671738783516} | train loss {'Reaction outcome loss': 0.2372615384005442, 'Total loss': 0.2372615384005442}
2022-12-31 14:39:30,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:30,384 INFO:     Epoch: 69
2022-12-31 14:39:32,000 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5354556520779927, 'Total loss': 0.5354556520779927} | train loss {'Reaction outcome loss': 0.26202219320407166, 'Total loss': 0.26202219320407166}
2022-12-31 14:39:32,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:32,000 INFO:     Epoch: 70
2022-12-31 14:39:33,608 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5426095366477967, 'Total loss': 0.5426095366477967} | train loss {'Reaction outcome loss': 0.24838102756041117, 'Total loss': 0.24838102756041117}
2022-12-31 14:39:33,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:33,608 INFO:     Epoch: 71
2022-12-31 14:39:35,216 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5433223356803258, 'Total loss': 0.5433223356803258} | train loss {'Reaction outcome loss': 0.23113517303937586, 'Total loss': 0.23113517303937586}
2022-12-31 14:39:35,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:35,217 INFO:     Epoch: 72
2022-12-31 14:39:36,825 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49211500386397045, 'Total loss': 0.49211500386397045} | train loss {'Reaction outcome loss': 0.2766180246869318, 'Total loss': 0.2766180246869318}
2022-12-31 14:39:36,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:36,827 INFO:     Epoch: 73
2022-12-31 14:39:38,443 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5567676723003387, 'Total loss': 0.5567676723003387} | train loss {'Reaction outcome loss': 0.22995793548129176, 'Total loss': 0.22995793548129176}
2022-12-31 14:39:38,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:38,443 INFO:     Epoch: 74
2022-12-31 14:39:40,084 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5036170502503713, 'Total loss': 0.5036170502503713} | train loss {'Reaction outcome loss': 0.3077353360603793, 'Total loss': 0.3077353360603793}
2022-12-31 14:39:40,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:40,084 INFO:     Epoch: 75
2022-12-31 14:39:41,687 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4943543920914332, 'Total loss': 0.4943543920914332} | train loss {'Reaction outcome loss': 0.24001223072316835, 'Total loss': 0.24001223072316835}
2022-12-31 14:39:41,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:41,687 INFO:     Epoch: 76
2022-12-31 14:39:43,297 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5197279552618662, 'Total loss': 0.5197279552618662} | train loss {'Reaction outcome loss': 0.22625753208400134, 'Total loss': 0.22625753208400134}
2022-12-31 14:39:43,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:43,298 INFO:     Epoch: 77
2022-12-31 14:39:44,908 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4798227111498515, 'Total loss': 0.4798227111498515} | train loss {'Reaction outcome loss': 0.2250173302617032, 'Total loss': 0.2250173302617032}
2022-12-31 14:39:44,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:44,908 INFO:     Epoch: 78
2022-12-31 14:39:46,504 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5612848301728567, 'Total loss': 0.5612848301728567} | train loss {'Reaction outcome loss': 0.22755946482167297, 'Total loss': 0.22755946482167297}
2022-12-31 14:39:46,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:46,504 INFO:     Epoch: 79
2022-12-31 14:39:48,123 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49964744249979653, 'Total loss': 0.49964744249979653} | train loss {'Reaction outcome loss': 0.2873405834568826, 'Total loss': 0.2873405834568826}
2022-12-31 14:39:48,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:48,123 INFO:     Epoch: 80
2022-12-31 14:39:49,752 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4769025554259618, 'Total loss': 0.4769025554259618} | train loss {'Reaction outcome loss': 0.24419027477320607, 'Total loss': 0.24419027477320607}
2022-12-31 14:39:49,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:49,752 INFO:     Epoch: 81
2022-12-31 14:39:51,387 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.530857249101003, 'Total loss': 0.530857249101003} | train loss {'Reaction outcome loss': 0.23534631012343976, 'Total loss': 0.23534631012343976}
2022-12-31 14:39:51,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:51,387 INFO:     Epoch: 82
2022-12-31 14:39:53,012 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4508164130151272, 'Total loss': 0.4508164130151272} | train loss {'Reaction outcome loss': 0.2315557894728862, 'Total loss': 0.2315557894728862}
2022-12-31 14:39:53,012 INFO:     Found new best model at epoch 82
2022-12-31 14:39:53,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:53,013 INFO:     Epoch: 83
2022-12-31 14:39:54,623 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4751812696456909, 'Total loss': 0.4751812696456909} | train loss {'Reaction outcome loss': 0.22810330882371552, 'Total loss': 0.22810330882371552}
2022-12-31 14:39:54,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:54,623 INFO:     Epoch: 84
2022-12-31 14:39:56,214 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49771244724591573, 'Total loss': 0.49771244724591573} | train loss {'Reaction outcome loss': 0.22669642905205273, 'Total loss': 0.22669642905205273}
2022-12-31 14:39:56,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:56,215 INFO:     Epoch: 85
2022-12-31 14:39:57,863 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.513282835483551, 'Total loss': 0.513282835483551} | train loss {'Reaction outcome loss': 0.3281936800314883, 'Total loss': 0.3281936800314883}
2022-12-31 14:39:57,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:57,863 INFO:     Epoch: 86
2022-12-31 14:39:59,464 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47073283096154533, 'Total loss': 0.47073283096154533} | train loss {'Reaction outcome loss': 0.2543144893117141, 'Total loss': 0.2543144893117141}
2022-12-31 14:39:59,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:39:59,464 INFO:     Epoch: 87
2022-12-31 14:40:01,077 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49508782227834064, 'Total loss': 0.49508782227834064} | train loss {'Reaction outcome loss': 0.24107475891250416, 'Total loss': 0.24107475891250416}
2022-12-31 14:40:01,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:01,077 INFO:     Epoch: 88
2022-12-31 14:40:02,688 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5257976194222768, 'Total loss': 0.5257976194222768} | train loss {'Reaction outcome loss': 0.22734465554316083, 'Total loss': 0.22734465554316083}
2022-12-31 14:40:02,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:02,688 INFO:     Epoch: 89
2022-12-31 14:40:04,289 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5105503479639689, 'Total loss': 0.5105503479639689} | train loss {'Reaction outcome loss': 0.21995546882122205, 'Total loss': 0.21995546882122205}
2022-12-31 14:40:04,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:04,289 INFO:     Epoch: 90
2022-12-31 14:40:05,917 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5401070435841878, 'Total loss': 0.5401070435841878} | train loss {'Reaction outcome loss': 0.2157894633257746, 'Total loss': 0.2157894633257746}
2022-12-31 14:40:05,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:05,917 INFO:     Epoch: 91
2022-12-31 14:40:07,529 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.484201991558075, 'Total loss': 0.484201991558075} | train loss {'Reaction outcome loss': 0.21104232095303418, 'Total loss': 0.21104232095303418}
2022-12-31 14:40:07,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:07,531 INFO:     Epoch: 92
2022-12-31 14:40:09,139 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5182538648446401, 'Total loss': 0.5182538648446401} | train loss {'Reaction outcome loss': 0.21913683896570507, 'Total loss': 0.21913683896570507}
2022-12-31 14:40:09,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:09,139 INFO:     Epoch: 93
2022-12-31 14:40:10,749 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5036137983202934, 'Total loss': 0.5036137983202934} | train loss {'Reaction outcome loss': 0.22762254225360096, 'Total loss': 0.22762254225360096}
2022-12-31 14:40:10,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:10,749 INFO:     Epoch: 94
2022-12-31 14:40:12,367 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4891365091005961, 'Total loss': 0.4891365091005961} | train loss {'Reaction outcome loss': 0.2552494502416543, 'Total loss': 0.2552494502416543}
2022-12-31 14:40:12,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:12,367 INFO:     Epoch: 95
2022-12-31 14:40:13,972 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4716531842947006, 'Total loss': 0.4716531842947006} | train loss {'Reaction outcome loss': 0.22015712886670794, 'Total loss': 0.22015712886670794}
2022-12-31 14:40:13,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:13,972 INFO:     Epoch: 96
2022-12-31 14:40:15,602 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5028868565956751, 'Total loss': 0.5028868565956751} | train loss {'Reaction outcome loss': 0.21135416696357634, 'Total loss': 0.21135416696357634}
2022-12-31 14:40:15,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:15,602 INFO:     Epoch: 97
2022-12-31 14:40:17,205 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5388924747705459, 'Total loss': 0.5388924747705459} | train loss {'Reaction outcome loss': 0.21412296770596068, 'Total loss': 0.21412296770596068}
2022-12-31 14:40:17,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:17,205 INFO:     Epoch: 98
2022-12-31 14:40:18,844 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5025549352169036, 'Total loss': 0.5025549352169036} | train loss {'Reaction outcome loss': 0.20861360612004806, 'Total loss': 0.20861360612004806}
2022-12-31 14:40:18,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:18,844 INFO:     Epoch: 99
2022-12-31 14:40:20,486 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5446987291177113, 'Total loss': 0.5446987291177113} | train loss {'Reaction outcome loss': 0.2008575590095817, 'Total loss': 0.2008575590095817}
2022-12-31 14:40:20,486 INFO:     Best model found after epoch 83 of 100.
2022-12-31 14:40:20,486 INFO:   Done with stage: TRAINING
2022-12-31 14:40:20,486 INFO:   Starting stage: EVALUATION
2022-12-31 14:40:20,616 INFO:   Done with stage: EVALUATION
2022-12-31 14:40:20,616 INFO:   Leaving out SEQ value Fold_5
2022-12-31 14:40:20,629 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 14:40:20,629 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:40:21,273 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:40:21,273 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:40:21,343 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:40:21,343 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:40:21,343 INFO:     No hyperparam tuning for this model
2022-12-31 14:40:21,343 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:40:21,343 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:40:21,344 INFO:     None feature selector for col prot
2022-12-31 14:40:21,344 INFO:     None feature selector for col prot
2022-12-31 14:40:21,344 INFO:     None feature selector for col prot
2022-12-31 14:40:21,345 INFO:     None feature selector for col chem
2022-12-31 14:40:21,345 INFO:     None feature selector for col chem
2022-12-31 14:40:21,345 INFO:     None feature selector for col chem
2022-12-31 14:40:21,345 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:40:21,345 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:40:21,347 INFO:     Number of params in model 223921
2022-12-31 14:40:21,350 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:40:21,350 INFO:   Starting stage: TRAINING
2022-12-31 14:40:21,394 INFO:     Val loss before train {'Reaction outcome loss': 0.9733663439750672, 'Total loss': 0.9733663439750672}
2022-12-31 14:40:21,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:21,395 INFO:     Epoch: 0
2022-12-31 14:40:23,011 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6028004507223765, 'Total loss': 0.6028004507223765} | train loss {'Reaction outcome loss': 0.7972644154400821, 'Total loss': 0.7972644154400821}
2022-12-31 14:40:23,011 INFO:     Found new best model at epoch 0
2022-12-31 14:40:23,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:23,012 INFO:     Epoch: 1
2022-12-31 14:40:24,656 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5028034369150798, 'Total loss': 0.5028034369150798} | train loss {'Reaction outcome loss': 0.5913105777302838, 'Total loss': 0.5913105777302838}
2022-12-31 14:40:24,656 INFO:     Found new best model at epoch 1
2022-12-31 14:40:24,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:24,657 INFO:     Epoch: 2
2022-12-31 14:40:26,264 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4867320716381073, 'Total loss': 0.4867320716381073} | train loss {'Reaction outcome loss': 0.5323896963635216, 'Total loss': 0.5323896963635216}
2022-12-31 14:40:26,265 INFO:     Found new best model at epoch 2
2022-12-31 14:40:26,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:26,266 INFO:     Epoch: 3
2022-12-31 14:40:27,877 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4780963083108266, 'Total loss': 0.4780963083108266} | train loss {'Reaction outcome loss': 0.5171036104253237, 'Total loss': 0.5171036104253237}
2022-12-31 14:40:27,877 INFO:     Found new best model at epoch 3
2022-12-31 14:40:27,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:27,878 INFO:     Epoch: 4
2022-12-31 14:40:29,489 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47500423739353814, 'Total loss': 0.47500423739353814} | train loss {'Reaction outcome loss': 0.503456306360338, 'Total loss': 0.503456306360338}
2022-12-31 14:40:29,489 INFO:     Found new best model at epoch 4
2022-12-31 14:40:29,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:29,490 INFO:     Epoch: 5
2022-12-31 14:40:31,125 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5006650974353154, 'Total loss': 0.5006650974353154} | train loss {'Reaction outcome loss': 0.4829307999934299, 'Total loss': 0.4829307999934299}
2022-12-31 14:40:31,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:31,125 INFO:     Epoch: 6
2022-12-31 14:40:32,745 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5048089166482289, 'Total loss': 0.5048089166482289} | train loss {'Reaction outcome loss': 0.4685442296491153, 'Total loss': 0.4685442296491153}
2022-12-31 14:40:32,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:32,745 INFO:     Epoch: 7
2022-12-31 14:40:34,367 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5062644898891449, 'Total loss': 0.5062644898891449} | train loss {'Reaction outcome loss': 0.5042330104911673, 'Total loss': 0.5042330104911673}
2022-12-31 14:40:34,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:34,367 INFO:     Epoch: 8
2022-12-31 14:40:35,982 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47230588893095654, 'Total loss': 0.47230588893095654} | train loss {'Reaction outcome loss': 0.46762348058215086, 'Total loss': 0.46762348058215086}
2022-12-31 14:40:35,982 INFO:     Found new best model at epoch 8
2022-12-31 14:40:35,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:35,983 INFO:     Epoch: 9
2022-12-31 14:40:37,632 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4805888096491496, 'Total loss': 0.4805888096491496} | train loss {'Reaction outcome loss': 0.44921925754370284, 'Total loss': 0.44921925754370284}
2022-12-31 14:40:37,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:37,633 INFO:     Epoch: 10
2022-12-31 14:40:39,248 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4487753262122472, 'Total loss': 0.4487753262122472} | train loss {'Reaction outcome loss': 0.44009835389105306, 'Total loss': 0.44009835389105306}
2022-12-31 14:40:39,248 INFO:     Found new best model at epoch 10
2022-12-31 14:40:39,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:39,249 INFO:     Epoch: 11
2022-12-31 14:40:40,850 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4275440017382304, 'Total loss': 0.4275440017382304} | train loss {'Reaction outcome loss': 0.4374464617793938, 'Total loss': 0.4374464617793938}
2022-12-31 14:40:40,850 INFO:     Found new best model at epoch 11
2022-12-31 14:40:40,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:40,851 INFO:     Epoch: 12
2022-12-31 14:40:42,469 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4497581273317337, 'Total loss': 0.4497581273317337} | train loss {'Reaction outcome loss': 0.42706182337217574, 'Total loss': 0.42706182337217574}
2022-12-31 14:40:42,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:42,470 INFO:     Epoch: 13
2022-12-31 14:40:44,073 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44650654594103495, 'Total loss': 0.44650654594103495} | train loss {'Reaction outcome loss': 0.42124407038605516, 'Total loss': 0.42124407038605516}
2022-12-31 14:40:44,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:44,074 INFO:     Epoch: 14
2022-12-31 14:40:45,691 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41276868780454, 'Total loss': 0.41276868780454} | train loss {'Reaction outcome loss': 0.42533395663443685, 'Total loss': 0.42533395663443685}
2022-12-31 14:40:45,692 INFO:     Found new best model at epoch 14
2022-12-31 14:40:45,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:45,693 INFO:     Epoch: 15
2022-12-31 14:40:47,319 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4216539497176806, 'Total loss': 0.4216539497176806} | train loss {'Reaction outcome loss': 0.4387030673847682, 'Total loss': 0.4387030673847682}
2022-12-31 14:40:47,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:47,319 INFO:     Epoch: 16
2022-12-31 14:40:48,965 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4383055845896403, 'Total loss': 0.4383055845896403} | train loss {'Reaction outcome loss': 0.42419910784909903, 'Total loss': 0.42419910784909903}
2022-12-31 14:40:48,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:48,965 INFO:     Epoch: 17
2022-12-31 14:40:50,586 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49074341654777526, 'Total loss': 0.49074341654777526} | train loss {'Reaction outcome loss': 0.4052617374206117, 'Total loss': 0.4052617374206117}
2022-12-31 14:40:50,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:50,586 INFO:     Epoch: 18
2022-12-31 14:40:52,229 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4113412102063497, 'Total loss': 0.4113412102063497} | train loss {'Reaction outcome loss': 0.4043038158797308, 'Total loss': 0.4043038158797308}
2022-12-31 14:40:52,229 INFO:     Found new best model at epoch 18
2022-12-31 14:40:52,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:52,230 INFO:     Epoch: 19
2022-12-31 14:40:53,832 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43145272334416707, 'Total loss': 0.43145272334416707} | train loss {'Reaction outcome loss': 0.4017643598380728, 'Total loss': 0.4017643598380728}
2022-12-31 14:40:53,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:53,832 INFO:     Epoch: 20
2022-12-31 14:40:55,447 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45884772936503093, 'Total loss': 0.45884772936503093} | train loss {'Reaction outcome loss': 0.39128043966880743, 'Total loss': 0.39128043966880743}
2022-12-31 14:40:55,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:55,448 INFO:     Epoch: 21
2022-12-31 14:40:57,062 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.473643030722936, 'Total loss': 0.473643030722936} | train loss {'Reaction outcome loss': 0.38721758933599526, 'Total loss': 0.38721758933599526}
2022-12-31 14:40:57,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:57,062 INFO:     Epoch: 22
2022-12-31 14:40:58,660 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4095914512872696, 'Total loss': 0.4095914512872696} | train loss {'Reaction outcome loss': 0.38406401709410903, 'Total loss': 0.38406401709410903}
2022-12-31 14:40:58,660 INFO:     Found new best model at epoch 22
2022-12-31 14:40:58,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:40:58,661 INFO:     Epoch: 23
2022-12-31 14:41:00,277 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41122290790081023, 'Total loss': 0.41122290790081023} | train loss {'Reaction outcome loss': 0.3813690581018159, 'Total loss': 0.3813690581018159}
2022-12-31 14:41:00,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:00,277 INFO:     Epoch: 24
2022-12-31 14:41:01,917 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4091207394997279, 'Total loss': 0.4091207394997279} | train loss {'Reaction outcome loss': 0.37205786796023504, 'Total loss': 0.37205786796023504}
2022-12-31 14:41:01,917 INFO:     Found new best model at epoch 24
2022-12-31 14:41:01,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:01,918 INFO:     Epoch: 25
2022-12-31 14:41:03,522 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39269569714864094, 'Total loss': 0.39269569714864094} | train loss {'Reaction outcome loss': 0.3712304659513419, 'Total loss': 0.3712304659513419}
2022-12-31 14:41:03,522 INFO:     Found new best model at epoch 25
2022-12-31 14:41:03,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:03,523 INFO:     Epoch: 26
2022-12-31 14:41:05,147 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4103367487589518, 'Total loss': 0.4103367487589518} | train loss {'Reaction outcome loss': 0.36517336276828893, 'Total loss': 0.36517336276828893}
2022-12-31 14:41:05,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:05,148 INFO:     Epoch: 27
2022-12-31 14:41:06,766 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42100854913393654, 'Total loss': 0.42100854913393654} | train loss {'Reaction outcome loss': 0.360546664830126, 'Total loss': 0.360546664830126}
2022-12-31 14:41:06,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:06,766 INFO:     Epoch: 28
2022-12-31 14:41:08,387 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4565430571635564, 'Total loss': 0.4565430571635564} | train loss {'Reaction outcome loss': 0.37117594248358754, 'Total loss': 0.37117594248358754}
2022-12-31 14:41:08,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:08,387 INFO:     Epoch: 29
2022-12-31 14:41:10,002 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4074698974688848, 'Total loss': 0.4074698974688848} | train loss {'Reaction outcome loss': 0.39147197064754646, 'Total loss': 0.39147197064754646}
2022-12-31 14:41:10,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:10,002 INFO:     Epoch: 30
2022-12-31 14:41:11,599 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4285417159398397, 'Total loss': 0.4285417159398397} | train loss {'Reaction outcome loss': 0.34943676830701315, 'Total loss': 0.34943676830701315}
2022-12-31 14:41:11,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:11,599 INFO:     Epoch: 31
2022-12-31 14:41:13,234 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45615560909112296, 'Total loss': 0.45615560909112296} | train loss {'Reaction outcome loss': 0.3408875726399592, 'Total loss': 0.3408875726399592}
2022-12-31 14:41:13,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:13,235 INFO:     Epoch: 32
2022-12-31 14:41:14,853 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38553993503252665, 'Total loss': 0.38553993503252665} | train loss {'Reaction outcome loss': 0.33955765375192615, 'Total loss': 0.33955765375192615}
2022-12-31 14:41:14,854 INFO:     Found new best model at epoch 32
2022-12-31 14:41:14,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:14,855 INFO:     Epoch: 33
2022-12-31 14:41:16,456 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3811483492453893, 'Total loss': 0.3811483492453893} | train loss {'Reaction outcome loss': 0.3432729195222276, 'Total loss': 0.3432729195222276}
2022-12-31 14:41:16,456 INFO:     Found new best model at epoch 33
2022-12-31 14:41:16,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:16,457 INFO:     Epoch: 34
2022-12-31 14:41:18,057 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3926054507493973, 'Total loss': 0.3926054507493973} | train loss {'Reaction outcome loss': 0.3302713493290155, 'Total loss': 0.3302713493290155}
2022-12-31 14:41:18,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:18,058 INFO:     Epoch: 35
2022-12-31 14:41:19,667 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4087355817357699, 'Total loss': 0.4087355817357699} | train loss {'Reaction outcome loss': 0.35686642507874017, 'Total loss': 0.35686642507874017}
2022-12-31 14:41:19,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:19,668 INFO:     Epoch: 36
2022-12-31 14:41:21,265 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42849029699961344, 'Total loss': 0.42849029699961344} | train loss {'Reaction outcome loss': 0.3280009988364696, 'Total loss': 0.3280009988364696}
2022-12-31 14:41:21,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:21,266 INFO:     Epoch: 37
2022-12-31 14:41:22,874 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4144922306140264, 'Total loss': 0.4144922306140264} | train loss {'Reaction outcome loss': 0.32150576201704517, 'Total loss': 0.32150576201704517}
2022-12-31 14:41:22,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:22,874 INFO:     Epoch: 38
2022-12-31 14:41:24,481 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3948949674765269, 'Total loss': 0.3948949674765269} | train loss {'Reaction outcome loss': 0.3155864915503459, 'Total loss': 0.3155864915503459}
2022-12-31 14:41:24,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:24,481 INFO:     Epoch: 39
2022-12-31 14:41:26,078 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41287507812182106, 'Total loss': 0.41287507812182106} | train loss {'Reaction outcome loss': 0.3157324032837768, 'Total loss': 0.3157324032837768}
2022-12-31 14:41:26,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:26,078 INFO:     Epoch: 40
2022-12-31 14:41:27,689 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4018573115269343, 'Total loss': 0.4018573115269343} | train loss {'Reaction outcome loss': 0.3092576038687422, 'Total loss': 0.3092576038687422}
2022-12-31 14:41:27,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:27,689 INFO:     Epoch: 41
2022-12-31 14:41:29,284 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40619592865308124, 'Total loss': 0.40619592865308124} | train loss {'Reaction outcome loss': 0.3055896156079868, 'Total loss': 0.3055896156079868}
2022-12-31 14:41:29,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:29,284 INFO:     Epoch: 42
2022-12-31 14:41:30,894 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3800768911838531, 'Total loss': 0.3800768911838531} | train loss {'Reaction outcome loss': 0.3067053717466584, 'Total loss': 0.3067053717466584}
2022-12-31 14:41:30,894 INFO:     Found new best model at epoch 42
2022-12-31 14:41:30,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:30,895 INFO:     Epoch: 43
2022-12-31 14:41:32,506 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3736753632624944, 'Total loss': 0.3736753632624944} | train loss {'Reaction outcome loss': 0.31445915172335465, 'Total loss': 0.31445915172335465}
2022-12-31 14:41:32,506 INFO:     Found new best model at epoch 43
2022-12-31 14:41:32,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:32,507 INFO:     Epoch: 44
2022-12-31 14:41:34,116 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.37339400698741276, 'Total loss': 0.37339400698741276} | train loss {'Reaction outcome loss': 0.2957400564860175, 'Total loss': 0.2957400564860175}
2022-12-31 14:41:34,117 INFO:     Found new best model at epoch 44
2022-12-31 14:41:34,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:34,118 INFO:     Epoch: 45
2022-12-31 14:41:35,740 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4492258717616399, 'Total loss': 0.4492258717616399} | train loss {'Reaction outcome loss': 0.2932778190722498, 'Total loss': 0.2932778190722498}
2022-12-31 14:41:35,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:35,741 INFO:     Epoch: 46
2022-12-31 14:41:37,354 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42135267456372577, 'Total loss': 0.42135267456372577} | train loss {'Reaction outcome loss': 0.2952729760419469, 'Total loss': 0.2952729760419469}
2022-12-31 14:41:37,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:37,355 INFO:     Epoch: 47
2022-12-31 14:41:38,952 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4009708076715469, 'Total loss': 0.4009708076715469} | train loss {'Reaction outcome loss': 0.2898655722096589, 'Total loss': 0.2898655722096589}
2022-12-31 14:41:38,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:38,952 INFO:     Epoch: 48
2022-12-31 14:41:40,565 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4276716947555542, 'Total loss': 0.4276716947555542} | train loss {'Reaction outcome loss': 0.28489242099475226, 'Total loss': 0.28489242099475226}
2022-12-31 14:41:40,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:40,565 INFO:     Epoch: 49
2022-12-31 14:41:42,179 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.384014430642128, 'Total loss': 0.384014430642128} | train loss {'Reaction outcome loss': 0.28453326593844924, 'Total loss': 0.28453326593844924}
2022-12-31 14:41:42,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:42,179 INFO:     Epoch: 50
2022-12-31 14:41:43,774 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4220425228277842, 'Total loss': 0.4220425228277842} | train loss {'Reaction outcome loss': 0.2866175343317108, 'Total loss': 0.2866175343317108}
2022-12-31 14:41:43,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:43,774 INFO:     Epoch: 51
2022-12-31 14:41:45,389 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4010321165124575, 'Total loss': 0.4010321165124575} | train loss {'Reaction outcome loss': 0.2756347295539656, 'Total loss': 0.2756347295539656}
2022-12-31 14:41:45,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:45,389 INFO:     Epoch: 52
2022-12-31 14:41:47,015 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3854995091756185, 'Total loss': 0.3854995091756185} | train loss {'Reaction outcome loss': 0.2869033847625057, 'Total loss': 0.2869033847625057}
2022-12-31 14:41:47,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:47,015 INFO:     Epoch: 53
2022-12-31 14:41:48,613 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40924260119597117, 'Total loss': 0.40924260119597117} | train loss {'Reaction outcome loss': 0.2743814081213845, 'Total loss': 0.2743814081213845}
2022-12-31 14:41:48,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:48,613 INFO:     Epoch: 54
2022-12-31 14:41:50,226 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4005827456712723, 'Total loss': 0.4005827456712723} | train loss {'Reaction outcome loss': 0.2733763960654935, 'Total loss': 0.2733763960654935}
2022-12-31 14:41:50,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:50,228 INFO:     Epoch: 55
2022-12-31 14:41:51,843 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40925727287928265, 'Total loss': 0.40925727287928265} | train loss {'Reaction outcome loss': 0.26272747977265576, 'Total loss': 0.26272747977265576}
2022-12-31 14:41:51,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:51,843 INFO:     Epoch: 56
2022-12-31 14:41:53,458 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3681997994581858, 'Total loss': 0.3681997994581858} | train loss {'Reaction outcome loss': 0.2652328517920662, 'Total loss': 0.2652328517920662}
2022-12-31 14:41:53,459 INFO:     Found new best model at epoch 56
2022-12-31 14:41:53,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:53,460 INFO:     Epoch: 57
2022-12-31 14:41:55,093 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39129722913106285, 'Total loss': 0.39129722913106285} | train loss {'Reaction outcome loss': 0.2650888662420861, 'Total loss': 0.2650888662420861}
2022-12-31 14:41:55,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:55,093 INFO:     Epoch: 58
2022-12-31 14:41:56,692 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40266313950220745, 'Total loss': 0.40266313950220745} | train loss {'Reaction outcome loss': 0.26059187746242335, 'Total loss': 0.26059187746242335}
2022-12-31 14:41:56,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:56,693 INFO:     Epoch: 59
2022-12-31 14:41:58,308 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38786040246486664, 'Total loss': 0.38786040246486664} | train loss {'Reaction outcome loss': 0.2568613120449194, 'Total loss': 0.2568613120449194}
2022-12-31 14:41:58,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:58,308 INFO:     Epoch: 60
2022-12-31 14:41:59,923 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.38543741206328075, 'Total loss': 0.38543741206328075} | train loss {'Reaction outcome loss': 0.2902530378702542, 'Total loss': 0.2902530378702542}
2022-12-31 14:41:59,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:41:59,923 INFO:     Epoch: 61
2022-12-31 14:42:01,526 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41852683822313946, 'Total loss': 0.41852683822313946} | train loss {'Reaction outcome loss': 0.26187569160770247, 'Total loss': 0.26187569160770247}
2022-12-31 14:42:01,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:01,526 INFO:     Epoch: 62
2022-12-31 14:42:03,163 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3914574039479097, 'Total loss': 0.3914574039479097} | train loss {'Reaction outcome loss': 0.26314849463591783, 'Total loss': 0.26314849463591783}
2022-12-31 14:42:03,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:03,163 INFO:     Epoch: 63
2022-12-31 14:42:04,791 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3825363298257192, 'Total loss': 0.3825363298257192} | train loss {'Reaction outcome loss': 0.2503349341965024, 'Total loss': 0.2503349341965024}
2022-12-31 14:42:04,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:04,791 INFO:     Epoch: 64
2022-12-31 14:42:06,022 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.386591500043869, 'Total loss': 0.386591500043869} | train loss {'Reaction outcome loss': 0.25150719819994527, 'Total loss': 0.25150719819994527}
2022-12-31 14:42:06,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:06,022 INFO:     Epoch: 65
2022-12-31 14:42:07,088 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.364488751689593, 'Total loss': 0.364488751689593} | train loss {'Reaction outcome loss': 0.2490877108513445, 'Total loss': 0.2490877108513445}
2022-12-31 14:42:07,088 INFO:     Found new best model at epoch 65
2022-12-31 14:42:07,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:07,089 INFO:     Epoch: 66
2022-12-31 14:42:08,153 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4261621276537577, 'Total loss': 0.4261621276537577} | train loss {'Reaction outcome loss': 0.24189848446985707, 'Total loss': 0.24189848446985707}
2022-12-31 14:42:08,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:08,153 INFO:     Epoch: 67
2022-12-31 14:42:09,232 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39044072926044465, 'Total loss': 0.39044072926044465} | train loss {'Reaction outcome loss': 0.2426870395159484, 'Total loss': 0.2426870395159484}
2022-12-31 14:42:09,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:09,233 INFO:     Epoch: 68
2022-12-31 14:42:10,515 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38047161102294924, 'Total loss': 0.38047161102294924} | train loss {'Reaction outcome loss': 0.24289850582220202, 'Total loss': 0.24289850582220202}
2022-12-31 14:42:10,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:10,516 INFO:     Epoch: 69
2022-12-31 14:42:12,173 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39463186462720234, 'Total loss': 0.39463186462720234} | train loss {'Reaction outcome loss': 0.24186560203974217, 'Total loss': 0.24186560203974217}
2022-12-31 14:42:12,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:12,173 INFO:     Epoch: 70
2022-12-31 14:42:13,783 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4309979697068532, 'Total loss': 0.4309979697068532} | train loss {'Reaction outcome loss': 0.23742489080051082, 'Total loss': 0.23742489080051082}
2022-12-31 14:42:13,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:13,783 INFO:     Epoch: 71
2022-12-31 14:42:15,395 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37208751291036607, 'Total loss': 0.37208751291036607} | train loss {'Reaction outcome loss': 0.24390657349410333, 'Total loss': 0.24390657349410333}
2022-12-31 14:42:15,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:15,396 INFO:     Epoch: 72
2022-12-31 14:42:17,015 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3734887977441152, 'Total loss': 0.3734887977441152} | train loss {'Reaction outcome loss': 0.23713748597715428, 'Total loss': 0.23713748597715428}
2022-12-31 14:42:17,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:17,016 INFO:     Epoch: 73
2022-12-31 14:42:18,607 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.34215531051158904, 'Total loss': 0.34215531051158904} | train loss {'Reaction outcome loss': 0.24359884233200463, 'Total loss': 0.24359884233200463}
2022-12-31 14:42:18,607 INFO:     Found new best model at epoch 73
2022-12-31 14:42:18,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:18,608 INFO:     Epoch: 74
2022-12-31 14:42:20,223 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3824141710996628, 'Total loss': 0.3824141710996628} | train loss {'Reaction outcome loss': 0.2381220191474194, 'Total loss': 0.2381220191474194}
2022-12-31 14:42:20,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:20,224 INFO:     Epoch: 75
2022-12-31 14:42:21,858 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4508881375193596, 'Total loss': 0.4508881375193596} | train loss {'Reaction outcome loss': 0.24285702567979478, 'Total loss': 0.24285702567979478}
2022-12-31 14:42:21,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:21,858 INFO:     Epoch: 76
2022-12-31 14:42:23,501 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4047431687513987, 'Total loss': 0.4047431687513987} | train loss {'Reaction outcome loss': 0.23301909543089636, 'Total loss': 0.23301909543089636}
2022-12-31 14:42:23,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:23,501 INFO:     Epoch: 77
2022-12-31 14:42:25,151 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38630994657675427, 'Total loss': 0.38630994657675427} | train loss {'Reaction outcome loss': 0.23173370608508223, 'Total loss': 0.23173370608508223}
2022-12-31 14:42:25,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:25,153 INFO:     Epoch: 78
2022-12-31 14:42:26,761 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.36972924570242566, 'Total loss': 0.36972924570242566} | train loss {'Reaction outcome loss': 0.23096629532764765, 'Total loss': 0.23096629532764765}
2022-12-31 14:42:26,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:26,762 INFO:     Epoch: 79
2022-12-31 14:42:28,373 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.35037611971298854, 'Total loss': 0.35037611971298854} | train loss {'Reaction outcome loss': 0.22847983579697978, 'Total loss': 0.22847983579697978}
2022-12-31 14:42:28,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:28,373 INFO:     Epoch: 80
2022-12-31 14:42:30,016 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3649921794732412, 'Total loss': 0.3649921794732412} | train loss {'Reaction outcome loss': 0.22558457257253103, 'Total loss': 0.22558457257253103}
2022-12-31 14:42:30,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:30,017 INFO:     Epoch: 81
2022-12-31 14:42:31,631 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39241893390814464, 'Total loss': 0.39241893390814464} | train loss {'Reaction outcome loss': 0.22234770358688588, 'Total loss': 0.22234770358688588}
2022-12-31 14:42:31,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:31,632 INFO:     Epoch: 82
2022-12-31 14:42:33,241 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37748905618985495, 'Total loss': 0.37748905618985495} | train loss {'Reaction outcome loss': 0.23343550134450197, 'Total loss': 0.23343550134450197}
2022-12-31 14:42:33,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:33,242 INFO:     Epoch: 83
2022-12-31 14:42:34,853 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38073036273320515, 'Total loss': 0.38073036273320515} | train loss {'Reaction outcome loss': 0.28140599825681, 'Total loss': 0.28140599825681}
2022-12-31 14:42:34,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:34,853 INFO:     Epoch: 84
2022-12-31 14:42:36,466 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3813192660609881, 'Total loss': 0.3813192660609881} | train loss {'Reaction outcome loss': 0.23708231193080975, 'Total loss': 0.23708231193080975}
2022-12-31 14:42:36,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:36,466 INFO:     Epoch: 85
2022-12-31 14:42:38,077 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4018704265356064, 'Total loss': 0.4018704265356064} | train loss {'Reaction outcome loss': 0.22965444276865193, 'Total loss': 0.22965444276865193}
2022-12-31 14:42:38,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:38,077 INFO:     Epoch: 86
2022-12-31 14:42:39,690 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3719882021347682, 'Total loss': 0.3719882021347682} | train loss {'Reaction outcome loss': 0.22291885138733103, 'Total loss': 0.22291885138733103}
2022-12-31 14:42:39,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:39,690 INFO:     Epoch: 87
2022-12-31 14:42:41,304 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4054067845145861, 'Total loss': 0.4054067845145861} | train loss {'Reaction outcome loss': 0.22015735809353815, 'Total loss': 0.22015735809353815}
2022-12-31 14:42:41,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:41,305 INFO:     Epoch: 88
2022-12-31 14:42:42,917 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39176174998283386, 'Total loss': 0.39176174998283386} | train loss {'Reaction outcome loss': 0.2186814314159362, 'Total loss': 0.2186814314159362}
2022-12-31 14:42:42,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:42,918 INFO:     Epoch: 89
2022-12-31 14:42:44,530 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38567651708920797, 'Total loss': 0.38567651708920797} | train loss {'Reaction outcome loss': 0.21614376300240637, 'Total loss': 0.21614376300240637}
2022-12-31 14:42:44,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:44,531 INFO:     Epoch: 90
2022-12-31 14:42:46,165 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3716261059045792, 'Total loss': 0.3716261059045792} | train loss {'Reaction outcome loss': 0.2175580745156301, 'Total loss': 0.2175580745156301}
2022-12-31 14:42:46,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:46,165 INFO:     Epoch: 91
2022-12-31 14:42:47,778 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4264628643790881, 'Total loss': 0.4264628643790881} | train loss {'Reaction outcome loss': 0.2115894041785066, 'Total loss': 0.2115894041785066}
2022-12-31 14:42:47,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:47,779 INFO:     Epoch: 92
2022-12-31 14:42:49,400 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3710162470738093, 'Total loss': 0.3710162470738093} | train loss {'Reaction outcome loss': 0.21872967932147835, 'Total loss': 0.21872967932147835}
2022-12-31 14:42:49,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:49,400 INFO:     Epoch: 93
2022-12-31 14:42:51,018 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3722097769379616, 'Total loss': 0.3722097769379616} | train loss {'Reaction outcome loss': 0.21736306924730595, 'Total loss': 0.21736306924730595}
2022-12-31 14:42:51,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:51,019 INFO:     Epoch: 94
2022-12-31 14:42:52,640 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3735103368759155, 'Total loss': 0.3735103368759155} | train loss {'Reaction outcome loss': 0.20778514061669778, 'Total loss': 0.20778514061669778}
2022-12-31 14:42:52,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:52,641 INFO:     Epoch: 95
2022-12-31 14:42:54,258 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.36200447181860607, 'Total loss': 0.36200447181860607} | train loss {'Reaction outcome loss': 0.20260205865581182, 'Total loss': 0.20260205865581182}
2022-12-31 14:42:54,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:54,258 INFO:     Epoch: 96
2022-12-31 14:42:55,868 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44202743570009867, 'Total loss': 0.44202743570009867} | train loss {'Reaction outcome loss': 0.20360828552388147, 'Total loss': 0.20360828552388147}
2022-12-31 14:42:55,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:55,868 INFO:     Epoch: 97
2022-12-31 14:42:57,510 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40499007105827334, 'Total loss': 0.40499007105827334} | train loss {'Reaction outcome loss': 0.214585372503253, 'Total loss': 0.214585372503253}
2022-12-31 14:42:57,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:57,511 INFO:     Epoch: 98
2022-12-31 14:42:59,127 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4075064907471339, 'Total loss': 0.4075064907471339} | train loss {'Reaction outcome loss': 0.20945058651673404, 'Total loss': 0.20945058651673404}
2022-12-31 14:42:59,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:42:59,128 INFO:     Epoch: 99
2022-12-31 14:43:00,748 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37215554813543955, 'Total loss': 0.37215554813543955} | train loss {'Reaction outcome loss': 0.20533493596830985, 'Total loss': 0.20533493596830985}
2022-12-31 14:43:00,748 INFO:     Best model found after epoch 74 of 100.
2022-12-31 14:43:00,748 INFO:   Done with stage: TRAINING
2022-12-31 14:43:00,748 INFO:   Starting stage: EVALUATION
2022-12-31 14:43:00,876 INFO:   Done with stage: EVALUATION
2022-12-31 14:43:00,876 INFO:   Leaving out SEQ value Fold_6
2022-12-31 14:43:00,889 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 14:43:00,889 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:43:01,541 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:43:01,543 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:43:01,611 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:43:01,611 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:43:01,611 INFO:     No hyperparam tuning for this model
2022-12-31 14:43:01,612 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:43:01,612 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:43:01,612 INFO:     None feature selector for col prot
2022-12-31 14:43:01,612 INFO:     None feature selector for col prot
2022-12-31 14:43:01,613 INFO:     None feature selector for col prot
2022-12-31 14:43:01,613 INFO:     None feature selector for col chem
2022-12-31 14:43:01,613 INFO:     None feature selector for col chem
2022-12-31 14:43:01,613 INFO:     None feature selector for col chem
2022-12-31 14:43:01,613 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:43:01,613 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:43:01,615 INFO:     Number of params in model 223921
2022-12-31 14:43:01,618 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:43:01,618 INFO:   Starting stage: TRAINING
2022-12-31 14:43:01,663 INFO:     Val loss before train {'Reaction outcome loss': 1.031873913606008, 'Total loss': 1.031873913606008}
2022-12-31 14:43:01,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:01,664 INFO:     Epoch: 0
2022-12-31 14:43:03,266 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7072609563668569, 'Total loss': 0.7072609563668569} | train loss {'Reaction outcome loss': 0.8255494619965122, 'Total loss': 0.8255494619965122}
2022-12-31 14:43:03,266 INFO:     Found new best model at epoch 0
2022-12-31 14:43:03,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:03,267 INFO:     Epoch: 1
2022-12-31 14:43:04,871 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.580379726489385, 'Total loss': 0.580379726489385} | train loss {'Reaction outcome loss': 0.6070000157567138, 'Total loss': 0.6070000157567138}
2022-12-31 14:43:04,871 INFO:     Found new best model at epoch 1
2022-12-31 14:43:04,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:04,872 INFO:     Epoch: 2
2022-12-31 14:43:06,493 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5355035622914632, 'Total loss': 0.5355035622914632} | train loss {'Reaction outcome loss': 0.5362904781899297, 'Total loss': 0.5362904781899297}
2022-12-31 14:43:06,493 INFO:     Found new best model at epoch 2
2022-12-31 14:43:06,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:06,494 INFO:     Epoch: 3
2022-12-31 14:43:08,113 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5370950678984324, 'Total loss': 0.5370950678984324} | train loss {'Reaction outcome loss': 0.512225630911679, 'Total loss': 0.512225630911679}
2022-12-31 14:43:08,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:08,114 INFO:     Epoch: 4
2022-12-31 14:43:09,734 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5121405680974325, 'Total loss': 0.5121405680974325} | train loss {'Reaction outcome loss': 0.49261466507877255, 'Total loss': 0.49261466507877255}
2022-12-31 14:43:09,734 INFO:     Found new best model at epoch 4
2022-12-31 14:43:09,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:09,735 INFO:     Epoch: 5
2022-12-31 14:43:11,384 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.490686563650767, 'Total loss': 0.490686563650767} | train loss {'Reaction outcome loss': 0.4860323964473573, 'Total loss': 0.4860323964473573}
2022-12-31 14:43:11,384 INFO:     Found new best model at epoch 5
2022-12-31 14:43:11,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:11,385 INFO:     Epoch: 6
2022-12-31 14:43:12,992 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5243577877680461, 'Total loss': 0.5243577877680461} | train loss {'Reaction outcome loss': 0.4718879397541607, 'Total loss': 0.4718879397541607}
2022-12-31 14:43:12,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:12,992 INFO:     Epoch: 7
2022-12-31 14:43:14,590 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4848546048005422, 'Total loss': 0.4848546048005422} | train loss {'Reaction outcome loss': 0.46406588039028085, 'Total loss': 0.46406588039028085}
2022-12-31 14:43:14,590 INFO:     Found new best model at epoch 7
2022-12-31 14:43:14,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:14,591 INFO:     Epoch: 8
2022-12-31 14:43:16,211 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4770685295263926, 'Total loss': 0.4770685295263926} | train loss {'Reaction outcome loss': 0.45487997812699754, 'Total loss': 0.45487997812699754}
2022-12-31 14:43:16,211 INFO:     Found new best model at epoch 8
2022-12-31 14:43:16,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:16,212 INFO:     Epoch: 9
2022-12-31 14:43:17,832 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49999459385871886, 'Total loss': 0.49999459385871886} | train loss {'Reaction outcome loss': 0.45454321989944263, 'Total loss': 0.45454321989944263}
2022-12-31 14:43:17,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:17,832 INFO:     Epoch: 10
2022-12-31 14:43:19,452 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46576932072639465, 'Total loss': 0.46576932072639465} | train loss {'Reaction outcome loss': 0.44308332609355666, 'Total loss': 0.44308332609355666}
2022-12-31 14:43:19,452 INFO:     Found new best model at epoch 10
2022-12-31 14:43:19,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:19,453 INFO:     Epoch: 11
2022-12-31 14:43:21,077 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4867710689703623, 'Total loss': 0.4867710689703623} | train loss {'Reaction outcome loss': 0.43966775979268424, 'Total loss': 0.43966775979268424}
2022-12-31 14:43:21,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:21,078 INFO:     Epoch: 12
2022-12-31 14:43:22,680 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45607715447743735, 'Total loss': 0.45607715447743735} | train loss {'Reaction outcome loss': 0.43448983557818166, 'Total loss': 0.43448983557818166}
2022-12-31 14:43:22,681 INFO:     Found new best model at epoch 12
2022-12-31 14:43:22,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:22,682 INFO:     Epoch: 13
2022-12-31 14:43:24,327 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4715275138616562, 'Total loss': 0.4715275138616562} | train loss {'Reaction outcome loss': 0.430086765989715, 'Total loss': 0.430086765989715}
2022-12-31 14:43:24,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:24,328 INFO:     Epoch: 14
2022-12-31 14:43:25,968 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4694664736588796, 'Total loss': 0.4694664736588796} | train loss {'Reaction outcome loss': 0.4262054544278431, 'Total loss': 0.4262054544278431}
2022-12-31 14:43:25,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:25,968 INFO:     Epoch: 15
2022-12-31 14:43:27,620 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47054725885391235, 'Total loss': 0.47054725885391235} | train loss {'Reaction outcome loss': 0.4214977055572861, 'Total loss': 0.4214977055572861}
2022-12-31 14:43:27,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:27,620 INFO:     Epoch: 16
2022-12-31 14:43:29,268 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45689205328623456, 'Total loss': 0.45689205328623456} | train loss {'Reaction outcome loss': 0.40829819814715573, 'Total loss': 0.40829819814715573}
2022-12-31 14:43:29,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:29,268 INFO:     Epoch: 17
2022-12-31 14:43:30,883 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4646254003047943, 'Total loss': 0.4646254003047943} | train loss {'Reaction outcome loss': 0.4067224698941415, 'Total loss': 0.4067224698941415}
2022-12-31 14:43:30,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:30,883 INFO:     Epoch: 18
2022-12-31 14:43:32,505 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4490858872731527, 'Total loss': 0.4490858872731527} | train loss {'Reaction outcome loss': 0.3992565679313474, 'Total loss': 0.3992565679313474}
2022-12-31 14:43:32,505 INFO:     Found new best model at epoch 18
2022-12-31 14:43:32,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:32,506 INFO:     Epoch: 19
2022-12-31 14:43:34,132 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4606308420499166, 'Total loss': 0.4606308420499166} | train loss {'Reaction outcome loss': 0.3942474954179908, 'Total loss': 0.3942474954179908}
2022-12-31 14:43:34,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:34,133 INFO:     Epoch: 20
2022-12-31 14:43:35,764 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45307995080947877, 'Total loss': 0.45307995080947877} | train loss {'Reaction outcome loss': 0.3891397217550863, 'Total loss': 0.3891397217550863}
2022-12-31 14:43:35,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:35,764 INFO:     Epoch: 21
2022-12-31 14:43:37,418 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44520373245080314, 'Total loss': 0.44520373245080314} | train loss {'Reaction outcome loss': 0.38483547703077214, 'Total loss': 0.38483547703077214}
2022-12-31 14:43:37,419 INFO:     Found new best model at epoch 21
2022-12-31 14:43:37,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:37,420 INFO:     Epoch: 22
2022-12-31 14:43:39,048 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4248569250106812, 'Total loss': 0.4248569250106812} | train loss {'Reaction outcome loss': 0.3729226738752441, 'Total loss': 0.3729226738752441}
2022-12-31 14:43:39,048 INFO:     Found new best model at epoch 22
2022-12-31 14:43:39,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:39,049 INFO:     Epoch: 23
2022-12-31 14:43:40,670 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48826422691345217, 'Total loss': 0.48826422691345217} | train loss {'Reaction outcome loss': 0.3697244900443494, 'Total loss': 0.3697244900443494}
2022-12-31 14:43:40,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:40,670 INFO:     Epoch: 24
2022-12-31 14:43:42,280 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4481684178113937, 'Total loss': 0.4481684178113937} | train loss {'Reaction outcome loss': 0.3633335540440969, 'Total loss': 0.3633335540440969}
2022-12-31 14:43:42,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:42,280 INFO:     Epoch: 25
2022-12-31 14:43:43,900 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4303429146607717, 'Total loss': 0.4303429146607717} | train loss {'Reaction outcome loss': 0.35651610955757357, 'Total loss': 0.35651610955757357}
2022-12-31 14:43:43,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:43,900 INFO:     Epoch: 26
2022-12-31 14:43:45,524 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43019504845142365, 'Total loss': 0.43019504845142365} | train loss {'Reaction outcome loss': 0.35421867996777007, 'Total loss': 0.35421867996777007}
2022-12-31 14:43:45,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:45,524 INFO:     Epoch: 27
2022-12-31 14:43:47,151 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41849474708239237, 'Total loss': 0.41849474708239237} | train loss {'Reaction outcome loss': 0.34922962095117743, 'Total loss': 0.34922962095117743}
2022-12-31 14:43:47,152 INFO:     Found new best model at epoch 27
2022-12-31 14:43:47,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:47,152 INFO:     Epoch: 28
2022-12-31 14:43:48,753 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40908072392145794, 'Total loss': 0.40908072392145794} | train loss {'Reaction outcome loss': 0.34466101963489926, 'Total loss': 0.34466101963489926}
2022-12-31 14:43:48,753 INFO:     Found new best model at epoch 28
2022-12-31 14:43:48,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:48,754 INFO:     Epoch: 29
2022-12-31 14:43:50,370 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45437533358732857, 'Total loss': 0.45437533358732857} | train loss {'Reaction outcome loss': 0.33363689275102065, 'Total loss': 0.33363689275102065}
2022-12-31 14:43:50,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:50,370 INFO:     Epoch: 30
2022-12-31 14:43:52,024 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41055582811435065, 'Total loss': 0.41055582811435065} | train loss {'Reaction outcome loss': 0.334847657312555, 'Total loss': 0.334847657312555}
2022-12-31 14:43:52,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:52,024 INFO:     Epoch: 31
2022-12-31 14:43:53,649 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41881685256958007, 'Total loss': 0.41881685256958007} | train loss {'Reaction outcome loss': 0.3286164096062364, 'Total loss': 0.3286164096062364}
2022-12-31 14:43:53,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:53,649 INFO:     Epoch: 32
2022-12-31 14:43:55,269 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4373507817586263, 'Total loss': 0.4373507817586263} | train loss {'Reaction outcome loss': 0.32236627849753585, 'Total loss': 0.32236627849753585}
2022-12-31 14:43:55,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:55,269 INFO:     Epoch: 33
2022-12-31 14:43:56,889 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43337172269821167, 'Total loss': 0.43337172269821167} | train loss {'Reaction outcome loss': 0.3186968090248022, 'Total loss': 0.3186968090248022}
2022-12-31 14:43:56,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:56,890 INFO:     Epoch: 34
2022-12-31 14:43:58,518 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4013579229513804, 'Total loss': 0.4013579229513804} | train loss {'Reaction outcome loss': 0.3151408520254848, 'Total loss': 0.3151408520254848}
2022-12-31 14:43:58,518 INFO:     Found new best model at epoch 34
2022-12-31 14:43:58,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:43:58,519 INFO:     Epoch: 35
2022-12-31 14:44:00,120 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3733670006195704, 'Total loss': 0.3733670006195704} | train loss {'Reaction outcome loss': 0.30317658118715357, 'Total loss': 0.30317658118715357}
2022-12-31 14:44:00,120 INFO:     Found new best model at epoch 35
2022-12-31 14:44:00,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:00,121 INFO:     Epoch: 36
2022-12-31 14:44:01,741 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40386872390906015, 'Total loss': 0.40386872390906015} | train loss {'Reaction outcome loss': 0.3026956857757018, 'Total loss': 0.3026956857757018}
2022-12-31 14:44:01,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:01,741 INFO:     Epoch: 37
2022-12-31 14:44:03,360 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40653345187505086, 'Total loss': 0.40653345187505086} | train loss {'Reaction outcome loss': 0.30511480830744286, 'Total loss': 0.30511480830744286}
2022-12-31 14:44:03,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:03,360 INFO:     Epoch: 38
2022-12-31 14:44:04,979 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44273565808931986, 'Total loss': 0.44273565808931986} | train loss {'Reaction outcome loss': 0.2975097255586287, 'Total loss': 0.2975097255586287}
2022-12-31 14:44:04,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:04,979 INFO:     Epoch: 39
2022-12-31 14:44:06,581 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4166455606619517, 'Total loss': 0.4166455606619517} | train loss {'Reaction outcome loss': 0.29762247162753386, 'Total loss': 0.29762247162753386}
2022-12-31 14:44:06,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:06,582 INFO:     Epoch: 40
2022-12-31 14:44:08,184 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3877733317514261, 'Total loss': 0.3877733317514261} | train loss {'Reaction outcome loss': 0.2939098725626615, 'Total loss': 0.2939098725626615}
2022-12-31 14:44:08,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:08,185 INFO:     Epoch: 41
2022-12-31 14:44:09,802 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4095363900065422, 'Total loss': 0.4095363900065422} | train loss {'Reaction outcome loss': 0.2872793355600283, 'Total loss': 0.2872793355600283}
2022-12-31 14:44:09,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:09,803 INFO:     Epoch: 42
2022-12-31 14:44:11,421 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4150252858797709, 'Total loss': 0.4150252858797709} | train loss {'Reaction outcome loss': 0.2793057278632472, 'Total loss': 0.2793057278632472}
2022-12-31 14:44:11,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:11,422 INFO:     Epoch: 43
2022-12-31 14:44:13,041 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3952648162841797, 'Total loss': 0.3952648162841797} | train loss {'Reaction outcome loss': 0.2812738834950898, 'Total loss': 0.2812738834950898}
2022-12-31 14:44:13,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:13,041 INFO:     Epoch: 44
2022-12-31 14:44:14,659 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3916770527760188, 'Total loss': 0.3916770527760188} | train loss {'Reaction outcome loss': 0.27423934154346963, 'Total loss': 0.27423934154346963}
2022-12-31 14:44:14,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:14,659 INFO:     Epoch: 45
2022-12-31 14:44:16,259 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40623977184295657, 'Total loss': 0.40623977184295657} | train loss {'Reaction outcome loss': 0.2788772861530419, 'Total loss': 0.2788772861530419}
2022-12-31 14:44:16,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:16,259 INFO:     Epoch: 46
2022-12-31 14:44:17,875 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.374653139958779, 'Total loss': 0.374653139958779} | train loss {'Reaction outcome loss': 0.2667048131166167, 'Total loss': 0.2667048131166167}
2022-12-31 14:44:17,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:17,876 INFO:     Epoch: 47
2022-12-31 14:44:19,504 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.36491052955389025, 'Total loss': 0.36491052955389025} | train loss {'Reaction outcome loss': 0.2653756790696929, 'Total loss': 0.2653756790696929}
2022-12-31 14:44:19,505 INFO:     Found new best model at epoch 47
2022-12-31 14:44:19,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:19,505 INFO:     Epoch: 48
2022-12-31 14:44:21,122 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4313090552886327, 'Total loss': 0.4313090552886327} | train loss {'Reaction outcome loss': 0.2671985793657036, 'Total loss': 0.2671985793657036}
2022-12-31 14:44:21,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:21,122 INFO:     Epoch: 49
2022-12-31 14:44:22,741 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3943575441837311, 'Total loss': 0.3943575441837311} | train loss {'Reaction outcome loss': 0.2609286697359507, 'Total loss': 0.2609286697359507}
2022-12-31 14:44:22,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:22,741 INFO:     Epoch: 50
2022-12-31 14:44:24,344 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42387230892976124, 'Total loss': 0.42387230892976124} | train loss {'Reaction outcome loss': 0.26428709243716747, 'Total loss': 0.26428709243716747}
2022-12-31 14:44:24,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:24,344 INFO:     Epoch: 51
2022-12-31 14:44:25,946 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3793884813785553, 'Total loss': 0.3793884813785553} | train loss {'Reaction outcome loss': 0.2576972292837038, 'Total loss': 0.2576972292837038}
2022-12-31 14:44:25,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:25,946 INFO:     Epoch: 52
2022-12-31 14:44:27,569 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38603508969148, 'Total loss': 0.38603508969148} | train loss {'Reaction outcome loss': 0.2596351683597057, 'Total loss': 0.2596351683597057}
2022-12-31 14:44:27,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:27,570 INFO:     Epoch: 53
2022-12-31 14:44:29,190 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42153626879056294, 'Total loss': 0.42153626879056294} | train loss {'Reaction outcome loss': 0.25211691677516546, 'Total loss': 0.25211691677516546}
2022-12-31 14:44:29,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:29,191 INFO:     Epoch: 54
2022-12-31 14:44:30,813 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40501325329144794, 'Total loss': 0.40501325329144794} | train loss {'Reaction outcome loss': 0.25061714545645436, 'Total loss': 0.25061714545645436}
2022-12-31 14:44:30,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:30,814 INFO:     Epoch: 55
2022-12-31 14:44:32,433 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3820610404014587, 'Total loss': 0.3820610404014587} | train loss {'Reaction outcome loss': 0.2501546868294585, 'Total loss': 0.2501546868294585}
2022-12-31 14:44:32,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:32,433 INFO:     Epoch: 56
2022-12-31 14:44:34,056 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38782802522182463, 'Total loss': 0.38782802522182463} | train loss {'Reaction outcome loss': 0.2500637305987871, 'Total loss': 0.2500637305987871}
2022-12-31 14:44:34,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:34,056 INFO:     Epoch: 57
2022-12-31 14:44:35,676 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39006452560424804, 'Total loss': 0.39006452560424804} | train loss {'Reaction outcome loss': 0.24549365149884878, 'Total loss': 0.24549365149884878}
2022-12-31 14:44:35,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:35,677 INFO:     Epoch: 58
2022-12-31 14:44:37,292 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.419966055949529, 'Total loss': 0.419966055949529} | train loss {'Reaction outcome loss': 0.2378795841702055, 'Total loss': 0.2378795841702055}
2022-12-31 14:44:37,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:37,292 INFO:     Epoch: 59
2022-12-31 14:44:38,910 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39686478674411774, 'Total loss': 0.39686478674411774} | train loss {'Reaction outcome loss': 0.24696697722380773, 'Total loss': 0.24696697722380773}
2022-12-31 14:44:38,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:38,911 INFO:     Epoch: 60
2022-12-31 14:44:40,538 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3623721202214559, 'Total loss': 0.3623721202214559} | train loss {'Reaction outcome loss': 0.23526851230364845, 'Total loss': 0.23526851230364845}
2022-12-31 14:44:40,538 INFO:     Found new best model at epoch 60
2022-12-31 14:44:40,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:40,539 INFO:     Epoch: 61
2022-12-31 14:44:42,180 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4107903689146042, 'Total loss': 0.4107903689146042} | train loss {'Reaction outcome loss': 0.2356252241408997, 'Total loss': 0.2356252241408997}
2022-12-31 14:44:42,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:42,180 INFO:     Epoch: 62
2022-12-31 14:44:43,823 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4121299078067144, 'Total loss': 0.4121299078067144} | train loss {'Reaction outcome loss': 0.2357280623396381, 'Total loss': 0.2357280623396381}
2022-12-31 14:44:43,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:43,823 INFO:     Epoch: 63
2022-12-31 14:44:45,446 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3846519817908605, 'Total loss': 0.3846519817908605} | train loss {'Reaction outcome loss': 0.23833549479257973, 'Total loss': 0.23833549479257973}
2022-12-31 14:44:45,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:45,447 INFO:     Epoch: 64
2022-12-31 14:44:47,080 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38702759246031443, 'Total loss': 0.38702759246031443} | train loss {'Reaction outcome loss': 0.2313971802330028, 'Total loss': 0.2313971802330028}
2022-12-31 14:44:47,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:47,080 INFO:     Epoch: 65
2022-12-31 14:44:48,697 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3933598001797994, 'Total loss': 0.3933598001797994} | train loss {'Reaction outcome loss': 0.23494741516961087, 'Total loss': 0.23494741516961087}
2022-12-31 14:44:48,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:48,697 INFO:     Epoch: 66
2022-12-31 14:44:50,316 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4095354383190473, 'Total loss': 0.4095354383190473} | train loss {'Reaction outcome loss': 0.2301170693488543, 'Total loss': 0.2301170693488543}
2022-12-31 14:44:50,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:50,316 INFO:     Epoch: 67
2022-12-31 14:44:51,921 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3815996706485748, 'Total loss': 0.3815996706485748} | train loss {'Reaction outcome loss': 0.22849122440233988, 'Total loss': 0.22849122440233988}
2022-12-31 14:44:51,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:51,921 INFO:     Epoch: 68
2022-12-31 14:44:53,524 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37060070981582005, 'Total loss': 0.37060070981582005} | train loss {'Reaction outcome loss': 0.2248289525266804, 'Total loss': 0.2248289525266804}
2022-12-31 14:44:53,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:53,525 INFO:     Epoch: 69
2022-12-31 14:44:55,141 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40897457202275594, 'Total loss': 0.40897457202275594} | train loss {'Reaction outcome loss': 0.22299649511272296, 'Total loss': 0.22299649511272296}
2022-12-31 14:44:55,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:55,142 INFO:     Epoch: 70
2022-12-31 14:44:56,786 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4118999222914378, 'Total loss': 0.4118999222914378} | train loss {'Reaction outcome loss': 0.22317714248161885, 'Total loss': 0.22317714248161885}
2022-12-31 14:44:56,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:56,786 INFO:     Epoch: 71
2022-12-31 14:44:58,406 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38979054192701973, 'Total loss': 0.38979054192701973} | train loss {'Reaction outcome loss': 0.22210556178585716, 'Total loss': 0.22210556178585716}
2022-12-31 14:44:58,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:44:58,407 INFO:     Epoch: 72
2022-12-31 14:45:00,027 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3901142140229543, 'Total loss': 0.3901142140229543} | train loss {'Reaction outcome loss': 0.22269939820850368, 'Total loss': 0.22269939820850368}
2022-12-31 14:45:00,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:00,027 INFO:     Epoch: 73
2022-12-31 14:45:01,657 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4058043082555135, 'Total loss': 0.4058043082555135} | train loss {'Reaction outcome loss': 0.22336886445268828, 'Total loss': 0.22336886445268828}
2022-12-31 14:45:01,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:01,657 INFO:     Epoch: 74
2022-12-31 14:45:03,278 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3629636769493421, 'Total loss': 0.3629636769493421} | train loss {'Reaction outcome loss': 0.21868794020736046, 'Total loss': 0.21868794020736046}
2022-12-31 14:45:03,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:03,278 INFO:     Epoch: 75
2022-12-31 14:45:04,936 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3677322765191396, 'Total loss': 0.3677322765191396} | train loss {'Reaction outcome loss': 0.21951877885239218, 'Total loss': 0.21951877885239218}
2022-12-31 14:45:04,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:04,936 INFO:     Epoch: 76
2022-12-31 14:45:06,577 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4167077531417211, 'Total loss': 0.4167077531417211} | train loss {'Reaction outcome loss': 0.21782461057554944, 'Total loss': 0.21782461057554944}
2022-12-31 14:45:06,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:06,577 INFO:     Epoch: 77
2022-12-31 14:45:08,200 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39016305804252627, 'Total loss': 0.39016305804252627} | train loss {'Reaction outcome loss': 0.21789171841224178, 'Total loss': 0.21789171841224178}
2022-12-31 14:45:08,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:08,200 INFO:     Epoch: 78
2022-12-31 14:45:09,828 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3863412141799927, 'Total loss': 0.3863412141799927} | train loss {'Reaction outcome loss': 0.2212444547906733, 'Total loss': 0.2212444547906733}
2022-12-31 14:45:09,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:09,829 INFO:     Epoch: 79
2022-12-31 14:45:11,432 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3893941767513752, 'Total loss': 0.3893941767513752} | train loss {'Reaction outcome loss': 0.21261870456247553, 'Total loss': 0.21261870456247553}
2022-12-31 14:45:11,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:11,432 INFO:     Epoch: 80
2022-12-31 14:45:13,067 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41005152463912964, 'Total loss': 0.41005152463912964} | train loss {'Reaction outcome loss': 0.21547995361126288, 'Total loss': 0.21547995361126288}
2022-12-31 14:45:13,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:13,067 INFO:     Epoch: 81
2022-12-31 14:45:14,699 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4305994937817256, 'Total loss': 0.4305994937817256} | train loss {'Reaction outcome loss': 0.21373306456886043, 'Total loss': 0.21373306456886043}
2022-12-31 14:45:14,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:14,699 INFO:     Epoch: 82
2022-12-31 14:45:16,331 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3861799647410711, 'Total loss': 0.3861799647410711} | train loss {'Reaction outcome loss': 0.21167159185405243, 'Total loss': 0.21167159185405243}
2022-12-31 14:45:16,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:16,332 INFO:     Epoch: 83
2022-12-31 14:45:17,988 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3810587555170059, 'Total loss': 0.3810587555170059} | train loss {'Reaction outcome loss': 0.21047364410671948, 'Total loss': 0.21047364410671948}
2022-12-31 14:45:17,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:17,988 INFO:     Epoch: 84
2022-12-31 14:45:19,620 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4045553584893545, 'Total loss': 0.4045553584893545} | train loss {'Reaction outcome loss': 0.2103006625010057, 'Total loss': 0.2103006625010057}
2022-12-31 14:45:19,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:19,621 INFO:     Epoch: 85
2022-12-31 14:45:21,241 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3954974770545959, 'Total loss': 0.3954974770545959} | train loss {'Reaction outcome loss': 0.2176472421211026, 'Total loss': 0.2176472421211026}
2022-12-31 14:45:21,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:21,241 INFO:     Epoch: 86
2022-12-31 14:45:22,857 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3885518769423167, 'Total loss': 0.3885518769423167} | train loss {'Reaction outcome loss': 0.20684586278421785, 'Total loss': 0.20684586278421785}
2022-12-31 14:45:22,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:22,857 INFO:     Epoch: 87
2022-12-31 14:45:24,474 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39311426480611167, 'Total loss': 0.39311426480611167} | train loss {'Reaction outcome loss': 0.2091068631636537, 'Total loss': 0.2091068631636537}
2022-12-31 14:45:24,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:24,475 INFO:     Epoch: 88
2022-12-31 14:45:26,100 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.356939638654391, 'Total loss': 0.356939638654391} | train loss {'Reaction outcome loss': 0.2061634473233662, 'Total loss': 0.2061634473233662}
2022-12-31 14:45:26,100 INFO:     Found new best model at epoch 88
2022-12-31 14:45:26,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:26,101 INFO:     Epoch: 89
2022-12-31 14:45:27,711 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.36846930185953775, 'Total loss': 0.36846930185953775} | train loss {'Reaction outcome loss': 0.2075962316117078, 'Total loss': 0.2075962316117078}
2022-12-31 14:45:27,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:27,711 INFO:     Epoch: 90
2022-12-31 14:45:29,363 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38244999945163727, 'Total loss': 0.38244999945163727} | train loss {'Reaction outcome loss': 0.2075761079465439, 'Total loss': 0.2075761079465439}
2022-12-31 14:45:29,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:29,364 INFO:     Epoch: 91
2022-12-31 14:45:30,995 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3766395757595698, 'Total loss': 0.3766395757595698} | train loss {'Reaction outcome loss': 0.1949954253053192, 'Total loss': 0.1949954253053192}
2022-12-31 14:45:30,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:30,995 INFO:     Epoch: 92
2022-12-31 14:45:32,617 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3765014087160428, 'Total loss': 0.3765014087160428} | train loss {'Reaction outcome loss': 0.2054634239618744, 'Total loss': 0.2054634239618744}
2022-12-31 14:45:32,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:32,617 INFO:     Epoch: 93
2022-12-31 14:45:34,244 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3982401390870412, 'Total loss': 0.3982401390870412} | train loss {'Reaction outcome loss': 0.20264159150367825, 'Total loss': 0.20264159150367825}
2022-12-31 14:45:34,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:34,244 INFO:     Epoch: 94
2022-12-31 14:45:35,884 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.36528528332710264, 'Total loss': 0.36528528332710264} | train loss {'Reaction outcome loss': 0.20043618933697793, 'Total loss': 0.20043618933697793}
2022-12-31 14:45:35,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:35,884 INFO:     Epoch: 95
2022-12-31 14:45:37,516 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40509817202885945, 'Total loss': 0.40509817202885945} | train loss {'Reaction outcome loss': 0.1975953174176683, 'Total loss': 0.1975953174176683}
2022-12-31 14:45:37,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:37,516 INFO:     Epoch: 96
2022-12-31 14:45:39,149 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39150731166203817, 'Total loss': 0.39150731166203817} | train loss {'Reaction outcome loss': 0.1981881731105733, 'Total loss': 0.1981881731105733}
2022-12-31 14:45:39,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:39,150 INFO:     Epoch: 97
2022-12-31 14:45:40,802 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3883748859167099, 'Total loss': 0.3883748859167099} | train loss {'Reaction outcome loss': 0.2042620503999266, 'Total loss': 0.2042620503999266}
2022-12-31 14:45:40,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:40,803 INFO:     Epoch: 98
2022-12-31 14:45:42,428 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37172116537888844, 'Total loss': 0.37172116537888844} | train loss {'Reaction outcome loss': 0.19949882029007704, 'Total loss': 0.19949882029007704}
2022-12-31 14:45:42,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:42,428 INFO:     Epoch: 99
2022-12-31 14:45:44,041 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4219656397898992, 'Total loss': 0.4219656397898992} | train loss {'Reaction outcome loss': 0.1998886412433231, 'Total loss': 0.1998886412433231}
2022-12-31 14:45:44,041 INFO:     Best model found after epoch 89 of 100.
2022-12-31 14:45:44,042 INFO:   Done with stage: TRAINING
2022-12-31 14:45:44,042 INFO:   Starting stage: EVALUATION
2022-12-31 14:45:44,163 INFO:   Done with stage: EVALUATION
2022-12-31 14:45:44,163 INFO:   Leaving out SEQ value Fold_7
2022-12-31 14:45:44,176 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 14:45:44,176 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:45:44,826 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:45:44,826 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:45:44,895 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:45:44,896 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:45:44,896 INFO:     No hyperparam tuning for this model
2022-12-31 14:45:44,896 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:45:44,896 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:45:44,896 INFO:     None feature selector for col prot
2022-12-31 14:45:44,897 INFO:     None feature selector for col prot
2022-12-31 14:45:44,897 INFO:     None feature selector for col prot
2022-12-31 14:45:44,897 INFO:     None feature selector for col chem
2022-12-31 14:45:44,897 INFO:     None feature selector for col chem
2022-12-31 14:45:44,897 INFO:     None feature selector for col chem
2022-12-31 14:45:44,897 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:45:44,898 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:45:44,899 INFO:     Number of params in model 223921
2022-12-31 14:45:44,903 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:45:44,903 INFO:   Starting stage: TRAINING
2022-12-31 14:45:44,948 INFO:     Val loss before train {'Reaction outcome loss': 1.0070865670839946, 'Total loss': 1.0070865670839946}
2022-12-31 14:45:44,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:44,949 INFO:     Epoch: 0
2022-12-31 14:45:46,551 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7829095443089803, 'Total loss': 0.7829095443089803} | train loss {'Reaction outcome loss': 0.8181526013229729, 'Total loss': 0.8181526013229729}
2022-12-31 14:45:46,552 INFO:     Found new best model at epoch 0
2022-12-31 14:45:46,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:46,553 INFO:     Epoch: 1
2022-12-31 14:45:48,159 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6382785002390544, 'Total loss': 0.6382785002390544} | train loss {'Reaction outcome loss': 0.5947217801955633, 'Total loss': 0.5947217801955633}
2022-12-31 14:45:48,160 INFO:     Found new best model at epoch 1
2022-12-31 14:45:48,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:48,161 INFO:     Epoch: 2
2022-12-31 14:45:49,779 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6042513887087504, 'Total loss': 0.6042513887087504} | train loss {'Reaction outcome loss': 0.5259041997069486, 'Total loss': 0.5259041997069486}
2022-12-31 14:45:49,779 INFO:     Found new best model at epoch 2
2022-12-31 14:45:49,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:49,780 INFO:     Epoch: 3
2022-12-31 14:45:51,407 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5825235267480214, 'Total loss': 0.5825235267480214} | train loss {'Reaction outcome loss': 0.5063899634439593, 'Total loss': 0.5063899634439593}
2022-12-31 14:45:51,407 INFO:     Found new best model at epoch 3
2022-12-31 14:45:51,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:51,408 INFO:     Epoch: 4
2022-12-31 14:45:53,036 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6219196279843648, 'Total loss': 0.6219196279843648} | train loss {'Reaction outcome loss': 0.48508788747477616, 'Total loss': 0.48508788747477616}
2022-12-31 14:45:53,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:53,036 INFO:     Epoch: 5
2022-12-31 14:45:54,673 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.6016246259212494, 'Total loss': 0.6016246259212494} | train loss {'Reaction outcome loss': 0.47236644172711495, 'Total loss': 0.47236644172711495}
2022-12-31 14:45:54,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:54,673 INFO:     Epoch: 6
2022-12-31 14:45:56,318 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5644170607129733, 'Total loss': 0.5644170607129733} | train loss {'Reaction outcome loss': 0.4661538461055136, 'Total loss': 0.4661538461055136}
2022-12-31 14:45:56,318 INFO:     Found new best model at epoch 6
2022-12-31 14:45:56,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:56,319 INFO:     Epoch: 7
2022-12-31 14:45:57,940 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5625987728436788, 'Total loss': 0.5625987728436788} | train loss {'Reaction outcome loss': 0.46291406482242936, 'Total loss': 0.46291406482242936}
2022-12-31 14:45:57,940 INFO:     Found new best model at epoch 7
2022-12-31 14:45:57,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:57,941 INFO:     Epoch: 8
2022-12-31 14:45:59,582 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.6029976983865102, 'Total loss': 0.6029976983865102} | train loss {'Reaction outcome loss': 0.450114526419433, 'Total loss': 0.450114526419433}
2022-12-31 14:45:59,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:45:59,583 INFO:     Epoch: 9
2022-12-31 14:46:01,225 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5829280058542887, 'Total loss': 0.5829280058542887} | train loss {'Reaction outcome loss': 0.4463654639273344, 'Total loss': 0.4463654639273344}
2022-12-31 14:46:01,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:01,226 INFO:     Epoch: 10
2022-12-31 14:46:02,881 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5735804080963135, 'Total loss': 0.5735804080963135} | train loss {'Reaction outcome loss': 0.439945353228693, 'Total loss': 0.439945353228693}
2022-12-31 14:46:02,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:02,881 INFO:     Epoch: 11
2022-12-31 14:46:04,511 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.566774598757426, 'Total loss': 0.566774598757426} | train loss {'Reaction outcome loss': 0.43560949414430544, 'Total loss': 0.43560949414430544}
2022-12-31 14:46:04,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:04,511 INFO:     Epoch: 12
2022-12-31 14:46:06,131 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5713179667790731, 'Total loss': 0.5713179667790731} | train loss {'Reaction outcome loss': 0.4329164248726428, 'Total loss': 0.4329164248726428}
2022-12-31 14:46:06,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:06,131 INFO:     Epoch: 13
2022-12-31 14:46:07,776 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5696438193321228, 'Total loss': 0.5696438193321228} | train loss {'Reaction outcome loss': 0.4228471572971516, 'Total loss': 0.4228471572971516}
2022-12-31 14:46:07,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:07,777 INFO:     Epoch: 14
2022-12-31 14:46:09,433 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5505615870157877, 'Total loss': 0.5505615870157877} | train loss {'Reaction outcome loss': 0.4154265483955614, 'Total loss': 0.4154265483955614}
2022-12-31 14:46:09,433 INFO:     Found new best model at epoch 14
2022-12-31 14:46:09,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:09,434 INFO:     Epoch: 15
2022-12-31 14:46:11,093 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5266999721527099, 'Total loss': 0.5266999721527099} | train loss {'Reaction outcome loss': 0.4095408993668935, 'Total loss': 0.4095408993668935}
2022-12-31 14:46:11,093 INFO:     Found new best model at epoch 15
2022-12-31 14:46:11,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:11,094 INFO:     Epoch: 16
2022-12-31 14:46:12,731 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5576059182484945, 'Total loss': 0.5576059182484945} | train loss {'Reaction outcome loss': 0.4059665263613639, 'Total loss': 0.4059665263613639}
2022-12-31 14:46:12,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:12,731 INFO:     Epoch: 17
2022-12-31 14:46:14,365 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5388024727503459, 'Total loss': 0.5388024727503459} | train loss {'Reaction outcome loss': 0.3966160879776366, 'Total loss': 0.3966160879776366}
2022-12-31 14:46:14,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:14,365 INFO:     Epoch: 18
2022-12-31 14:46:15,997 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5204443057378133, 'Total loss': 0.5204443057378133} | train loss {'Reaction outcome loss': 0.3971533339322689, 'Total loss': 0.3971533339322689}
2022-12-31 14:46:15,998 INFO:     Found new best model at epoch 18
2022-12-31 14:46:15,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:15,999 INFO:     Epoch: 19
2022-12-31 14:46:17,621 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5332668602466584, 'Total loss': 0.5332668602466584} | train loss {'Reaction outcome loss': 0.3907110460559814, 'Total loss': 0.3907110460559814}
2022-12-31 14:46:17,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:17,622 INFO:     Epoch: 20
2022-12-31 14:46:19,282 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.52569020986557, 'Total loss': 0.52569020986557} | train loss {'Reaction outcome loss': 0.37791725724182407, 'Total loss': 0.37791725724182407}
2022-12-31 14:46:19,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:19,282 INFO:     Epoch: 21
2022-12-31 14:46:20,935 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5331147750218709, 'Total loss': 0.5331147750218709} | train loss {'Reaction outcome loss': 0.38060094636700215, 'Total loss': 0.38060094636700215}
2022-12-31 14:46:20,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:20,935 INFO:     Epoch: 22
2022-12-31 14:46:22,542 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5231047789255778, 'Total loss': 0.5231047789255778} | train loss {'Reaction outcome loss': 0.3742719516830539, 'Total loss': 0.3742719516830539}
2022-12-31 14:46:22,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:22,543 INFO:     Epoch: 23
2022-12-31 14:46:24,144 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5020925462245941, 'Total loss': 0.5020925462245941} | train loss {'Reaction outcome loss': 0.374446394318708, 'Total loss': 0.374446394318708}
2022-12-31 14:46:24,144 INFO:     Found new best model at epoch 23
2022-12-31 14:46:24,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:24,145 INFO:     Epoch: 24
2022-12-31 14:46:25,762 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5362134416898091, 'Total loss': 0.5362134416898091} | train loss {'Reaction outcome loss': 0.3612445739874556, 'Total loss': 0.3612445739874556}
2022-12-31 14:46:25,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:25,762 INFO:     Epoch: 25
2022-12-31 14:46:27,381 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49676983455816903, 'Total loss': 0.49676983455816903} | train loss {'Reaction outcome loss': 0.3573975627603083, 'Total loss': 0.3573975627603083}
2022-12-31 14:46:27,381 INFO:     Found new best model at epoch 25
2022-12-31 14:46:27,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:27,382 INFO:     Epoch: 26
2022-12-31 14:46:29,026 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.516400150458018, 'Total loss': 0.516400150458018} | train loss {'Reaction outcome loss': 0.3548905204188092, 'Total loss': 0.3548905204188092}
2022-12-31 14:46:29,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:29,027 INFO:     Epoch: 27
2022-12-31 14:46:30,648 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5438608586788177, 'Total loss': 0.5438608586788177} | train loss {'Reaction outcome loss': 0.34705797921772036, 'Total loss': 0.34705797921772036}
2022-12-31 14:46:30,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:30,648 INFO:     Epoch: 28
2022-12-31 14:46:32,282 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4600512226422628, 'Total loss': 0.4600512226422628} | train loss {'Reaction outcome loss': 0.3450736187479126, 'Total loss': 0.3450736187479126}
2022-12-31 14:46:32,282 INFO:     Found new best model at epoch 28
2022-12-31 14:46:32,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:32,283 INFO:     Epoch: 29
2022-12-31 14:46:33,923 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.482304173707962, 'Total loss': 0.482304173707962} | train loss {'Reaction outcome loss': 0.33739949004314435, 'Total loss': 0.33739949004314435}
2022-12-31 14:46:33,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:33,923 INFO:     Epoch: 30
2022-12-31 14:46:35,578 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48918027281761167, 'Total loss': 0.48918027281761167} | train loss {'Reaction outcome loss': 0.328016678321878, 'Total loss': 0.328016678321878}
2022-12-31 14:46:35,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:35,579 INFO:     Epoch: 31
2022-12-31 14:46:37,210 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4690645128488541, 'Total loss': 0.4690645128488541} | train loss {'Reaction outcome loss': 0.33238103324782764, 'Total loss': 0.33238103324782764}
2022-12-31 14:46:37,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:37,210 INFO:     Epoch: 32
2022-12-31 14:46:38,854 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47414899071057637, 'Total loss': 0.47414899071057637} | train loss {'Reaction outcome loss': 0.326189680993288, 'Total loss': 0.326189680993288}
2022-12-31 14:46:38,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:38,854 INFO:     Epoch: 33
2022-12-31 14:46:40,474 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.481962517897288, 'Total loss': 0.481962517897288} | train loss {'Reaction outcome loss': 0.32235107116320505, 'Total loss': 0.32235107116320505}
2022-12-31 14:46:40,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:40,475 INFO:     Epoch: 34
2022-12-31 14:46:42,083 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4636368801196416, 'Total loss': 0.4636368801196416} | train loss {'Reaction outcome loss': 0.322796887869439, 'Total loss': 0.322796887869439}
2022-12-31 14:46:42,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:42,083 INFO:     Epoch: 35
2022-12-31 14:46:43,715 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4839941730101903, 'Total loss': 0.4839941730101903} | train loss {'Reaction outcome loss': 0.3141145755936953, 'Total loss': 0.3141145755936953}
2022-12-31 14:46:43,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:43,715 INFO:     Epoch: 36
2022-12-31 14:46:45,331 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4442045281330744, 'Total loss': 0.4442045281330744} | train loss {'Reaction outcome loss': 0.3092315496897009, 'Total loss': 0.3092315496897009}
2022-12-31 14:46:45,331 INFO:     Found new best model at epoch 36
2022-12-31 14:46:45,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:45,332 INFO:     Epoch: 37
2022-12-31 14:46:46,964 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4479652379949888, 'Total loss': 0.4479652379949888} | train loss {'Reaction outcome loss': 0.30114017116302616, 'Total loss': 0.30114017116302616}
2022-12-31 14:46:46,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:46,965 INFO:     Epoch: 38
2022-12-31 14:46:48,582 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47668138742446897, 'Total loss': 0.47668138742446897} | train loss {'Reaction outcome loss': 0.30162596343495357, 'Total loss': 0.30162596343495357}
2022-12-31 14:46:48,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:48,582 INFO:     Epoch: 39
2022-12-31 14:46:50,200 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45947879056135815, 'Total loss': 0.45947879056135815} | train loss {'Reaction outcome loss': 0.2987345715561068, 'Total loss': 0.2987345715561068}
2022-12-31 14:46:50,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:50,201 INFO:     Epoch: 40
2022-12-31 14:46:51,821 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4609380513429642, 'Total loss': 0.4609380513429642} | train loss {'Reaction outcome loss': 0.2955872773021352, 'Total loss': 0.2955872773021352}
2022-12-31 14:46:51,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:51,821 INFO:     Epoch: 41
2022-12-31 14:46:53,434 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46300245920817057, 'Total loss': 0.46300245920817057} | train loss {'Reaction outcome loss': 0.29154502812920924, 'Total loss': 0.29154502812920924}
2022-12-31 14:46:53,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:53,435 INFO:     Epoch: 42
2022-12-31 14:46:55,055 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46782915443181994, 'Total loss': 0.46782915443181994} | train loss {'Reaction outcome loss': 0.2862314802967684, 'Total loss': 0.2862314802967684}
2022-12-31 14:46:55,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:55,056 INFO:     Epoch: 43
2022-12-31 14:46:56,711 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4438536157210668, 'Total loss': 0.4438536157210668} | train loss {'Reaction outcome loss': 0.2838405329424767, 'Total loss': 0.2838405329424767}
2022-12-31 14:46:56,711 INFO:     Found new best model at epoch 43
2022-12-31 14:46:56,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:56,712 INFO:     Epoch: 44
2022-12-31 14:46:58,366 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4572374790906906, 'Total loss': 0.4572374790906906} | train loss {'Reaction outcome loss': 0.2863654049940488, 'Total loss': 0.2863654049940488}
2022-12-31 14:46:58,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:58,366 INFO:     Epoch: 45
2022-12-31 14:46:59,976 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46807442704836527, 'Total loss': 0.46807442704836527} | train loss {'Reaction outcome loss': 0.2796730557691965, 'Total loss': 0.2796730557691965}
2022-12-31 14:46:59,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:46:59,976 INFO:     Epoch: 46
2022-12-31 14:47:01,601 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4737857739130656, 'Total loss': 0.4737857739130656} | train loss {'Reaction outcome loss': 0.28530548679699536, 'Total loss': 0.28530548679699536}
2022-12-31 14:47:01,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:01,601 INFO:     Epoch: 47
2022-12-31 14:47:03,219 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46198052962621056, 'Total loss': 0.46198052962621056} | train loss {'Reaction outcome loss': 0.271580524621565, 'Total loss': 0.271580524621565}
2022-12-31 14:47:03,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:03,220 INFO:     Epoch: 48
2022-12-31 14:47:04,838 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4681954622268677, 'Total loss': 0.4681954622268677} | train loss {'Reaction outcome loss': 0.27704416212730026, 'Total loss': 0.27704416212730026}
2022-12-31 14:47:04,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:04,839 INFO:     Epoch: 49
2022-12-31 14:47:06,457 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4492753307024638, 'Total loss': 0.4492753307024638} | train loss {'Reaction outcome loss': 0.2749140896172085, 'Total loss': 0.2749140896172085}
2022-12-31 14:47:06,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:06,458 INFO:     Epoch: 50
2022-12-31 14:47:08,084 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4391240229209264, 'Total loss': 0.4391240229209264} | train loss {'Reaction outcome loss': 0.26376838402466224, 'Total loss': 0.26376838402466224}
2022-12-31 14:47:08,084 INFO:     Found new best model at epoch 50
2022-12-31 14:47:08,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:08,085 INFO:     Epoch: 51
2022-12-31 14:47:09,685 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4434417088826497, 'Total loss': 0.4434417088826497} | train loss {'Reaction outcome loss': 0.26568553471662076, 'Total loss': 0.26568553471662076}
2022-12-31 14:47:09,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:09,686 INFO:     Epoch: 52
2022-12-31 14:47:11,318 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43540421724319456, 'Total loss': 0.43540421724319456} | train loss {'Reaction outcome loss': 0.25974895579182283, 'Total loss': 0.25974895579182283}
2022-12-31 14:47:11,318 INFO:     Found new best model at epoch 52
2022-12-31 14:47:11,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:11,319 INFO:     Epoch: 53
2022-12-31 14:47:12,938 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4675544997056325, 'Total loss': 0.4675544997056325} | train loss {'Reaction outcome loss': 0.25711613610413747, 'Total loss': 0.25711613610413747}
2022-12-31 14:47:12,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:12,939 INFO:     Epoch: 54
2022-12-31 14:47:14,578 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.479548371831576, 'Total loss': 0.479548371831576} | train loss {'Reaction outcome loss': 0.25747736061953463, 'Total loss': 0.25747736061953463}
2022-12-31 14:47:14,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:14,578 INFO:     Epoch: 55
2022-12-31 14:47:16,202 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4641963173945745, 'Total loss': 0.4641963173945745} | train loss {'Reaction outcome loss': 0.2541416445713396, 'Total loss': 0.2541416445713396}
2022-12-31 14:47:16,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:16,202 INFO:     Epoch: 56
2022-12-31 14:47:17,812 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4666602591673533, 'Total loss': 0.4666602591673533} | train loss {'Reaction outcome loss': 0.25492847073379404, 'Total loss': 0.25492847073379404}
2022-12-31 14:47:17,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:17,813 INFO:     Epoch: 57
2022-12-31 14:47:19,420 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4197148382663727, 'Total loss': 0.4197148382663727} | train loss {'Reaction outcome loss': 0.2550385169321772, 'Total loss': 0.2550385169321772}
2022-12-31 14:47:19,420 INFO:     Found new best model at epoch 57
2022-12-31 14:47:19,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:19,421 INFO:     Epoch: 58
2022-12-31 14:47:21,045 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46260566810766857, 'Total loss': 0.46260566810766857} | train loss {'Reaction outcome loss': 0.245787974850473, 'Total loss': 0.245787974850473}
2022-12-31 14:47:21,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:21,046 INFO:     Epoch: 59
2022-12-31 14:47:22,671 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4694534718990326, 'Total loss': 0.4694534718990326} | train loss {'Reaction outcome loss': 0.24480299753832904, 'Total loss': 0.24480299753832904}
2022-12-31 14:47:22,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:22,671 INFO:     Epoch: 60
2022-12-31 14:47:24,291 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.463231286406517, 'Total loss': 0.463231286406517} | train loss {'Reaction outcome loss': 0.24685777612837428, 'Total loss': 0.24685777612837428}
2022-12-31 14:47:24,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:24,292 INFO:     Epoch: 61
2022-12-31 14:47:25,895 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4628604605793953, 'Total loss': 0.4628604605793953} | train loss {'Reaction outcome loss': 0.24976324175723194, 'Total loss': 0.24976324175723194}
2022-12-31 14:47:25,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:25,896 INFO:     Epoch: 62
2022-12-31 14:47:27,540 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4587666988372803, 'Total loss': 0.4587666988372803} | train loss {'Reaction outcome loss': 0.24300354805569893, 'Total loss': 0.24300354805569893}
2022-12-31 14:47:27,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:27,540 INFO:     Epoch: 63
2022-12-31 14:47:29,155 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44206262230873106, 'Total loss': 0.44206262230873106} | train loss {'Reaction outcome loss': 0.24465922435698526, 'Total loss': 0.24465922435698526}
2022-12-31 14:47:29,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:29,155 INFO:     Epoch: 64
2022-12-31 14:47:30,784 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4494766414165497, 'Total loss': 0.4494766414165497} | train loss {'Reaction outcome loss': 0.24181868291934044, 'Total loss': 0.24181868291934044}
2022-12-31 14:47:30,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:30,784 INFO:     Epoch: 65
2022-12-31 14:47:32,420 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4553257713715235, 'Total loss': 0.4553257713715235} | train loss {'Reaction outcome loss': 0.2395561769914003, 'Total loss': 0.2395561769914003}
2022-12-31 14:47:32,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:32,420 INFO:     Epoch: 66
2022-12-31 14:47:34,040 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47244950830936433, 'Total loss': 0.47244950830936433} | train loss {'Reaction outcome loss': 0.23571355570954966, 'Total loss': 0.23571355570954966}
2022-12-31 14:47:34,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:34,040 INFO:     Epoch: 67
2022-12-31 14:47:35,650 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46190052926540376, 'Total loss': 0.46190052926540376} | train loss {'Reaction outcome loss': 0.23469104276237074, 'Total loss': 0.23469104276237074}
2022-12-31 14:47:35,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:35,650 INFO:     Epoch: 68
2022-12-31 14:47:37,256 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46995196441809334, 'Total loss': 0.46995196441809334} | train loss {'Reaction outcome loss': 0.22741813204563913, 'Total loss': 0.22741813204563913}
2022-12-31 14:47:37,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:37,256 INFO:     Epoch: 69
2022-12-31 14:47:38,881 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44444369077682494, 'Total loss': 0.44444369077682494} | train loss {'Reaction outcome loss': 0.22913276117685039, 'Total loss': 0.22913276117685039}
2022-12-31 14:47:38,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:38,881 INFO:     Epoch: 70
2022-12-31 14:47:40,496 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42519211769104004, 'Total loss': 0.42519211769104004} | train loss {'Reaction outcome loss': 0.23058334272018624, 'Total loss': 0.23058334272018624}
2022-12-31 14:47:40,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:40,496 INFO:     Epoch: 71
2022-12-31 14:47:42,119 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4041915128628413, 'Total loss': 0.4041915128628413} | train loss {'Reaction outcome loss': 0.23054748199987712, 'Total loss': 0.23054748199987712}
2022-12-31 14:47:42,119 INFO:     Found new best model at epoch 71
2022-12-31 14:47:42,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:42,120 INFO:     Epoch: 72
2022-12-31 14:47:43,749 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4483907123406728, 'Total loss': 0.4483907123406728} | train loss {'Reaction outcome loss': 0.235175129169067, 'Total loss': 0.235175129169067}
2022-12-31 14:47:43,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:43,749 INFO:     Epoch: 73
2022-12-31 14:47:45,380 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.466953972975413, 'Total loss': 0.466953972975413} | train loss {'Reaction outcome loss': 0.22560710887616292, 'Total loss': 0.22560710887616292}
2022-12-31 14:47:45,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:45,380 INFO:     Epoch: 74
2022-12-31 14:47:46,992 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45273191332817075, 'Total loss': 0.45273191332817075} | train loss {'Reaction outcome loss': 0.22879392964368692, 'Total loss': 0.22879392964368692}
2022-12-31 14:47:46,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:46,992 INFO:     Epoch: 75
2022-12-31 14:47:48,636 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4546479066212972, 'Total loss': 0.4546479066212972} | train loss {'Reaction outcome loss': 0.2230181487391464, 'Total loss': 0.2230181487391464}
2022-12-31 14:47:48,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:48,637 INFO:     Epoch: 76
2022-12-31 14:47:50,260 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4520438194274902, 'Total loss': 0.4520438194274902} | train loss {'Reaction outcome loss': 0.22126950224061304, 'Total loss': 0.22126950224061304}
2022-12-31 14:47:50,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:50,260 INFO:     Epoch: 77
2022-12-31 14:47:51,881 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4799667904774348, 'Total loss': 0.4799667904774348} | train loss {'Reaction outcome loss': 0.22334160501076858, 'Total loss': 0.22334160501076858}
2022-12-31 14:47:51,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:51,881 INFO:     Epoch: 78
2022-12-31 14:47:53,493 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46679489811261493, 'Total loss': 0.46679489811261493} | train loss {'Reaction outcome loss': 0.22070282293544133, 'Total loss': 0.22070282293544133}
2022-12-31 14:47:53,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:53,493 INFO:     Epoch: 79
2022-12-31 14:47:55,118 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46417627334594724, 'Total loss': 0.46417627334594724} | train loss {'Reaction outcome loss': 0.21900402561556345, 'Total loss': 0.21900402561556345}
2022-12-31 14:47:55,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:55,119 INFO:     Epoch: 80
2022-12-31 14:47:56,745 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46072046756744384, 'Total loss': 0.46072046756744384} | train loss {'Reaction outcome loss': 0.21830804352833477, 'Total loss': 0.21830804352833477}
2022-12-31 14:47:56,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:56,745 INFO:     Epoch: 81
2022-12-31 14:47:58,363 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.461006452391545, 'Total loss': 0.461006452391545} | train loss {'Reaction outcome loss': 0.21549655171615553, 'Total loss': 0.21549655171615553}
2022-12-31 14:47:58,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:58,363 INFO:     Epoch: 82
2022-12-31 14:47:59,986 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4144272873799006, 'Total loss': 0.4144272873799006} | train loss {'Reaction outcome loss': 0.2174592963234935, 'Total loss': 0.2174592963234935}
2022-12-31 14:47:59,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:47:59,986 INFO:     Epoch: 83
2022-12-31 14:48:01,609 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46165254910786946, 'Total loss': 0.46165254910786946} | train loss {'Reaction outcome loss': 0.22758891487944644, 'Total loss': 0.22758891487944644}
2022-12-31 14:48:01,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:01,609 INFO:     Epoch: 84
2022-12-31 14:48:03,240 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4521243174870809, 'Total loss': 0.4521243174870809} | train loss {'Reaction outcome loss': 0.2160364978270948, 'Total loss': 0.2160364978270948}
2022-12-31 14:48:03,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:03,241 INFO:     Epoch: 85
2022-12-31 14:48:04,854 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4847649226586024, 'Total loss': 0.4847649226586024} | train loss {'Reaction outcome loss': 0.21962520429723315, 'Total loss': 0.21962520429723315}
2022-12-31 14:48:04,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:04,855 INFO:     Epoch: 86
2022-12-31 14:48:06,480 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47263286312421166, 'Total loss': 0.47263286312421166} | train loss {'Reaction outcome loss': 0.2097305538711081, 'Total loss': 0.2097305538711081}
2022-12-31 14:48:06,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:06,480 INFO:     Epoch: 87
2022-12-31 14:48:08,116 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49043732285499575, 'Total loss': 0.49043732285499575} | train loss {'Reaction outcome loss': 0.21441668208809536, 'Total loss': 0.21441668208809536}
2022-12-31 14:48:08,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:08,117 INFO:     Epoch: 88
2022-12-31 14:48:09,742 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.435854118069013, 'Total loss': 0.435854118069013} | train loss {'Reaction outcome loss': 0.22099091629043813, 'Total loss': 0.22099091629043813}
2022-12-31 14:48:09,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:09,742 INFO:     Epoch: 89
2022-12-31 14:48:11,357 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48750762939453124, 'Total loss': 0.48750762939453124} | train loss {'Reaction outcome loss': 0.21849360658588823, 'Total loss': 0.21849360658588823}
2022-12-31 14:48:11,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:11,357 INFO:     Epoch: 90
2022-12-31 14:48:12,968 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44955784678459165, 'Total loss': 0.44955784678459165} | train loss {'Reaction outcome loss': 0.2078703609076648, 'Total loss': 0.2078703609076648}
2022-12-31 14:48:12,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:12,968 INFO:     Epoch: 91
2022-12-31 14:48:14,618 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4292798568805059, 'Total loss': 0.4292798568805059} | train loss {'Reaction outcome loss': 0.21389030179661103, 'Total loss': 0.21389030179661103}
2022-12-31 14:48:14,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:14,618 INFO:     Epoch: 92
2022-12-31 14:48:16,261 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4382730940977732, 'Total loss': 0.4382730940977732} | train loss {'Reaction outcome loss': 0.20794647913224432, 'Total loss': 0.20794647913224432}
2022-12-31 14:48:16,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:16,261 INFO:     Epoch: 93
2022-12-31 14:48:17,916 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44941033820311227, 'Total loss': 0.44941033820311227} | train loss {'Reaction outcome loss': 0.2084976313736572, 'Total loss': 0.2084976313736572}
2022-12-31 14:48:17,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:17,916 INFO:     Epoch: 94
2022-12-31 14:48:19,565 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4327626337607702, 'Total loss': 0.4327626337607702} | train loss {'Reaction outcome loss': 0.2130710529533319, 'Total loss': 0.2130710529533319}
2022-12-31 14:48:19,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:19,566 INFO:     Epoch: 95
2022-12-31 14:48:21,186 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47803574800491333, 'Total loss': 0.47803574800491333} | train loss {'Reaction outcome loss': 0.20829214816677658, 'Total loss': 0.20829214816677658}
2022-12-31 14:48:21,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:21,186 INFO:     Epoch: 96
2022-12-31 14:48:22,807 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4621662070353826, 'Total loss': 0.4621662070353826} | train loss {'Reaction outcome loss': 0.2059288499305287, 'Total loss': 0.2059288499305287}
2022-12-31 14:48:22,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:22,808 INFO:     Epoch: 97
2022-12-31 14:48:24,447 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4756662607192993, 'Total loss': 0.4756662607192993} | train loss {'Reaction outcome loss': 0.20339744866217085, 'Total loss': 0.20339744866217085}
2022-12-31 14:48:24,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:24,447 INFO:     Epoch: 98
2022-12-31 14:48:26,084 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4943008035421371, 'Total loss': 0.4943008035421371} | train loss {'Reaction outcome loss': 0.2077828363081716, 'Total loss': 0.2077828363081716}
2022-12-31 14:48:26,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:26,084 INFO:     Epoch: 99
2022-12-31 14:48:27,717 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4653948257366816, 'Total loss': 0.4653948257366816} | train loss {'Reaction outcome loss': 0.2043663508087289, 'Total loss': 0.2043663508087289}
2022-12-31 14:48:27,717 INFO:     Best model found after epoch 72 of 100.
2022-12-31 14:48:27,717 INFO:   Done with stage: TRAINING
2022-12-31 14:48:27,717 INFO:   Starting stage: EVALUATION
2022-12-31 14:48:27,839 INFO:   Done with stage: EVALUATION
2022-12-31 14:48:27,839 INFO:   Leaving out SEQ value Fold_8
2022-12-31 14:48:27,852 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 14:48:27,852 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:48:28,506 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:48:28,506 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:48:28,575 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:48:28,575 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:48:28,575 INFO:     No hyperparam tuning for this model
2022-12-31 14:48:28,575 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:48:28,575 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:48:28,576 INFO:     None feature selector for col prot
2022-12-31 14:48:28,576 INFO:     None feature selector for col prot
2022-12-31 14:48:28,576 INFO:     None feature selector for col prot
2022-12-31 14:48:28,577 INFO:     None feature selector for col chem
2022-12-31 14:48:28,577 INFO:     None feature selector for col chem
2022-12-31 14:48:28,577 INFO:     None feature selector for col chem
2022-12-31 14:48:28,577 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:48:28,577 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:48:28,580 INFO:     Number of params in model 223921
2022-12-31 14:48:28,583 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:48:28,583 INFO:   Starting stage: TRAINING
2022-12-31 14:48:28,627 INFO:     Val loss before train {'Reaction outcome loss': 0.9505830585956574, 'Total loss': 0.9505830585956574}
2022-12-31 14:48:28,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:28,628 INFO:     Epoch: 0
2022-12-31 14:48:30,228 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6215186536312103, 'Total loss': 0.6215186536312103} | train loss {'Reaction outcome loss': 0.8216165956379711, 'Total loss': 0.8216165956379711}
2022-12-31 14:48:30,228 INFO:     Found new best model at epoch 0
2022-12-31 14:48:30,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:30,229 INFO:     Epoch: 1
2022-12-31 14:48:31,828 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5340237865845362, 'Total loss': 0.5340237865845362} | train loss {'Reaction outcome loss': 0.5994011245522837, 'Total loss': 0.5994011245522837}
2022-12-31 14:48:31,828 INFO:     Found new best model at epoch 1
2022-12-31 14:48:31,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:31,829 INFO:     Epoch: 2
2022-12-31 14:48:33,461 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5190111835797627, 'Total loss': 0.5190111835797627} | train loss {'Reaction outcome loss': 0.526446260727834, 'Total loss': 0.526446260727834}
2022-12-31 14:48:33,461 INFO:     Found new best model at epoch 2
2022-12-31 14:48:33,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:33,462 INFO:     Epoch: 3
2022-12-31 14:48:35,110 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5215694963932037, 'Total loss': 0.5215694963932037} | train loss {'Reaction outcome loss': 0.4961865533116287, 'Total loss': 0.4961865533116287}
2022-12-31 14:48:35,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:35,110 INFO:     Epoch: 4
2022-12-31 14:48:36,751 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5101622660954793, 'Total loss': 0.5101622660954793} | train loss {'Reaction outcome loss': 0.47856142093181575, 'Total loss': 0.47856142093181575}
2022-12-31 14:48:36,751 INFO:     Found new best model at epoch 4
2022-12-31 14:48:36,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:36,752 INFO:     Epoch: 5
2022-12-31 14:48:38,373 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4950345973173777, 'Total loss': 0.4950345973173777} | train loss {'Reaction outcome loss': 0.4790730873743693, 'Total loss': 0.4790730873743693}
2022-12-31 14:48:38,373 INFO:     Found new best model at epoch 5
2022-12-31 14:48:38,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:38,374 INFO:     Epoch: 6
2022-12-31 14:48:39,992 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4864441653092702, 'Total loss': 0.4864441653092702} | train loss {'Reaction outcome loss': 0.4856959430621498, 'Total loss': 0.4856959430621498}
2022-12-31 14:48:39,992 INFO:     Found new best model at epoch 6
2022-12-31 14:48:39,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:39,993 INFO:     Epoch: 7
2022-12-31 14:48:41,595 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4603230779369672, 'Total loss': 0.4603230779369672} | train loss {'Reaction outcome loss': 0.45801178629820544, 'Total loss': 0.45801178629820544}
2022-12-31 14:48:41,595 INFO:     Found new best model at epoch 7
2022-12-31 14:48:41,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:41,596 INFO:     Epoch: 8
2022-12-31 14:48:43,205 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5007746418317159, 'Total loss': 0.5007746418317159} | train loss {'Reaction outcome loss': 0.4445767867922162, 'Total loss': 0.4445767867922162}
2022-12-31 14:48:43,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:43,206 INFO:     Epoch: 9
2022-12-31 14:48:44,827 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4987161656220754, 'Total loss': 0.4987161656220754} | train loss {'Reaction outcome loss': 0.4417837296470838, 'Total loss': 0.4417837296470838}
2022-12-31 14:48:44,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:44,828 INFO:     Epoch: 10
2022-12-31 14:48:46,456 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4914811491966248, 'Total loss': 0.4914811491966248} | train loss {'Reaction outcome loss': 0.4418795415186796, 'Total loss': 0.4418795415186796}
2022-12-31 14:48:46,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:46,456 INFO:     Epoch: 11
2022-12-31 14:48:48,060 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4680607666571935, 'Total loss': 0.4680607666571935} | train loss {'Reaction outcome loss': 0.441138970782049, 'Total loss': 0.441138970782049}
2022-12-31 14:48:48,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:48,060 INFO:     Epoch: 12
2022-12-31 14:48:49,674 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4473239541053772, 'Total loss': 0.4473239541053772} | train loss {'Reaction outcome loss': 0.4237793047467004, 'Total loss': 0.4237793047467004}
2022-12-31 14:48:49,674 INFO:     Found new best model at epoch 12
2022-12-31 14:48:49,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:49,675 INFO:     Epoch: 13
2022-12-31 14:48:51,292 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5042245974143346, 'Total loss': 0.5042245974143346} | train loss {'Reaction outcome loss': 0.41363707239793585, 'Total loss': 0.41363707239793585}
2022-12-31 14:48:51,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:51,292 INFO:     Epoch: 14
2022-12-31 14:48:52,903 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47119560043017067, 'Total loss': 0.47119560043017067} | train loss {'Reaction outcome loss': 0.4123950856282254, 'Total loss': 0.4123950856282254}
2022-12-31 14:48:52,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:52,903 INFO:     Epoch: 15
2022-12-31 14:48:54,528 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49351630012194314, 'Total loss': 0.49351630012194314} | train loss {'Reaction outcome loss': 0.40527598134518694, 'Total loss': 0.40527598134518694}
2022-12-31 14:48:54,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:54,529 INFO:     Epoch: 16
2022-12-31 14:48:56,135 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44253997802734374, 'Total loss': 0.44253997802734374} | train loss {'Reaction outcome loss': 0.4025438264201301, 'Total loss': 0.4025438264201301}
2022-12-31 14:48:56,136 INFO:     Found new best model at epoch 16
2022-12-31 14:48:56,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:56,137 INFO:     Epoch: 17
2022-12-31 14:48:57,734 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47797948320706685, 'Total loss': 0.47797948320706685} | train loss {'Reaction outcome loss': 0.39136564645214356, 'Total loss': 0.39136564645214356}
2022-12-31 14:48:57,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:57,735 INFO:     Epoch: 18
2022-12-31 14:48:59,332 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45310266812642414, 'Total loss': 0.45310266812642414} | train loss {'Reaction outcome loss': 0.4154188436712476, 'Total loss': 0.4154188436712476}
2022-12-31 14:48:59,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:48:59,332 INFO:     Epoch: 19
2022-12-31 14:49:00,982 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44089075724283855, 'Total loss': 0.44089075724283855} | train loss {'Reaction outcome loss': 0.39424545734747907, 'Total loss': 0.39424545734747907}
2022-12-31 14:49:00,983 INFO:     Found new best model at epoch 19
2022-12-31 14:49:00,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:00,984 INFO:     Epoch: 20
2022-12-31 14:49:02,633 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46536275347073874, 'Total loss': 0.46536275347073874} | train loss {'Reaction outcome loss': 0.3823933879696373, 'Total loss': 0.3823933879696373}
2022-12-31 14:49:02,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:02,633 INFO:     Epoch: 21
2022-12-31 14:49:04,253 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4447937230269114, 'Total loss': 0.4447937230269114} | train loss {'Reaction outcome loss': 0.3918046377265178, 'Total loss': 0.3918046377265178}
2022-12-31 14:49:04,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:04,254 INFO:     Epoch: 22
2022-12-31 14:49:05,861 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.455675578614076, 'Total loss': 0.455675578614076} | train loss {'Reaction outcome loss': 0.37365967985512555, 'Total loss': 0.37365967985512555}
2022-12-31 14:49:05,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:05,862 INFO:     Epoch: 23
2022-12-31 14:49:07,480 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43627095023790996, 'Total loss': 0.43627095023790996} | train loss {'Reaction outcome loss': 0.3649139905348842, 'Total loss': 0.3649139905348842}
2022-12-31 14:49:07,480 INFO:     Found new best model at epoch 23
2022-12-31 14:49:07,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:07,481 INFO:     Epoch: 24
2022-12-31 14:49:09,135 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4750446836153666, 'Total loss': 0.4750446836153666} | train loss {'Reaction outcome loss': 0.3799179621526729, 'Total loss': 0.3799179621526729}
2022-12-31 14:49:09,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:09,135 INFO:     Epoch: 25
2022-12-31 14:49:10,803 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46322954893112184, 'Total loss': 0.46322954893112184} | train loss {'Reaction outcome loss': 0.3622246662752055, 'Total loss': 0.3622246662752055}
2022-12-31 14:49:10,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:10,804 INFO:     Epoch: 26
2022-12-31 14:49:12,460 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46849404176076254, 'Total loss': 0.46849404176076254} | train loss {'Reaction outcome loss': 0.3599756462904422, 'Total loss': 0.3599756462904422}
2022-12-31 14:49:12,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:12,460 INFO:     Epoch: 27
2022-12-31 14:49:14,087 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46816059748331706, 'Total loss': 0.46816059748331706} | train loss {'Reaction outcome loss': 0.3740925367489673, 'Total loss': 0.3740925367489673}
2022-12-31 14:49:14,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:14,088 INFO:     Epoch: 28
2022-12-31 14:49:15,719 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4525636211037636, 'Total loss': 0.4525636211037636} | train loss {'Reaction outcome loss': 0.3562304472041884, 'Total loss': 0.3562304472041884}
2022-12-31 14:49:15,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:15,719 INFO:     Epoch: 29
2022-12-31 14:49:17,328 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4408812284469604, 'Total loss': 0.4408812284469604} | train loss {'Reaction outcome loss': 0.33878452694582756, 'Total loss': 0.33878452694582756}
2022-12-31 14:49:17,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:17,328 INFO:     Epoch: 30
2022-12-31 14:49:18,947 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4492777983347575, 'Total loss': 0.4492777983347575} | train loss {'Reaction outcome loss': 0.333539042839497, 'Total loss': 0.333539042839497}
2022-12-31 14:49:18,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:18,948 INFO:     Epoch: 31
2022-12-31 14:49:20,561 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45029924710591634, 'Total loss': 0.45029924710591634} | train loss {'Reaction outcome loss': 0.3349939690889332, 'Total loss': 0.3349939690889332}
2022-12-31 14:49:20,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:20,561 INFO:     Epoch: 32
2022-12-31 14:49:22,183 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45190405497948327, 'Total loss': 0.45190405497948327} | train loss {'Reaction outcome loss': 0.333418681908317, 'Total loss': 0.333418681908317}
2022-12-31 14:49:22,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:22,184 INFO:     Epoch: 33
2022-12-31 14:49:23,779 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45654581785202025, 'Total loss': 0.45654581785202025} | train loss {'Reaction outcome loss': 0.3263452696931157, 'Total loss': 0.3263452696931157}
2022-12-31 14:49:23,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:23,779 INFO:     Epoch: 34
2022-12-31 14:49:25,422 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46932771305243176, 'Total loss': 0.46932771305243176} | train loss {'Reaction outcome loss': 0.31973893693445815, 'Total loss': 0.31973893693445815}
2022-12-31 14:49:25,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:25,424 INFO:     Epoch: 35
2022-12-31 14:49:27,025 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4588921248912811, 'Total loss': 0.4588921248912811} | train loss {'Reaction outcome loss': 0.3273015165384846, 'Total loss': 0.3273015165384846}
2022-12-31 14:49:27,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:27,025 INFO:     Epoch: 36
2022-12-31 14:49:28,638 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4322509914636612, 'Total loss': 0.4322509914636612} | train loss {'Reaction outcome loss': 0.315957632712156, 'Total loss': 0.315957632712156}
2022-12-31 14:49:28,638 INFO:     Found new best model at epoch 36
2022-12-31 14:49:28,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:28,639 INFO:     Epoch: 37
2022-12-31 14:49:30,268 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4541071097056071, 'Total loss': 0.4541071097056071} | train loss {'Reaction outcome loss': 0.30694039260624384, 'Total loss': 0.30694039260624384}
2022-12-31 14:49:30,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:30,269 INFO:     Epoch: 38
2022-12-31 14:49:31,884 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.451512499153614, 'Total loss': 0.451512499153614} | train loss {'Reaction outcome loss': 0.31014907686714677, 'Total loss': 0.31014907686714677}
2022-12-31 14:49:31,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:31,885 INFO:     Epoch: 39
2022-12-31 14:49:33,481 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4504297475020091, 'Total loss': 0.4504297475020091} | train loss {'Reaction outcome loss': 0.36627619067692885, 'Total loss': 0.36627619067692885}
2022-12-31 14:49:33,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:33,481 INFO:     Epoch: 40
2022-12-31 14:49:35,071 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5188421368598938, 'Total loss': 0.5188421368598938} | train loss {'Reaction outcome loss': 0.333010561062374, 'Total loss': 0.333010561062374}
2022-12-31 14:49:35,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:35,071 INFO:     Epoch: 41
2022-12-31 14:49:36,695 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4388218134641647, 'Total loss': 0.4388218134641647} | train loss {'Reaction outcome loss': 0.3657059772277548, 'Total loss': 0.3657059772277548}
2022-12-31 14:49:36,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:36,695 INFO:     Epoch: 42
2022-12-31 14:49:38,301 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43705466091632844, 'Total loss': 0.43705466091632844} | train loss {'Reaction outcome loss': 0.31370307967511285, 'Total loss': 0.31370307967511285}
2022-12-31 14:49:38,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:38,301 INFO:     Epoch: 43
2022-12-31 14:49:39,908 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4790233095486959, 'Total loss': 0.4790233095486959} | train loss {'Reaction outcome loss': 0.30188296949220955, 'Total loss': 0.30188296949220955}
2022-12-31 14:49:39,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:39,908 INFO:     Epoch: 44
2022-12-31 14:49:41,520 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4367536763350169, 'Total loss': 0.4367536763350169} | train loss {'Reaction outcome loss': 0.33277737226445175, 'Total loss': 0.33277737226445175}
2022-12-31 14:49:41,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:41,520 INFO:     Epoch: 45
2022-12-31 14:49:43,118 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3919934511184692, 'Total loss': 0.3919934511184692} | train loss {'Reaction outcome loss': 0.29636649834835715, 'Total loss': 0.29636649834835715}
2022-12-31 14:49:43,118 INFO:     Found new best model at epoch 45
2022-12-31 14:49:43,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:43,119 INFO:     Epoch: 46
2022-12-31 14:49:44,731 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4585457364718119, 'Total loss': 0.4585457364718119} | train loss {'Reaction outcome loss': 0.28534569322684966, 'Total loss': 0.28534569322684966}
2022-12-31 14:49:44,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:44,732 INFO:     Epoch: 47
2022-12-31 14:49:46,344 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46778527796268465, 'Total loss': 0.46778527796268465} | train loss {'Reaction outcome loss': 0.28632957581430674, 'Total loss': 0.28632957581430674}
2022-12-31 14:49:46,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:46,344 INFO:     Epoch: 48
2022-12-31 14:49:47,964 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42956650257110596, 'Total loss': 0.42956650257110596} | train loss {'Reaction outcome loss': 0.278798566299699, 'Total loss': 0.278798566299699}
2022-12-31 14:49:47,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:47,964 INFO:     Epoch: 49
2022-12-31 14:49:49,601 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42772852977116904, 'Total loss': 0.42772852977116904} | train loss {'Reaction outcome loss': 0.2789306989187658, 'Total loss': 0.2789306989187658}
2022-12-31 14:49:49,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:49,601 INFO:     Epoch: 50
2022-12-31 14:49:51,197 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42737668255964917, 'Total loss': 0.42737668255964917} | train loss {'Reaction outcome loss': 0.2726922180584591, 'Total loss': 0.2726922180584591}
2022-12-31 14:49:51,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:51,197 INFO:     Epoch: 51
2022-12-31 14:49:52,821 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4315298835436503, 'Total loss': 0.4315298835436503} | train loss {'Reaction outcome loss': 0.29394997793871513, 'Total loss': 0.29394997793871513}
2022-12-31 14:49:52,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:52,821 INFO:     Epoch: 52
2022-12-31 14:49:54,437 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4453648626804352, 'Total loss': 0.4453648626804352} | train loss {'Reaction outcome loss': 0.2703158689014938, 'Total loss': 0.2703158689014938}
2022-12-31 14:49:54,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:54,438 INFO:     Epoch: 53
2022-12-31 14:49:56,060 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4455491195122401, 'Total loss': 0.4455491195122401} | train loss {'Reaction outcome loss': 0.2716100829142227, 'Total loss': 0.2716100829142227}
2022-12-31 14:49:56,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:56,061 INFO:     Epoch: 54
2022-12-31 14:49:57,718 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43482002218564353, 'Total loss': 0.43482002218564353} | train loss {'Reaction outcome loss': 0.2681846584301388, 'Total loss': 0.2681846584301388}
2022-12-31 14:49:57,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:57,719 INFO:     Epoch: 55
2022-12-31 14:49:59,348 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4598303536574046, 'Total loss': 0.4598303536574046} | train loss {'Reaction outcome loss': 0.30911022754710005, 'Total loss': 0.30911022754710005}
2022-12-31 14:49:59,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:49:59,348 INFO:     Epoch: 56
2022-12-31 14:50:00,968 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46472473939259845, 'Total loss': 0.46472473939259845} | train loss {'Reaction outcome loss': 0.2643205234823087, 'Total loss': 0.2643205234823087}
2022-12-31 14:50:00,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:00,968 INFO:     Epoch: 57
2022-12-31 14:50:02,580 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45877490441004437, 'Total loss': 0.45877490441004437} | train loss {'Reaction outcome loss': 0.2592588882535642, 'Total loss': 0.2592588882535642}
2022-12-31 14:50:02,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:02,581 INFO:     Epoch: 58
2022-12-31 14:50:04,220 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43722614645957947, 'Total loss': 0.43722614645957947} | train loss {'Reaction outcome loss': 0.25675457216583303, 'Total loss': 0.25675457216583303}
2022-12-31 14:50:04,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:04,220 INFO:     Epoch: 59
2022-12-31 14:50:05,868 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4209640194972356, 'Total loss': 0.4209640194972356} | train loss {'Reaction outcome loss': 0.25188264397518756, 'Total loss': 0.25188264397518756}
2022-12-31 14:50:05,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:05,869 INFO:     Epoch: 60
2022-12-31 14:50:07,484 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4344847490390142, 'Total loss': 0.4344847490390142} | train loss {'Reaction outcome loss': 0.2449864285721349, 'Total loss': 0.2449864285721349}
2022-12-31 14:50:07,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:07,485 INFO:     Epoch: 61
2022-12-31 14:50:09,087 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4587450921535492, 'Total loss': 0.4587450921535492} | train loss {'Reaction outcome loss': 0.24188532461277276, 'Total loss': 0.24188532461277276}
2022-12-31 14:50:09,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:09,087 INFO:     Epoch: 62
2022-12-31 14:50:10,716 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4329367339611053, 'Total loss': 0.4329367339611053} | train loss {'Reaction outcome loss': 0.24375702262687296, 'Total loss': 0.24375702262687296}
2022-12-31 14:50:10,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:10,716 INFO:     Epoch: 63
2022-12-31 14:50:12,318 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4318916310866674, 'Total loss': 0.4318916310866674} | train loss {'Reaction outcome loss': 0.24459613713122014, 'Total loss': 0.24459613713122014}
2022-12-31 14:50:12,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:12,318 INFO:     Epoch: 64
2022-12-31 14:50:13,924 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4415157665808996, 'Total loss': 0.4415157665808996} | train loss {'Reaction outcome loss': 0.24363241954099224, 'Total loss': 0.24363241954099224}
2022-12-31 14:50:13,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:13,924 INFO:     Epoch: 65
2022-12-31 14:50:15,530 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3920135796070099, 'Total loss': 0.3920135796070099} | train loss {'Reaction outcome loss': 0.24193265590868882, 'Total loss': 0.24193265590868882}
2022-12-31 14:50:15,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:15,531 INFO:     Epoch: 66
2022-12-31 14:50:17,137 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46363565325737, 'Total loss': 0.46363565325737} | train loss {'Reaction outcome loss': 0.23615110279786386, 'Total loss': 0.23615110279786386}
2022-12-31 14:50:17,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:17,137 INFO:     Epoch: 67
2022-12-31 14:50:18,740 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4377611587444941, 'Total loss': 0.4377611587444941} | train loss {'Reaction outcome loss': 0.2646869685149927, 'Total loss': 0.2646869685149927}
2022-12-31 14:50:18,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:18,741 INFO:     Epoch: 68
2022-12-31 14:50:20,358 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46540862222512563, 'Total loss': 0.46540862222512563} | train loss {'Reaction outcome loss': 0.24637584997664974, 'Total loss': 0.24637584997664974}
2022-12-31 14:50:20,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:20,359 INFO:     Epoch: 69
2022-12-31 14:50:21,990 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4584015190601349, 'Total loss': 0.4584015190601349} | train loss {'Reaction outcome loss': 0.23905269634860157, 'Total loss': 0.23905269634860157}
2022-12-31 14:50:21,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:21,991 INFO:     Epoch: 70
2022-12-31 14:50:23,615 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42914287050565086, 'Total loss': 0.42914287050565086} | train loss {'Reaction outcome loss': 0.23970322118080017, 'Total loss': 0.23970322118080017}
2022-12-31 14:50:23,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:23,615 INFO:     Epoch: 71
2022-12-31 14:50:25,229 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46186487674713134, 'Total loss': 0.46186487674713134} | train loss {'Reaction outcome loss': 0.23788384690313882, 'Total loss': 0.23788384690313882}
2022-12-31 14:50:25,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:25,229 INFO:     Epoch: 72
2022-12-31 14:50:26,835 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4743942360083262, 'Total loss': 0.4743942360083262} | train loss {'Reaction outcome loss': 0.23252400681646407, 'Total loss': 0.23252400681646407}
2022-12-31 14:50:26,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:26,837 INFO:     Epoch: 73
2022-12-31 14:50:28,425 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40707455277442933, 'Total loss': 0.40707455277442933} | train loss {'Reaction outcome loss': 0.25090962309627357, 'Total loss': 0.25090962309627357}
2022-12-31 14:50:28,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:28,425 INFO:     Epoch: 74
2022-12-31 14:50:30,034 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4570634682973226, 'Total loss': 0.4570634682973226} | train loss {'Reaction outcome loss': 0.23217863773090253, 'Total loss': 0.23217863773090253}
2022-12-31 14:50:30,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:30,034 INFO:     Epoch: 75
2022-12-31 14:50:31,655 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5159947435061137, 'Total loss': 0.5159947435061137} | train loss {'Reaction outcome loss': 0.22668181253475664, 'Total loss': 0.22668181253475664}
2022-12-31 14:50:31,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:31,655 INFO:     Epoch: 76
2022-12-31 14:50:33,299 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40908116539940237, 'Total loss': 0.40908116539940237} | train loss {'Reaction outcome loss': 0.2276260211871451, 'Total loss': 0.2276260211871451}
2022-12-31 14:50:33,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:33,300 INFO:     Epoch: 77
2022-12-31 14:50:34,920 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42984144339958824, 'Total loss': 0.42984144339958824} | train loss {'Reaction outcome loss': 0.22061090655894816, 'Total loss': 0.22061090655894816}
2022-12-31 14:50:34,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:34,921 INFO:     Epoch: 78
2022-12-31 14:50:36,516 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4551825602849325, 'Total loss': 0.4551825602849325} | train loss {'Reaction outcome loss': 0.2477205128112025, 'Total loss': 0.2477205128112025}
2022-12-31 14:50:36,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:36,517 INFO:     Epoch: 79
2022-12-31 14:50:38,161 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40017160077889763, 'Total loss': 0.40017160077889763} | train loss {'Reaction outcome loss': 0.22577001055996979, 'Total loss': 0.22577001055996979}
2022-12-31 14:50:38,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:38,162 INFO:     Epoch: 80
2022-12-31 14:50:39,765 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4231843173503876, 'Total loss': 0.4231843173503876} | train loss {'Reaction outcome loss': 0.223372284738023, 'Total loss': 0.223372284738023}
2022-12-31 14:50:39,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:39,766 INFO:     Epoch: 81
2022-12-31 14:50:41,389 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40275046130021414, 'Total loss': 0.40275046130021414} | train loss {'Reaction outcome loss': 0.22947291992064836, 'Total loss': 0.22947291992064836}
2022-12-31 14:50:41,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:41,390 INFO:     Epoch: 82
2022-12-31 14:50:42,997 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42569753130277, 'Total loss': 0.42569753130277} | train loss {'Reaction outcome loss': 0.22731621239285416, 'Total loss': 0.22731621239285416}
2022-12-31 14:50:42,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:42,997 INFO:     Epoch: 83
2022-12-31 14:50:44,639 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42748507956663767, 'Total loss': 0.42748507956663767} | train loss {'Reaction outcome loss': 0.2251504798574994, 'Total loss': 0.2251504798574994}
2022-12-31 14:50:44,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:44,639 INFO:     Epoch: 84
2022-12-31 14:50:46,255 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42571299771467846, 'Total loss': 0.42571299771467846} | train loss {'Reaction outcome loss': 0.21420323676547792, 'Total loss': 0.21420323676547792}
2022-12-31 14:50:46,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:46,256 INFO:     Epoch: 85
2022-12-31 14:50:47,848 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.437542288005352, 'Total loss': 0.437542288005352} | train loss {'Reaction outcome loss': 0.21940060473086, 'Total loss': 0.21940060473086}
2022-12-31 14:50:47,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:47,848 INFO:     Epoch: 86
2022-12-31 14:50:49,470 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39544717172781624, 'Total loss': 0.39544717172781624} | train loss {'Reaction outcome loss': 0.21516676088018963, 'Total loss': 0.21516676088018963}
2022-12-31 14:50:49,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:49,470 INFO:     Epoch: 87
2022-12-31 14:50:51,105 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44866509437561036, 'Total loss': 0.44866509437561036} | train loss {'Reaction outcome loss': 0.2121875548736948, 'Total loss': 0.2121875548736948}
2022-12-31 14:50:51,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:51,105 INFO:     Epoch: 88
2022-12-31 14:50:52,719 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44307739635308585, 'Total loss': 0.44307739635308585} | train loss {'Reaction outcome loss': 0.20925057301149314, 'Total loss': 0.20925057301149314}
2022-12-31 14:50:52,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:52,719 INFO:     Epoch: 89
2022-12-31 14:50:54,335 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3945595552523931, 'Total loss': 0.3945595552523931} | train loss {'Reaction outcome loss': 0.21461711584529636, 'Total loss': 0.21461711584529636}
2022-12-31 14:50:54,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:54,335 INFO:     Epoch: 90
2022-12-31 14:50:55,964 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40210641771554945, 'Total loss': 0.40210641771554945} | train loss {'Reaction outcome loss': 0.20821469477991544, 'Total loss': 0.20821469477991544}
2022-12-31 14:50:55,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:55,965 INFO:     Epoch: 91
2022-12-31 14:50:57,576 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42183988690376284, 'Total loss': 0.42183988690376284} | train loss {'Reaction outcome loss': 0.20708155413698134, 'Total loss': 0.20708155413698134}
2022-12-31 14:50:57,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:57,578 INFO:     Epoch: 92
2022-12-31 14:50:59,205 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4143676554163297, 'Total loss': 0.4143676554163297} | train loss {'Reaction outcome loss': 0.21581269678511267, 'Total loss': 0.21581269678511267}
2022-12-31 14:50:59,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:50:59,205 INFO:     Epoch: 93
2022-12-31 14:51:00,852 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.477176171541214, 'Total loss': 0.477176171541214} | train loss {'Reaction outcome loss': 0.21092378542137644, 'Total loss': 0.21092378542137644}
2022-12-31 14:51:00,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:00,852 INFO:     Epoch: 94
2022-12-31 14:51:02,497 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43586548964182537, 'Total loss': 0.43586548964182537} | train loss {'Reaction outcome loss': 0.21120819795127635, 'Total loss': 0.21120819795127635}
2022-12-31 14:51:02,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:02,497 INFO:     Epoch: 95
2022-12-31 14:51:04,112 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.442521296441555, 'Total loss': 0.442521296441555} | train loss {'Reaction outcome loss': 0.21170745323953283, 'Total loss': 0.21170745323953283}
2022-12-31 14:51:04,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:04,113 INFO:     Epoch: 96
2022-12-31 14:51:05,712 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4729367603858312, 'Total loss': 0.4729367603858312} | train loss {'Reaction outcome loss': 0.20579908524962157, 'Total loss': 0.20579908524962157}
2022-12-31 14:51:05,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:05,712 INFO:     Epoch: 97
2022-12-31 14:51:07,313 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4500747392574946, 'Total loss': 0.4500747392574946} | train loss {'Reaction outcome loss': 0.21193008146424225, 'Total loss': 0.21193008146424225}
2022-12-31 14:51:07,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:07,313 INFO:     Epoch: 98
2022-12-31 14:51:08,925 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41403183539708455, 'Total loss': 0.41403183539708455} | train loss {'Reaction outcome loss': 0.1997328063032752, 'Total loss': 0.1997328063032752}
2022-12-31 14:51:08,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:08,926 INFO:     Epoch: 99
2022-12-31 14:51:10,539 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4205863058567047, 'Total loss': 0.4205863058567047} | train loss {'Reaction outcome loss': 0.21048840937758054, 'Total loss': 0.21048840937758054}
2022-12-31 14:51:10,539 INFO:     Best model found after epoch 46 of 100.
2022-12-31 14:51:10,539 INFO:   Done with stage: TRAINING
2022-12-31 14:51:10,539 INFO:   Starting stage: EVALUATION
2022-12-31 14:51:10,668 INFO:   Done with stage: EVALUATION
2022-12-31 14:51:10,668 INFO:   Leaving out SEQ value Fold_9
2022-12-31 14:51:10,680 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 14:51:10,681 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:51:11,335 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:51:11,335 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:51:11,404 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:51:11,404 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:51:11,404 INFO:     No hyperparam tuning for this model
2022-12-31 14:51:11,405 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:51:11,405 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:51:11,405 INFO:     None feature selector for col prot
2022-12-31 14:51:11,405 INFO:     None feature selector for col prot
2022-12-31 14:51:11,406 INFO:     None feature selector for col prot
2022-12-31 14:51:11,406 INFO:     None feature selector for col chem
2022-12-31 14:51:11,406 INFO:     None feature selector for col chem
2022-12-31 14:51:11,406 INFO:     None feature selector for col chem
2022-12-31 14:51:11,406 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:51:11,406 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:51:11,408 INFO:     Number of params in model 223921
2022-12-31 14:51:11,411 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:51:11,412 INFO:   Starting stage: TRAINING
2022-12-31 14:51:11,458 INFO:     Val loss before train {'Reaction outcome loss': 0.9763741612434387, 'Total loss': 0.9763741612434387}
2022-12-31 14:51:11,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:11,459 INFO:     Epoch: 0
2022-12-31 14:51:13,054 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6866064389546712, 'Total loss': 0.6866064389546712} | train loss {'Reaction outcome loss': 0.8390906854343695, 'Total loss': 0.8390906854343695}
2022-12-31 14:51:13,054 INFO:     Found new best model at epoch 0
2022-12-31 14:51:13,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:13,055 INFO:     Epoch: 1
2022-12-31 14:51:14,680 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.604699699083964, 'Total loss': 0.604699699083964} | train loss {'Reaction outcome loss': 0.6407083004065182, 'Total loss': 0.6407083004065182}
2022-12-31 14:51:14,680 INFO:     Found new best model at epoch 1
2022-12-31 14:51:14,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:14,681 INFO:     Epoch: 2
2022-12-31 14:51:16,298 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5072179814179738, 'Total loss': 0.5072179814179738} | train loss {'Reaction outcome loss': 0.5714193258039735, 'Total loss': 0.5714193258039735}
2022-12-31 14:51:16,299 INFO:     Found new best model at epoch 2
2022-12-31 14:51:16,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:16,300 INFO:     Epoch: 3
2022-12-31 14:51:17,913 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46596825619538623, 'Total loss': 0.46596825619538623} | train loss {'Reaction outcome loss': 0.520263031449007, 'Total loss': 0.520263031449007}
2022-12-31 14:51:17,913 INFO:     Found new best model at epoch 3
2022-12-31 14:51:17,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:17,914 INFO:     Epoch: 4
2022-12-31 14:51:19,529 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49179781079292295, 'Total loss': 0.49179781079292295} | train loss {'Reaction outcome loss': 0.5323565697324448, 'Total loss': 0.5323565697324448}
2022-12-31 14:51:19,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:19,529 INFO:     Epoch: 5
2022-12-31 14:51:21,142 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46607623298962914, 'Total loss': 0.46607623298962914} | train loss {'Reaction outcome loss': 0.5065204170431293, 'Total loss': 0.5065204170431293}
2022-12-31 14:51:21,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:21,142 INFO:     Epoch: 6
2022-12-31 14:51:22,763 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44141295552253723, 'Total loss': 0.44141295552253723} | train loss {'Reaction outcome loss': 0.4813633663242386, 'Total loss': 0.4813633663242386}
2022-12-31 14:51:22,763 INFO:     Found new best model at epoch 6
2022-12-31 14:51:22,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:22,764 INFO:     Epoch: 7
2022-12-31 14:51:24,380 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4396358966827393, 'Total loss': 0.4396358966827393} | train loss {'Reaction outcome loss': 0.4717105837586079, 'Total loss': 0.4717105837586079}
2022-12-31 14:51:24,380 INFO:     Found new best model at epoch 7
2022-12-31 14:51:24,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:24,381 INFO:     Epoch: 8
2022-12-31 14:51:26,000 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44574834605058034, 'Total loss': 0.44574834605058034} | train loss {'Reaction outcome loss': 0.46380908493175294, 'Total loss': 0.46380908493175294}
2022-12-31 14:51:26,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:26,000 INFO:     Epoch: 9
2022-12-31 14:51:27,616 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43439687887827555, 'Total loss': 0.43439687887827555} | train loss {'Reaction outcome loss': 0.4622201248480385, 'Total loss': 0.4622201248480385}
2022-12-31 14:51:27,616 INFO:     Found new best model at epoch 9
2022-12-31 14:51:27,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:27,617 INFO:     Epoch: 10
2022-12-31 14:51:29,231 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44121092359224956, 'Total loss': 0.44121092359224956} | train loss {'Reaction outcome loss': 0.45143755597561813, 'Total loss': 0.45143755597561813}
2022-12-31 14:51:29,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:29,232 INFO:     Epoch: 11
2022-12-31 14:51:30,829 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47544986307621, 'Total loss': 0.47544986307621} | train loss {'Reaction outcome loss': 0.44792426517908124, 'Total loss': 0.44792426517908124}
2022-12-31 14:51:30,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:30,829 INFO:     Epoch: 12
2022-12-31 14:51:32,444 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47817567984263104, 'Total loss': 0.47817567984263104} | train loss {'Reaction outcome loss': 0.46455473798340646, 'Total loss': 0.46455473798340646}
2022-12-31 14:51:32,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:32,444 INFO:     Epoch: 13
2022-12-31 14:51:34,053 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.459081972638766, 'Total loss': 0.459081972638766} | train loss {'Reaction outcome loss': 0.485642864274374, 'Total loss': 0.485642864274374}
2022-12-31 14:51:34,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:34,054 INFO:     Epoch: 14
2022-12-31 14:51:35,669 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42332395911216736, 'Total loss': 0.42332395911216736} | train loss {'Reaction outcome loss': 0.4700904224570178, 'Total loss': 0.4700904224570178}
2022-12-31 14:51:35,670 INFO:     Found new best model at epoch 14
2022-12-31 14:51:35,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:35,671 INFO:     Epoch: 15
2022-12-31 14:51:37,284 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41452866593996684, 'Total loss': 0.41452866593996684} | train loss {'Reaction outcome loss': 0.435801251995988, 'Total loss': 0.435801251995988}
2022-12-31 14:51:37,284 INFO:     Found new best model at epoch 15
2022-12-31 14:51:37,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:37,285 INFO:     Epoch: 16
2022-12-31 14:51:38,928 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4443518082300822, 'Total loss': 0.4443518082300822} | train loss {'Reaction outcome loss': 0.4336599487865317, 'Total loss': 0.4336599487865317}
2022-12-31 14:51:38,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:38,928 INFO:     Epoch: 17
2022-12-31 14:51:40,543 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42772660255432127, 'Total loss': 0.42772660255432127} | train loss {'Reaction outcome loss': 0.45536552752921544, 'Total loss': 0.45536552752921544}
2022-12-31 14:51:40,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:40,543 INFO:     Epoch: 18
2022-12-31 14:51:42,154 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4167595863342285, 'Total loss': 0.4167595863342285} | train loss {'Reaction outcome loss': 0.47379270810431434, 'Total loss': 0.47379270810431434}
2022-12-31 14:51:42,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:42,154 INFO:     Epoch: 19
2022-12-31 14:51:43,800 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42016184131304424, 'Total loss': 0.42016184131304424} | train loss {'Reaction outcome loss': 0.42997829481095506, 'Total loss': 0.42997829481095506}
2022-12-31 14:51:43,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:43,800 INFO:     Epoch: 20
2022-12-31 14:51:45,450 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40006151298681897, 'Total loss': 0.40006151298681897} | train loss {'Reaction outcome loss': 0.43086823527498735, 'Total loss': 0.43086823527498735}
2022-12-31 14:51:45,450 INFO:     Found new best model at epoch 20
2022-12-31 14:51:45,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:45,451 INFO:     Epoch: 21
2022-12-31 14:51:47,077 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4198274900515874, 'Total loss': 0.4198274900515874} | train loss {'Reaction outcome loss': 0.4086098889719047, 'Total loss': 0.4086098889719047}
2022-12-31 14:51:47,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:47,077 INFO:     Epoch: 22
2022-12-31 14:51:48,687 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4333183358112971, 'Total loss': 0.4333183358112971} | train loss {'Reaction outcome loss': 0.4026295340850792, 'Total loss': 0.4026295340850792}
2022-12-31 14:51:48,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:48,688 INFO:     Epoch: 23
2022-12-31 14:51:50,327 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4072250167528788, 'Total loss': 0.4072250167528788} | train loss {'Reaction outcome loss': 0.40230441532111255, 'Total loss': 0.40230441532111255}
2022-12-31 14:51:50,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:50,328 INFO:     Epoch: 24
2022-12-31 14:51:51,937 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3999055107434591, 'Total loss': 0.3999055107434591} | train loss {'Reaction outcome loss': 0.39463674193383125, 'Total loss': 0.39463674193383125}
2022-12-31 14:51:51,937 INFO:     Found new best model at epoch 24
2022-12-31 14:51:51,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:51,938 INFO:     Epoch: 25
2022-12-31 14:51:53,562 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3944710602362951, 'Total loss': 0.3944710602362951} | train loss {'Reaction outcome loss': 0.3914446242337547, 'Total loss': 0.3914446242337547}
2022-12-31 14:51:53,562 INFO:     Found new best model at epoch 25
2022-12-31 14:51:53,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:53,563 INFO:     Epoch: 26
2022-12-31 14:51:55,177 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41247959434986115, 'Total loss': 0.41247959434986115} | train loss {'Reaction outcome loss': 0.3869277989302856, 'Total loss': 0.3869277989302856}
2022-12-31 14:51:55,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:55,178 INFO:     Epoch: 27
2022-12-31 14:51:56,790 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3739300479491552, 'Total loss': 0.3739300479491552} | train loss {'Reaction outcome loss': 0.3776154825249677, 'Total loss': 0.3776154825249677}
2022-12-31 14:51:56,790 INFO:     Found new best model at epoch 27
2022-12-31 14:51:56,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:56,791 INFO:     Epoch: 28
2022-12-31 14:51:58,396 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4171326940258344, 'Total loss': 0.4171326940258344} | train loss {'Reaction outcome loss': 0.37489988290083903, 'Total loss': 0.37489988290083903}
2022-12-31 14:51:58,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:51:58,396 INFO:     Epoch: 29
2022-12-31 14:52:00,034 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38334563573201497, 'Total loss': 0.38334563573201497} | train loss {'Reaction outcome loss': 0.3657767451165811, 'Total loss': 0.3657767451165811}
2022-12-31 14:52:00,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:00,035 INFO:     Epoch: 30
2022-12-31 14:52:01,685 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4458825627962748, 'Total loss': 0.4458825627962748} | train loss {'Reaction outcome loss': 0.3643899895107387, 'Total loss': 0.3643899895107387}
2022-12-31 14:52:01,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:01,685 INFO:     Epoch: 31
2022-12-31 14:52:03,323 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3906613896290461, 'Total loss': 0.3906613896290461} | train loss {'Reaction outcome loss': 0.3639320000367951, 'Total loss': 0.3639320000367951}
2022-12-31 14:52:03,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:03,323 INFO:     Epoch: 32
2022-12-31 14:52:04,970 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41601291596889495, 'Total loss': 0.41601291596889495} | train loss {'Reaction outcome loss': 0.35678751871961617, 'Total loss': 0.35678751871961617}
2022-12-31 14:52:04,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:04,971 INFO:     Epoch: 33
2022-12-31 14:52:06,589 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.392667156457901, 'Total loss': 0.392667156457901} | train loss {'Reaction outcome loss': 0.39119461447272985, 'Total loss': 0.39119461447272985}
2022-12-31 14:52:06,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:06,589 INFO:     Epoch: 34
2022-12-31 14:52:08,220 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3825052171945572, 'Total loss': 0.3825052171945572} | train loss {'Reaction outcome loss': 0.3554415783062037, 'Total loss': 0.3554415783062037}
2022-12-31 14:52:08,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:08,220 INFO:     Epoch: 35
2022-12-31 14:52:09,846 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3720412353674571, 'Total loss': 0.3720412353674571} | train loss {'Reaction outcome loss': 0.3421910691894996, 'Total loss': 0.3421910691894996}
2022-12-31 14:52:09,846 INFO:     Found new best model at epoch 35
2022-12-31 14:52:09,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:09,847 INFO:     Epoch: 36
2022-12-31 14:52:11,471 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.36148735880851746, 'Total loss': 0.36148735880851746} | train loss {'Reaction outcome loss': 0.33818640416838985, 'Total loss': 0.33818640416838985}
2022-12-31 14:52:11,472 INFO:     Found new best model at epoch 36
2022-12-31 14:52:11,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:11,473 INFO:     Epoch: 37
2022-12-31 14:52:13,102 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38758986194928485, 'Total loss': 0.38758986194928485} | train loss {'Reaction outcome loss': 0.33722742759129976, 'Total loss': 0.33722742759129976}
2022-12-31 14:52:13,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:13,102 INFO:     Epoch: 38
2022-12-31 14:52:14,720 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3753182182709376, 'Total loss': 0.3753182182709376} | train loss {'Reaction outcome loss': 0.33488779544384906, 'Total loss': 0.33488779544384906}
2022-12-31 14:52:14,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:14,720 INFO:     Epoch: 39
2022-12-31 14:52:16,320 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3664979120095571, 'Total loss': 0.3664979120095571} | train loss {'Reaction outcome loss': 0.3510287346831266, 'Total loss': 0.3510287346831266}
2022-12-31 14:52:16,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:16,320 INFO:     Epoch: 40
2022-12-31 14:52:17,968 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.36634402771790825, 'Total loss': 0.36634402771790825} | train loss {'Reaction outcome loss': 0.33170273657331406, 'Total loss': 0.33170273657331406}
2022-12-31 14:52:17,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:17,968 INFO:     Epoch: 41
2022-12-31 14:52:19,577 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38885369102160133, 'Total loss': 0.38885369102160133} | train loss {'Reaction outcome loss': 0.32203211921496666, 'Total loss': 0.32203211921496666}
2022-12-31 14:52:19,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:19,577 INFO:     Epoch: 42
2022-12-31 14:52:21,197 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3613412355383237, 'Total loss': 0.3613412355383237} | train loss {'Reaction outcome loss': 0.33750032907256106, 'Total loss': 0.33750032907256106}
2022-12-31 14:52:21,197 INFO:     Found new best model at epoch 42
2022-12-31 14:52:21,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:21,198 INFO:     Epoch: 43
2022-12-31 14:52:22,831 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3820696125427882, 'Total loss': 0.3820696125427882} | train loss {'Reaction outcome loss': 0.3154303478684438, 'Total loss': 0.3154303478684438}
2022-12-31 14:52:22,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:22,831 INFO:     Epoch: 44
2022-12-31 14:52:24,455 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.36368919909000397, 'Total loss': 0.36368919909000397} | train loss {'Reaction outcome loss': 0.30670575225477753, 'Total loss': 0.30670575225477753}
2022-12-31 14:52:24,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:24,455 INFO:     Epoch: 45
2022-12-31 14:52:26,062 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.36563642621040343, 'Total loss': 0.36563642621040343} | train loss {'Reaction outcome loss': 0.30315630367376667, 'Total loss': 0.30315630367376667}
2022-12-31 14:52:26,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:26,062 INFO:     Epoch: 46
2022-12-31 14:52:27,671 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3472215473651886, 'Total loss': 0.3472215473651886} | train loss {'Reaction outcome loss': 0.3093605287473453, 'Total loss': 0.3093605287473453}
2022-12-31 14:52:27,671 INFO:     Found new best model at epoch 46
2022-12-31 14:52:27,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:27,672 INFO:     Epoch: 47
2022-12-31 14:52:29,293 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3842089613278707, 'Total loss': 0.3842089613278707} | train loss {'Reaction outcome loss': 0.3029426169460234, 'Total loss': 0.3029426169460234}
2022-12-31 14:52:29,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:29,293 INFO:     Epoch: 48
2022-12-31 14:52:30,918 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.35254622449477513, 'Total loss': 0.35254622449477513} | train loss {'Reaction outcome loss': 0.3326149926237438, 'Total loss': 0.3326149926237438}
2022-12-31 14:52:30,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:30,918 INFO:     Epoch: 49
2022-12-31 14:52:32,566 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.36811066369215645, 'Total loss': 0.36811066369215645} | train loss {'Reaction outcome loss': 0.31003955491157115, 'Total loss': 0.31003955491157115}
2022-12-31 14:52:32,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:32,566 INFO:     Epoch: 50
2022-12-31 14:52:34,207 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3845976129174232, 'Total loss': 0.3845976129174232} | train loss {'Reaction outcome loss': 0.32089064502245, 'Total loss': 0.32089064502245}
2022-12-31 14:52:34,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:34,207 INFO:     Epoch: 51
2022-12-31 14:52:35,806 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.34282124439875283, 'Total loss': 0.34282124439875283} | train loss {'Reaction outcome loss': 0.2906352172539946, 'Total loss': 0.2906352172539946}
2022-12-31 14:52:35,806 INFO:     Found new best model at epoch 51
2022-12-31 14:52:35,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:35,807 INFO:     Epoch: 52
2022-12-31 14:52:37,390 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36711692015329994, 'Total loss': 0.36711692015329994} | train loss {'Reaction outcome loss': 0.28344988017551775, 'Total loss': 0.28344988017551775}
2022-12-31 14:52:37,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:37,391 INFO:     Epoch: 53
2022-12-31 14:52:39,007 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3505505825082461, 'Total loss': 0.3505505825082461} | train loss {'Reaction outcome loss': 0.2857589738551473, 'Total loss': 0.2857589738551473}
2022-12-31 14:52:39,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:39,007 INFO:     Epoch: 54
2022-12-31 14:52:40,653 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.36181865632534027, 'Total loss': 0.36181865632534027} | train loss {'Reaction outcome loss': 0.2818597106607226, 'Total loss': 0.2818597106607226}
2022-12-31 14:52:40,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:40,654 INFO:     Epoch: 55
2022-12-31 14:52:42,271 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.35266556168595947, 'Total loss': 0.35266556168595947} | train loss {'Reaction outcome loss': 0.2836246244420392, 'Total loss': 0.2836246244420392}
2022-12-31 14:52:42,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:42,272 INFO:     Epoch: 56
2022-12-31 14:52:43,709 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3320003007849058, 'Total loss': 0.3320003007849058} | train loss {'Reaction outcome loss': 0.2768072225036398, 'Total loss': 0.2768072225036398}
2022-12-31 14:52:43,709 INFO:     Found new best model at epoch 56
2022-12-31 14:52:43,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:43,710 INFO:     Epoch: 57
2022-12-31 14:52:44,807 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.34148884067932767, 'Total loss': 0.34148884067932767} | train loss {'Reaction outcome loss': 0.27137409411775676, 'Total loss': 0.27137409411775676}
2022-12-31 14:52:44,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:44,808 INFO:     Epoch: 58
2022-12-31 14:52:45,898 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.371203339099884, 'Total loss': 0.371203339099884} | train loss {'Reaction outcome loss': 0.27120864392001776, 'Total loss': 0.27120864392001776}
2022-12-31 14:52:45,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:45,898 INFO:     Epoch: 59
2022-12-31 14:52:46,988 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.33453679184118906, 'Total loss': 0.33453679184118906} | train loss {'Reaction outcome loss': 0.27138977769151307, 'Total loss': 0.27138977769151307}
2022-12-31 14:52:46,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:46,989 INFO:     Epoch: 60
2022-12-31 14:52:48,162 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.353532808025678, 'Total loss': 0.353532808025678} | train loss {'Reaction outcome loss': 0.2631713933669085, 'Total loss': 0.2631713933669085}
2022-12-31 14:52:48,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:48,162 INFO:     Epoch: 61
2022-12-31 14:52:49,783 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.32063885355989136, 'Total loss': 0.32063885355989136} | train loss {'Reaction outcome loss': 0.2731969979468504, 'Total loss': 0.2731969979468504}
2022-12-31 14:52:49,784 INFO:     Found new best model at epoch 61
2022-12-31 14:52:49,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:49,784 INFO:     Epoch: 62
2022-12-31 14:52:51,424 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3770435482263565, 'Total loss': 0.3770435482263565} | train loss {'Reaction outcome loss': 0.26208368542553956, 'Total loss': 0.26208368542553956}
2022-12-31 14:52:51,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:51,424 INFO:     Epoch: 63
2022-12-31 14:52:53,028 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3445475747187932, 'Total loss': 0.3445475747187932} | train loss {'Reaction outcome loss': 0.2540720981529718, 'Total loss': 0.2540720981529718}
2022-12-31 14:52:53,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:53,028 INFO:     Epoch: 64
2022-12-31 14:52:54,647 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38185795744260154, 'Total loss': 0.38185795744260154} | train loss {'Reaction outcome loss': 0.2639519513409207, 'Total loss': 0.2639519513409207}
2022-12-31 14:52:54,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:54,647 INFO:     Epoch: 65
2022-12-31 14:52:56,264 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37589158018430074, 'Total loss': 0.37589158018430074} | train loss {'Reaction outcome loss': 0.25348672108130826, 'Total loss': 0.25348672108130826}
2022-12-31 14:52:56,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:56,265 INFO:     Epoch: 66
2022-12-31 14:52:57,888 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3164679562052091, 'Total loss': 0.3164679562052091} | train loss {'Reaction outcome loss': 0.2538640558942343, 'Total loss': 0.2538640558942343}
2022-12-31 14:52:57,888 INFO:     Found new best model at epoch 66
2022-12-31 14:52:57,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:57,889 INFO:     Epoch: 67
2022-12-31 14:52:59,531 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.32454100251197815, 'Total loss': 0.32454100251197815} | train loss {'Reaction outcome loss': 0.25436117485219584, 'Total loss': 0.25436117485219584}
2022-12-31 14:52:59,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:52:59,532 INFO:     Epoch: 68
2022-12-31 14:53:01,154 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4056769867738088, 'Total loss': 0.4056769867738088} | train loss {'Reaction outcome loss': 0.25539327307811566, 'Total loss': 0.25539327307811566}
2022-12-31 14:53:01,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:01,154 INFO:     Epoch: 69
2022-12-31 14:53:02,760 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.35331343710422514, 'Total loss': 0.35331343710422514} | train loss {'Reaction outcome loss': 0.25067874536433377, 'Total loss': 0.25067874536433377}
2022-12-31 14:53:02,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:02,760 INFO:     Epoch: 70
2022-12-31 14:53:04,401 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.36846802234649656, 'Total loss': 0.36846802234649656} | train loss {'Reaction outcome loss': 0.2644189697406862, 'Total loss': 0.2644189697406862}
2022-12-31 14:53:04,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:04,401 INFO:     Epoch: 71
2022-12-31 14:53:06,015 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3503846675157547, 'Total loss': 0.3503846675157547} | train loss {'Reaction outcome loss': 0.31587166115101695, 'Total loss': 0.31587166115101695}
2022-12-31 14:53:06,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:06,016 INFO:     Epoch: 72
2022-12-31 14:53:07,620 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.33454353859027225, 'Total loss': 0.33454353859027225} | train loss {'Reaction outcome loss': 0.25731131869015633, 'Total loss': 0.25731131869015633}
2022-12-31 14:53:07,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:07,620 INFO:     Epoch: 73
2022-12-31 14:53:09,254 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37188938359419504, 'Total loss': 0.37188938359419504} | train loss {'Reaction outcome loss': 0.24060756699654504, 'Total loss': 0.24060756699654504}
2022-12-31 14:53:09,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:09,255 INFO:     Epoch: 74
2022-12-31 14:53:10,854 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3601260056098302, 'Total loss': 0.3601260056098302} | train loss {'Reaction outcome loss': 0.2552682391998541, 'Total loss': 0.2552682391998541}
2022-12-31 14:53:10,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:10,854 INFO:     Epoch: 75
2022-12-31 14:53:12,501 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3463341385126114, 'Total loss': 0.3463341385126114} | train loss {'Reaction outcome loss': 0.24422676211342795, 'Total loss': 0.24422676211342795}
2022-12-31 14:53:12,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:12,501 INFO:     Epoch: 76
2022-12-31 14:53:14,138 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3272430643439293, 'Total loss': 0.3272430643439293} | train loss {'Reaction outcome loss': 0.2403591398786217, 'Total loss': 0.2403591398786217}
2022-12-31 14:53:14,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:14,138 INFO:     Epoch: 77
2022-12-31 14:53:15,752 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.33027924299240113, 'Total loss': 0.33027924299240113} | train loss {'Reaction outcome loss': 0.23945016710279995, 'Total loss': 0.23945016710279995}
2022-12-31 14:53:15,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:15,753 INFO:     Epoch: 78
2022-12-31 14:53:17,356 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3436174179116885, 'Total loss': 0.3436174179116885} | train loss {'Reaction outcome loss': 0.23817341298517009, 'Total loss': 0.23817341298517009}
2022-12-31 14:53:17,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:17,356 INFO:     Epoch: 79
2022-12-31 14:53:18,990 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.35183304200569787, 'Total loss': 0.35183304200569787} | train loss {'Reaction outcome loss': 0.2371129200920763, 'Total loss': 0.2371129200920763}
2022-12-31 14:53:18,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:18,990 INFO:     Epoch: 80
2022-12-31 14:53:20,585 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.35832632680734, 'Total loss': 0.35832632680734} | train loss {'Reaction outcome loss': 0.234403013475273, 'Total loss': 0.234403013475273}
2022-12-31 14:53:20,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:20,585 INFO:     Epoch: 81
2022-12-31 14:53:22,212 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3732683703303337, 'Total loss': 0.3732683703303337} | train loss {'Reaction outcome loss': 0.23868906045791463, 'Total loss': 0.23868906045791463}
2022-12-31 14:53:22,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:22,213 INFO:     Epoch: 82
2022-12-31 14:53:23,837 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3768973668416341, 'Total loss': 0.3768973668416341} | train loss {'Reaction outcome loss': 0.2864871236649207, 'Total loss': 0.2864871236649207}
2022-12-31 14:53:23,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:23,837 INFO:     Epoch: 83
2022-12-31 14:53:25,462 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3755220661560694, 'Total loss': 0.3755220661560694} | train loss {'Reaction outcome loss': 0.2394264809282385, 'Total loss': 0.2394264809282385}
2022-12-31 14:53:25,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:25,462 INFO:     Epoch: 84
2022-12-31 14:53:27,081 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3620623384912809, 'Total loss': 0.3620623384912809} | train loss {'Reaction outcome loss': 0.24204121591743466, 'Total loss': 0.24204121591743466}
2022-12-31 14:53:27,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:27,081 INFO:     Epoch: 85
2022-12-31 14:53:28,710 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3760063846906026, 'Total loss': 0.3760063846906026} | train loss {'Reaction outcome loss': 0.23313541687693745, 'Total loss': 0.23313541687693745}
2022-12-31 14:53:28,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:28,711 INFO:     Epoch: 86
2022-12-31 14:53:30,338 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3975356231133143, 'Total loss': 0.3975356231133143} | train loss {'Reaction outcome loss': 0.2411804716170266, 'Total loss': 0.2411804716170266}
2022-12-31 14:53:30,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:30,339 INFO:     Epoch: 87
2022-12-31 14:53:31,978 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38680636088053383, 'Total loss': 0.38680636088053383} | train loss {'Reaction outcome loss': 0.2624862635022272, 'Total loss': 0.2624862635022272}
2022-12-31 14:53:31,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:31,978 INFO:     Epoch: 88
2022-12-31 14:53:33,577 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.34991437941789627, 'Total loss': 0.34991437941789627} | train loss {'Reaction outcome loss': 0.2892262051868981, 'Total loss': 0.2892262051868981}
2022-12-31 14:53:33,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:33,578 INFO:     Epoch: 89
2022-12-31 14:53:35,192 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.34853412260611855, 'Total loss': 0.34853412260611855} | train loss {'Reaction outcome loss': 0.23876977054844273, 'Total loss': 0.23876977054844273}
2022-12-31 14:53:35,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:35,192 INFO:     Epoch: 90
2022-12-31 14:53:36,822 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3239819308121999, 'Total loss': 0.3239819308121999} | train loss {'Reaction outcome loss': 0.2293355635190602, 'Total loss': 0.2293355635190602}
2022-12-31 14:53:36,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:36,822 INFO:     Epoch: 91
2022-12-31 14:53:38,431 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3629660447438558, 'Total loss': 0.3629660447438558} | train loss {'Reaction outcome loss': 0.22036066385613673, 'Total loss': 0.22036066385613673}
2022-12-31 14:53:38,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:38,431 INFO:     Epoch: 92
2022-12-31 14:53:40,037 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3400717159112295, 'Total loss': 0.3400717159112295} | train loss {'Reaction outcome loss': 0.22521766191483408, 'Total loss': 0.22521766191483408}
2022-12-31 14:53:40,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:40,037 INFO:     Epoch: 93
2022-12-31 14:53:41,645 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3474288508296013, 'Total loss': 0.3474288508296013} | train loss {'Reaction outcome loss': 0.21984485602276266, 'Total loss': 0.21984485602276266}
2022-12-31 14:53:41,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:41,645 INFO:     Epoch: 94
2022-12-31 14:53:43,235 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.325815886259079, 'Total loss': 0.325815886259079} | train loss {'Reaction outcome loss': 0.22689890631717508, 'Total loss': 0.22689890631717508}
2022-12-31 14:53:43,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:43,235 INFO:     Epoch: 95
2022-12-31 14:53:44,840 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3331820920109749, 'Total loss': 0.3331820920109749} | train loss {'Reaction outcome loss': 0.2204069113267115, 'Total loss': 0.2204069113267115}
2022-12-31 14:53:44,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:44,840 INFO:     Epoch: 96
2022-12-31 14:53:46,448 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.32634324828783673, 'Total loss': 0.32634324828783673} | train loss {'Reaction outcome loss': 0.2188374520949277, 'Total loss': 0.2188374520949277}
2022-12-31 14:53:46,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:46,449 INFO:     Epoch: 97
2022-12-31 14:53:48,061 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3173612090448538, 'Total loss': 0.3173612090448538} | train loss {'Reaction outcome loss': 0.21795026417079288, 'Total loss': 0.21795026417079288}
2022-12-31 14:53:48,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:48,061 INFO:     Epoch: 98
2022-12-31 14:53:49,666 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.35974352310101193, 'Total loss': 0.35974352310101193} | train loss {'Reaction outcome loss': 0.22121220354595778, 'Total loss': 0.22121220354595778}
2022-12-31 14:53:49,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:49,666 INFO:     Epoch: 99
2022-12-31 14:53:51,272 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.362193696697553, 'Total loss': 0.362193696697553} | train loss {'Reaction outcome loss': 0.21727439395065143, 'Total loss': 0.21727439395065143}
2022-12-31 14:53:51,273 INFO:     Best model found after epoch 67 of 100.
2022-12-31 14:53:51,273 INFO:   Done with stage: TRAINING
2022-12-31 14:53:51,273 INFO:   Starting stage: EVALUATION
2022-12-31 14:53:51,401 INFO:   Done with stage: EVALUATION
2022-12-31 14:53:51,410 INFO:   Leaving out SEQ value Fold_0
2022-12-31 14:53:51,423 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 14:53:51,423 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:53:52,077 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:53:52,077 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:53:52,146 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:53:52,146 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:53:52,146 INFO:     No hyperparam tuning for this model
2022-12-31 14:53:52,146 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:53:52,146 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:53:52,147 INFO:     None feature selector for col prot
2022-12-31 14:53:52,147 INFO:     None feature selector for col prot
2022-12-31 14:53:52,147 INFO:     None feature selector for col prot
2022-12-31 14:53:52,148 INFO:     None feature selector for col chem
2022-12-31 14:53:52,148 INFO:     None feature selector for col chem
2022-12-31 14:53:52,148 INFO:     None feature selector for col chem
2022-12-31 14:53:52,148 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:53:52,148 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:53:52,150 INFO:     Number of params in model 223921
2022-12-31 14:53:52,153 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:53:52,153 INFO:   Starting stage: TRAINING
2022-12-31 14:53:52,198 INFO:     Val loss before train {'Reaction outcome loss': 0.9827038049697876, 'Total loss': 0.9827038049697876}
2022-12-31 14:53:52,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:52,198 INFO:     Epoch: 0
2022-12-31 14:53:53,827 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6933978835741679, 'Total loss': 0.6933978835741679} | train loss {'Reaction outcome loss': 0.8214923759011457, 'Total loss': 0.8214923759011457}
2022-12-31 14:53:53,827 INFO:     Found new best model at epoch 0
2022-12-31 14:53:53,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:53,828 INFO:     Epoch: 1
2022-12-31 14:53:55,444 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5851480960845947, 'Total loss': 0.5851480960845947} | train loss {'Reaction outcome loss': 0.5980335799229406, 'Total loss': 0.5980335799229406}
2022-12-31 14:53:55,444 INFO:     Found new best model at epoch 1
2022-12-31 14:53:55,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:55,445 INFO:     Epoch: 2
2022-12-31 14:53:57,032 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5065287033716838, 'Total loss': 0.5065287033716838} | train loss {'Reaction outcome loss': 0.5398960319096154, 'Total loss': 0.5398960319096154}
2022-12-31 14:53:57,032 INFO:     Found new best model at epoch 2
2022-12-31 14:53:57,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:57,033 INFO:     Epoch: 3
2022-12-31 14:53:58,627 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5053666114807129, 'Total loss': 0.5053666114807129} | train loss {'Reaction outcome loss': 0.5061354919397918, 'Total loss': 0.5061354919397918}
2022-12-31 14:53:58,627 INFO:     Found new best model at epoch 3
2022-12-31 14:53:58,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:53:58,628 INFO:     Epoch: 4
2022-12-31 14:54:00,213 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48955980439980823, 'Total loss': 0.48955980439980823} | train loss {'Reaction outcome loss': 0.4977272938746605, 'Total loss': 0.4977272938746605}
2022-12-31 14:54:00,213 INFO:     Found new best model at epoch 4
2022-12-31 14:54:00,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:00,214 INFO:     Epoch: 5
2022-12-31 14:54:01,799 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48298925161361694, 'Total loss': 0.48298925161361694} | train loss {'Reaction outcome loss': 0.48052669224077765, 'Total loss': 0.48052669224077765}
2022-12-31 14:54:01,799 INFO:     Found new best model at epoch 5
2022-12-31 14:54:01,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:01,800 INFO:     Epoch: 6
2022-12-31 14:54:03,397 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47864611943562824, 'Total loss': 0.47864611943562824} | train loss {'Reaction outcome loss': 0.47424974915211215, 'Total loss': 0.47424974915211215}
2022-12-31 14:54:03,397 INFO:     Found new best model at epoch 6
2022-12-31 14:54:03,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:03,398 INFO:     Epoch: 7
2022-12-31 14:54:04,986 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4683098435401917, 'Total loss': 0.4683098435401917} | train loss {'Reaction outcome loss': 0.4589245465658877, 'Total loss': 0.4589245465658877}
2022-12-31 14:54:04,986 INFO:     Found new best model at epoch 7
2022-12-31 14:54:04,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:04,987 INFO:     Epoch: 8
2022-12-31 14:54:06,589 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5178016930818558, 'Total loss': 0.5178016930818558} | train loss {'Reaction outcome loss': 0.4553595425656242, 'Total loss': 0.4553595425656242}
2022-12-31 14:54:06,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:06,589 INFO:     Epoch: 9
2022-12-31 14:54:08,187 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.490105535586675, 'Total loss': 0.490105535586675} | train loss {'Reaction outcome loss': 0.45378046107553216, 'Total loss': 0.45378046107553216}
2022-12-31 14:54:08,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:08,187 INFO:     Epoch: 10
2022-12-31 14:54:09,780 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4424814283847809, 'Total loss': 0.4424814283847809} | train loss {'Reaction outcome loss': 0.44601184586538883, 'Total loss': 0.44601184586538883}
2022-12-31 14:54:09,780 INFO:     Found new best model at epoch 10
2022-12-31 14:54:09,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:09,781 INFO:     Epoch: 11
2022-12-31 14:54:11,395 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4727056344350179, 'Total loss': 0.4727056344350179} | train loss {'Reaction outcome loss': 0.4354967750663305, 'Total loss': 0.4354967750663305}
2022-12-31 14:54:11,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:11,395 INFO:     Epoch: 12
2022-12-31 14:54:13,016 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43762064377466836, 'Total loss': 0.43762064377466836} | train loss {'Reaction outcome loss': 0.42871833002589044, 'Total loss': 0.42871833002589044}
2022-12-31 14:54:13,017 INFO:     Found new best model at epoch 12
2022-12-31 14:54:13,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:13,018 INFO:     Epoch: 13
2022-12-31 14:54:14,604 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43166214525699614, 'Total loss': 0.43166214525699614} | train loss {'Reaction outcome loss': 0.42400842459097393, 'Total loss': 0.42400842459097393}
2022-12-31 14:54:14,604 INFO:     Found new best model at epoch 13
2022-12-31 14:54:14,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:14,605 INFO:     Epoch: 14
2022-12-31 14:54:16,200 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47340355118115746, 'Total loss': 0.47340355118115746} | train loss {'Reaction outcome loss': 0.4185460081772648, 'Total loss': 0.4185460081772648}
2022-12-31 14:54:16,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:16,201 INFO:     Epoch: 15
2022-12-31 14:54:17,808 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43300366401672363, 'Total loss': 0.43300366401672363} | train loss {'Reaction outcome loss': 0.41364695705527804, 'Total loss': 0.41364695705527804}
2022-12-31 14:54:17,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:17,809 INFO:     Epoch: 16
2022-12-31 14:54:19,423 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44096820851167046, 'Total loss': 0.44096820851167046} | train loss {'Reaction outcome loss': 0.4094863953000873, 'Total loss': 0.4094863953000873}
2022-12-31 14:54:19,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:19,423 INFO:     Epoch: 17
2022-12-31 14:54:21,054 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4269938707351685, 'Total loss': 0.4269938707351685} | train loss {'Reaction outcome loss': 0.4015931702443283, 'Total loss': 0.4015931702443283}
2022-12-31 14:54:21,054 INFO:     Found new best model at epoch 17
2022-12-31 14:54:21,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:21,055 INFO:     Epoch: 18
2022-12-31 14:54:22,661 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43352763752142587, 'Total loss': 0.43352763752142587} | train loss {'Reaction outcome loss': 0.3990047034555978, 'Total loss': 0.3990047034555978}
2022-12-31 14:54:22,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:22,661 INFO:     Epoch: 19
2022-12-31 14:54:24,270 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4294895172119141, 'Total loss': 0.4294895172119141} | train loss {'Reaction outcome loss': 0.39405042218574643, 'Total loss': 0.39405042218574643}
2022-12-31 14:54:24,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:24,271 INFO:     Epoch: 20
2022-12-31 14:54:25,874 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41035876572132113, 'Total loss': 0.41035876572132113} | train loss {'Reaction outcome loss': 0.3850926141506129, 'Total loss': 0.3850926141506129}
2022-12-31 14:54:25,874 INFO:     Found new best model at epoch 20
2022-12-31 14:54:25,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:25,875 INFO:     Epoch: 21
2022-12-31 14:54:27,449 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43915084302425383, 'Total loss': 0.43915084302425383} | train loss {'Reaction outcome loss': 0.382264418513888, 'Total loss': 0.382264418513888}
2022-12-31 14:54:27,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:27,449 INFO:     Epoch: 22
2022-12-31 14:54:29,043 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41456480423609415, 'Total loss': 0.41456480423609415} | train loss {'Reaction outcome loss': 0.3714637159077573, 'Total loss': 0.3714637159077573}
2022-12-31 14:54:29,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:29,043 INFO:     Epoch: 23
2022-12-31 14:54:30,660 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39165508846441904, 'Total loss': 0.39165508846441904} | train loss {'Reaction outcome loss': 0.36870892810886796, 'Total loss': 0.36870892810886796}
2022-12-31 14:54:30,660 INFO:     Found new best model at epoch 23
2022-12-31 14:54:30,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:30,661 INFO:     Epoch: 24
2022-12-31 14:54:32,258 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4241990566253662, 'Total loss': 0.4241990566253662} | train loss {'Reaction outcome loss': 0.3689284690377051, 'Total loss': 0.3689284690377051}
2022-12-31 14:54:32,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:32,259 INFO:     Epoch: 25
2022-12-31 14:54:33,860 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42759489913781484, 'Total loss': 0.42759489913781484} | train loss {'Reaction outcome loss': 0.3630739395527074, 'Total loss': 0.3630739395527074}
2022-12-31 14:54:33,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:33,860 INFO:     Epoch: 26
2022-12-31 14:54:35,462 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41189463635285695, 'Total loss': 0.41189463635285695} | train loss {'Reaction outcome loss': 0.3588524823260568, 'Total loss': 0.3588524823260568}
2022-12-31 14:54:35,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:35,462 INFO:     Epoch: 27
2022-12-31 14:54:37,049 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40610974133014677, 'Total loss': 0.40610974133014677} | train loss {'Reaction outcome loss': 0.35419421585915734, 'Total loss': 0.35419421585915734}
2022-12-31 14:54:37,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:37,050 INFO:     Epoch: 28
2022-12-31 14:54:38,665 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4072524885336558, 'Total loss': 0.4072524885336558} | train loss {'Reaction outcome loss': 0.3437713216038516, 'Total loss': 0.3437713216038516}
2022-12-31 14:54:38,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:38,665 INFO:     Epoch: 29
2022-12-31 14:54:40,297 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42415599822998046, 'Total loss': 0.42415599822998046} | train loss {'Reaction outcome loss': 0.33964076158284706, 'Total loss': 0.33964076158284706}
2022-12-31 14:54:40,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:40,297 INFO:     Epoch: 30
2022-12-31 14:54:41,902 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3810845613479614, 'Total loss': 0.3810845613479614} | train loss {'Reaction outcome loss': 0.3347173880540977, 'Total loss': 0.3347173880540977}
2022-12-31 14:54:41,902 INFO:     Found new best model at epoch 30
2022-12-31 14:54:41,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:41,903 INFO:     Epoch: 31
2022-12-31 14:54:43,531 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38312493364016215, 'Total loss': 0.38312493364016215} | train loss {'Reaction outcome loss': 0.32966867728281196, 'Total loss': 0.32966867728281196}
2022-12-31 14:54:43,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:43,531 INFO:     Epoch: 32
2022-12-31 14:54:45,147 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.37167048354943594, 'Total loss': 0.37167048354943594} | train loss {'Reaction outcome loss': 0.3309353080435391, 'Total loss': 0.3309353080435391}
2022-12-31 14:54:45,147 INFO:     Found new best model at epoch 32
2022-12-31 14:54:45,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:45,148 INFO:     Epoch: 33
2022-12-31 14:54:46,736 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40147987206776936, 'Total loss': 0.40147987206776936} | train loss {'Reaction outcome loss': 0.3217689649195132, 'Total loss': 0.3217689649195132}
2022-12-31 14:54:46,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:46,736 INFO:     Epoch: 34
2022-12-31 14:54:48,361 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41965318272511165, 'Total loss': 0.41965318272511165} | train loss {'Reaction outcome loss': 0.3175441500098601, 'Total loss': 0.3175441500098601}
2022-12-31 14:54:48,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:48,361 INFO:     Epoch: 35
2022-12-31 14:54:49,933 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.375079611937205, 'Total loss': 0.375079611937205} | train loss {'Reaction outcome loss': 0.3141912610208901, 'Total loss': 0.3141912610208901}
2022-12-31 14:54:49,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:49,933 INFO:     Epoch: 36
2022-12-31 14:54:51,556 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42683838109175365, 'Total loss': 0.42683838109175365} | train loss {'Reaction outcome loss': 0.30630492561761913, 'Total loss': 0.30630492561761913}
2022-12-31 14:54:51,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:51,556 INFO:     Epoch: 37
2022-12-31 14:54:53,178 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3807854096094767, 'Total loss': 0.3807854096094767} | train loss {'Reaction outcome loss': 0.31350212818840995, 'Total loss': 0.31350212818840995}
2022-12-31 14:54:53,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:53,179 INFO:     Epoch: 38
2022-12-31 14:54:54,779 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3911866197983424, 'Total loss': 0.3911866197983424} | train loss {'Reaction outcome loss': 0.30489938370339625, 'Total loss': 0.30489938370339625}
2022-12-31 14:54:54,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:54,780 INFO:     Epoch: 39
2022-12-31 14:54:56,382 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39719348549842837, 'Total loss': 0.39719348549842837} | train loss {'Reaction outcome loss': 0.302749531962195, 'Total loss': 0.302749531962195}
2022-12-31 14:54:56,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:56,383 INFO:     Epoch: 40
2022-12-31 14:54:58,011 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42711101124684014, 'Total loss': 0.42711101124684014} | train loss {'Reaction outcome loss': 0.29493997042087744, 'Total loss': 0.29493997042087744}
2022-12-31 14:54:58,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:58,011 INFO:     Epoch: 41
2022-12-31 14:54:59,604 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3768801748752594, 'Total loss': 0.3768801748752594} | train loss {'Reaction outcome loss': 0.2931886662042489, 'Total loss': 0.2931886662042489}
2022-12-31 14:54:59,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:54:59,605 INFO:     Epoch: 42
2022-12-31 14:55:01,226 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40598348478476204, 'Total loss': 0.40598348478476204} | train loss {'Reaction outcome loss': 0.29196309371695034, 'Total loss': 0.29196309371695034}
2022-12-31 14:55:01,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:01,227 INFO:     Epoch: 43
2022-12-31 14:55:02,843 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3904183179140091, 'Total loss': 0.3904183179140091} | train loss {'Reaction outcome loss': 0.28839085782014756, 'Total loss': 0.28839085782014756}
2022-12-31 14:55:02,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:02,843 INFO:     Epoch: 44
2022-12-31 14:55:04,451 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39409076621135075, 'Total loss': 0.39409076621135075} | train loss {'Reaction outcome loss': 0.28118167837986546, 'Total loss': 0.28118167837986546}
2022-12-31 14:55:04,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:04,451 INFO:     Epoch: 45
2022-12-31 14:55:06,045 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4064544181029002, 'Total loss': 0.4064544181029002} | train loss {'Reaction outcome loss': 0.28035832824606965, 'Total loss': 0.28035832824606965}
2022-12-31 14:55:06,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:06,046 INFO:     Epoch: 46
2022-12-31 14:55:07,640 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38634359339873, 'Total loss': 0.38634359339873} | train loss {'Reaction outcome loss': 0.2802648582108264, 'Total loss': 0.2802648582108264}
2022-12-31 14:55:07,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:07,640 INFO:     Epoch: 47
2022-12-31 14:55:09,224 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.36536215295394264, 'Total loss': 0.36536215295394264} | train loss {'Reaction outcome loss': 0.27601617321807104, 'Total loss': 0.27601617321807104}
2022-12-31 14:55:09,224 INFO:     Found new best model at epoch 47
2022-12-31 14:55:09,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:09,225 INFO:     Epoch: 48
2022-12-31 14:55:10,820 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39221111734708153, 'Total loss': 0.39221111734708153} | train loss {'Reaction outcome loss': 0.2706572453008734, 'Total loss': 0.2706572453008734}
2022-12-31 14:55:10,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:10,820 INFO:     Epoch: 49
2022-12-31 14:55:12,415 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3870588819185893, 'Total loss': 0.3870588819185893} | train loss {'Reaction outcome loss': 0.26932898698116303, 'Total loss': 0.26932898698116303}
2022-12-31 14:55:12,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:12,416 INFO:     Epoch: 50
2022-12-31 14:55:14,030 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3952759444713593, 'Total loss': 0.3952759444713593} | train loss {'Reaction outcome loss': 0.2688971508403111, 'Total loss': 0.2688971508403111}
2022-12-31 14:55:14,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:14,030 INFO:     Epoch: 51
2022-12-31 14:55:15,627 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3819475253423055, 'Total loss': 0.3819475253423055} | train loss {'Reaction outcome loss': 0.26274092470968724, 'Total loss': 0.26274092470968724}
2022-12-31 14:55:15,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:15,627 INFO:     Epoch: 52
2022-12-31 14:55:17,215 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36528030037879944, 'Total loss': 0.36528030037879944} | train loss {'Reaction outcome loss': 0.26859502282238357, 'Total loss': 0.26859502282238357}
2022-12-31 14:55:17,215 INFO:     Found new best model at epoch 52
2022-12-31 14:55:17,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:17,216 INFO:     Epoch: 53
2022-12-31 14:55:18,810 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3585817108551661, 'Total loss': 0.3585817108551661} | train loss {'Reaction outcome loss': 0.25592385009475, 'Total loss': 0.25592385009475}
2022-12-31 14:55:18,810 INFO:     Found new best model at epoch 53
2022-12-31 14:55:18,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:18,811 INFO:     Epoch: 54
2022-12-31 14:55:20,407 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39225419486562413, 'Total loss': 0.39225419486562413} | train loss {'Reaction outcome loss': 0.2561186815129362, 'Total loss': 0.2561186815129362}
2022-12-31 14:55:20,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:20,407 INFO:     Epoch: 55
2022-12-31 14:55:21,990 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3995136072238286, 'Total loss': 0.3995136072238286} | train loss {'Reaction outcome loss': 0.2599365531677639, 'Total loss': 0.2599365531677639}
2022-12-31 14:55:21,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:21,990 INFO:     Epoch: 56
2022-12-31 14:55:23,586 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38674380083878834, 'Total loss': 0.38674380083878834} | train loss {'Reaction outcome loss': 0.255674615101277, 'Total loss': 0.255674615101277}
2022-12-31 14:55:23,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:23,587 INFO:     Epoch: 57
2022-12-31 14:55:25,181 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.35702044864495597, 'Total loss': 0.35702044864495597} | train loss {'Reaction outcome loss': 0.2489554689394949, 'Total loss': 0.2489554689394949}
2022-12-31 14:55:25,181 INFO:     Found new best model at epoch 57
2022-12-31 14:55:25,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:25,182 INFO:     Epoch: 58
2022-12-31 14:55:26,762 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3838773161172867, 'Total loss': 0.3838773161172867} | train loss {'Reaction outcome loss': 0.25149332808779323, 'Total loss': 0.25149332808779323}
2022-12-31 14:55:26,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:26,762 INFO:     Epoch: 59
2022-12-31 14:55:28,360 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3837148482600848, 'Total loss': 0.3837148482600848} | train loss {'Reaction outcome loss': 0.2529070231669249, 'Total loss': 0.2529070231669249}
2022-12-31 14:55:28,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:28,360 INFO:     Epoch: 60
2022-12-31 14:55:29,956 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.35473744869232177, 'Total loss': 0.35473744869232177} | train loss {'Reaction outcome loss': 0.2458473806792911, 'Total loss': 0.2458473806792911}
2022-12-31 14:55:29,957 INFO:     Found new best model at epoch 60
2022-12-31 14:55:29,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:29,958 INFO:     Epoch: 61
2022-12-31 14:55:31,546 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4049066344896952, 'Total loss': 0.4049066344896952} | train loss {'Reaction outcome loss': 0.24346267277660377, 'Total loss': 0.24346267277660377}
2022-12-31 14:55:31,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:31,546 INFO:     Epoch: 62
2022-12-31 14:55:33,140 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3725550822913647, 'Total loss': 0.3725550822913647} | train loss {'Reaction outcome loss': 0.25079172648435094, 'Total loss': 0.25079172648435094}
2022-12-31 14:55:33,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:33,141 INFO:     Epoch: 63
2022-12-31 14:55:34,723 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39483158687750497, 'Total loss': 0.39483158687750497} | train loss {'Reaction outcome loss': 0.24023881672888342, 'Total loss': 0.24023881672888342}
2022-12-31 14:55:34,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:34,723 INFO:     Epoch: 64
2022-12-31 14:55:36,330 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3918949564297994, 'Total loss': 0.3918949564297994} | train loss {'Reaction outcome loss': 0.24112808023219126, 'Total loss': 0.24112808023219126}
2022-12-31 14:55:36,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:36,330 INFO:     Epoch: 65
2022-12-31 14:55:37,958 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3974402735630671, 'Total loss': 0.3974402735630671} | train loss {'Reaction outcome loss': 0.2488127367938087, 'Total loss': 0.2488127367938087}
2022-12-31 14:55:37,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:37,958 INFO:     Epoch: 66
2022-12-31 14:55:39,575 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3783659457539519, 'Total loss': 0.3783659457539519} | train loss {'Reaction outcome loss': 0.23635407891396407, 'Total loss': 0.23635407891396407}
2022-12-31 14:55:39,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:39,575 INFO:     Epoch: 67
2022-12-31 14:55:41,160 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36390073373913767, 'Total loss': 0.36390073373913767} | train loss {'Reaction outcome loss': 0.22838886930559674, 'Total loss': 0.22838886930559674}
2022-12-31 14:55:41,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:41,161 INFO:     Epoch: 68
2022-12-31 14:55:42,753 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37873651484648385, 'Total loss': 0.37873651484648385} | train loss {'Reaction outcome loss': 0.2369225107024621, 'Total loss': 0.2369225107024621}
2022-12-31 14:55:42,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:42,754 INFO:     Epoch: 69
2022-12-31 14:55:44,335 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39500097185373306, 'Total loss': 0.39500097185373306} | train loss {'Reaction outcome loss': 0.23630512441868765, 'Total loss': 0.23630512441868765}
2022-12-31 14:55:44,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:44,336 INFO:     Epoch: 70
2022-12-31 14:55:45,930 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39560745656490326, 'Total loss': 0.39560745656490326} | train loss {'Reaction outcome loss': 0.2412732137217574, 'Total loss': 0.2412732137217574}
2022-12-31 14:55:45,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:45,931 INFO:     Epoch: 71
2022-12-31 14:55:47,523 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3652897268533707, 'Total loss': 0.3652897268533707} | train loss {'Reaction outcome loss': 0.2258862929459471, 'Total loss': 0.2258862929459471}
2022-12-31 14:55:47,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:47,523 INFO:     Epoch: 72
2022-12-31 14:55:49,104 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4079679220914841, 'Total loss': 0.4079679220914841} | train loss {'Reaction outcome loss': 0.23069709757968349, 'Total loss': 0.23069709757968349}
2022-12-31 14:55:49,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:49,104 INFO:     Epoch: 73
2022-12-31 14:55:50,714 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39546643793582914, 'Total loss': 0.39546643793582914} | train loss {'Reaction outcome loss': 0.22613490046593396, 'Total loss': 0.22613490046593396}
2022-12-31 14:55:50,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:50,714 INFO:     Epoch: 74
2022-12-31 14:55:52,318 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3837045262257258, 'Total loss': 0.3837045262257258} | train loss {'Reaction outcome loss': 0.2278307095496324, 'Total loss': 0.2278307095496324}
2022-12-31 14:55:52,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:52,319 INFO:     Epoch: 75
2022-12-31 14:55:53,902 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4025393391648928, 'Total loss': 0.4025393391648928} | train loss {'Reaction outcome loss': 0.22161699144210475, 'Total loss': 0.22161699144210475}
2022-12-31 14:55:53,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:53,902 INFO:     Epoch: 76
2022-12-31 14:55:55,505 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42167707284291583, 'Total loss': 0.42167707284291583} | train loss {'Reaction outcome loss': 0.22506439574334744, 'Total loss': 0.22506439574334744}
2022-12-31 14:55:55,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:55,506 INFO:     Epoch: 77
2022-12-31 14:55:57,102 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38916098276774086, 'Total loss': 0.38916098276774086} | train loss {'Reaction outcome loss': 0.21800928265128258, 'Total loss': 0.21800928265128258}
2022-12-31 14:55:57,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:57,102 INFO:     Epoch: 78
2022-12-31 14:55:58,687 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.418477659424146, 'Total loss': 0.418477659424146} | train loss {'Reaction outcome loss': 0.22055799068278042, 'Total loss': 0.22055799068278042}
2022-12-31 14:55:58,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:55:58,687 INFO:     Epoch: 79
2022-12-31 14:56:00,284 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4248323135077953, 'Total loss': 0.4248323135077953} | train loss {'Reaction outcome loss': 0.22040391183478664, 'Total loss': 0.22040391183478664}
2022-12-31 14:56:00,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:00,285 INFO:     Epoch: 80
2022-12-31 14:56:01,863 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3969660480817159, 'Total loss': 0.3969660480817159} | train loss {'Reaction outcome loss': 0.22028593767951005, 'Total loss': 0.22028593767951005}
2022-12-31 14:56:01,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:01,864 INFO:     Epoch: 81
2022-12-31 14:56:03,478 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3630962041517099, 'Total loss': 0.3630962041517099} | train loss {'Reaction outcome loss': 0.21461330201939074, 'Total loss': 0.21461330201939074}
2022-12-31 14:56:03,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:03,479 INFO:     Epoch: 82
2022-12-31 14:56:05,090 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39343604842821756, 'Total loss': 0.39343604842821756} | train loss {'Reaction outcome loss': 0.22277661283113007, 'Total loss': 0.22277661283113007}
2022-12-31 14:56:05,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:05,090 INFO:     Epoch: 83
2022-12-31 14:56:06,694 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37303628822167717, 'Total loss': 0.37303628822167717} | train loss {'Reaction outcome loss': 0.2124667706335113, 'Total loss': 0.2124667706335113}
2022-12-31 14:56:06,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:06,695 INFO:     Epoch: 84
2022-12-31 14:56:08,303 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4036560505628586, 'Total loss': 0.4036560505628586} | train loss {'Reaction outcome loss': 0.21653361854408562, 'Total loss': 0.21653361854408562}
2022-12-31 14:56:08,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:08,303 INFO:     Epoch: 85
2022-12-31 14:56:09,935 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3803134838740031, 'Total loss': 0.3803134838740031} | train loss {'Reaction outcome loss': 0.22058040170801163, 'Total loss': 0.22058040170801163}
2022-12-31 14:56:09,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:09,936 INFO:     Epoch: 86
2022-12-31 14:56:11,536 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3963941896955172, 'Total loss': 0.3963941896955172} | train loss {'Reaction outcome loss': 0.20821481023704375, 'Total loss': 0.20821481023704375}
2022-12-31 14:56:11,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:11,537 INFO:     Epoch: 87
2022-12-31 14:56:13,163 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41111819123228394, 'Total loss': 0.41111819123228394} | train loss {'Reaction outcome loss': 0.20862077876762317, 'Total loss': 0.20862077876762317}
2022-12-31 14:56:13,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:13,163 INFO:     Epoch: 88
2022-12-31 14:56:14,764 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3831955303748449, 'Total loss': 0.3831955303748449} | train loss {'Reaction outcome loss': 0.2117622021286592, 'Total loss': 0.2117622021286592}
2022-12-31 14:56:14,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:14,765 INFO:     Epoch: 89
2022-12-31 14:56:16,357 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3828083823124568, 'Total loss': 0.3828083823124568} | train loss {'Reaction outcome loss': 0.20867642803104036, 'Total loss': 0.20867642803104036}
2022-12-31 14:56:16,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:16,358 INFO:     Epoch: 90
2022-12-31 14:56:17,959 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39656134446461994, 'Total loss': 0.39656134446461994} | train loss {'Reaction outcome loss': 0.21724570580642588, 'Total loss': 0.21724570580642588}
2022-12-31 14:56:17,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:17,960 INFO:     Epoch: 91
2022-12-31 14:56:19,563 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3910888393719991, 'Total loss': 0.3910888393719991} | train loss {'Reaction outcome loss': 0.20867912887330473, 'Total loss': 0.20867912887330473}
2022-12-31 14:56:19,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:19,563 INFO:     Epoch: 92
2022-12-31 14:56:21,148 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3539495334029198, 'Total loss': 0.3539495334029198} | train loss {'Reaction outcome loss': 0.20662461070303065, 'Total loss': 0.20662461070303065}
2022-12-31 14:56:21,148 INFO:     Found new best model at epoch 92
2022-12-31 14:56:21,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:21,149 INFO:     Epoch: 93
2022-12-31 14:56:22,757 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3687213609615962, 'Total loss': 0.3687213609615962} | train loss {'Reaction outcome loss': 0.2045259963462714, 'Total loss': 0.2045259963462714}
2022-12-31 14:56:22,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:22,758 INFO:     Epoch: 94
2022-12-31 14:56:24,387 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.37533853749434154, 'Total loss': 0.37533853749434154} | train loss {'Reaction outcome loss': 0.20479170262242538, 'Total loss': 0.20479170262242538}
2022-12-31 14:56:24,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:24,388 INFO:     Epoch: 95
2022-12-31 14:56:25,996 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.425672976175944, 'Total loss': 0.425672976175944} | train loss {'Reaction outcome loss': 0.21214327435722968, 'Total loss': 0.21214327435722968}
2022-12-31 14:56:25,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:25,996 INFO:     Epoch: 96
2022-12-31 14:56:27,623 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.34825922350088756, 'Total loss': 0.34825922350088756} | train loss {'Reaction outcome loss': 0.21126597008266806, 'Total loss': 0.21126597008266806}
2022-12-31 14:56:27,624 INFO:     Found new best model at epoch 96
2022-12-31 14:56:27,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:27,625 INFO:     Epoch: 97
2022-12-31 14:56:29,229 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3678272987405459, 'Total loss': 0.3678272987405459} | train loss {'Reaction outcome loss': 0.20236434848013804, 'Total loss': 0.20236434848013804}
2022-12-31 14:56:29,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:29,230 INFO:     Epoch: 98
2022-12-31 14:56:30,844 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41218037406603497, 'Total loss': 0.41218037406603497} | train loss {'Reaction outcome loss': 0.19805381808729067, 'Total loss': 0.19805381808729067}
2022-12-31 14:56:30,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:30,846 INFO:     Epoch: 99
2022-12-31 14:56:32,445 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40316572586695354, 'Total loss': 0.40316572586695354} | train loss {'Reaction outcome loss': 0.20237168335240252, 'Total loss': 0.20237168335240252}
2022-12-31 14:56:32,445 INFO:     Best model found after epoch 97 of 100.
2022-12-31 14:56:32,445 INFO:   Done with stage: TRAINING
2022-12-31 14:56:32,446 INFO:   Starting stage: EVALUATION
2022-12-31 14:56:32,579 INFO:   Done with stage: EVALUATION
2022-12-31 14:56:32,580 INFO:   Leaving out SEQ value Fold_1
2022-12-31 14:56:32,592 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 14:56:32,593 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:56:33,238 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:56:33,238 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:56:33,307 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:56:33,307 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:56:33,307 INFO:     No hyperparam tuning for this model
2022-12-31 14:56:33,307 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:56:33,307 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:56:33,308 INFO:     None feature selector for col prot
2022-12-31 14:56:33,308 INFO:     None feature selector for col prot
2022-12-31 14:56:33,308 INFO:     None feature selector for col prot
2022-12-31 14:56:33,308 INFO:     None feature selector for col chem
2022-12-31 14:56:33,309 INFO:     None feature selector for col chem
2022-12-31 14:56:33,309 INFO:     None feature selector for col chem
2022-12-31 14:56:33,309 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:56:33,309 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:56:33,310 INFO:     Number of params in model 223921
2022-12-31 14:56:33,314 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:56:33,314 INFO:   Starting stage: TRAINING
2022-12-31 14:56:33,358 INFO:     Val loss before train {'Reaction outcome loss': 0.9141725023587545, 'Total loss': 0.9141725023587545}
2022-12-31 14:56:33,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:33,358 INFO:     Epoch: 0
2022-12-31 14:56:34,958 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5801102300484975, 'Total loss': 0.5801102300484975} | train loss {'Reaction outcome loss': 0.8105610507530171, 'Total loss': 0.8105610507530171}
2022-12-31 14:56:34,958 INFO:     Found new best model at epoch 0
2022-12-31 14:56:34,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:34,959 INFO:     Epoch: 1
2022-12-31 14:56:36,556 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5250402718782425, 'Total loss': 0.5250402718782425} | train loss {'Reaction outcome loss': 0.6094812293410737, 'Total loss': 0.6094812293410737}
2022-12-31 14:56:36,556 INFO:     Found new best model at epoch 1
2022-12-31 14:56:36,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:36,557 INFO:     Epoch: 2
2022-12-31 14:56:38,136 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4758971035480499, 'Total loss': 0.4758971035480499} | train loss {'Reaction outcome loss': 0.5407774933091887, 'Total loss': 0.5407774933091887}
2022-12-31 14:56:38,137 INFO:     Found new best model at epoch 2
2022-12-31 14:56:38,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:38,138 INFO:     Epoch: 3
2022-12-31 14:56:39,736 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.41336125234762827, 'Total loss': 0.41336125234762827} | train loss {'Reaction outcome loss': 0.5206659129469386, 'Total loss': 0.5206659129469386}
2022-12-31 14:56:39,736 INFO:     Found new best model at epoch 3
2022-12-31 14:56:39,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:39,737 INFO:     Epoch: 4
2022-12-31 14:56:41,335 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43854396641254423, 'Total loss': 0.43854396641254423} | train loss {'Reaction outcome loss': 0.4977594871660729, 'Total loss': 0.4977594871660729}
2022-12-31 14:56:41,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:41,336 INFO:     Epoch: 5
2022-12-31 14:56:42,911 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.39537757337093354, 'Total loss': 0.39537757337093354} | train loss {'Reaction outcome loss': 0.48966174870183615, 'Total loss': 0.48966174870183615}
2022-12-31 14:56:42,911 INFO:     Found new best model at epoch 5
2022-12-31 14:56:42,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:42,912 INFO:     Epoch: 6
2022-12-31 14:56:44,505 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.427445662021637, 'Total loss': 0.427445662021637} | train loss {'Reaction outcome loss': 0.4802057250187947, 'Total loss': 0.4802057250187947}
2022-12-31 14:56:44,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:44,505 INFO:     Epoch: 7
2022-12-31 14:56:46,096 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4355050633351008, 'Total loss': 0.4355050633351008} | train loss {'Reaction outcome loss': 0.46503672047412437, 'Total loss': 0.46503672047412437}
2022-12-31 14:56:46,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:46,096 INFO:     Epoch: 8
2022-12-31 14:56:47,683 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4131924053033193, 'Total loss': 0.4131924053033193} | train loss {'Reaction outcome loss': 0.4621820615761446, 'Total loss': 0.4621820615761446}
2022-12-31 14:56:47,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:47,683 INFO:     Epoch: 9
2022-12-31 14:56:49,311 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40612741708755495, 'Total loss': 0.40612741708755495} | train loss {'Reaction outcome loss': 0.45938423980068377, 'Total loss': 0.45938423980068377}
2022-12-31 14:56:49,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:49,312 INFO:     Epoch: 10
2022-12-31 14:56:50,938 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3802698165178299, 'Total loss': 0.3802698165178299} | train loss {'Reaction outcome loss': 0.45038203764092793, 'Total loss': 0.45038203764092793}
2022-12-31 14:56:50,938 INFO:     Found new best model at epoch 10
2022-12-31 14:56:50,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:50,939 INFO:     Epoch: 11
2022-12-31 14:56:52,544 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3787966916958491, 'Total loss': 0.3787966916958491} | train loss {'Reaction outcome loss': 0.44838604210933924, 'Total loss': 0.44838604210933924}
2022-12-31 14:56:52,545 INFO:     Found new best model at epoch 11
2022-12-31 14:56:52,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:52,546 INFO:     Epoch: 12
2022-12-31 14:56:54,173 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4288003216187159, 'Total loss': 0.4288003216187159} | train loss {'Reaction outcome loss': 0.43779016998442977, 'Total loss': 0.43779016998442977}
2022-12-31 14:56:54,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:54,174 INFO:     Epoch: 13
2022-12-31 14:56:55,764 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4030053635438283, 'Total loss': 0.4030053635438283} | train loss {'Reaction outcome loss': 0.43495733599304715, 'Total loss': 0.43495733599304715}
2022-12-31 14:56:55,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:55,765 INFO:     Epoch: 14
2022-12-31 14:56:57,350 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3958282063404719, 'Total loss': 0.3958282063404719} | train loss {'Reaction outcome loss': 0.4270472853502511, 'Total loss': 0.4270472853502511}
2022-12-31 14:56:57,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:57,350 INFO:     Epoch: 15
2022-12-31 14:56:58,944 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.375493249297142, 'Total loss': 0.375493249297142} | train loss {'Reaction outcome loss': 0.4243546867326939, 'Total loss': 0.4243546867326939}
2022-12-31 14:56:58,944 INFO:     Found new best model at epoch 15
2022-12-31 14:56:58,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:56:58,945 INFO:     Epoch: 16
2022-12-31 14:57:00,534 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41917380889256795, 'Total loss': 0.41917380889256795} | train loss {'Reaction outcome loss': 0.4173985932690975, 'Total loss': 0.4173985932690975}
2022-12-31 14:57:00,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:00,535 INFO:     Epoch: 17
2022-12-31 14:57:02,113 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39584029217561084, 'Total loss': 0.39584029217561084} | train loss {'Reaction outcome loss': 0.4101541994255541, 'Total loss': 0.4101541994255541}
2022-12-31 14:57:02,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:02,114 INFO:     Epoch: 18
2022-12-31 14:57:03,706 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3809841721629103, 'Total loss': 0.3809841721629103} | train loss {'Reaction outcome loss': 0.40648584209737326, 'Total loss': 0.40648584209737326}
2022-12-31 14:57:03,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:03,706 INFO:     Epoch: 19
2022-12-31 14:57:05,296 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39022416770458224, 'Total loss': 0.39022416770458224} | train loss {'Reaction outcome loss': 0.4021070888300082, 'Total loss': 0.4021070888300082}
2022-12-31 14:57:05,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:05,297 INFO:     Epoch: 20
2022-12-31 14:57:06,923 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3899550060431162, 'Total loss': 0.3899550060431162} | train loss {'Reaction outcome loss': 0.39569002856592556, 'Total loss': 0.39569002856592556}
2022-12-31 14:57:06,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:06,924 INFO:     Epoch: 21
2022-12-31 14:57:08,547 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3711833929022153, 'Total loss': 0.3711833929022153} | train loss {'Reaction outcome loss': 0.3918634007374446, 'Total loss': 0.3918634007374446}
2022-12-31 14:57:08,548 INFO:     Found new best model at epoch 21
2022-12-31 14:57:08,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:08,549 INFO:     Epoch: 22
2022-12-31 14:57:10,148 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.36703722725311916, 'Total loss': 0.36703722725311916} | train loss {'Reaction outcome loss': 0.37767575211795695, 'Total loss': 0.37767575211795695}
2022-12-31 14:57:10,148 INFO:     Found new best model at epoch 22
2022-12-31 14:57:10,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:10,149 INFO:     Epoch: 23
2022-12-31 14:57:11,741 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4306757889688015, 'Total loss': 0.4306757889688015} | train loss {'Reaction outcome loss': 0.37751287197346217, 'Total loss': 0.37751287197346217}
2022-12-31 14:57:11,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:11,741 INFO:     Epoch: 24
2022-12-31 14:57:13,334 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3847041815519333, 'Total loss': 0.3847041815519333} | train loss {'Reaction outcome loss': 0.37180224969819353, 'Total loss': 0.37180224969819353}
2022-12-31 14:57:13,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:13,334 INFO:     Epoch: 25
2022-12-31 14:57:14,577 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39817965825398766, 'Total loss': 0.39817965825398766} | train loss {'Reaction outcome loss': 0.36959517412842846, 'Total loss': 0.36959517412842846}
2022-12-31 14:57:14,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:14,577 INFO:     Epoch: 26
2022-12-31 14:57:15,633 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.37928038040796913, 'Total loss': 0.37928038040796913} | train loss {'Reaction outcome loss': 0.3675486725983602, 'Total loss': 0.3675486725983602}
2022-12-31 14:57:15,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:15,634 INFO:     Epoch: 27
2022-12-31 14:57:16,684 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.34918123682339985, 'Total loss': 0.34918123682339985} | train loss {'Reaction outcome loss': 0.3586297726783997, 'Total loss': 0.3586297726783997}
2022-12-31 14:57:16,684 INFO:     Found new best model at epoch 27
2022-12-31 14:57:16,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:16,685 INFO:     Epoch: 28
2022-12-31 14:57:17,751 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38953006466229756, 'Total loss': 0.38953006466229756} | train loss {'Reaction outcome loss': 0.35353621974205357, 'Total loss': 0.35353621974205357}
2022-12-31 14:57:17,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:17,751 INFO:     Epoch: 29
2022-12-31 14:57:18,952 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.37310126721858977, 'Total loss': 0.37310126721858977} | train loss {'Reaction outcome loss': 0.3542250598142872, 'Total loss': 0.3542250598142872}
2022-12-31 14:57:18,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:18,952 INFO:     Epoch: 30
2022-12-31 14:57:20,548 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38832601606845857, 'Total loss': 0.38832601606845857} | train loss {'Reaction outcome loss': 0.3460177611627858, 'Total loss': 0.3460177611627858}
2022-12-31 14:57:20,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:20,549 INFO:     Epoch: 31
2022-12-31 14:57:22,143 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3797102967898051, 'Total loss': 0.3797102967898051} | train loss {'Reaction outcome loss': 0.33509783982384556, 'Total loss': 0.33509783982384556}
2022-12-31 14:57:22,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:22,143 INFO:     Epoch: 32
2022-12-31 14:57:23,738 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.37391932706038156, 'Total loss': 0.37391932706038156} | train loss {'Reaction outcome loss': 0.33629508697745075, 'Total loss': 0.33629508697745075}
2022-12-31 14:57:23,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:23,738 INFO:     Epoch: 33
2022-12-31 14:57:25,323 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.37870853741963706, 'Total loss': 0.37870853741963706} | train loss {'Reaction outcome loss': 0.33263250343474277, 'Total loss': 0.33263250343474277}
2022-12-31 14:57:25,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:25,323 INFO:     Epoch: 34
2022-12-31 14:57:26,936 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3831125279267629, 'Total loss': 0.3831125279267629} | train loss {'Reaction outcome loss': 0.3282310433494739, 'Total loss': 0.3282310433494739}
2022-12-31 14:57:26,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:26,937 INFO:     Epoch: 35
2022-12-31 14:57:28,538 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3693095604578654, 'Total loss': 0.3693095604578654} | train loss {'Reaction outcome loss': 0.31889192226441787, 'Total loss': 0.31889192226441787}
2022-12-31 14:57:28,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:28,538 INFO:     Epoch: 36
2022-12-31 14:57:30,162 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.344522233804067, 'Total loss': 0.344522233804067} | train loss {'Reaction outcome loss': 0.322156622896701, 'Total loss': 0.322156622896701}
2022-12-31 14:57:30,162 INFO:     Found new best model at epoch 36
2022-12-31 14:57:30,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:30,164 INFO:     Epoch: 37
2022-12-31 14:57:31,757 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3717268606026967, 'Total loss': 0.3717268606026967} | train loss {'Reaction outcome loss': 0.31710473562662417, 'Total loss': 0.31710473562662417}
2022-12-31 14:57:31,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:31,758 INFO:     Epoch: 38
2022-12-31 14:57:33,347 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3650469034910202, 'Total loss': 0.3650469034910202} | train loss {'Reaction outcome loss': 0.3077149373571296, 'Total loss': 0.3077149373571296}
2022-12-31 14:57:33,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:33,347 INFO:     Epoch: 39
2022-12-31 14:57:34,926 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3441940814256668, 'Total loss': 0.3441940814256668} | train loss {'Reaction outcome loss': 0.3152513237663241, 'Total loss': 0.3152513237663241}
2022-12-31 14:57:34,926 INFO:     Found new best model at epoch 39
2022-12-31 14:57:34,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:34,927 INFO:     Epoch: 40
2022-12-31 14:57:36,517 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.36396357119083406, 'Total loss': 0.36396357119083406} | train loss {'Reaction outcome loss': 0.3053862262285236, 'Total loss': 0.3053862262285236}
2022-12-31 14:57:36,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:36,518 INFO:     Epoch: 41
2022-12-31 14:57:38,106 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3400317629178365, 'Total loss': 0.3400317629178365} | train loss {'Reaction outcome loss': 0.3103354920397748, 'Total loss': 0.3103354920397748}
2022-12-31 14:57:38,106 INFO:     Found new best model at epoch 41
2022-12-31 14:57:38,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:38,107 INFO:     Epoch: 42
2022-12-31 14:57:39,702 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3947245806455612, 'Total loss': 0.3947245806455612} | train loss {'Reaction outcome loss': 0.30266168074948446, 'Total loss': 0.30266168074948446}
2022-12-31 14:57:39,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:39,703 INFO:     Epoch: 43
2022-12-31 14:57:41,315 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.350550165772438, 'Total loss': 0.350550165772438} | train loss {'Reaction outcome loss': 0.29360109392976586, 'Total loss': 0.29360109392976586}
2022-12-31 14:57:41,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:41,315 INFO:     Epoch: 44
2022-12-31 14:57:42,941 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.32672701676686605, 'Total loss': 0.32672701676686605} | train loss {'Reaction outcome loss': 0.2920342849315086, 'Total loss': 0.2920342849315086}
2022-12-31 14:57:42,942 INFO:     Found new best model at epoch 44
2022-12-31 14:57:42,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:42,943 INFO:     Epoch: 45
2022-12-31 14:57:44,531 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3665534635384878, 'Total loss': 0.3665534635384878} | train loss {'Reaction outcome loss': 0.297901125454204, 'Total loss': 0.297901125454204}
2022-12-31 14:57:44,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:44,531 INFO:     Epoch: 46
2022-12-31 14:57:46,110 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3355952223141988, 'Total loss': 0.3355952223141988} | train loss {'Reaction outcome loss': 0.28689381878672937, 'Total loss': 0.28689381878672937}
2022-12-31 14:57:46,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:46,110 INFO:     Epoch: 47
2022-12-31 14:57:47,707 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.344421191016833, 'Total loss': 0.344421191016833} | train loss {'Reaction outcome loss': 0.28670283903678256, 'Total loss': 0.28670283903678256}
2022-12-31 14:57:47,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:47,707 INFO:     Epoch: 48
2022-12-31 14:57:49,320 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3543005049228668, 'Total loss': 0.3543005049228668} | train loss {'Reaction outcome loss': 0.28156822000121895, 'Total loss': 0.28156822000121895}
2022-12-31 14:57:49,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:49,320 INFO:     Epoch: 49
2022-12-31 14:57:50,921 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.33634093794971703, 'Total loss': 0.33634093794971703} | train loss {'Reaction outcome loss': 0.2752929142379499, 'Total loss': 0.2752929142379499}
2022-12-31 14:57:50,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:50,922 INFO:     Epoch: 50
2022-12-31 14:57:52,509 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.35541826436916985, 'Total loss': 0.35541826436916985} | train loss {'Reaction outcome loss': 0.27870338564336083, 'Total loss': 0.27870338564336083}
2022-12-31 14:57:52,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:52,510 INFO:     Epoch: 51
2022-12-31 14:57:54,123 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3604856576770544, 'Total loss': 0.3604856576770544} | train loss {'Reaction outcome loss': 0.27711817641288805, 'Total loss': 0.27711817641288805}
2022-12-31 14:57:54,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:54,123 INFO:     Epoch: 52
2022-12-31 14:57:55,732 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36329016586144763, 'Total loss': 0.36329016586144763} | train loss {'Reaction outcome loss': 0.27621654735966805, 'Total loss': 0.27621654735966805}
2022-12-31 14:57:55,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:55,732 INFO:     Epoch: 53
2022-12-31 14:57:57,330 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3397375404834747, 'Total loss': 0.3397375404834747} | train loss {'Reaction outcome loss': 0.27109222043810527, 'Total loss': 0.27109222043810527}
2022-12-31 14:57:57,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:57,330 INFO:     Epoch: 54
2022-12-31 14:57:58,925 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.33749522638196744, 'Total loss': 0.33749522638196744} | train loss {'Reaction outcome loss': 0.2664348089405687, 'Total loss': 0.2664348089405687}
2022-12-31 14:57:58,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:57:58,925 INFO:     Epoch: 55
2022-12-31 14:58:00,521 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3665847818056742, 'Total loss': 0.3665847818056742} | train loss {'Reaction outcome loss': 0.26440527674916026, 'Total loss': 0.26440527674916026}
2022-12-31 14:58:00,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:00,521 INFO:     Epoch: 56
2022-12-31 14:58:02,102 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.35569588641325633, 'Total loss': 0.35569588641325633} | train loss {'Reaction outcome loss': 0.2645285095637425, 'Total loss': 0.2645285095637425}
2022-12-31 14:58:02,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:02,102 INFO:     Epoch: 57
2022-12-31 14:58:03,698 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3693681627511978, 'Total loss': 0.3693681627511978} | train loss {'Reaction outcome loss': 0.26473518158053305, 'Total loss': 0.26473518158053305}
2022-12-31 14:58:03,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:03,698 INFO:     Epoch: 58
2022-12-31 14:58:05,314 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.36359787384668985, 'Total loss': 0.36359787384668985} | train loss {'Reaction outcome loss': 0.26692400839957564, 'Total loss': 0.26692400839957564}
2022-12-31 14:58:05,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:05,314 INFO:     Epoch: 59
2022-12-31 14:58:06,949 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3546406447887421, 'Total loss': 0.3546406447887421} | train loss {'Reaction outcome loss': 0.260949072602031, 'Total loss': 0.260949072602031}
2022-12-31 14:58:06,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:06,949 INFO:     Epoch: 60
2022-12-31 14:58:08,585 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36692501107851666, 'Total loss': 0.36692501107851666} | train loss {'Reaction outcome loss': 0.26043281239549537, 'Total loss': 0.26043281239549537}
2022-12-31 14:58:08,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:08,585 INFO:     Epoch: 61
2022-12-31 14:58:10,212 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3414199650287628, 'Total loss': 0.3414199650287628} | train loss {'Reaction outcome loss': 0.2521745577904877, 'Total loss': 0.2521745577904877}
2022-12-31 14:58:10,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:10,212 INFO:     Epoch: 62
2022-12-31 14:58:11,817 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3714040194948514, 'Total loss': 0.3714040194948514} | train loss {'Reaction outcome loss': 0.24850249260445653, 'Total loss': 0.24850249260445653}
2022-12-31 14:58:11,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:11,818 INFO:     Epoch: 63
2022-12-31 14:58:13,424 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.372072164217631, 'Total loss': 0.372072164217631} | train loss {'Reaction outcome loss': 0.2520201125560881, 'Total loss': 0.2520201125560881}
2022-12-31 14:58:13,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:13,425 INFO:     Epoch: 64
2022-12-31 14:58:15,063 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3502314070860545, 'Total loss': 0.3502314070860545} | train loss {'Reaction outcome loss': 0.25255905084939667, 'Total loss': 0.25255905084939667}
2022-12-31 14:58:15,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:15,063 INFO:     Epoch: 65
2022-12-31 14:58:16,691 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38863972226778665, 'Total loss': 0.38863972226778665} | train loss {'Reaction outcome loss': 0.2477379827572531, 'Total loss': 0.2477379827572531}
2022-12-31 14:58:16,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:16,691 INFO:     Epoch: 66
2022-12-31 14:58:18,324 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3561924954255422, 'Total loss': 0.3561924954255422} | train loss {'Reaction outcome loss': 0.254168970926559, 'Total loss': 0.254168970926559}
2022-12-31 14:58:18,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:18,324 INFO:     Epoch: 67
2022-12-31 14:58:19,909 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38016190032164254, 'Total loss': 0.38016190032164254} | train loss {'Reaction outcome loss': 0.24686118844135804, 'Total loss': 0.24686118844135804}
2022-12-31 14:58:19,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:19,910 INFO:     Epoch: 68
2022-12-31 14:58:21,514 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3647333860397339, 'Total loss': 0.3647333860397339} | train loss {'Reaction outcome loss': 0.2388476882771258, 'Total loss': 0.2388476882771258}
2022-12-31 14:58:21,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:21,514 INFO:     Epoch: 69
2022-12-31 14:58:23,096 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3471314509709676, 'Total loss': 0.3471314509709676} | train loss {'Reaction outcome loss': 0.24771051566652108, 'Total loss': 0.24771051566652108}
2022-12-31 14:58:23,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:23,096 INFO:     Epoch: 70
2022-12-31 14:58:24,693 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.36171296338240305, 'Total loss': 0.36171296338240305} | train loss {'Reaction outcome loss': 0.2399639961456423, 'Total loss': 0.2399639961456423}
2022-12-31 14:58:24,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:24,693 INFO:     Epoch: 71
2022-12-31 14:58:26,291 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3537009358406067, 'Total loss': 0.3537009358406067} | train loss {'Reaction outcome loss': 0.23978067677972953, 'Total loss': 0.23978067677972953}
2022-12-31 14:58:26,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:26,291 INFO:     Epoch: 72
2022-12-31 14:58:27,921 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.34800013502438865, 'Total loss': 0.34800013502438865} | train loss {'Reaction outcome loss': 0.23437364464932745, 'Total loss': 0.23437364464932745}
2022-12-31 14:58:27,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:27,922 INFO:     Epoch: 73
2022-12-31 14:58:29,535 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3451239784558614, 'Total loss': 0.3451239784558614} | train loss {'Reaction outcome loss': 0.24365355562241303, 'Total loss': 0.24365355562241303}
2022-12-31 14:58:29,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:29,536 INFO:     Epoch: 74
2022-12-31 14:58:31,150 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3381099298596382, 'Total loss': 0.3381099298596382} | train loss {'Reaction outcome loss': 0.23732861570140598, 'Total loss': 0.23732861570140598}
2022-12-31 14:58:31,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:31,150 INFO:     Epoch: 75
2022-12-31 14:58:32,739 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4033602048953374, 'Total loss': 0.4033602048953374} | train loss {'Reaction outcome loss': 0.23065999722033192, 'Total loss': 0.23065999722033192}
2022-12-31 14:58:32,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:32,740 INFO:     Epoch: 76
2022-12-31 14:58:34,333 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3520549158255259, 'Total loss': 0.3520549158255259} | train loss {'Reaction outcome loss': 0.23719473551590364, 'Total loss': 0.23719473551590364}
2022-12-31 14:58:34,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:34,334 INFO:     Epoch: 77
2022-12-31 14:58:35,927 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3631284962097804, 'Total loss': 0.3631284962097804} | train loss {'Reaction outcome loss': 0.23664906345335118, 'Total loss': 0.23664906345335118}
2022-12-31 14:58:35,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:35,927 INFO:     Epoch: 78
2022-12-31 14:58:37,547 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3660597244898478, 'Total loss': 0.3660597244898478} | train loss {'Reaction outcome loss': 0.2354150026381671, 'Total loss': 0.2354150026381671}
2022-12-31 14:58:37,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:37,547 INFO:     Epoch: 79
2022-12-31 14:58:39,136 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.31812764604886373, 'Total loss': 0.31812764604886373} | train loss {'Reaction outcome loss': 0.22780916633104886, 'Total loss': 0.22780916633104886}
2022-12-31 14:58:39,136 INFO:     Found new best model at epoch 79
2022-12-31 14:58:39,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:39,137 INFO:     Epoch: 80
2022-12-31 14:58:40,721 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.39823203484217323, 'Total loss': 0.39823203484217323} | train loss {'Reaction outcome loss': 0.2236752363583653, 'Total loss': 0.2236752363583653}
2022-12-31 14:58:40,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:40,721 INFO:     Epoch: 81
2022-12-31 14:58:42,317 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4029980937639872, 'Total loss': 0.4029980937639872} | train loss {'Reaction outcome loss': 0.2246745685968316, 'Total loss': 0.2246745685968316}
2022-12-31 14:58:42,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:42,317 INFO:     Epoch: 82
2022-12-31 14:58:43,911 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3560598482688268, 'Total loss': 0.3560598482688268} | train loss {'Reaction outcome loss': 0.2297267915046477, 'Total loss': 0.2297267915046477}
2022-12-31 14:58:43,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:43,912 INFO:     Epoch: 83
2022-12-31 14:58:45,506 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.34729039669036865, 'Total loss': 0.34729039669036865} | train loss {'Reaction outcome loss': 0.23164079773611637, 'Total loss': 0.23164079773611637}
2022-12-31 14:58:45,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:45,506 INFO:     Epoch: 84
2022-12-31 14:58:47,105 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3547161415219307, 'Total loss': 0.3547161415219307} | train loss {'Reaction outcome loss': 0.2268252772289318, 'Total loss': 0.2268252772289318}
2022-12-31 14:58:47,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:47,105 INFO:     Epoch: 85
2022-12-31 14:58:48,709 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.33174044663707414, 'Total loss': 0.33174044663707414} | train loss {'Reaction outcome loss': 0.2233699032006574, 'Total loss': 0.2233699032006574}
2022-12-31 14:58:48,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:48,710 INFO:     Epoch: 86
2022-12-31 14:58:50,296 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.30256983687480293, 'Total loss': 0.30256983687480293} | train loss {'Reaction outcome loss': 0.2204477423256188, 'Total loss': 0.2204477423256188}
2022-12-31 14:58:50,296 INFO:     Found new best model at epoch 86
2022-12-31 14:58:50,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:50,297 INFO:     Epoch: 87
2022-12-31 14:58:51,896 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3443414385120074, 'Total loss': 0.3443414385120074} | train loss {'Reaction outcome loss': 0.22049793736129017, 'Total loss': 0.22049793736129017}
2022-12-31 14:58:51,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:51,896 INFO:     Epoch: 88
2022-12-31 14:58:53,496 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3596753110488256, 'Total loss': 0.3596753110488256} | train loss {'Reaction outcome loss': 0.22140123348533017, 'Total loss': 0.22140123348533017}
2022-12-31 14:58:53,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:53,496 INFO:     Epoch: 89
2022-12-31 14:58:55,094 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3607611174384753, 'Total loss': 0.3607611174384753} | train loss {'Reaction outcome loss': 0.21864878814735692, 'Total loss': 0.21864878814735692}
2022-12-31 14:58:55,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:55,095 INFO:     Epoch: 90
2022-12-31 14:58:56,679 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38851638535658517, 'Total loss': 0.38851638535658517} | train loss {'Reaction outcome loss': 0.2184927650341839, 'Total loss': 0.2184927650341839}
2022-12-31 14:58:56,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:56,680 INFO:     Epoch: 91
2022-12-31 14:58:58,309 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3265345881382624, 'Total loss': 0.3265345881382624} | train loss {'Reaction outcome loss': 0.21672322674767003, 'Total loss': 0.21672322674767003}
2022-12-31 14:58:58,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:58,309 INFO:     Epoch: 92
2022-12-31 14:58:59,915 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.33710632969935733, 'Total loss': 0.33710632969935733} | train loss {'Reaction outcome loss': 0.22023712373901527, 'Total loss': 0.22023712373901527}
2022-12-31 14:58:59,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:58:59,915 INFO:     Epoch: 93
2022-12-31 14:59:01,542 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.34333435595035555, 'Total loss': 0.34333435595035555} | train loss {'Reaction outcome loss': 0.21408250948393737, 'Total loss': 0.21408250948393737}
2022-12-31 14:59:01,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:01,543 INFO:     Epoch: 94
2022-12-31 14:59:03,150 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3315535085275769, 'Total loss': 0.3315535085275769} | train loss {'Reaction outcome loss': 0.21486709404381968, 'Total loss': 0.21486709404381968}
2022-12-31 14:59:03,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:03,151 INFO:     Epoch: 95
2022-12-31 14:59:04,757 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3603314364949862, 'Total loss': 0.3603314364949862} | train loss {'Reaction outcome loss': 0.20942021073302725, 'Total loss': 0.20942021073302725}
2022-12-31 14:59:04,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:04,758 INFO:     Epoch: 96
2022-12-31 14:59:06,355 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.32524740397930146, 'Total loss': 0.32524740397930146} | train loss {'Reaction outcome loss': 0.2113527385893213, 'Total loss': 0.2113527385893213}
2022-12-31 14:59:06,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:06,356 INFO:     Epoch: 97
2022-12-31 14:59:07,959 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3583467264970144, 'Total loss': 0.3583467264970144} | train loss {'Reaction outcome loss': 0.21105056639672035, 'Total loss': 0.21105056639672035}
2022-12-31 14:59:07,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:07,960 INFO:     Epoch: 98
2022-12-31 14:59:09,555 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.33925993045171104, 'Total loss': 0.33925993045171104} | train loss {'Reaction outcome loss': 0.21069972157723957, 'Total loss': 0.21069972157723957}
2022-12-31 14:59:09,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:09,555 INFO:     Epoch: 99
2022-12-31 14:59:11,183 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3912502388159434, 'Total loss': 0.3912502388159434} | train loss {'Reaction outcome loss': 0.20370765961706638, 'Total loss': 0.20370765961706638}
2022-12-31 14:59:11,184 INFO:     Best model found after epoch 87 of 100.
2022-12-31 14:59:11,184 INFO:   Done with stage: TRAINING
2022-12-31 14:59:11,184 INFO:   Starting stage: EVALUATION
2022-12-31 14:59:11,325 INFO:   Done with stage: EVALUATION
2022-12-31 14:59:11,325 INFO:   Leaving out SEQ value Fold_2
2022-12-31 14:59:11,338 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2022-12-31 14:59:11,338 INFO:   Starting stage: FEATURE SCALING
2022-12-31 14:59:11,975 INFO:   Done with stage: FEATURE SCALING
2022-12-31 14:59:11,975 INFO:   Starting stage: SCALING TARGETS
2022-12-31 14:59:12,042 INFO:   Done with stage: SCALING TARGETS
2022-12-31 14:59:12,043 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:59:12,043 INFO:     No hyperparam tuning for this model
2022-12-31 14:59:12,043 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 14:59:12,043 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 14:59:12,044 INFO:     None feature selector for col prot
2022-12-31 14:59:12,044 INFO:     None feature selector for col prot
2022-12-31 14:59:12,044 INFO:     None feature selector for col prot
2022-12-31 14:59:12,044 INFO:     None feature selector for col chem
2022-12-31 14:59:12,044 INFO:     None feature selector for col chem
2022-12-31 14:59:12,044 INFO:     None feature selector for col chem
2022-12-31 14:59:12,045 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 14:59:12,045 INFO:   Starting stage: BUILD MODEL
2022-12-31 14:59:12,046 INFO:     Number of params in model 223921
2022-12-31 14:59:12,050 INFO:   Done with stage: BUILD MODEL
2022-12-31 14:59:12,050 INFO:   Starting stage: TRAINING
2022-12-31 14:59:12,093 INFO:     Val loss before train {'Reaction outcome loss': 1.0323768734931946, 'Total loss': 1.0323768734931946}
2022-12-31 14:59:12,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:12,094 INFO:     Epoch: 0
2022-12-31 14:59:13,694 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6317427595456441, 'Total loss': 0.6317427595456441} | train loss {'Reaction outcome loss': 0.8053107469504169, 'Total loss': 0.8053107469504169}
2022-12-31 14:59:13,694 INFO:     Found new best model at epoch 0
2022-12-31 14:59:13,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:13,695 INFO:     Epoch: 1
2022-12-31 14:59:15,279 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5284626205762227, 'Total loss': 0.5284626205762227} | train loss {'Reaction outcome loss': 0.5950039615270396, 'Total loss': 0.5950039615270396}
2022-12-31 14:59:15,279 INFO:     Found new best model at epoch 1
2022-12-31 14:59:15,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:15,280 INFO:     Epoch: 2
2022-12-31 14:59:16,861 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5109271923700969, 'Total loss': 0.5109271923700969} | train loss {'Reaction outcome loss': 0.5226774620943844, 'Total loss': 0.5226774620943844}
2022-12-31 14:59:16,861 INFO:     Found new best model at epoch 2
2022-12-31 14:59:16,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:16,862 INFO:     Epoch: 3
2022-12-31 14:59:18,444 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5383376856644948, 'Total loss': 0.5383376856644948} | train loss {'Reaction outcome loss': 0.5038061033095821, 'Total loss': 0.5038061033095821}
2022-12-31 14:59:18,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:18,444 INFO:     Epoch: 4
2022-12-31 14:59:20,026 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5104086418946584, 'Total loss': 0.5104086418946584} | train loss {'Reaction outcome loss': 0.4881003712376105, 'Total loss': 0.4881003712376105}
2022-12-31 14:59:20,027 INFO:     Found new best model at epoch 4
2022-12-31 14:59:20,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:20,029 INFO:     Epoch: 5
2022-12-31 14:59:21,610 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45988756120204927, 'Total loss': 0.45988756120204927} | train loss {'Reaction outcome loss': 0.47601225081405074, 'Total loss': 0.47601225081405074}
2022-12-31 14:59:21,610 INFO:     Found new best model at epoch 5
2022-12-31 14:59:21,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:21,611 INFO:     Epoch: 6
2022-12-31 14:59:23,177 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49090619484583536, 'Total loss': 0.49090619484583536} | train loss {'Reaction outcome loss': 0.47021271458851016, 'Total loss': 0.47021271458851016}
2022-12-31 14:59:23,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:23,178 INFO:     Epoch: 7
2022-12-31 14:59:24,802 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4685652633508047, 'Total loss': 0.4685652633508047} | train loss {'Reaction outcome loss': 0.4604567414170262, 'Total loss': 0.4604567414170262}
2022-12-31 14:59:24,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:24,802 INFO:     Epoch: 8
2022-12-31 14:59:26,374 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4854978322982788, 'Total loss': 0.4854978322982788} | train loss {'Reaction outcome loss': 0.4511444539216612, 'Total loss': 0.4511444539216612}
2022-12-31 14:59:26,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:26,374 INFO:     Epoch: 9
2022-12-31 14:59:27,953 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4487438003222148, 'Total loss': 0.4487438003222148} | train loss {'Reaction outcome loss': 0.4445996079937558, 'Total loss': 0.4445996079937558}
2022-12-31 14:59:27,953 INFO:     Found new best model at epoch 9
2022-12-31 14:59:27,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:27,954 INFO:     Epoch: 10
2022-12-31 14:59:29,534 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4365195651849111, 'Total loss': 0.4365195651849111} | train loss {'Reaction outcome loss': 0.4397142972398508, 'Total loss': 0.4397142972398508}
2022-12-31 14:59:29,534 INFO:     Found new best model at epoch 10
2022-12-31 14:59:29,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:29,535 INFO:     Epoch: 11
2022-12-31 14:59:31,113 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43567941362659135, 'Total loss': 0.43567941362659135} | train loss {'Reaction outcome loss': 0.43136122737533494, 'Total loss': 0.43136122737533494}
2022-12-31 14:59:31,113 INFO:     Found new best model at epoch 11
2022-12-31 14:59:31,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:31,114 INFO:     Epoch: 12
2022-12-31 14:59:32,675 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45047797660032907, 'Total loss': 0.45047797660032907} | train loss {'Reaction outcome loss': 0.42788362153891707, 'Total loss': 0.42788362153891707}
2022-12-31 14:59:32,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:32,676 INFO:     Epoch: 13
2022-12-31 14:59:34,255 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42903159658114115, 'Total loss': 0.42903159658114115} | train loss {'Reaction outcome loss': 0.42544461187401383, 'Total loss': 0.42544461187401383}
2022-12-31 14:59:34,255 INFO:     Found new best model at epoch 13
2022-12-31 14:59:34,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:34,256 INFO:     Epoch: 14
2022-12-31 14:59:35,828 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46664462486902875, 'Total loss': 0.46664462486902875} | train loss {'Reaction outcome loss': 0.4139328882703042, 'Total loss': 0.4139328882703042}
2022-12-31 14:59:35,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:35,828 INFO:     Epoch: 15
2022-12-31 14:59:37,440 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45559892654418943, 'Total loss': 0.45559892654418943} | train loss {'Reaction outcome loss': 0.41429528728732323, 'Total loss': 0.41429528728732323}
2022-12-31 14:59:37,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:37,441 INFO:     Epoch: 16
2022-12-31 14:59:39,031 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4571143170197805, 'Total loss': 0.4571143170197805} | train loss {'Reaction outcome loss': 0.4073558534973222, 'Total loss': 0.4073558534973222}
2022-12-31 14:59:39,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:39,032 INFO:     Epoch: 17
2022-12-31 14:59:40,619 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43377900222937266, 'Total loss': 0.43377900222937266} | train loss {'Reaction outcome loss': 0.39618248143319273, 'Total loss': 0.39618248143319273}
2022-12-31 14:59:40,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:40,619 INFO:     Epoch: 18
2022-12-31 14:59:42,183 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4113406370083491, 'Total loss': 0.4113406370083491} | train loss {'Reaction outcome loss': 0.39991335375612513, 'Total loss': 0.39991335375612513}
2022-12-31 14:59:42,183 INFO:     Found new best model at epoch 18
2022-12-31 14:59:42,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:42,184 INFO:     Epoch: 19
2022-12-31 14:59:43,756 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43080228368441265, 'Total loss': 0.43080228368441265} | train loss {'Reaction outcome loss': 0.3900905508286839, 'Total loss': 0.3900905508286839}
2022-12-31 14:59:43,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:43,756 INFO:     Epoch: 20
2022-12-31 14:59:45,366 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42512240409851076, 'Total loss': 0.42512240409851076} | train loss {'Reaction outcome loss': 0.38279611367141186, 'Total loss': 0.38279611367141186}
2022-12-31 14:59:45,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:45,366 INFO:     Epoch: 21
2022-12-31 14:59:46,946 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4186374843120575, 'Total loss': 0.4186374843120575} | train loss {'Reaction outcome loss': 0.3739833655007651, 'Total loss': 0.3739833655007651}
2022-12-31 14:59:46,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:46,947 INFO:     Epoch: 22
2022-12-31 14:59:48,542 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4276695430278778, 'Total loss': 0.4276695430278778} | train loss {'Reaction outcome loss': 0.3707246818885592, 'Total loss': 0.3707246818885592}
2022-12-31 14:59:48,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:48,543 INFO:     Epoch: 23
2022-12-31 14:59:50,134 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4243201901515325, 'Total loss': 0.4243201901515325} | train loss {'Reaction outcome loss': 0.3658848589911672, 'Total loss': 0.3658848589911672}
2022-12-31 14:59:50,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:50,134 INFO:     Epoch: 24
2022-12-31 14:59:51,732 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40767985085646313, 'Total loss': 0.40767985085646313} | train loss {'Reaction outcome loss': 0.3609667619985848, 'Total loss': 0.3609667619985848}
2022-12-31 14:59:51,732 INFO:     Found new best model at epoch 24
2022-12-31 14:59:51,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:51,733 INFO:     Epoch: 25
2022-12-31 14:59:53,316 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4190206696589788, 'Total loss': 0.4190206696589788} | train loss {'Reaction outcome loss': 0.3589764865067172, 'Total loss': 0.3589764865067172}
2022-12-31 14:59:53,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:53,316 INFO:     Epoch: 26
2022-12-31 14:59:54,898 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3988834818204244, 'Total loss': 0.3988834818204244} | train loss {'Reaction outcome loss': 0.3510341157112614, 'Total loss': 0.3510341157112614}
2022-12-31 14:59:54,899 INFO:     Found new best model at epoch 26
2022-12-31 14:59:54,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:54,900 INFO:     Epoch: 27
2022-12-31 14:59:56,488 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4484588901201884, 'Total loss': 0.4484588901201884} | train loss {'Reaction outcome loss': 0.3494115815088978, 'Total loss': 0.3494115815088978}
2022-12-31 14:59:56,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:56,488 INFO:     Epoch: 28
2022-12-31 14:59:58,110 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4107581555843353, 'Total loss': 0.4107581555843353} | train loss {'Reaction outcome loss': 0.3505015052387635, 'Total loss': 0.3505015052387635}
2022-12-31 14:59:58,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:58,110 INFO:     Epoch: 29
2022-12-31 14:59:59,695 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4463366409142812, 'Total loss': 0.4463366409142812} | train loss {'Reaction outcome loss': 0.34184903156603397, 'Total loss': 0.34184903156603397}
2022-12-31 14:59:59,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 14:59:59,695 INFO:     Epoch: 30
2022-12-31 15:00:01,301 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40682466228803, 'Total loss': 0.40682466228803} | train loss {'Reaction outcome loss': 0.33733507462973084, 'Total loss': 0.33733507462973084}
2022-12-31 15:00:01,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:01,302 INFO:     Epoch: 31
2022-12-31 15:00:02,871 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43219235638777415, 'Total loss': 0.43219235638777415} | train loss {'Reaction outcome loss': 0.3302504893845958, 'Total loss': 0.3302504893845958}
2022-12-31 15:00:02,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:02,871 INFO:     Epoch: 32
2022-12-31 15:00:04,491 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4284884989261627, 'Total loss': 0.4284884989261627} | train loss {'Reaction outcome loss': 0.3309515517589901, 'Total loss': 0.3309515517589901}
2022-12-31 15:00:04,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:04,491 INFO:     Epoch: 33
2022-12-31 15:00:06,092 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41644342939058937, 'Total loss': 0.41644342939058937} | train loss {'Reaction outcome loss': 0.3226987963672934, 'Total loss': 0.3226987963672934}
2022-12-31 15:00:06,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:06,092 INFO:     Epoch: 34
2022-12-31 15:00:07,677 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4105012873808543, 'Total loss': 0.4105012873808543} | train loss {'Reaction outcome loss': 0.31631406745787477, 'Total loss': 0.31631406745787477}
2022-12-31 15:00:07,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:07,677 INFO:     Epoch: 35
2022-12-31 15:00:09,259 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.397683909535408, 'Total loss': 0.397683909535408} | train loss {'Reaction outcome loss': 0.3151269247721042, 'Total loss': 0.3151269247721042}
2022-12-31 15:00:09,260 INFO:     Found new best model at epoch 35
2022-12-31 15:00:09,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:09,261 INFO:     Epoch: 36
2022-12-31 15:00:10,854 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41223787864049277, 'Total loss': 0.41223787864049277} | train loss {'Reaction outcome loss': 0.309974186768501, 'Total loss': 0.309974186768501}
2022-12-31 15:00:10,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:10,854 INFO:     Epoch: 37
2022-12-31 15:00:12,441 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3792176862557729, 'Total loss': 0.3792176862557729} | train loss {'Reaction outcome loss': 0.3036240782602467, 'Total loss': 0.3036240782602467}
2022-12-31 15:00:12,441 INFO:     Found new best model at epoch 37
2022-12-31 15:00:12,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:12,442 INFO:     Epoch: 38
2022-12-31 15:00:14,026 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3773351311683655, 'Total loss': 0.3773351311683655} | train loss {'Reaction outcome loss': 0.29951510648500873, 'Total loss': 0.29951510648500873}
2022-12-31 15:00:14,027 INFO:     Found new best model at epoch 38
2022-12-31 15:00:14,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:14,028 INFO:     Epoch: 39
2022-12-31 15:00:15,611 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4004623423020045, 'Total loss': 0.4004623423020045} | train loss {'Reaction outcome loss': 0.29394782032144023, 'Total loss': 0.29394782032144023}
2022-12-31 15:00:15,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:15,612 INFO:     Epoch: 40
2022-12-31 15:00:17,199 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39023059209187827, 'Total loss': 0.39023059209187827} | train loss {'Reaction outcome loss': 0.28984826102138006, 'Total loss': 0.28984826102138006}
2022-12-31 15:00:17,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:17,200 INFO:     Epoch: 41
2022-12-31 15:00:18,771 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4126336028178533, 'Total loss': 0.4126336028178533} | train loss {'Reaction outcome loss': 0.2958676296928932, 'Total loss': 0.2958676296928932}
2022-12-31 15:00:18,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:18,771 INFO:     Epoch: 42
2022-12-31 15:00:20,354 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.403402250011762, 'Total loss': 0.403402250011762} | train loss {'Reaction outcome loss': 0.28980746584844763, 'Total loss': 0.28980746584844763}
2022-12-31 15:00:20,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:20,355 INFO:     Epoch: 43
2022-12-31 15:00:21,940 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3722215285524726, 'Total loss': 0.3722215285524726} | train loss {'Reaction outcome loss': 0.27960489848388076, 'Total loss': 0.27960489848388076}
2022-12-31 15:00:21,940 INFO:     Found new best model at epoch 43
2022-12-31 15:00:21,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:21,941 INFO:     Epoch: 44
2022-12-31 15:00:23,524 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4086461871862411, 'Total loss': 0.4086461871862411} | train loss {'Reaction outcome loss': 0.2951947425894192, 'Total loss': 0.2951947425894192}
2022-12-31 15:00:23,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:23,525 INFO:     Epoch: 45
2022-12-31 15:00:25,113 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.391935591896375, 'Total loss': 0.391935591896375} | train loss {'Reaction outcome loss': 0.27378082631423906, 'Total loss': 0.27378082631423906}
2022-12-31 15:00:25,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:25,114 INFO:     Epoch: 46
2022-12-31 15:00:26,684 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40126705865065254, 'Total loss': 0.40126705865065254} | train loss {'Reaction outcome loss': 0.2759816063863545, 'Total loss': 0.2759816063863545}
2022-12-31 15:00:26,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:26,686 INFO:     Epoch: 47
2022-12-31 15:00:28,263 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4193386326233546, 'Total loss': 0.4193386326233546} | train loss {'Reaction outcome loss': 0.2797117969949087, 'Total loss': 0.2797117969949087}
2022-12-31 15:00:28,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:28,264 INFO:     Epoch: 48
2022-12-31 15:00:29,834 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4102166126171748, 'Total loss': 0.4102166126171748} | train loss {'Reaction outcome loss': 0.2716317672516147, 'Total loss': 0.2716317672516147}
2022-12-31 15:00:29,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:29,835 INFO:     Epoch: 49
2022-12-31 15:00:31,440 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3674102639158567, 'Total loss': 0.3674102639158567} | train loss {'Reaction outcome loss': 0.2691659518273554, 'Total loss': 0.2691659518273554}
2022-12-31 15:00:31,440 INFO:     Found new best model at epoch 49
2022-12-31 15:00:31,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:31,441 INFO:     Epoch: 50
2022-12-31 15:00:33,020 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3820377588272095, 'Total loss': 0.3820377588272095} | train loss {'Reaction outcome loss': 0.2637075054634541, 'Total loss': 0.2637075054634541}
2022-12-31 15:00:33,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:33,020 INFO:     Epoch: 51
2022-12-31 15:00:34,597 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4478762924671173, 'Total loss': 0.4478762924671173} | train loss {'Reaction outcome loss': 0.2550760128181359, 'Total loss': 0.2550760128181359}
2022-12-31 15:00:34,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:34,597 INFO:     Epoch: 52
2022-12-31 15:00:36,163 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43541118999322254, 'Total loss': 0.43541118999322254} | train loss {'Reaction outcome loss': 0.2601424657303249, 'Total loss': 0.2601424657303249}
2022-12-31 15:00:36,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:36,164 INFO:     Epoch: 53
2022-12-31 15:00:37,731 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38232999940713247, 'Total loss': 0.38232999940713247} | train loss {'Reaction outcome loss': 0.2576498577433099, 'Total loss': 0.2576498577433099}
2022-12-31 15:00:37,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:37,731 INFO:     Epoch: 54
2022-12-31 15:00:39,315 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39317909677823387, 'Total loss': 0.39317909677823387} | train loss {'Reaction outcome loss': 0.25154697826317757, 'Total loss': 0.25154697826317757}
2022-12-31 15:00:39,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:39,316 INFO:     Epoch: 55
2022-12-31 15:00:40,914 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37431977738936745, 'Total loss': 0.37431977738936745} | train loss {'Reaction outcome loss': 0.2657358424799909, 'Total loss': 0.2657358424799909}
2022-12-31 15:00:40,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:40,914 INFO:     Epoch: 56
2022-12-31 15:00:42,492 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42333668768405913, 'Total loss': 0.42333668768405913} | train loss {'Reaction outcome loss': 0.2545956902590845, 'Total loss': 0.2545956902590845}
2022-12-31 15:00:42,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:42,492 INFO:     Epoch: 57
2022-12-31 15:00:44,072 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3735778917868932, 'Total loss': 0.3735778917868932} | train loss {'Reaction outcome loss': 0.25060569366433305, 'Total loss': 0.25060569366433305}
2022-12-31 15:00:44,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:44,073 INFO:     Epoch: 58
2022-12-31 15:00:45,650 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3913525938987732, 'Total loss': 0.3913525938987732} | train loss {'Reaction outcome loss': 0.2451004261267801, 'Total loss': 0.2451004261267801}
2022-12-31 15:00:45,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:45,651 INFO:     Epoch: 59
2022-12-31 15:00:47,223 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3874480019013087, 'Total loss': 0.3874480019013087} | train loss {'Reaction outcome loss': 0.2522692538220504, 'Total loss': 0.2522692538220504}
2022-12-31 15:00:47,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:47,224 INFO:     Epoch: 60
2022-12-31 15:00:48,808 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4140483170747757, 'Total loss': 0.4140483170747757} | train loss {'Reaction outcome loss': 0.24001263983795124, 'Total loss': 0.24001263983795124}
2022-12-31 15:00:48,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:48,809 INFO:     Epoch: 61
2022-12-31 15:00:50,407 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42135990858078004, 'Total loss': 0.42135990858078004} | train loss {'Reaction outcome loss': 0.24474715059313826, 'Total loss': 0.24474715059313826}
2022-12-31 15:00:50,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:50,407 INFO:     Epoch: 62
2022-12-31 15:00:51,989 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40209602812925976, 'Total loss': 0.40209602812925976} | train loss {'Reaction outcome loss': 0.24308188295342387, 'Total loss': 0.24308188295342387}
2022-12-31 15:00:51,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:51,989 INFO:     Epoch: 63
2022-12-31 15:00:53,578 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39090980490048727, 'Total loss': 0.39090980490048727} | train loss {'Reaction outcome loss': 0.23986681231823354, 'Total loss': 0.23986681231823354}
2022-12-31 15:00:53,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:53,578 INFO:     Epoch: 64
2022-12-31 15:00:55,146 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40012429157892865, 'Total loss': 0.40012429157892865} | train loss {'Reaction outcome loss': 0.234178797022278, 'Total loss': 0.234178797022278}
2022-12-31 15:00:55,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:55,147 INFO:     Epoch: 65
2022-12-31 15:00:56,709 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3623682876427968, 'Total loss': 0.3623682876427968} | train loss {'Reaction outcome loss': 0.23608555333393305, 'Total loss': 0.23608555333393305}
2022-12-31 15:00:56,709 INFO:     Found new best model at epoch 65
2022-12-31 15:00:56,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:56,710 INFO:     Epoch: 66
2022-12-31 15:00:58,286 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3746146364758412, 'Total loss': 0.3746146364758412} | train loss {'Reaction outcome loss': 0.23500114425714386, 'Total loss': 0.23500114425714386}
2022-12-31 15:00:58,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:58,286 INFO:     Epoch: 67
2022-12-31 15:00:59,858 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40599247217178347, 'Total loss': 0.40599247217178347} | train loss {'Reaction outcome loss': 0.23187967991916897, 'Total loss': 0.23187967991916897}
2022-12-31 15:00:59,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:00:59,858 INFO:     Epoch: 68
2022-12-31 15:01:01,436 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37812947332859037, 'Total loss': 0.37812947332859037} | train loss {'Reaction outcome loss': 0.23932771584727008, 'Total loss': 0.23932771584727008}
2022-12-31 15:01:01,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:01,438 INFO:     Epoch: 69
2022-12-31 15:01:03,026 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41194346646467844, 'Total loss': 0.41194346646467844} | train loss {'Reaction outcome loss': 0.22933429810888653, 'Total loss': 0.22933429810888653}
2022-12-31 15:01:03,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:03,026 INFO:     Epoch: 70
2022-12-31 15:01:04,617 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3938470929861069, 'Total loss': 0.3938470929861069} | train loss {'Reaction outcome loss': 0.22175097284749204, 'Total loss': 0.22175097284749204}
2022-12-31 15:01:04,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:04,618 INFO:     Epoch: 71
2022-12-31 15:01:06,185 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40250851549208166, 'Total loss': 0.40250851549208166} | train loss {'Reaction outcome loss': 0.23035919146674147, 'Total loss': 0.23035919146674147}
2022-12-31 15:01:06,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:06,185 INFO:     Epoch: 72
2022-12-31 15:01:07,770 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.381506727465118, 'Total loss': 0.381506727465118} | train loss {'Reaction outcome loss': 0.223958389428049, 'Total loss': 0.223958389428049}
2022-12-31 15:01:07,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:07,771 INFO:     Epoch: 73
2022-12-31 15:01:09,372 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3879016677538554, 'Total loss': 0.3879016677538554} | train loss {'Reaction outcome loss': 0.22559946136913397, 'Total loss': 0.22559946136913397}
2022-12-31 15:01:09,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:09,372 INFO:     Epoch: 74
2022-12-31 15:01:10,978 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3729443778594335, 'Total loss': 0.3729443778594335} | train loss {'Reaction outcome loss': 0.21982231128589694, 'Total loss': 0.21982231128589694}
2022-12-31 15:01:10,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:10,978 INFO:     Epoch: 75
2022-12-31 15:01:12,568 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3792770947019259, 'Total loss': 0.3792770947019259} | train loss {'Reaction outcome loss': 0.2255460219767041, 'Total loss': 0.2255460219767041}
2022-12-31 15:01:12,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:12,569 INFO:     Epoch: 76
2022-12-31 15:01:14,149 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41339304447174074, 'Total loss': 0.41339304447174074} | train loss {'Reaction outcome loss': 0.21724426137056627, 'Total loss': 0.21724426137056627}
2022-12-31 15:01:14,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:14,150 INFO:     Epoch: 77
2022-12-31 15:01:15,728 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3659842607875665, 'Total loss': 0.3659842607875665} | train loss {'Reaction outcome loss': 0.2136224390753301, 'Total loss': 0.2136224390753301}
2022-12-31 15:01:15,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:15,728 INFO:     Epoch: 78
2022-12-31 15:01:17,342 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4180579443772634, 'Total loss': 0.4180579443772634} | train loss {'Reaction outcome loss': 0.21491345910980914, 'Total loss': 0.21491345910980914}
2022-12-31 15:01:17,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:17,342 INFO:     Epoch: 79
2022-12-31 15:01:18,936 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4265506585439046, 'Total loss': 0.4265506585439046} | train loss {'Reaction outcome loss': 0.21248672070923327, 'Total loss': 0.21248672070923327}
2022-12-31 15:01:18,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:18,936 INFO:     Epoch: 80
2022-12-31 15:01:20,559 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41170770625273384, 'Total loss': 0.41170770625273384} | train loss {'Reaction outcome loss': 0.215942522655224, 'Total loss': 0.215942522655224}
2022-12-31 15:01:20,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:20,560 INFO:     Epoch: 81
2022-12-31 15:01:22,125 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3713275174416291, 'Total loss': 0.3713275174416291} | train loss {'Reaction outcome loss': 0.2156442129688949, 'Total loss': 0.2156442129688949}
2022-12-31 15:01:22,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:22,125 INFO:     Epoch: 82
2022-12-31 15:01:23,692 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36878968173017107, 'Total loss': 0.36878968173017107} | train loss {'Reaction outcome loss': 0.21502246197684224, 'Total loss': 0.21502246197684224}
2022-12-31 15:01:23,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:23,692 INFO:     Epoch: 83
2022-12-31 15:01:25,271 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4268452674150467, 'Total loss': 0.4268452674150467} | train loss {'Reaction outcome loss': 0.21554487818556517, 'Total loss': 0.21554487818556517}
2022-12-31 15:01:25,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:25,271 INFO:     Epoch: 84
2022-12-31 15:01:26,851 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46453796525796254, 'Total loss': 0.46453796525796254} | train loss {'Reaction outcome loss': 0.20376695983964138, 'Total loss': 0.20376695983964138}
2022-12-31 15:01:26,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:26,851 INFO:     Epoch: 85
2022-12-31 15:01:28,428 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3451942997674147, 'Total loss': 0.3451942997674147} | train loss {'Reaction outcome loss': 0.20336264462598574, 'Total loss': 0.20336264462598574}
2022-12-31 15:01:28,428 INFO:     Found new best model at epoch 85
2022-12-31 15:01:28,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:28,429 INFO:     Epoch: 86
2022-12-31 15:01:30,000 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4045870194832484, 'Total loss': 0.4045870194832484} | train loss {'Reaction outcome loss': 0.20628576067265988, 'Total loss': 0.20628576067265988}
2022-12-31 15:01:30,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:30,000 INFO:     Epoch: 87
2022-12-31 15:01:31,621 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4028523713350296, 'Total loss': 0.4028523713350296} | train loss {'Reaction outcome loss': 0.20294678772926825, 'Total loss': 0.20294678772926825}
2022-12-31 15:01:31,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:31,621 INFO:     Epoch: 88
2022-12-31 15:01:33,221 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4497334102789561, 'Total loss': 0.4497334102789561} | train loss {'Reaction outcome loss': 0.20094460040000972, 'Total loss': 0.20094460040000972}
2022-12-31 15:01:33,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:33,223 INFO:     Epoch: 89
2022-12-31 15:01:34,840 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42117471992969513, 'Total loss': 0.42117471992969513} | train loss {'Reaction outcome loss': 0.2073446669413045, 'Total loss': 0.2073446669413045}
2022-12-31 15:01:34,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:34,840 INFO:     Epoch: 90
2022-12-31 15:01:36,451 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40619611988464993, 'Total loss': 0.40619611988464993} | train loss {'Reaction outcome loss': 0.20215631596661582, 'Total loss': 0.20215631596661582}
2022-12-31 15:01:36,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:36,452 INFO:     Epoch: 91
2022-12-31 15:01:38,062 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4067639589309692, 'Total loss': 0.4067639589309692} | train loss {'Reaction outcome loss': 0.2014218286002859, 'Total loss': 0.2014218286002859}
2022-12-31 15:01:38,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:38,062 INFO:     Epoch: 92
2022-12-31 15:01:39,642 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4606494814157486, 'Total loss': 0.4606494814157486} | train loss {'Reaction outcome loss': 0.20203736590778257, 'Total loss': 0.20203736590778257}
2022-12-31 15:01:39,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:39,643 INFO:     Epoch: 93
2022-12-31 15:01:41,206 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.465713632106781, 'Total loss': 0.465713632106781} | train loss {'Reaction outcome loss': 0.19812872865996786, 'Total loss': 0.19812872865996786}
2022-12-31 15:01:41,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:41,206 INFO:     Epoch: 94
2022-12-31 15:01:42,810 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4046803702910741, 'Total loss': 0.4046803702910741} | train loss {'Reaction outcome loss': 0.19625163465270917, 'Total loss': 0.19625163465270917}
2022-12-31 15:01:42,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:42,811 INFO:     Epoch: 95
2022-12-31 15:01:44,418 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3679368992646535, 'Total loss': 0.3679368992646535} | train loss {'Reaction outcome loss': 0.1962443641369743, 'Total loss': 0.1962443641369743}
2022-12-31 15:01:44,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:44,418 INFO:     Epoch: 96
2022-12-31 15:01:46,020 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3933502460519473, 'Total loss': 0.3933502460519473} | train loss {'Reaction outcome loss': 0.19616569151132748, 'Total loss': 0.19616569151132748}
2022-12-31 15:01:46,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:46,020 INFO:     Epoch: 97
2022-12-31 15:01:47,620 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4159538000822067, 'Total loss': 0.4159538000822067} | train loss {'Reaction outcome loss': 0.1992847291903907, 'Total loss': 0.1992847291903907}
2022-12-31 15:01:47,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:47,621 INFO:     Epoch: 98
2022-12-31 15:01:49,213 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4085308293501536, 'Total loss': 0.4085308293501536} | train loss {'Reaction outcome loss': 0.19311375640387685, 'Total loss': 0.19311375640387685}
2022-12-31 15:01:49,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:49,213 INFO:     Epoch: 99
2022-12-31 15:01:50,793 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3752488059302171, 'Total loss': 0.3752488059302171} | train loss {'Reaction outcome loss': 0.19454743494571794, 'Total loss': 0.19454743494571794}
2022-12-31 15:01:50,793 INFO:     Best model found after epoch 86 of 100.
2022-12-31 15:01:50,793 INFO:   Done with stage: TRAINING
2022-12-31 15:01:50,793 INFO:   Starting stage: EVALUATION
2022-12-31 15:01:50,938 INFO:   Done with stage: EVALUATION
2022-12-31 15:01:50,938 INFO:   Leaving out SEQ value Fold_3
2022-12-31 15:01:50,951 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 15:01:50,951 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:01:51,599 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:01:51,599 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:01:51,667 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:01:51,668 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:01:51,668 INFO:     No hyperparam tuning for this model
2022-12-31 15:01:51,668 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:01:51,668 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:01:51,669 INFO:     None feature selector for col prot
2022-12-31 15:01:51,669 INFO:     None feature selector for col prot
2022-12-31 15:01:51,669 INFO:     None feature selector for col prot
2022-12-31 15:01:51,669 INFO:     None feature selector for col chem
2022-12-31 15:01:51,669 INFO:     None feature selector for col chem
2022-12-31 15:01:51,670 INFO:     None feature selector for col chem
2022-12-31 15:01:51,670 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:01:51,670 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:01:51,671 INFO:     Number of params in model 223921
2022-12-31 15:01:51,675 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:01:51,675 INFO:   Starting stage: TRAINING
2022-12-31 15:01:51,721 INFO:     Val loss before train {'Reaction outcome loss': 1.0100796381632486, 'Total loss': 1.0100796381632486}
2022-12-31 15:01:51,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:51,721 INFO:     Epoch: 0
2022-12-31 15:01:53,315 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6887730598449707, 'Total loss': 0.6887730598449707} | train loss {'Reaction outcome loss': 0.827593551282465, 'Total loss': 0.827593551282465}
2022-12-31 15:01:53,316 INFO:     Found new best model at epoch 0
2022-12-31 15:01:53,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:53,317 INFO:     Epoch: 1
2022-12-31 15:01:54,910 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5749039093653361, 'Total loss': 0.5749039093653361} | train loss {'Reaction outcome loss': 0.6100403776351553, 'Total loss': 0.6100403776351553}
2022-12-31 15:01:54,910 INFO:     Found new best model at epoch 1
2022-12-31 15:01:54,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:54,911 INFO:     Epoch: 2
2022-12-31 15:01:56,521 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5031720409790675, 'Total loss': 0.5031720409790675} | train loss {'Reaction outcome loss': 0.522555988091622, 'Total loss': 0.522555988091622}
2022-12-31 15:01:56,521 INFO:     Found new best model at epoch 2
2022-12-31 15:01:56,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:56,522 INFO:     Epoch: 3
2022-12-31 15:01:58,120 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.511629785100619, 'Total loss': 0.511629785100619} | train loss {'Reaction outcome loss': 0.5032428706975749, 'Total loss': 0.5032428706975749}
2022-12-31 15:01:58,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:58,120 INFO:     Epoch: 4
2022-12-31 15:01:59,710 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5136153558890025, 'Total loss': 0.5136153558890025} | train loss {'Reaction outcome loss': 0.485581115758332, 'Total loss': 0.485581115758332}
2022-12-31 15:01:59,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:01:59,710 INFO:     Epoch: 5
2022-12-31 15:02:01,346 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5103651811679204, 'Total loss': 0.5103651811679204} | train loss {'Reaction outcome loss': 0.47672896821350946, 'Total loss': 0.47672896821350946}
2022-12-31 15:02:01,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:01,347 INFO:     Epoch: 6
2022-12-31 15:02:02,974 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4966004947821299, 'Total loss': 0.4966004947821299} | train loss {'Reaction outcome loss': 0.4635907278878845, 'Total loss': 0.4635907278878845}
2022-12-31 15:02:02,974 INFO:     Found new best model at epoch 6
2022-12-31 15:02:02,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:02,975 INFO:     Epoch: 7
2022-12-31 15:02:04,612 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48802061279614767, 'Total loss': 0.48802061279614767} | train loss {'Reaction outcome loss': 0.4610394442277233, 'Total loss': 0.4610394442277233}
2022-12-31 15:02:04,612 INFO:     Found new best model at epoch 7
2022-12-31 15:02:04,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:04,613 INFO:     Epoch: 8
2022-12-31 15:02:06,228 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4787538945674896, 'Total loss': 0.4787538945674896} | train loss {'Reaction outcome loss': 0.4465933018465982, 'Total loss': 0.4465933018465982}
2022-12-31 15:02:06,228 INFO:     Found new best model at epoch 8
2022-12-31 15:02:06,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:06,229 INFO:     Epoch: 9
2022-12-31 15:02:07,848 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4827779750029246, 'Total loss': 0.4827779750029246} | train loss {'Reaction outcome loss': 0.44538862500203785, 'Total loss': 0.44538862500203785}
2022-12-31 15:02:07,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:07,849 INFO:     Epoch: 10
2022-12-31 15:02:09,430 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45554734269777936, 'Total loss': 0.45554734269777936} | train loss {'Reaction outcome loss': 0.43378362848158303, 'Total loss': 0.43378362848158303}
2022-12-31 15:02:09,430 INFO:     Found new best model at epoch 10
2022-12-31 15:02:09,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:09,431 INFO:     Epoch: 11
2022-12-31 15:02:11,025 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5298394511143366, 'Total loss': 0.5298394511143366} | train loss {'Reaction outcome loss': 0.4291966731530906, 'Total loss': 0.4291966731530906}
2022-12-31 15:02:11,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:11,025 INFO:     Epoch: 12
2022-12-31 15:02:12,620 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4728587547938029, 'Total loss': 0.4728587547938029} | train loss {'Reaction outcome loss': 0.4228761110210071, 'Total loss': 0.4228761110210071}
2022-12-31 15:02:12,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:12,620 INFO:     Epoch: 13
2022-12-31 15:02:14,214 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.470912625392278, 'Total loss': 0.470912625392278} | train loss {'Reaction outcome loss': 0.4248224245044437, 'Total loss': 0.4248224245044437}
2022-12-31 15:02:14,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:14,215 INFO:     Epoch: 14
2022-12-31 15:02:15,792 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4658871764938037, 'Total loss': 0.4658871764938037} | train loss {'Reaction outcome loss': 0.41422997126831623, 'Total loss': 0.41422997126831623}
2022-12-31 15:02:15,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:15,792 INFO:     Epoch: 15
2022-12-31 15:02:17,374 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4340994228919347, 'Total loss': 0.4340994228919347} | train loss {'Reaction outcome loss': 0.40678323799893806, 'Total loss': 0.40678323799893806}
2022-12-31 15:02:17,375 INFO:     Found new best model at epoch 15
2022-12-31 15:02:17,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:17,376 INFO:     Epoch: 16
2022-12-31 15:02:18,972 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46561046640078224, 'Total loss': 0.46561046640078224} | train loss {'Reaction outcome loss': 0.40567028905897246, 'Total loss': 0.40567028905897246}
2022-12-31 15:02:18,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:18,972 INFO:     Epoch: 17
2022-12-31 15:02:20,570 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4596106300751368, 'Total loss': 0.4596106300751368} | train loss {'Reaction outcome loss': 0.3983331100784079, 'Total loss': 0.3983331100784079}
2022-12-31 15:02:20,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:20,571 INFO:     Epoch: 18
2022-12-31 15:02:22,170 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45406318207581836, 'Total loss': 0.45406318207581836} | train loss {'Reaction outcome loss': 0.39020488403030557, 'Total loss': 0.39020488403030557}
2022-12-31 15:02:22,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:22,170 INFO:     Epoch: 19
2022-12-31 15:02:23,767 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4738241235415141, 'Total loss': 0.4738241235415141} | train loss {'Reaction outcome loss': 0.38674965092953106, 'Total loss': 0.38674965092953106}
2022-12-31 15:02:23,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:23,767 INFO:     Epoch: 20
2022-12-31 15:02:25,380 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4510494222243627, 'Total loss': 0.4510494222243627} | train loss {'Reaction outcome loss': 0.37881845921060464, 'Total loss': 0.37881845921060464}
2022-12-31 15:02:25,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:25,381 INFO:     Epoch: 21
2022-12-31 15:02:26,993 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4404076079527537, 'Total loss': 0.4404076079527537} | train loss {'Reaction outcome loss': 0.37749913117311296, 'Total loss': 0.37749913117311296}
2022-12-31 15:02:26,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:26,994 INFO:     Epoch: 22
2022-12-31 15:02:28,615 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4434245765209198, 'Total loss': 0.4434245765209198} | train loss {'Reaction outcome loss': 0.36702318924621946, 'Total loss': 0.36702318924621946}
2022-12-31 15:02:28,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:28,615 INFO:     Epoch: 23
2022-12-31 15:02:30,218 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4484679003556569, 'Total loss': 0.4484679003556569} | train loss {'Reaction outcome loss': 0.366897654114631, 'Total loss': 0.366897654114631}
2022-12-31 15:02:30,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:30,218 INFO:     Epoch: 24
2022-12-31 15:02:31,815 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4040944740797083, 'Total loss': 0.4040944740797083} | train loss {'Reaction outcome loss': 0.36178944053223533, 'Total loss': 0.36178944053223533}
2022-12-31 15:02:31,815 INFO:     Found new best model at epoch 24
2022-12-31 15:02:31,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:31,816 INFO:     Epoch: 25
2022-12-31 15:02:33,401 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.518383240699768, 'Total loss': 0.518383240699768} | train loss {'Reaction outcome loss': 0.35416759496187644, 'Total loss': 0.35416759496187644}
2022-12-31 15:02:33,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:33,401 INFO:     Epoch: 26
2022-12-31 15:02:34,998 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44916746616363523, 'Total loss': 0.44916746616363523} | train loss {'Reaction outcome loss': 0.34924209571994136, 'Total loss': 0.34924209571994136}
2022-12-31 15:02:34,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:34,999 INFO:     Epoch: 27
2022-12-31 15:02:36,601 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4009931147098541, 'Total loss': 0.4009931147098541} | train loss {'Reaction outcome loss': 0.34512976861565653, 'Total loss': 0.34512976861565653}
2022-12-31 15:02:36,601 INFO:     Found new best model at epoch 27
2022-12-31 15:02:36,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:36,602 INFO:     Epoch: 28
2022-12-31 15:02:38,237 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45082783202330273, 'Total loss': 0.45082783202330273} | train loss {'Reaction outcome loss': 0.3284702057114048, 'Total loss': 0.3284702057114048}
2022-12-31 15:02:38,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:38,237 INFO:     Epoch: 29
2022-12-31 15:02:39,863 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4142029861609141, 'Total loss': 0.4142029861609141} | train loss {'Reaction outcome loss': 0.3289599060250895, 'Total loss': 0.3289599060250895}
2022-12-31 15:02:39,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:39,863 INFO:     Epoch: 30
2022-12-31 15:02:41,489 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4225610703229904, 'Total loss': 0.4225610703229904} | train loss {'Reaction outcome loss': 0.3221627575256964, 'Total loss': 0.3221627575256964}
2022-12-31 15:02:41,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:41,489 INFO:     Epoch: 31
2022-12-31 15:02:43,105 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3764036302765211, 'Total loss': 0.3764036302765211} | train loss {'Reaction outcome loss': 0.32551802447351225, 'Total loss': 0.32551802447351225}
2022-12-31 15:02:43,105 INFO:     Found new best model at epoch 31
2022-12-31 15:02:43,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:43,106 INFO:     Epoch: 32
2022-12-31 15:02:44,720 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39360100229581196, 'Total loss': 0.39360100229581196} | train loss {'Reaction outcome loss': 0.31216450061404355, 'Total loss': 0.31216450061404355}
2022-12-31 15:02:44,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:44,722 INFO:     Epoch: 33
2022-12-31 15:02:46,357 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4252319782972336, 'Total loss': 0.4252319782972336} | train loss {'Reaction outcome loss': 0.31323081785201157, 'Total loss': 0.31323081785201157}
2022-12-31 15:02:46,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:46,357 INFO:     Epoch: 34
2022-12-31 15:02:47,994 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39410209357738496, 'Total loss': 0.39410209357738496} | train loss {'Reaction outcome loss': 0.3156748169312512, 'Total loss': 0.3156748169312512}
2022-12-31 15:02:47,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:47,994 INFO:     Epoch: 35
2022-12-31 15:02:49,619 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.393601922194163, 'Total loss': 0.393601922194163} | train loss {'Reaction outcome loss': 0.309156525159513, 'Total loss': 0.309156525159513}
2022-12-31 15:02:49,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:49,619 INFO:     Epoch: 36
2022-12-31 15:02:51,210 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3987339754899343, 'Total loss': 0.3987339754899343} | train loss {'Reaction outcome loss': 0.3011801329298611, 'Total loss': 0.3011801329298611}
2022-12-31 15:02:51,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:51,211 INFO:     Epoch: 37
2022-12-31 15:02:52,827 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39928657909234366, 'Total loss': 0.39928657909234366} | train loss {'Reaction outcome loss': 0.29992182261861156, 'Total loss': 0.29992182261861156}
2022-12-31 15:02:52,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:52,827 INFO:     Epoch: 38
2022-12-31 15:02:54,416 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38061360518137616, 'Total loss': 0.38061360518137616} | train loss {'Reaction outcome loss': 0.2930301835855646, 'Total loss': 0.2930301835855646}
2022-12-31 15:02:54,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:54,417 INFO:     Epoch: 39
2022-12-31 15:02:56,049 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3844072153170904, 'Total loss': 0.3844072153170904} | train loss {'Reaction outcome loss': 0.2983243526061521, 'Total loss': 0.2983243526061521}
2022-12-31 15:02:56,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:56,049 INFO:     Epoch: 40
2022-12-31 15:02:57,687 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4348384400208791, 'Total loss': 0.4348384400208791} | train loss {'Reaction outcome loss': 0.2879275434861218, 'Total loss': 0.2879275434861218}
2022-12-31 15:02:57,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:57,687 INFO:     Epoch: 41
2022-12-31 15:02:59,302 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38748712142308556, 'Total loss': 0.38748712142308556} | train loss {'Reaction outcome loss': 0.28483726463559333, 'Total loss': 0.28483726463559333}
2022-12-31 15:02:59,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:02:59,302 INFO:     Epoch: 42
2022-12-31 15:03:00,900 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3733996291955312, 'Total loss': 0.3733996291955312} | train loss {'Reaction outcome loss': 0.28623388494181373, 'Total loss': 0.28623388494181373}
2022-12-31 15:03:00,900 INFO:     Found new best model at epoch 42
2022-12-31 15:03:00,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:00,901 INFO:     Epoch: 43
2022-12-31 15:03:02,510 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40321866373221077, 'Total loss': 0.40321866373221077} | train loss {'Reaction outcome loss': 0.2843999694624956, 'Total loss': 0.2843999694624956}
2022-12-31 15:03:02,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:02,510 INFO:     Epoch: 44
2022-12-31 15:03:04,107 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41017876466115316, 'Total loss': 0.41017876466115316} | train loss {'Reaction outcome loss': 0.2765523848280202, 'Total loss': 0.2765523848280202}
2022-12-31 15:03:04,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:04,108 INFO:     Epoch: 45
2022-12-31 15:03:05,744 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41494487623373666, 'Total loss': 0.41494487623373666} | train loss {'Reaction outcome loss': 0.2815641276538372, 'Total loss': 0.2815641276538372}
2022-12-31 15:03:05,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:05,744 INFO:     Epoch: 46
2022-12-31 15:03:07,372 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3921105325222015, 'Total loss': 0.3921105325222015} | train loss {'Reaction outcome loss': 0.2695161932059666, 'Total loss': 0.2695161932059666}
2022-12-31 15:03:07,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:07,373 INFO:     Epoch: 47
2022-12-31 15:03:08,995 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.358083575963974, 'Total loss': 0.358083575963974} | train loss {'Reaction outcome loss': 0.26028251050407214, 'Total loss': 0.26028251050407214}
2022-12-31 15:03:08,995 INFO:     Found new best model at epoch 47
2022-12-31 15:03:08,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:08,996 INFO:     Epoch: 48
2022-12-31 15:03:10,595 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4395479808251063, 'Total loss': 0.4395479808251063} | train loss {'Reaction outcome loss': 0.26737417268437624, 'Total loss': 0.26737417268437624}
2022-12-31 15:03:10,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:10,595 INFO:     Epoch: 49
2022-12-31 15:03:12,201 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3671588655561209, 'Total loss': 0.3671588655561209} | train loss {'Reaction outcome loss': 0.26418003944313007, 'Total loss': 0.26418003944313007}
2022-12-31 15:03:12,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:12,201 INFO:     Epoch: 50
2022-12-31 15:03:13,830 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4203036149342855, 'Total loss': 0.4203036149342855} | train loss {'Reaction outcome loss': 0.2690116393712968, 'Total loss': 0.2690116393712968}
2022-12-31 15:03:13,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:13,830 INFO:     Epoch: 51
2022-12-31 15:03:15,431 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3873410960038503, 'Total loss': 0.3873410960038503} | train loss {'Reaction outcome loss': 0.25968359190508394, 'Total loss': 0.25968359190508394}
2022-12-31 15:03:15,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:15,431 INFO:     Epoch: 52
2022-12-31 15:03:17,026 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3709733267625173, 'Total loss': 0.3709733267625173} | train loss {'Reaction outcome loss': 0.2595763304508733, 'Total loss': 0.2595763304508733}
2022-12-31 15:03:17,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:17,027 INFO:     Epoch: 53
2022-12-31 15:03:18,634 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36999003117283186, 'Total loss': 0.36999003117283186} | train loss {'Reaction outcome loss': 0.25091841747562815, 'Total loss': 0.25091841747562815}
2022-12-31 15:03:18,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:18,634 INFO:     Epoch: 54
2022-12-31 15:03:20,223 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.385594841837883, 'Total loss': 0.385594841837883} | train loss {'Reaction outcome loss': 0.2507982623362302, 'Total loss': 0.2507982623362302}
2022-12-31 15:03:20,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:20,224 INFO:     Epoch: 55
2022-12-31 15:03:21,818 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37491448322931925, 'Total loss': 0.37491448322931925} | train loss {'Reaction outcome loss': 0.24577793515674826, 'Total loss': 0.24577793515674826}
2022-12-31 15:03:21,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:21,819 INFO:     Epoch: 56
2022-12-31 15:03:23,458 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38198012908299767, 'Total loss': 0.38198012908299767} | train loss {'Reaction outcome loss': 0.24992377596506238, 'Total loss': 0.24992377596506238}
2022-12-31 15:03:23,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:23,459 INFO:     Epoch: 57
2022-12-31 15:03:25,096 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43554666837056477, 'Total loss': 0.43554666837056477} | train loss {'Reaction outcome loss': 0.24776420183479786, 'Total loss': 0.24776420183479786}
2022-12-31 15:03:25,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:25,097 INFO:     Epoch: 58
2022-12-31 15:03:26,721 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3868410994609197, 'Total loss': 0.3868410994609197} | train loss {'Reaction outcome loss': 0.25333029927726647, 'Total loss': 0.25333029927726647}
2022-12-31 15:03:26,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:26,722 INFO:     Epoch: 59
2022-12-31 15:03:28,325 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3941797306140264, 'Total loss': 0.3941797306140264} | train loss {'Reaction outcome loss': 0.24572080396877152, 'Total loss': 0.24572080396877152}
2022-12-31 15:03:28,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:28,325 INFO:     Epoch: 60
2022-12-31 15:03:29,958 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3804705182711283, 'Total loss': 0.3804705182711283} | train loss {'Reaction outcome loss': 0.24170848111329724, 'Total loss': 0.24170848111329724}
2022-12-31 15:03:29,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:29,959 INFO:     Epoch: 61
2022-12-31 15:03:31,581 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38196039001146953, 'Total loss': 0.38196039001146953} | train loss {'Reaction outcome loss': 0.24163725403864889, 'Total loss': 0.24163725403864889}
2022-12-31 15:03:31,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:31,581 INFO:     Epoch: 62
2022-12-31 15:03:33,220 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.34279329925775526, 'Total loss': 0.34279329925775526} | train loss {'Reaction outcome loss': 0.23919248750202193, 'Total loss': 0.23919248750202193}
2022-12-31 15:03:33,220 INFO:     Found new best model at epoch 62
2022-12-31 15:03:33,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:33,221 INFO:     Epoch: 63
2022-12-31 15:03:34,846 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36872771282990774, 'Total loss': 0.36872771282990774} | train loss {'Reaction outcome loss': 0.23557204272543644, 'Total loss': 0.23557204272543644}
2022-12-31 15:03:34,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:34,846 INFO:     Epoch: 64
2022-12-31 15:03:36,474 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3771985391775767, 'Total loss': 0.3771985391775767} | train loss {'Reaction outcome loss': 0.2366402582673315, 'Total loss': 0.2366402582673315}
2022-12-31 15:03:36,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:36,474 INFO:     Epoch: 65
2022-12-31 15:03:38,093 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3492400656143824, 'Total loss': 0.3492400656143824} | train loss {'Reaction outcome loss': 0.23711569106926883, 'Total loss': 0.23711569106926883}
2022-12-31 15:03:38,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:38,093 INFO:     Epoch: 66
2022-12-31 15:03:39,703 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3788540482521057, 'Total loss': 0.3788540482521057} | train loss {'Reaction outcome loss': 0.23038363358155436, 'Total loss': 0.23038363358155436}
2022-12-31 15:03:39,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:39,704 INFO:     Epoch: 67
2022-12-31 15:03:41,335 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36381733417510986, 'Total loss': 0.36381733417510986} | train loss {'Reaction outcome loss': 0.2326372624884774, 'Total loss': 0.2326372624884774}
2022-12-31 15:03:41,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:41,336 INFO:     Epoch: 68
2022-12-31 15:03:42,976 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37915579477945965, 'Total loss': 0.37915579477945965} | train loss {'Reaction outcome loss': 0.22573194945108715, 'Total loss': 0.22573194945108715}
2022-12-31 15:03:42,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:42,976 INFO:     Epoch: 69
2022-12-31 15:03:44,611 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3632605363925298, 'Total loss': 0.3632605363925298} | train loss {'Reaction outcome loss': 0.2243543160657813, 'Total loss': 0.2243543160657813}
2022-12-31 15:03:44,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:44,611 INFO:     Epoch: 70
2022-12-31 15:03:46,232 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3754681060711543, 'Total loss': 0.3754681060711543} | train loss {'Reaction outcome loss': 0.23194854773825754, 'Total loss': 0.23194854773825754}
2022-12-31 15:03:46,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:46,233 INFO:     Epoch: 71
2022-12-31 15:03:47,831 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37957103351751964, 'Total loss': 0.37957103351751964} | train loss {'Reaction outcome loss': 0.22404122513032307, 'Total loss': 0.22404122513032307}
2022-12-31 15:03:47,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:47,832 INFO:     Epoch: 72
2022-12-31 15:03:49,410 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37020252148310345, 'Total loss': 0.37020252148310345} | train loss {'Reaction outcome loss': 0.2172211663199276, 'Total loss': 0.2172211663199276}
2022-12-31 15:03:49,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:49,410 INFO:     Epoch: 73
2022-12-31 15:03:51,008 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3834591180086136, 'Total loss': 0.3834591180086136} | train loss {'Reaction outcome loss': 0.22404051014650478, 'Total loss': 0.22404051014650478}
2022-12-31 15:03:51,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:51,009 INFO:     Epoch: 74
2022-12-31 15:03:52,609 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.35097263554732006, 'Total loss': 0.35097263554732006} | train loss {'Reaction outcome loss': 0.2192031955958283, 'Total loss': 0.2192031955958283}
2022-12-31 15:03:52,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:52,609 INFO:     Epoch: 75
2022-12-31 15:03:54,209 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4001031716664632, 'Total loss': 0.4001031716664632} | train loss {'Reaction outcome loss': 0.2231401455500265, 'Total loss': 0.2231401455500265}
2022-12-31 15:03:54,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:54,209 INFO:     Epoch: 76
2022-12-31 15:03:55,794 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3621873443325361, 'Total loss': 0.3621873443325361} | train loss {'Reaction outcome loss': 0.21833465026052545, 'Total loss': 0.21833465026052545}
2022-12-31 15:03:55,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:55,794 INFO:     Epoch: 77
2022-12-31 15:03:57,383 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36490736256043116, 'Total loss': 0.36490736256043116} | train loss {'Reaction outcome loss': 0.22028477122857623, 'Total loss': 0.22028477122857623}
2022-12-31 15:03:57,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:57,384 INFO:     Epoch: 78
2022-12-31 15:03:59,004 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3701603641112646, 'Total loss': 0.3701603641112646} | train loss {'Reaction outcome loss': 0.22528675212320892, 'Total loss': 0.22528675212320892}
2022-12-31 15:03:59,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:03:59,004 INFO:     Epoch: 79
2022-12-31 15:04:00,636 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4177097568909327, 'Total loss': 0.4177097568909327} | train loss {'Reaction outcome loss': 0.21108431176003747, 'Total loss': 0.21108431176003747}
2022-12-31 15:04:00,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:00,636 INFO:     Epoch: 80
2022-12-31 15:04:02,266 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3978237343331178, 'Total loss': 0.3978237343331178} | train loss {'Reaction outcome loss': 0.22161362078856595, 'Total loss': 0.22161362078856595}
2022-12-31 15:04:02,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:02,266 INFO:     Epoch: 81
2022-12-31 15:04:03,880 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3862370987733205, 'Total loss': 0.3862370987733205} | train loss {'Reaction outcome loss': 0.21151887026554259, 'Total loss': 0.21151887026554259}
2022-12-31 15:04:03,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:03,880 INFO:     Epoch: 82
2022-12-31 15:04:05,492 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3735136464238167, 'Total loss': 0.3735136464238167} | train loss {'Reaction outcome loss': 0.21790537168781687, 'Total loss': 0.21790537168781687}
2022-12-31 15:04:05,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:05,493 INFO:     Epoch: 83
2022-12-31 15:04:07,090 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3746418436368307, 'Total loss': 0.3746418436368307} | train loss {'Reaction outcome loss': 0.21449330559231505, 'Total loss': 0.21449330559231505}
2022-12-31 15:04:07,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:07,090 INFO:     Epoch: 84
2022-12-31 15:04:08,687 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37775512772301834, 'Total loss': 0.37775512772301834} | train loss {'Reaction outcome loss': 0.21269949505880584, 'Total loss': 0.21269949505880584}
2022-12-31 15:04:08,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:08,688 INFO:     Epoch: 85
2022-12-31 15:04:10,286 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37927597562472026, 'Total loss': 0.37927597562472026} | train loss {'Reaction outcome loss': 0.2057874032914856, 'Total loss': 0.2057874032914856}
2022-12-31 15:04:10,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:10,287 INFO:     Epoch: 86
2022-12-31 15:04:11,902 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.36132150093714394, 'Total loss': 0.36132150093714394} | train loss {'Reaction outcome loss': 0.20563786582219123, 'Total loss': 0.20563786582219123}
2022-12-31 15:04:11,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:11,902 INFO:     Epoch: 87
2022-12-31 15:04:13,518 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.36707067117094994, 'Total loss': 0.36707067117094994} | train loss {'Reaction outcome loss': 0.21201832012959967, 'Total loss': 0.21201832012959967}
2022-12-31 15:04:13,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:13,518 INFO:     Epoch: 88
2022-12-31 15:04:15,111 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40855323771635693, 'Total loss': 0.40855323771635693} | train loss {'Reaction outcome loss': 0.20342590155447052, 'Total loss': 0.20342590155447052}
2022-12-31 15:04:15,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:15,111 INFO:     Epoch: 89
2022-12-31 15:04:16,694 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38764975368976595, 'Total loss': 0.38764975368976595} | train loss {'Reaction outcome loss': 0.2054097810556201, 'Total loss': 0.2054097810556201}
2022-12-31 15:04:16,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:16,694 INFO:     Epoch: 90
2022-12-31 15:04:18,308 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3697934036453565, 'Total loss': 0.3697934036453565} | train loss {'Reaction outcome loss': 0.20728793173321408, 'Total loss': 0.20728793173321408}
2022-12-31 15:04:18,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:18,308 INFO:     Epoch: 91
2022-12-31 15:04:19,910 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38190578122933705, 'Total loss': 0.38190578122933705} | train loss {'Reaction outcome loss': 0.2023979235630836, 'Total loss': 0.2023979235630836}
2022-12-31 15:04:19,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:19,910 INFO:     Epoch: 92
2022-12-31 15:04:21,505 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.35845441023508706, 'Total loss': 0.35845441023508706} | train loss {'Reaction outcome loss': 0.20344997197389603, 'Total loss': 0.20344997197389603}
2022-12-31 15:04:21,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:21,506 INFO:     Epoch: 93
2022-12-31 15:04:23,089 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37828652560710907, 'Total loss': 0.37828652560710907} | train loss {'Reaction outcome loss': 0.1987327886405435, 'Total loss': 0.1987327886405435}
2022-12-31 15:04:23,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:23,089 INFO:     Epoch: 94
2022-12-31 15:04:24,668 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.402317546804746, 'Total loss': 0.402317546804746} | train loss {'Reaction outcome loss': 0.20152006146028964, 'Total loss': 0.20152006146028964}
2022-12-31 15:04:24,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:24,668 INFO:     Epoch: 95
2022-12-31 15:04:26,274 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40901134510835013, 'Total loss': 0.40901134510835013} | train loss {'Reaction outcome loss': 0.20309213927206005, 'Total loss': 0.20309213927206005}
2022-12-31 15:04:26,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:26,274 INFO:     Epoch: 96
2022-12-31 15:04:27,884 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3822095145781835, 'Total loss': 0.3822095145781835} | train loss {'Reaction outcome loss': 0.200929008172757, 'Total loss': 0.200929008172757}
2022-12-31 15:04:27,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:27,885 INFO:     Epoch: 97
2022-12-31 15:04:29,517 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3824372182289759, 'Total loss': 0.3824372182289759} | train loss {'Reaction outcome loss': 0.19897148034188653, 'Total loss': 0.19897148034188653}
2022-12-31 15:04:29,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:29,518 INFO:     Epoch: 98
2022-12-31 15:04:31,126 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41433965265750883, 'Total loss': 0.41433965265750883} | train loss {'Reaction outcome loss': 0.19370234222661187, 'Total loss': 0.19370234222661187}
2022-12-31 15:04:31,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:31,126 INFO:     Epoch: 99
2022-12-31 15:04:32,740 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3739073167244593, 'Total loss': 0.3739073167244593} | train loss {'Reaction outcome loss': 0.2042022122981122, 'Total loss': 0.2042022122981122}
2022-12-31 15:04:32,741 INFO:     Best model found after epoch 63 of 100.
2022-12-31 15:04:32,741 INFO:   Done with stage: TRAINING
2022-12-31 15:04:32,741 INFO:   Starting stage: EVALUATION
2022-12-31 15:04:32,875 INFO:   Done with stage: EVALUATION
2022-12-31 15:04:32,875 INFO:   Leaving out SEQ value Fold_4
2022-12-31 15:04:32,888 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 15:04:32,888 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:04:33,540 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:04:33,540 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:04:33,609 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:04:33,609 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:04:33,609 INFO:     No hyperparam tuning for this model
2022-12-31 15:04:33,609 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:04:33,609 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:04:33,610 INFO:     None feature selector for col prot
2022-12-31 15:04:33,610 INFO:     None feature selector for col prot
2022-12-31 15:04:33,610 INFO:     None feature selector for col prot
2022-12-31 15:04:33,611 INFO:     None feature selector for col chem
2022-12-31 15:04:33,611 INFO:     None feature selector for col chem
2022-12-31 15:04:33,611 INFO:     None feature selector for col chem
2022-12-31 15:04:33,611 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:04:33,611 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:04:33,613 INFO:     Number of params in model 223921
2022-12-31 15:04:33,616 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:04:33,616 INFO:   Starting stage: TRAINING
2022-12-31 15:04:33,661 INFO:     Val loss before train {'Reaction outcome loss': 0.9871244470278422, 'Total loss': 0.9871244470278422}
2022-12-31 15:04:33,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:33,661 INFO:     Epoch: 0
2022-12-31 15:04:35,315 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.686612582206726, 'Total loss': 0.686612582206726} | train loss {'Reaction outcome loss': 0.8210425852438172, 'Total loss': 0.8210425852438172}
2022-12-31 15:04:35,316 INFO:     Found new best model at epoch 0
2022-12-31 15:04:35,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:35,316 INFO:     Epoch: 1
2022-12-31 15:04:36,953 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5932255188624064, 'Total loss': 0.5932255188624064} | train loss {'Reaction outcome loss': 0.6052267218432271, 'Total loss': 0.6052267218432271}
2022-12-31 15:04:36,953 INFO:     Found new best model at epoch 1
2022-12-31 15:04:36,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:36,954 INFO:     Epoch: 2
2022-12-31 15:04:38,602 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5665135820706685, 'Total loss': 0.5665135820706685} | train loss {'Reaction outcome loss': 0.5352924140674543, 'Total loss': 0.5352924140674543}
2022-12-31 15:04:38,602 INFO:     Found new best model at epoch 2
2022-12-31 15:04:38,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:38,603 INFO:     Epoch: 3
2022-12-31 15:04:40,232 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.563532555103302, 'Total loss': 0.563532555103302} | train loss {'Reaction outcome loss': 0.5044130007282491, 'Total loss': 0.5044130007282491}
2022-12-31 15:04:40,233 INFO:     Found new best model at epoch 3
2022-12-31 15:04:40,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:40,234 INFO:     Epoch: 4
2022-12-31 15:04:41,877 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5817807714144388, 'Total loss': 0.5817807714144388} | train loss {'Reaction outcome loss': 0.4940920643750511, 'Total loss': 0.4940920643750511}
2022-12-31 15:04:41,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:41,877 INFO:     Epoch: 5
2022-12-31 15:04:43,510 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5404410223166148, 'Total loss': 0.5404410223166148} | train loss {'Reaction outcome loss': 0.4821195466316134, 'Total loss': 0.4821195466316134}
2022-12-31 15:04:43,510 INFO:     Found new best model at epoch 5
2022-12-31 15:04:43,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:43,511 INFO:     Epoch: 6
2022-12-31 15:04:45,147 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5318297684192658, 'Total loss': 0.5318297684192658} | train loss {'Reaction outcome loss': 0.46981230028484705, 'Total loss': 0.46981230028484705}
2022-12-31 15:04:45,148 INFO:     Found new best model at epoch 6
2022-12-31 15:04:45,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:45,148 INFO:     Epoch: 7
2022-12-31 15:04:46,779 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5287935594717662, 'Total loss': 0.5287935594717662} | train loss {'Reaction outcome loss': 0.4608662104778772, 'Total loss': 0.4608662104778772}
2022-12-31 15:04:46,779 INFO:     Found new best model at epoch 7
2022-12-31 15:04:46,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:46,780 INFO:     Epoch: 8
2022-12-31 15:04:48,428 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5515691061814626, 'Total loss': 0.5515691061814626} | train loss {'Reaction outcome loss': 0.4532106878094725, 'Total loss': 0.4532106878094725}
2022-12-31 15:04:48,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:48,429 INFO:     Epoch: 9
2022-12-31 15:04:50,049 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.518585600455602, 'Total loss': 0.518585600455602} | train loss {'Reaction outcome loss': 0.4459808985786748, 'Total loss': 0.4459808985786748}
2022-12-31 15:04:50,049 INFO:     Found new best model at epoch 9
2022-12-31 15:04:50,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:50,050 INFO:     Epoch: 10
2022-12-31 15:04:51,660 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5358531713485718, 'Total loss': 0.5358531713485718} | train loss {'Reaction outcome loss': 0.44546740416047376, 'Total loss': 0.44546740416047376}
2022-12-31 15:04:51,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:51,660 INFO:     Epoch: 11
2022-12-31 15:04:53,300 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5221157332261404, 'Total loss': 0.5221157332261404} | train loss {'Reaction outcome loss': 0.4343803042969549, 'Total loss': 0.4343803042969549}
2022-12-31 15:04:53,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:53,301 INFO:     Epoch: 12
2022-12-31 15:04:54,940 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5400500138600667, 'Total loss': 0.5400500138600667} | train loss {'Reaction outcome loss': 0.4298818402449577, 'Total loss': 0.4298818402449577}
2022-12-31 15:04:54,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:54,940 INFO:     Epoch: 13
2022-12-31 15:04:56,577 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5446276664733887, 'Total loss': 0.5446276664733887} | train loss {'Reaction outcome loss': 0.4222860563048817, 'Total loss': 0.4222860563048817}
2022-12-31 15:04:56,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:56,577 INFO:     Epoch: 14
2022-12-31 15:04:58,218 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4982713262240092, 'Total loss': 0.4982713262240092} | train loss {'Reaction outcome loss': 0.415842104609047, 'Total loss': 0.415842104609047}
2022-12-31 15:04:58,218 INFO:     Found new best model at epoch 14
2022-12-31 15:04:58,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:58,219 INFO:     Epoch: 15
2022-12-31 15:04:59,836 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5404459138711294, 'Total loss': 0.5404459138711294} | train loss {'Reaction outcome loss': 0.4164148982789112, 'Total loss': 0.4164148982789112}
2022-12-31 15:04:59,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:04:59,836 INFO:     Epoch: 16
2022-12-31 15:05:01,467 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5443718433380127, 'Total loss': 0.5443718433380127} | train loss {'Reaction outcome loss': 0.404782084136233, 'Total loss': 0.404782084136233}
2022-12-31 15:05:01,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:01,467 INFO:     Epoch: 17
2022-12-31 15:05:03,118 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5039124856392543, 'Total loss': 0.5039124856392543} | train loss {'Reaction outcome loss': 0.4033265100650839, 'Total loss': 0.4033265100650839}
2022-12-31 15:05:03,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:03,118 INFO:     Epoch: 18
2022-12-31 15:05:04,748 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5071357528368632, 'Total loss': 0.5071357528368632} | train loss {'Reaction outcome loss': 0.3975643813879051, 'Total loss': 0.3975643813879051}
2022-12-31 15:05:04,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:04,749 INFO:     Epoch: 19
2022-12-31 15:05:06,399 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4932905942201614, 'Total loss': 0.4932905942201614} | train loss {'Reaction outcome loss': 0.396995999241779, 'Total loss': 0.396995999241779}
2022-12-31 15:05:06,400 INFO:     Found new best model at epoch 19
2022-12-31 15:05:06,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:06,401 INFO:     Epoch: 20
2022-12-31 15:05:08,019 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.530644029378891, 'Total loss': 0.530644029378891} | train loss {'Reaction outcome loss': 0.38073300987159303, 'Total loss': 0.38073300987159303}
2022-12-31 15:05:08,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:08,020 INFO:     Epoch: 21
2022-12-31 15:05:09,659 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5271185358365377, 'Total loss': 0.5271185358365377} | train loss {'Reaction outcome loss': 0.37970335985994513, 'Total loss': 0.37970335985994513}
2022-12-31 15:05:09,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:09,659 INFO:     Epoch: 22
2022-12-31 15:05:11,287 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5028309802214305, 'Total loss': 0.5028309802214305} | train loss {'Reaction outcome loss': 0.3758548723015975, 'Total loss': 0.3758548723015975}
2022-12-31 15:05:11,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:11,287 INFO:     Epoch: 23
2022-12-31 15:05:12,928 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5205367823441823, 'Total loss': 0.5205367823441823} | train loss {'Reaction outcome loss': 0.37352189115023354, 'Total loss': 0.37352189115023354}
2022-12-31 15:05:12,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:12,929 INFO:     Epoch: 24
2022-12-31 15:05:14,556 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.504429715871811, 'Total loss': 0.504429715871811} | train loss {'Reaction outcome loss': 0.3576012288996889, 'Total loss': 0.3576012288996889}
2022-12-31 15:05:14,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:14,556 INFO:     Epoch: 25
2022-12-31 15:05:16,199 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5089733252922694, 'Total loss': 0.5089733252922694} | train loss {'Reaction outcome loss': 0.3591028250726982, 'Total loss': 0.3591028250726982}
2022-12-31 15:05:16,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:16,200 INFO:     Epoch: 26
2022-12-31 15:05:17,807 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.486895693341891, 'Total loss': 0.486895693341891} | train loss {'Reaction outcome loss': 0.35360882586601194, 'Total loss': 0.35360882586601194}
2022-12-31 15:05:17,808 INFO:     Found new best model at epoch 26
2022-12-31 15:05:17,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:17,808 INFO:     Epoch: 27
2022-12-31 15:05:19,417 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.503592433532079, 'Total loss': 0.503592433532079} | train loss {'Reaction outcome loss': 0.35009464917415317, 'Total loss': 0.35009464917415317}
2022-12-31 15:05:19,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:19,417 INFO:     Epoch: 28
2022-12-31 15:05:21,052 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.491764164964358, 'Total loss': 0.491764164964358} | train loss {'Reaction outcome loss': 0.34473845779573015, 'Total loss': 0.34473845779573015}
2022-12-31 15:05:21,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:21,053 INFO:     Epoch: 29
2022-12-31 15:05:22,677 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49495227734247843, 'Total loss': 0.49495227734247843} | train loss {'Reaction outcome loss': 0.34059052325327904, 'Total loss': 0.34059052325327904}
2022-12-31 15:05:22,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:22,677 INFO:     Epoch: 30
2022-12-31 15:05:24,302 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5222524007161459, 'Total loss': 0.5222524007161459} | train loss {'Reaction outcome loss': 0.33179887962470417, 'Total loss': 0.33179887962470417}
2022-12-31 15:05:24,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:24,302 INFO:     Epoch: 31
2022-12-31 15:05:25,901 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5071408569812774, 'Total loss': 0.5071408569812774} | train loss {'Reaction outcome loss': 0.3264991663369461, 'Total loss': 0.3264991663369461}
2022-12-31 15:05:25,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:25,902 INFO:     Epoch: 32
2022-12-31 15:05:27,524 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5628854950269063, 'Total loss': 0.5628854950269063} | train loss {'Reaction outcome loss': 0.32427785134057274, 'Total loss': 0.32427785134057274}
2022-12-31 15:05:27,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:27,525 INFO:     Epoch: 33
2022-12-31 15:05:29,138 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5150434017181397, 'Total loss': 0.5150434017181397} | train loss {'Reaction outcome loss': 0.321011919299618, 'Total loss': 0.321011919299618}
2022-12-31 15:05:29,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:29,138 INFO:     Epoch: 34
2022-12-31 15:05:30,758 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.500616188844045, 'Total loss': 0.500616188844045} | train loss {'Reaction outcome loss': 0.3203389918976312, 'Total loss': 0.3203389918976312}
2022-12-31 15:05:30,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:30,758 INFO:     Epoch: 35
2022-12-31 15:05:32,397 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4964618186155955, 'Total loss': 0.4964618186155955} | train loss {'Reaction outcome loss': 0.31337069654131194, 'Total loss': 0.31337069654131194}
2022-12-31 15:05:32,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:32,397 INFO:     Epoch: 36
2022-12-31 15:05:34,024 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4959554354349772, 'Total loss': 0.4959554354349772} | train loss {'Reaction outcome loss': 0.310211918710156, 'Total loss': 0.310211918710156}
2022-12-31 15:05:34,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:34,025 INFO:     Epoch: 37
2022-12-31 15:05:35,647 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4858681321144104, 'Total loss': 0.4858681321144104} | train loss {'Reaction outcome loss': 0.3016829946707087, 'Total loss': 0.3016829946707087}
2022-12-31 15:05:35,647 INFO:     Found new best model at epoch 37
2022-12-31 15:05:35,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:35,648 INFO:     Epoch: 38
2022-12-31 15:05:37,252 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5144282619158427, 'Total loss': 0.5144282619158427} | train loss {'Reaction outcome loss': 0.299184566760429, 'Total loss': 0.299184566760429}
2022-12-31 15:05:37,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:37,252 INFO:     Epoch: 39
2022-12-31 15:05:38,903 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5266732056935628, 'Total loss': 0.5266732056935628} | train loss {'Reaction outcome loss': 0.29991845161206887, 'Total loss': 0.29991845161206887}
2022-12-31 15:05:38,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:38,904 INFO:     Epoch: 40
2022-12-31 15:05:40,544 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4946837991476059, 'Total loss': 0.4946837991476059} | train loss {'Reaction outcome loss': 0.29636647267139343, 'Total loss': 0.29636647267139343}
2022-12-31 15:05:40,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:40,544 INFO:     Epoch: 41
2022-12-31 15:05:42,166 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45465969741344453, 'Total loss': 0.45465969741344453} | train loss {'Reaction outcome loss': 0.28601759970726087, 'Total loss': 0.28601759970726087}
2022-12-31 15:05:42,166 INFO:     Found new best model at epoch 41
2022-12-31 15:05:42,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:42,167 INFO:     Epoch: 42
2022-12-31 15:05:43,786 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5587486227353414, 'Total loss': 0.5587486227353414} | train loss {'Reaction outcome loss': 0.2945117470051838, 'Total loss': 0.2945117470051838}
2022-12-31 15:05:43,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:43,786 INFO:     Epoch: 43
2022-12-31 15:05:45,420 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5009972929954529, 'Total loss': 0.5009972929954529} | train loss {'Reaction outcome loss': 0.28616056957077035, 'Total loss': 0.28616056957077035}
2022-12-31 15:05:45,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:45,421 INFO:     Epoch: 44
2022-12-31 15:05:47,040 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4659044951200485, 'Total loss': 0.4659044951200485} | train loss {'Reaction outcome loss': 0.28238203597090306, 'Total loss': 0.28238203597090306}
2022-12-31 15:05:47,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:47,041 INFO:     Epoch: 45
2022-12-31 15:05:48,692 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46392023464043936, 'Total loss': 0.46392023464043936} | train loss {'Reaction outcome loss': 0.2756327595628986, 'Total loss': 0.2756327595628986}
2022-12-31 15:05:48,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:48,693 INFO:     Epoch: 46
2022-12-31 15:05:50,332 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4970256268978119, 'Total loss': 0.4970256268978119} | train loss {'Reaction outcome loss': 0.27592519165053697, 'Total loss': 0.27592519165053697}
2022-12-31 15:05:50,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:50,332 INFO:     Epoch: 47
2022-12-31 15:05:51,949 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48115967710812885, 'Total loss': 0.48115967710812885} | train loss {'Reaction outcome loss': 0.2746540323868125, 'Total loss': 0.2746540323868125}
2022-12-31 15:05:51,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:51,949 INFO:     Epoch: 48
2022-12-31 15:05:53,554 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48299054404099784, 'Total loss': 0.48299054404099784} | train loss {'Reaction outcome loss': 0.27098616086188637, 'Total loss': 0.27098616086188637}
2022-12-31 15:05:53,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:53,554 INFO:     Epoch: 49
2022-12-31 15:05:55,160 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4932456433773041, 'Total loss': 0.4932456433773041} | train loss {'Reaction outcome loss': 0.269530192837926, 'Total loss': 0.269530192837926}
2022-12-31 15:05:55,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:55,160 INFO:     Epoch: 50
2022-12-31 15:05:56,793 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44960612456003823, 'Total loss': 0.44960612456003823} | train loss {'Reaction outcome loss': 0.26334259217934486, 'Total loss': 0.26334259217934486}
2022-12-31 15:05:56,793 INFO:     Found new best model at epoch 50
2022-12-31 15:05:56,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:56,794 INFO:     Epoch: 51
2022-12-31 15:05:58,446 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44920854568481444, 'Total loss': 0.44920854568481444} | train loss {'Reaction outcome loss': 0.2661122406836236, 'Total loss': 0.2661122406836236}
2022-12-31 15:05:58,446 INFO:     Found new best model at epoch 51
2022-12-31 15:05:58,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:05:58,447 INFO:     Epoch: 52
2022-12-31 15:06:00,067 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5240557253360748, 'Total loss': 0.5240557253360748} | train loss {'Reaction outcome loss': 0.2596920506847141, 'Total loss': 0.2596920506847141}
2022-12-31 15:06:00,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:00,068 INFO:     Epoch: 53
2022-12-31 15:06:01,682 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4444329281648, 'Total loss': 0.4444329281648} | train loss {'Reaction outcome loss': 0.26147902267396667, 'Total loss': 0.26147902267396667}
2022-12-31 15:06:01,682 INFO:     Found new best model at epoch 53
2022-12-31 15:06:01,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:01,683 INFO:     Epoch: 54
2022-12-31 15:06:03,284 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.441230312983195, 'Total loss': 0.441230312983195} | train loss {'Reaction outcome loss': 0.2575085989068454, 'Total loss': 0.2575085989068454}
2022-12-31 15:06:03,284 INFO:     Found new best model at epoch 54
2022-12-31 15:06:03,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:03,285 INFO:     Epoch: 55
2022-12-31 15:06:04,888 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45930359611908594, 'Total loss': 0.45930359611908594} | train loss {'Reaction outcome loss': 0.26117045475365025, 'Total loss': 0.26117045475365025}
2022-12-31 15:06:04,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:04,889 INFO:     Epoch: 56
2022-12-31 15:06:06,503 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47269231677055357, 'Total loss': 0.47269231677055357} | train loss {'Reaction outcome loss': 0.25471298424829647, 'Total loss': 0.25471298424829647}
2022-12-31 15:06:06,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:06,503 INFO:     Epoch: 57
2022-12-31 15:06:08,118 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43959662814935047, 'Total loss': 0.43959662814935047} | train loss {'Reaction outcome loss': 0.2508457619091664, 'Total loss': 0.2508457619091664}
2022-12-31 15:06:08,118 INFO:     Found new best model at epoch 57
2022-12-31 15:06:08,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:08,119 INFO:     Epoch: 58
2022-12-31 15:06:09,735 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4992197185754776, 'Total loss': 0.4992197185754776} | train loss {'Reaction outcome loss': 0.25419544475657413, 'Total loss': 0.25419544475657413}
2022-12-31 15:06:09,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:09,736 INFO:     Epoch: 59
2022-12-31 15:06:11,334 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4323234011729558, 'Total loss': 0.4323234011729558} | train loss {'Reaction outcome loss': 0.2479592842799662, 'Total loss': 0.2479592842799662}
2022-12-31 15:06:11,335 INFO:     Found new best model at epoch 59
2022-12-31 15:06:11,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:11,336 INFO:     Epoch: 60
2022-12-31 15:06:12,950 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4501921812693278, 'Total loss': 0.4501921812693278} | train loss {'Reaction outcome loss': 0.24622181473494867, 'Total loss': 0.24622181473494867}
2022-12-31 15:06:12,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:12,950 INFO:     Epoch: 61
2022-12-31 15:06:14,557 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5387611865997315, 'Total loss': 0.5387611865997315} | train loss {'Reaction outcome loss': 0.24839846777733052, 'Total loss': 0.24839846777733052}
2022-12-31 15:06:14,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:14,558 INFO:     Epoch: 62
2022-12-31 15:06:16,173 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44177099416653315, 'Total loss': 0.44177099416653315} | train loss {'Reaction outcome loss': 0.24859497050623602, 'Total loss': 0.24859497050623602}
2022-12-31 15:06:16,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:16,173 INFO:     Epoch: 63
2022-12-31 15:06:17,789 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43408547242482504, 'Total loss': 0.43408547242482504} | train loss {'Reaction outcome loss': 0.24745922110678917, 'Total loss': 0.24745922110678917}
2022-12-31 15:06:17,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:17,790 INFO:     Epoch: 64
2022-12-31 15:06:19,407 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4454450190067291, 'Total loss': 0.4454450190067291} | train loss {'Reaction outcome loss': 0.2441776363777555, 'Total loss': 0.2441776363777555}
2022-12-31 15:06:19,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:19,407 INFO:     Epoch: 65
2022-12-31 15:06:21,038 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4707622329394023, 'Total loss': 0.4707622329394023} | train loss {'Reaction outcome loss': 0.24126876523509783, 'Total loss': 0.24126876523509783}
2022-12-31 15:06:21,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:21,038 INFO:     Epoch: 66
2022-12-31 15:06:22,643 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46955299774805703, 'Total loss': 0.46955299774805703} | train loss {'Reaction outcome loss': 0.23905781185799127, 'Total loss': 0.23905781185799127}
2022-12-31 15:06:22,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:22,643 INFO:     Epoch: 67
2022-12-31 15:06:24,270 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44748336474100747, 'Total loss': 0.44748336474100747} | train loss {'Reaction outcome loss': 0.23360492777254177, 'Total loss': 0.23360492777254177}
2022-12-31 15:06:24,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:24,271 INFO:     Epoch: 68
2022-12-31 15:06:25,885 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4326055626074473, 'Total loss': 0.4326055626074473} | train loss {'Reaction outcome loss': 0.23565660478943953, 'Total loss': 0.23565660478943953}
2022-12-31 15:06:25,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:25,886 INFO:     Epoch: 69
2022-12-31 15:06:27,501 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4612528711557388, 'Total loss': 0.4612528711557388} | train loss {'Reaction outcome loss': 0.23183841236769506, 'Total loss': 0.23183841236769506}
2022-12-31 15:06:27,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:27,501 INFO:     Epoch: 70
2022-12-31 15:06:29,112 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4067828059196472, 'Total loss': 0.4067828059196472} | train loss {'Reaction outcome loss': 0.24252664633364238, 'Total loss': 0.24252664633364238}
2022-12-31 15:06:29,112 INFO:     Found new best model at epoch 70
2022-12-31 15:06:29,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:29,113 INFO:     Epoch: 71
2022-12-31 15:06:30,739 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4638297994931539, 'Total loss': 0.4638297994931539} | train loss {'Reaction outcome loss': 0.23076974912563386, 'Total loss': 0.23076974912563386}
2022-12-31 15:06:30,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:30,740 INFO:     Epoch: 72
2022-12-31 15:06:32,346 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4362826108932495, 'Total loss': 0.4362826108932495} | train loss {'Reaction outcome loss': 0.22985956185776404, 'Total loss': 0.22985956185776404}
2022-12-31 15:06:32,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:32,347 INFO:     Epoch: 73
2022-12-31 15:06:33,988 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4520321413874626, 'Total loss': 0.4520321413874626} | train loss {'Reaction outcome loss': 0.22512538926104345, 'Total loss': 0.22512538926104345}
2022-12-31 15:06:33,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:33,988 INFO:     Epoch: 74
2022-12-31 15:06:35,669 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49017784794171654, 'Total loss': 0.49017784794171654} | train loss {'Reaction outcome loss': 0.2260191763317488, 'Total loss': 0.2260191763317488}
2022-12-31 15:06:35,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:35,669 INFO:     Epoch: 75
2022-12-31 15:06:37,339 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4170632600784302, 'Total loss': 0.4170632600784302} | train loss {'Reaction outcome loss': 0.2216568513494321, 'Total loss': 0.2216568513494321}
2022-12-31 15:06:37,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:37,339 INFO:     Epoch: 76
2022-12-31 15:06:38,966 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46610460579395296, 'Total loss': 0.46610460579395296} | train loss {'Reaction outcome loss': 0.22721785769565872, 'Total loss': 0.22721785769565872}
2022-12-31 15:06:38,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:38,966 INFO:     Epoch: 77
2022-12-31 15:06:40,610 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4171824395656586, 'Total loss': 0.4171824395656586} | train loss {'Reaction outcome loss': 0.235644626965753, 'Total loss': 0.235644626965753}
2022-12-31 15:06:40,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:40,611 INFO:     Epoch: 78
2022-12-31 15:06:42,269 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43590640723705293, 'Total loss': 0.43590640723705293} | train loss {'Reaction outcome loss': 0.22704705240924436, 'Total loss': 0.22704705240924436}
2022-12-31 15:06:42,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:42,269 INFO:     Epoch: 79
2022-12-31 15:06:43,925 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4685901547471682, 'Total loss': 0.4685901547471682} | train loss {'Reaction outcome loss': 0.22811789568580876, 'Total loss': 0.22811789568580876}
2022-12-31 15:06:43,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:43,925 INFO:     Epoch: 80
2022-12-31 15:06:45,574 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45265955328941343, 'Total loss': 0.45265955328941343} | train loss {'Reaction outcome loss': 0.21976514627303026, 'Total loss': 0.21976514627303026}
2022-12-31 15:06:45,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:45,575 INFO:     Epoch: 81
2022-12-31 15:06:47,223 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4915443907181422, 'Total loss': 0.4915443907181422} | train loss {'Reaction outcome loss': 0.22694306245699042, 'Total loss': 0.22694306245699042}
2022-12-31 15:06:47,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:47,224 INFO:     Epoch: 82
2022-12-31 15:06:48,859 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47682427167892455, 'Total loss': 0.47682427167892455} | train loss {'Reaction outcome loss': 0.22073091945816034, 'Total loss': 0.22073091945816034}
2022-12-31 15:06:48,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:48,859 INFO:     Epoch: 83
2022-12-31 15:06:50,477 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43951666355133057, 'Total loss': 0.43951666355133057} | train loss {'Reaction outcome loss': 0.21749793543120585, 'Total loss': 0.21749793543120585}
2022-12-31 15:06:50,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:50,477 INFO:     Epoch: 84
2022-12-31 15:06:52,128 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.445908555885156, 'Total loss': 0.445908555885156} | train loss {'Reaction outcome loss': 0.22129792801780282, 'Total loss': 0.22129792801780282}
2022-12-31 15:06:52,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:52,129 INFO:     Epoch: 85
2022-12-31 15:06:53,778 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42889227668444313, 'Total loss': 0.42889227668444313} | train loss {'Reaction outcome loss': 0.21976110874423052, 'Total loss': 0.21976110874423052}
2022-12-31 15:06:53,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:53,778 INFO:     Epoch: 86
2022-12-31 15:06:55,414 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43990398744742076, 'Total loss': 0.43990398744742076} | train loss {'Reaction outcome loss': 0.22375029733653318, 'Total loss': 0.22375029733653318}
2022-12-31 15:06:55,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:55,414 INFO:     Epoch: 87
2022-12-31 15:06:57,018 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.470335661371549, 'Total loss': 0.470335661371549} | train loss {'Reaction outcome loss': 0.21993716755404477, 'Total loss': 0.21993716755404477}
2022-12-31 15:06:57,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:57,018 INFO:     Epoch: 88
2022-12-31 15:06:58,648 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43155038754145303, 'Total loss': 0.43155038754145303} | train loss {'Reaction outcome loss': 0.21327273754759385, 'Total loss': 0.21327273754759385}
2022-12-31 15:06:58,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:06:58,649 INFO:     Epoch: 89
2022-12-31 15:07:00,250 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4561219533284505, 'Total loss': 0.4561219533284505} | train loss {'Reaction outcome loss': 0.20746797294984656, 'Total loss': 0.20746797294984656}
2022-12-31 15:07:00,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:00,251 INFO:     Epoch: 90
2022-12-31 15:07:01,896 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4265693465868632, 'Total loss': 0.4265693465868632} | train loss {'Reaction outcome loss': 0.21383396776843588, 'Total loss': 0.21383396776843588}
2022-12-31 15:07:01,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:01,897 INFO:     Epoch: 91
2022-12-31 15:07:03,548 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4691790153582891, 'Total loss': 0.4691790153582891} | train loss {'Reaction outcome loss': 0.2110410138043417, 'Total loss': 0.2110410138043417}
2022-12-31 15:07:03,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:03,548 INFO:     Epoch: 92
2022-12-31 15:07:05,191 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45850892340143523, 'Total loss': 0.45850892340143523} | train loss {'Reaction outcome loss': 0.20697770324881973, 'Total loss': 0.20697770324881973}
2022-12-31 15:07:05,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:05,192 INFO:     Epoch: 93
2022-12-31 15:07:06,822 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43016855319341024, 'Total loss': 0.43016855319341024} | train loss {'Reaction outcome loss': 0.21112749659009145, 'Total loss': 0.21112749659009145}
2022-12-31 15:07:06,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:06,822 INFO:     Epoch: 94
2022-12-31 15:07:08,437 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4477278207739194, 'Total loss': 0.4477278207739194} | train loss {'Reaction outcome loss': 0.21030394053792695, 'Total loss': 0.21030394053792695}
2022-12-31 15:07:08,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:08,437 INFO:     Epoch: 95
2022-12-31 15:07:10,061 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46809021482865015, 'Total loss': 0.46809021482865015} | train loss {'Reaction outcome loss': 0.20889516521097307, 'Total loss': 0.20889516521097307}
2022-12-31 15:07:10,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:10,061 INFO:     Epoch: 96
2022-12-31 15:07:11,682 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48710085848967233, 'Total loss': 0.48710085848967233} | train loss {'Reaction outcome loss': 0.21057558296389528, 'Total loss': 0.21057558296389528}
2022-12-31 15:07:11,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:11,683 INFO:     Epoch: 97
2022-12-31 15:07:13,302 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5086142619450887, 'Total loss': 0.5086142619450887} | train loss {'Reaction outcome loss': 0.21308073878880013, 'Total loss': 0.21308073878880013}
2022-12-31 15:07:13,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:13,302 INFO:     Epoch: 98
2022-12-31 15:07:14,929 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4947299242019653, 'Total loss': 0.4947299242019653} | train loss {'Reaction outcome loss': 0.20598294270571174, 'Total loss': 0.20598294270571174}
2022-12-31 15:07:14,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:14,929 INFO:     Epoch: 99
2022-12-31 15:07:16,551 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4861346423625946, 'Total loss': 0.4861346423625946} | train loss {'Reaction outcome loss': 0.2191183696827088, 'Total loss': 0.2191183696827088}
2022-12-31 15:07:16,552 INFO:     Best model found after epoch 71 of 100.
2022-12-31 15:07:16,552 INFO:   Done with stage: TRAINING
2022-12-31 15:07:16,552 INFO:   Starting stage: EVALUATION
2022-12-31 15:07:16,674 INFO:   Done with stage: EVALUATION
2022-12-31 15:07:16,674 INFO:   Leaving out SEQ value Fold_5
2022-12-31 15:07:16,687 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 15:07:16,687 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:07:17,335 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:07:17,335 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:07:17,404 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:07:17,404 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:07:17,404 INFO:     No hyperparam tuning for this model
2022-12-31 15:07:17,404 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:07:17,404 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:07:17,405 INFO:     None feature selector for col prot
2022-12-31 15:07:17,405 INFO:     None feature selector for col prot
2022-12-31 15:07:17,405 INFO:     None feature selector for col prot
2022-12-31 15:07:17,406 INFO:     None feature selector for col chem
2022-12-31 15:07:17,406 INFO:     None feature selector for col chem
2022-12-31 15:07:17,406 INFO:     None feature selector for col chem
2022-12-31 15:07:17,406 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:07:17,406 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:07:17,408 INFO:     Number of params in model 223921
2022-12-31 15:07:17,411 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:07:17,411 INFO:   Starting stage: TRAINING
2022-12-31 15:07:17,455 INFO:     Val loss before train {'Reaction outcome loss': 0.886945366859436, 'Total loss': 0.886945366859436}
2022-12-31 15:07:17,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:17,455 INFO:     Epoch: 0
2022-12-31 15:07:19,092 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5820427000522613, 'Total loss': 0.5820427000522613} | train loss {'Reaction outcome loss': 0.8048194775942861, 'Total loss': 0.8048194775942861}
2022-12-31 15:07:19,093 INFO:     Found new best model at epoch 0
2022-12-31 15:07:19,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:19,094 INFO:     Epoch: 1
2022-12-31 15:07:20,731 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5441301226615906, 'Total loss': 0.5441301226615906} | train loss {'Reaction outcome loss': 0.5852985476758936, 'Total loss': 0.5852985476758936}
2022-12-31 15:07:20,731 INFO:     Found new best model at epoch 1
2022-12-31 15:07:20,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:20,732 INFO:     Epoch: 2
2022-12-31 15:07:22,375 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5042850991090139, 'Total loss': 0.5042850991090139} | train loss {'Reaction outcome loss': 0.5202523096051027, 'Total loss': 0.5202523096051027}
2022-12-31 15:07:22,376 INFO:     Found new best model at epoch 2
2022-12-31 15:07:22,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:22,377 INFO:     Epoch: 3
2022-12-31 15:07:23,985 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5156745135784149, 'Total loss': 0.5156745135784149} | train loss {'Reaction outcome loss': 0.4969281064151427, 'Total loss': 0.4969281064151427}
2022-12-31 15:07:23,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:23,986 INFO:     Epoch: 4
2022-12-31 15:07:25,616 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4730664253234863, 'Total loss': 0.4730664253234863} | train loss {'Reaction outcome loss': 0.48816522186628747, 'Total loss': 0.48816522186628747}
2022-12-31 15:07:25,617 INFO:     Found new best model at epoch 4
2022-12-31 15:07:25,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:25,618 INFO:     Epoch: 5
2022-12-31 15:07:27,233 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4799140214920044, 'Total loss': 0.4799140214920044} | train loss {'Reaction outcome loss': 0.47333663476072924, 'Total loss': 0.47333663476072924}
2022-12-31 15:07:27,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:27,233 INFO:     Epoch: 6
2022-12-31 15:07:28,855 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4533163507779439, 'Total loss': 0.4533163507779439} | train loss {'Reaction outcome loss': 0.4686749102514143, 'Total loss': 0.4686749102514143}
2022-12-31 15:07:28,855 INFO:     Found new best model at epoch 6
2022-12-31 15:07:28,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:28,856 INFO:     Epoch: 7
2022-12-31 15:07:30,479 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.503378822406133, 'Total loss': 0.503378822406133} | train loss {'Reaction outcome loss': 0.4566265454899103, 'Total loss': 0.4566265454899103}
2022-12-31 15:07:30,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:30,479 INFO:     Epoch: 8
2022-12-31 15:07:32,118 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4682726432879766, 'Total loss': 0.4682726432879766} | train loss {'Reaction outcome loss': 0.44787443125290993, 'Total loss': 0.44787443125290993}
2022-12-31 15:07:32,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:32,119 INFO:     Epoch: 9
2022-12-31 15:07:33,728 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47068496445814767, 'Total loss': 0.47068496445814767} | train loss {'Reaction outcome loss': 0.4420125289460382, 'Total loss': 0.4420125289460382}
2022-12-31 15:07:33,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:33,728 INFO:     Epoch: 10
2022-12-31 15:07:35,333 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4235967914263407, 'Total loss': 0.4235967914263407} | train loss {'Reaction outcome loss': 0.4378701890633855, 'Total loss': 0.4378701890633855}
2022-12-31 15:07:35,333 INFO:     Found new best model at epoch 10
2022-12-31 15:07:35,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:35,334 INFO:     Epoch: 11
2022-12-31 15:07:36,979 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4348821957906087, 'Total loss': 0.4348821957906087} | train loss {'Reaction outcome loss': 0.4273952167709812, 'Total loss': 0.4273952167709812}
2022-12-31 15:07:36,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:36,980 INFO:     Epoch: 12
2022-12-31 15:07:38,619 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4439947038888931, 'Total loss': 0.4439947038888931} | train loss {'Reaction outcome loss': 0.42396766146382703, 'Total loss': 0.42396766146382703}
2022-12-31 15:07:38,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:38,620 INFO:     Epoch: 13
2022-12-31 15:07:40,265 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44782647291819255, 'Total loss': 0.44782647291819255} | train loss {'Reaction outcome loss': 0.41842218235619233, 'Total loss': 0.41842218235619233}
2022-12-31 15:07:40,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:40,265 INFO:     Epoch: 14
2022-12-31 15:07:41,891 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45292095343271893, 'Total loss': 0.45292095343271893} | train loss {'Reaction outcome loss': 0.41552311085191446, 'Total loss': 0.41552311085191446}
2022-12-31 15:07:41,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:41,891 INFO:     Epoch: 15
2022-12-31 15:07:43,524 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43482172886530557, 'Total loss': 0.43482172886530557} | train loss {'Reaction outcome loss': 0.406764522974887, 'Total loss': 0.406764522974887}
2022-12-31 15:07:43,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:43,524 INFO:     Epoch: 16
2022-12-31 15:07:45,135 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4338960001866023, 'Total loss': 0.4338960001866023} | train loss {'Reaction outcome loss': 0.40965069313987496, 'Total loss': 0.40965069313987496}
2022-12-31 15:07:45,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:45,135 INFO:     Epoch: 17
2022-12-31 15:07:46,760 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4253773331642151, 'Total loss': 0.4253773331642151} | train loss {'Reaction outcome loss': 0.3993825203191072, 'Total loss': 0.3993825203191072}
2022-12-31 15:07:46,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:46,760 INFO:     Epoch: 18
2022-12-31 15:07:48,384 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44248831272125244, 'Total loss': 0.44248831272125244} | train loss {'Reaction outcome loss': 0.39467128132224516, 'Total loss': 0.39467128132224516}
2022-12-31 15:07:48,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:48,385 INFO:     Epoch: 19
2022-12-31 15:07:50,011 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4215066164731979, 'Total loss': 0.4215066164731979} | train loss {'Reaction outcome loss': 0.3880832938995172, 'Total loss': 0.3880832938995172}
2022-12-31 15:07:50,011 INFO:     Found new best model at epoch 19
2022-12-31 15:07:50,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:50,012 INFO:     Epoch: 20
2022-12-31 15:07:51,434 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4329253524541855, 'Total loss': 0.4329253524541855} | train loss {'Reaction outcome loss': 0.37481546644054164, 'Total loss': 0.37481546644054164}
2022-12-31 15:07:51,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:51,436 INFO:     Epoch: 21
2022-12-31 15:07:52,552 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4168877998987834, 'Total loss': 0.4168877998987834} | train loss {'Reaction outcome loss': 0.3788635578235134, 'Total loss': 0.3788635578235134}
2022-12-31 15:07:52,552 INFO:     Found new best model at epoch 21
2022-12-31 15:07:52,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:52,553 INFO:     Epoch: 22
2022-12-31 15:07:53,652 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4338954448699951, 'Total loss': 0.4338954448699951} | train loss {'Reaction outcome loss': 0.36909245398393176, 'Total loss': 0.36909245398393176}
2022-12-31 15:07:53,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:53,652 INFO:     Epoch: 23
2022-12-31 15:07:54,757 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4459816485643387, 'Total loss': 0.4459816485643387} | train loss {'Reaction outcome loss': 0.3637841861385731, 'Total loss': 0.3637841861385731}
2022-12-31 15:07:54,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:54,757 INFO:     Epoch: 24
2022-12-31 15:07:56,001 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42085169851779936, 'Total loss': 0.42085169851779936} | train loss {'Reaction outcome loss': 0.35945414673765647, 'Total loss': 0.35945414673765647}
2022-12-31 15:07:56,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:56,002 INFO:     Epoch: 25
2022-12-31 15:07:57,633 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4376942018667857, 'Total loss': 0.4376942018667857} | train loss {'Reaction outcome loss': 0.35287125965425686, 'Total loss': 0.35287125965425686}
2022-12-31 15:07:57,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:57,634 INFO:     Epoch: 26
2022-12-31 15:07:59,272 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4411059116323789, 'Total loss': 0.4411059116323789} | train loss {'Reaction outcome loss': 0.35537351600637507, 'Total loss': 0.35537351600637507}
2022-12-31 15:07:59,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:07:59,272 INFO:     Epoch: 27
2022-12-31 15:08:00,899 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3927292267481486, 'Total loss': 0.3927292267481486} | train loss {'Reaction outcome loss': 0.3418706132078859, 'Total loss': 0.3418706132078859}
2022-12-31 15:08:00,899 INFO:     Found new best model at epoch 27
2022-12-31 15:08:00,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:00,900 INFO:     Epoch: 28
2022-12-31 15:08:02,541 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3929657111565272, 'Total loss': 0.3929657111565272} | train loss {'Reaction outcome loss': 0.3450738745220409, 'Total loss': 0.3450738745220409}
2022-12-31 15:08:02,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:02,541 INFO:     Epoch: 29
2022-12-31 15:08:04,160 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42500874648491543, 'Total loss': 0.42500874648491543} | train loss {'Reaction outcome loss': 0.3354965625364428, 'Total loss': 0.3354965625364428}
2022-12-31 15:08:04,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:04,160 INFO:     Epoch: 30
2022-12-31 15:08:05,781 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40649716754754384, 'Total loss': 0.40649716754754384} | train loss {'Reaction outcome loss': 0.33324322815890345, 'Total loss': 0.33324322815890345}
2022-12-31 15:08:05,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:05,781 INFO:     Epoch: 31
2022-12-31 15:08:07,407 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42674965461095177, 'Total loss': 0.42674965461095177} | train loss {'Reaction outcome loss': 0.3264959099221746, 'Total loss': 0.3264959099221746}
2022-12-31 15:08:07,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:07,408 INFO:     Epoch: 32
2022-12-31 15:08:09,034 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39282792011896767, 'Total loss': 0.39282792011896767} | train loss {'Reaction outcome loss': 0.3178268576087934, 'Total loss': 0.3178268576087934}
2022-12-31 15:08:09,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:09,034 INFO:     Epoch: 33
2022-12-31 15:08:10,638 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4033497412999471, 'Total loss': 0.4033497412999471} | train loss {'Reaction outcome loss': 0.320428852301212, 'Total loss': 0.320428852301212}
2022-12-31 15:08:10,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:10,639 INFO:     Epoch: 34
2022-12-31 15:08:12,266 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.36170827051003773, 'Total loss': 0.36170827051003773} | train loss {'Reaction outcome loss': 0.32126191665926135, 'Total loss': 0.32126191665926135}
2022-12-31 15:08:12,267 INFO:     Found new best model at epoch 34
2022-12-31 15:08:12,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:12,268 INFO:     Epoch: 35
2022-12-31 15:08:13,882 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.36807525033752125, 'Total loss': 0.36807525033752125} | train loss {'Reaction outcome loss': 0.3077673802844884, 'Total loss': 0.3077673802844884}
2022-12-31 15:08:13,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:13,882 INFO:     Epoch: 36
2022-12-31 15:08:15,535 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3623242874940236, 'Total loss': 0.3623242874940236} | train loss {'Reaction outcome loss': 0.3072538665808495, 'Total loss': 0.3072538665808495}
2022-12-31 15:08:15,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:15,535 INFO:     Epoch: 37
2022-12-31 15:08:17,197 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4189233342806498, 'Total loss': 0.4189233342806498} | train loss {'Reaction outcome loss': 0.30447914198525117, 'Total loss': 0.30447914198525117}
2022-12-31 15:08:17,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:17,197 INFO:     Epoch: 38
2022-12-31 15:08:18,828 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4202383617560069, 'Total loss': 0.4202383617560069} | train loss {'Reaction outcome loss': 0.29999360717187507, 'Total loss': 0.29999360717187507}
2022-12-31 15:08:18,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:18,828 INFO:     Epoch: 39
2022-12-31 15:08:20,454 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39997622072696687, 'Total loss': 0.39997622072696687} | train loss {'Reaction outcome loss': 0.3021740937598776, 'Total loss': 0.3021740937598776}
2022-12-31 15:08:20,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:20,454 INFO:     Epoch: 40
2022-12-31 15:08:22,086 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4266162802775701, 'Total loss': 0.4266162802775701} | train loss {'Reaction outcome loss': 0.28969386308739764, 'Total loss': 0.28969386308739764}
2022-12-31 15:08:22,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:22,087 INFO:     Epoch: 41
2022-12-31 15:08:23,708 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4004802664120992, 'Total loss': 0.4004802664120992} | train loss {'Reaction outcome loss': 0.28916676554976817, 'Total loss': 0.28916676554976817}
2022-12-31 15:08:23,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:23,708 INFO:     Epoch: 42
2022-12-31 15:08:25,336 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3991973380247752, 'Total loss': 0.3991973380247752} | train loss {'Reaction outcome loss': 0.2874391831000359, 'Total loss': 0.2874391831000359}
2022-12-31 15:08:25,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:25,336 INFO:     Epoch: 43
2022-12-31 15:08:26,957 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40110483169555666, 'Total loss': 0.40110483169555666} | train loss {'Reaction outcome loss': 0.28348408295144245, 'Total loss': 0.28348408295144245}
2022-12-31 15:08:26,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:26,957 INFO:     Epoch: 44
2022-12-31 15:08:28,573 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.35311853090922035, 'Total loss': 0.35311853090922035} | train loss {'Reaction outcome loss': 0.2831973520642153, 'Total loss': 0.2831973520642153}
2022-12-31 15:08:28,574 INFO:     Found new best model at epoch 44
2022-12-31 15:08:28,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:28,575 INFO:     Epoch: 45
2022-12-31 15:08:30,193 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38807141880194346, 'Total loss': 0.38807141880194346} | train loss {'Reaction outcome loss': 0.27696734604960316, 'Total loss': 0.27696734604960316}
2022-12-31 15:08:30,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:30,193 INFO:     Epoch: 46
2022-12-31 15:08:31,830 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3977439612150192, 'Total loss': 0.3977439612150192} | train loss {'Reaction outcome loss': 0.2790738332492135, 'Total loss': 0.2790738332492135}
2022-12-31 15:08:31,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:31,830 INFO:     Epoch: 47
2022-12-31 15:08:33,460 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38508974611759184, 'Total loss': 0.38508974611759184} | train loss {'Reaction outcome loss': 0.26982114121102685, 'Total loss': 0.26982114121102685}
2022-12-31 15:08:33,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:33,460 INFO:     Epoch: 48
2022-12-31 15:08:35,116 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3730512301127116, 'Total loss': 0.3730512301127116} | train loss {'Reaction outcome loss': 0.263457046505669, 'Total loss': 0.263457046505669}
2022-12-31 15:08:35,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:35,116 INFO:     Epoch: 49
2022-12-31 15:08:36,752 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3846810301144918, 'Total loss': 0.3846810301144918} | train loss {'Reaction outcome loss': 0.26802184002386537, 'Total loss': 0.26802184002386537}
2022-12-31 15:08:36,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:36,753 INFO:     Epoch: 50
2022-12-31 15:08:38,408 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.36084384719530743, 'Total loss': 0.36084384719530743} | train loss {'Reaction outcome loss': 0.2584146962833964, 'Total loss': 0.2584146962833964}
2022-12-31 15:08:38,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:38,409 INFO:     Epoch: 51
2022-12-31 15:08:40,032 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3844696129361788, 'Total loss': 0.3844696129361788} | train loss {'Reaction outcome loss': 0.2678085746586538, 'Total loss': 0.2678085746586538}
2022-12-31 15:08:40,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:40,032 INFO:     Epoch: 52
2022-12-31 15:08:41,666 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40076669653256736, 'Total loss': 0.40076669653256736} | train loss {'Reaction outcome loss': 0.26275675940169324, 'Total loss': 0.26275675940169324}
2022-12-31 15:08:41,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:41,667 INFO:     Epoch: 53
2022-12-31 15:08:43,318 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.35940344383319217, 'Total loss': 0.35940344383319217} | train loss {'Reaction outcome loss': 0.2536595460794032, 'Total loss': 0.2536595460794032}
2022-12-31 15:08:43,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:43,318 INFO:     Epoch: 54
2022-12-31 15:08:44,969 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3838794449965159, 'Total loss': 0.3838794449965159} | train loss {'Reaction outcome loss': 0.2554636955234333, 'Total loss': 0.2554636955234333}
2022-12-31 15:08:44,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:44,970 INFO:     Epoch: 55
2022-12-31 15:08:46,589 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3607377290725708, 'Total loss': 0.3607377290725708} | train loss {'Reaction outcome loss': 0.2581431685614026, 'Total loss': 0.2581431685614026}
2022-12-31 15:08:46,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:46,590 INFO:     Epoch: 56
2022-12-31 15:08:48,249 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39480150838692984, 'Total loss': 0.39480150838692984} | train loss {'Reaction outcome loss': 0.2514206638848846, 'Total loss': 0.2514206638848846}
2022-12-31 15:08:48,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:48,249 INFO:     Epoch: 57
2022-12-31 15:08:49,909 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3560119703412056, 'Total loss': 0.3560119703412056} | train loss {'Reaction outcome loss': 0.24746846266440536, 'Total loss': 0.24746846266440536}
2022-12-31 15:08:49,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:49,910 INFO:     Epoch: 58
2022-12-31 15:08:51,534 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39821120897928874, 'Total loss': 0.39821120897928874} | train loss {'Reaction outcome loss': 0.24432640787657847, 'Total loss': 0.24432640787657847}
2022-12-31 15:08:51,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:51,534 INFO:     Epoch: 59
2022-12-31 15:08:53,166 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38546442091464994, 'Total loss': 0.38546442091464994} | train loss {'Reaction outcome loss': 0.24817832458481892, 'Total loss': 0.24817832458481892}
2022-12-31 15:08:53,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:53,167 INFO:     Epoch: 60
2022-12-31 15:08:54,824 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36743649492661157, 'Total loss': 0.36743649492661157} | train loss {'Reaction outcome loss': 0.24431075261979757, 'Total loss': 0.24431075261979757}
2022-12-31 15:08:54,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:54,824 INFO:     Epoch: 61
2022-12-31 15:08:56,424 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37717008690039316, 'Total loss': 0.37717008690039316} | train loss {'Reaction outcome loss': 0.2433877929184411, 'Total loss': 0.2433877929184411}
2022-12-31 15:08:56,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:56,424 INFO:     Epoch: 62
2022-12-31 15:08:58,041 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3564199542005857, 'Total loss': 0.3564199542005857} | train loss {'Reaction outcome loss': 0.2406777486151306, 'Total loss': 0.2406777486151306}
2022-12-31 15:08:58,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:58,041 INFO:     Epoch: 63
2022-12-31 15:08:59,648 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36800059378147126, 'Total loss': 0.36800059378147126} | train loss {'Reaction outcome loss': 0.24316367647519826, 'Total loss': 0.24316367647519826}
2022-12-31 15:08:59,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:08:59,649 INFO:     Epoch: 64
2022-12-31 15:09:01,301 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37963828146457673, 'Total loss': 0.37963828146457673} | train loss {'Reaction outcome loss': 0.2380558328588732, 'Total loss': 0.2380558328588732}
2022-12-31 15:09:01,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:01,301 INFO:     Epoch: 65
2022-12-31 15:09:02,916 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39992503772179283, 'Total loss': 0.39992503772179283} | train loss {'Reaction outcome loss': 0.2378051311503894, 'Total loss': 0.2378051311503894}
2022-12-31 15:09:02,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:02,916 INFO:     Epoch: 66
2022-12-31 15:09:04,542 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.35995163172483446, 'Total loss': 0.35995163172483446} | train loss {'Reaction outcome loss': 0.22990442741164663, 'Total loss': 0.22990442741164663}
2022-12-31 15:09:04,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:04,543 INFO:     Epoch: 67
2022-12-31 15:09:06,179 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38247577945391337, 'Total loss': 0.38247577945391337} | train loss {'Reaction outcome loss': 0.2333430287424838, 'Total loss': 0.2333430287424838}
2022-12-31 15:09:06,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:06,179 INFO:     Epoch: 68
2022-12-31 15:09:07,803 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4026506265004476, 'Total loss': 0.4026506265004476} | train loss {'Reaction outcome loss': 0.23684820031162204, 'Total loss': 0.23684820031162204}
2022-12-31 15:09:07,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:07,803 INFO:     Epoch: 69
2022-12-31 15:09:09,421 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.37945736447970074, 'Total loss': 0.37945736447970074} | train loss {'Reaction outcome loss': 0.227162162521148, 'Total loss': 0.227162162521148}
2022-12-31 15:09:09,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:09,422 INFO:     Epoch: 70
2022-12-31 15:09:11,069 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3658615410327911, 'Total loss': 0.3658615410327911} | train loss {'Reaction outcome loss': 0.2263943773933051, 'Total loss': 0.2263943773933051}
2022-12-31 15:09:11,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:11,070 INFO:     Epoch: 71
2022-12-31 15:09:12,718 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3776832436521848, 'Total loss': 0.3776832436521848} | train loss {'Reaction outcome loss': 0.23466351869035285, 'Total loss': 0.23466351869035285}
2022-12-31 15:09:12,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:12,719 INFO:     Epoch: 72
2022-12-31 15:09:14,331 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.35479938983917236, 'Total loss': 0.35479938983917236} | train loss {'Reaction outcome loss': 0.2306156644281605, 'Total loss': 0.2306156644281605}
2022-12-31 15:09:14,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:14,331 INFO:     Epoch: 73
2022-12-31 15:09:15,967 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37396580129861834, 'Total loss': 0.37396580129861834} | train loss {'Reaction outcome loss': 0.2325086076861577, 'Total loss': 0.2325086076861577}
2022-12-31 15:09:15,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:15,968 INFO:     Epoch: 74
2022-12-31 15:09:17,596 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38131197293599445, 'Total loss': 0.38131197293599445} | train loss {'Reaction outcome loss': 0.2223126369962193, 'Total loss': 0.2223126369962193}
2022-12-31 15:09:17,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:17,597 INFO:     Epoch: 75
2022-12-31 15:09:19,240 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3892175228645404, 'Total loss': 0.3892175228645404} | train loss {'Reaction outcome loss': 0.22527258287079713, 'Total loss': 0.22527258287079713}
2022-12-31 15:09:19,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:19,240 INFO:     Epoch: 76
2022-12-31 15:09:20,880 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.35769016842047374, 'Total loss': 0.35769016842047374} | train loss {'Reaction outcome loss': 0.22664384391925396, 'Total loss': 0.22664384391925396}
2022-12-31 15:09:20,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:20,881 INFO:     Epoch: 77
2022-12-31 15:09:22,500 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3952027420202891, 'Total loss': 0.3952027420202891} | train loss {'Reaction outcome loss': 0.21833568350798602, 'Total loss': 0.21833568350798602}
2022-12-31 15:09:22,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:22,501 INFO:     Epoch: 78
2022-12-31 15:09:24,121 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3669787625471751, 'Total loss': 0.3669787625471751} | train loss {'Reaction outcome loss': 0.21791519689968777, 'Total loss': 0.21791519689968777}
2022-12-31 15:09:24,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:24,122 INFO:     Epoch: 79
2022-12-31 15:09:25,740 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.35096321304639183, 'Total loss': 0.35096321304639183} | train loss {'Reaction outcome loss': 0.2208622976438233, 'Total loss': 0.2208622976438233}
2022-12-31 15:09:25,740 INFO:     Found new best model at epoch 79
2022-12-31 15:09:25,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:25,741 INFO:     Epoch: 80
2022-12-31 15:09:27,361 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3923076604803403, 'Total loss': 0.3923076604803403} | train loss {'Reaction outcome loss': 0.2177512916376552, 'Total loss': 0.2177512916376552}
2022-12-31 15:09:27,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:27,361 INFO:     Epoch: 81
2022-12-31 15:09:29,016 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4006532286604246, 'Total loss': 0.4006532286604246} | train loss {'Reaction outcome loss': 0.21702026346503397, 'Total loss': 0.21702026346503397}
2022-12-31 15:09:29,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:29,016 INFO:     Epoch: 82
2022-12-31 15:09:30,668 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4055531809727351, 'Total loss': 0.4055531809727351} | train loss {'Reaction outcome loss': 0.2197192799542032, 'Total loss': 0.2197192799542032}
2022-12-31 15:09:30,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:30,669 INFO:     Epoch: 83
2022-12-31 15:09:32,279 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37661314010620117, 'Total loss': 0.37661314010620117} | train loss {'Reaction outcome loss': 0.21074402634565473, 'Total loss': 0.21074402634565473}
2022-12-31 15:09:32,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:32,280 INFO:     Epoch: 84
2022-12-31 15:09:33,933 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.387477707862854, 'Total loss': 0.387477707862854} | train loss {'Reaction outcome loss': 0.21527656781006377, 'Total loss': 0.21527656781006377}
2022-12-31 15:09:33,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:33,933 INFO:     Epoch: 85
2022-12-31 15:09:35,580 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37845347821712494, 'Total loss': 0.37845347821712494} | train loss {'Reaction outcome loss': 0.21176799960326848, 'Total loss': 0.21176799960326848}
2022-12-31 15:09:35,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:35,580 INFO:     Epoch: 86
2022-12-31 15:09:37,217 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3542340305944284, 'Total loss': 0.3542340305944284} | train loss {'Reaction outcome loss': 0.21191349777557789, 'Total loss': 0.21191349777557789}
2022-12-31 15:09:37,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:37,217 INFO:     Epoch: 87
2022-12-31 15:09:38,876 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.33641057908535005, 'Total loss': 0.33641057908535005} | train loss {'Reaction outcome loss': 0.2101617024451602, 'Total loss': 0.2101617024451602}
2022-12-31 15:09:38,876 INFO:     Found new best model at epoch 87
2022-12-31 15:09:38,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:38,877 INFO:     Epoch: 88
2022-12-31 15:09:40,470 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.365752703944842, 'Total loss': 0.365752703944842} | train loss {'Reaction outcome loss': 0.21292893158184492, 'Total loss': 0.21292893158184492}
2022-12-31 15:09:40,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:40,470 INFO:     Epoch: 89
2022-12-31 15:09:42,107 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3820976257324219, 'Total loss': 0.3820976257324219} | train loss {'Reaction outcome loss': 0.2034396669333162, 'Total loss': 0.2034396669333162}
2022-12-31 15:09:42,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:42,108 INFO:     Epoch: 90
2022-12-31 15:09:43,731 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3905650168657303, 'Total loss': 0.3905650168657303} | train loss {'Reaction outcome loss': 0.2042026074219912, 'Total loss': 0.2042026074219912}
2022-12-31 15:09:43,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:43,732 INFO:     Epoch: 91
2022-12-31 15:09:45,347 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3973517566919327, 'Total loss': 0.3973517566919327} | train loss {'Reaction outcome loss': 0.20926748219514366, 'Total loss': 0.20926748219514366}
2022-12-31 15:09:45,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:45,347 INFO:     Epoch: 92
2022-12-31 15:09:46,976 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3745215783516566, 'Total loss': 0.3745215783516566} | train loss {'Reaction outcome loss': 0.20552953545152064, 'Total loss': 0.20552953545152064}
2022-12-31 15:09:46,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:46,976 INFO:     Epoch: 93
2022-12-31 15:09:48,631 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3494782269001007, 'Total loss': 0.3494782269001007} | train loss {'Reaction outcome loss': 0.2042198866498169, 'Total loss': 0.2042198866498169}
2022-12-31 15:09:48,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:48,631 INFO:     Epoch: 94
2022-12-31 15:09:50,254 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.33952324390411376, 'Total loss': 0.33952324390411376} | train loss {'Reaction outcome loss': 0.2134465844259473, 'Total loss': 0.2134465844259473}
2022-12-31 15:09:50,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:50,255 INFO:     Epoch: 95
2022-12-31 15:09:51,874 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37395789052049316, 'Total loss': 0.37395789052049316} | train loss {'Reaction outcome loss': 0.20065468927636904, 'Total loss': 0.20065468927636904}
2022-12-31 15:09:51,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:51,874 INFO:     Epoch: 96
2022-12-31 15:09:53,495 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39520411292711893, 'Total loss': 0.39520411292711893} | train loss {'Reaction outcome loss': 0.19786326971833026, 'Total loss': 0.19786326971833026}
2022-12-31 15:09:53,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:53,495 INFO:     Epoch: 97
2022-12-31 15:09:55,119 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4048622190952301, 'Total loss': 0.4048622190952301} | train loss {'Reaction outcome loss': 0.21465456075562897, 'Total loss': 0.21465456075562897}
2022-12-31 15:09:55,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:55,119 INFO:     Epoch: 98
2022-12-31 15:09:56,754 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46161538163820903, 'Total loss': 0.46161538163820903} | train loss {'Reaction outcome loss': 0.20423737528064836, 'Total loss': 0.20423737528064836}
2022-12-31 15:09:56,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:56,754 INFO:     Epoch: 99
2022-12-31 15:09:58,399 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3997343694170316, 'Total loss': 0.3997343694170316} | train loss {'Reaction outcome loss': 0.19977892265866917, 'Total loss': 0.19977892265866917}
2022-12-31 15:09:58,400 INFO:     Best model found after epoch 88 of 100.
2022-12-31 15:09:58,400 INFO:   Done with stage: TRAINING
2022-12-31 15:09:58,400 INFO:   Starting stage: EVALUATION
2022-12-31 15:09:58,524 INFO:   Done with stage: EVALUATION
2022-12-31 15:09:58,524 INFO:   Leaving out SEQ value Fold_6
2022-12-31 15:09:58,537 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 15:09:58,537 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:09:59,192 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:09:59,193 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:09:59,262 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:09:59,262 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:09:59,262 INFO:     No hyperparam tuning for this model
2022-12-31 15:09:59,262 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:09:59,262 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:09:59,263 INFO:     None feature selector for col prot
2022-12-31 15:09:59,263 INFO:     None feature selector for col prot
2022-12-31 15:09:59,263 INFO:     None feature selector for col prot
2022-12-31 15:09:59,264 INFO:     None feature selector for col chem
2022-12-31 15:09:59,264 INFO:     None feature selector for col chem
2022-12-31 15:09:59,264 INFO:     None feature selector for col chem
2022-12-31 15:09:59,264 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:09:59,264 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:09:59,266 INFO:     Number of params in model 223921
2022-12-31 15:09:59,269 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:09:59,269 INFO:   Starting stage: TRAINING
2022-12-31 15:09:59,313 INFO:     Val loss before train {'Reaction outcome loss': 0.9123462557792663, 'Total loss': 0.9123462557792663}
2022-12-31 15:09:59,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:09:59,314 INFO:     Epoch: 0
2022-12-31 15:10:00,933 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5878515938917795, 'Total loss': 0.5878515938917795} | train loss {'Reaction outcome loss': 0.8073730622603145, 'Total loss': 0.8073730622603145}
2022-12-31 15:10:00,933 INFO:     Found new best model at epoch 0
2022-12-31 15:10:00,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:00,934 INFO:     Epoch: 1
2022-12-31 15:10:02,555 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5271924614906311, 'Total loss': 0.5271924614906311} | train loss {'Reaction outcome loss': 0.5865919530822051, 'Total loss': 0.5865919530822051}
2022-12-31 15:10:02,555 INFO:     Found new best model at epoch 1
2022-12-31 15:10:02,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:02,556 INFO:     Epoch: 2
2022-12-31 15:10:04,184 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49410699009895326, 'Total loss': 0.49410699009895326} | train loss {'Reaction outcome loss': 0.5329651563068589, 'Total loss': 0.5329651563068589}
2022-12-31 15:10:04,185 INFO:     Found new best model at epoch 2
2022-12-31 15:10:04,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:04,186 INFO:     Epoch: 3
2022-12-31 15:10:05,816 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4768651266892751, 'Total loss': 0.4768651266892751} | train loss {'Reaction outcome loss': 0.49769333047987324, 'Total loss': 0.49769333047987324}
2022-12-31 15:10:05,817 INFO:     Found new best model at epoch 3
2022-12-31 15:10:05,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:05,818 INFO:     Epoch: 4
2022-12-31 15:10:07,450 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4960488925377528, 'Total loss': 0.4960488925377528} | train loss {'Reaction outcome loss': 0.48752117931627625, 'Total loss': 0.48752117931627625}
2022-12-31 15:10:07,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:07,450 INFO:     Epoch: 5
2022-12-31 15:10:09,073 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4691626787185669, 'Total loss': 0.4691626787185669} | train loss {'Reaction outcome loss': 0.4746923536492599, 'Total loss': 0.4746923536492599}
2022-12-31 15:10:09,073 INFO:     Found new best model at epoch 5
2022-12-31 15:10:09,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:09,074 INFO:     Epoch: 6
2022-12-31 15:10:10,724 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4524470314383507, 'Total loss': 0.4524470314383507} | train loss {'Reaction outcome loss': 0.4657072365714324, 'Total loss': 0.4657072365714324}
2022-12-31 15:10:10,724 INFO:     Found new best model at epoch 6
2022-12-31 15:10:10,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:10,725 INFO:     Epoch: 7
2022-12-31 15:10:12,349 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4699255267779032, 'Total loss': 0.4699255267779032} | train loss {'Reaction outcome loss': 0.4575467881635638, 'Total loss': 0.4575467881635638}
2022-12-31 15:10:12,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:12,349 INFO:     Epoch: 8
2022-12-31 15:10:13,988 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43860144515832267, 'Total loss': 0.43860144515832267} | train loss {'Reaction outcome loss': 0.45127620114961686, 'Total loss': 0.45127620114961686}
2022-12-31 15:10:13,988 INFO:     Found new best model at epoch 8
2022-12-31 15:10:13,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:13,989 INFO:     Epoch: 9
2022-12-31 15:10:15,641 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4418872078259786, 'Total loss': 0.4418872078259786} | train loss {'Reaction outcome loss': 0.4442163325496529, 'Total loss': 0.4442163325496529}
2022-12-31 15:10:15,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:15,641 INFO:     Epoch: 10
2022-12-31 15:10:17,267 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4480892737706502, 'Total loss': 0.4480892737706502} | train loss {'Reaction outcome loss': 0.437070008999389, 'Total loss': 0.437070008999389}
2022-12-31 15:10:17,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:17,268 INFO:     Epoch: 11
2022-12-31 15:10:18,912 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43827540377775825, 'Total loss': 0.43827540377775825} | train loss {'Reaction outcome loss': 0.4289041474084992, 'Total loss': 0.4289041474084992}
2022-12-31 15:10:18,913 INFO:     Found new best model at epoch 11
2022-12-31 15:10:18,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:18,914 INFO:     Epoch: 12
2022-12-31 15:10:20,549 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4117990702390671, 'Total loss': 0.4117990702390671} | train loss {'Reaction outcome loss': 0.4231694201108351, 'Total loss': 0.4231694201108351}
2022-12-31 15:10:20,549 INFO:     Found new best model at epoch 12
2022-12-31 15:10:20,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:20,550 INFO:     Epoch: 13
2022-12-31 15:10:22,182 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4380784571170807, 'Total loss': 0.4380784571170807} | train loss {'Reaction outcome loss': 0.42071292003354444, 'Total loss': 0.42071292003354444}
2022-12-31 15:10:22,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:22,183 INFO:     Epoch: 14
2022-12-31 15:10:23,817 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41252018411954244, 'Total loss': 0.41252018411954244} | train loss {'Reaction outcome loss': 0.4158995212307906, 'Total loss': 0.4158995212307906}
2022-12-31 15:10:23,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:23,817 INFO:     Epoch: 15
2022-12-31 15:10:25,463 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44318680961926776, 'Total loss': 0.44318680961926776} | train loss {'Reaction outcome loss': 0.4114645229995466, 'Total loss': 0.4114645229995466}
2022-12-31 15:10:25,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:25,464 INFO:     Epoch: 16
2022-12-31 15:10:27,086 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4180312931537628, 'Total loss': 0.4180312931537628} | train loss {'Reaction outcome loss': 0.4045809451961345, 'Total loss': 0.4045809451961345}
2022-12-31 15:10:27,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:27,087 INFO:     Epoch: 17
2022-12-31 15:10:28,716 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4330634166797002, 'Total loss': 0.4330634166797002} | train loss {'Reaction outcome loss': 0.4009582799210445, 'Total loss': 0.4009582799210445}
2022-12-31 15:10:28,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:28,716 INFO:     Epoch: 18
2022-12-31 15:10:30,339 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4116715848445892, 'Total loss': 0.4116715848445892} | train loss {'Reaction outcome loss': 0.39508308805121845, 'Total loss': 0.39508308805121845}
2022-12-31 15:10:30,339 INFO:     Found new best model at epoch 18
2022-12-31 15:10:30,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:30,340 INFO:     Epoch: 19
2022-12-31 15:10:31,967 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38936992635329565, 'Total loss': 0.38936992635329565} | train loss {'Reaction outcome loss': 0.3848428304176038, 'Total loss': 0.3848428304176038}
2022-12-31 15:10:31,967 INFO:     Found new best model at epoch 19
2022-12-31 15:10:31,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:31,968 INFO:     Epoch: 20
2022-12-31 15:10:33,625 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3858937640984853, 'Total loss': 0.3858937640984853} | train loss {'Reaction outcome loss': 0.3830262499353731, 'Total loss': 0.3830262499353731}
2022-12-31 15:10:33,626 INFO:     Found new best model at epoch 20
2022-12-31 15:10:33,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:33,627 INFO:     Epoch: 21
2022-12-31 15:10:35,244 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3940909663836161, 'Total loss': 0.3940909663836161} | train loss {'Reaction outcome loss': 0.37525324144195565, 'Total loss': 0.37525324144195565}
2022-12-31 15:10:35,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:35,245 INFO:     Epoch: 22
2022-12-31 15:10:36,880 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38028549949328105, 'Total loss': 0.38028549949328105} | train loss {'Reaction outcome loss': 0.3748200393755944, 'Total loss': 0.3748200393755944}
2022-12-31 15:10:36,880 INFO:     Found new best model at epoch 22
2022-12-31 15:10:36,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:36,881 INFO:     Epoch: 23
2022-12-31 15:10:38,508 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.361681134502093, 'Total loss': 0.361681134502093} | train loss {'Reaction outcome loss': 0.36640223979089237, 'Total loss': 0.36640223979089237}
2022-12-31 15:10:38,508 INFO:     Found new best model at epoch 23
2022-12-31 15:10:38,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:38,509 INFO:     Epoch: 24
2022-12-31 15:10:40,125 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38645961582660676, 'Total loss': 0.38645961582660676} | train loss {'Reaction outcome loss': 0.3614344716018288, 'Total loss': 0.3614344716018288}
2022-12-31 15:10:40,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:40,125 INFO:     Epoch: 25
2022-12-31 15:10:41,753 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3700948784748713, 'Total loss': 0.3700948784748713} | train loss {'Reaction outcome loss': 0.3578064824699925, 'Total loss': 0.3578064824699925}
2022-12-31 15:10:41,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:41,754 INFO:     Epoch: 26
2022-12-31 15:10:43,387 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.37864470581213633, 'Total loss': 0.37864470581213633} | train loss {'Reaction outcome loss': 0.35223169665151555, 'Total loss': 0.35223169665151555}
2022-12-31 15:10:43,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:43,387 INFO:     Epoch: 27
2022-12-31 15:10:45,015 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3714145412047704, 'Total loss': 0.3714145412047704} | train loss {'Reaction outcome loss': 0.35092546884979153, 'Total loss': 0.35092546884979153}
2022-12-31 15:10:45,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:45,015 INFO:     Epoch: 28
2022-12-31 15:10:46,653 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3720238586266836, 'Total loss': 0.3720238586266836} | train loss {'Reaction outcome loss': 0.3410564441812168, 'Total loss': 0.3410564441812168}
2022-12-31 15:10:46,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:46,654 INFO:     Epoch: 29
2022-12-31 15:10:48,309 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39019112586975097, 'Total loss': 0.39019112586975097} | train loss {'Reaction outcome loss': 0.3383091927543014, 'Total loss': 0.3383091927543014}
2022-12-31 15:10:48,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:48,310 INFO:     Epoch: 30
2022-12-31 15:10:49,925 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3956388642390569, 'Total loss': 0.3956388642390569} | train loss {'Reaction outcome loss': 0.3374959477341132, 'Total loss': 0.3374959477341132}
2022-12-31 15:10:49,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:49,925 INFO:     Epoch: 31
2022-12-31 15:10:51,569 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41132644017537434, 'Total loss': 0.41132644017537434} | train loss {'Reaction outcome loss': 0.3267446782453396, 'Total loss': 0.3267446782453396}
2022-12-31 15:10:51,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:51,569 INFO:     Epoch: 32
2022-12-31 15:10:53,180 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3501385380824407, 'Total loss': 0.3501385380824407} | train loss {'Reaction outcome loss': 0.31908260600553956, 'Total loss': 0.31908260600553956}
2022-12-31 15:10:53,180 INFO:     Found new best model at epoch 32
2022-12-31 15:10:53,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:53,181 INFO:     Epoch: 33
2022-12-31 15:10:54,809 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3617577170332273, 'Total loss': 0.3617577170332273} | train loss {'Reaction outcome loss': 0.31427818551551995, 'Total loss': 0.31427818551551995}
2022-12-31 15:10:54,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:54,810 INFO:     Epoch: 34
2022-12-31 15:10:56,445 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37001944084962207, 'Total loss': 0.37001944084962207} | train loss {'Reaction outcome loss': 0.31737724263960704, 'Total loss': 0.31737724263960704}
2022-12-31 15:10:56,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:56,445 INFO:     Epoch: 35
2022-12-31 15:10:58,075 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3481293300787608, 'Total loss': 0.3481293300787608} | train loss {'Reaction outcome loss': 0.3103109121537811, 'Total loss': 0.3103109121537811}
2022-12-31 15:10:58,075 INFO:     Found new best model at epoch 35
2022-12-31 15:10:58,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:58,076 INFO:     Epoch: 36
2022-12-31 15:10:59,729 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3737207531929016, 'Total loss': 0.3737207531929016} | train loss {'Reaction outcome loss': 0.3093859457044395, 'Total loss': 0.3093859457044395}
2022-12-31 15:10:59,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:10:59,729 INFO:     Epoch: 37
2022-12-31 15:11:01,371 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3578084260225296, 'Total loss': 0.3578084260225296} | train loss {'Reaction outcome loss': 0.3061924181502003, 'Total loss': 0.3061924181502003}
2022-12-31 15:11:01,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:01,372 INFO:     Epoch: 38
2022-12-31 15:11:02,995 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3673602526386579, 'Total loss': 0.3673602526386579} | train loss {'Reaction outcome loss': 0.30379637138454063, 'Total loss': 0.30379637138454063}
2022-12-31 15:11:02,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:02,996 INFO:     Epoch: 39
2022-12-31 15:11:04,644 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.33851113468408583, 'Total loss': 0.33851113468408583} | train loss {'Reaction outcome loss': 0.29824849044641866, 'Total loss': 0.29824849044641866}
2022-12-31 15:11:04,644 INFO:     Found new best model at epoch 39
2022-12-31 15:11:04,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:04,645 INFO:     Epoch: 40
2022-12-31 15:11:06,276 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3899039874474208, 'Total loss': 0.3899039874474208} | train loss {'Reaction outcome loss': 0.29704551470032237, 'Total loss': 0.29704551470032237}
2022-12-31 15:11:06,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:06,278 INFO:     Epoch: 41
2022-12-31 15:11:07,912 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.33982297281424206, 'Total loss': 0.33982297281424206} | train loss {'Reaction outcome loss': 0.2946120224059274, 'Total loss': 0.2946120224059274}
2022-12-31 15:11:07,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:07,912 INFO:     Epoch: 42
2022-12-31 15:11:09,574 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3856473445892334, 'Total loss': 0.3856473445892334} | train loss {'Reaction outcome loss': 0.2862565199363748, 'Total loss': 0.2862565199363748}
2022-12-31 15:11:09,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:09,574 INFO:     Epoch: 43
2022-12-31 15:11:11,225 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.33480537434418994, 'Total loss': 0.33480537434418994} | train loss {'Reaction outcome loss': 0.28589581910668727, 'Total loss': 0.28589581910668727}
2022-12-31 15:11:11,225 INFO:     Found new best model at epoch 43
2022-12-31 15:11:11,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:11,226 INFO:     Epoch: 44
2022-12-31 15:11:12,840 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3263994519909223, 'Total loss': 0.3263994519909223} | train loss {'Reaction outcome loss': 0.2831822398861715, 'Total loss': 0.2831822398861715}
2022-12-31 15:11:12,840 INFO:     Found new best model at epoch 44
2022-12-31 15:11:12,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:12,841 INFO:     Epoch: 45
2022-12-31 15:11:14,468 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3719736009836197, 'Total loss': 0.3719736009836197} | train loss {'Reaction outcome loss': 0.2791791468293873, 'Total loss': 0.2791791468293873}
2022-12-31 15:11:14,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:14,468 INFO:     Epoch: 46
2022-12-31 15:11:16,093 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.368733087182045, 'Total loss': 0.368733087182045} | train loss {'Reaction outcome loss': 0.2729966827409362, 'Total loss': 0.2729966827409362}
2022-12-31 15:11:16,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:16,093 INFO:     Epoch: 47
2022-12-31 15:11:17,759 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3520778944094976, 'Total loss': 0.3520778944094976} | train loss {'Reaction outcome loss': 0.27414783792375225, 'Total loss': 0.27414783792375225}
2022-12-31 15:11:17,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:17,760 INFO:     Epoch: 48
2022-12-31 15:11:19,425 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3743894080320994, 'Total loss': 0.3743894080320994} | train loss {'Reaction outcome loss': 0.2725845707129916, 'Total loss': 0.2725845707129916}
2022-12-31 15:11:19,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:19,425 INFO:     Epoch: 49
2022-12-31 15:11:21,064 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3628803610801697, 'Total loss': 0.3628803610801697} | train loss {'Reaction outcome loss': 0.26404743476195885, 'Total loss': 0.26404743476195885}
2022-12-31 15:11:21,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:21,064 INFO:     Epoch: 50
2022-12-31 15:11:22,715 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3503648594021797, 'Total loss': 0.3503648594021797} | train loss {'Reaction outcome loss': 0.2617369975612267, 'Total loss': 0.2617369975612267}
2022-12-31 15:11:22,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:22,715 INFO:     Epoch: 51
2022-12-31 15:11:24,341 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.35808678368727365, 'Total loss': 0.35808678368727365} | train loss {'Reaction outcome loss': 0.2594533243925993, 'Total loss': 0.2594533243925993}
2022-12-31 15:11:24,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:24,341 INFO:     Epoch: 52
2022-12-31 15:11:25,965 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.346214297413826, 'Total loss': 0.346214297413826} | train loss {'Reaction outcome loss': 0.2604224818862894, 'Total loss': 0.2604224818862894}
2022-12-31 15:11:25,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:25,966 INFO:     Epoch: 53
2022-12-31 15:11:27,591 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.35437709987163546, 'Total loss': 0.35437709987163546} | train loss {'Reaction outcome loss': 0.25666007959697434, 'Total loss': 0.25666007959697434}
2022-12-31 15:11:27,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:27,591 INFO:     Epoch: 54
2022-12-31 15:11:29,220 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.36061426798502605, 'Total loss': 0.36061426798502605} | train loss {'Reaction outcome loss': 0.25708937737754534, 'Total loss': 0.25708937737754534}
2022-12-31 15:11:29,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:29,220 INFO:     Epoch: 55
2022-12-31 15:11:30,832 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3475658088922501, 'Total loss': 0.3475658088922501} | train loss {'Reaction outcome loss': 0.2490437330227574, 'Total loss': 0.2490437330227574}
2022-12-31 15:11:30,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:30,832 INFO:     Epoch: 56
2022-12-31 15:11:32,474 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3635517696539561, 'Total loss': 0.3635517696539561} | train loss {'Reaction outcome loss': 0.24975786605574163, 'Total loss': 0.24975786605574163}
2022-12-31 15:11:32,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:32,474 INFO:     Epoch: 57
2022-12-31 15:11:34,097 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3613596871495247, 'Total loss': 0.3613596871495247} | train loss {'Reaction outcome loss': 0.2491180920832209, 'Total loss': 0.2491180920832209}
2022-12-31 15:11:34,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:34,098 INFO:     Epoch: 58
2022-12-31 15:11:35,707 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.34661994377772015, 'Total loss': 0.34661994377772015} | train loss {'Reaction outcome loss': 0.2544258327798293, 'Total loss': 0.2544258327798293}
2022-12-31 15:11:35,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:35,708 INFO:     Epoch: 59
2022-12-31 15:11:37,354 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.34426351885000867, 'Total loss': 0.34426351885000867} | train loss {'Reaction outcome loss': 0.24833229419502972, 'Total loss': 0.24833229419502972}
2022-12-31 15:11:37,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:37,355 INFO:     Epoch: 60
2022-12-31 15:11:38,988 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3686598519484202, 'Total loss': 0.3686598519484202} | train loss {'Reaction outcome loss': 0.25704906431668934, 'Total loss': 0.25704906431668934}
2022-12-31 15:11:38,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:38,988 INFO:     Epoch: 61
2022-12-31 15:11:40,631 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3429030428330104, 'Total loss': 0.3429030428330104} | train loss {'Reaction outcome loss': 0.23922611253894194, 'Total loss': 0.23922611253894194}
2022-12-31 15:11:40,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:40,631 INFO:     Epoch: 62
2022-12-31 15:11:42,253 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3403347392876943, 'Total loss': 0.3403347392876943} | train loss {'Reaction outcome loss': 0.24198640098237173, 'Total loss': 0.24198640098237173}
2022-12-31 15:11:42,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:42,253 INFO:     Epoch: 63
2022-12-31 15:11:43,866 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3533894265691439, 'Total loss': 0.3533894265691439} | train loss {'Reaction outcome loss': 0.23840379203915166, 'Total loss': 0.23840379203915166}
2022-12-31 15:11:43,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:43,867 INFO:     Epoch: 64
2022-12-31 15:11:45,517 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3422630916039149, 'Total loss': 0.3422630916039149} | train loss {'Reaction outcome loss': 0.23908700772463629, 'Total loss': 0.23908700772463629}
2022-12-31 15:11:45,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:45,518 INFO:     Epoch: 65
2022-12-31 15:11:47,160 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3498395691315333, 'Total loss': 0.3498395691315333} | train loss {'Reaction outcome loss': 0.2323909721300275, 'Total loss': 0.2323909721300275}
2022-12-31 15:11:47,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:47,160 INFO:     Epoch: 66
2022-12-31 15:11:48,781 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.33008028715848925, 'Total loss': 0.33008028715848925} | train loss {'Reaction outcome loss': 0.23125705038220873, 'Total loss': 0.23125705038220873}
2022-12-31 15:11:48,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:48,781 INFO:     Epoch: 67
2022-12-31 15:11:50,406 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.33689963817596436, 'Total loss': 0.33689963817596436} | train loss {'Reaction outcome loss': 0.2331926090784021, 'Total loss': 0.2331926090784021}
2022-12-31 15:11:50,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:50,407 INFO:     Epoch: 68
2022-12-31 15:11:52,041 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.35106133222579955, 'Total loss': 0.35106133222579955} | train loss {'Reaction outcome loss': 0.23248633771919602, 'Total loss': 0.23248633771919602}
2022-12-31 15:11:52,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:52,041 INFO:     Epoch: 69
2022-12-31 15:11:53,647 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3718743016322454, 'Total loss': 0.3718743016322454} | train loss {'Reaction outcome loss': 0.23342636024532334, 'Total loss': 0.23342636024532334}
2022-12-31 15:11:53,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:53,647 INFO:     Epoch: 70
2022-12-31 15:11:55,268 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.31982309619585675, 'Total loss': 0.31982309619585675} | train loss {'Reaction outcome loss': 0.22859652718993084, 'Total loss': 0.22859652718993084}
2022-12-31 15:11:55,268 INFO:     Found new best model at epoch 70
2022-12-31 15:11:55,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:55,269 INFO:     Epoch: 71
2022-12-31 15:11:56,880 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.35212141970793404, 'Total loss': 0.35212141970793404} | train loss {'Reaction outcome loss': 0.2299158882739742, 'Total loss': 0.2299158882739742}
2022-12-31 15:11:56,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:56,881 INFO:     Epoch: 72
2022-12-31 15:11:58,488 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3724641521771749, 'Total loss': 0.3724641521771749} | train loss {'Reaction outcome loss': 0.23052232104625942, 'Total loss': 0.23052232104625942}
2022-12-31 15:11:58,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:11:58,488 INFO:     Epoch: 73
2022-12-31 15:12:00,106 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3615077098210653, 'Total loss': 0.3615077098210653} | train loss {'Reaction outcome loss': 0.23170107014019997, 'Total loss': 0.23170107014019997}
2022-12-31 15:12:00,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:00,106 INFO:     Epoch: 74
2022-12-31 15:12:01,703 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3512407054503759, 'Total loss': 0.3512407054503759} | train loss {'Reaction outcome loss': 0.2208476498897863, 'Total loss': 0.2208476498897863}
2022-12-31 15:12:01,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:01,703 INFO:     Epoch: 75
2022-12-31 15:12:03,353 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37693478365739186, 'Total loss': 0.37693478365739186} | train loss {'Reaction outcome loss': 0.22146437715214512, 'Total loss': 0.22146437715214512}
2022-12-31 15:12:03,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:03,353 INFO:     Epoch: 76
2022-12-31 15:12:05,006 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3403518721461296, 'Total loss': 0.3403518721461296} | train loss {'Reaction outcome loss': 0.21962662377404824, 'Total loss': 0.21962662377404824}
2022-12-31 15:12:05,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:05,007 INFO:     Epoch: 77
2022-12-31 15:12:06,625 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.35148187205195425, 'Total loss': 0.35148187205195425} | train loss {'Reaction outcome loss': 0.22136836913868194, 'Total loss': 0.22136836913868194}
2022-12-31 15:12:06,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:06,625 INFO:     Epoch: 78
2022-12-31 15:12:08,248 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3299601073066393, 'Total loss': 0.3299601073066393} | train loss {'Reaction outcome loss': 0.21989213695433596, 'Total loss': 0.21989213695433596}
2022-12-31 15:12:08,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:08,248 INFO:     Epoch: 79
2022-12-31 15:12:09,899 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3374715864658356, 'Total loss': 0.3374715864658356} | train loss {'Reaction outcome loss': 0.21791446948632437, 'Total loss': 0.21791446948632437}
2022-12-31 15:12:09,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:09,900 INFO:     Epoch: 80
2022-12-31 15:12:11,515 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3521765028436979, 'Total loss': 0.3521765028436979} | train loss {'Reaction outcome loss': 0.21355718536981608, 'Total loss': 0.21355718536981608}
2022-12-31 15:12:11,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:11,516 INFO:     Epoch: 81
2022-12-31 15:12:13,167 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.33357735474904376, 'Total loss': 0.33357735474904376} | train loss {'Reaction outcome loss': 0.2130837535304068, 'Total loss': 0.2130837535304068}
2022-12-31 15:12:13,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:13,168 INFO:     Epoch: 82
2022-12-31 15:12:14,823 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37135258813699085, 'Total loss': 0.37135258813699085} | train loss {'Reaction outcome loss': 0.21289193376710483, 'Total loss': 0.21289193376710483}
2022-12-31 15:12:14,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:14,823 INFO:     Epoch: 83
2022-12-31 15:12:16,440 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3705923135081927, 'Total loss': 0.3705923135081927} | train loss {'Reaction outcome loss': 0.2126203230128284, 'Total loss': 0.2126203230128284}
2022-12-31 15:12:16,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:16,440 INFO:     Epoch: 84
2022-12-31 15:12:18,065 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3304462959369024, 'Total loss': 0.3304462959369024} | train loss {'Reaction outcome loss': 0.21111872187052394, 'Total loss': 0.21111872187052394}
2022-12-31 15:12:18,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:18,065 INFO:     Epoch: 85
2022-12-31 15:12:19,682 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3436753414571285, 'Total loss': 0.3436753414571285} | train loss {'Reaction outcome loss': 0.2136222585659165, 'Total loss': 0.2136222585659165}
2022-12-31 15:12:19,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:19,683 INFO:     Epoch: 86
2022-12-31 15:12:21,351 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.372042187054952, 'Total loss': 0.372042187054952} | train loss {'Reaction outcome loss': 0.21490989125834692, 'Total loss': 0.21490989125834692}
2022-12-31 15:12:21,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:21,351 INFO:     Epoch: 87
2022-12-31 15:12:23,045 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3499503552913666, 'Total loss': 0.3499503552913666} | train loss {'Reaction outcome loss': 0.21285036775125493, 'Total loss': 0.21285036775125493}
2022-12-31 15:12:23,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:23,045 INFO:     Epoch: 88
2022-12-31 15:12:24,626 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3646679431200027, 'Total loss': 0.3646679431200027} | train loss {'Reaction outcome loss': 0.21262207093383, 'Total loss': 0.21262207093383}
2022-12-31 15:12:24,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:24,626 INFO:     Epoch: 89
2022-12-31 15:12:25,793 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3452375372250875, 'Total loss': 0.3452375372250875} | train loss {'Reaction outcome loss': 0.2115174302770773, 'Total loss': 0.2115174302770773}
2022-12-31 15:12:25,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:25,794 INFO:     Epoch: 90
2022-12-31 15:12:26,858 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3760010401407878, 'Total loss': 0.3760010401407878} | train loss {'Reaction outcome loss': 0.2064790139344625, 'Total loss': 0.2064790139344625}
2022-12-31 15:12:26,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:26,858 INFO:     Epoch: 91
2022-12-31 15:12:27,941 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.35244730363289517, 'Total loss': 0.35244730363289517} | train loss {'Reaction outcome loss': 0.20614043067105195, 'Total loss': 0.20614043067105195}
2022-12-31 15:12:27,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:27,941 INFO:     Epoch: 92
2022-12-31 15:12:29,004 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3423380672931671, 'Total loss': 0.3423380672931671} | train loss {'Reaction outcome loss': 0.20073948046427878, 'Total loss': 0.20073948046427878}
2022-12-31 15:12:29,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:29,005 INFO:     Epoch: 93
2022-12-31 15:12:30,423 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.31855321725209557, 'Total loss': 0.31855321725209557} | train loss {'Reaction outcome loss': 0.20719835426429764, 'Total loss': 0.20719835426429764}
2022-12-31 15:12:30,423 INFO:     Found new best model at epoch 93
2022-12-31 15:12:30,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:30,424 INFO:     Epoch: 94
2022-12-31 15:12:32,074 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3373361895481745, 'Total loss': 0.3373361895481745} | train loss {'Reaction outcome loss': 0.20590117939542776, 'Total loss': 0.20590117939542776}
2022-12-31 15:12:32,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:32,074 INFO:     Epoch: 95
2022-12-31 15:12:33,723 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3713046302398046, 'Total loss': 0.3713046302398046} | train loss {'Reaction outcome loss': 0.19549202962714626, 'Total loss': 0.19549202962714626}
2022-12-31 15:12:33,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:33,723 INFO:     Epoch: 96
2022-12-31 15:12:35,371 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.354345566034317, 'Total loss': 0.354345566034317} | train loss {'Reaction outcome loss': 0.20317053954900388, 'Total loss': 0.20317053954900388}
2022-12-31 15:12:35,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:35,371 INFO:     Epoch: 97
2022-12-31 15:12:36,987 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3512900402148565, 'Total loss': 0.3512900402148565} | train loss {'Reaction outcome loss': 0.21194775167193652, 'Total loss': 0.21194775167193652}
2022-12-31 15:12:36,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:36,988 INFO:     Epoch: 98
2022-12-31 15:12:38,623 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.33894217312335967, 'Total loss': 0.33894217312335967} | train loss {'Reaction outcome loss': 0.20076173408770603, 'Total loss': 0.20076173408770603}
2022-12-31 15:12:38,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:38,623 INFO:     Epoch: 99
2022-12-31 15:12:40,233 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3719160531957944, 'Total loss': 0.3719160531957944} | train loss {'Reaction outcome loss': 0.2078075285846307, 'Total loss': 0.2078075285846307}
2022-12-31 15:12:40,233 INFO:     Best model found after epoch 94 of 100.
2022-12-31 15:12:40,234 INFO:   Done with stage: TRAINING
2022-12-31 15:12:40,234 INFO:   Starting stage: EVALUATION
2022-12-31 15:12:40,356 INFO:   Done with stage: EVALUATION
2022-12-31 15:12:40,357 INFO:   Leaving out SEQ value Fold_7
2022-12-31 15:12:40,369 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 15:12:40,370 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:12:41,017 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:12:41,017 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:12:41,086 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:12:41,086 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:12:41,086 INFO:     No hyperparam tuning for this model
2022-12-31 15:12:41,086 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:12:41,086 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:12:41,087 INFO:     None feature selector for col prot
2022-12-31 15:12:41,087 INFO:     None feature selector for col prot
2022-12-31 15:12:41,087 INFO:     None feature selector for col prot
2022-12-31 15:12:41,088 INFO:     None feature selector for col chem
2022-12-31 15:12:41,088 INFO:     None feature selector for col chem
2022-12-31 15:12:41,088 INFO:     None feature selector for col chem
2022-12-31 15:12:41,088 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:12:41,088 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:12:41,090 INFO:     Number of params in model 223921
2022-12-31 15:12:41,093 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:12:41,093 INFO:   Starting stage: TRAINING
2022-12-31 15:12:41,137 INFO:     Val loss before train {'Reaction outcome loss': 0.9600698510805766, 'Total loss': 0.9600698510805766}
2022-12-31 15:12:41,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:41,137 INFO:     Epoch: 0
2022-12-31 15:12:42,787 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6251797695954641, 'Total loss': 0.6251797695954641} | train loss {'Reaction outcome loss': 0.816998942126436, 'Total loss': 0.816998942126436}
2022-12-31 15:12:42,787 INFO:     Found new best model at epoch 0
2022-12-31 15:12:42,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:42,788 INFO:     Epoch: 1
2022-12-31 15:12:44,410 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5131340523560842, 'Total loss': 0.5131340523560842} | train loss {'Reaction outcome loss': 0.5948665007572311, 'Total loss': 0.5948665007572311}
2022-12-31 15:12:44,410 INFO:     Found new best model at epoch 1
2022-12-31 15:12:44,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:44,411 INFO:     Epoch: 2
2022-12-31 15:12:46,050 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4842541476090749, 'Total loss': 0.4842541476090749} | train loss {'Reaction outcome loss': 0.5216950315323117, 'Total loss': 0.5216950315323117}
2022-12-31 15:12:46,050 INFO:     Found new best model at epoch 2
2022-12-31 15:12:46,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:46,051 INFO:     Epoch: 3
2022-12-31 15:12:47,668 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5085995197296143, 'Total loss': 0.5085995197296143} | train loss {'Reaction outcome loss': 0.5050114172675549, 'Total loss': 0.5050114172675549}
2022-12-31 15:12:47,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:47,668 INFO:     Epoch: 4
2022-12-31 15:12:49,295 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47214632034301757, 'Total loss': 0.47214632034301757} | train loss {'Reaction outcome loss': 0.4882418555257983, 'Total loss': 0.4882418555257983}
2022-12-31 15:12:49,296 INFO:     Found new best model at epoch 4
2022-12-31 15:12:49,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:49,297 INFO:     Epoch: 5
2022-12-31 15:12:50,922 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4966890891393026, 'Total loss': 0.4966890891393026} | train loss {'Reaction outcome loss': 0.47746907900817126, 'Total loss': 0.47746907900817126}
2022-12-31 15:12:50,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:50,923 INFO:     Epoch: 6
2022-12-31 15:12:52,566 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4569683055082957, 'Total loss': 0.4569683055082957} | train loss {'Reaction outcome loss': 0.4697949217114638, 'Total loss': 0.4697949217114638}
2022-12-31 15:12:52,566 INFO:     Found new best model at epoch 6
2022-12-31 15:12:52,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:52,567 INFO:     Epoch: 7
2022-12-31 15:12:54,194 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48764445781707766, 'Total loss': 0.48764445781707766} | train loss {'Reaction outcome loss': 0.46129764769804604, 'Total loss': 0.46129764769804604}
2022-12-31 15:12:54,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:54,194 INFO:     Epoch: 8
2022-12-31 15:12:55,821 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5421002368132274, 'Total loss': 0.5421002368132274} | train loss {'Reaction outcome loss': 0.45729927143034954, 'Total loss': 0.45729927143034954}
2022-12-31 15:12:55,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:55,822 INFO:     Epoch: 9
2022-12-31 15:12:57,432 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4827677587668101, 'Total loss': 0.4827677587668101} | train loss {'Reaction outcome loss': 0.45132839007282943, 'Total loss': 0.45132839007282943}
2022-12-31 15:12:57,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:57,433 INFO:     Epoch: 10
2022-12-31 15:12:59,061 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4669528802235921, 'Total loss': 0.4669528802235921} | train loss {'Reaction outcome loss': 0.44333559411850215, 'Total loss': 0.44333559411850215}
2022-12-31 15:12:59,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:12:59,061 INFO:     Epoch: 11
2022-12-31 15:13:00,691 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44893343448638917, 'Total loss': 0.44893343448638917} | train loss {'Reaction outcome loss': 0.43999711760329857, 'Total loss': 0.43999711760329857}
2022-12-31 15:13:00,691 INFO:     Found new best model at epoch 11
2022-12-31 15:13:00,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:00,692 INFO:     Epoch: 12
2022-12-31 15:13:02,325 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4481529970963796, 'Total loss': 0.4481529970963796} | train loss {'Reaction outcome loss': 0.42805782616783994, 'Total loss': 0.42805782616783994}
2022-12-31 15:13:02,325 INFO:     Found new best model at epoch 12
2022-12-31 15:13:02,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:02,326 INFO:     Epoch: 13
2022-12-31 15:13:03,954 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44459571142991383, 'Total loss': 0.44459571142991383} | train loss {'Reaction outcome loss': 0.42582398653030396, 'Total loss': 0.42582398653030396}
2022-12-31 15:13:03,955 INFO:     Found new best model at epoch 13
2022-12-31 15:13:03,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:03,956 INFO:     Epoch: 14
2022-12-31 15:13:05,588 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45357341567675274, 'Total loss': 0.45357341567675274} | train loss {'Reaction outcome loss': 0.4149009124897017, 'Total loss': 0.4149009124897017}
2022-12-31 15:13:05,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:05,588 INFO:     Epoch: 15
2022-12-31 15:13:07,234 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4402940680583318, 'Total loss': 0.4402940680583318} | train loss {'Reaction outcome loss': 0.4109247883896105, 'Total loss': 0.4109247883896105}
2022-12-31 15:13:07,234 INFO:     Found new best model at epoch 15
2022-12-31 15:13:07,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:07,235 INFO:     Epoch: 16
2022-12-31 15:13:08,871 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4466413915157318, 'Total loss': 0.4466413915157318} | train loss {'Reaction outcome loss': 0.41318880642902117, 'Total loss': 0.41318880642902117}
2022-12-31 15:13:08,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:08,871 INFO:     Epoch: 17
2022-12-31 15:13:10,525 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4669946193695068, 'Total loss': 0.4669946193695068} | train loss {'Reaction outcome loss': 0.4014569707887267, 'Total loss': 0.4014569707887267}
2022-12-31 15:13:10,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:10,526 INFO:     Epoch: 18
2022-12-31 15:13:12,149 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4436207120617231, 'Total loss': 0.4436207120617231} | train loss {'Reaction outcome loss': 0.39320611025774954, 'Total loss': 0.39320611025774954}
2022-12-31 15:13:12,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:12,149 INFO:     Epoch: 19
2022-12-31 15:13:13,768 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4355548024177551, 'Total loss': 0.4355548024177551} | train loss {'Reaction outcome loss': 0.3899560889182108, 'Total loss': 0.3899560889182108}
2022-12-31 15:13:13,768 INFO:     Found new best model at epoch 19
2022-12-31 15:13:13,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:13,769 INFO:     Epoch: 20
2022-12-31 15:13:15,370 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45574037432670594, 'Total loss': 0.45574037432670594} | train loss {'Reaction outcome loss': 0.3778648228798102, 'Total loss': 0.3778648228798102}
2022-12-31 15:13:15,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:15,370 INFO:     Epoch: 21
2022-12-31 15:13:16,988 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43325807253519694, 'Total loss': 0.43325807253519694} | train loss {'Reaction outcome loss': 0.378993992286899, 'Total loss': 0.378993992286899}
2022-12-31 15:13:16,988 INFO:     Found new best model at epoch 21
2022-12-31 15:13:16,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:16,989 INFO:     Epoch: 22
2022-12-31 15:13:18,614 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42048507928848267, 'Total loss': 0.42048507928848267} | train loss {'Reaction outcome loss': 0.36849406918356137, 'Total loss': 0.36849406918356137}
2022-12-31 15:13:18,614 INFO:     Found new best model at epoch 22
2022-12-31 15:13:18,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:18,615 INFO:     Epoch: 23
2022-12-31 15:13:20,255 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43562011420726776, 'Total loss': 0.43562011420726776} | train loss {'Reaction outcome loss': 0.3657487041790993, 'Total loss': 0.3657487041790993}
2022-12-31 15:13:20,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:20,255 INFO:     Epoch: 24
2022-12-31 15:13:21,880 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40343682169914247, 'Total loss': 0.40343682169914247} | train loss {'Reaction outcome loss': 0.36039638858194384, 'Total loss': 0.36039638858194384}
2022-12-31 15:13:21,880 INFO:     Found new best model at epoch 24
2022-12-31 15:13:21,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:21,881 INFO:     Epoch: 25
2022-12-31 15:13:23,511 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4275757292906443, 'Total loss': 0.4275757292906443} | train loss {'Reaction outcome loss': 0.35265249670197385, 'Total loss': 0.35265249670197385}
2022-12-31 15:13:23,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:23,512 INFO:     Epoch: 26
2022-12-31 15:13:25,109 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4024163901805878, 'Total loss': 0.4024163901805878} | train loss {'Reaction outcome loss': 0.3446184122121291, 'Total loss': 0.3446184122121291}
2022-12-31 15:13:25,110 INFO:     Found new best model at epoch 26
2022-12-31 15:13:25,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:25,111 INFO:     Epoch: 27
2022-12-31 15:13:26,729 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4137159039576848, 'Total loss': 0.4137159039576848} | train loss {'Reaction outcome loss': 0.340637778157254, 'Total loss': 0.340637778157254}
2022-12-31 15:13:26,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:26,729 INFO:     Epoch: 28
2022-12-31 15:13:28,347 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4065129021803538, 'Total loss': 0.4065129021803538} | train loss {'Reaction outcome loss': 0.34039954303188874, 'Total loss': 0.34039954303188874}
2022-12-31 15:13:28,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:28,347 INFO:     Epoch: 29
2022-12-31 15:13:29,963 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42021385629971825, 'Total loss': 0.42021385629971825} | train loss {'Reaction outcome loss': 0.33530366182703836, 'Total loss': 0.33530366182703836}
2022-12-31 15:13:29,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:29,963 INFO:     Epoch: 30
2022-12-31 15:13:31,617 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43357807099819184, 'Total loss': 0.43357807099819184} | train loss {'Reaction outcome loss': 0.3309691211726476, 'Total loss': 0.3309691211726476}
2022-12-31 15:13:31,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:31,618 INFO:     Epoch: 31
2022-12-31 15:13:33,242 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38927966058254243, 'Total loss': 0.38927966058254243} | train loss {'Reaction outcome loss': 0.3229550923143483, 'Total loss': 0.3229550923143483}
2022-12-31 15:13:33,242 INFO:     Found new best model at epoch 31
2022-12-31 15:13:33,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:33,243 INFO:     Epoch: 32
2022-12-31 15:13:34,869 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40236733108758926, 'Total loss': 0.40236733108758926} | train loss {'Reaction outcome loss': 0.31796919764271714, 'Total loss': 0.31796919764271714}
2022-12-31 15:13:34,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:34,869 INFO:     Epoch: 33
2022-12-31 15:13:36,485 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4095958630243937, 'Total loss': 0.4095958630243937} | train loss {'Reaction outcome loss': 0.32188275803405025, 'Total loss': 0.32188275803405025}
2022-12-31 15:13:36,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:36,485 INFO:     Epoch: 34
2022-12-31 15:13:38,100 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39203174114227296, 'Total loss': 0.39203174114227296} | train loss {'Reaction outcome loss': 0.3184460403686826, 'Total loss': 0.3184460403686826}
2022-12-31 15:13:38,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:38,100 INFO:     Epoch: 35
2022-12-31 15:13:39,702 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4170512686173121, 'Total loss': 0.4170512686173121} | train loss {'Reaction outcome loss': 0.3100119067174433, 'Total loss': 0.3100119067174433}
2022-12-31 15:13:39,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:39,702 INFO:     Epoch: 36
2022-12-31 15:13:41,348 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45458352168401084, 'Total loss': 0.45458352168401084} | train loss {'Reaction outcome loss': 0.30273020283625013, 'Total loss': 0.30273020283625013}
2022-12-31 15:13:41,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:41,348 INFO:     Epoch: 37
2022-12-31 15:13:42,959 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3964426930993795, 'Total loss': 0.3964426930993795} | train loss {'Reaction outcome loss': 0.30749631738996247, 'Total loss': 0.30749631738996247}
2022-12-31 15:13:42,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:42,959 INFO:     Epoch: 38
2022-12-31 15:13:44,576 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3892075439294179, 'Total loss': 0.3892075439294179} | train loss {'Reaction outcome loss': 0.3011556968146713, 'Total loss': 0.3011556968146713}
2022-12-31 15:13:44,577 INFO:     Found new best model at epoch 38
2022-12-31 15:13:44,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:44,578 INFO:     Epoch: 39
2022-12-31 15:13:46,215 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4336438039938609, 'Total loss': 0.4336438039938609} | train loss {'Reaction outcome loss': 0.293315487446445, 'Total loss': 0.293315487446445}
2022-12-31 15:13:46,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:46,216 INFO:     Epoch: 40
2022-12-31 15:13:47,842 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4044421558578809, 'Total loss': 0.4044421558578809} | train loss {'Reaction outcome loss': 0.29372298028925264, 'Total loss': 0.29372298028925264}
2022-12-31 15:13:47,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:47,842 INFO:     Epoch: 41
2022-12-31 15:13:49,455 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4270950615406036, 'Total loss': 0.4270950615406036} | train loss {'Reaction outcome loss': 0.29439522906976484, 'Total loss': 0.29439522906976484}
2022-12-31 15:13:49,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:49,456 INFO:     Epoch: 42
2022-12-31 15:13:51,071 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.36871702373027804, 'Total loss': 0.36871702373027804} | train loss {'Reaction outcome loss': 0.2861318150905065, 'Total loss': 0.2861318150905065}
2022-12-31 15:13:51,072 INFO:     Found new best model at epoch 42
2022-12-31 15:13:51,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:51,072 INFO:     Epoch: 43
2022-12-31 15:13:52,716 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42333884636561075, 'Total loss': 0.42333884636561075} | train loss {'Reaction outcome loss': 0.2788585433501091, 'Total loss': 0.2788585433501091}
2022-12-31 15:13:52,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:52,716 INFO:     Epoch: 44
2022-12-31 15:13:54,336 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41878855029741924, 'Total loss': 0.41878855029741924} | train loss {'Reaction outcome loss': 0.27849924774161317, 'Total loss': 0.27849924774161317}
2022-12-31 15:13:54,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:54,336 INFO:     Epoch: 45
2022-12-31 15:13:55,944 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41620498498280845, 'Total loss': 0.41620498498280845} | train loss {'Reaction outcome loss': 0.27302980346316036, 'Total loss': 0.27302980346316036}
2022-12-31 15:13:55,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:55,944 INFO:     Epoch: 46
2022-12-31 15:13:57,546 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4107474719484647, 'Total loss': 0.4107474719484647} | train loss {'Reaction outcome loss': 0.2758365523621494, 'Total loss': 0.2758365523621494}
2022-12-31 15:13:57,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:57,546 INFO:     Epoch: 47
2022-12-31 15:13:59,156 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4449578166007996, 'Total loss': 0.4449578166007996} | train loss {'Reaction outcome loss': 0.26540669164072306, 'Total loss': 0.26540669164072306}
2022-12-31 15:13:59,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:13:59,156 INFO:     Epoch: 48
2022-12-31 15:14:00,765 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40125645995140075, 'Total loss': 0.40125645995140075} | train loss {'Reaction outcome loss': 0.26821679847873076, 'Total loss': 0.26821679847873076}
2022-12-31 15:14:00,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:00,766 INFO:     Epoch: 49
2022-12-31 15:14:02,405 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48959415356318153, 'Total loss': 0.48959415356318153} | train loss {'Reaction outcome loss': 0.2615138347183324, 'Total loss': 0.2615138347183324}
2022-12-31 15:14:02,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:02,405 INFO:     Epoch: 50
2022-12-31 15:14:04,036 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40929905970891317, 'Total loss': 0.40929905970891317} | train loss {'Reaction outcome loss': 0.2639083045296075, 'Total loss': 0.2639083045296075}
2022-12-31 15:14:04,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:04,036 INFO:     Epoch: 51
2022-12-31 15:14:05,686 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3903101513783137, 'Total loss': 0.3903101513783137} | train loss {'Reaction outcome loss': 0.2567786182468549, 'Total loss': 0.2567786182468549}
2022-12-31 15:14:05,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:05,686 INFO:     Epoch: 52
2022-12-31 15:14:07,317 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3928883860508601, 'Total loss': 0.3928883860508601} | train loss {'Reaction outcome loss': 0.26046554203605826, 'Total loss': 0.26046554203605826}
2022-12-31 15:14:07,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:07,318 INFO:     Epoch: 53
2022-12-31 15:14:08,924 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42634021043777465, 'Total loss': 0.42634021043777465} | train loss {'Reaction outcome loss': 0.2526209328175667, 'Total loss': 0.2526209328175667}
2022-12-31 15:14:08,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:08,924 INFO:     Epoch: 54
2022-12-31 15:14:10,551 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.439097648859024, 'Total loss': 0.439097648859024} | train loss {'Reaction outcome loss': 0.2535887001895948, 'Total loss': 0.2535887001895948}
2022-12-31 15:14:10,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:10,551 INFO:     Epoch: 55
2022-12-31 15:14:12,184 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3993633064130942, 'Total loss': 0.3993633064130942} | train loss {'Reaction outcome loss': 0.2488702553448802, 'Total loss': 0.2488702553448802}
2022-12-31 15:14:12,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:12,184 INFO:     Epoch: 56
2022-12-31 15:14:13,830 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4110626846551895, 'Total loss': 0.4110626846551895} | train loss {'Reaction outcome loss': 0.24666108344328533, 'Total loss': 0.24666108344328533}
2022-12-31 15:14:13,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:13,830 INFO:     Epoch: 57
2022-12-31 15:14:15,437 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3766711751619975, 'Total loss': 0.3766711751619975} | train loss {'Reaction outcome loss': 0.24411481021758882, 'Total loss': 0.24411481021758882}
2022-12-31 15:14:15,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:15,437 INFO:     Epoch: 58
2022-12-31 15:14:17,056 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39702390134334564, 'Total loss': 0.39702390134334564} | train loss {'Reaction outcome loss': 0.24575979452217098, 'Total loss': 0.24575979452217098}
2022-12-31 15:14:17,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:17,057 INFO:     Epoch: 59
2022-12-31 15:14:18,660 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38770065903663636, 'Total loss': 0.38770065903663636} | train loss {'Reaction outcome loss': 0.24739082399688472, 'Total loss': 0.24739082399688472}
2022-12-31 15:14:18,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:18,660 INFO:     Epoch: 60
2022-12-31 15:14:20,275 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4231051077445348, 'Total loss': 0.4231051077445348} | train loss {'Reaction outcome loss': 0.23694900889958284, 'Total loss': 0.23694900889958284}
2022-12-31 15:14:20,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:20,275 INFO:     Epoch: 61
2022-12-31 15:14:21,912 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38694321165482204, 'Total loss': 0.38694321165482204} | train loss {'Reaction outcome loss': 0.235288686061863, 'Total loss': 0.235288686061863}
2022-12-31 15:14:21,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:21,912 INFO:     Epoch: 62
2022-12-31 15:14:23,569 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3911335359017054, 'Total loss': 0.3911335359017054} | train loss {'Reaction outcome loss': 0.23979008096919163, 'Total loss': 0.23979008096919163}
2022-12-31 15:14:23,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:23,569 INFO:     Epoch: 63
2022-12-31 15:14:25,225 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40094101627667744, 'Total loss': 0.40094101627667744} | train loss {'Reaction outcome loss': 0.23708306150746258, 'Total loss': 0.23708306150746258}
2022-12-31 15:14:25,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:25,226 INFO:     Epoch: 64
2022-12-31 15:14:26,898 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3935416320959727, 'Total loss': 0.3935416320959727} | train loss {'Reaction outcome loss': 0.23487908666153245, 'Total loss': 0.23487908666153245}
2022-12-31 15:14:26,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:26,898 INFO:     Epoch: 65
2022-12-31 15:14:28,549 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39877822001775104, 'Total loss': 0.39877822001775104} | train loss {'Reaction outcome loss': 0.23735256670278224, 'Total loss': 0.23735256670278224}
2022-12-31 15:14:28,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:28,549 INFO:     Epoch: 66
2022-12-31 15:14:30,227 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45289055109024046, 'Total loss': 0.45289055109024046} | train loss {'Reaction outcome loss': 0.23104385656408885, 'Total loss': 0.23104385656408885}
2022-12-31 15:14:30,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:30,228 INFO:     Epoch: 67
2022-12-31 15:14:31,903 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42387475768725075, 'Total loss': 0.42387475768725075} | train loss {'Reaction outcome loss': 0.23211206792978173, 'Total loss': 0.23211206792978173}
2022-12-31 15:14:31,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:31,903 INFO:     Epoch: 68
2022-12-31 15:14:33,539 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38699821159243586, 'Total loss': 0.38699821159243586} | train loss {'Reaction outcome loss': 0.2326043191086837, 'Total loss': 0.2326043191086837}
2022-12-31 15:14:33,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:33,539 INFO:     Epoch: 69
2022-12-31 15:14:35,193 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40988067984580995, 'Total loss': 0.40988067984580995} | train loss {'Reaction outcome loss': 0.22772401466373932, 'Total loss': 0.22772401466373932}
2022-12-31 15:14:35,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:35,193 INFO:     Epoch: 70
2022-12-31 15:14:36,823 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45907498796780905, 'Total loss': 0.45907498796780905} | train loss {'Reaction outcome loss': 0.21821109602221084, 'Total loss': 0.21821109602221084}
2022-12-31 15:14:36,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:36,825 INFO:     Epoch: 71
2022-12-31 15:14:38,468 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43622826039791107, 'Total loss': 0.43622826039791107} | train loss {'Reaction outcome loss': 0.2195935608072724, 'Total loss': 0.2195935608072724}
2022-12-31 15:14:38,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:38,469 INFO:     Epoch: 72
2022-12-31 15:14:40,124 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.36730604370435077, 'Total loss': 0.36730604370435077} | train loss {'Reaction outcome loss': 0.2214184105497136, 'Total loss': 0.2214184105497136}
2022-12-31 15:14:40,124 INFO:     Found new best model at epoch 72
2022-12-31 15:14:40,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:40,126 INFO:     Epoch: 73
2022-12-31 15:14:41,770 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4381103515625, 'Total loss': 0.4381103515625} | train loss {'Reaction outcome loss': 0.2260327578290275, 'Total loss': 0.2260327578290275}
2022-12-31 15:14:41,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:41,770 INFO:     Epoch: 74
2022-12-31 15:14:43,381 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38509088158607485, 'Total loss': 0.38509088158607485} | train loss {'Reaction outcome loss': 0.22092739239146778, 'Total loss': 0.22092739239146778}
2022-12-31 15:14:43,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:43,382 INFO:     Epoch: 75
2022-12-31 15:14:44,995 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38312122523784636, 'Total loss': 0.38312122523784636} | train loss {'Reaction outcome loss': 0.21927818112640174, 'Total loss': 0.21927818112640174}
2022-12-31 15:14:44,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:44,995 INFO:     Epoch: 76
2022-12-31 15:14:46,613 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3816043963034948, 'Total loss': 0.3816043963034948} | train loss {'Reaction outcome loss': 0.21829856836677458, 'Total loss': 0.21829856836677458}
2022-12-31 15:14:46,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:46,613 INFO:     Epoch: 77
2022-12-31 15:14:48,258 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38087604343891146, 'Total loss': 0.38087604343891146} | train loss {'Reaction outcome loss': 0.21530485118231618, 'Total loss': 0.21530485118231618}
2022-12-31 15:14:48,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:48,258 INFO:     Epoch: 78
2022-12-31 15:14:49,873 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4053049092491468, 'Total loss': 0.4053049092491468} | train loss {'Reaction outcome loss': 0.22054758797053395, 'Total loss': 0.22054758797053395}
2022-12-31 15:14:49,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:49,873 INFO:     Epoch: 79
2022-12-31 15:14:51,511 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42180278301239016, 'Total loss': 0.42180278301239016} | train loss {'Reaction outcome loss': 0.2175078409007794, 'Total loss': 0.2175078409007794}
2022-12-31 15:14:51,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:51,512 INFO:     Epoch: 80
2022-12-31 15:14:53,113 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.39392185509204863, 'Total loss': 0.39392185509204863} | train loss {'Reaction outcome loss': 0.21407818958324645, 'Total loss': 0.21407818958324645}
2022-12-31 15:14:53,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:53,113 INFO:     Epoch: 81
2022-12-31 15:14:54,720 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3923167536656062, 'Total loss': 0.3923167536656062} | train loss {'Reaction outcome loss': 0.2107867342470355, 'Total loss': 0.2107867342470355}
2022-12-31 15:14:54,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:54,720 INFO:     Epoch: 82
2022-12-31 15:14:56,342 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4272727290789286, 'Total loss': 0.4272727290789286} | train loss {'Reaction outcome loss': 0.2110385691027564, 'Total loss': 0.2110385691027564}
2022-12-31 15:14:56,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:56,343 INFO:     Epoch: 83
2022-12-31 15:14:57,958 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4302202045917511, 'Total loss': 0.4302202045917511} | train loss {'Reaction outcome loss': 0.20886469821341416, 'Total loss': 0.20886469821341416}
2022-12-31 15:14:57,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:57,958 INFO:     Epoch: 84
2022-12-31 15:14:59,604 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38546977440516156, 'Total loss': 0.38546977440516156} | train loss {'Reaction outcome loss': 0.20976014636349377, 'Total loss': 0.20976014636349377}
2022-12-31 15:14:59,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:14:59,604 INFO:     Epoch: 85
2022-12-31 15:15:01,237 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3855365057786306, 'Total loss': 0.3855365057786306} | train loss {'Reaction outcome loss': 0.20467569146453257, 'Total loss': 0.20467569146453257}
2022-12-31 15:15:01,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:01,238 INFO:     Epoch: 86
2022-12-31 15:15:02,856 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3982912798722585, 'Total loss': 0.3982912798722585} | train loss {'Reaction outcome loss': 0.20526254683437115, 'Total loss': 0.20526254683437115}
2022-12-31 15:15:02,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:02,856 INFO:     Epoch: 87
2022-12-31 15:15:04,452 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38891219943761823, 'Total loss': 0.38891219943761823} | train loss {'Reaction outcome loss': 0.20972615028546604, 'Total loss': 0.20972615028546604}
2022-12-31 15:15:04,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:04,452 INFO:     Epoch: 88
2022-12-31 15:15:06,101 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3735950320959091, 'Total loss': 0.3735950320959091} | train loss {'Reaction outcome loss': 0.20202756783376963, 'Total loss': 0.20202756783376963}
2022-12-31 15:15:06,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:06,101 INFO:     Epoch: 89
2022-12-31 15:15:07,759 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38550445760289825, 'Total loss': 0.38550445760289825} | train loss {'Reaction outcome loss': 0.20483642007940406, 'Total loss': 0.20483642007940406}
2022-12-31 15:15:07,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:07,759 INFO:     Epoch: 90
2022-12-31 15:15:09,408 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4601572036743164, 'Total loss': 0.4601572036743164} | train loss {'Reaction outcome loss': 0.2074744343330633, 'Total loss': 0.2074744343330633}
2022-12-31 15:15:09,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:09,408 INFO:     Epoch: 91
2022-12-31 15:15:11,056 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.425418625275294, 'Total loss': 0.425418625275294} | train loss {'Reaction outcome loss': 0.20378817478026723, 'Total loss': 0.20378817478026723}
2022-12-31 15:15:11,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:11,056 INFO:     Epoch: 92
2022-12-31 15:15:12,708 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42440195977687833, 'Total loss': 0.42440195977687833} | train loss {'Reaction outcome loss': 0.19763294792320538, 'Total loss': 0.19763294792320538}
2022-12-31 15:15:12,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:12,710 INFO:     Epoch: 93
2022-12-31 15:15:14,358 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4040848582983017, 'Total loss': 0.4040848582983017} | train loss {'Reaction outcome loss': 0.207744736130272, 'Total loss': 0.207744736130272}
2022-12-31 15:15:14,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:14,358 INFO:     Epoch: 94
2022-12-31 15:15:16,006 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47100173532962797, 'Total loss': 0.47100173532962797} | train loss {'Reaction outcome loss': 0.19806417308425, 'Total loss': 0.19806417308425}
2022-12-31 15:15:16,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:16,006 INFO:     Epoch: 95
2022-12-31 15:15:17,663 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3982947409152985, 'Total loss': 0.3982947409152985} | train loss {'Reaction outcome loss': 0.20608148085027395, 'Total loss': 0.20608148085027395}
2022-12-31 15:15:17,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:17,664 INFO:     Epoch: 96
2022-12-31 15:15:19,301 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3771782547235489, 'Total loss': 0.3771782547235489} | train loss {'Reaction outcome loss': 0.20029811951119977, 'Total loss': 0.20029811951119977}
2022-12-31 15:15:19,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:19,302 INFO:     Epoch: 97
2022-12-31 15:15:20,928 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41559744377930957, 'Total loss': 0.41559744377930957} | train loss {'Reaction outcome loss': 0.20038371835415006, 'Total loss': 0.20038371835415006}
2022-12-31 15:15:20,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:20,928 INFO:     Epoch: 98
2022-12-31 15:15:22,572 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4253537426392237, 'Total loss': 0.4253537426392237} | train loss {'Reaction outcome loss': 0.19369103248476552, 'Total loss': 0.19369103248476552}
2022-12-31 15:15:22,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:22,572 INFO:     Epoch: 99
2022-12-31 15:15:24,187 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4056793381770452, 'Total loss': 0.4056793381770452} | train loss {'Reaction outcome loss': 0.1933920450999472, 'Total loss': 0.1933920450999472}
2022-12-31 15:15:24,187 INFO:     Best model found after epoch 73 of 100.
2022-12-31 15:15:24,187 INFO:   Done with stage: TRAINING
2022-12-31 15:15:24,187 INFO:   Starting stage: EVALUATION
2022-12-31 15:15:24,311 INFO:   Done with stage: EVALUATION
2022-12-31 15:15:24,311 INFO:   Leaving out SEQ value Fold_8
2022-12-31 15:15:24,323 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 15:15:24,324 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:15:24,976 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:15:24,976 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:15:25,043 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:15:25,043 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:15:25,044 INFO:     No hyperparam tuning for this model
2022-12-31 15:15:25,044 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:15:25,044 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:15:25,044 INFO:     None feature selector for col prot
2022-12-31 15:15:25,044 INFO:     None feature selector for col prot
2022-12-31 15:15:25,045 INFO:     None feature selector for col prot
2022-12-31 15:15:25,045 INFO:     None feature selector for col chem
2022-12-31 15:15:25,045 INFO:     None feature selector for col chem
2022-12-31 15:15:25,045 INFO:     None feature selector for col chem
2022-12-31 15:15:25,045 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:15:25,045 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:15:25,047 INFO:     Number of params in model 223921
2022-12-31 15:15:25,051 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:15:25,051 INFO:   Starting stage: TRAINING
2022-12-31 15:15:25,095 INFO:     Val loss before train {'Reaction outcome loss': 1.065801978111267, 'Total loss': 1.065801978111267}
2022-12-31 15:15:25,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:25,095 INFO:     Epoch: 0
2022-12-31 15:15:26,723 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6998606781164806, 'Total loss': 0.6998606781164806} | train loss {'Reaction outcome loss': 0.8131320424323535, 'Total loss': 0.8131320424323535}
2022-12-31 15:15:26,723 INFO:     Found new best model at epoch 0
2022-12-31 15:15:26,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:26,724 INFO:     Epoch: 1
2022-12-31 15:15:28,299 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5577532807985942, 'Total loss': 0.5577532807985942} | train loss {'Reaction outcome loss': 0.607965803113732, 'Total loss': 0.607965803113732}
2022-12-31 15:15:28,299 INFO:     Found new best model at epoch 1
2022-12-31 15:15:28,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:28,300 INFO:     Epoch: 2
2022-12-31 15:15:29,906 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5356399933497111, 'Total loss': 0.5356399933497111} | train loss {'Reaction outcome loss': 0.5288513632912706, 'Total loss': 0.5288513632912706}
2022-12-31 15:15:29,907 INFO:     Found new best model at epoch 2
2022-12-31 15:15:29,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:29,908 INFO:     Epoch: 3
2022-12-31 15:15:31,506 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5268766343593597, 'Total loss': 0.5268766343593597} | train loss {'Reaction outcome loss': 0.5029850131730094, 'Total loss': 0.5029850131730094}
2022-12-31 15:15:31,507 INFO:     Found new best model at epoch 3
2022-12-31 15:15:31,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:31,508 INFO:     Epoch: 4
2022-12-31 15:15:33,112 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5344210902849833, 'Total loss': 0.5344210902849833} | train loss {'Reaction outcome loss': 0.49061551434497763, 'Total loss': 0.49061551434497763}
2022-12-31 15:15:33,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:33,112 INFO:     Epoch: 5
2022-12-31 15:15:34,750 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47637665271759033, 'Total loss': 0.47637665271759033} | train loss {'Reaction outcome loss': 0.47605008767904156, 'Total loss': 0.47605008767904156}
2022-12-31 15:15:34,750 INFO:     Found new best model at epoch 5
2022-12-31 15:15:34,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:34,751 INFO:     Epoch: 6
2022-12-31 15:15:36,388 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49483778874079387, 'Total loss': 0.49483778874079387} | train loss {'Reaction outcome loss': 0.4700176409941955, 'Total loss': 0.4700176409941955}
2022-12-31 15:15:36,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:36,388 INFO:     Epoch: 7
2022-12-31 15:15:38,016 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4711563100417455, 'Total loss': 0.4711563100417455} | train loss {'Reaction outcome loss': 0.46432939775451254, 'Total loss': 0.46432939775451254}
2022-12-31 15:15:38,016 INFO:     Found new best model at epoch 7
2022-12-31 15:15:38,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:38,018 INFO:     Epoch: 8
2022-12-31 15:15:39,685 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49415129820505777, 'Total loss': 0.49415129820505777} | train loss {'Reaction outcome loss': 0.45567742563838504, 'Total loss': 0.45567742563838504}
2022-12-31 15:15:39,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:39,685 INFO:     Epoch: 9
2022-12-31 15:15:41,272 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5061228632926941, 'Total loss': 0.5061228632926941} | train loss {'Reaction outcome loss': 0.4434981617505533, 'Total loss': 0.4434981617505533}
2022-12-31 15:15:41,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:41,273 INFO:     Epoch: 10
2022-12-31 15:15:42,905 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4807241320610046, 'Total loss': 0.4807241320610046} | train loss {'Reaction outcome loss': 0.44158315223498934, 'Total loss': 0.44158315223498934}
2022-12-31 15:15:42,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:42,905 INFO:     Epoch: 11
2022-12-31 15:15:44,530 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4586239161590735, 'Total loss': 0.4586239161590735} | train loss {'Reaction outcome loss': 0.43724994782875054, 'Total loss': 0.43724994782875054}
2022-12-31 15:15:44,531 INFO:     Found new best model at epoch 11
2022-12-31 15:15:44,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:44,532 INFO:     Epoch: 12
2022-12-31 15:15:46,132 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4792023499806722, 'Total loss': 0.4792023499806722} | train loss {'Reaction outcome loss': 0.4270114478566786, 'Total loss': 0.4270114478566786}
2022-12-31 15:15:46,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:46,132 INFO:     Epoch: 13
2022-12-31 15:15:47,749 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4662199517091115, 'Total loss': 0.4662199517091115} | train loss {'Reaction outcome loss': 0.41718726159229763, 'Total loss': 0.41718726159229763}
2022-12-31 15:15:47,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:47,751 INFO:     Epoch: 14
2022-12-31 15:15:49,388 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44298563500245414, 'Total loss': 0.44298563500245414} | train loss {'Reaction outcome loss': 0.41644559855008645, 'Total loss': 0.41644559855008645}
2022-12-31 15:15:49,388 INFO:     Found new best model at epoch 14
2022-12-31 15:15:49,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:49,389 INFO:     Epoch: 15
2022-12-31 15:15:50,975 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4993052065372467, 'Total loss': 0.4993052065372467} | train loss {'Reaction outcome loss': 0.41116615800853196, 'Total loss': 0.41116615800853196}
2022-12-31 15:15:50,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:50,976 INFO:     Epoch: 16
2022-12-31 15:15:52,576 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45495169162750243, 'Total loss': 0.45495169162750243} | train loss {'Reaction outcome loss': 0.40794536985293794, 'Total loss': 0.40794536985293794}
2022-12-31 15:15:52,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:52,576 INFO:     Epoch: 17
2022-12-31 15:15:54,178 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46780578295389813, 'Total loss': 0.46780578295389813} | train loss {'Reaction outcome loss': 0.40133049224850037, 'Total loss': 0.40133049224850037}
2022-12-31 15:15:54,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:54,179 INFO:     Epoch: 18
2022-12-31 15:15:55,764 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44008007446924846, 'Total loss': 0.44008007446924846} | train loss {'Reaction outcome loss': 0.3926771586339404, 'Total loss': 0.3926771586339404}
2022-12-31 15:15:55,764 INFO:     Found new best model at epoch 18
2022-12-31 15:15:55,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:55,765 INFO:     Epoch: 19
2022-12-31 15:15:57,395 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48169502218564353, 'Total loss': 0.48169502218564353} | train loss {'Reaction outcome loss': 0.3948836844332897, 'Total loss': 0.3948836844332897}
2022-12-31 15:15:57,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:57,395 INFO:     Epoch: 20
2022-12-31 15:15:59,026 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4934057851632436, 'Total loss': 0.4934057851632436} | train loss {'Reaction outcome loss': 0.3841973850707503, 'Total loss': 0.3841973850707503}
2022-12-31 15:15:59,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:15:59,026 INFO:     Epoch: 21
2022-12-31 15:16:00,611 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46817280848821, 'Total loss': 0.46817280848821} | train loss {'Reaction outcome loss': 0.3864196427438381, 'Total loss': 0.3864196427438381}
2022-12-31 15:16:00,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:00,611 INFO:     Epoch: 22
2022-12-31 15:16:02,209 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47009644110997517, 'Total loss': 0.47009644110997517} | train loss {'Reaction outcome loss': 0.36783959164562885, 'Total loss': 0.36783959164562885}
2022-12-31 15:16:02,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:02,209 INFO:     Epoch: 23
2022-12-31 15:16:03,804 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4454930057128271, 'Total loss': 0.4454930057128271} | train loss {'Reaction outcome loss': 0.37205638070284885, 'Total loss': 0.37205638070284885}
2022-12-31 15:16:03,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:03,804 INFO:     Epoch: 24
2022-12-31 15:16:05,406 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4351925432682037, 'Total loss': 0.4351925432682037} | train loss {'Reaction outcome loss': 0.36602115666452983, 'Total loss': 0.36602115666452983}
2022-12-31 15:16:05,406 INFO:     Found new best model at epoch 24
2022-12-31 15:16:05,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:05,407 INFO:     Epoch: 25
2022-12-31 15:16:07,040 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43298406365017095, 'Total loss': 0.43298406365017095} | train loss {'Reaction outcome loss': 0.36010753616255564, 'Total loss': 0.36010753616255564}
2022-12-31 15:16:07,041 INFO:     Found new best model at epoch 25
2022-12-31 15:16:07,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:07,042 INFO:     Epoch: 26
2022-12-31 15:16:08,624 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4801180432240168, 'Total loss': 0.4801180432240168} | train loss {'Reaction outcome loss': 0.3561425350171371, 'Total loss': 0.3561425350171371}
2022-12-31 15:16:08,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:08,625 INFO:     Epoch: 27
2022-12-31 15:16:10,241 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3970712373654048, 'Total loss': 0.3970712373654048} | train loss {'Reaction outcome loss': 0.3446025850564024, 'Total loss': 0.3446025850564024}
2022-12-31 15:16:10,241 INFO:     Found new best model at epoch 27
2022-12-31 15:16:10,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:10,242 INFO:     Epoch: 28
2022-12-31 15:16:11,861 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4447779754797618, 'Total loss': 0.4447779754797618} | train loss {'Reaction outcome loss': 0.34329339033876455, 'Total loss': 0.34329339033876455}
2022-12-31 15:16:11,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:11,861 INFO:     Epoch: 29
2022-12-31 15:16:13,455 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4254409501949946, 'Total loss': 0.4254409501949946} | train loss {'Reaction outcome loss': 0.33777068888455847, 'Total loss': 0.33777068888455847}
2022-12-31 15:16:13,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:13,455 INFO:     Epoch: 30
2022-12-31 15:16:15,052 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43347740868727364, 'Total loss': 0.43347740868727364} | train loss {'Reaction outcome loss': 0.33008585341383506, 'Total loss': 0.33008585341383506}
2022-12-31 15:16:15,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:15,052 INFO:     Epoch: 31
2022-12-31 15:16:16,646 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43295587301254274, 'Total loss': 0.43295587301254274} | train loss {'Reaction outcome loss': 0.3306810270695791, 'Total loss': 0.3306810270695791}
2022-12-31 15:16:16,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:16,646 INFO:     Epoch: 32
2022-12-31 15:16:18,235 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4179302910963694, 'Total loss': 0.4179302910963694} | train loss {'Reaction outcome loss': 0.3282119415863587, 'Total loss': 0.3282119415863587}
2022-12-31 15:16:18,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:18,236 INFO:     Epoch: 33
2022-12-31 15:16:19,867 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40888849794864657, 'Total loss': 0.40888849794864657} | train loss {'Reaction outcome loss': 0.32345840688386973, 'Total loss': 0.32345840688386973}
2022-12-31 15:16:19,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:19,868 INFO:     Epoch: 34
2022-12-31 15:16:21,502 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3937599307547013, 'Total loss': 0.3937599307547013} | train loss {'Reaction outcome loss': 0.31492342223433684, 'Total loss': 0.31492342223433684}
2022-12-31 15:16:21,503 INFO:     Found new best model at epoch 34
2022-12-31 15:16:21,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:21,504 INFO:     Epoch: 35
2022-12-31 15:16:23,109 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47063856224219003, 'Total loss': 0.47063856224219003} | train loss {'Reaction outcome loss': 0.31322551602973553, 'Total loss': 0.31322551602973553}
2022-12-31 15:16:23,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:23,109 INFO:     Epoch: 36
2022-12-31 15:16:24,740 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41523734231789905, 'Total loss': 0.41523734231789905} | train loss {'Reaction outcome loss': 0.3109224123377217, 'Total loss': 0.3109224123377217}
2022-12-31 15:16:24,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:24,741 INFO:     Epoch: 37
2022-12-31 15:16:26,340 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4275944739580154, 'Total loss': 0.4275944739580154} | train loss {'Reaction outcome loss': 0.30300765612373387, 'Total loss': 0.30300765612373387}
2022-12-31 15:16:26,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:26,340 INFO:     Epoch: 38
2022-12-31 15:16:27,935 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42922543187936146, 'Total loss': 0.42922543187936146} | train loss {'Reaction outcome loss': 0.29760003032801796, 'Total loss': 0.29760003032801796}
2022-12-31 15:16:27,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:27,935 INFO:     Epoch: 39
2022-12-31 15:16:29,536 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4295339897274971, 'Total loss': 0.4295339897274971} | train loss {'Reaction outcome loss': 0.30225287360159586, 'Total loss': 0.30225287360159586}
2022-12-31 15:16:29,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:29,536 INFO:     Epoch: 40
2022-12-31 15:16:31,145 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4237262447675069, 'Total loss': 0.4237262447675069} | train loss {'Reaction outcome loss': 0.2951186517403074, 'Total loss': 0.2951186517403074}
2022-12-31 15:16:31,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:31,145 INFO:     Epoch: 41
2022-12-31 15:16:32,739 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43415029992659887, 'Total loss': 0.43415029992659887} | train loss {'Reaction outcome loss': 0.3004933951055481, 'Total loss': 0.3004933951055481}
2022-12-31 15:16:32,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:32,739 INFO:     Epoch: 42
2022-12-31 15:16:34,370 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45597828924655914, 'Total loss': 0.45597828924655914} | train loss {'Reaction outcome loss': 0.2892695598467423, 'Total loss': 0.2892695598467423}
2022-12-31 15:16:34,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:34,370 INFO:     Epoch: 43
2022-12-31 15:16:35,968 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4178066949049632, 'Total loss': 0.4178066949049632} | train loss {'Reaction outcome loss': 0.2865992223667185, 'Total loss': 0.2865992223667185}
2022-12-31 15:16:35,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:35,969 INFO:     Epoch: 44
2022-12-31 15:16:37,581 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4311393916606903, 'Total loss': 0.4311393916606903} | train loss {'Reaction outcome loss': 0.28394020305960066, 'Total loss': 0.28394020305960066}
2022-12-31 15:16:37,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:37,582 INFO:     Epoch: 45
2022-12-31 15:16:39,191 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4141907533009847, 'Total loss': 0.4141907533009847} | train loss {'Reaction outcome loss': 0.2782184557622149, 'Total loss': 0.2782184557622149}
2022-12-31 15:16:39,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:39,191 INFO:     Epoch: 46
2022-12-31 15:16:40,789 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4154571533203125, 'Total loss': 0.4154571533203125} | train loss {'Reaction outcome loss': 0.2755405232854133, 'Total loss': 0.2755405232854133}
2022-12-31 15:16:40,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:40,789 INFO:     Epoch: 47
2022-12-31 15:16:42,423 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4472228040297826, 'Total loss': 0.4472228040297826} | train loss {'Reaction outcome loss': 0.2800035460913268, 'Total loss': 0.2800035460913268}
2022-12-31 15:16:42,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:42,423 INFO:     Epoch: 48
2022-12-31 15:16:44,032 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4266810039679209, 'Total loss': 0.4266810039679209} | train loss {'Reaction outcome loss': 0.27996243128593823, 'Total loss': 0.27996243128593823}
2022-12-31 15:16:44,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:44,032 INFO:     Epoch: 49
2022-12-31 15:16:45,644 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43920378883679706, 'Total loss': 0.43920378883679706} | train loss {'Reaction outcome loss': 0.2688606208611796, 'Total loss': 0.2688606208611796}
2022-12-31 15:16:45,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:45,644 INFO:     Epoch: 50
2022-12-31 15:16:47,257 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41175828178723656, 'Total loss': 0.41175828178723656} | train loss {'Reaction outcome loss': 0.2682739742725653, 'Total loss': 0.2682739742725653}
2022-12-31 15:16:47,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:47,257 INFO:     Epoch: 51
2022-12-31 15:16:48,861 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42232462763786316, 'Total loss': 0.42232462763786316} | train loss {'Reaction outcome loss': 0.26769095849599284, 'Total loss': 0.26769095849599284}
2022-12-31 15:16:48,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:48,862 INFO:     Epoch: 52
2022-12-31 15:16:50,469 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41699478924274447, 'Total loss': 0.41699478924274447} | train loss {'Reaction outcome loss': 0.26712114391780467, 'Total loss': 0.26712114391780467}
2022-12-31 15:16:50,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:50,469 INFO:     Epoch: 53
2022-12-31 15:16:52,094 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3897252490123113, 'Total loss': 0.3897252490123113} | train loss {'Reaction outcome loss': 0.26033285555232616, 'Total loss': 0.26033285555232616}
2022-12-31 15:16:52,094 INFO:     Found new best model at epoch 53
2022-12-31 15:16:52,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:52,095 INFO:     Epoch: 54
2022-12-31 15:16:53,687 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4150438606739044, 'Total loss': 0.4150438606739044} | train loss {'Reaction outcome loss': 0.26416357251795103, 'Total loss': 0.26416357251795103}
2022-12-31 15:16:53,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:53,687 INFO:     Epoch: 55
2022-12-31 15:16:55,286 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4014848756293456, 'Total loss': 0.4014848756293456} | train loss {'Reaction outcome loss': 0.2600658752132941, 'Total loss': 0.2600658752132941}
2022-12-31 15:16:55,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:55,287 INFO:     Epoch: 56
2022-12-31 15:16:56,905 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4528234084447225, 'Total loss': 0.4528234084447225} | train loss {'Reaction outcome loss': 0.2534250332056171, 'Total loss': 0.2534250332056171}
2022-12-31 15:16:56,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:56,906 INFO:     Epoch: 57
2022-12-31 15:16:58,511 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3955019106467565, 'Total loss': 0.3955019106467565} | train loss {'Reaction outcome loss': 0.2599360919251603, 'Total loss': 0.2599360919251603}
2022-12-31 15:16:58,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:16:58,512 INFO:     Epoch: 58
2022-12-31 15:17:00,108 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4088880648215612, 'Total loss': 0.4088880648215612} | train loss {'Reaction outcome loss': 0.2500292894831539, 'Total loss': 0.2500292894831539}
2022-12-31 15:17:00,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:00,108 INFO:     Epoch: 59
2022-12-31 15:17:01,729 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4265398283799489, 'Total loss': 0.4265398283799489} | train loss {'Reaction outcome loss': 0.2525356919062834, 'Total loss': 0.2525356919062834}
2022-12-31 15:17:01,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:01,730 INFO:     Epoch: 60
2022-12-31 15:17:03,346 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41092739601929984, 'Total loss': 0.41092739601929984} | train loss {'Reaction outcome loss': 0.2535152861807686, 'Total loss': 0.2535152861807686}
2022-12-31 15:17:03,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:03,347 INFO:     Epoch: 61
2022-12-31 15:17:04,963 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4051975424091021, 'Total loss': 0.4051975424091021} | train loss {'Reaction outcome loss': 0.2519727511073116, 'Total loss': 0.2519727511073116}
2022-12-31 15:17:04,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:04,963 INFO:     Epoch: 62
2022-12-31 15:17:06,579 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41677474876244863, 'Total loss': 0.41677474876244863} | train loss {'Reaction outcome loss': 0.2511795898423578, 'Total loss': 0.2511795898423578}
2022-12-31 15:17:06,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:06,579 INFO:     Epoch: 63
2022-12-31 15:17:08,175 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45431376496950787, 'Total loss': 0.45431376496950787} | train loss {'Reaction outcome loss': 0.24902453909825234, 'Total loss': 0.24902453909825234}
2022-12-31 15:17:08,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:08,176 INFO:     Epoch: 64
2022-12-31 15:17:09,797 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4172115961710612, 'Total loss': 0.4172115961710612} | train loss {'Reaction outcome loss': 0.24038189823610068, 'Total loss': 0.24038189823610068}
2022-12-31 15:17:09,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:09,797 INFO:     Epoch: 65
2022-12-31 15:17:11,416 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4487844179073969, 'Total loss': 0.4487844179073969} | train loss {'Reaction outcome loss': 0.24271123391324587, 'Total loss': 0.24271123391324587}
2022-12-31 15:17:11,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:11,417 INFO:     Epoch: 66
2022-12-31 15:17:13,007 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40139268934726713, 'Total loss': 0.40139268934726713} | train loss {'Reaction outcome loss': 0.23238056212881186, 'Total loss': 0.23238056212881186}
2022-12-31 15:17:13,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:13,007 INFO:     Epoch: 67
2022-12-31 15:17:14,608 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45470975935459135, 'Total loss': 0.45470975935459135} | train loss {'Reaction outcome loss': 0.2362610869055247, 'Total loss': 0.2362610869055247}
2022-12-31 15:17:14,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:14,608 INFO:     Epoch: 68
2022-12-31 15:17:16,212 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4423667103052139, 'Total loss': 0.4423667103052139} | train loss {'Reaction outcome loss': 0.24694367509715967, 'Total loss': 0.24694367509715967}
2022-12-31 15:17:16,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:16,212 INFO:     Epoch: 69
2022-12-31 15:17:17,809 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4230817844470342, 'Total loss': 0.4230817844470342} | train loss {'Reaction outcome loss': 0.24074847489105958, 'Total loss': 0.24074847489105958}
2022-12-31 15:17:17,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:17,810 INFO:     Epoch: 70
2022-12-31 15:17:19,441 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4592552572488785, 'Total loss': 0.4592552572488785} | train loss {'Reaction outcome loss': 0.23827592391575123, 'Total loss': 0.23827592391575123}
2022-12-31 15:17:19,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:19,442 INFO:     Epoch: 71
2022-12-31 15:17:21,056 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39899627876778443, 'Total loss': 0.39899627876778443} | train loss {'Reaction outcome loss': 0.24447802002167832, 'Total loss': 0.24447802002167832}
2022-12-31 15:17:21,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:21,056 INFO:     Epoch: 72
2022-12-31 15:17:22,643 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.437831782301267, 'Total loss': 0.437831782301267} | train loss {'Reaction outcome loss': 0.23257616668749248, 'Total loss': 0.23257616668749248}
2022-12-31 15:17:22,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:22,643 INFO:     Epoch: 73
2022-12-31 15:17:24,246 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4250754108031591, 'Total loss': 0.4250754108031591} | train loss {'Reaction outcome loss': 0.23980733862377868, 'Total loss': 0.23980733862377868}
2022-12-31 15:17:24,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:24,247 INFO:     Epoch: 74
2022-12-31 15:17:25,879 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44608047803243, 'Total loss': 0.44608047803243} | train loss {'Reaction outcome loss': 0.2310834096024071, 'Total loss': 0.2310834096024071}
2022-12-31 15:17:25,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:25,880 INFO:     Epoch: 75
2022-12-31 15:17:27,484 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46288328170776366, 'Total loss': 0.46288328170776366} | train loss {'Reaction outcome loss': 0.22435054955936043, 'Total loss': 0.22435054955936043}
2022-12-31 15:17:27,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:27,484 INFO:     Epoch: 76
2022-12-31 15:17:29,120 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.426289501786232, 'Total loss': 0.426289501786232} | train loss {'Reaction outcome loss': 0.2332634170043425, 'Total loss': 0.2332634170043425}
2022-12-31 15:17:29,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:29,121 INFO:     Epoch: 77
2022-12-31 15:17:30,727 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38606505244970324, 'Total loss': 0.38606505244970324} | train loss {'Reaction outcome loss': 0.22059156364985627, 'Total loss': 0.22059156364985627}
2022-12-31 15:17:30,727 INFO:     Found new best model at epoch 77
2022-12-31 15:17:30,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:30,728 INFO:     Epoch: 78
2022-12-31 15:17:32,342 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4176691949367523, 'Total loss': 0.4176691949367523} | train loss {'Reaction outcome loss': 0.23062374145064476, 'Total loss': 0.23062374145064476}
2022-12-31 15:17:32,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:32,342 INFO:     Epoch: 79
2022-12-31 15:17:33,943 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4175688147544861, 'Total loss': 0.4175688147544861} | train loss {'Reaction outcome loss': 0.22367457012870234, 'Total loss': 0.22367457012870234}
2022-12-31 15:17:33,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:33,944 INFO:     Epoch: 80
2022-12-31 15:17:35,525 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.410540409386158, 'Total loss': 0.410540409386158} | train loss {'Reaction outcome loss': 0.22272578526940875, 'Total loss': 0.22272578526940875}
2022-12-31 15:17:35,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:35,525 INFO:     Epoch: 81
2022-12-31 15:17:37,131 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46421897212664287, 'Total loss': 0.46421897212664287} | train loss {'Reaction outcome loss': 0.2226905253219561, 'Total loss': 0.2226905253219561}
2022-12-31 15:17:37,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:37,131 INFO:     Epoch: 82
2022-12-31 15:17:38,732 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42330329020818075, 'Total loss': 0.42330329020818075} | train loss {'Reaction outcome loss': 0.2245371640340364, 'Total loss': 0.2245371640340364}
2022-12-31 15:17:38,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:38,733 INFO:     Epoch: 83
2022-12-31 15:17:40,326 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4763683001200358, 'Total loss': 0.4763683001200358} | train loss {'Reaction outcome loss': 0.21563725196246575, 'Total loss': 0.21563725196246575}
2022-12-31 15:17:40,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:40,326 INFO:     Epoch: 84
2022-12-31 15:17:41,960 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41379846235116324, 'Total loss': 0.41379846235116324} | train loss {'Reaction outcome loss': 0.22365738630947404, 'Total loss': 0.22365738630947404}
2022-12-31 15:17:41,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:41,961 INFO:     Epoch: 85
2022-12-31 15:17:43,579 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4231227854887644, 'Total loss': 0.4231227854887644} | train loss {'Reaction outcome loss': 0.22801009512567608, 'Total loss': 0.22801009512567608}
2022-12-31 15:17:43,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:43,579 INFO:     Epoch: 86
2022-12-31 15:17:45,191 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.442794335881869, 'Total loss': 0.442794335881869} | train loss {'Reaction outcome loss': 0.22023278980916977, 'Total loss': 0.22023278980916977}
2022-12-31 15:17:45,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:45,192 INFO:     Epoch: 87
2022-12-31 15:17:46,812 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4056296666463216, 'Total loss': 0.4056296666463216} | train loss {'Reaction outcome loss': 0.21170507859520232, 'Total loss': 0.21170507859520232}
2022-12-31 15:17:46,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:46,812 INFO:     Epoch: 88
2022-12-31 15:17:48,431 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4473120013872782, 'Total loss': 0.4473120013872782} | train loss {'Reaction outcome loss': 0.2140189391717206, 'Total loss': 0.2140189391717206}
2022-12-31 15:17:48,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:48,431 INFO:     Epoch: 89
2022-12-31 15:17:50,026 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40640794932842256, 'Total loss': 0.40640794932842256} | train loss {'Reaction outcome loss': 0.21319657183816507, 'Total loss': 0.21319657183816507}
2022-12-31 15:17:50,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:50,027 INFO:     Epoch: 90
2022-12-31 15:17:51,659 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4033090313275655, 'Total loss': 0.4033090313275655} | train loss {'Reaction outcome loss': 0.21159390099754516, 'Total loss': 0.21159390099754516}
2022-12-31 15:17:51,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:51,660 INFO:     Epoch: 91
2022-12-31 15:17:53,295 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39545757124821346, 'Total loss': 0.39545757124821346} | train loss {'Reaction outcome loss': 0.2239810468520235, 'Total loss': 0.2239810468520235}
2022-12-31 15:17:53,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:53,295 INFO:     Epoch: 92
2022-12-31 15:17:54,907 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44282185335954033, 'Total loss': 0.44282185335954033} | train loss {'Reaction outcome loss': 0.21265269614701723, 'Total loss': 0.21265269614701723}
2022-12-31 15:17:54,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:54,908 INFO:     Epoch: 93
2022-12-31 15:17:56,536 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4204933322966099, 'Total loss': 0.4204933322966099} | train loss {'Reaction outcome loss': 0.21590236842251606, 'Total loss': 0.21590236842251606}
2022-12-31 15:17:56,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:56,537 INFO:     Epoch: 94
2022-12-31 15:17:58,142 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42270947496096295, 'Total loss': 0.42270947496096295} | train loss {'Reaction outcome loss': 0.20845393311014793, 'Total loss': 0.20845393311014793}
2022-12-31 15:17:58,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:58,143 INFO:     Epoch: 95
2022-12-31 15:17:59,771 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.430593878030777, 'Total loss': 0.430593878030777} | train loss {'Reaction outcome loss': 0.2077418437132435, 'Total loss': 0.2077418437132435}
2022-12-31 15:17:59,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:17:59,772 INFO:     Epoch: 96
2022-12-31 15:18:01,396 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4321775158246358, 'Total loss': 0.4321775158246358} | train loss {'Reaction outcome loss': 0.21441810924804558, 'Total loss': 0.21441810924804558}
2022-12-31 15:18:01,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:01,397 INFO:     Epoch: 97
2022-12-31 15:18:02,996 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4329685236016909, 'Total loss': 0.4329685236016909} | train loss {'Reaction outcome loss': 0.20399145334007313, 'Total loss': 0.20399145334007313}
2022-12-31 15:18:02,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:02,996 INFO:     Epoch: 98
2022-12-31 15:18:04,606 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4518181433280309, 'Total loss': 0.4518181433280309} | train loss {'Reaction outcome loss': 0.19980162734940757, 'Total loss': 0.19980162734940757}
2022-12-31 15:18:04,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:04,607 INFO:     Epoch: 99
2022-12-31 15:18:06,211 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4496212273836136, 'Total loss': 0.4496212273836136} | train loss {'Reaction outcome loss': 0.20638075373033538, 'Total loss': 0.20638075373033538}
2022-12-31 15:18:06,211 INFO:     Best model found after epoch 78 of 100.
2022-12-31 15:18:06,211 INFO:   Done with stage: TRAINING
2022-12-31 15:18:06,211 INFO:   Starting stage: EVALUATION
2022-12-31 15:18:06,345 INFO:   Done with stage: EVALUATION
2022-12-31 15:18:06,345 INFO:   Leaving out SEQ value Fold_9
2022-12-31 15:18:06,358 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 15:18:06,358 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:18:06,997 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:18:06,997 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:18:07,066 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:18:07,066 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:18:07,066 INFO:     No hyperparam tuning for this model
2022-12-31 15:18:07,066 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:18:07,066 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:18:07,067 INFO:     None feature selector for col prot
2022-12-31 15:18:07,067 INFO:     None feature selector for col prot
2022-12-31 15:18:07,067 INFO:     None feature selector for col prot
2022-12-31 15:18:07,068 INFO:     None feature selector for col chem
2022-12-31 15:18:07,068 INFO:     None feature selector for col chem
2022-12-31 15:18:07,068 INFO:     None feature selector for col chem
2022-12-31 15:18:07,068 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:18:07,068 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:18:07,070 INFO:     Number of params in model 223921
2022-12-31 15:18:07,073 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:18:07,073 INFO:   Starting stage: TRAINING
2022-12-31 15:18:07,116 INFO:     Val loss before train {'Reaction outcome loss': 0.9953607479731242, 'Total loss': 0.9953607479731242}
2022-12-31 15:18:07,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:07,116 INFO:     Epoch: 0
2022-12-31 15:18:08,761 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6885254919528961, 'Total loss': 0.6885254919528961} | train loss {'Reaction outcome loss': 0.81571746379326, 'Total loss': 0.81571746379326}
2022-12-31 15:18:08,762 INFO:     Found new best model at epoch 0
2022-12-31 15:18:08,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:08,763 INFO:     Epoch: 1
2022-12-31 15:18:10,396 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5737817883491516, 'Total loss': 0.5737817883491516} | train loss {'Reaction outcome loss': 0.5938539553642024, 'Total loss': 0.5938539553642024}
2022-12-31 15:18:10,396 INFO:     Found new best model at epoch 1
2022-12-31 15:18:10,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:10,397 INFO:     Epoch: 2
2022-12-31 15:18:11,995 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5679466644922893, 'Total loss': 0.5679466644922893} | train loss {'Reaction outcome loss': 0.521206014128267, 'Total loss': 0.521206014128267}
2022-12-31 15:18:11,995 INFO:     Found new best model at epoch 2
2022-12-31 15:18:11,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:11,996 INFO:     Epoch: 3
2022-12-31 15:18:13,614 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5490715742111206, 'Total loss': 0.5490715742111206} | train loss {'Reaction outcome loss': 0.5327455539634263, 'Total loss': 0.5327455539634263}
2022-12-31 15:18:13,614 INFO:     Found new best model at epoch 3
2022-12-31 15:18:13,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:13,615 INFO:     Epoch: 4
2022-12-31 15:18:15,225 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5410734792550405, 'Total loss': 0.5410734792550405} | train loss {'Reaction outcome loss': 0.5060761273987051, 'Total loss': 0.5060761273987051}
2022-12-31 15:18:15,225 INFO:     Found new best model at epoch 4
2022-12-31 15:18:15,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:15,226 INFO:     Epoch: 5
2022-12-31 15:18:16,814 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5146566152572631, 'Total loss': 0.5146566152572631} | train loss {'Reaction outcome loss': 0.4678071358281633, 'Total loss': 0.4678071358281633}
2022-12-31 15:18:16,814 INFO:     Found new best model at epoch 5
2022-12-31 15:18:16,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:16,815 INFO:     Epoch: 6
2022-12-31 15:18:18,431 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.501767693956693, 'Total loss': 0.501767693956693} | train loss {'Reaction outcome loss': 0.4637740430476117, 'Total loss': 0.4637740430476117}
2022-12-31 15:18:18,431 INFO:     Found new best model at epoch 6
2022-12-31 15:18:18,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:18,432 INFO:     Epoch: 7
2022-12-31 15:18:20,077 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4837953040997187, 'Total loss': 0.4837953040997187} | train loss {'Reaction outcome loss': 0.46102874272543454, 'Total loss': 0.46102874272543454}
2022-12-31 15:18:20,077 INFO:     Found new best model at epoch 7
2022-12-31 15:18:20,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:20,078 INFO:     Epoch: 8
2022-12-31 15:18:21,683 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5148582100868225, 'Total loss': 0.5148582100868225} | train loss {'Reaction outcome loss': 0.5041606113545772, 'Total loss': 0.5041606113545772}
2022-12-31 15:18:21,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:21,683 INFO:     Epoch: 9
2022-12-31 15:18:23,316 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5485217452049256, 'Total loss': 0.5485217452049256} | train loss {'Reaction outcome loss': 0.46005590400402097, 'Total loss': 0.46005590400402097}
2022-12-31 15:18:23,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:23,316 INFO:     Epoch: 10
2022-12-31 15:18:24,933 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5049873093763987, 'Total loss': 0.5049873093763987} | train loss {'Reaction outcome loss': 0.47774430330626777, 'Total loss': 0.47774430330626777}
2022-12-31 15:18:24,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:24,934 INFO:     Epoch: 11
2022-12-31 15:18:26,545 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.504390549659729, 'Total loss': 0.504390549659729} | train loss {'Reaction outcome loss': 0.4372409853503864, 'Total loss': 0.4372409853503864}
2022-12-31 15:18:26,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:26,546 INFO:     Epoch: 12
2022-12-31 15:18:28,164 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5071293572584789, 'Total loss': 0.5071293572584789} | train loss {'Reaction outcome loss': 0.42958938503178995, 'Total loss': 0.42958938503178995}
2022-12-31 15:18:28,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:28,164 INFO:     Epoch: 13
2022-12-31 15:18:29,789 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48844860394795736, 'Total loss': 0.48844860394795736} | train loss {'Reaction outcome loss': 0.4319094635606946, 'Total loss': 0.4319094635606946}
2022-12-31 15:18:29,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:29,789 INFO:     Epoch: 14
2022-12-31 15:18:31,410 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48589298129081726, 'Total loss': 0.48589298129081726} | train loss {'Reaction outcome loss': 0.4191717015653368, 'Total loss': 0.4191717015653368}
2022-12-31 15:18:31,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:31,411 INFO:     Epoch: 15
2022-12-31 15:18:33,040 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4790401056408882, 'Total loss': 0.4790401056408882} | train loss {'Reaction outcome loss': 0.4160977960496709, 'Total loss': 0.4160977960496709}
2022-12-31 15:18:33,041 INFO:     Found new best model at epoch 15
2022-12-31 15:18:33,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:33,042 INFO:     Epoch: 16
2022-12-31 15:18:34,642 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4833609640598297, 'Total loss': 0.4833609640598297} | train loss {'Reaction outcome loss': 0.4159139807747704, 'Total loss': 0.4159139807747704}
2022-12-31 15:18:34,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:34,642 INFO:     Epoch: 17
2022-12-31 15:18:36,259 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49117399056752525, 'Total loss': 0.49117399056752525} | train loss {'Reaction outcome loss': 0.4016144475967124, 'Total loss': 0.4016144475967124}
2022-12-31 15:18:36,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:36,260 INFO:     Epoch: 18
2022-12-31 15:18:37,894 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4542296310265859, 'Total loss': 0.4542296310265859} | train loss {'Reaction outcome loss': 0.40413631789683213, 'Total loss': 0.40413631789683213}
2022-12-31 15:18:37,894 INFO:     Found new best model at epoch 18
2022-12-31 15:18:37,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:37,895 INFO:     Epoch: 19
2022-12-31 15:18:39,515 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49403001070022584, 'Total loss': 0.49403001070022584} | train loss {'Reaction outcome loss': 0.39688297682374285, 'Total loss': 0.39688297682374285}
2022-12-31 15:18:39,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:39,515 INFO:     Epoch: 20
2022-12-31 15:18:41,148 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4825432628393173, 'Total loss': 0.4825432628393173} | train loss {'Reaction outcome loss': 0.4037472907237817, 'Total loss': 0.4037472907237817}
2022-12-31 15:18:41,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:41,149 INFO:     Epoch: 21
2022-12-31 15:18:42,772 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4758468568325043, 'Total loss': 0.4758468568325043} | train loss {'Reaction outcome loss': 0.4128703018785387, 'Total loss': 0.4128703018785387}
2022-12-31 15:18:42,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:42,772 INFO:     Epoch: 22
2022-12-31 15:18:44,394 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48992392619450886, 'Total loss': 0.48992392619450886} | train loss {'Reaction outcome loss': 0.386055929451317, 'Total loss': 0.386055929451317}
2022-12-31 15:18:44,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:44,394 INFO:     Epoch: 23
2022-12-31 15:18:46,027 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4574388752381007, 'Total loss': 0.4574388752381007} | train loss {'Reaction outcome loss': 0.3962341980853428, 'Total loss': 0.3962341980853428}
2022-12-31 15:18:46,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:46,028 INFO:     Epoch: 24
2022-12-31 15:18:47,648 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45800250669320425, 'Total loss': 0.45800250669320425} | train loss {'Reaction outcome loss': 0.3795847267459106, 'Total loss': 0.3795847267459106}
2022-12-31 15:18:47,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:47,648 INFO:     Epoch: 25
2022-12-31 15:18:49,280 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4601691524187724, 'Total loss': 0.4601691524187724} | train loss {'Reaction outcome loss': 0.37071290018671343, 'Total loss': 0.37071290018671343}
2022-12-31 15:18:49,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:49,280 INFO:     Epoch: 26
2022-12-31 15:18:50,936 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5322211484114329, 'Total loss': 0.5322211484114329} | train loss {'Reaction outcome loss': 0.3692895072795775, 'Total loss': 0.3692895072795775}
2022-12-31 15:18:50,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:50,936 INFO:     Epoch: 27
2022-12-31 15:18:52,543 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44684694409370423, 'Total loss': 0.44684694409370423} | train loss {'Reaction outcome loss': 0.3934338400342866, 'Total loss': 0.3934338400342866}
2022-12-31 15:18:52,544 INFO:     Found new best model at epoch 27
2022-12-31 15:18:52,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:52,545 INFO:     Epoch: 28
2022-12-31 15:18:54,196 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4337516377369563, 'Total loss': 0.4337516377369563} | train loss {'Reaction outcome loss': 0.36256908768437046, 'Total loss': 0.36256908768437046}
2022-12-31 15:18:54,196 INFO:     Found new best model at epoch 28
2022-12-31 15:18:54,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:54,197 INFO:     Epoch: 29
2022-12-31 15:18:55,807 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5350432892640432, 'Total loss': 0.5350432892640432} | train loss {'Reaction outcome loss': 0.35789839596744033, 'Total loss': 0.35789839596744033}
2022-12-31 15:18:55,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:55,807 INFO:     Epoch: 30
2022-12-31 15:18:57,398 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5072954932848612, 'Total loss': 0.5072954932848612} | train loss {'Reaction outcome loss': 0.37247967190932535, 'Total loss': 0.37247967190932535}
2022-12-31 15:18:57,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:57,399 INFO:     Epoch: 31
2022-12-31 15:18:58,999 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46473175088564556, 'Total loss': 0.46473175088564556} | train loss {'Reaction outcome loss': 0.3519702719953046, 'Total loss': 0.3519702719953046}
2022-12-31 15:18:58,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:18:58,999 INFO:     Epoch: 32
2022-12-31 15:19:00,601 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4513892074426015, 'Total loss': 0.4513892074426015} | train loss {'Reaction outcome loss': 0.34174631456540816, 'Total loss': 0.34174631456540816}
2022-12-31 15:19:00,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:00,601 INFO:     Epoch: 33
2022-12-31 15:19:02,216 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47904526789983115, 'Total loss': 0.47904526789983115} | train loss {'Reaction outcome loss': 0.34219004867929104, 'Total loss': 0.34219004867929104}
2022-12-31 15:19:02,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:02,217 INFO:     Epoch: 34
2022-12-31 15:19:03,863 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42957424024740853, 'Total loss': 0.42957424024740853} | train loss {'Reaction outcome loss': 0.33637684758455644, 'Total loss': 0.33637684758455644}
2022-12-31 15:19:03,864 INFO:     Found new best model at epoch 34
2022-12-31 15:19:03,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:03,865 INFO:     Epoch: 35
2022-12-31 15:19:05,498 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4579462548096975, 'Total loss': 0.4579462548096975} | train loss {'Reaction outcome loss': 0.3271898953142332, 'Total loss': 0.3271898953142332}
2022-12-31 15:19:05,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:05,498 INFO:     Epoch: 36
2022-12-31 15:19:07,099 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4147821327050527, 'Total loss': 0.4147821327050527} | train loss {'Reaction outcome loss': 0.32954661935223883, 'Total loss': 0.32954661935223883}
2022-12-31 15:19:07,099 INFO:     Found new best model at epoch 36
2022-12-31 15:19:07,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:07,100 INFO:     Epoch: 37
2022-12-31 15:19:08,702 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.433673561612765, 'Total loss': 0.433673561612765} | train loss {'Reaction outcome loss': 0.31881339207450143, 'Total loss': 0.31881339207450143}
2022-12-31 15:19:08,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:08,702 INFO:     Epoch: 38
2022-12-31 15:19:10,293 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4325693815946579, 'Total loss': 0.4325693815946579} | train loss {'Reaction outcome loss': 0.31084677239583025, 'Total loss': 0.31084677239583025}
2022-12-31 15:19:10,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:10,293 INFO:     Epoch: 39
2022-12-31 15:19:11,892 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.459567137559255, 'Total loss': 0.459567137559255} | train loss {'Reaction outcome loss': 0.3190563226091689, 'Total loss': 0.3190563226091689}
2022-12-31 15:19:11,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:11,893 INFO:     Epoch: 40
2022-12-31 15:19:13,491 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45756734212239586, 'Total loss': 0.45756734212239586} | train loss {'Reaction outcome loss': 0.3138146390328589, 'Total loss': 0.3138146390328589}
2022-12-31 15:19:13,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:13,492 INFO:     Epoch: 41
2022-12-31 15:19:15,088 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42649980783462527, 'Total loss': 0.42649980783462527} | train loss {'Reaction outcome loss': 0.30350098506997986, 'Total loss': 0.30350098506997986}
2022-12-31 15:19:15,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:15,089 INFO:     Epoch: 42
2022-12-31 15:19:16,715 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4304911951224009, 'Total loss': 0.4304911951224009} | train loss {'Reaction outcome loss': 0.30771412940668885, 'Total loss': 0.30771412940668885}
2022-12-31 15:19:16,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:16,716 INFO:     Epoch: 43
2022-12-31 15:19:18,328 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46795118153095244, 'Total loss': 0.46795118153095244} | train loss {'Reaction outcome loss': 0.3030749799155814, 'Total loss': 0.3030749799155814}
2022-12-31 15:19:18,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:18,328 INFO:     Epoch: 44
2022-12-31 15:19:19,919 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46998011072476703, 'Total loss': 0.46998011072476703} | train loss {'Reaction outcome loss': 0.29380560216858337, 'Total loss': 0.29380560216858337}
2022-12-31 15:19:19,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:19,919 INFO:     Epoch: 45
2022-12-31 15:19:21,518 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4315963049729665, 'Total loss': 0.4315963049729665} | train loss {'Reaction outcome loss': 0.28589760120456154, 'Total loss': 0.28589760120456154}
2022-12-31 15:19:21,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:21,518 INFO:     Epoch: 46
2022-12-31 15:19:23,121 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4908916175365448, 'Total loss': 0.4908916175365448} | train loss {'Reaction outcome loss': 0.2812078205237597, 'Total loss': 0.2812078205237597}
2022-12-31 15:19:23,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:23,121 INFO:     Epoch: 47
2022-12-31 15:19:24,733 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40205741822719576, 'Total loss': 0.40205741822719576} | train loss {'Reaction outcome loss': 0.28587497828655195, 'Total loss': 0.28587497828655195}
2022-12-31 15:19:24,733 INFO:     Found new best model at epoch 47
2022-12-31 15:19:24,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:24,734 INFO:     Epoch: 48
2022-12-31 15:19:26,368 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45546968777974445, 'Total loss': 0.45546968777974445} | train loss {'Reaction outcome loss': 0.2802300526612047, 'Total loss': 0.2802300526612047}
2022-12-31 15:19:26,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:26,368 INFO:     Epoch: 49
2022-12-31 15:19:27,986 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4483570377031962, 'Total loss': 0.4483570377031962} | train loss {'Reaction outcome loss': 0.29161348577210866, 'Total loss': 0.29161348577210866}
2022-12-31 15:19:27,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:27,986 INFO:     Epoch: 50
2022-12-31 15:19:29,591 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43841716398795444, 'Total loss': 0.43841716398795444} | train loss {'Reaction outcome loss': 0.3094256400684084, 'Total loss': 0.3094256400684084}
2022-12-31 15:19:29,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:29,591 INFO:     Epoch: 51
2022-12-31 15:19:31,204 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42375043630599973, 'Total loss': 0.42375043630599973} | train loss {'Reaction outcome loss': 0.2873880821292835, 'Total loss': 0.2873880821292835}
2022-12-31 15:19:31,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:31,204 INFO:     Epoch: 52
2022-12-31 15:19:32,811 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4278539687395096, 'Total loss': 0.4278539687395096} | train loss {'Reaction outcome loss': 0.27732925794586755, 'Total loss': 0.27732925794586755}
2022-12-31 15:19:32,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:32,813 INFO:     Epoch: 53
2022-12-31 15:19:34,411 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4274071176846822, 'Total loss': 0.4274071176846822} | train loss {'Reaction outcome loss': 0.27327871977931995, 'Total loss': 0.27327871977931995}
2022-12-31 15:19:34,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:34,412 INFO:     Epoch: 54
2022-12-31 15:19:36,019 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.406392373641332, 'Total loss': 0.406392373641332} | train loss {'Reaction outcome loss': 0.27141300202835567, 'Total loss': 0.27141300202835567}
2022-12-31 15:19:36,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:36,019 INFO:     Epoch: 55
2022-12-31 15:19:37,618 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3749405403931936, 'Total loss': 0.3749405403931936} | train loss {'Reaction outcome loss': 0.27119615747664205, 'Total loss': 0.27119615747664205}
2022-12-31 15:19:37,619 INFO:     Found new best model at epoch 55
2022-12-31 15:19:37,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:37,620 INFO:     Epoch: 56
2022-12-31 15:19:39,230 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4402528623739878, 'Total loss': 0.4402528623739878} | train loss {'Reaction outcome loss': 0.2638097209619709, 'Total loss': 0.2638097209619709}
2022-12-31 15:19:39,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:39,231 INFO:     Epoch: 57
2022-12-31 15:19:40,874 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5198187996943792, 'Total loss': 0.5198187996943792} | train loss {'Reaction outcome loss': 0.2581698417994973, 'Total loss': 0.2581698417994973}
2022-12-31 15:19:40,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:40,875 INFO:     Epoch: 58
2022-12-31 15:19:42,503 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4189154267311096, 'Total loss': 0.4189154267311096} | train loss {'Reaction outcome loss': 0.2659507890276618, 'Total loss': 0.2659507890276618}
2022-12-31 15:19:42,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:42,503 INFO:     Epoch: 59
2022-12-31 15:19:44,139 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4119036893049876, 'Total loss': 0.4119036893049876} | train loss {'Reaction outcome loss': 0.25592710867109103, 'Total loss': 0.25592710867109103}
2022-12-31 15:19:44,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:44,139 INFO:     Epoch: 60
2022-12-31 15:19:45,754 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42013089458147684, 'Total loss': 0.42013089458147684} | train loss {'Reaction outcome loss': 0.2542423139608165, 'Total loss': 0.2542423139608165}
2022-12-31 15:19:45,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:45,754 INFO:     Epoch: 61
2022-12-31 15:19:47,371 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4059448738892873, 'Total loss': 0.4059448738892873} | train loss {'Reaction outcome loss': 0.25660714537245466, 'Total loss': 0.25660714537245466}
2022-12-31 15:19:47,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:47,372 INFO:     Epoch: 62
2022-12-31 15:19:49,009 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4287276474138101, 'Total loss': 0.4287276474138101} | train loss {'Reaction outcome loss': 0.25767338598666684, 'Total loss': 0.25767338598666684}
2022-12-31 15:19:49,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:49,009 INFO:     Epoch: 63
2022-12-31 15:19:50,650 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4257605314254761, 'Total loss': 0.4257605314254761} | train loss {'Reaction outcome loss': 0.24720724355395668, 'Total loss': 0.24720724355395668}
2022-12-31 15:19:50,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:50,650 INFO:     Epoch: 64
2022-12-31 15:19:52,260 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41721749703089395, 'Total loss': 0.41721749703089395} | train loss {'Reaction outcome loss': 0.24855202808807456, 'Total loss': 0.24855202808807456}
2022-12-31 15:19:52,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:52,261 INFO:     Epoch: 65
2022-12-31 15:19:53,871 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4205756425857544, 'Total loss': 0.4205756425857544} | train loss {'Reaction outcome loss': 0.24708348650323309, 'Total loss': 0.24708348650323309}
2022-12-31 15:19:53,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:53,871 INFO:     Epoch: 66
2022-12-31 15:19:55,468 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41432488212982815, 'Total loss': 0.41432488212982815} | train loss {'Reaction outcome loss': 0.2451851811071021, 'Total loss': 0.2451851811071021}
2022-12-31 15:19:55,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:55,468 INFO:     Epoch: 67
2022-12-31 15:19:57,094 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39060168464978534, 'Total loss': 0.39060168464978534} | train loss {'Reaction outcome loss': 0.24853664079294674, 'Total loss': 0.24853664079294674}
2022-12-31 15:19:57,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:57,094 INFO:     Epoch: 68
2022-12-31 15:19:58,705 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5003470838069916, 'Total loss': 0.5003470838069916} | train loss {'Reaction outcome loss': 0.24551201918148907, 'Total loss': 0.24551201918148907}
2022-12-31 15:19:58,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:19:58,705 INFO:     Epoch: 69
2022-12-31 15:20:00,319 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41616495748360954, 'Total loss': 0.41616495748360954} | train loss {'Reaction outcome loss': 0.28326596773357765, 'Total loss': 0.28326596773357765}
2022-12-31 15:20:00,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:00,320 INFO:     Epoch: 70
2022-12-31 15:20:01,924 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4279447913169861, 'Total loss': 0.4279447913169861} | train loss {'Reaction outcome loss': 0.24458525400135334, 'Total loss': 0.24458525400135334}
2022-12-31 15:20:01,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:01,925 INFO:     Epoch: 71
2022-12-31 15:20:03,535 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4322415898243586, 'Total loss': 0.4322415898243586} | train loss {'Reaction outcome loss': 0.2509969448184837, 'Total loss': 0.2509969448184837}
2022-12-31 15:20:03,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:03,536 INFO:     Epoch: 72
2022-12-31 15:20:05,132 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46776451766490934, 'Total loss': 0.46776451766490934} | train loss {'Reaction outcome loss': 0.3503160818304489, 'Total loss': 0.3503160818304489}
2022-12-31 15:20:05,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:05,132 INFO:     Epoch: 73
2022-12-31 15:20:06,739 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4575260023276011, 'Total loss': 0.4575260023276011} | train loss {'Reaction outcome loss': 0.2711349371893448, 'Total loss': 0.2711349371893448}
2022-12-31 15:20:06,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:06,740 INFO:     Epoch: 74
2022-12-31 15:20:08,347 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4336665610472361, 'Total loss': 0.4336665610472361} | train loss {'Reaction outcome loss': 0.25869406399041234, 'Total loss': 0.25869406399041234}
2022-12-31 15:20:08,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:08,348 INFO:     Epoch: 75
2022-12-31 15:20:09,954 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41534131169319155, 'Total loss': 0.41534131169319155} | train loss {'Reaction outcome loss': 0.25217425857461395, 'Total loss': 0.25217425857461395}
2022-12-31 15:20:09,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:09,955 INFO:     Epoch: 76
2022-12-31 15:20:11,593 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4370342579980691, 'Total loss': 0.4370342579980691} | train loss {'Reaction outcome loss': 0.24973423382861243, 'Total loss': 0.24973423382861243}
2022-12-31 15:20:11,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:11,593 INFO:     Epoch: 77
2022-12-31 15:20:13,197 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4195387045542399, 'Total loss': 0.4195387045542399} | train loss {'Reaction outcome loss': 0.23814089812156558, 'Total loss': 0.23814089812156558}
2022-12-31 15:20:13,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:13,197 INFO:     Epoch: 78
2022-12-31 15:20:14,802 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44122079710165657, 'Total loss': 0.44122079710165657} | train loss {'Reaction outcome loss': 0.23563775444252288, 'Total loss': 0.23563775444252288}
2022-12-31 15:20:14,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:14,803 INFO:     Epoch: 79
2022-12-31 15:20:16,412 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39433141152064005, 'Total loss': 0.39433141152064005} | train loss {'Reaction outcome loss': 0.2274416518613588, 'Total loss': 0.2274416518613588}
2022-12-31 15:20:16,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:16,412 INFO:     Epoch: 80
2022-12-31 15:20:18,011 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3977853715419769, 'Total loss': 0.3977853715419769} | train loss {'Reaction outcome loss': 0.2254319043118364, 'Total loss': 0.2254319043118364}
2022-12-31 15:20:18,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:18,011 INFO:     Epoch: 81
2022-12-31 15:20:19,634 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4433525780836741, 'Total loss': 0.4433525780836741} | train loss {'Reaction outcome loss': 0.2275609445852646, 'Total loss': 0.2275609445852646}
2022-12-31 15:20:19,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:19,634 INFO:     Epoch: 82
2022-12-31 15:20:21,240 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43615692257881167, 'Total loss': 0.43615692257881167} | train loss {'Reaction outcome loss': 0.23256017219450703, 'Total loss': 0.23256017219450703}
2022-12-31 15:20:21,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:21,241 INFO:     Epoch: 83
2022-12-31 15:20:22,840 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47086519400278726, 'Total loss': 0.47086519400278726} | train loss {'Reaction outcome loss': 0.2246110429379927, 'Total loss': 0.2246110429379927}
2022-12-31 15:20:22,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:22,841 INFO:     Epoch: 84
2022-12-31 15:20:24,449 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38473564585049946, 'Total loss': 0.38473564585049946} | train loss {'Reaction outcome loss': 0.23316364727646072, 'Total loss': 0.23316364727646072}
2022-12-31 15:20:24,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:24,449 INFO:     Epoch: 85
2022-12-31 15:20:26,059 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4216350426276525, 'Total loss': 0.4216350426276525} | train loss {'Reaction outcome loss': 0.21807567456710167, 'Total loss': 0.21807567456710167}
2022-12-31 15:20:26,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:26,060 INFO:     Epoch: 86
2022-12-31 15:20:27,667 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4320430397987366, 'Total loss': 0.4320430397987366} | train loss {'Reaction outcome loss': 0.22785075964872004, 'Total loss': 0.22785075964872004}
2022-12-31 15:20:27,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:27,668 INFO:     Epoch: 87
2022-12-31 15:20:29,337 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4335344215234121, 'Total loss': 0.4335344215234121} | train loss {'Reaction outcome loss': 0.2232318093487318, 'Total loss': 0.2232318093487318}
2022-12-31 15:20:29,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:29,337 INFO:     Epoch: 88
2022-12-31 15:20:31,013 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4148670554161072, 'Total loss': 0.4148670554161072} | train loss {'Reaction outcome loss': 0.22320183004806007, 'Total loss': 0.22320183004806007}
2022-12-31 15:20:31,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:31,014 INFO:     Epoch: 89
2022-12-31 15:20:32,680 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4230295737584432, 'Total loss': 0.4230295737584432} | train loss {'Reaction outcome loss': 0.22091798875139237, 'Total loss': 0.22091798875139237}
2022-12-31 15:20:32,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:32,680 INFO:     Epoch: 90
2022-12-31 15:20:34,350 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4671163663268089, 'Total loss': 0.4671163663268089} | train loss {'Reaction outcome loss': 0.21916889388534322, 'Total loss': 0.21916889388534322}
2022-12-31 15:20:34,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:34,351 INFO:     Epoch: 91
2022-12-31 15:20:36,020 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4124426563580831, 'Total loss': 0.4124426563580831} | train loss {'Reaction outcome loss': 0.22325829601618022, 'Total loss': 0.22325829601618022}
2022-12-31 15:20:36,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:36,020 INFO:     Epoch: 92
2022-12-31 15:20:37,666 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44014661212762196, 'Total loss': 0.44014661212762196} | train loss {'Reaction outcome loss': 0.22564942557727447, 'Total loss': 0.22564942557727447}
2022-12-31 15:20:37,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:37,666 INFO:     Epoch: 93
2022-12-31 15:20:39,358 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4204008013010025, 'Total loss': 0.4204008013010025} | train loss {'Reaction outcome loss': 0.2223804488784863, 'Total loss': 0.2223804488784863}
2022-12-31 15:20:39,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:39,359 INFO:     Epoch: 94
2022-12-31 15:20:41,020 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4373406668504079, 'Total loss': 0.4373406668504079} | train loss {'Reaction outcome loss': 0.21351770154744398, 'Total loss': 0.21351770154744398}
2022-12-31 15:20:41,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:41,021 INFO:     Epoch: 95
2022-12-31 15:20:42,698 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40581181148688, 'Total loss': 0.40581181148688} | train loss {'Reaction outcome loss': 0.2135088069236203, 'Total loss': 0.2135088069236203}
2022-12-31 15:20:42,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:42,698 INFO:     Epoch: 96
2022-12-31 15:20:44,382 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4641683379809062, 'Total loss': 0.4641683379809062} | train loss {'Reaction outcome loss': 0.24859294875784763, 'Total loss': 0.24859294875784763}
2022-12-31 15:20:44,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:44,382 INFO:     Epoch: 97
2022-12-31 15:20:46,029 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4121586869160334, 'Total loss': 0.4121586869160334} | train loss {'Reaction outcome loss': 0.21565668073932445, 'Total loss': 0.21565668073932445}
2022-12-31 15:20:46,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:46,029 INFO:     Epoch: 98
2022-12-31 15:20:47,644 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4214580963055293, 'Total loss': 0.4214580963055293} | train loss {'Reaction outcome loss': 0.21575424374432128, 'Total loss': 0.21575424374432128}
2022-12-31 15:20:47,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:47,644 INFO:     Epoch: 99
2022-12-31 15:20:49,253 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4296175539493561, 'Total loss': 0.4296175539493561} | train loss {'Reaction outcome loss': 0.20926247436748951, 'Total loss': 0.20926247436748951}
2022-12-31 15:20:49,253 INFO:     Best model found after epoch 56 of 100.
2022-12-31 15:20:49,253 INFO:   Done with stage: TRAINING
2022-12-31 15:20:49,253 INFO:   Starting stage: EVALUATION
2022-12-31 15:20:49,382 INFO:   Done with stage: EVALUATION
2022-12-31 15:20:49,391 INFO:   Leaving out SEQ value Fold_0
2022-12-31 15:20:49,403 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2022-12-31 15:20:49,404 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:20:50,043 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:20:50,043 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:20:50,111 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:20:50,111 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:20:50,111 INFO:     No hyperparam tuning for this model
2022-12-31 15:20:50,111 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:20:50,111 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:20:50,112 INFO:     None feature selector for col prot
2022-12-31 15:20:50,112 INFO:     None feature selector for col prot
2022-12-31 15:20:50,112 INFO:     None feature selector for col prot
2022-12-31 15:20:50,112 INFO:     None feature selector for col chem
2022-12-31 15:20:50,113 INFO:     None feature selector for col chem
2022-12-31 15:20:50,113 INFO:     None feature selector for col chem
2022-12-31 15:20:50,113 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:20:50,113 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:20:50,114 INFO:     Number of params in model 223921
2022-12-31 15:20:50,118 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:20:50,118 INFO:   Starting stage: TRAINING
2022-12-31 15:20:50,163 INFO:     Val loss before train {'Reaction outcome loss': 0.912169082959493, 'Total loss': 0.912169082959493}
2022-12-31 15:20:50,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:50,163 INFO:     Epoch: 0
2022-12-31 15:20:51,776 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6704590717951456, 'Total loss': 0.6704590717951456} | train loss {'Reaction outcome loss': 0.8262837165176209, 'Total loss': 0.8262837165176209}
2022-12-31 15:20:51,776 INFO:     Found new best model at epoch 0
2022-12-31 15:20:51,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:51,777 INFO:     Epoch: 1
2022-12-31 15:20:53,362 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5129105071226756, 'Total loss': 0.5129105071226756} | train loss {'Reaction outcome loss': 0.5959890991779271, 'Total loss': 0.5959890991779271}
2022-12-31 15:20:53,363 INFO:     Found new best model at epoch 1
2022-12-31 15:20:53,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:53,364 INFO:     Epoch: 2
2022-12-31 15:20:54,940 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4916083465019862, 'Total loss': 0.4916083465019862} | train loss {'Reaction outcome loss': 0.5270238155258538, 'Total loss': 0.5270238155258538}
2022-12-31 15:20:54,940 INFO:     Found new best model at epoch 2
2022-12-31 15:20:54,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:54,941 INFO:     Epoch: 3
2022-12-31 15:20:56,528 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49777720173199974, 'Total loss': 0.49777720173199974} | train loss {'Reaction outcome loss': 0.4955727432706699, 'Total loss': 0.4955727432706699}
2022-12-31 15:20:56,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:56,528 INFO:     Epoch: 4
2022-12-31 15:20:58,134 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5001012861728669, 'Total loss': 0.5001012861728669} | train loss {'Reaction outcome loss': 0.48336949367144894, 'Total loss': 0.48336949367144894}
2022-12-31 15:20:58,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:58,135 INFO:     Epoch: 5
2022-12-31 15:20:59,720 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45667715469996134, 'Total loss': 0.45667715469996134} | train loss {'Reaction outcome loss': 0.46645464376989765, 'Total loss': 0.46645464376989765}
2022-12-31 15:20:59,720 INFO:     Found new best model at epoch 5
2022-12-31 15:20:59,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:20:59,721 INFO:     Epoch: 6
2022-12-31 15:21:01,337 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4449419677257538, 'Total loss': 0.4449419677257538} | train loss {'Reaction outcome loss': 0.4588162105021881, 'Total loss': 0.4588162105021881}
2022-12-31 15:21:01,337 INFO:     Found new best model at epoch 6
2022-12-31 15:21:01,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:01,338 INFO:     Epoch: 7
2022-12-31 15:21:02,939 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47329556544621787, 'Total loss': 0.47329556544621787} | train loss {'Reaction outcome loss': 0.45089416376339114, 'Total loss': 0.45089416376339114}
2022-12-31 15:21:02,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:02,939 INFO:     Epoch: 8
2022-12-31 15:21:04,519 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47988541225592296, 'Total loss': 0.47988541225592296} | train loss {'Reaction outcome loss': 0.4500177300834128, 'Total loss': 0.4500177300834128}
2022-12-31 15:21:04,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:04,520 INFO:     Epoch: 9
2022-12-31 15:21:06,130 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44776233832041423, 'Total loss': 0.44776233832041423} | train loss {'Reaction outcome loss': 0.4405891673701276, 'Total loss': 0.4405891673701276}
2022-12-31 15:21:06,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:06,131 INFO:     Epoch: 10
2022-12-31 15:21:07,713 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4910853743553162, 'Total loss': 0.4910853743553162} | train loss {'Reaction outcome loss': 0.4296194622327481, 'Total loss': 0.4296194622327481}
2022-12-31 15:21:07,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:07,713 INFO:     Epoch: 11
2022-12-31 15:21:09,301 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4308566405127446, 'Total loss': 0.4308566405127446} | train loss {'Reaction outcome loss': 0.4265525028714395, 'Total loss': 0.4265525028714395}
2022-12-31 15:21:09,301 INFO:     Found new best model at epoch 11
2022-12-31 15:21:09,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:09,302 INFO:     Epoch: 12
2022-12-31 15:21:10,900 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44623967905839285, 'Total loss': 0.44623967905839285} | train loss {'Reaction outcome loss': 0.4209634518161471, 'Total loss': 0.4209634518161471}
2022-12-31 15:21:10,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:10,901 INFO:     Epoch: 13
2022-12-31 15:21:12,514 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42750431696573893, 'Total loss': 0.42750431696573893} | train loss {'Reaction outcome loss': 0.4131805822803086, 'Total loss': 0.4131805822803086}
2022-12-31 15:21:12,514 INFO:     Found new best model at epoch 13
2022-12-31 15:21:12,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:12,515 INFO:     Epoch: 14
2022-12-31 15:21:14,108 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49994356532891593, 'Total loss': 0.49994356532891593} | train loss {'Reaction outcome loss': 0.40706907803831943, 'Total loss': 0.40706907803831943}
2022-12-31 15:21:14,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:14,108 INFO:     Epoch: 15
2022-12-31 15:21:15,732 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5100231011708577, 'Total loss': 0.5100231011708577} | train loss {'Reaction outcome loss': 0.4016668094645127, 'Total loss': 0.4016668094645127}
2022-12-31 15:21:15,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:15,732 INFO:     Epoch: 16
2022-12-31 15:21:17,321 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42295256157716116, 'Total loss': 0.42295256157716116} | train loss {'Reaction outcome loss': 0.3991617176585532, 'Total loss': 0.3991617176585532}
2022-12-31 15:21:17,321 INFO:     Found new best model at epoch 16
2022-12-31 15:21:17,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:17,322 INFO:     Epoch: 17
2022-12-31 15:21:18,906 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4425816516081492, 'Total loss': 0.4425816516081492} | train loss {'Reaction outcome loss': 0.39052007809226363, 'Total loss': 0.39052007809226363}
2022-12-31 15:21:18,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:18,906 INFO:     Epoch: 18
2022-12-31 15:21:20,516 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4405597979823748, 'Total loss': 0.4405597979823748} | train loss {'Reaction outcome loss': 0.3871469148795543, 'Total loss': 0.3871469148795543}
2022-12-31 15:21:20,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:20,516 INFO:     Epoch: 19
2022-12-31 15:21:22,088 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4091470678647359, 'Total loss': 0.4091470678647359} | train loss {'Reaction outcome loss': 0.383731406580698, 'Total loss': 0.383731406580698}
2022-12-31 15:21:22,088 INFO:     Found new best model at epoch 19
2022-12-31 15:21:22,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:22,089 INFO:     Epoch: 20
2022-12-31 15:21:23,708 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4308075894912084, 'Total loss': 0.4308075894912084} | train loss {'Reaction outcome loss': 0.37725577855352105, 'Total loss': 0.37725577855352105}
2022-12-31 15:21:23,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:23,709 INFO:     Epoch: 21
2022-12-31 15:21:25,302 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40062044163544974, 'Total loss': 0.40062044163544974} | train loss {'Reaction outcome loss': 0.37050711217841537, 'Total loss': 0.37050711217841537}
2022-12-31 15:21:25,303 INFO:     Found new best model at epoch 21
2022-12-31 15:21:25,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:25,304 INFO:     Epoch: 22
2022-12-31 15:21:26,876 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.408088481426239, 'Total loss': 0.408088481426239} | train loss {'Reaction outcome loss': 0.37089141906407486, 'Total loss': 0.37089141906407486}
2022-12-31 15:21:26,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:26,876 INFO:     Epoch: 23
2022-12-31 15:21:28,462 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4181374500195185, 'Total loss': 0.4181374500195185} | train loss {'Reaction outcome loss': 0.35655263871834286, 'Total loss': 0.35655263871834286}
2022-12-31 15:21:28,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:28,463 INFO:     Epoch: 24
2022-12-31 15:21:30,050 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38951470305522284, 'Total loss': 0.38951470305522284} | train loss {'Reaction outcome loss': 0.3591163254916888, 'Total loss': 0.3591163254916888}
2022-12-31 15:21:30,050 INFO:     Found new best model at epoch 24
2022-12-31 15:21:30,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:30,051 INFO:     Epoch: 25
2022-12-31 15:21:31,623 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41671800216039023, 'Total loss': 0.41671800216039023} | train loss {'Reaction outcome loss': 0.35030859531456693, 'Total loss': 0.35030859531456693}
2022-12-31 15:21:31,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:31,623 INFO:     Epoch: 26
2022-12-31 15:21:33,253 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.37852427462736765, 'Total loss': 0.37852427462736765} | train loss {'Reaction outcome loss': 0.34982370733664925, 'Total loss': 0.34982370733664925}
2022-12-31 15:21:33,253 INFO:     Found new best model at epoch 26
2022-12-31 15:21:33,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:33,255 INFO:     Epoch: 27
2022-12-31 15:21:34,876 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40673580517371494, 'Total loss': 0.40673580517371494} | train loss {'Reaction outcome loss': 0.3440291304759874, 'Total loss': 0.3440291304759874}
2022-12-31 15:21:34,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:34,877 INFO:     Epoch: 28
2022-12-31 15:21:36,481 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4181426634391149, 'Total loss': 0.4181426634391149} | train loss {'Reaction outcome loss': 0.3360345710302631, 'Total loss': 0.3360345710302631}
2022-12-31 15:21:36,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:36,481 INFO:     Epoch: 29
2022-12-31 15:21:38,106 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4168953597545624, 'Total loss': 0.4168953597545624} | train loss {'Reaction outcome loss': 0.33135680013037255, 'Total loss': 0.33135680013037255}
2022-12-31 15:21:38,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:38,106 INFO:     Epoch: 30
2022-12-31 15:21:39,729 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4132714917262395, 'Total loss': 0.4132714917262395} | train loss {'Reaction outcome loss': 0.3314369215296643, 'Total loss': 0.3314369215296643}
2022-12-31 15:21:39,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:39,729 INFO:     Epoch: 31
2022-12-31 15:21:41,344 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4008542043467363, 'Total loss': 0.4008542043467363} | train loss {'Reaction outcome loss': 0.3271847409900704, 'Total loss': 0.3271847409900704}
2022-12-31 15:21:41,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:41,345 INFO:     Epoch: 32
2022-12-31 15:21:42,965 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40815810561180116, 'Total loss': 0.40815810561180116} | train loss {'Reaction outcome loss': 0.3257690380530164, 'Total loss': 0.3257690380530164}
2022-12-31 15:21:42,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:42,966 INFO:     Epoch: 33
2022-12-31 15:21:44,569 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.37731590469678244, 'Total loss': 0.37731590469678244} | train loss {'Reaction outcome loss': 0.3105183193576952, 'Total loss': 0.3105183193576952}
2022-12-31 15:21:44,569 INFO:     Found new best model at epoch 33
2022-12-31 15:21:44,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:44,570 INFO:     Epoch: 34
2022-12-31 15:21:46,191 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4496205429236094, 'Total loss': 0.4496205429236094} | train loss {'Reaction outcome loss': 0.31214600576025975, 'Total loss': 0.31214600576025975}
2022-12-31 15:21:46,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:46,192 INFO:     Epoch: 35
2022-12-31 15:21:47,812 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4573267380396525, 'Total loss': 0.4573267380396525} | train loss {'Reaction outcome loss': 0.3038102139296127, 'Total loss': 0.3038102139296127}
2022-12-31 15:21:47,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:47,813 INFO:     Epoch: 36
2022-12-31 15:21:49,416 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40680043200651805, 'Total loss': 0.40680043200651805} | train loss {'Reaction outcome loss': 0.30466989232605235, 'Total loss': 0.30466989232605235}
2022-12-31 15:21:49,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:49,416 INFO:     Epoch: 37
2022-12-31 15:21:51,024 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42349869608879087, 'Total loss': 0.42349869608879087} | train loss {'Reaction outcome loss': 0.29792554672408805, 'Total loss': 0.29792554672408805}
2022-12-31 15:21:51,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:51,025 INFO:     Epoch: 38
2022-12-31 15:21:52,626 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.37514143784840903, 'Total loss': 0.37514143784840903} | train loss {'Reaction outcome loss': 0.295574890745192, 'Total loss': 0.295574890745192}
2022-12-31 15:21:52,626 INFO:     Found new best model at epoch 38
2022-12-31 15:21:52,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:52,627 INFO:     Epoch: 39
2022-12-31 15:21:54,200 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4117265005906423, 'Total loss': 0.4117265005906423} | train loss {'Reaction outcome loss': 0.3036757641887753, 'Total loss': 0.3036757641887753}
2022-12-31 15:21:54,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:54,200 INFO:     Epoch: 40
2022-12-31 15:21:55,797 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38987892071406044, 'Total loss': 0.38987892071406044} | train loss {'Reaction outcome loss': 0.29141019140387375, 'Total loss': 0.29141019140387375}
2022-12-31 15:21:55,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:55,797 INFO:     Epoch: 41
2022-12-31 15:21:57,396 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45173630118370056, 'Total loss': 0.45173630118370056} | train loss {'Reaction outcome loss': 0.2917540278629403, 'Total loss': 0.2917540278629403}
2022-12-31 15:21:57,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:57,396 INFO:     Epoch: 42
2022-12-31 15:21:58,989 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42868677377700803, 'Total loss': 0.42868677377700803} | train loss {'Reaction outcome loss': 0.282051286381769, 'Total loss': 0.282051286381769}
2022-12-31 15:21:58,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:21:58,989 INFO:     Epoch: 43
2022-12-31 15:22:00,591 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4206856926282247, 'Total loss': 0.4206856926282247} | train loss {'Reaction outcome loss': 0.2807495439858124, 'Total loss': 0.2807495439858124}
2022-12-31 15:22:00,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:00,592 INFO:     Epoch: 44
2022-12-31 15:22:02,176 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41994723975658416, 'Total loss': 0.41994723975658416} | train loss {'Reaction outcome loss': 0.27958559544543937, 'Total loss': 0.27958559544543937}
2022-12-31 15:22:02,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:02,176 INFO:     Epoch: 45
2022-12-31 15:22:03,748 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41289989749590555, 'Total loss': 0.41289989749590555} | train loss {'Reaction outcome loss': 0.27781091891641546, 'Total loss': 0.27781091891641546}
2022-12-31 15:22:03,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:03,749 INFO:     Epoch: 46
2022-12-31 15:22:05,345 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41716661552588147, 'Total loss': 0.41716661552588147} | train loss {'Reaction outcome loss': 0.27045740192666706, 'Total loss': 0.27045740192666706}
2022-12-31 15:22:05,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:05,345 INFO:     Epoch: 47
2022-12-31 15:22:06,927 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39339963893095653, 'Total loss': 0.39339963893095653} | train loss {'Reaction outcome loss': 0.26635203452787715, 'Total loss': 0.26635203452787715}
2022-12-31 15:22:06,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:06,927 INFO:     Epoch: 48
2022-12-31 15:22:08,494 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4141186118125916, 'Total loss': 0.4141186118125916} | train loss {'Reaction outcome loss': 0.2705739908800134, 'Total loss': 0.2705739908800134}
2022-12-31 15:22:08,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:08,494 INFO:     Epoch: 49
2022-12-31 15:22:10,077 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3921236957112948, 'Total loss': 0.3921236957112948} | train loss {'Reaction outcome loss': 0.262231996578484, 'Total loss': 0.262231996578484}
2022-12-31 15:22:10,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:10,077 INFO:     Epoch: 50
2022-12-31 15:22:11,652 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38002409438292184, 'Total loss': 0.38002409438292184} | train loss {'Reaction outcome loss': 0.2673254207642646, 'Total loss': 0.2673254207642646}
2022-12-31 15:22:11,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:11,653 INFO:     Epoch: 51
2022-12-31 15:22:13,249 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4263405382633209, 'Total loss': 0.4263405382633209} | train loss {'Reaction outcome loss': 0.2624652072704806, 'Total loss': 0.2624652072704806}
2022-12-31 15:22:13,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:13,249 INFO:     Epoch: 52
2022-12-31 15:22:14,867 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4236154854297638, 'Total loss': 0.4236154854297638} | train loss {'Reaction outcome loss': 0.2554896010079067, 'Total loss': 0.2554896010079067}
2022-12-31 15:22:14,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:14,867 INFO:     Epoch: 53
2022-12-31 15:22:16,460 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4076210250457128, 'Total loss': 0.4076210250457128} | train loss {'Reaction outcome loss': 0.25817637236245883, 'Total loss': 0.25817637236245883}
2022-12-31 15:22:16,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:16,462 INFO:     Epoch: 54
2022-12-31 15:22:18,031 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44227759142716727, 'Total loss': 0.44227759142716727} | train loss {'Reaction outcome loss': 0.25320202866878455, 'Total loss': 0.25320202866878455}
2022-12-31 15:22:18,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:18,031 INFO:     Epoch: 55
2022-12-31 15:22:19,612 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3736497700214386, 'Total loss': 0.3736497700214386} | train loss {'Reaction outcome loss': 0.25042716625431805, 'Total loss': 0.25042716625431805}
2022-12-31 15:22:19,612 INFO:     Found new best model at epoch 55
2022-12-31 15:22:19,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:19,613 INFO:     Epoch: 56
2022-12-31 15:22:21,176 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38792406022548676, 'Total loss': 0.38792406022548676} | train loss {'Reaction outcome loss': 0.2544173251809999, 'Total loss': 0.2544173251809999}
2022-12-31 15:22:21,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:21,176 INFO:     Epoch: 57
2022-12-31 15:22:22,770 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4152472635110219, 'Total loss': 0.4152472635110219} | train loss {'Reaction outcome loss': 0.24340581756456312, 'Total loss': 0.24340581756456312}
2022-12-31 15:22:22,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:22,771 INFO:     Epoch: 58
2022-12-31 15:22:24,367 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38986299724783746, 'Total loss': 0.38986299724783746} | train loss {'Reaction outcome loss': 0.24508636007669668, 'Total loss': 0.24508636007669668}
2022-12-31 15:22:24,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:24,367 INFO:     Epoch: 59
2022-12-31 15:22:25,934 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4231052130460739, 'Total loss': 0.4231052130460739} | train loss {'Reaction outcome loss': 0.24224560348337648, 'Total loss': 0.24224560348337648}
2022-12-31 15:22:25,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:25,935 INFO:     Epoch: 60
2022-12-31 15:22:27,520 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40578493277231853, 'Total loss': 0.40578493277231853} | train loss {'Reaction outcome loss': 0.252302169868537, 'Total loss': 0.252302169868537}
2022-12-31 15:22:27,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:27,520 INFO:     Epoch: 61
2022-12-31 15:22:29,101 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40756374100844067, 'Total loss': 0.40756374100844067} | train loss {'Reaction outcome loss': 0.2401088253969526, 'Total loss': 0.2401088253969526}
2022-12-31 15:22:29,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:29,102 INFO:     Epoch: 62
2022-12-31 15:22:30,683 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37501205106576285, 'Total loss': 0.37501205106576285} | train loss {'Reaction outcome loss': 0.2368327506793821, 'Total loss': 0.2368327506793821}
2022-12-31 15:22:30,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:30,684 INFO:     Epoch: 63
2022-12-31 15:22:32,299 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38455766687790555, 'Total loss': 0.38455766687790555} | train loss {'Reaction outcome loss': 0.23933375767703646, 'Total loss': 0.23933375767703646}
2022-12-31 15:22:32,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:32,299 INFO:     Epoch: 64
2022-12-31 15:22:33,913 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3825166632731756, 'Total loss': 0.3825166632731756} | train loss {'Reaction outcome loss': 0.23912788480795177, 'Total loss': 0.23912788480795177}
2022-12-31 15:22:33,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:33,913 INFO:     Epoch: 65
2022-12-31 15:22:35,500 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.36859180927276614, 'Total loss': 0.36859180927276614} | train loss {'Reaction outcome loss': 0.2305861723186565, 'Total loss': 0.2305861723186565}
2022-12-31 15:22:35,501 INFO:     Found new best model at epoch 65
2022-12-31 15:22:35,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:35,502 INFO:     Epoch: 66
2022-12-31 15:22:37,080 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3997720787922541, 'Total loss': 0.3997720787922541} | train loss {'Reaction outcome loss': 0.23729905517723726, 'Total loss': 0.23729905517723726}
2022-12-31 15:22:37,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:37,080 INFO:     Epoch: 67
2022-12-31 15:22:38,659 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42452812095483144, 'Total loss': 0.42452812095483144} | train loss {'Reaction outcome loss': 0.2264159983024001, 'Total loss': 0.2264159983024001}
2022-12-31 15:22:38,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:38,659 INFO:     Epoch: 68
2022-12-31 15:22:40,225 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3571368147308628, 'Total loss': 0.3571368147308628} | train loss {'Reaction outcome loss': 0.22607284125861646, 'Total loss': 0.22607284125861646}
2022-12-31 15:22:40,225 INFO:     Found new best model at epoch 68
2022-12-31 15:22:40,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:40,226 INFO:     Epoch: 69
2022-12-31 15:22:41,805 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4143674592177073, 'Total loss': 0.4143674592177073} | train loss {'Reaction outcome loss': 0.2199414592524956, 'Total loss': 0.2199414592524956}
2022-12-31 15:22:41,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:41,805 INFO:     Epoch: 70
2022-12-31 15:22:43,385 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39140649636586505, 'Total loss': 0.39140649636586505} | train loss {'Reaction outcome loss': 0.23029817756938978, 'Total loss': 0.23029817756938978}
2022-12-31 15:22:43,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:43,385 INFO:     Epoch: 71
2022-12-31 15:22:44,976 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3630639558037122, 'Total loss': 0.3630639558037122} | train loss {'Reaction outcome loss': 0.2250482234691452, 'Total loss': 0.2250482234691452}
2022-12-31 15:22:44,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:44,976 INFO:     Epoch: 72
2022-12-31 15:22:46,584 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4006603002548218, 'Total loss': 0.4006603002548218} | train loss {'Reaction outcome loss': 0.22360162650032236, 'Total loss': 0.22360162650032236}
2022-12-31 15:22:46,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:46,584 INFO:     Epoch: 73
2022-12-31 15:22:48,151 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.36688646965970595, 'Total loss': 0.36688646965970595} | train loss {'Reaction outcome loss': 0.2184175772736763, 'Total loss': 0.2184175772736763}
2022-12-31 15:22:48,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:48,152 INFO:     Epoch: 74
2022-12-31 15:22:49,756 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3583676948522528, 'Total loss': 0.3583676948522528} | train loss {'Reaction outcome loss': 0.21785817232766494, 'Total loss': 0.21785817232766494}
2022-12-31 15:22:49,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:49,756 INFO:     Epoch: 75
2022-12-31 15:22:51,372 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4421192198991776, 'Total loss': 0.4421192198991776} | train loss {'Reaction outcome loss': 0.21748995207717498, 'Total loss': 0.21748995207717498}
2022-12-31 15:22:51,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:51,372 INFO:     Epoch: 76
2022-12-31 15:22:52,928 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37708003784840305, 'Total loss': 0.37708003784840305} | train loss {'Reaction outcome loss': 0.21996535231596429, 'Total loss': 0.21996535231596429}
2022-12-31 15:22:52,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:52,928 INFO:     Epoch: 77
2022-12-31 15:22:54,504 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3886998767654101, 'Total loss': 0.3886998767654101} | train loss {'Reaction outcome loss': 0.20666106113291094, 'Total loss': 0.20666106113291094}
2022-12-31 15:22:54,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:54,504 INFO:     Epoch: 78
2022-12-31 15:22:56,079 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3818712408343951, 'Total loss': 0.3818712408343951} | train loss {'Reaction outcome loss': 0.2147569371133053, 'Total loss': 0.2147569371133053}
2022-12-31 15:22:56,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:56,079 INFO:     Epoch: 79
2022-12-31 15:22:57,642 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41943110326925914, 'Total loss': 0.41943110326925914} | train loss {'Reaction outcome loss': 0.21161532743638073, 'Total loss': 0.21161532743638073}
2022-12-31 15:22:57,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:57,642 INFO:     Epoch: 80
2022-12-31 15:22:59,217 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3715830884873867, 'Total loss': 0.3715830884873867} | train loss {'Reaction outcome loss': 0.2163925347265502, 'Total loss': 0.2163925347265502}
2022-12-31 15:22:59,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:22:59,218 INFO:     Epoch: 81
2022-12-31 15:23:00,794 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38111051817735037, 'Total loss': 0.38111051817735037} | train loss {'Reaction outcome loss': 0.2148467758361154, 'Total loss': 0.2148467758361154}
2022-12-31 15:23:00,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:00,794 INFO:     Epoch: 82
2022-12-31 15:23:02,155 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4065352390209834, 'Total loss': 0.4065352390209834} | train loss {'Reaction outcome loss': 0.215572422322202, 'Total loss': 0.215572422322202}
2022-12-31 15:23:02,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:02,155 INFO:     Epoch: 83
2022-12-31 15:23:03,211 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3677061285202702, 'Total loss': 0.3677061285202702} | train loss {'Reaction outcome loss': 0.2073851499115409, 'Total loss': 0.2073851499115409}
2022-12-31 15:23:03,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:03,211 INFO:     Epoch: 84
2022-12-31 15:23:04,261 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37609903464714683, 'Total loss': 0.37609903464714683} | train loss {'Reaction outcome loss': 0.20775607024144202, 'Total loss': 0.20775607024144202}
2022-12-31 15:23:04,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:04,261 INFO:     Epoch: 85
2022-12-31 15:23:05,324 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38562567830085753, 'Total loss': 0.38562567830085753} | train loss {'Reaction outcome loss': 0.20626369826633112, 'Total loss': 0.20626369826633112}
2022-12-31 15:23:05,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:05,324 INFO:     Epoch: 86
2022-12-31 15:23:06,457 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3690849294265111, 'Total loss': 0.3690849294265111} | train loss {'Reaction outcome loss': 0.20279608548333614, 'Total loss': 0.20279608548333614}
2022-12-31 15:23:06,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:06,457 INFO:     Epoch: 87
2022-12-31 15:23:08,107 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3357294673720996, 'Total loss': 0.3357294673720996} | train loss {'Reaction outcome loss': 0.20795517913461062, 'Total loss': 0.20795517913461062}
2022-12-31 15:23:08,108 INFO:     Found new best model at epoch 87
2022-12-31 15:23:08,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:08,109 INFO:     Epoch: 88
2022-12-31 15:23:09,746 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3782636026541392, 'Total loss': 0.3782636026541392} | train loss {'Reaction outcome loss': 0.20176980953759813, 'Total loss': 0.20176980953759813}
2022-12-31 15:23:09,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:09,746 INFO:     Epoch: 89
2022-12-31 15:23:11,379 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3810968965291977, 'Total loss': 0.3810968965291977} | train loss {'Reaction outcome loss': 0.2073964913997703, 'Total loss': 0.2073964913997703}
2022-12-31 15:23:11,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:11,379 INFO:     Epoch: 90
2022-12-31 15:23:12,999 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.37196540584166843, 'Total loss': 0.37196540584166843} | train loss {'Reaction outcome loss': 0.19479623486415046, 'Total loss': 0.19479623486415046}
2022-12-31 15:23:12,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:12,999 INFO:     Epoch: 91
2022-12-31 15:23:14,604 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43906382843852043, 'Total loss': 0.43906382843852043} | train loss {'Reaction outcome loss': 0.19496549272779168, 'Total loss': 0.19496549272779168}
2022-12-31 15:23:14,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:14,604 INFO:     Epoch: 92
2022-12-31 15:23:16,196 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3681619133800268, 'Total loss': 0.3681619133800268} | train loss {'Reaction outcome loss': 0.19978841295898842, 'Total loss': 0.19978841295898842}
2022-12-31 15:23:16,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:16,196 INFO:     Epoch: 93
2022-12-31 15:23:17,798 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36235606769720713, 'Total loss': 0.36235606769720713} | train loss {'Reaction outcome loss': 0.19986389299022975, 'Total loss': 0.19986389299022975}
2022-12-31 15:23:17,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:17,798 INFO:     Epoch: 94
2022-12-31 15:23:19,401 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3734226067860921, 'Total loss': 0.3734226067860921} | train loss {'Reaction outcome loss': 0.2016940342942837, 'Total loss': 0.2016940342942837}
2022-12-31 15:23:19,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:19,401 INFO:     Epoch: 95
2022-12-31 15:23:20,985 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38326115161180496, 'Total loss': 0.38326115161180496} | train loss {'Reaction outcome loss': 0.19484552163699456, 'Total loss': 0.19484552163699456}
2022-12-31 15:23:20,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:20,985 INFO:     Epoch: 96
2022-12-31 15:23:22,563 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39512082040309904, 'Total loss': 0.39512082040309904} | train loss {'Reaction outcome loss': 0.19701898331681741, 'Total loss': 0.19701898331681741}
2022-12-31 15:23:22,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:22,563 INFO:     Epoch: 97
2022-12-31 15:23:24,176 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40910807251930237, 'Total loss': 0.40910807251930237} | train loss {'Reaction outcome loss': 0.20092248775037452, 'Total loss': 0.20092248775037452}
2022-12-31 15:23:24,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:24,178 INFO:     Epoch: 98
2022-12-31 15:23:25,765 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3697867959737778, 'Total loss': 0.3697867959737778} | train loss {'Reaction outcome loss': 0.19996985736753228, 'Total loss': 0.19996985736753228}
2022-12-31 15:23:25,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:25,765 INFO:     Epoch: 99
2022-12-31 15:23:27,380 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37684859751413263, 'Total loss': 0.37684859751413263} | train loss {'Reaction outcome loss': 0.1971073758984294, 'Total loss': 0.1971073758984294}
2022-12-31 15:23:27,380 INFO:     Best model found after epoch 88 of 100.
2022-12-31 15:23:27,380 INFO:   Done with stage: TRAINING
2022-12-31 15:23:27,380 INFO:   Starting stage: EVALUATION
2022-12-31 15:23:27,528 INFO:   Done with stage: EVALUATION
2022-12-31 15:23:27,528 INFO:   Leaving out SEQ value Fold_1
2022-12-31 15:23:27,541 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 15:23:27,541 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:23:28,182 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:23:28,182 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:23:28,250 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:23:28,250 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:23:28,250 INFO:     No hyperparam tuning for this model
2022-12-31 15:23:28,250 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:23:28,250 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:23:28,251 INFO:     None feature selector for col prot
2022-12-31 15:23:28,251 INFO:     None feature selector for col prot
2022-12-31 15:23:28,251 INFO:     None feature selector for col prot
2022-12-31 15:23:28,252 INFO:     None feature selector for col chem
2022-12-31 15:23:28,252 INFO:     None feature selector for col chem
2022-12-31 15:23:28,252 INFO:     None feature selector for col chem
2022-12-31 15:23:28,252 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:23:28,252 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:23:28,254 INFO:     Number of params in model 223921
2022-12-31 15:23:28,257 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:23:28,257 INFO:   Starting stage: TRAINING
2022-12-31 15:23:28,301 INFO:     Val loss before train {'Reaction outcome loss': 0.889659337202708, 'Total loss': 0.889659337202708}
2022-12-31 15:23:28,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:28,301 INFO:     Epoch: 0
2022-12-31 15:23:29,942 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5634365151325862, 'Total loss': 0.5634365151325862} | train loss {'Reaction outcome loss': 0.8245233813994122, 'Total loss': 0.8245233813994122}
2022-12-31 15:23:29,942 INFO:     Found new best model at epoch 0
2022-12-31 15:23:29,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:29,943 INFO:     Epoch: 1
2022-12-31 15:23:31,559 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4511069973309835, 'Total loss': 0.4511069973309835} | train loss {'Reaction outcome loss': 0.6080281826919013, 'Total loss': 0.6080281826919013}
2022-12-31 15:23:31,560 INFO:     Found new best model at epoch 1
2022-12-31 15:23:31,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:31,561 INFO:     Epoch: 2
2022-12-31 15:23:33,192 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.41777499914169314, 'Total loss': 0.41777499914169314} | train loss {'Reaction outcome loss': 0.5394027615985731, 'Total loss': 0.5394027615985731}
2022-12-31 15:23:33,192 INFO:     Found new best model at epoch 2
2022-12-31 15:23:33,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:33,193 INFO:     Epoch: 3
2022-12-31 15:23:34,804 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.3916497806708018, 'Total loss': 0.3916497806708018} | train loss {'Reaction outcome loss': 0.5147020814627626, 'Total loss': 0.5147020814627626}
2022-12-31 15:23:34,804 INFO:     Found new best model at epoch 3
2022-12-31 15:23:34,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:34,805 INFO:     Epoch: 4
2022-12-31 15:23:36,443 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4396394302447637, 'Total loss': 0.4396394302447637} | train loss {'Reaction outcome loss': 0.5008302104190319, 'Total loss': 0.5008302104190319}
2022-12-31 15:23:36,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:36,443 INFO:     Epoch: 5
2022-12-31 15:23:38,083 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3792561610539754, 'Total loss': 0.3792561610539754} | train loss {'Reaction outcome loss': 0.490226176207083, 'Total loss': 0.490226176207083}
2022-12-31 15:23:38,083 INFO:     Found new best model at epoch 5
2022-12-31 15:23:38,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:38,084 INFO:     Epoch: 6
2022-12-31 15:23:39,712 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3540976544221242, 'Total loss': 0.3540976544221242} | train loss {'Reaction outcome loss': 0.47551551028868577, 'Total loss': 0.47551551028868577}
2022-12-31 15:23:39,712 INFO:     Found new best model at epoch 6
2022-12-31 15:23:39,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:39,713 INFO:     Epoch: 7
2022-12-31 15:23:41,312 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.37896353999773663, 'Total loss': 0.37896353999773663} | train loss {'Reaction outcome loss': 0.46771246428689817, 'Total loss': 0.46771246428689817}
2022-12-31 15:23:41,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:41,312 INFO:     Epoch: 8
2022-12-31 15:23:42,916 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3739768455425898, 'Total loss': 0.3739768455425898} | train loss {'Reaction outcome loss': 0.45945462046095925, 'Total loss': 0.45945462046095925}
2022-12-31 15:23:42,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:42,916 INFO:     Epoch: 9
2022-12-31 15:23:44,538 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.339859402179718, 'Total loss': 0.339859402179718} | train loss {'Reaction outcome loss': 0.461345288657794, 'Total loss': 0.461345288657794}
2022-12-31 15:23:44,539 INFO:     Found new best model at epoch 9
2022-12-31 15:23:44,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:44,540 INFO:     Epoch: 10
2022-12-31 15:23:46,169 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.34987886746724445, 'Total loss': 0.34987886746724445} | train loss {'Reaction outcome loss': 0.4488038906868357, 'Total loss': 0.4488038906868357}
2022-12-31 15:23:46,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:46,170 INFO:     Epoch: 11
2022-12-31 15:23:47,780 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.35242975652217867, 'Total loss': 0.35242975652217867} | train loss {'Reaction outcome loss': 0.438723619129971, 'Total loss': 0.438723619129971}
2022-12-31 15:23:47,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:47,780 INFO:     Epoch: 12
2022-12-31 15:23:49,376 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3341248665004969, 'Total loss': 0.3341248665004969} | train loss {'Reaction outcome loss': 0.4362382012670928, 'Total loss': 0.4362382012670928}
2022-12-31 15:23:49,376 INFO:     Found new best model at epoch 12
2022-12-31 15:23:49,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:49,377 INFO:     Epoch: 13
2022-12-31 15:23:50,998 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40616378287474314, 'Total loss': 0.40616378287474314} | train loss {'Reaction outcome loss': 0.4331255774319607, 'Total loss': 0.4331255774319607}
2022-12-31 15:23:50,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:50,999 INFO:     Epoch: 14
2022-12-31 15:23:52,592 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3403504451115926, 'Total loss': 0.3403504451115926} | train loss {'Reaction outcome loss': 0.4257814930412021, 'Total loss': 0.4257814930412021}
2022-12-31 15:23:52,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:52,592 INFO:     Epoch: 15
2022-12-31 15:23:54,202 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3470497876405716, 'Total loss': 0.3470497876405716} | train loss {'Reaction outcome loss': 0.4149962546453424, 'Total loss': 0.4149962546453424}
2022-12-31 15:23:54,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:54,203 INFO:     Epoch: 16
2022-12-31 15:23:55,809 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3515140612920125, 'Total loss': 0.3515140612920125} | train loss {'Reaction outcome loss': 0.4077809315419545, 'Total loss': 0.4077809315419545}
2022-12-31 15:23:55,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:55,809 INFO:     Epoch: 17
2022-12-31 15:23:57,409 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3553971886634827, 'Total loss': 0.3553971886634827} | train loss {'Reaction outcome loss': 0.40384600752026495, 'Total loss': 0.40384600752026495}
2022-12-31 15:23:57,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:57,409 INFO:     Epoch: 18
2022-12-31 15:23:59,014 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3756668115655581, 'Total loss': 0.3756668115655581} | train loss {'Reaction outcome loss': 0.39954940626656055, 'Total loss': 0.39954940626656055}
2022-12-31 15:23:59,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:23:59,015 INFO:     Epoch: 19
2022-12-31 15:24:00,649 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3623740643262863, 'Total loss': 0.3623740643262863} | train loss {'Reaction outcome loss': 0.39072923446549984, 'Total loss': 0.39072923446549984}
2022-12-31 15:24:00,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:00,649 INFO:     Epoch: 20
2022-12-31 15:24:02,237 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3509656290213267, 'Total loss': 0.3509656290213267} | train loss {'Reaction outcome loss': 0.38894640817476883, 'Total loss': 0.38894640817476883}
2022-12-31 15:24:02,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:02,238 INFO:     Epoch: 21
2022-12-31 15:24:03,865 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.336704941590627, 'Total loss': 0.336704941590627} | train loss {'Reaction outcome loss': 0.3808293037497214, 'Total loss': 0.3808293037497214}
2022-12-31 15:24:03,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:03,865 INFO:     Epoch: 22
2022-12-31 15:24:05,504 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3045029769341151, 'Total loss': 0.3045029769341151} | train loss {'Reaction outcome loss': 0.37202608835523143, 'Total loss': 0.37202608835523143}
2022-12-31 15:24:05,504 INFO:     Found new best model at epoch 22
2022-12-31 15:24:05,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:05,505 INFO:     Epoch: 23
2022-12-31 15:24:07,135 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3474243402481079, 'Total loss': 0.3474243402481079} | train loss {'Reaction outcome loss': 0.3707931741365116, 'Total loss': 0.3707931741365116}
2022-12-31 15:24:07,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:07,135 INFO:     Epoch: 24
2022-12-31 15:24:08,753 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.34383264084657034, 'Total loss': 0.34383264084657034} | train loss {'Reaction outcome loss': 0.3647457436270957, 'Total loss': 0.3647457436270957}
2022-12-31 15:24:08,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:08,753 INFO:     Epoch: 25
2022-12-31 15:24:10,360 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3256516511241595, 'Total loss': 0.3256516511241595} | train loss {'Reaction outcome loss': 0.3580384089400733, 'Total loss': 0.3580384089400733}
2022-12-31 15:24:10,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:10,360 INFO:     Epoch: 26
2022-12-31 15:24:11,957 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3004596342643102, 'Total loss': 0.3004596342643102} | train loss {'Reaction outcome loss': 0.3532460713147247, 'Total loss': 0.3532460713147247}
2022-12-31 15:24:11,957 INFO:     Found new best model at epoch 26
2022-12-31 15:24:11,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:11,958 INFO:     Epoch: 27
2022-12-31 15:24:13,592 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3290411392847697, 'Total loss': 0.3290411392847697} | train loss {'Reaction outcome loss': 0.35311251810758654, 'Total loss': 0.35311251810758654}
2022-12-31 15:24:13,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:13,592 INFO:     Epoch: 28
2022-12-31 15:24:15,231 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.34371877908706666, 'Total loss': 0.34371877908706666} | train loss {'Reaction outcome loss': 0.33974738973770696, 'Total loss': 0.33974738973770696}
2022-12-31 15:24:15,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:15,231 INFO:     Epoch: 29
2022-12-31 15:24:16,842 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.312600473066171, 'Total loss': 0.312600473066171} | train loss {'Reaction outcome loss': 0.34302241326629246, 'Total loss': 0.34302241326629246}
2022-12-31 15:24:16,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:16,842 INFO:     Epoch: 30
2022-12-31 15:24:18,439 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.29309815019369123, 'Total loss': 0.29309815019369123} | train loss {'Reaction outcome loss': 0.3384679626048046, 'Total loss': 0.3384679626048046}
2022-12-31 15:24:18,440 INFO:     Found new best model at epoch 30
2022-12-31 15:24:18,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:18,441 INFO:     Epoch: 31
2022-12-31 15:24:20,024 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3062589774529139, 'Total loss': 0.3062589774529139} | train loss {'Reaction outcome loss': 0.32849778141146596, 'Total loss': 0.32849778141146596}
2022-12-31 15:24:20,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:20,024 INFO:     Epoch: 32
2022-12-31 15:24:21,651 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.34510576327641806, 'Total loss': 0.34510576327641806} | train loss {'Reaction outcome loss': 0.3195732317212289, 'Total loss': 0.3195732317212289}
2022-12-31 15:24:21,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:21,651 INFO:     Epoch: 33
2022-12-31 15:24:23,284 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3322481781244278, 'Total loss': 0.3322481781244278} | train loss {'Reaction outcome loss': 0.32351804608955, 'Total loss': 0.32351804608955}
2022-12-31 15:24:23,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:23,284 INFO:     Epoch: 34
2022-12-31 15:24:24,915 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3003293424844742, 'Total loss': 0.3003293424844742} | train loss {'Reaction outcome loss': 0.3193868830473754, 'Total loss': 0.3193868830473754}
2022-12-31 15:24:24,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:24,915 INFO:     Epoch: 35
2022-12-31 15:24:26,511 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.31711266189813614, 'Total loss': 0.31711266189813614} | train loss {'Reaction outcome loss': 0.3163665848763755, 'Total loss': 0.3163665848763755}
2022-12-31 15:24:26,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:26,511 INFO:     Epoch: 36
2022-12-31 15:24:28,106 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.30774350663026173, 'Total loss': 0.30774350663026173} | train loss {'Reaction outcome loss': 0.3112983801232202, 'Total loss': 0.3112983801232202}
2022-12-31 15:24:28,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:28,106 INFO:     Epoch: 37
2022-12-31 15:24:29,716 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.33489112854003905, 'Total loss': 0.33489112854003905} | train loss {'Reaction outcome loss': 0.3013925492274065, 'Total loss': 0.3013925492274065}
2022-12-31 15:24:29,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:29,718 INFO:     Epoch: 38
2022-12-31 15:24:31,346 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.35555200080076854, 'Total loss': 0.35555200080076854} | train loss {'Reaction outcome loss': 0.29727914643875003, 'Total loss': 0.29727914643875003}
2022-12-31 15:24:31,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:31,346 INFO:     Epoch: 39
2022-12-31 15:24:32,936 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.35337935785452523, 'Total loss': 0.35337935785452523} | train loss {'Reaction outcome loss': 0.3019158155079523, 'Total loss': 0.3019158155079523}
2022-12-31 15:24:32,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:32,937 INFO:     Epoch: 40
2022-12-31 15:24:34,525 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.35307088096936545, 'Total loss': 0.35307088096936545} | train loss {'Reaction outcome loss': 0.2928006593545858, 'Total loss': 0.2928006593545858}
2022-12-31 15:24:34,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:34,525 INFO:     Epoch: 41
2022-12-31 15:24:36,123 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3490481247504552, 'Total loss': 0.3490481247504552} | train loss {'Reaction outcome loss': 0.29552994181748726, 'Total loss': 0.29552994181748726}
2022-12-31 15:24:36,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:36,124 INFO:     Epoch: 42
2022-12-31 15:24:37,714 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3314127564430237, 'Total loss': 0.3314127564430237} | train loss {'Reaction outcome loss': 0.2829874985898933, 'Total loss': 0.2829874985898933}
2022-12-31 15:24:37,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:37,714 INFO:     Epoch: 43
2022-12-31 15:24:39,349 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3432012528181076, 'Total loss': 0.3432012528181076} | train loss {'Reaction outcome loss': 0.2802322878889794, 'Total loss': 0.2802322878889794}
2022-12-31 15:24:39,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:39,349 INFO:     Epoch: 44
2022-12-31 15:24:40,988 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.31243752837181094, 'Total loss': 0.31243752837181094} | train loss {'Reaction outcome loss': 0.28247756962358517, 'Total loss': 0.28247756962358517}
2022-12-31 15:24:40,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:40,988 INFO:     Epoch: 45
2022-12-31 15:24:42,626 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3131550575296084, 'Total loss': 0.3131550575296084} | train loss {'Reaction outcome loss': 0.2872595264148103, 'Total loss': 0.2872595264148103}
2022-12-31 15:24:42,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:42,627 INFO:     Epoch: 46
2022-12-31 15:24:44,238 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37344294786453247, 'Total loss': 0.37344294786453247} | train loss {'Reaction outcome loss': 0.2756478129104324, 'Total loss': 0.2756478129104324}
2022-12-31 15:24:44,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:44,238 INFO:     Epoch: 47
2022-12-31 15:24:45,876 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3379480471213659, 'Total loss': 0.3379480471213659} | train loss {'Reaction outcome loss': 0.2763886663274173, 'Total loss': 0.2763886663274173}
2022-12-31 15:24:45,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:45,876 INFO:     Epoch: 48
2022-12-31 15:24:47,469 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3458231697479884, 'Total loss': 0.3458231697479884} | train loss {'Reaction outcome loss': 0.27441722305532357, 'Total loss': 0.27441722305532357}
2022-12-31 15:24:47,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:47,469 INFO:     Epoch: 49
2022-12-31 15:24:49,063 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3313576300938924, 'Total loss': 0.3313576300938924} | train loss {'Reaction outcome loss': 0.2684323297147333, 'Total loss': 0.2684323297147333}
2022-12-31 15:24:49,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:49,064 INFO:     Epoch: 50
2022-12-31 15:24:50,672 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3798345545927683, 'Total loss': 0.3798345545927683} | train loss {'Reaction outcome loss': 0.2646970330282067, 'Total loss': 0.2646970330282067}
2022-12-31 15:24:50,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:50,672 INFO:     Epoch: 51
2022-12-31 15:24:52,270 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3352590431769689, 'Total loss': 0.3352590431769689} | train loss {'Reaction outcome loss': 0.26738357793430995, 'Total loss': 0.26738357793430995}
2022-12-31 15:24:52,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:52,270 INFO:     Epoch: 52
2022-12-31 15:24:53,848 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3142998069524765, 'Total loss': 0.3142998069524765} | train loss {'Reaction outcome loss': 0.262078368995529, 'Total loss': 0.262078368995529}
2022-12-31 15:24:53,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:53,849 INFO:     Epoch: 53
2022-12-31 15:24:55,469 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3174219598372777, 'Total loss': 0.3174219598372777} | train loss {'Reaction outcome loss': 0.2610066845387655, 'Total loss': 0.2610066845387655}
2022-12-31 15:24:55,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:55,470 INFO:     Epoch: 54
2022-12-31 15:24:57,062 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3175578782955805, 'Total loss': 0.3175578782955805} | train loss {'Reaction outcome loss': 0.2619218925272461, 'Total loss': 0.2619218925272461}
2022-12-31 15:24:57,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:57,062 INFO:     Epoch: 55
2022-12-31 15:24:58,679 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3204124743739764, 'Total loss': 0.3204124743739764} | train loss {'Reaction outcome loss': 0.2547470228814513, 'Total loss': 0.2547470228814513}
2022-12-31 15:24:58,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:24:58,679 INFO:     Epoch: 56
2022-12-31 15:25:00,305 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.30905700474977493, 'Total loss': 0.30905700474977493} | train loss {'Reaction outcome loss': 0.25868812805707875, 'Total loss': 0.25868812805707875}
2022-12-31 15:25:00,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:00,306 INFO:     Epoch: 57
2022-12-31 15:25:01,875 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.31553147236506146, 'Total loss': 0.31553147236506146} | train loss {'Reaction outcome loss': 0.25574195261256105, 'Total loss': 0.25574195261256105}
2022-12-31 15:25:01,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:01,875 INFO:     Epoch: 58
2022-12-31 15:25:03,468 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.2953161522746086, 'Total loss': 0.2953161522746086} | train loss {'Reaction outcome loss': 0.24714194565848277, 'Total loss': 0.24714194565848277}
2022-12-31 15:25:03,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:03,468 INFO:     Epoch: 59
2022-12-31 15:25:05,051 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3261932015419006, 'Total loss': 0.3261932015419006} | train loss {'Reaction outcome loss': 0.24801549790970925, 'Total loss': 0.24801549790970925}
2022-12-31 15:25:05,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:05,051 INFO:     Epoch: 60
2022-12-31 15:25:06,646 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.346390933295091, 'Total loss': 0.346390933295091} | train loss {'Reaction outcome loss': 0.2505182773894528, 'Total loss': 0.2505182773894528}
2022-12-31 15:25:06,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:06,647 INFO:     Epoch: 61
2022-12-31 15:25:08,243 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.33291016668081286, 'Total loss': 0.33291016668081286} | train loss {'Reaction outcome loss': 0.24157180333931516, 'Total loss': 0.24157180333931516}
2022-12-31 15:25:08,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:08,243 INFO:     Epoch: 62
2022-12-31 15:25:09,840 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.33132292131582897, 'Total loss': 0.33132292131582897} | train loss {'Reaction outcome loss': 0.2441575496192396, 'Total loss': 0.2441575496192396}
2022-12-31 15:25:09,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:09,840 INFO:     Epoch: 63
2022-12-31 15:25:11,429 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.35602804720401765, 'Total loss': 0.35602804720401765} | train loss {'Reaction outcome loss': 0.2392692015010075, 'Total loss': 0.2392692015010075}
2022-12-31 15:25:11,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:11,429 INFO:     Epoch: 64
2022-12-31 15:25:13,060 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.29122427602608997, 'Total loss': 0.29122427602608997} | train loss {'Reaction outcome loss': 0.2368468919048344, 'Total loss': 0.2368468919048344}
2022-12-31 15:25:13,060 INFO:     Found new best model at epoch 64
2022-12-31 15:25:13,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:13,061 INFO:     Epoch: 65
2022-12-31 15:25:14,667 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.35690279106299083, 'Total loss': 0.35690279106299083} | train loss {'Reaction outcome loss': 0.22942892202332507, 'Total loss': 0.22942892202332507}
2022-12-31 15:25:14,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:14,668 INFO:     Epoch: 66
2022-12-31 15:25:16,297 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3505389201144377, 'Total loss': 0.3505389201144377} | train loss {'Reaction outcome loss': 0.23923085122811097, 'Total loss': 0.23923085122811097}
2022-12-31 15:25:16,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:16,298 INFO:     Epoch: 67
2022-12-31 15:25:17,940 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3356455018122991, 'Total loss': 0.3356455018122991} | train loss {'Reaction outcome loss': 0.23784163500433855, 'Total loss': 0.23784163500433855}
2022-12-31 15:25:17,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:17,941 INFO:     Epoch: 68
2022-12-31 15:25:19,554 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3179851012925307, 'Total loss': 0.3179851012925307} | train loss {'Reaction outcome loss': 0.23827932163882648, 'Total loss': 0.23827932163882648}
2022-12-31 15:25:19,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:19,554 INFO:     Epoch: 69
2022-12-31 15:25:21,141 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.29389073501030605, 'Total loss': 0.29389073501030605} | train loss {'Reaction outcome loss': 0.23979678885997646, 'Total loss': 0.23979678885997646}
2022-12-31 15:25:21,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:21,142 INFO:     Epoch: 70
2022-12-31 15:25:22,725 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.330001063644886, 'Total loss': 0.330001063644886} | train loss {'Reaction outcome loss': 0.23455490631452441, 'Total loss': 0.23455490631452441}
2022-12-31 15:25:22,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:22,725 INFO:     Epoch: 71
2022-12-31 15:25:24,336 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.32414506673812865, 'Total loss': 0.32414506673812865} | train loss {'Reaction outcome loss': 0.2307460325477767, 'Total loss': 0.2307460325477767}
2022-12-31 15:25:24,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:24,336 INFO:     Epoch: 72
2022-12-31 15:25:25,938 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.32756606141726174, 'Total loss': 0.32756606141726174} | train loss {'Reaction outcome loss': 0.2270765783278829, 'Total loss': 0.2270765783278829}
2022-12-31 15:25:25,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:25,938 INFO:     Epoch: 73
2022-12-31 15:25:27,537 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.34220177233219146, 'Total loss': 0.34220177233219146} | train loss {'Reaction outcome loss': 0.22903389121358195, 'Total loss': 0.22903389121358195}
2022-12-31 15:25:27,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:27,537 INFO:     Epoch: 74
2022-12-31 15:25:29,146 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.32587344000736873, 'Total loss': 0.32587344000736873} | train loss {'Reaction outcome loss': 0.22806532757805428, 'Total loss': 0.22806532757805428}
2022-12-31 15:25:29,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:29,147 INFO:     Epoch: 75
2022-12-31 15:25:30,789 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3592601031064987, 'Total loss': 0.3592601031064987} | train loss {'Reaction outcome loss': 0.21908754171857978, 'Total loss': 0.21908754171857978}
2022-12-31 15:25:30,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:30,790 INFO:     Epoch: 76
2022-12-31 15:25:32,447 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3297771528363228, 'Total loss': 0.3297771528363228} | train loss {'Reaction outcome loss': 0.23009192925898264, 'Total loss': 0.23009192925898264}
2022-12-31 15:25:32,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:32,447 INFO:     Epoch: 77
2022-12-31 15:25:34,081 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3356121296683947, 'Total loss': 0.3356121296683947} | train loss {'Reaction outcome loss': 0.21969120607568618, 'Total loss': 0.21969120607568618}
2022-12-31 15:25:34,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:34,081 INFO:     Epoch: 78
2022-12-31 15:25:35,716 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3529998968044917, 'Total loss': 0.3529998968044917} | train loss {'Reaction outcome loss': 0.22512031702773413, 'Total loss': 0.22512031702773413}
2022-12-31 15:25:35,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:35,716 INFO:     Epoch: 79
2022-12-31 15:25:37,347 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.30424144566059114, 'Total loss': 0.30424144566059114} | train loss {'Reaction outcome loss': 0.22219641707891966, 'Total loss': 0.22219641707891966}
2022-12-31 15:25:37,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:37,348 INFO:     Epoch: 80
2022-12-31 15:25:38,955 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.36534979442755383, 'Total loss': 0.36534979442755383} | train loss {'Reaction outcome loss': 0.21524481745572746, 'Total loss': 0.21524481745572746}
2022-12-31 15:25:38,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:38,956 INFO:     Epoch: 81
2022-12-31 15:25:40,586 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.30028149411082267, 'Total loss': 0.30028149411082267} | train loss {'Reaction outcome loss': 0.2196751362134288, 'Total loss': 0.2196751362134288}
2022-12-31 15:25:40,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:40,586 INFO:     Epoch: 82
2022-12-31 15:25:42,203 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.33231758524974186, 'Total loss': 0.33231758524974186} | train loss {'Reaction outcome loss': 0.21227427134902155, 'Total loss': 0.21227427134902155}
2022-12-31 15:25:42,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:42,204 INFO:     Epoch: 83
2022-12-31 15:25:43,838 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.34650376240412395, 'Total loss': 0.34650376240412395} | train loss {'Reaction outcome loss': 0.22020889544030176, 'Total loss': 0.22020889544030176}
2022-12-31 15:25:43,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:43,839 INFO:     Epoch: 84
2022-12-31 15:25:45,473 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.32656894624233246, 'Total loss': 0.32656894624233246} | train loss {'Reaction outcome loss': 0.21837557532423496, 'Total loss': 0.21837557532423496}
2022-12-31 15:25:45,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:45,474 INFO:     Epoch: 85
2022-12-31 15:25:47,077 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.31478714048862455, 'Total loss': 0.31478714048862455} | train loss {'Reaction outcome loss': 0.21321843713386, 'Total loss': 0.21321843713386}
2022-12-31 15:25:47,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:47,078 INFO:     Epoch: 86
2022-12-31 15:25:48,663 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3290212209026019, 'Total loss': 0.3290212209026019} | train loss {'Reaction outcome loss': 0.21206452923548155, 'Total loss': 0.21206452923548155}
2022-12-31 15:25:48,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:48,663 INFO:     Epoch: 87
2022-12-31 15:25:50,277 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3309507618347804, 'Total loss': 0.3309507618347804} | train loss {'Reaction outcome loss': 0.21426035934229837, 'Total loss': 0.21426035934229837}
2022-12-31 15:25:50,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:50,278 INFO:     Epoch: 88
2022-12-31 15:25:51,912 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3224753588438034, 'Total loss': 0.3224753588438034} | train loss {'Reaction outcome loss': 0.21166846434157477, 'Total loss': 0.21166846434157477}
2022-12-31 15:25:51,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:51,912 INFO:     Epoch: 89
2022-12-31 15:25:53,543 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3640922412276268, 'Total loss': 0.3640922412276268} | train loss {'Reaction outcome loss': 0.21886181505057065, 'Total loss': 0.21886181505057065}
2022-12-31 15:25:53,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:53,543 INFO:     Epoch: 90
2022-12-31 15:25:55,179 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3302303522825241, 'Total loss': 0.3302303522825241} | train loss {'Reaction outcome loss': 0.21542607325326352, 'Total loss': 0.21542607325326352}
2022-12-31 15:25:55,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:55,180 INFO:     Epoch: 91
2022-12-31 15:25:56,796 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3382506608963013, 'Total loss': 0.3382506608963013} | train loss {'Reaction outcome loss': 0.21789237474818735, 'Total loss': 0.21789237474818735}
2022-12-31 15:25:56,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:56,797 INFO:     Epoch: 92
2022-12-31 15:25:58,429 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3476874500513077, 'Total loss': 0.3476874500513077} | train loss {'Reaction outcome loss': 0.20761632155898932, 'Total loss': 0.20761632155898932}
2022-12-31 15:25:58,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:25:58,429 INFO:     Epoch: 93
2022-12-31 15:26:00,025 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3358932942152023, 'Total loss': 0.3358932942152023} | train loss {'Reaction outcome loss': 0.20292789880594198, 'Total loss': 0.20292789880594198}
2022-12-31 15:26:00,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:00,025 INFO:     Epoch: 94
2022-12-31 15:26:01,636 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.37983355224132537, 'Total loss': 0.37983355224132537} | train loss {'Reaction outcome loss': 0.19367544651439372, 'Total loss': 0.19367544651439372}
2022-12-31 15:26:01,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:01,636 INFO:     Epoch: 95
2022-12-31 15:26:03,266 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35323255956172944, 'Total loss': 0.35323255956172944} | train loss {'Reaction outcome loss': 0.21352447113905945, 'Total loss': 0.21352447113905945}
2022-12-31 15:26:03,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:03,266 INFO:     Epoch: 96
2022-12-31 15:26:04,888 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3389048218727112, 'Total loss': 0.3389048218727112} | train loss {'Reaction outcome loss': 0.21122893752244704, 'Total loss': 0.21122893752244704}
2022-12-31 15:26:04,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:04,888 INFO:     Epoch: 97
2022-12-31 15:26:06,477 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.34131155411402386, 'Total loss': 0.34131155411402386} | train loss {'Reaction outcome loss': 0.21391100875598235, 'Total loss': 0.21391100875598235}
2022-12-31 15:26:06,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:06,478 INFO:     Epoch: 98
2022-12-31 15:26:08,085 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.31030611991882323, 'Total loss': 0.31030611991882323} | train loss {'Reaction outcome loss': 0.2042042398009531, 'Total loss': 0.2042042398009531}
2022-12-31 15:26:08,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:08,086 INFO:     Epoch: 99
2022-12-31 15:26:09,688 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.33748931884765626, 'Total loss': 0.33748931884765626} | train loss {'Reaction outcome loss': 0.19988391029369765, 'Total loss': 0.19988391029369765}
2022-12-31 15:26:09,688 INFO:     Best model found after epoch 65 of 100.
2022-12-31 15:26:09,688 INFO:   Done with stage: TRAINING
2022-12-31 15:26:09,688 INFO:   Starting stage: EVALUATION
2022-12-31 15:26:09,823 INFO:   Done with stage: EVALUATION
2022-12-31 15:26:09,823 INFO:   Leaving out SEQ value Fold_2
2022-12-31 15:26:09,836 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 15:26:09,836 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:26:10,486 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:26:10,486 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:26:10,554 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:26:10,554 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:26:10,554 INFO:     No hyperparam tuning for this model
2022-12-31 15:26:10,554 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:26:10,554 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:26:10,555 INFO:     None feature selector for col prot
2022-12-31 15:26:10,555 INFO:     None feature selector for col prot
2022-12-31 15:26:10,555 INFO:     None feature selector for col prot
2022-12-31 15:26:10,556 INFO:     None feature selector for col chem
2022-12-31 15:26:10,556 INFO:     None feature selector for col chem
2022-12-31 15:26:10,556 INFO:     None feature selector for col chem
2022-12-31 15:26:10,556 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:26:10,556 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:26:10,558 INFO:     Number of params in model 223921
2022-12-31 15:26:10,561 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:26:10,561 INFO:   Starting stage: TRAINING
2022-12-31 15:26:10,607 INFO:     Val loss before train {'Reaction outcome loss': 1.0517500321070352, 'Total loss': 1.0517500321070352}
2022-12-31 15:26:10,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:10,607 INFO:     Epoch: 0
2022-12-31 15:26:12,253 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6480507373809814, 'Total loss': 0.6480507373809814} | train loss {'Reaction outcome loss': 0.8217162666977316, 'Total loss': 0.8217162666977316}
2022-12-31 15:26:12,253 INFO:     Found new best model at epoch 0
2022-12-31 15:26:12,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:12,254 INFO:     Epoch: 1
2022-12-31 15:26:13,908 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5551432589689891, 'Total loss': 0.5551432589689891} | train loss {'Reaction outcome loss': 0.6121715932436084, 'Total loss': 0.6121715932436084}
2022-12-31 15:26:13,909 INFO:     Found new best model at epoch 1
2022-12-31 15:26:13,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:13,910 INFO:     Epoch: 2
2022-12-31 15:26:15,536 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5047815223534902, 'Total loss': 0.5047815223534902} | train loss {'Reaction outcome loss': 0.5278063177610275, 'Total loss': 0.5278063177610275}
2022-12-31 15:26:15,537 INFO:     Found new best model at epoch 2
2022-12-31 15:26:15,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:15,538 INFO:     Epoch: 3
2022-12-31 15:26:17,166 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47878153026103976, 'Total loss': 0.47878153026103976} | train loss {'Reaction outcome loss': 0.5070850698918377, 'Total loss': 0.5070850698918377}
2022-12-31 15:26:17,166 INFO:     Found new best model at epoch 3
2022-12-31 15:26:17,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:17,167 INFO:     Epoch: 4
2022-12-31 15:26:18,801 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46763796905676525, 'Total loss': 0.46763796905676525} | train loss {'Reaction outcome loss': 0.4886569992839055, 'Total loss': 0.4886569992839055}
2022-12-31 15:26:18,801 INFO:     Found new best model at epoch 4
2022-12-31 15:26:18,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:18,802 INFO:     Epoch: 5
2022-12-31 15:26:20,436 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.464319642384847, 'Total loss': 0.464319642384847} | train loss {'Reaction outcome loss': 0.47976579214446247, 'Total loss': 0.47976579214446247}
2022-12-31 15:26:20,436 INFO:     Found new best model at epoch 5
2022-12-31 15:26:20,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:20,437 INFO:     Epoch: 6
2022-12-31 15:26:22,053 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4708456486463547, 'Total loss': 0.4708456486463547} | train loss {'Reaction outcome loss': 0.47306707145079324, 'Total loss': 0.47306707145079324}
2022-12-31 15:26:22,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:22,054 INFO:     Epoch: 7
2022-12-31 15:26:23,673 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4540462225675583, 'Total loss': 0.4540462225675583} | train loss {'Reaction outcome loss': 0.4569728877041743, 'Total loss': 0.4569728877041743}
2022-12-31 15:26:23,674 INFO:     Found new best model at epoch 7
2022-12-31 15:26:23,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:23,675 INFO:     Epoch: 8
2022-12-31 15:26:25,289 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4697633812824885, 'Total loss': 0.4697633812824885} | train loss {'Reaction outcome loss': 0.45137859968320077, 'Total loss': 0.45137859968320077}
2022-12-31 15:26:25,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:25,289 INFO:     Epoch: 9
2022-12-31 15:26:26,893 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4657292664051056, 'Total loss': 0.4657292664051056} | train loss {'Reaction outcome loss': 0.4449217363490143, 'Total loss': 0.4449217363490143}
2022-12-31 15:26:26,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:26,893 INFO:     Epoch: 10
2022-12-31 15:26:28,523 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4816848635673523, 'Total loss': 0.4816848635673523} | train loss {'Reaction outcome loss': 0.43697378845219803, 'Total loss': 0.43697378845219803}
2022-12-31 15:26:28,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:28,524 INFO:     Epoch: 11
2022-12-31 15:26:30,153 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4441400667031606, 'Total loss': 0.4441400667031606} | train loss {'Reaction outcome loss': 0.43441720217621577, 'Total loss': 0.43441720217621577}
2022-12-31 15:26:30,153 INFO:     Found new best model at epoch 11
2022-12-31 15:26:30,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:30,154 INFO:     Epoch: 12
2022-12-31 15:26:31,767 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4640803317228953, 'Total loss': 0.4640803317228953} | train loss {'Reaction outcome loss': 0.4347777057547068, 'Total loss': 0.4347777057547068}
2022-12-31 15:26:31,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:31,767 INFO:     Epoch: 13
2022-12-31 15:26:33,385 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4517604440450668, 'Total loss': 0.4517604440450668} | train loss {'Reaction outcome loss': 0.4350056007396484, 'Total loss': 0.4350056007396484}
2022-12-31 15:26:33,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:33,385 INFO:     Epoch: 14
2022-12-31 15:26:35,001 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5091902126868566, 'Total loss': 0.5091902126868566} | train loss {'Reaction outcome loss': 0.4394531071294045, 'Total loss': 0.4394531071294045}
2022-12-31 15:26:35,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:35,001 INFO:     Epoch: 15
2022-12-31 15:26:36,624 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4487334613998731, 'Total loss': 0.4487334613998731} | train loss {'Reaction outcome loss': 0.4590147437132976, 'Total loss': 0.4590147437132976}
2022-12-31 15:26:36,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:36,624 INFO:     Epoch: 16
2022-12-31 15:26:38,242 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4326408753792445, 'Total loss': 0.4326408753792445} | train loss {'Reaction outcome loss': 0.40889870258642064, 'Total loss': 0.40889870258642064}
2022-12-31 15:26:38,242 INFO:     Found new best model at epoch 16
2022-12-31 15:26:38,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:38,243 INFO:     Epoch: 17
2022-12-31 15:26:39,865 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4229893863201141, 'Total loss': 0.4229893863201141} | train loss {'Reaction outcome loss': 0.40229006215130264, 'Total loss': 0.40229006215130264}
2022-12-31 15:26:39,865 INFO:     Found new best model at epoch 17
2022-12-31 15:26:39,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:39,866 INFO:     Epoch: 18
2022-12-31 15:26:41,490 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43947164018948875, 'Total loss': 0.43947164018948875} | train loss {'Reaction outcome loss': 0.40778483050888864, 'Total loss': 0.40778483050888864}
2022-12-31 15:26:41,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:41,490 INFO:     Epoch: 19
2022-12-31 15:26:43,113 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43302734692891437, 'Total loss': 0.43302734692891437} | train loss {'Reaction outcome loss': 0.43483534132766855, 'Total loss': 0.43483534132766855}
2022-12-31 15:26:43,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:43,115 INFO:     Epoch: 20
2022-12-31 15:26:44,738 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43361979027589165, 'Total loss': 0.43361979027589165} | train loss {'Reaction outcome loss': 0.39715668872214743, 'Total loss': 0.39715668872214743}
2022-12-31 15:26:44,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:44,738 INFO:     Epoch: 21
2022-12-31 15:26:46,345 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41258551577727, 'Total loss': 0.41258551577727} | train loss {'Reaction outcome loss': 0.39164464527289383, 'Total loss': 0.39164464527289383}
2022-12-31 15:26:46,345 INFO:     Found new best model at epoch 21
2022-12-31 15:26:46,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:46,346 INFO:     Epoch: 22
2022-12-31 15:26:47,968 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3946772783994675, 'Total loss': 0.3946772783994675} | train loss {'Reaction outcome loss': 0.3797487503160601, 'Total loss': 0.3797487503160601}
2022-12-31 15:26:47,968 INFO:     Found new best model at epoch 22
2022-12-31 15:26:47,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:47,969 INFO:     Epoch: 23
2022-12-31 15:26:49,605 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42403548359870913, 'Total loss': 0.42403548359870913} | train loss {'Reaction outcome loss': 0.3803100305730882, 'Total loss': 0.3803100305730882}
2022-12-31 15:26:49,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:49,606 INFO:     Epoch: 24
2022-12-31 15:26:51,210 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39961894949277244, 'Total loss': 0.39961894949277244} | train loss {'Reaction outcome loss': 0.3662465906067603, 'Total loss': 0.3662465906067603}
2022-12-31 15:26:51,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:51,210 INFO:     Epoch: 25
2022-12-31 15:26:52,847 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4535285969575246, 'Total loss': 0.4535285969575246} | train loss {'Reaction outcome loss': 0.3720456474879082, 'Total loss': 0.3720456474879082}
2022-12-31 15:26:52,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:52,848 INFO:     Epoch: 26
2022-12-31 15:26:54,443 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4136129488547643, 'Total loss': 0.4136129488547643} | train loss {'Reaction outcome loss': 0.35683247410570795, 'Total loss': 0.35683247410570795}
2022-12-31 15:26:54,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:54,443 INFO:     Epoch: 27
2022-12-31 15:26:56,051 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4178457140922546, 'Total loss': 0.4178457140922546} | train loss {'Reaction outcome loss': 0.3528163009525641, 'Total loss': 0.3528163009525641}
2022-12-31 15:26:56,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:56,051 INFO:     Epoch: 28
2022-12-31 15:26:57,697 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4302800387144089, 'Total loss': 0.4302800387144089} | train loss {'Reaction outcome loss': 0.38618465880458447, 'Total loss': 0.38618465880458447}
2022-12-31 15:26:57,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:57,698 INFO:     Epoch: 29
2022-12-31 15:26:59,327 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3984868218501409, 'Total loss': 0.3984868218501409} | train loss {'Reaction outcome loss': 0.3460846705045011, 'Total loss': 0.3460846705045011}
2022-12-31 15:26:59,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:26:59,327 INFO:     Epoch: 30
2022-12-31 15:27:00,927 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4094615399837494, 'Total loss': 0.4094615399837494} | train loss {'Reaction outcome loss': 0.3385753202609772, 'Total loss': 0.3385753202609772}
2022-12-31 15:27:00,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:00,927 INFO:     Epoch: 31
2022-12-31 15:27:02,533 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4088411311308543, 'Total loss': 0.4088411311308543} | train loss {'Reaction outcome loss': 0.3331245236989597, 'Total loss': 0.3331245236989597}
2022-12-31 15:27:02,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:02,534 INFO:     Epoch: 32
2022-12-31 15:27:04,161 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.37192402879397074, 'Total loss': 0.37192402879397074} | train loss {'Reaction outcome loss': 0.32575833344447386, 'Total loss': 0.32575833344447386}
2022-12-31 15:27:04,161 INFO:     Found new best model at epoch 32
2022-12-31 15:27:04,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:04,162 INFO:     Epoch: 33
2022-12-31 15:27:05,793 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3882519692182541, 'Total loss': 0.3882519692182541} | train loss {'Reaction outcome loss': 0.3240313037582066, 'Total loss': 0.3240313037582066}
2022-12-31 15:27:05,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:05,793 INFO:     Epoch: 34
2022-12-31 15:27:07,436 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40679158295194306, 'Total loss': 0.40679158295194306} | train loss {'Reaction outcome loss': 0.33861471280671546, 'Total loss': 0.33861471280671546}
2022-12-31 15:27:07,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:07,436 INFO:     Epoch: 35
2022-12-31 15:27:09,051 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4266644775867462, 'Total loss': 0.4266644775867462} | train loss {'Reaction outcome loss': 0.34339523733849975, 'Total loss': 0.34339523733849975}
2022-12-31 15:27:09,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:09,051 INFO:     Epoch: 36
2022-12-31 15:27:10,660 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4032795717318853, 'Total loss': 0.4032795717318853} | train loss {'Reaction outcome loss': 0.36403082191448094, 'Total loss': 0.36403082191448094}
2022-12-31 15:27:10,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:10,660 INFO:     Epoch: 37
2022-12-31 15:27:12,255 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3951071212689082, 'Total loss': 0.3951071212689082} | train loss {'Reaction outcome loss': 0.3266804096747892, 'Total loss': 0.3266804096747892}
2022-12-31 15:27:12,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:12,256 INFO:     Epoch: 38
2022-12-31 15:27:13,901 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3732785920302073, 'Total loss': 0.3732785920302073} | train loss {'Reaction outcome loss': 0.3115208143369629, 'Total loss': 0.3115208143369629}
2022-12-31 15:27:13,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:13,902 INFO:     Epoch: 39
2022-12-31 15:27:15,511 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43372357785701754, 'Total loss': 0.43372357785701754} | train loss {'Reaction outcome loss': 0.30361156656906224, 'Total loss': 0.30361156656906224}
2022-12-31 15:27:15,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:15,512 INFO:     Epoch: 40
2022-12-31 15:27:17,122 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3975730001926422, 'Total loss': 0.3975730001926422} | train loss {'Reaction outcome loss': 0.3030798023303404, 'Total loss': 0.3030798023303404}
2022-12-31 15:27:17,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:17,122 INFO:     Epoch: 41
2022-12-31 15:27:18,722 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4017076427737872, 'Total loss': 0.4017076427737872} | train loss {'Reaction outcome loss': 0.3011911928422152, 'Total loss': 0.3011911928422152}
2022-12-31 15:27:18,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:18,722 INFO:     Epoch: 42
2022-12-31 15:27:20,332 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3860930244127909, 'Total loss': 0.3860930244127909} | train loss {'Reaction outcome loss': 0.2993399262659427, 'Total loss': 0.2993399262659427}
2022-12-31 15:27:20,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:20,333 INFO:     Epoch: 43
2022-12-31 15:27:21,927 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41062593857447305, 'Total loss': 0.41062593857447305} | train loss {'Reaction outcome loss': 0.2918162139409316, 'Total loss': 0.2918162139409316}
2022-12-31 15:27:21,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:21,927 INFO:     Epoch: 44
2022-12-31 15:27:23,535 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39677057762940726, 'Total loss': 0.39677057762940726} | train loss {'Reaction outcome loss': 0.2857856998166096, 'Total loss': 0.2857856998166096}
2022-12-31 15:27:23,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:23,535 INFO:     Epoch: 45
2022-12-31 15:27:25,147 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3897719532251358, 'Total loss': 0.3897719532251358} | train loss {'Reaction outcome loss': 0.28503006998401864, 'Total loss': 0.28503006998401864}
2022-12-31 15:27:25,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:25,147 INFO:     Epoch: 46
2022-12-31 15:27:26,753 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37762860059738157, 'Total loss': 0.37762860059738157} | train loss {'Reaction outcome loss': 0.27948022417832113, 'Total loss': 0.27948022417832113}
2022-12-31 15:27:26,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:26,753 INFO:     Epoch: 47
2022-12-31 15:27:28,383 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38491977552572887, 'Total loss': 0.38491977552572887} | train loss {'Reaction outcome loss': 0.27855674963633437, 'Total loss': 0.27855674963633437}
2022-12-31 15:27:28,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:28,384 INFO:     Epoch: 48
2022-12-31 15:27:29,986 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37132486552000044, 'Total loss': 0.37132486552000044} | train loss {'Reaction outcome loss': 0.28652613422414963, 'Total loss': 0.28652613422414963}
2022-12-31 15:27:29,986 INFO:     Found new best model at epoch 48
2022-12-31 15:27:29,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:29,987 INFO:     Epoch: 49
2022-12-31 15:27:31,599 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3503923957546552, 'Total loss': 0.3503923957546552} | train loss {'Reaction outcome loss': 0.30034469129674585, 'Total loss': 0.30034469129674585}
2022-12-31 15:27:31,599 INFO:     Found new best model at epoch 49
2022-12-31 15:27:31,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:31,600 INFO:     Epoch: 50
2022-12-31 15:27:33,226 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39647955596446993, 'Total loss': 0.39647955596446993} | train loss {'Reaction outcome loss': 0.27737939999265043, 'Total loss': 0.27737939999265043}
2022-12-31 15:27:33,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:33,227 INFO:     Epoch: 51
2022-12-31 15:27:34,863 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.37708007196585336, 'Total loss': 0.37708007196585336} | train loss {'Reaction outcome loss': 0.2795640623502339, 'Total loss': 0.2795640623502339}
2022-12-31 15:27:34,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:34,863 INFO:     Epoch: 52
2022-12-31 15:27:36,311 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3792726288239161, 'Total loss': 0.3792726288239161} | train loss {'Reaction outcome loss': 0.2737746385062802, 'Total loss': 0.2737746385062802}
2022-12-31 15:27:36,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:36,311 INFO:     Epoch: 53
2022-12-31 15:27:37,402 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3859195237358411, 'Total loss': 0.3859195237358411} | train loss {'Reaction outcome loss': 0.26446811284446425, 'Total loss': 0.26446811284446425}
2022-12-31 15:27:37,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:37,402 INFO:     Epoch: 54
2022-12-31 15:27:38,476 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3769589821497599, 'Total loss': 0.3769589821497599} | train loss {'Reaction outcome loss': 0.26795711977225123, 'Total loss': 0.26795711977225123}
2022-12-31 15:27:38,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:38,476 INFO:     Epoch: 55
2022-12-31 15:27:39,543 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40695403615633646, 'Total loss': 0.40695403615633646} | train loss {'Reaction outcome loss': 0.2648517757485894, 'Total loss': 0.2648517757485894}
2022-12-31 15:27:39,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:39,543 INFO:     Epoch: 56
2022-12-31 15:27:40,676 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38101043502489723, 'Total loss': 0.38101043502489723} | train loss {'Reaction outcome loss': 0.2626643957219262, 'Total loss': 0.2626643957219262}
2022-12-31 15:27:40,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:40,677 INFO:     Epoch: 57
2022-12-31 15:27:42,291 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3688055710246166, 'Total loss': 0.3688055710246166} | train loss {'Reaction outcome loss': 0.26606444315700134, 'Total loss': 0.26606444315700134}
2022-12-31 15:27:42,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:42,292 INFO:     Epoch: 58
2022-12-31 15:27:43,897 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3586732566356659, 'Total loss': 0.3586732566356659} | train loss {'Reaction outcome loss': 0.2595847608130155, 'Total loss': 0.2595847608130155}
2022-12-31 15:27:43,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:43,898 INFO:     Epoch: 59
2022-12-31 15:27:45,495 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38771482904752097, 'Total loss': 0.38771482904752097} | train loss {'Reaction outcome loss': 0.27155551342856715, 'Total loss': 0.27155551342856715}
2022-12-31 15:27:45,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:45,496 INFO:     Epoch: 60
2022-12-31 15:27:47,109 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3799774219592412, 'Total loss': 0.3799774219592412} | train loss {'Reaction outcome loss': 0.2575580833317773, 'Total loss': 0.2575580833317773}
2022-12-31 15:27:47,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:47,109 INFO:     Epoch: 61
2022-12-31 15:27:48,756 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3682315667470296, 'Total loss': 0.3682315667470296} | train loss {'Reaction outcome loss': 0.2545253744686741, 'Total loss': 0.2545253744686741}
2022-12-31 15:27:48,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:48,756 INFO:     Epoch: 62
2022-12-31 15:27:50,376 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4216693143049876, 'Total loss': 0.4216693143049876} | train loss {'Reaction outcome loss': 0.2563515672693348, 'Total loss': 0.2563515672693348}
2022-12-31 15:27:50,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:50,377 INFO:     Epoch: 63
2022-12-31 15:27:52,038 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3800843377908071, 'Total loss': 0.3800843377908071} | train loss {'Reaction outcome loss': 0.2531025112842579, 'Total loss': 0.2531025112842579}
2022-12-31 15:27:52,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:52,038 INFO:     Epoch: 64
2022-12-31 15:27:53,705 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37027179400126137, 'Total loss': 0.37027179400126137} | train loss {'Reaction outcome loss': 0.2518894931021403, 'Total loss': 0.2518894931021403}
2022-12-31 15:27:53,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:53,706 INFO:     Epoch: 65
2022-12-31 15:27:55,315 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.35439227769772214, 'Total loss': 0.35439227769772214} | train loss {'Reaction outcome loss': 0.2515723951143192, 'Total loss': 0.2515723951143192}
2022-12-31 15:27:55,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:55,315 INFO:     Epoch: 66
2022-12-31 15:27:56,941 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3607960174481074, 'Total loss': 0.3607960174481074} | train loss {'Reaction outcome loss': 0.24332779370192642, 'Total loss': 0.24332779370192642}
2022-12-31 15:27:56,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:56,941 INFO:     Epoch: 67
2022-12-31 15:27:58,581 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.35916955371697745, 'Total loss': 0.35916955371697745} | train loss {'Reaction outcome loss': 0.2489670260983985, 'Total loss': 0.2489670260983985}
2022-12-31 15:27:58,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:27:58,581 INFO:     Epoch: 68
2022-12-31 15:28:00,208 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.36052656372388203, 'Total loss': 0.36052656372388203} | train loss {'Reaction outcome loss': 0.24736216589909696, 'Total loss': 0.24736216589909696}
2022-12-31 15:28:00,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:00,208 INFO:     Epoch: 69
2022-12-31 15:28:01,840 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.35727755129337313, 'Total loss': 0.35727755129337313} | train loss {'Reaction outcome loss': 0.23875191667795423, 'Total loss': 0.23875191667795423}
2022-12-31 15:28:01,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:01,840 INFO:     Epoch: 70
2022-12-31 15:28:03,484 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4157215158144633, 'Total loss': 0.4157215158144633} | train loss {'Reaction outcome loss': 0.24477401325492648, 'Total loss': 0.24477401325492648}
2022-12-31 15:28:03,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:03,486 INFO:     Epoch: 71
2022-12-31 15:28:05,107 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3854672431945801, 'Total loss': 0.3854672431945801} | train loss {'Reaction outcome loss': 0.23405382477685108, 'Total loss': 0.23405382477685108}
2022-12-31 15:28:05,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:05,108 INFO:     Epoch: 72
2022-12-31 15:28:06,753 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.36572886010011035, 'Total loss': 0.36572886010011035} | train loss {'Reaction outcome loss': 0.23903594243387014, 'Total loss': 0.23903594243387014}
2022-12-31 15:28:06,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:06,753 INFO:     Epoch: 73
2022-12-31 15:28:08,370 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4040530413389206, 'Total loss': 0.4040530413389206} | train loss {'Reaction outcome loss': 0.23155974108379704, 'Total loss': 0.23155974108379704}
2022-12-31 15:28:08,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:08,370 INFO:     Epoch: 74
2022-12-31 15:28:09,990 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3861750771601995, 'Total loss': 0.3861750771601995} | train loss {'Reaction outcome loss': 0.2368284199130384, 'Total loss': 0.2368284199130384}
2022-12-31 15:28:09,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:09,990 INFO:     Epoch: 75
2022-12-31 15:28:11,632 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3584422593315442, 'Total loss': 0.3584422593315442} | train loss {'Reaction outcome loss': 0.23058334055404767, 'Total loss': 0.23058334055404767}
2022-12-31 15:28:11,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:11,633 INFO:     Epoch: 76
2022-12-31 15:28:13,250 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38926559686660767, 'Total loss': 0.38926559686660767} | train loss {'Reaction outcome loss': 0.23243585576816206, 'Total loss': 0.23243585576816206}
2022-12-31 15:28:13,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:13,251 INFO:     Epoch: 77
2022-12-31 15:28:14,858 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39024266600608826, 'Total loss': 0.39024266600608826} | train loss {'Reaction outcome loss': 0.2322226525758869, 'Total loss': 0.2322226525758869}
2022-12-31 15:28:14,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:14,858 INFO:     Epoch: 78
2022-12-31 15:28:16,462 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4063253621260325, 'Total loss': 0.4063253621260325} | train loss {'Reaction outcome loss': 0.23334490232662283, 'Total loss': 0.23334490232662283}
2022-12-31 15:28:16,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:16,462 INFO:     Epoch: 79
2022-12-31 15:28:18,076 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3874535580476125, 'Total loss': 0.3874535580476125} | train loss {'Reaction outcome loss': 0.2288466265755773, 'Total loss': 0.2288466265755773}
2022-12-31 15:28:18,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:18,076 INFO:     Epoch: 80
2022-12-31 15:28:19,716 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3944353540738424, 'Total loss': 0.3944353540738424} | train loss {'Reaction outcome loss': 0.22566896385472754, 'Total loss': 0.22566896385472754}
2022-12-31 15:28:19,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:19,717 INFO:     Epoch: 81
2022-12-31 15:28:21,333 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38635868231455484, 'Total loss': 0.38635868231455484} | train loss {'Reaction outcome loss': 0.2317210906252697, 'Total loss': 0.2317210906252697}
2022-12-31 15:28:21,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:21,333 INFO:     Epoch: 82
2022-12-31 15:28:22,925 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37693211138248445, 'Total loss': 0.37693211138248445} | train loss {'Reaction outcome loss': 0.23399217415810225, 'Total loss': 0.23399217415810225}
2022-12-31 15:28:22,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:22,926 INFO:     Epoch: 83
2022-12-31 15:28:24,531 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3671532909075419, 'Total loss': 0.3671532909075419} | train loss {'Reaction outcome loss': 0.22114947666388773, 'Total loss': 0.22114947666388773}
2022-12-31 15:28:24,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:24,532 INFO:     Epoch: 84
2022-12-31 15:28:26,124 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3910342400272687, 'Total loss': 0.3910342400272687} | train loss {'Reaction outcome loss': 0.21895820347835188, 'Total loss': 0.21895820347835188}
2022-12-31 15:28:26,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:26,125 INFO:     Epoch: 85
2022-12-31 15:28:27,756 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.368649485707283, 'Total loss': 0.368649485707283} | train loss {'Reaction outcome loss': 0.2229364879237002, 'Total loss': 0.2229364879237002}
2022-12-31 15:28:27,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:27,756 INFO:     Epoch: 86
2022-12-31 15:28:29,397 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37656345466772717, 'Total loss': 0.37656345466772717} | train loss {'Reaction outcome loss': 0.22162448659323952, 'Total loss': 0.22162448659323952}
2022-12-31 15:28:29,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:29,397 INFO:     Epoch: 87
2022-12-31 15:28:31,021 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.36584778825441994, 'Total loss': 0.36584778825441994} | train loss {'Reaction outcome loss': 0.21375436381060645, 'Total loss': 0.21375436381060645}
2022-12-31 15:28:31,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:31,022 INFO:     Epoch: 88
2022-12-31 15:28:32,644 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39642418225606285, 'Total loss': 0.39642418225606285} | train loss {'Reaction outcome loss': 0.21354290196862732, 'Total loss': 0.21354290196862732}
2022-12-31 15:28:32,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:32,644 INFO:     Epoch: 89
2022-12-31 15:28:34,273 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3471844524145126, 'Total loss': 0.3471844524145126} | train loss {'Reaction outcome loss': 0.21270476355541335, 'Total loss': 0.21270476355541335}
2022-12-31 15:28:34,273 INFO:     Found new best model at epoch 89
2022-12-31 15:28:34,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:34,274 INFO:     Epoch: 90
2022-12-31 15:28:35,867 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3798701028029124, 'Total loss': 0.3798701028029124} | train loss {'Reaction outcome loss': 0.22566023579893524, 'Total loss': 0.22566023579893524}
2022-12-31 15:28:35,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:35,867 INFO:     Epoch: 91
2022-12-31 15:28:37,471 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.37324878573417664, 'Total loss': 0.37324878573417664} | train loss {'Reaction outcome loss': 0.21617711876667495, 'Total loss': 0.21617711876667495}
2022-12-31 15:28:37,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:37,471 INFO:     Epoch: 92
2022-12-31 15:28:39,078 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4174288908640544, 'Total loss': 0.4174288908640544} | train loss {'Reaction outcome loss': 0.21298864320514427, 'Total loss': 0.21298864320514427}
2022-12-31 15:28:39,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:39,079 INFO:     Epoch: 93
2022-12-31 15:28:40,683 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.35151755511760713, 'Total loss': 0.35151755511760713} | train loss {'Reaction outcome loss': 0.24622149793393203, 'Total loss': 0.24622149793393203}
2022-12-31 15:28:40,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:40,683 INFO:     Epoch: 94
2022-12-31 15:28:42,294 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.37293604811032616, 'Total loss': 0.37293604811032616} | train loss {'Reaction outcome loss': 0.21966030372414683, 'Total loss': 0.21966030372414683}
2022-12-31 15:28:42,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:42,294 INFO:     Epoch: 95
2022-12-31 15:28:43,936 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.387639594078064, 'Total loss': 0.387639594078064} | train loss {'Reaction outcome loss': 0.20628814981192473, 'Total loss': 0.20628814981192473}
2022-12-31 15:28:43,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:43,936 INFO:     Epoch: 96
2022-12-31 15:28:45,552 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38283068537712095, 'Total loss': 0.38283068537712095} | train loss {'Reaction outcome loss': 0.2062165840601454, 'Total loss': 0.2062165840601454}
2022-12-31 15:28:45,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:45,552 INFO:     Epoch: 97
2022-12-31 15:28:47,179 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.37354089121023815, 'Total loss': 0.37354089121023815} | train loss {'Reaction outcome loss': 0.20254244193589935, 'Total loss': 0.20254244193589935}
2022-12-31 15:28:47,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:47,179 INFO:     Epoch: 98
2022-12-31 15:28:48,790 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3825647344191869, 'Total loss': 0.3825647344191869} | train loss {'Reaction outcome loss': 0.21627399108062187, 'Total loss': 0.21627399108062187}
2022-12-31 15:28:48,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:48,790 INFO:     Epoch: 99
2022-12-31 15:28:50,400 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3918206992248694, 'Total loss': 0.3918206992248694} | train loss {'Reaction outcome loss': 0.2557853396064129, 'Total loss': 0.2557853396064129}
2022-12-31 15:28:50,400 INFO:     Best model found after epoch 90 of 100.
2022-12-31 15:28:50,400 INFO:   Done with stage: TRAINING
2022-12-31 15:28:50,401 INFO:   Starting stage: EVALUATION
2022-12-31 15:28:50,529 INFO:   Done with stage: EVALUATION
2022-12-31 15:28:50,529 INFO:   Leaving out SEQ value Fold_3
2022-12-31 15:28:50,543 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 15:28:50,543 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:28:51,193 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:28:51,193 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:28:51,261 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:28:51,261 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:28:51,261 INFO:     No hyperparam tuning for this model
2022-12-31 15:28:51,261 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:28:51,261 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:28:51,262 INFO:     None feature selector for col prot
2022-12-31 15:28:51,262 INFO:     None feature selector for col prot
2022-12-31 15:28:51,262 INFO:     None feature selector for col prot
2022-12-31 15:28:51,263 INFO:     None feature selector for col chem
2022-12-31 15:28:51,263 INFO:     None feature selector for col chem
2022-12-31 15:28:51,263 INFO:     None feature selector for col chem
2022-12-31 15:28:51,263 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:28:51,263 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:28:51,265 INFO:     Number of params in model 223921
2022-12-31 15:28:51,268 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:28:51,268 INFO:   Starting stage: TRAINING
2022-12-31 15:28:51,312 INFO:     Val loss before train {'Reaction outcome loss': 1.0728725711504619, 'Total loss': 1.0728725711504619}
2022-12-31 15:28:51,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:51,312 INFO:     Epoch: 0
2022-12-31 15:28:52,939 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7085744619369507, 'Total loss': 0.7085744619369507} | train loss {'Reaction outcome loss': 0.8052273890462475, 'Total loss': 0.8052273890462475}
2022-12-31 15:28:52,939 INFO:     Found new best model at epoch 0
2022-12-31 15:28:52,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:52,940 INFO:     Epoch: 1
2022-12-31 15:28:54,540 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6165110568205515, 'Total loss': 0.6165110568205515} | train loss {'Reaction outcome loss': 0.5922875081499418, 'Total loss': 0.5922875081499418}
2022-12-31 15:28:54,540 INFO:     Found new best model at epoch 1
2022-12-31 15:28:54,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:54,541 INFO:     Epoch: 2
2022-12-31 15:28:56,146 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5838862876097362, 'Total loss': 0.5838862876097362} | train loss {'Reaction outcome loss': 0.5345219368304032, 'Total loss': 0.5345219368304032}
2022-12-31 15:28:56,147 INFO:     Found new best model at epoch 2
2022-12-31 15:28:56,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:56,148 INFO:     Epoch: 3
2022-12-31 15:28:57,753 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5366394966840744, 'Total loss': 0.5366394966840744} | train loss {'Reaction outcome loss': 0.5130883755897968, 'Total loss': 0.5130883755897968}
2022-12-31 15:28:57,753 INFO:     Found new best model at epoch 3
2022-12-31 15:28:57,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:57,754 INFO:     Epoch: 4
2022-12-31 15:28:59,348 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.509706034262975, 'Total loss': 0.509706034262975} | train loss {'Reaction outcome loss': 0.49488254701313766, 'Total loss': 0.49488254701313766}
2022-12-31 15:28:59,349 INFO:     Found new best model at epoch 4
2022-12-31 15:28:59,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:28:59,349 INFO:     Epoch: 5
2022-12-31 15:29:00,954 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5331468085447947, 'Total loss': 0.5331468085447947} | train loss {'Reaction outcome loss': 0.4794693585135974, 'Total loss': 0.4794693585135974}
2022-12-31 15:29:00,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:00,955 INFO:     Epoch: 6
2022-12-31 15:29:02,548 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5308949490388234, 'Total loss': 0.5308949490388234} | train loss {'Reaction outcome loss': 0.4727938801482104, 'Total loss': 0.4727938801482104}
2022-12-31 15:29:02,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:02,549 INFO:     Epoch: 7
2022-12-31 15:29:04,156 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5063901662826538, 'Total loss': 0.5063901662826538} | train loss {'Reaction outcome loss': 0.48326958697630884, 'Total loss': 0.48326958697630884}
2022-12-31 15:29:04,156 INFO:     Found new best model at epoch 7
2022-12-31 15:29:04,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:04,157 INFO:     Epoch: 8
2022-12-31 15:29:05,767 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5070526401201884, 'Total loss': 0.5070526401201884} | train loss {'Reaction outcome loss': 0.46072380509956373, 'Total loss': 0.46072380509956373}
2022-12-31 15:29:05,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:05,767 INFO:     Epoch: 9
2022-12-31 15:29:07,363 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49233532150586445, 'Total loss': 0.49233532150586445} | train loss {'Reaction outcome loss': 0.45488039321144635, 'Total loss': 0.45488039321144635}
2022-12-31 15:29:07,363 INFO:     Found new best model at epoch 9
2022-12-31 15:29:07,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:07,364 INFO:     Epoch: 10
2022-12-31 15:29:08,987 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5093861758708954, 'Total loss': 0.5093861758708954} | train loss {'Reaction outcome loss': 0.4532792572087298, 'Total loss': 0.4532792572087298}
2022-12-31 15:29:08,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:08,987 INFO:     Epoch: 11
2022-12-31 15:29:10,597 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4849796156088511, 'Total loss': 0.4849796156088511} | train loss {'Reaction outcome loss': 0.44601385445433983, 'Total loss': 0.44601385445433983}
2022-12-31 15:29:10,598 INFO:     Found new best model at epoch 11
2022-12-31 15:29:10,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:10,599 INFO:     Epoch: 12
2022-12-31 15:29:12,207 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5261310140291849, 'Total loss': 0.5261310140291849} | train loss {'Reaction outcome loss': 0.43521213802033226, 'Total loss': 0.43521213802033226}
2022-12-31 15:29:12,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:12,208 INFO:     Epoch: 13
2022-12-31 15:29:13,855 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.486893226703008, 'Total loss': 0.486893226703008} | train loss {'Reaction outcome loss': 0.43315928395284153, 'Total loss': 0.43315928395284153}
2022-12-31 15:29:13,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:13,855 INFO:     Epoch: 14
2022-12-31 15:29:15,474 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.493618102868398, 'Total loss': 0.493618102868398} | train loss {'Reaction outcome loss': 0.4258102817811828, 'Total loss': 0.4258102817811828}
2022-12-31 15:29:15,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:15,475 INFO:     Epoch: 15
2022-12-31 15:29:17,085 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5025596201419831, 'Total loss': 0.5025596201419831} | train loss {'Reaction outcome loss': 0.4212205932320406, 'Total loss': 0.4212205932320406}
2022-12-31 15:29:17,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:17,085 INFO:     Epoch: 16
2022-12-31 15:29:18,694 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4731046110391617, 'Total loss': 0.4731046110391617} | train loss {'Reaction outcome loss': 0.41876591960022197, 'Total loss': 0.41876591960022197}
2022-12-31 15:29:18,695 INFO:     Found new best model at epoch 16
2022-12-31 15:29:18,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:18,696 INFO:     Epoch: 17
2022-12-31 15:29:20,287 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48850900133450825, 'Total loss': 0.48850900133450825} | train loss {'Reaction outcome loss': 0.4088234708351724, 'Total loss': 0.4088234708351724}
2022-12-31 15:29:20,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:20,288 INFO:     Epoch: 18
2022-12-31 15:29:21,916 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.475822339951992, 'Total loss': 0.475822339951992} | train loss {'Reaction outcome loss': 0.4150663777322009, 'Total loss': 0.4150663777322009}
2022-12-31 15:29:21,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:21,916 INFO:     Epoch: 19
2022-12-31 15:29:23,531 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4804893910884857, 'Total loss': 0.4804893910884857} | train loss {'Reaction outcome loss': 0.4142754958618594, 'Total loss': 0.4142754958618594}
2022-12-31 15:29:23,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:23,531 INFO:     Epoch: 20
2022-12-31 15:29:25,146 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4618738392988841, 'Total loss': 0.4618738392988841} | train loss {'Reaction outcome loss': 0.39249503746142855, 'Total loss': 0.39249503746142855}
2022-12-31 15:29:25,146 INFO:     Found new best model at epoch 20
2022-12-31 15:29:25,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:25,147 INFO:     Epoch: 21
2022-12-31 15:29:26,770 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5206954578558604, 'Total loss': 0.5206954578558604} | train loss {'Reaction outcome loss': 0.3925296998299334, 'Total loss': 0.3925296998299334}
2022-12-31 15:29:26,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:26,772 INFO:     Epoch: 22
2022-12-31 15:29:28,380 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4992950091759364, 'Total loss': 0.4992950091759364} | train loss {'Reaction outcome loss': 0.3868948195291602, 'Total loss': 0.3868948195291602}
2022-12-31 15:29:28,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:28,381 INFO:     Epoch: 23
2022-12-31 15:29:29,977 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5008141775925954, 'Total loss': 0.5008141775925954} | train loss {'Reaction outcome loss': 0.3859566185403863, 'Total loss': 0.3859566185403863}
2022-12-31 15:29:29,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:29,978 INFO:     Epoch: 24
2022-12-31 15:29:31,586 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4726536085208257, 'Total loss': 0.4726536085208257} | train loss {'Reaction outcome loss': 0.3679823210067812, 'Total loss': 0.3679823210067812}
2022-12-31 15:29:31,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:31,586 INFO:     Epoch: 25
2022-12-31 15:29:33,193 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4798775285482407, 'Total loss': 0.4798775285482407} | train loss {'Reaction outcome loss': 0.37365917312664626, 'Total loss': 0.37365917312664626}
2022-12-31 15:29:33,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:33,194 INFO:     Epoch: 26
2022-12-31 15:29:34,797 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48696585893630984, 'Total loss': 0.48696585893630984} | train loss {'Reaction outcome loss': 0.3656199925943561, 'Total loss': 0.3656199925943561}
2022-12-31 15:29:34,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:34,797 INFO:     Epoch: 27
2022-12-31 15:29:36,434 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5078174889087677, 'Total loss': 0.5078174889087677} | train loss {'Reaction outcome loss': 0.3614653727053192, 'Total loss': 0.3614653727053192}
2022-12-31 15:29:36,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:36,434 INFO:     Epoch: 28
2022-12-31 15:29:38,071 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4866235355536143, 'Total loss': 0.4866235355536143} | train loss {'Reaction outcome loss': 0.35812760149027506, 'Total loss': 0.35812760149027506}
2022-12-31 15:29:38,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:38,071 INFO:     Epoch: 29
2022-12-31 15:29:39,689 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49524593551953633, 'Total loss': 0.49524593551953633} | train loss {'Reaction outcome loss': 0.3474214147992324, 'Total loss': 0.3474214147992324}
2022-12-31 15:29:39,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:39,689 INFO:     Epoch: 30
2022-12-31 15:29:41,336 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4605108102162679, 'Total loss': 0.4605108102162679} | train loss {'Reaction outcome loss': 0.34086734815787495, 'Total loss': 0.34086734815787495}
2022-12-31 15:29:41,336 INFO:     Found new best model at epoch 30
2022-12-31 15:29:41,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:41,337 INFO:     Epoch: 31
2022-12-31 15:29:42,968 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4696445445219676, 'Total loss': 0.4696445445219676} | train loss {'Reaction outcome loss': 0.34707252257309545, 'Total loss': 0.34707252257309545}
2022-12-31 15:29:42,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:42,968 INFO:     Epoch: 32
2022-12-31 15:29:44,597 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46512492895126345, 'Total loss': 0.46512492895126345} | train loss {'Reaction outcome loss': 0.33288940748320456, 'Total loss': 0.33288940748320456}
2022-12-31 15:29:44,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:44,597 INFO:     Epoch: 33
2022-12-31 15:29:46,215 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47462796171506244, 'Total loss': 0.47462796171506244} | train loss {'Reaction outcome loss': 0.33175499127178953, 'Total loss': 0.33175499127178953}
2022-12-31 15:29:46,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:46,216 INFO:     Epoch: 34
2022-12-31 15:29:47,815 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4713010330994924, 'Total loss': 0.4713010330994924} | train loss {'Reaction outcome loss': 0.3525063445562989, 'Total loss': 0.3525063445562989}
2022-12-31 15:29:47,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:47,815 INFO:     Epoch: 35
2022-12-31 15:29:49,452 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47841562032699586, 'Total loss': 0.47841562032699586} | train loss {'Reaction outcome loss': 0.3201559373629752, 'Total loss': 0.3201559373629752}
2022-12-31 15:29:49,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:49,453 INFO:     Epoch: 36
2022-12-31 15:29:51,081 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4662801484266917, 'Total loss': 0.4662801484266917} | train loss {'Reaction outcome loss': 0.32052124208865385, 'Total loss': 0.32052124208865385}
2022-12-31 15:29:51,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:51,082 INFO:     Epoch: 37
2022-12-31 15:29:52,676 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4957873423894246, 'Total loss': 0.4957873423894246} | train loss {'Reaction outcome loss': 0.31534939579179755, 'Total loss': 0.31534939579179755}
2022-12-31 15:29:52,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:52,676 INFO:     Epoch: 38
2022-12-31 15:29:54,282 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.484441618124644, 'Total loss': 0.484441618124644} | train loss {'Reaction outcome loss': 0.34661028260159027, 'Total loss': 0.34661028260159027}
2022-12-31 15:29:54,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:54,282 INFO:     Epoch: 39
2022-12-31 15:29:55,892 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46957712471485136, 'Total loss': 0.46957712471485136} | train loss {'Reaction outcome loss': 0.3095460032816028, 'Total loss': 0.3095460032816028}
2022-12-31 15:29:55,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:55,892 INFO:     Epoch: 40
2022-12-31 15:29:57,496 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4495193394521872, 'Total loss': 0.4495193394521872} | train loss {'Reaction outcome loss': 0.30562908780352765, 'Total loss': 0.30562908780352765}
2022-12-31 15:29:57,497 INFO:     Found new best model at epoch 40
2022-12-31 15:29:57,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:57,498 INFO:     Epoch: 41
2022-12-31 15:29:59,109 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46114273766676583, 'Total loss': 0.46114273766676583} | train loss {'Reaction outcome loss': 0.30143174785062793, 'Total loss': 0.30143174785062793}
2022-12-31 15:29:59,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:29:59,109 INFO:     Epoch: 42
2022-12-31 15:30:00,726 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.478927352031072, 'Total loss': 0.478927352031072} | train loss {'Reaction outcome loss': 0.29444023918198503, 'Total loss': 0.29444023918198503}
2022-12-31 15:30:00,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:00,727 INFO:     Epoch: 43
2022-12-31 15:30:02,348 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45464981297651924, 'Total loss': 0.45464981297651924} | train loss {'Reaction outcome loss': 0.28620042549311253, 'Total loss': 0.28620042549311253}
2022-12-31 15:30:02,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:02,348 INFO:     Epoch: 44
2022-12-31 15:30:03,961 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45359574953715004, 'Total loss': 0.45359574953715004} | train loss {'Reaction outcome loss': 0.2848639442828784, 'Total loss': 0.2848639442828784}
2022-12-31 15:30:03,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:03,962 INFO:     Epoch: 45
2022-12-31 15:30:05,566 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.452389266093572, 'Total loss': 0.452389266093572} | train loss {'Reaction outcome loss': 0.2893488786547728, 'Total loss': 0.2893488786547728}
2022-12-31 15:30:05,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:05,566 INFO:     Epoch: 46
2022-12-31 15:30:07,183 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45552610158920287, 'Total loss': 0.45552610158920287} | train loss {'Reaction outcome loss': 0.3052583188565104, 'Total loss': 0.3052583188565104}
2022-12-31 15:30:07,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:07,183 INFO:     Epoch: 47
2022-12-31 15:30:08,824 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48641803562641145, 'Total loss': 0.48641803562641145} | train loss {'Reaction outcome loss': 0.27650172555790364, 'Total loss': 0.27650172555790364}
2022-12-31 15:30:08,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:08,825 INFO:     Epoch: 48
2022-12-31 15:30:10,458 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49382394750912983, 'Total loss': 0.49382394750912983} | train loss {'Reaction outcome loss': 0.27361227475969074, 'Total loss': 0.27361227475969074}
2022-12-31 15:30:10,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:10,458 INFO:     Epoch: 49
2022-12-31 15:30:12,062 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4406966855128606, 'Total loss': 0.4406966855128606} | train loss {'Reaction outcome loss': 0.2709522456760802, 'Total loss': 0.2709522456760802}
2022-12-31 15:30:12,062 INFO:     Found new best model at epoch 49
2022-12-31 15:30:12,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:12,063 INFO:     Epoch: 50
2022-12-31 15:30:13,674 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45956030786037444, 'Total loss': 0.45956030786037444} | train loss {'Reaction outcome loss': 0.26525211167387647, 'Total loss': 0.26525211167387647}
2022-12-31 15:30:13,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:13,675 INFO:     Epoch: 51
2022-12-31 15:30:15,268 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5110683083534241, 'Total loss': 0.5110683083534241} | train loss {'Reaction outcome loss': 0.26599434011723794, 'Total loss': 0.26599434011723794}
2022-12-31 15:30:15,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:15,268 INFO:     Epoch: 52
2022-12-31 15:30:16,905 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47305041054884595, 'Total loss': 0.47305041054884595} | train loss {'Reaction outcome loss': 0.2633410208176086, 'Total loss': 0.2633410208176086}
2022-12-31 15:30:16,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:16,906 INFO:     Epoch: 53
2022-12-31 15:30:18,542 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46162868638833365, 'Total loss': 0.46162868638833365} | train loss {'Reaction outcome loss': 0.2665496464022368, 'Total loss': 0.2665496464022368}
2022-12-31 15:30:18,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:18,542 INFO:     Epoch: 54
2022-12-31 15:30:20,172 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4725984821716944, 'Total loss': 0.4725984821716944} | train loss {'Reaction outcome loss': 0.2556295507917336, 'Total loss': 0.2556295507917336}
2022-12-31 15:30:20,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:20,172 INFO:     Epoch: 55
2022-12-31 15:30:21,821 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4689692258834839, 'Total loss': 0.4689692258834839} | train loss {'Reaction outcome loss': 0.25220345039396425, 'Total loss': 0.25220345039396425}
2022-12-31 15:30:21,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:21,821 INFO:     Epoch: 56
2022-12-31 15:30:23,466 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4291953225930532, 'Total loss': 0.4291953225930532} | train loss {'Reaction outcome loss': 0.2529036823303297, 'Total loss': 0.2529036823303297}
2022-12-31 15:30:23,466 INFO:     Found new best model at epoch 56
2022-12-31 15:30:23,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:23,467 INFO:     Epoch: 57
2022-12-31 15:30:25,084 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47010593911012016, 'Total loss': 0.47010593911012016} | train loss {'Reaction outcome loss': 0.2496618187094324, 'Total loss': 0.2496618187094324}
2022-12-31 15:30:25,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:25,084 INFO:     Epoch: 58
2022-12-31 15:30:26,719 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4973730226357778, 'Total loss': 0.4973730226357778} | train loss {'Reaction outcome loss': 0.25875783713590994, 'Total loss': 0.25875783713590994}
2022-12-31 15:30:26,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:26,719 INFO:     Epoch: 59
2022-12-31 15:30:28,334 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46670889457066855, 'Total loss': 0.46670889457066855} | train loss {'Reaction outcome loss': 0.2480942710371101, 'Total loss': 0.2480942710371101}
2022-12-31 15:30:28,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:28,335 INFO:     Epoch: 60
2022-12-31 15:30:29,979 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47467428346474966, 'Total loss': 0.47467428346474966} | train loss {'Reaction outcome loss': 0.24555555340223204, 'Total loss': 0.24555555340223204}
2022-12-31 15:30:29,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:29,979 INFO:     Epoch: 61
2022-12-31 15:30:31,619 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4450604726870855, 'Total loss': 0.4450604726870855} | train loss {'Reaction outcome loss': 0.2431136127780664, 'Total loss': 0.2431136127780664}
2022-12-31 15:30:31,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:31,620 INFO:     Epoch: 62
2022-12-31 15:30:33,253 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.506842835744222, 'Total loss': 0.506842835744222} | train loss {'Reaction outcome loss': 0.24460763945514202, 'Total loss': 0.24460763945514202}
2022-12-31 15:30:33,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:33,253 INFO:     Epoch: 63
2022-12-31 15:30:34,904 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47773932218551635, 'Total loss': 0.47773932218551635} | train loss {'Reaction outcome loss': 0.24346956924326124, 'Total loss': 0.24346956924326124}
2022-12-31 15:30:34,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:34,905 INFO:     Epoch: 64
2022-12-31 15:30:36,559 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4461556628346443, 'Total loss': 0.4461556628346443} | train loss {'Reaction outcome loss': 0.23962510883828383, 'Total loss': 0.23962510883828383}
2022-12-31 15:30:36,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:36,560 INFO:     Epoch: 65
2022-12-31 15:30:38,158 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4660879115263621, 'Total loss': 0.4660879115263621} | train loss {'Reaction outcome loss': 0.23804062374751928, 'Total loss': 0.23804062374751928}
2022-12-31 15:30:38,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:38,159 INFO:     Epoch: 66
2022-12-31 15:30:39,809 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4518147339423498, 'Total loss': 0.4518147339423498} | train loss {'Reaction outcome loss': 0.24641617851844733, 'Total loss': 0.24641617851844733}
2022-12-31 15:30:39,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:39,810 INFO:     Epoch: 67
2022-12-31 15:30:41,451 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4947783946990967, 'Total loss': 0.4947783946990967} | train loss {'Reaction outcome loss': 0.23938943993715034, 'Total loss': 0.23938943993715034}
2022-12-31 15:30:41,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:41,451 INFO:     Epoch: 68
2022-12-31 15:30:43,055 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44416458408037823, 'Total loss': 0.44416458408037823} | train loss {'Reaction outcome loss': 0.23577791064188047, 'Total loss': 0.23577791064188047}
2022-12-31 15:30:43,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:43,055 INFO:     Epoch: 69
2022-12-31 15:30:44,664 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47019091844558714, 'Total loss': 0.47019091844558714} | train loss {'Reaction outcome loss': 0.22405833136977177, 'Total loss': 0.22405833136977177}
2022-12-31 15:30:44,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:44,665 INFO:     Epoch: 70
2022-12-31 15:30:46,276 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46544077396392824, 'Total loss': 0.46544077396392824} | train loss {'Reaction outcome loss': 0.2292735516498594, 'Total loss': 0.2292735516498594}
2022-12-31 15:30:46,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:46,276 INFO:     Epoch: 71
2022-12-31 15:30:47,886 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4356348524490992, 'Total loss': 0.4356348524490992} | train loss {'Reaction outcome loss': 0.23130642131023257, 'Total loss': 0.23130642131023257}
2022-12-31 15:30:47,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:47,886 INFO:     Epoch: 72
2022-12-31 15:30:49,495 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4950424820184708, 'Total loss': 0.4950424820184708} | train loss {'Reaction outcome loss': 0.2381704005183301, 'Total loss': 0.2381704005183301}
2022-12-31 15:30:49,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:49,496 INFO:     Epoch: 73
2022-12-31 15:30:51,093 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4575363576412201, 'Total loss': 0.4575363576412201} | train loss {'Reaction outcome loss': 0.2792923511908579, 'Total loss': 0.2792923511908579}
2022-12-31 15:30:51,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:51,094 INFO:     Epoch: 74
2022-12-31 15:30:52,700 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45026133159796394, 'Total loss': 0.45026133159796394} | train loss {'Reaction outcome loss': 0.23293174804944167, 'Total loss': 0.23293174804944167}
2022-12-31 15:30:52,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:52,700 INFO:     Epoch: 75
2022-12-31 15:30:54,308 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47771316170692446, 'Total loss': 0.47771316170692446} | train loss {'Reaction outcome loss': 0.227829203563, 'Total loss': 0.227829203563}
2022-12-31 15:30:54,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:54,308 INFO:     Epoch: 76
2022-12-31 15:30:55,904 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43768074810504914, 'Total loss': 0.43768074810504914} | train loss {'Reaction outcome loss': 0.22030298752740593, 'Total loss': 0.22030298752740593}
2022-12-31 15:30:55,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:55,905 INFO:     Epoch: 77
2022-12-31 15:30:57,547 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49772009054819744, 'Total loss': 0.49772009054819744} | train loss {'Reaction outcome loss': 0.22580275739090977, 'Total loss': 0.22580275739090977}
2022-12-31 15:30:57,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:57,548 INFO:     Epoch: 78
2022-12-31 15:30:59,196 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4856986145178477, 'Total loss': 0.4856986145178477} | train loss {'Reaction outcome loss': 0.2308426261135827, 'Total loss': 0.2308426261135827}
2022-12-31 15:30:59,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:30:59,197 INFO:     Epoch: 79
2022-12-31 15:31:00,843 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45590073267618814, 'Total loss': 0.45590073267618814} | train loss {'Reaction outcome loss': 0.2159479153307747, 'Total loss': 0.2159479153307747}
2022-12-31 15:31:00,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:00,843 INFO:     Epoch: 80
2022-12-31 15:31:02,496 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43665773371855415, 'Total loss': 0.43665773371855415} | train loss {'Reaction outcome loss': 0.2243172168497564, 'Total loss': 0.2243172168497564}
2022-12-31 15:31:02,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:02,496 INFO:     Epoch: 81
2022-12-31 15:31:04,161 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4454929282267888, 'Total loss': 0.4454929282267888} | train loss {'Reaction outcome loss': 0.21743263477579286, 'Total loss': 0.21743263477579286}
2022-12-31 15:31:04,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:04,161 INFO:     Epoch: 82
2022-12-31 15:31:05,786 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4364111403624217, 'Total loss': 0.4364111403624217} | train loss {'Reaction outcome loss': 0.22411194936689688, 'Total loss': 0.22411194936689688}
2022-12-31 15:31:05,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:05,787 INFO:     Epoch: 83
2022-12-31 15:31:07,442 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43772661288579306, 'Total loss': 0.43772661288579306} | train loss {'Reaction outcome loss': 0.21520507303311193, 'Total loss': 0.21520507303311193}
2022-12-31 15:31:07,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:07,442 INFO:     Epoch: 84
2022-12-31 15:31:09,110 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49068646132946014, 'Total loss': 0.49068646132946014} | train loss {'Reaction outcome loss': 0.2171484957362354, 'Total loss': 0.2171484957362354}
2022-12-31 15:31:09,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:09,110 INFO:     Epoch: 85
2022-12-31 15:31:10,767 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45615445176760355, 'Total loss': 0.45615445176760355} | train loss {'Reaction outcome loss': 0.20973703874472488, 'Total loss': 0.20973703874472488}
2022-12-31 15:31:10,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:10,768 INFO:     Epoch: 86
2022-12-31 15:31:12,432 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44730043411254883, 'Total loss': 0.44730043411254883} | train loss {'Reaction outcome loss': 0.20763307619881413, 'Total loss': 0.20763307619881413}
2022-12-31 15:31:12,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:12,432 INFO:     Epoch: 87
2022-12-31 15:31:14,088 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.432240683833758, 'Total loss': 0.432240683833758} | train loss {'Reaction outcome loss': 0.2078987295642129, 'Total loss': 0.2078987295642129}
2022-12-31 15:31:14,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:14,089 INFO:     Epoch: 88
2022-12-31 15:31:15,744 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45658840934435524, 'Total loss': 0.45658840934435524} | train loss {'Reaction outcome loss': 0.20994440182719543, 'Total loss': 0.20994440182719543}
2022-12-31 15:31:15,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:15,745 INFO:     Epoch: 89
2022-12-31 15:31:17,397 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46526406407356263, 'Total loss': 0.46526406407356263} | train loss {'Reaction outcome loss': 0.23287621887815793, 'Total loss': 0.23287621887815793}
2022-12-31 15:31:17,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:17,398 INFO:     Epoch: 90
2022-12-31 15:31:19,037 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44522842665513357, 'Total loss': 0.44522842665513357} | train loss {'Reaction outcome loss': 0.2152360791232491, 'Total loss': 0.2152360791232491}
2022-12-31 15:31:19,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:19,038 INFO:     Epoch: 91
2022-12-31 15:31:20,679 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4487928862373034, 'Total loss': 0.4487928862373034} | train loss {'Reaction outcome loss': 0.2157552162543125, 'Total loss': 0.2157552162543125}
2022-12-31 15:31:20,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:20,679 INFO:     Epoch: 92
2022-12-31 15:31:22,329 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49153654972712196, 'Total loss': 0.49153654972712196} | train loss {'Reaction outcome loss': 0.21095794085683167, 'Total loss': 0.21095794085683167}
2022-12-31 15:31:22,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:22,329 INFO:     Epoch: 93
2022-12-31 15:31:23,968 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4599466363588969, 'Total loss': 0.4599466363588969} | train loss {'Reaction outcome loss': 0.20363655821479304, 'Total loss': 0.20363655821479304}
2022-12-31 15:31:23,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:23,969 INFO:     Epoch: 94
2022-12-31 15:31:25,637 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44047582646210987, 'Total loss': 0.44047582646210987} | train loss {'Reaction outcome loss': 0.20316908364622868, 'Total loss': 0.20316908364622868}
2022-12-31 15:31:25,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:25,637 INFO:     Epoch: 95
2022-12-31 15:31:27,291 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44017940709988274, 'Total loss': 0.44017940709988274} | train loss {'Reaction outcome loss': 0.19642788646202805, 'Total loss': 0.19642788646202805}
2022-12-31 15:31:27,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:27,292 INFO:     Epoch: 96
2022-12-31 15:31:28,919 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4553643683592478, 'Total loss': 0.4553643683592478} | train loss {'Reaction outcome loss': 0.1974537977631648, 'Total loss': 0.1974537977631648}
2022-12-31 15:31:28,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:28,920 INFO:     Epoch: 97
2022-12-31 15:31:30,563 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49787175556023916, 'Total loss': 0.49787175556023916} | train loss {'Reaction outcome loss': 0.19880299121818415, 'Total loss': 0.19880299121818415}
2022-12-31 15:31:30,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:30,565 INFO:     Epoch: 98
2022-12-31 15:31:32,224 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4680477499961853, 'Total loss': 0.4680477499961853} | train loss {'Reaction outcome loss': 0.1978305420139488, 'Total loss': 0.1978305420139488}
2022-12-31 15:31:32,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:32,224 INFO:     Epoch: 99
2022-12-31 15:31:33,849 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45412556727727255, 'Total loss': 0.45412556727727255} | train loss {'Reaction outcome loss': 0.22351320006925127, 'Total loss': 0.22351320006925127}
2022-12-31 15:31:33,850 INFO:     Best model found after epoch 57 of 100.
2022-12-31 15:31:33,850 INFO:   Done with stage: TRAINING
2022-12-31 15:31:33,850 INFO:   Starting stage: EVALUATION
2022-12-31 15:31:33,997 INFO:   Done with stage: EVALUATION
2022-12-31 15:31:33,998 INFO:   Leaving out SEQ value Fold_4
2022-12-31 15:31:34,012 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 15:31:34,012 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:31:34,713 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:31:34,713 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:31:34,792 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:31:34,792 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:31:34,792 INFO:     No hyperparam tuning for this model
2022-12-31 15:31:34,792 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:31:34,792 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:31:34,793 INFO:     None feature selector for col prot
2022-12-31 15:31:34,793 INFO:     None feature selector for col prot
2022-12-31 15:31:34,793 INFO:     None feature selector for col prot
2022-12-31 15:31:34,794 INFO:     None feature selector for col chem
2022-12-31 15:31:34,794 INFO:     None feature selector for col chem
2022-12-31 15:31:34,794 INFO:     None feature selector for col chem
2022-12-31 15:31:34,794 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:31:34,794 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:31:34,796 INFO:     Number of params in model 223921
2022-12-31 15:31:34,800 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:31:34,800 INFO:   Starting stage: TRAINING
2022-12-31 15:31:34,849 INFO:     Val loss before train {'Reaction outcome loss': 0.9900262872378032, 'Total loss': 0.9900262872378032}
2022-12-31 15:31:34,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:34,849 INFO:     Epoch: 0
2022-12-31 15:31:36,508 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6911229292551676, 'Total loss': 0.6911229292551676} | train loss {'Reaction outcome loss': 0.8145340288373968, 'Total loss': 0.8145340288373968}
2022-12-31 15:31:36,508 INFO:     Found new best model at epoch 0
2022-12-31 15:31:36,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:36,509 INFO:     Epoch: 1
2022-12-31 15:31:38,138 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5369246701399485, 'Total loss': 0.5369246701399485} | train loss {'Reaction outcome loss': 0.6020203194032938, 'Total loss': 0.6020203194032938}
2022-12-31 15:31:38,139 INFO:     Found new best model at epoch 1
2022-12-31 15:31:38,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:38,141 INFO:     Epoch: 2
2022-12-31 15:31:39,795 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5265109399954478, 'Total loss': 0.5265109399954478} | train loss {'Reaction outcome loss': 0.5306766515174067, 'Total loss': 0.5306766515174067}
2022-12-31 15:31:39,795 INFO:     Found new best model at epoch 2
2022-12-31 15:31:39,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:39,797 INFO:     Epoch: 3
2022-12-31 15:31:41,458 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5232709189256032, 'Total loss': 0.5232709189256032} | train loss {'Reaction outcome loss': 0.5036484419438814, 'Total loss': 0.5036484419438814}
2022-12-31 15:31:41,458 INFO:     Found new best model at epoch 3
2022-12-31 15:31:41,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:41,460 INFO:     Epoch: 4
2022-12-31 15:31:43,086 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5516164640585581, 'Total loss': 0.5516164640585581} | train loss {'Reaction outcome loss': 0.4878407403127381, 'Total loss': 0.4878407403127381}
2022-12-31 15:31:43,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:43,087 INFO:     Epoch: 5
2022-12-31 15:31:44,748 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5214553038279216, 'Total loss': 0.5214553038279216} | train loss {'Reaction outcome loss': 0.47588719857944045, 'Total loss': 0.47588719857944045}
2022-12-31 15:31:44,748 INFO:     Found new best model at epoch 5
2022-12-31 15:31:44,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:44,750 INFO:     Epoch: 6
2022-12-31 15:31:46,401 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5036468704541525, 'Total loss': 0.5036468704541525} | train loss {'Reaction outcome loss': 0.46954108462652144, 'Total loss': 0.46954108462652144}
2022-12-31 15:31:46,401 INFO:     Found new best model at epoch 6
2022-12-31 15:31:46,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:46,403 INFO:     Epoch: 7
2022-12-31 15:31:48,031 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5148085256417593, 'Total loss': 0.5148085256417593} | train loss {'Reaction outcome loss': 0.4581955755230322, 'Total loss': 0.4581955755230322}
2022-12-31 15:31:48,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:48,032 INFO:     Epoch: 8
2022-12-31 15:31:49,694 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5066128969192505, 'Total loss': 0.5066128969192505} | train loss {'Reaction outcome loss': 0.4559691137624131, 'Total loss': 0.4559691137624131}
2022-12-31 15:31:49,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:49,694 INFO:     Epoch: 9
2022-12-31 15:31:51,345 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48598330914974214, 'Total loss': 0.48598330914974214} | train loss {'Reaction outcome loss': 0.44973373687439444, 'Total loss': 0.44973373687439444}
2022-12-31 15:31:51,346 INFO:     Found new best model at epoch 9
2022-12-31 15:31:51,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:51,347 INFO:     Epoch: 10
2022-12-31 15:31:53,005 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5011051138242085, 'Total loss': 0.5011051138242085} | train loss {'Reaction outcome loss': 0.44276996069866825, 'Total loss': 0.44276996069866825}
2022-12-31 15:31:53,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:53,006 INFO:     Epoch: 11
2022-12-31 15:31:54,664 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47797322273254395, 'Total loss': 0.47797322273254395} | train loss {'Reaction outcome loss': 0.439997591051384, 'Total loss': 0.439997591051384}
2022-12-31 15:31:54,664 INFO:     Found new best model at epoch 11
2022-12-31 15:31:54,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:54,665 INFO:     Epoch: 12
2022-12-31 15:31:56,289 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4996512134869893, 'Total loss': 0.4996512134869893} | train loss {'Reaction outcome loss': 0.43141656592219313, 'Total loss': 0.43141656592219313}
2022-12-31 15:31:56,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:56,289 INFO:     Epoch: 13
2022-12-31 15:31:57,944 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48242462674776715, 'Total loss': 0.48242462674776715} | train loss {'Reaction outcome loss': 0.43121701618824626, 'Total loss': 0.43121701618824626}
2022-12-31 15:31:57,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:57,945 INFO:     Epoch: 14
2022-12-31 15:31:59,594 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.493369859457016, 'Total loss': 0.493369859457016} | train loss {'Reaction outcome loss': 0.4232966581944524, 'Total loss': 0.4232966581944524}
2022-12-31 15:31:59,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:31:59,594 INFO:     Epoch: 15
2022-12-31 15:32:01,220 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4648706843455633, 'Total loss': 0.4648706843455633} | train loss {'Reaction outcome loss': 0.41793663885834414, 'Total loss': 0.41793663885834414}
2022-12-31 15:32:01,220 INFO:     Found new best model at epoch 15
2022-12-31 15:32:01,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:01,221 INFO:     Epoch: 16
2022-12-31 15:32:02,853 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47053878257671994, 'Total loss': 0.47053878257671994} | train loss {'Reaction outcome loss': 0.4080001120102535, 'Total loss': 0.4080001120102535}
2022-12-31 15:32:02,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:02,853 INFO:     Epoch: 17
2022-12-31 15:32:04,482 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.475250510374705, 'Total loss': 0.475250510374705} | train loss {'Reaction outcome loss': 0.4045108336726681, 'Total loss': 0.4045108336726681}
2022-12-31 15:32:04,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:04,482 INFO:     Epoch: 18
2022-12-31 15:32:06,094 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4913389980792999, 'Total loss': 0.4913389980792999} | train loss {'Reaction outcome loss': 0.39702747907449193, 'Total loss': 0.39702747907449193}
2022-12-31 15:32:06,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:06,095 INFO:     Epoch: 19
2022-12-31 15:32:07,722 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4647391617298126, 'Total loss': 0.4647391617298126} | train loss {'Reaction outcome loss': 0.38880976464343847, 'Total loss': 0.38880976464343847}
2022-12-31 15:32:07,722 INFO:     Found new best model at epoch 19
2022-12-31 15:32:07,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:07,723 INFO:     Epoch: 20
2022-12-31 15:32:09,323 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46680410504341124, 'Total loss': 0.46680410504341124} | train loss {'Reaction outcome loss': 0.3891640587403886, 'Total loss': 0.3891640587403886}
2022-12-31 15:32:09,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:09,323 INFO:     Epoch: 21
2022-12-31 15:32:10,980 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49349870880444846, 'Total loss': 0.49349870880444846} | train loss {'Reaction outcome loss': 0.3802350074429374, 'Total loss': 0.3802350074429374}
2022-12-31 15:32:10,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:10,980 INFO:     Epoch: 22
2022-12-31 15:32:12,621 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4624717772006989, 'Total loss': 0.4624717772006989} | train loss {'Reaction outcome loss': 0.3811006284846726, 'Total loss': 0.3811006284846726}
2022-12-31 15:32:12,622 INFO:     Found new best model at epoch 22
2022-12-31 15:32:12,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:12,623 INFO:     Epoch: 23
2022-12-31 15:32:14,228 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45757437745730084, 'Total loss': 0.45757437745730084} | train loss {'Reaction outcome loss': 0.3754821361348517, 'Total loss': 0.3754821361348517}
2022-12-31 15:32:14,228 INFO:     Found new best model at epoch 23
2022-12-31 15:32:14,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:14,229 INFO:     Epoch: 24
2022-12-31 15:32:15,832 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4777767618497213, 'Total loss': 0.4777767618497213} | train loss {'Reaction outcome loss': 0.37383760259039567, 'Total loss': 0.37383760259039567}
2022-12-31 15:32:15,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:15,832 INFO:     Epoch: 25
2022-12-31 15:32:17,447 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4348825742801031, 'Total loss': 0.4348825742801031} | train loss {'Reaction outcome loss': 0.3696972635517482, 'Total loss': 0.3696972635517482}
2022-12-31 15:32:17,447 INFO:     Found new best model at epoch 25
2022-12-31 15:32:17,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:17,448 INFO:     Epoch: 26
2022-12-31 15:32:19,040 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4561233510573705, 'Total loss': 0.4561233510573705} | train loss {'Reaction outcome loss': 0.36274638626764827, 'Total loss': 0.36274638626764827}
2022-12-31 15:32:19,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:19,041 INFO:     Epoch: 27
2022-12-31 15:32:20,655 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4198429932196935, 'Total loss': 0.4198429932196935} | train loss {'Reaction outcome loss': 0.3591303747106976, 'Total loss': 0.3591303747106976}
2022-12-31 15:32:20,655 INFO:     Found new best model at epoch 27
2022-12-31 15:32:20,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:20,656 INFO:     Epoch: 28
2022-12-31 15:32:22,270 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44510922729969027, 'Total loss': 0.44510922729969027} | train loss {'Reaction outcome loss': 0.35449140080476066, 'Total loss': 0.35449140080476066}
2022-12-31 15:32:22,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:22,271 INFO:     Epoch: 29
2022-12-31 15:32:23,872 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44659503599007927, 'Total loss': 0.44659503599007927} | train loss {'Reaction outcome loss': 0.34997116505346576, 'Total loss': 0.34997116505346576}
2022-12-31 15:32:23,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:23,872 INFO:     Epoch: 30
2022-12-31 15:32:25,505 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4412526885668437, 'Total loss': 0.4412526885668437} | train loss {'Reaction outcome loss': 0.3438330756681921, 'Total loss': 0.3438330756681921}
2022-12-31 15:32:25,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:25,506 INFO:     Epoch: 31
2022-12-31 15:32:27,115 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48069139420986173, 'Total loss': 0.48069139420986173} | train loss {'Reaction outcome loss': 0.3411127631199489, 'Total loss': 0.3411127631199489}
2022-12-31 15:32:27,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:27,116 INFO:     Epoch: 32
2022-12-31 15:32:28,717 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44442948351303735, 'Total loss': 0.44442948351303735} | train loss {'Reaction outcome loss': 0.32960780691153735, 'Total loss': 0.32960780691153735}
2022-12-31 15:32:28,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:28,718 INFO:     Epoch: 33
2022-12-31 15:32:30,332 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47880391975243886, 'Total loss': 0.47880391975243886} | train loss {'Reaction outcome loss': 0.33120317603814475, 'Total loss': 0.33120317603814475}
2022-12-31 15:32:30,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:30,332 INFO:     Epoch: 34
2022-12-31 15:32:31,947 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47885503868261975, 'Total loss': 0.47885503868261975} | train loss {'Reaction outcome loss': 0.3305227377246864, 'Total loss': 0.3305227377246864}
2022-12-31 15:32:31,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:31,948 INFO:     Epoch: 35
2022-12-31 15:32:33,547 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4666142791509628, 'Total loss': 0.4666142791509628} | train loss {'Reaction outcome loss': 0.3233210783626629, 'Total loss': 0.3233210783626629}
2022-12-31 15:32:33,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:33,547 INFO:     Epoch: 36
2022-12-31 15:32:35,163 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39905700931946436, 'Total loss': 0.39905700931946436} | train loss {'Reaction outcome loss': 0.31839837184989495, 'Total loss': 0.31839837184989495}
2022-12-31 15:32:35,163 INFO:     Found new best model at epoch 36
2022-12-31 15:32:35,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:35,164 INFO:     Epoch: 37
2022-12-31 15:32:36,776 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4130935003360113, 'Total loss': 0.4130935003360113} | train loss {'Reaction outcome loss': 0.31871593660180747, 'Total loss': 0.31871593660180747}
2022-12-31 15:32:36,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:36,776 INFO:     Epoch: 38
2022-12-31 15:32:38,428 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42816938857237496, 'Total loss': 0.42816938857237496} | train loss {'Reaction outcome loss': 0.3133730309534589, 'Total loss': 0.3133730309534589}
2022-12-31 15:32:38,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:38,428 INFO:     Epoch: 39
2022-12-31 15:32:40,092 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4664296607176463, 'Total loss': 0.4664296607176463} | train loss {'Reaction outcome loss': 0.3102156259926433, 'Total loss': 0.3102156259926433}
2022-12-31 15:32:40,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:40,092 INFO:     Epoch: 40
2022-12-31 15:32:41,724 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4200624366601308, 'Total loss': 0.4200624366601308} | train loss {'Reaction outcome loss': 0.3057299274883976, 'Total loss': 0.3057299274883976}
2022-12-31 15:32:41,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:41,725 INFO:     Epoch: 41
2022-12-31 15:32:43,363 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4293285111586253, 'Total loss': 0.4293285111586253} | train loss {'Reaction outcome loss': 0.3025261518690022, 'Total loss': 0.3025261518690022}
2022-12-31 15:32:43,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:43,363 INFO:     Epoch: 42
2022-12-31 15:32:45,008 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44311493734518687, 'Total loss': 0.44311493734518687} | train loss {'Reaction outcome loss': 0.2991485454357273, 'Total loss': 0.2991485454357273}
2022-12-31 15:32:45,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:45,008 INFO:     Epoch: 43
2022-12-31 15:32:46,606 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4664165596167246, 'Total loss': 0.4664165596167246} | train loss {'Reaction outcome loss': 0.2997354384417568, 'Total loss': 0.2997354384417568}
2022-12-31 15:32:46,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:46,606 INFO:     Epoch: 44
2022-12-31 15:32:48,236 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.432719819744428, 'Total loss': 0.432719819744428} | train loss {'Reaction outcome loss': 0.29409677433085357, 'Total loss': 0.29409677433085357}
2022-12-31 15:32:48,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:48,237 INFO:     Epoch: 45
2022-12-31 15:32:49,864 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4072028954823812, 'Total loss': 0.4072028954823812} | train loss {'Reaction outcome loss': 0.28949987940786115, 'Total loss': 0.28949987940786115}
2022-12-31 15:32:49,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:49,864 INFO:     Epoch: 46
2022-12-31 15:32:51,487 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42513533929983777, 'Total loss': 0.42513533929983777} | train loss {'Reaction outcome loss': 0.2818574895308982, 'Total loss': 0.2818574895308982}
2022-12-31 15:32:51,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:51,487 INFO:     Epoch: 47
2022-12-31 15:32:53,130 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4369802673657735, 'Total loss': 0.4369802673657735} | train loss {'Reaction outcome loss': 0.28420346982050887, 'Total loss': 0.28420346982050887}
2022-12-31 15:32:53,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:53,130 INFO:     Epoch: 48
2022-12-31 15:32:54,751 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44056960542996726, 'Total loss': 0.44056960542996726} | train loss {'Reaction outcome loss': 0.28161988831007523, 'Total loss': 0.28161988831007523}
2022-12-31 15:32:54,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:54,751 INFO:     Epoch: 49
2022-12-31 15:32:56,403 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4103848526875178, 'Total loss': 0.4103848526875178} | train loss {'Reaction outcome loss': 0.2803012541619664, 'Total loss': 0.2803012541619664}
2022-12-31 15:32:56,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:56,403 INFO:     Epoch: 50
2022-12-31 15:32:58,046 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43487925330797833, 'Total loss': 0.43487925330797833} | train loss {'Reaction outcome loss': 0.2714768542844251, 'Total loss': 0.2714768542844251}
2022-12-31 15:32:58,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:58,047 INFO:     Epoch: 51
2022-12-31 15:32:59,666 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43860841194788613, 'Total loss': 0.43860841194788613} | train loss {'Reaction outcome loss': 0.2808518852661986, 'Total loss': 0.2808518852661986}
2022-12-31 15:32:59,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:32:59,666 INFO:     Epoch: 52
2022-12-31 15:33:01,297 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4200280785560608, 'Total loss': 0.4200280785560608} | train loss {'Reaction outcome loss': 0.27927833401500535, 'Total loss': 0.27927833401500535}
2022-12-31 15:33:01,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:01,298 INFO:     Epoch: 53
2022-12-31 15:33:02,918 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47348879675070443, 'Total loss': 0.47348879675070443} | train loss {'Reaction outcome loss': 0.26625366693207936, 'Total loss': 0.26625366693207936}
2022-12-31 15:33:02,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:02,918 INFO:     Epoch: 54
2022-12-31 15:33:04,536 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40313485314448677, 'Total loss': 0.40313485314448677} | train loss {'Reaction outcome loss': 0.2700478937813091, 'Total loss': 0.2700478937813091}
2022-12-31 15:33:04,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:04,536 INFO:     Epoch: 55
2022-12-31 15:33:06,186 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4110345726211866, 'Total loss': 0.4110345726211866} | train loss {'Reaction outcome loss': 0.26600507446413435, 'Total loss': 0.26600507446413435}
2022-12-31 15:33:06,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:06,186 INFO:     Epoch: 56
2022-12-31 15:33:07,832 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4147659877936045, 'Total loss': 0.4147659877936045} | train loss {'Reaction outcome loss': 0.2675665609323376, 'Total loss': 0.2675665609323376}
2022-12-31 15:33:07,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:07,832 INFO:     Epoch: 57
2022-12-31 15:33:09,468 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44042738278706867, 'Total loss': 0.44042738278706867} | train loss {'Reaction outcome loss': 0.26687591081814643, 'Total loss': 0.26687591081814643}
2022-12-31 15:33:09,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:09,468 INFO:     Epoch: 58
2022-12-31 15:33:11,114 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4367642958958944, 'Total loss': 0.4367642958958944} | train loss {'Reaction outcome loss': 0.26296752348327035, 'Total loss': 0.26296752348327035}
2022-12-31 15:33:11,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:11,114 INFO:     Epoch: 59
2022-12-31 15:33:12,746 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4414026826620102, 'Total loss': 0.4414026826620102} | train loss {'Reaction outcome loss': 0.26202702637936665, 'Total loss': 0.26202702637936665}
2022-12-31 15:33:12,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:12,747 INFO:     Epoch: 60
2022-12-31 15:33:14,357 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4073674420515696, 'Total loss': 0.4073674420515696} | train loss {'Reaction outcome loss': 0.25695977600741904, 'Total loss': 0.25695977600741904}
2022-12-31 15:33:14,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:14,358 INFO:     Epoch: 61
2022-12-31 15:33:15,975 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.402066533267498, 'Total loss': 0.402066533267498} | train loss {'Reaction outcome loss': 0.26162902743216027, 'Total loss': 0.26162902743216027}
2022-12-31 15:33:15,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:15,975 INFO:     Epoch: 62
2022-12-31 15:33:17,605 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40503951609134675, 'Total loss': 0.40503951609134675} | train loss {'Reaction outcome loss': 0.25015075888067806, 'Total loss': 0.25015075888067806}
2022-12-31 15:33:17,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:17,605 INFO:     Epoch: 63
2022-12-31 15:33:19,224 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41087700774272284, 'Total loss': 0.41087700774272284} | train loss {'Reaction outcome loss': 0.25395361877413003, 'Total loss': 0.25395361877413003}
2022-12-31 15:33:19,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:19,224 INFO:     Epoch: 64
2022-12-31 15:33:20,872 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45026973684628807, 'Total loss': 0.45026973684628807} | train loss {'Reaction outcome loss': 0.2536195674440437, 'Total loss': 0.2536195674440437}
2022-12-31 15:33:20,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:20,872 INFO:     Epoch: 65
2022-12-31 15:33:22,491 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43227039476235707, 'Total loss': 0.43227039476235707} | train loss {'Reaction outcome loss': 0.2490121512152658, 'Total loss': 0.2490121512152658}
2022-12-31 15:33:22,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:22,491 INFO:     Epoch: 66
2022-12-31 15:33:24,120 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4437143266201019, 'Total loss': 0.4437143266201019} | train loss {'Reaction outcome loss': 0.24912385584699118, 'Total loss': 0.24912385584699118}
2022-12-31 15:33:24,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:24,120 INFO:     Epoch: 67
2022-12-31 15:33:25,735 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40592621515194577, 'Total loss': 0.40592621515194577} | train loss {'Reaction outcome loss': 0.2440545073095104, 'Total loss': 0.2440545073095104}
2022-12-31 15:33:25,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:25,736 INFO:     Epoch: 68
2022-12-31 15:33:27,335 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41609695851802825, 'Total loss': 0.41609695851802825} | train loss {'Reaction outcome loss': 0.2391892842114617, 'Total loss': 0.2391892842114617}
2022-12-31 15:33:27,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:27,335 INFO:     Epoch: 69
2022-12-31 15:33:28,950 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46268848776817323, 'Total loss': 0.46268848776817323} | train loss {'Reaction outcome loss': 0.24017641533314105, 'Total loss': 0.24017641533314105}
2022-12-31 15:33:28,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:28,950 INFO:     Epoch: 70
2022-12-31 15:33:30,575 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40823743542035423, 'Total loss': 0.40823743542035423} | train loss {'Reaction outcome loss': 0.24285640310670925, 'Total loss': 0.24285640310670925}
2022-12-31 15:33:30,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:30,575 INFO:     Epoch: 71
2022-12-31 15:33:32,184 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4354311486085256, 'Total loss': 0.4354311486085256} | train loss {'Reaction outcome loss': 0.2391672031247874, 'Total loss': 0.2391672031247874}
2022-12-31 15:33:32,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:32,185 INFO:     Epoch: 72
2022-12-31 15:33:33,799 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4497862160205841, 'Total loss': 0.4497862160205841} | train loss {'Reaction outcome loss': 0.23237059522245335, 'Total loss': 0.23237059522245335}
2022-12-31 15:33:33,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:33,799 INFO:     Epoch: 73
2022-12-31 15:33:35,414 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4768941968679428, 'Total loss': 0.4768941968679428} | train loss {'Reaction outcome loss': 0.23720659195220212, 'Total loss': 0.23720659195220212}
2022-12-31 15:33:35,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:35,414 INFO:     Epoch: 74
2022-12-31 15:33:37,009 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4230154345432917, 'Total loss': 0.4230154345432917} | train loss {'Reaction outcome loss': 0.23790554512655263, 'Total loss': 0.23790554512655263}
2022-12-31 15:33:37,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:37,010 INFO:     Epoch: 75
2022-12-31 15:33:38,623 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4896350860595703, 'Total loss': 0.4896350860595703} | train loss {'Reaction outcome loss': 0.23473912966353583, 'Total loss': 0.23473912966353583}
2022-12-31 15:33:38,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:38,624 INFO:     Epoch: 76
2022-12-31 15:33:40,222 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.407658189535141, 'Total loss': 0.407658189535141} | train loss {'Reaction outcome loss': 0.23424703266054714, 'Total loss': 0.23424703266054714}
2022-12-31 15:33:40,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:40,223 INFO:     Epoch: 77
2022-12-31 15:33:41,869 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42998815278212227, 'Total loss': 0.42998815278212227} | train loss {'Reaction outcome loss': 0.22910512180911505, 'Total loss': 0.22910512180911505}
2022-12-31 15:33:41,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:41,869 INFO:     Epoch: 78
2022-12-31 15:33:43,490 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4258771737416585, 'Total loss': 0.4258771737416585} | train loss {'Reaction outcome loss': 0.2266962224288107, 'Total loss': 0.2266962224288107}
2022-12-31 15:33:43,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:43,491 INFO:     Epoch: 79
2022-12-31 15:33:45,092 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4280490259329478, 'Total loss': 0.4280490259329478} | train loss {'Reaction outcome loss': 0.23406408123322342, 'Total loss': 0.23406408123322342}
2022-12-31 15:33:45,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:45,092 INFO:     Epoch: 80
2022-12-31 15:33:46,712 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42673284411430357, 'Total loss': 0.42673284411430357} | train loss {'Reaction outcome loss': 0.22684141330501664, 'Total loss': 0.22684141330501664}
2022-12-31 15:33:46,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:46,712 INFO:     Epoch: 81
2022-12-31 15:33:48,324 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4382192154725393, 'Total loss': 0.4382192154725393} | train loss {'Reaction outcome loss': 0.22635714136171642, 'Total loss': 0.22635714136171642}
2022-12-31 15:33:48,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:48,325 INFO:     Epoch: 82
2022-12-31 15:33:49,920 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44098525245984393, 'Total loss': 0.44098525245984393} | train loss {'Reaction outcome loss': 0.22547836101442467, 'Total loss': 0.22547836101442467}
2022-12-31 15:33:49,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:49,920 INFO:     Epoch: 83
2022-12-31 15:33:51,533 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46662788490454354, 'Total loss': 0.46662788490454354} | train loss {'Reaction outcome loss': 0.2281212862379284, 'Total loss': 0.2281212862379284}
2022-12-31 15:33:51,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:51,533 INFO:     Epoch: 84
2022-12-31 15:33:53,147 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4580284615357717, 'Total loss': 0.4580284615357717} | train loss {'Reaction outcome loss': 0.22559498090444918, 'Total loss': 0.22559498090444918}
2022-12-31 15:33:53,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:53,147 INFO:     Epoch: 85
2022-12-31 15:33:54,747 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4299656500418981, 'Total loss': 0.4299656500418981} | train loss {'Reaction outcome loss': 0.2160370507502814, 'Total loss': 0.2160370507502814}
2022-12-31 15:33:54,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:54,748 INFO:     Epoch: 86
2022-12-31 15:33:56,363 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4527986059586207, 'Total loss': 0.4527986059586207} | train loss {'Reaction outcome loss': 0.21848040308117436, 'Total loss': 0.21848040308117436}
2022-12-31 15:33:56,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:56,363 INFO:     Epoch: 87
2022-12-31 15:33:57,960 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44308928549289706, 'Total loss': 0.44308928549289706} | train loss {'Reaction outcome loss': 0.22431972320611834, 'Total loss': 0.22431972320611834}
2022-12-31 15:33:57,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:57,961 INFO:     Epoch: 88
2022-12-31 15:33:59,579 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40785730083783467, 'Total loss': 0.40785730083783467} | train loss {'Reaction outcome loss': 0.21385657223149973, 'Total loss': 0.21385657223149973}
2022-12-31 15:33:59,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:33:59,580 INFO:     Epoch: 89
2022-12-31 15:34:01,195 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46747025847435, 'Total loss': 0.46747025847435} | train loss {'Reaction outcome loss': 0.21776447765905718, 'Total loss': 0.21776447765905718}
2022-12-31 15:34:01,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:01,195 INFO:     Epoch: 90
2022-12-31 15:34:02,800 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40422435849905014, 'Total loss': 0.40422435849905014} | train loss {'Reaction outcome loss': 0.21070812811355513, 'Total loss': 0.21070812811355513}
2022-12-31 15:34:02,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:02,801 INFO:     Epoch: 91
2022-12-31 15:34:04,435 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40358259081840514, 'Total loss': 0.40358259081840514} | train loss {'Reaction outcome loss': 0.2237004407879893, 'Total loss': 0.2237004407879893}
2022-12-31 15:34:04,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:04,436 INFO:     Epoch: 92
2022-12-31 15:34:06,071 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4588789810736974, 'Total loss': 0.4588789810736974} | train loss {'Reaction outcome loss': 0.21255148241182095, 'Total loss': 0.21255148241182095}
2022-12-31 15:34:06,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:06,071 INFO:     Epoch: 93
2022-12-31 15:34:07,692 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4081050549944242, 'Total loss': 0.4081050549944242} | train loss {'Reaction outcome loss': 0.21123374398084968, 'Total loss': 0.21123374398084968}
2022-12-31 15:34:07,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:07,693 INFO:     Epoch: 94
2022-12-31 15:34:09,334 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42705922325452167, 'Total loss': 0.42705922325452167} | train loss {'Reaction outcome loss': 0.2149444726238612, 'Total loss': 0.2149444726238612}
2022-12-31 15:34:09,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:09,334 INFO:     Epoch: 95
2022-12-31 15:34:10,989 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4172023952007294, 'Total loss': 0.4172023952007294} | train loss {'Reaction outcome loss': 0.21746844926089157, 'Total loss': 0.21746844926089157}
2022-12-31 15:34:10,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:10,989 INFO:     Epoch: 96
2022-12-31 15:34:12,623 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41004556020100913, 'Total loss': 0.41004556020100913} | train loss {'Reaction outcome loss': 0.2091425613564059, 'Total loss': 0.2091425613564059}
2022-12-31 15:34:12,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:12,623 INFO:     Epoch: 97
2022-12-31 15:34:14,238 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4328263243039449, 'Total loss': 0.4328263243039449} | train loss {'Reaction outcome loss': 0.2081422459885532, 'Total loss': 0.2081422459885532}
2022-12-31 15:34:14,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:14,239 INFO:     Epoch: 98
2022-12-31 15:34:15,844 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42719269754985967, 'Total loss': 0.42719269754985967} | train loss {'Reaction outcome loss': 0.2068093557193176, 'Total loss': 0.2068093557193176}
2022-12-31 15:34:15,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:15,844 INFO:     Epoch: 99
2022-12-31 15:34:17,447 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4328454981247584, 'Total loss': 0.4328454981247584} | train loss {'Reaction outcome loss': 0.20505073919408157, 'Total loss': 0.20505073919408157}
2022-12-31 15:34:17,447 INFO:     Best model found after epoch 37 of 100.
2022-12-31 15:34:17,447 INFO:   Done with stage: TRAINING
2022-12-31 15:34:17,447 INFO:   Starting stage: EVALUATION
2022-12-31 15:34:17,569 INFO:   Done with stage: EVALUATION
2022-12-31 15:34:17,569 INFO:   Leaving out SEQ value Fold_5
2022-12-31 15:34:17,582 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 15:34:17,582 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:34:18,240 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:34:18,240 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:34:18,308 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:34:18,308 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:34:18,308 INFO:     No hyperparam tuning for this model
2022-12-31 15:34:18,308 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:34:18,308 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:34:18,309 INFO:     None feature selector for col prot
2022-12-31 15:34:18,309 INFO:     None feature selector for col prot
2022-12-31 15:34:18,309 INFO:     None feature selector for col prot
2022-12-31 15:34:18,310 INFO:     None feature selector for col chem
2022-12-31 15:34:18,310 INFO:     None feature selector for col chem
2022-12-31 15:34:18,310 INFO:     None feature selector for col chem
2022-12-31 15:34:18,310 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:34:18,310 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:34:18,312 INFO:     Number of params in model 223921
2022-12-31 15:34:18,315 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:34:18,315 INFO:   Starting stage: TRAINING
2022-12-31 15:34:18,361 INFO:     Val loss before train {'Reaction outcome loss': 0.8753021081288656, 'Total loss': 0.8753021081288656}
2022-12-31 15:34:18,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:18,361 INFO:     Epoch: 0
2022-12-31 15:34:19,957 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6306348065535228, 'Total loss': 0.6306348065535228} | train loss {'Reaction outcome loss': 0.8272479172170597, 'Total loss': 0.8272479172170597}
2022-12-31 15:34:19,957 INFO:     Found new best model at epoch 0
2022-12-31 15:34:19,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:19,958 INFO:     Epoch: 1
2022-12-31 15:34:21,548 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.501083759466807, 'Total loss': 0.501083759466807} | train loss {'Reaction outcome loss': 0.6089427110052457, 'Total loss': 0.6089427110052457}
2022-12-31 15:34:21,548 INFO:     Found new best model at epoch 1
2022-12-31 15:34:21,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:21,549 INFO:     Epoch: 2
2022-12-31 15:34:23,182 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5501316686471304, 'Total loss': 0.5501316686471304} | train loss {'Reaction outcome loss': 0.5330210489621998, 'Total loss': 0.5330210489621998}
2022-12-31 15:34:23,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:23,182 INFO:     Epoch: 3
2022-12-31 15:34:24,805 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48084919253985087, 'Total loss': 0.48084919253985087} | train loss {'Reaction outcome loss': 0.5091363740880994, 'Total loss': 0.5091363740880994}
2022-12-31 15:34:24,806 INFO:     Found new best model at epoch 3
2022-12-31 15:34:24,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:24,807 INFO:     Epoch: 4
2022-12-31 15:34:26,417 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.463033057252566, 'Total loss': 0.463033057252566} | train loss {'Reaction outcome loss': 0.4815058932796012, 'Total loss': 0.4815058932796012}
2022-12-31 15:34:26,417 INFO:     Found new best model at epoch 4
2022-12-31 15:34:26,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:26,418 INFO:     Epoch: 5
2022-12-31 15:34:28,029 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47712676028410594, 'Total loss': 0.47712676028410594} | train loss {'Reaction outcome loss': 0.47449833872544506, 'Total loss': 0.47449833872544506}
2022-12-31 15:34:28,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:28,029 INFO:     Epoch: 6
2022-12-31 15:34:29,657 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47482048769791924, 'Total loss': 0.47482048769791924} | train loss {'Reaction outcome loss': 0.4651876705950194, 'Total loss': 0.4651876705950194}
2022-12-31 15:34:29,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:29,657 INFO:     Epoch: 7
2022-12-31 15:34:31,270 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4407700538635254, 'Total loss': 0.4407700538635254} | train loss {'Reaction outcome loss': 0.4539026238133002, 'Total loss': 0.4539026238133002}
2022-12-31 15:34:31,271 INFO:     Found new best model at epoch 7
2022-12-31 15:34:31,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:31,272 INFO:     Epoch: 8
2022-12-31 15:34:32,901 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43779909213383994, 'Total loss': 0.43779909213383994} | train loss {'Reaction outcome loss': 0.44589506508442606, 'Total loss': 0.44589506508442606}
2022-12-31 15:34:32,901 INFO:     Found new best model at epoch 8
2022-12-31 15:34:32,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:32,902 INFO:     Epoch: 9
2022-12-31 15:34:34,512 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4075144370396932, 'Total loss': 0.4075144370396932} | train loss {'Reaction outcome loss': 0.44406507566680004, 'Total loss': 0.44406507566680004}
2022-12-31 15:34:34,513 INFO:     Found new best model at epoch 9
2022-12-31 15:34:34,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:34,514 INFO:     Epoch: 10
2022-12-31 15:34:36,125 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42239225407441455, 'Total loss': 0.42239225407441455} | train loss {'Reaction outcome loss': 0.4348589852996116, 'Total loss': 0.4348589852996116}
2022-12-31 15:34:36,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:36,125 INFO:     Epoch: 11
2022-12-31 15:34:37,732 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4291047950585683, 'Total loss': 0.4291047950585683} | train loss {'Reaction outcome loss': 0.4314248177365665, 'Total loss': 0.4314248177365665}
2022-12-31 15:34:37,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:37,732 INFO:     Epoch: 12
2022-12-31 15:34:39,317 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.423132069905599, 'Total loss': 0.423132069905599} | train loss {'Reaction outcome loss': 0.4283917546544197, 'Total loss': 0.4283917546544197}
2022-12-31 15:34:39,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:39,317 INFO:     Epoch: 13
2022-12-31 15:34:40,952 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4253324309984843, 'Total loss': 0.4253324309984843} | train loss {'Reaction outcome loss': 0.41365937301277245, 'Total loss': 0.41365937301277245}
2022-12-31 15:34:40,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:40,952 INFO:     Epoch: 14
2022-12-31 15:34:42,586 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4400439620018005, 'Total loss': 0.4400439620018005} | train loss {'Reaction outcome loss': 0.4108735881745815, 'Total loss': 0.4108735881745815}
2022-12-31 15:34:42,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:42,586 INFO:     Epoch: 15
2022-12-31 15:34:44,179 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3940263350804647, 'Total loss': 0.3940263350804647} | train loss {'Reaction outcome loss': 0.41053543169132983, 'Total loss': 0.41053543169132983}
2022-12-31 15:34:44,180 INFO:     Found new best model at epoch 15
2022-12-31 15:34:44,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:44,181 INFO:     Epoch: 16
2022-12-31 15:34:45,779 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42934833963712055, 'Total loss': 0.42934833963712055} | train loss {'Reaction outcome loss': 0.4083542933918699, 'Total loss': 0.4083542933918699}
2022-12-31 15:34:45,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:45,779 INFO:     Epoch: 17
2022-12-31 15:34:47,375 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4298106094201406, 'Total loss': 0.4298106094201406} | train loss {'Reaction outcome loss': 0.39598866590183146, 'Total loss': 0.39598866590183146}
2022-12-31 15:34:47,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:47,376 INFO:     Epoch: 18
2022-12-31 15:34:48,964 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4105233778556188, 'Total loss': 0.4105233778556188} | train loss {'Reaction outcome loss': 0.3948071685476895, 'Total loss': 0.3948071685476895}
2022-12-31 15:34:48,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:48,964 INFO:     Epoch: 19
2022-12-31 15:34:50,576 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42189662853876747, 'Total loss': 0.42189662853876747} | train loss {'Reaction outcome loss': 0.38610735821136594, 'Total loss': 0.38610735821136594}
2022-12-31 15:34:50,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:50,576 INFO:     Epoch: 20
2022-12-31 15:34:52,179 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3831724176804225, 'Total loss': 0.3831724176804225} | train loss {'Reaction outcome loss': 0.38096922932423816, 'Total loss': 0.38096922932423816}
2022-12-31 15:34:52,179 INFO:     Found new best model at epoch 20
2022-12-31 15:34:52,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:52,180 INFO:     Epoch: 21
2022-12-31 15:34:53,813 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.37653830808897815, 'Total loss': 0.37653830808897815} | train loss {'Reaction outcome loss': 0.3732561895447056, 'Total loss': 0.3732561895447056}
2022-12-31 15:34:53,813 INFO:     Found new best model at epoch 21
2022-12-31 15:34:53,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:53,814 INFO:     Epoch: 22
2022-12-31 15:34:55,423 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42737172345320384, 'Total loss': 0.42737172345320384} | train loss {'Reaction outcome loss': 0.373325616964241, 'Total loss': 0.373325616964241}
2022-12-31 15:34:55,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:55,423 INFO:     Epoch: 23
2022-12-31 15:34:57,064 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39671738147735597, 'Total loss': 0.39671738147735597} | train loss {'Reaction outcome loss': 0.36734526846421894, 'Total loss': 0.36734526846421894}
2022-12-31 15:34:57,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:57,065 INFO:     Epoch: 24
2022-12-31 15:34:58,660 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3998992790778478, 'Total loss': 0.3998992790778478} | train loss {'Reaction outcome loss': 0.36800327656423526, 'Total loss': 0.36800327656423526}
2022-12-31 15:34:58,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:34:58,661 INFO:     Epoch: 25
2022-12-31 15:35:00,276 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4037428438663483, 'Total loss': 0.4037428438663483} | train loss {'Reaction outcome loss': 0.3546675801766615, 'Total loss': 0.3546675801766615}
2022-12-31 15:35:00,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:00,278 INFO:     Epoch: 26
2022-12-31 15:35:01,885 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4203700363636017, 'Total loss': 0.4203700363636017} | train loss {'Reaction outcome loss': 0.3509708050312135, 'Total loss': 0.3509708050312135}
2022-12-31 15:35:01,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:01,886 INFO:     Epoch: 27
2022-12-31 15:35:03,510 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.373000505566597, 'Total loss': 0.373000505566597} | train loss {'Reaction outcome loss': 0.35058054450328335, 'Total loss': 0.35058054450328335}
2022-12-31 15:35:03,510 INFO:     Found new best model at epoch 27
2022-12-31 15:35:03,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:03,511 INFO:     Epoch: 28
2022-12-31 15:35:05,139 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3710596521695455, 'Total loss': 0.3710596521695455} | train loss {'Reaction outcome loss': 0.34304658973412794, 'Total loss': 0.34304658973412794}
2022-12-31 15:35:05,140 INFO:     Found new best model at epoch 28
2022-12-31 15:35:05,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:05,141 INFO:     Epoch: 29
2022-12-31 15:35:06,756 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4069480617841085, 'Total loss': 0.4069480617841085} | train loss {'Reaction outcome loss': 0.3321460745141019, 'Total loss': 0.3321460745141019}
2022-12-31 15:35:06,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:06,757 INFO:     Epoch: 30
2022-12-31 15:35:08,391 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3962644686301549, 'Total loss': 0.3962644686301549} | train loss {'Reaction outcome loss': 0.3312113039929719, 'Total loss': 0.3312113039929719}
2022-12-31 15:35:08,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:08,391 INFO:     Epoch: 31
2022-12-31 15:35:10,024 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4042501856883367, 'Total loss': 0.4042501856883367} | train loss {'Reaction outcome loss': 0.32645078018362067, 'Total loss': 0.32645078018362067}
2022-12-31 15:35:10,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:10,024 INFO:     Epoch: 32
2022-12-31 15:35:11,621 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3702181806166967, 'Total loss': 0.3702181806166967} | train loss {'Reaction outcome loss': 0.32332732686161125, 'Total loss': 0.32332732686161125}
2022-12-31 15:35:11,622 INFO:     Found new best model at epoch 32
2022-12-31 15:35:11,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:11,623 INFO:     Epoch: 33
2022-12-31 15:35:13,243 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40689309934775036, 'Total loss': 0.40689309934775036} | train loss {'Reaction outcome loss': 0.3158251855005748, 'Total loss': 0.3158251855005748}
2022-12-31 15:35:13,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:13,243 INFO:     Epoch: 34
2022-12-31 15:35:14,883 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37251558204491936, 'Total loss': 0.37251558204491936} | train loss {'Reaction outcome loss': 0.3150628238753246, 'Total loss': 0.3150628238753246}
2022-12-31 15:35:14,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:14,883 INFO:     Epoch: 35
2022-12-31 15:35:16,499 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41242399215698244, 'Total loss': 0.41242399215698244} | train loss {'Reaction outcome loss': 0.31382617876477487, 'Total loss': 0.31382617876477487}
2022-12-31 15:35:16,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:16,499 INFO:     Epoch: 36
2022-12-31 15:35:18,132 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4255151659250259, 'Total loss': 0.4255151659250259} | train loss {'Reaction outcome loss': 0.30447083222169946, 'Total loss': 0.30447083222169946}
2022-12-31 15:35:18,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:18,132 INFO:     Epoch: 37
2022-12-31 15:35:19,743 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40555172264575956, 'Total loss': 0.40555172264575956} | train loss {'Reaction outcome loss': 0.30633581291041234, 'Total loss': 0.30633581291041234}
2022-12-31 15:35:19,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:19,743 INFO:     Epoch: 38
2022-12-31 15:35:21,357 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3704147458076477, 'Total loss': 0.3704147458076477} | train loss {'Reaction outcome loss': 0.29961829945227525, 'Total loss': 0.29961829945227525}
2022-12-31 15:35:21,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:21,357 INFO:     Epoch: 39
2022-12-31 15:35:23,003 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.35941211357712743, 'Total loss': 0.35941211357712743} | train loss {'Reaction outcome loss': 0.29924705767337856, 'Total loss': 0.29924705767337856}
2022-12-31 15:35:23,003 INFO:     Found new best model at epoch 39
2022-12-31 15:35:23,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:23,004 INFO:     Epoch: 40
2022-12-31 15:35:24,634 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38204565991957984, 'Total loss': 0.38204565991957984} | train loss {'Reaction outcome loss': 0.2919707796026538, 'Total loss': 0.2919707796026538}
2022-12-31 15:35:24,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:24,634 INFO:     Epoch: 41
2022-12-31 15:35:26,226 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4530090848604838, 'Total loss': 0.4530090848604838} | train loss {'Reaction outcome loss': 0.2855358624110257, 'Total loss': 0.2855358624110257}
2022-12-31 15:35:26,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:26,226 INFO:     Epoch: 42
2022-12-31 15:35:27,841 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3598412682612737, 'Total loss': 0.3598412682612737} | train loss {'Reaction outcome loss': 0.28615652869054437, 'Total loss': 0.28615652869054437}
2022-12-31 15:35:27,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:27,841 INFO:     Epoch: 43
2022-12-31 15:35:29,457 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42546758353710173, 'Total loss': 0.42546758353710173} | train loss {'Reaction outcome loss': 0.28068064771810153, 'Total loss': 0.28068064771810153}
2022-12-31 15:35:29,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:29,457 INFO:     Epoch: 44
2022-12-31 15:35:31,100 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3658593624830246, 'Total loss': 0.3658593624830246} | train loss {'Reaction outcome loss': 0.2750465007648416, 'Total loss': 0.2750465007648416}
2022-12-31 15:35:31,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:31,100 INFO:     Epoch: 45
2022-12-31 15:35:32,731 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.36622251371542613, 'Total loss': 0.36622251371542613} | train loss {'Reaction outcome loss': 0.2799704801427187, 'Total loss': 0.2799704801427187}
2022-12-31 15:35:32,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:32,731 INFO:     Epoch: 46
2022-12-31 15:35:34,324 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3995495150486628, 'Total loss': 0.3995495150486628} | train loss {'Reaction outcome loss': 0.2730656214004015, 'Total loss': 0.2730656214004015}
2022-12-31 15:35:34,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:34,324 INFO:     Epoch: 47
2022-12-31 15:35:35,954 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.35957897305488584, 'Total loss': 0.35957897305488584} | train loss {'Reaction outcome loss': 0.2702456548891581, 'Total loss': 0.2702456548891581}
2022-12-31 15:35:35,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:35,955 INFO:     Epoch: 48
2022-12-31 15:35:37,580 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39797203093767164, 'Total loss': 0.39797203093767164} | train loss {'Reaction outcome loss': 0.2644099495951494, 'Total loss': 0.2644099495951494}
2022-12-31 15:35:37,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:37,580 INFO:     Epoch: 49
2022-12-31 15:35:39,194 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3885306586821874, 'Total loss': 0.3885306586821874} | train loss {'Reaction outcome loss': 0.2742169248144122, 'Total loss': 0.2742169248144122}
2022-12-31 15:35:39,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:39,194 INFO:     Epoch: 50
2022-12-31 15:35:40,817 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39419396221637726, 'Total loss': 0.39419396221637726} | train loss {'Reaction outcome loss': 0.26114693804759614, 'Total loss': 0.26114693804759614}
2022-12-31 15:35:40,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:40,817 INFO:     Epoch: 51
2022-12-31 15:35:42,417 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.38686164766550063, 'Total loss': 0.38686164766550063} | train loss {'Reaction outcome loss': 0.26054190981616504, 'Total loss': 0.26054190981616504}
2022-12-31 15:35:42,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:42,418 INFO:     Epoch: 52
2022-12-31 15:35:44,010 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3830275038878123, 'Total loss': 0.3830275038878123} | train loss {'Reaction outcome loss': 0.25516663858816574, 'Total loss': 0.25516663858816574}
2022-12-31 15:35:44,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:44,010 INFO:     Epoch: 53
2022-12-31 15:35:45,609 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4173476795355479, 'Total loss': 0.4173476795355479} | train loss {'Reaction outcome loss': 0.26418212844725075, 'Total loss': 0.26418212844725075}
2022-12-31 15:35:45,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:45,609 INFO:     Epoch: 54
2022-12-31 15:35:47,202 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44617321888605754, 'Total loss': 0.44617321888605754} | train loss {'Reaction outcome loss': 0.2518661420003776, 'Total loss': 0.2518661420003776}
2022-12-31 15:35:47,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:47,202 INFO:     Epoch: 55
2022-12-31 15:35:48,800 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38633738458156586, 'Total loss': 0.38633738458156586} | train loss {'Reaction outcome loss': 0.2522692615234286, 'Total loss': 0.2522692615234286}
2022-12-31 15:35:48,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:48,800 INFO:     Epoch: 56
2022-12-31 15:35:50,417 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4091590444246928, 'Total loss': 0.4091590444246928} | train loss {'Reaction outcome loss': 0.2571819028579188, 'Total loss': 0.2571819028579188}
2022-12-31 15:35:50,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:50,418 INFO:     Epoch: 57
2022-12-31 15:35:52,032 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40517583191394807, 'Total loss': 0.40517583191394807} | train loss {'Reaction outcome loss': 0.25038350073036053, 'Total loss': 0.25038350073036053}
2022-12-31 15:35:52,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:52,032 INFO:     Epoch: 58
2022-12-31 15:35:53,641 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3977176010608673, 'Total loss': 0.3977176010608673} | train loss {'Reaction outcome loss': 0.24429667326383783, 'Total loss': 0.24429667326383783}
2022-12-31 15:35:53,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:53,641 INFO:     Epoch: 59
2022-12-31 15:35:55,243 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.418916118144989, 'Total loss': 0.418916118144989} | train loss {'Reaction outcome loss': 0.2472533246869371, 'Total loss': 0.2472533246869371}
2022-12-31 15:35:55,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:55,244 INFO:     Epoch: 60
2022-12-31 15:35:56,829 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41751842002073924, 'Total loss': 0.41751842002073924} | train loss {'Reaction outcome loss': 0.23968958645297664, 'Total loss': 0.23968958645297664}
2022-12-31 15:35:56,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:56,829 INFO:     Epoch: 61
2022-12-31 15:35:58,438 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40160074830055237, 'Total loss': 0.40160074830055237} | train loss {'Reaction outcome loss': 0.24438101071592447, 'Total loss': 0.24438101071592447}
2022-12-31 15:35:58,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:35:58,438 INFO:     Epoch: 62
2022-12-31 15:36:00,070 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40099598169326783, 'Total loss': 0.40099598169326783} | train loss {'Reaction outcome loss': 0.24592630824849118, 'Total loss': 0.24592630824849118}
2022-12-31 15:36:00,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:00,070 INFO:     Epoch: 63
2022-12-31 15:36:01,667 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38550374110539753, 'Total loss': 0.38550374110539753} | train loss {'Reaction outcome loss': 0.23679893140266411, 'Total loss': 0.23679893140266411}
2022-12-31 15:36:01,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:01,667 INFO:     Epoch: 64
2022-12-31 15:36:03,294 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3871851881345113, 'Total loss': 0.3871851881345113} | train loss {'Reaction outcome loss': 0.2460865861783824, 'Total loss': 0.2460865861783824}
2022-12-31 15:36:03,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:03,295 INFO:     Epoch: 65
2022-12-31 15:36:04,931 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4090088834365209, 'Total loss': 0.4090088834365209} | train loss {'Reaction outcome loss': 0.23131552329082994, 'Total loss': 0.23131552329082994}
2022-12-31 15:36:04,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:04,931 INFO:     Epoch: 66
2022-12-31 15:36:06,532 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42697964509328207, 'Total loss': 0.42697964509328207} | train loss {'Reaction outcome loss': 0.23329361728018652, 'Total loss': 0.23329361728018652}
2022-12-31 15:36:06,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:06,532 INFO:     Epoch: 67
2022-12-31 15:36:08,153 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40796518325805664, 'Total loss': 0.40796518325805664} | train loss {'Reaction outcome loss': 0.22863790988378282, 'Total loss': 0.22863790988378282}
2022-12-31 15:36:08,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:08,154 INFO:     Epoch: 68
2022-12-31 15:36:09,759 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3770050793886185, 'Total loss': 0.3770050793886185} | train loss {'Reaction outcome loss': 0.23492768228761035, 'Total loss': 0.23492768228761035}
2022-12-31 15:36:09,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:09,759 INFO:     Epoch: 69
2022-12-31 15:36:11,367 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4049370211859544, 'Total loss': 0.4049370211859544} | train loss {'Reaction outcome loss': 0.2232489002066372, 'Total loss': 0.2232489002066372}
2022-12-31 15:36:11,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:11,368 INFO:     Epoch: 70
2022-12-31 15:36:13,006 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4014352262020111, 'Total loss': 0.4014352262020111} | train loss {'Reaction outcome loss': 0.22387631177684686, 'Total loss': 0.22387631177684686}
2022-12-31 15:36:13,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:13,006 INFO:     Epoch: 71
2022-12-31 15:36:14,614 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4043680558602015, 'Total loss': 0.4043680558602015} | train loss {'Reaction outcome loss': 0.22917994453714494, 'Total loss': 0.22917994453714494}
2022-12-31 15:36:14,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:14,615 INFO:     Epoch: 72
2022-12-31 15:36:16,243 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3817735460897287, 'Total loss': 0.3817735460897287} | train loss {'Reaction outcome loss': 0.22746816352281693, 'Total loss': 0.22746816352281693}
2022-12-31 15:36:16,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:16,243 INFO:     Epoch: 73
2022-12-31 15:36:17,846 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3739259141186873, 'Total loss': 0.3739259141186873} | train loss {'Reaction outcome loss': 0.21838468386635293, 'Total loss': 0.21838468386635293}
2022-12-31 15:36:17,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:17,847 INFO:     Epoch: 74
2022-12-31 15:36:19,450 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41889597723881405, 'Total loss': 0.41889597723881405} | train loss {'Reaction outcome loss': 0.22044349189195103, 'Total loss': 0.22044349189195103}
2022-12-31 15:36:19,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:19,451 INFO:     Epoch: 75
2022-12-31 15:36:21,070 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48412773907184603, 'Total loss': 0.48412773907184603} | train loss {'Reaction outcome loss': 0.21857144693796435, 'Total loss': 0.21857144693796435}
2022-12-31 15:36:21,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:21,071 INFO:     Epoch: 76
2022-12-31 15:36:22,685 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3770852675040563, 'Total loss': 0.3770852675040563} | train loss {'Reaction outcome loss': 0.21649637974689911, 'Total loss': 0.21649637974689911}
2022-12-31 15:36:22,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:22,685 INFO:     Epoch: 77
2022-12-31 15:36:24,279 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3266385237375895, 'Total loss': 0.3266385237375895} | train loss {'Reaction outcome loss': 0.21993934373323717, 'Total loss': 0.21993934373323717}
2022-12-31 15:36:24,279 INFO:     Found new best model at epoch 77
2022-12-31 15:36:24,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:24,280 INFO:     Epoch: 78
2022-12-31 15:36:25,856 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.36138505935668946, 'Total loss': 0.36138505935668946} | train loss {'Reaction outcome loss': 0.22067666192450663, 'Total loss': 0.22067666192450663}
2022-12-31 15:36:25,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:25,856 INFO:     Epoch: 79
2022-12-31 15:36:27,452 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38731804887453714, 'Total loss': 0.38731804887453714} | train loss {'Reaction outcome loss': 0.21583476719738792, 'Total loss': 0.21583476719738792}
2022-12-31 15:36:27,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:27,452 INFO:     Epoch: 80
2022-12-31 15:36:29,061 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3499896764755249, 'Total loss': 0.3499896764755249} | train loss {'Reaction outcome loss': 0.21595447264734086, 'Total loss': 0.21595447264734086}
2022-12-31 15:36:29,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:29,062 INFO:     Epoch: 81
2022-12-31 15:36:30,658 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.343015601982673, 'Total loss': 0.343015601982673} | train loss {'Reaction outcome loss': 0.21740492058061336, 'Total loss': 0.21740492058061336}
2022-12-31 15:36:30,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:30,659 INFO:     Epoch: 82
2022-12-31 15:36:32,270 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42153154611587523, 'Total loss': 0.42153154611587523} | train loss {'Reaction outcome loss': 0.2154880758429313, 'Total loss': 0.2154880758429313}
2022-12-31 15:36:32,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:32,271 INFO:     Epoch: 83
2022-12-31 15:36:33,860 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.33881162603696185, 'Total loss': 0.33881162603696185} | train loss {'Reaction outcome loss': 0.21542775467799527, 'Total loss': 0.21542775467799527}
2022-12-31 15:36:33,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:33,860 INFO:     Epoch: 84
2022-12-31 15:36:35,476 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38338647174338497, 'Total loss': 0.38338647174338497} | train loss {'Reaction outcome loss': 0.21763079581496708, 'Total loss': 0.21763079581496708}
2022-12-31 15:36:35,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:35,476 INFO:     Epoch: 85
2022-12-31 15:36:37,087 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3906409313281377, 'Total loss': 0.3906409313281377} | train loss {'Reaction outcome loss': 0.21038088937337598, 'Total loss': 0.21038088937337598}
2022-12-31 15:36:37,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:37,087 INFO:     Epoch: 86
2022-12-31 15:36:38,678 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.35157010654608406, 'Total loss': 0.35157010654608406} | train loss {'Reaction outcome loss': 0.20561279215081765, 'Total loss': 0.20561279215081765}
2022-12-31 15:36:38,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:38,679 INFO:     Epoch: 87
2022-12-31 15:36:40,295 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.36965065052111945, 'Total loss': 0.36965065052111945} | train loss {'Reaction outcome loss': 0.20636637589085277, 'Total loss': 0.20636637589085277}
2022-12-31 15:36:40,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:40,295 INFO:     Epoch: 88
2022-12-31 15:36:41,880 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4104888091484706, 'Total loss': 0.4104888091484706} | train loss {'Reaction outcome loss': 0.20371105158905478, 'Total loss': 0.20371105158905478}
2022-12-31 15:36:41,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:41,882 INFO:     Epoch: 89
2022-12-31 15:36:43,479 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40946166416009266, 'Total loss': 0.40946166416009266} | train loss {'Reaction outcome loss': 0.21051174080692722, 'Total loss': 0.21051174080692722}
2022-12-31 15:36:43,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:43,479 INFO:     Epoch: 90
2022-12-31 15:36:45,072 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4425369183222453, 'Total loss': 0.4425369183222453} | train loss {'Reaction outcome loss': 0.20349872224440757, 'Total loss': 0.20349872224440757}
2022-12-31 15:36:45,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:45,073 INFO:     Epoch: 91
2022-12-31 15:36:46,668 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38310364286104837, 'Total loss': 0.38310364286104837} | train loss {'Reaction outcome loss': 0.21274303054151528, 'Total loss': 0.21274303054151528}
2022-12-31 15:36:46,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:46,668 INFO:     Epoch: 92
2022-12-31 15:36:48,283 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3712025426328182, 'Total loss': 0.3712025426328182} | train loss {'Reaction outcome loss': 0.20907045865472215, 'Total loss': 0.20907045865472215}
2022-12-31 15:36:48,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:48,283 INFO:     Epoch: 93
2022-12-31 15:36:49,881 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39841612974802654, 'Total loss': 0.39841612974802654} | train loss {'Reaction outcome loss': 0.20002620389181985, 'Total loss': 0.20002620389181985}
2022-12-31 15:36:49,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:49,881 INFO:     Epoch: 94
2022-12-31 15:36:51,474 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44069098283847175, 'Total loss': 0.44069098283847175} | train loss {'Reaction outcome loss': 0.19869097237250882, 'Total loss': 0.19869097237250882}
2022-12-31 15:36:51,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:51,475 INFO:     Epoch: 95
2022-12-31 15:36:53,115 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38383875638246534, 'Total loss': 0.38383875638246534} | train loss {'Reaction outcome loss': 0.2012615732909826, 'Total loss': 0.2012615732909826}
2022-12-31 15:36:53,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:53,115 INFO:     Epoch: 96
2022-12-31 15:36:54,747 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39188835869232813, 'Total loss': 0.39188835869232813} | train loss {'Reaction outcome loss': 0.20379421206014434, 'Total loss': 0.20379421206014434}
2022-12-31 15:36:54,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:54,747 INFO:     Epoch: 97
2022-12-31 15:36:56,340 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38737307290236156, 'Total loss': 0.38737307290236156} | train loss {'Reaction outcome loss': 0.19335227875705183, 'Total loss': 0.19335227875705183}
2022-12-31 15:36:56,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:56,340 INFO:     Epoch: 98
2022-12-31 15:36:57,934 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44923145075639087, 'Total loss': 0.44923145075639087} | train loss {'Reaction outcome loss': 0.1960271217717524, 'Total loss': 0.1960271217717524}
2022-12-31 15:36:57,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:36:57,935 INFO:     Epoch: 99
2022-12-31 15:36:59,521 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40217316846052803, 'Total loss': 0.40217316846052803} | train loss {'Reaction outcome loss': 0.18939264850813325, 'Total loss': 0.18939264850813325}
2022-12-31 15:36:59,521 INFO:     Best model found after epoch 78 of 100.
2022-12-31 15:36:59,521 INFO:   Done with stage: TRAINING
2022-12-31 15:36:59,521 INFO:   Starting stage: EVALUATION
2022-12-31 15:36:59,655 INFO:   Done with stage: EVALUATION
2022-12-31 15:36:59,655 INFO:   Leaving out SEQ value Fold_6
2022-12-31 15:36:59,668 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 15:36:59,668 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:37:00,329 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:37:00,330 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:37:00,398 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:37:00,398 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:37:00,398 INFO:     No hyperparam tuning for this model
2022-12-31 15:37:00,398 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:37:00,398 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:37:00,399 INFO:     None feature selector for col prot
2022-12-31 15:37:00,399 INFO:     None feature selector for col prot
2022-12-31 15:37:00,399 INFO:     None feature selector for col prot
2022-12-31 15:37:00,400 INFO:     None feature selector for col chem
2022-12-31 15:37:00,400 INFO:     None feature selector for col chem
2022-12-31 15:37:00,400 INFO:     None feature selector for col chem
2022-12-31 15:37:00,400 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:37:00,400 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:37:00,402 INFO:     Number of params in model 223921
2022-12-31 15:37:00,405 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:37:00,405 INFO:   Starting stage: TRAINING
2022-12-31 15:37:00,449 INFO:     Val loss before train {'Reaction outcome loss': 1.1085497260093689, 'Total loss': 1.1085497260093689}
2022-12-31 15:37:00,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:00,450 INFO:     Epoch: 0
2022-12-31 15:37:02,057 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7435261805852255, 'Total loss': 0.7435261805852255} | train loss {'Reaction outcome loss': 0.8044891619420313, 'Total loss': 0.8044891619420313}
2022-12-31 15:37:02,057 INFO:     Found new best model at epoch 0
2022-12-31 15:37:02,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:02,058 INFO:     Epoch: 1
2022-12-31 15:37:03,683 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6356093486150106, 'Total loss': 0.6356093486150106} | train loss {'Reaction outcome loss': 0.5877552295560802, 'Total loss': 0.5877552295560802}
2022-12-31 15:37:03,683 INFO:     Found new best model at epoch 1
2022-12-31 15:37:03,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:03,684 INFO:     Epoch: 2
2022-12-31 15:37:05,281 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5946742475032807, 'Total loss': 0.5946742475032807} | train loss {'Reaction outcome loss': 0.5292458321366992, 'Total loss': 0.5292458321366992}
2022-12-31 15:37:05,281 INFO:     Found new best model at epoch 2
2022-12-31 15:37:05,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:05,282 INFO:     Epoch: 3
2022-12-31 15:37:06,875 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5940761685371398, 'Total loss': 0.5940761685371398} | train loss {'Reaction outcome loss': 0.5055606122855302, 'Total loss': 0.5055606122855302}
2022-12-31 15:37:06,875 INFO:     Found new best model at epoch 3
2022-12-31 15:37:06,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:06,876 INFO:     Epoch: 4
2022-12-31 15:37:08,461 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5724147995313008, 'Total loss': 0.5724147995313008} | train loss {'Reaction outcome loss': 0.4939682740213234, 'Total loss': 0.4939682740213234}
2022-12-31 15:37:08,461 INFO:     Found new best model at epoch 4
2022-12-31 15:37:08,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:08,462 INFO:     Epoch: 5
2022-12-31 15:37:10,046 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5903147081534068, 'Total loss': 0.5903147081534068} | train loss {'Reaction outcome loss': 0.48125311039087976, 'Total loss': 0.48125311039087976}
2022-12-31 15:37:10,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:10,046 INFO:     Epoch: 6
2022-12-31 15:37:11,666 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.506480872631073, 'Total loss': 0.506480872631073} | train loss {'Reaction outcome loss': 0.46717883209824124, 'Total loss': 0.46717883209824124}
2022-12-31 15:37:11,666 INFO:     Found new best model at epoch 6
2022-12-31 15:37:11,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:11,667 INFO:     Epoch: 7
2022-12-31 15:37:13,242 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5785062352816264, 'Total loss': 0.5785062352816264} | train loss {'Reaction outcome loss': 0.4625197999424987, 'Total loss': 0.4625197999424987}
2022-12-31 15:37:13,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:13,244 INFO:     Epoch: 8
2022-12-31 15:37:14,820 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5428573886553446, 'Total loss': 0.5428573886553446} | train loss {'Reaction outcome loss': 0.45233649497292255, 'Total loss': 0.45233649497292255}
2022-12-31 15:37:14,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:14,820 INFO:     Epoch: 9
2022-12-31 15:37:16,440 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.580582865079244, 'Total loss': 0.580582865079244} | train loss {'Reaction outcome loss': 0.44815382001164195, 'Total loss': 0.44815382001164195}
2022-12-31 15:37:16,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:16,440 INFO:     Epoch: 10
2022-12-31 15:37:18,026 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5222387125094732, 'Total loss': 0.5222387125094732} | train loss {'Reaction outcome loss': 0.43841448243393566, 'Total loss': 0.43841448243393566}
2022-12-31 15:37:18,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:18,026 INFO:     Epoch: 11
2022-12-31 15:37:19,613 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.522491576274236, 'Total loss': 0.522491576274236} | train loss {'Reaction outcome loss': 0.43670480046080146, 'Total loss': 0.43670480046080146}
2022-12-31 15:37:19,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:19,614 INFO:     Epoch: 12
2022-12-31 15:37:21,198 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5123378098011017, 'Total loss': 0.5123378098011017} | train loss {'Reaction outcome loss': 0.43208216911270503, 'Total loss': 0.43208216911270503}
2022-12-31 15:37:21,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:21,198 INFO:     Epoch: 13
2022-12-31 15:37:22,773 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5267763614654541, 'Total loss': 0.5267763614654541} | train loss {'Reaction outcome loss': 0.42373388691808717, 'Total loss': 0.42373388691808717}
2022-12-31 15:37:22,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:22,773 INFO:     Epoch: 14
2022-12-31 15:37:24,361 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5003558019797008, 'Total loss': 0.5003558019797008} | train loss {'Reaction outcome loss': 0.41631863934871477, 'Total loss': 0.41631863934871477}
2022-12-31 15:37:24,361 INFO:     Found new best model at epoch 14
2022-12-31 15:37:24,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:24,362 INFO:     Epoch: 15
2022-12-31 15:37:25,949 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4870019425948461, 'Total loss': 0.4870019425948461} | train loss {'Reaction outcome loss': 0.41018057947521247, 'Total loss': 0.41018057947521247}
2022-12-31 15:37:25,949 INFO:     Found new best model at epoch 15
2022-12-31 15:37:25,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:25,950 INFO:     Epoch: 16
2022-12-31 15:37:27,521 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5058577090501786, 'Total loss': 0.5058577090501786} | train loss {'Reaction outcome loss': 0.40732226651775966, 'Total loss': 0.40732226651775966}
2022-12-31 15:37:27,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:27,521 INFO:     Epoch: 17
2022-12-31 15:37:29,108 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49264099150896073, 'Total loss': 0.49264099150896073} | train loss {'Reaction outcome loss': 0.40429859987763694, 'Total loss': 0.40429859987763694}
2022-12-31 15:37:29,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:29,108 INFO:     Epoch: 18
2022-12-31 15:37:30,717 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4869919409354528, 'Total loss': 0.4869919409354528} | train loss {'Reaction outcome loss': 0.39277276121107213, 'Total loss': 0.39277276121107213}
2022-12-31 15:37:30,717 INFO:     Found new best model at epoch 18
2022-12-31 15:37:30,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:30,718 INFO:     Epoch: 19
2022-12-31 15:37:32,302 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5318836520115534, 'Total loss': 0.5318836520115534} | train loss {'Reaction outcome loss': 0.39326268625565064, 'Total loss': 0.39326268625565064}
2022-12-31 15:37:32,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:32,303 INFO:     Epoch: 20
2022-12-31 15:37:33,890 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4839142103989919, 'Total loss': 0.4839142103989919} | train loss {'Reaction outcome loss': 0.38712240504476175, 'Total loss': 0.38712240504476175}
2022-12-31 15:37:33,890 INFO:     Found new best model at epoch 20
2022-12-31 15:37:33,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:33,891 INFO:     Epoch: 21
2022-12-31 15:37:35,459 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5347712328036626, 'Total loss': 0.5347712328036626} | train loss {'Reaction outcome loss': 0.38316437490147986, 'Total loss': 0.38316437490147986}
2022-12-31 15:37:35,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:35,459 INFO:     Epoch: 22
2022-12-31 15:37:37,086 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5097442249457041, 'Total loss': 0.5097442249457041} | train loss {'Reaction outcome loss': 0.37374555401422166, 'Total loss': 0.37374555401422166}
2022-12-31 15:37:37,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:37,086 INFO:     Epoch: 23
2022-12-31 15:37:38,713 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.49322826067606607, 'Total loss': 0.49322826067606607} | train loss {'Reaction outcome loss': 0.3679423609905409, 'Total loss': 0.3679423609905409}
2022-12-31 15:37:38,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:38,714 INFO:     Epoch: 24
2022-12-31 15:37:40,323 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4871824940045675, 'Total loss': 0.4871824940045675} | train loss {'Reaction outcome loss': 0.36297547023047455, 'Total loss': 0.36297547023047455}
2022-12-31 15:37:40,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:40,323 INFO:     Epoch: 25
2022-12-31 15:37:41,958 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49637928207715354, 'Total loss': 0.49637928207715354} | train loss {'Reaction outcome loss': 0.3579481847775288, 'Total loss': 0.3579481847775288}
2022-12-31 15:37:41,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:41,959 INFO:     Epoch: 26
2022-12-31 15:37:43,574 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4875669072071711, 'Total loss': 0.4875669072071711} | train loss {'Reaction outcome loss': 0.35182301401273236, 'Total loss': 0.35182301401273236}
2022-12-31 15:37:43,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:43,574 INFO:     Epoch: 27
2022-12-31 15:37:45,176 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5400586406389872, 'Total loss': 0.5400586406389872} | train loss {'Reaction outcome loss': 0.3471969563732326, 'Total loss': 0.3471969563732326}
2022-12-31 15:37:45,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:45,176 INFO:     Epoch: 28
2022-12-31 15:37:46,769 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5158637503782908, 'Total loss': 0.5158637503782908} | train loss {'Reaction outcome loss': 0.3418598180780044, 'Total loss': 0.3418598180780044}
2022-12-31 15:37:46,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:46,769 INFO:     Epoch: 29
2022-12-31 15:37:48,385 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49063843687375386, 'Total loss': 0.49063843687375386} | train loss {'Reaction outcome loss': 0.33878948239288925, 'Total loss': 0.33878948239288925}
2022-12-31 15:37:48,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:48,387 INFO:     Epoch: 30
2022-12-31 15:37:49,984 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5019246985514959, 'Total loss': 0.5019246985514959} | train loss {'Reaction outcome loss': 0.33473132768366143, 'Total loss': 0.33473132768366143}
2022-12-31 15:37:49,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:49,984 INFO:     Epoch: 31
2022-12-31 15:37:51,594 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4685189247131348, 'Total loss': 0.4685189247131348} | train loss {'Reaction outcome loss': 0.33801401076299364, 'Total loss': 0.33801401076299364}
2022-12-31 15:37:51,594 INFO:     Found new best model at epoch 31
2022-12-31 15:37:51,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:51,595 INFO:     Epoch: 32
2022-12-31 15:37:53,203 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49351222316424054, 'Total loss': 0.49351222316424054} | train loss {'Reaction outcome loss': 0.32905067841866953, 'Total loss': 0.32905067841866953}
2022-12-31 15:37:53,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:53,204 INFO:     Epoch: 33
2022-12-31 15:37:54,816 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5241909523804983, 'Total loss': 0.5241909523804983} | train loss {'Reaction outcome loss': 0.32858281287845675, 'Total loss': 0.32858281287845675}
2022-12-31 15:37:54,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:54,817 INFO:     Epoch: 34
2022-12-31 15:37:56,431 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47198108832041424, 'Total loss': 0.47198108832041424} | train loss {'Reaction outcome loss': 0.31822695228315534, 'Total loss': 0.31822695228315534}
2022-12-31 15:37:56,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:56,432 INFO:     Epoch: 35
2022-12-31 15:37:58,017 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49465592006842296, 'Total loss': 0.49465592006842296} | train loss {'Reaction outcome loss': 0.3183957944204519, 'Total loss': 0.3183957944204519}
2022-12-31 15:37:58,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:58,017 INFO:     Epoch: 36
2022-12-31 15:37:59,597 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5102829078833262, 'Total loss': 0.5102829078833262} | train loss {'Reaction outcome loss': 0.31406550578800313, 'Total loss': 0.31406550578800313}
2022-12-31 15:37:59,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:37:59,597 INFO:     Epoch: 37
2022-12-31 15:38:01,189 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5092416028181712, 'Total loss': 0.5092416028181712} | train loss {'Reaction outcome loss': 0.3064536513426365, 'Total loss': 0.3064536513426365}
2022-12-31 15:38:01,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:01,189 INFO:     Epoch: 38
2022-12-31 15:38:02,764 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5097782393296559, 'Total loss': 0.5097782393296559} | train loss {'Reaction outcome loss': 0.30187499547725194, 'Total loss': 0.30187499547725194}
2022-12-31 15:38:02,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:02,765 INFO:     Epoch: 39
2022-12-31 15:38:04,375 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.467346461613973, 'Total loss': 0.467346461613973} | train loss {'Reaction outcome loss': 0.2968457524320145, 'Total loss': 0.2968457524320145}
2022-12-31 15:38:04,375 INFO:     Found new best model at epoch 39
2022-12-31 15:38:04,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:04,376 INFO:     Epoch: 40
2022-12-31 15:38:05,981 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4832616001367569, 'Total loss': 0.4832616001367569} | train loss {'Reaction outcome loss': 0.28993701827013013, 'Total loss': 0.28993701827013013}
2022-12-31 15:38:05,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:05,982 INFO:     Epoch: 41
2022-12-31 15:38:07,573 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49962314367294314, 'Total loss': 0.49962314367294314} | train loss {'Reaction outcome loss': 0.29694224788974494, 'Total loss': 0.29694224788974494}
2022-12-31 15:38:07,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:07,574 INFO:     Epoch: 42
2022-12-31 15:38:09,165 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45158937374750774, 'Total loss': 0.45158937374750774} | train loss {'Reaction outcome loss': 0.29208394238254526, 'Total loss': 0.29208394238254526}
2022-12-31 15:38:09,165 INFO:     Found new best model at epoch 42
2022-12-31 15:38:09,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:09,166 INFO:     Epoch: 43
2022-12-31 15:38:10,791 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4928632001082102, 'Total loss': 0.4928632001082102} | train loss {'Reaction outcome loss': 0.27737637639264046, 'Total loss': 0.27737637639264046}
2022-12-31 15:38:10,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:10,791 INFO:     Epoch: 44
2022-12-31 15:38:12,164 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5562449316183726, 'Total loss': 0.5562449316183726} | train loss {'Reaction outcome loss': 0.2830932767782019, 'Total loss': 0.2830932767782019}
2022-12-31 15:38:12,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:12,164 INFO:     Epoch: 45
2022-12-31 15:38:13,231 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4869096000989278, 'Total loss': 0.4869096000989278} | train loss {'Reaction outcome loss': 0.275505067500876, 'Total loss': 0.275505067500876}
2022-12-31 15:38:13,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:13,231 INFO:     Epoch: 46
2022-12-31 15:38:14,289 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47550074259440106, 'Total loss': 0.47550074259440106} | train loss {'Reaction outcome loss': 0.2722669254592705, 'Total loss': 0.2722669254592705}
2022-12-31 15:38:14,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:14,289 INFO:     Epoch: 47
2022-12-31 15:38:15,361 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45985315839449564, 'Total loss': 0.45985315839449564} | train loss {'Reaction outcome loss': 0.27286915669401923, 'Total loss': 0.27286915669401923}
2022-12-31 15:38:15,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:15,361 INFO:     Epoch: 48
2022-12-31 15:38:16,477 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5334527522325516, 'Total loss': 0.5334527522325516} | train loss {'Reaction outcome loss': 0.27270535403869417, 'Total loss': 0.27270535403869417}
2022-12-31 15:38:16,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:16,477 INFO:     Epoch: 49
2022-12-31 15:38:18,075 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5077677488327026, 'Total loss': 0.5077677488327026} | train loss {'Reaction outcome loss': 0.27210157938069585, 'Total loss': 0.27210157938069585}
2022-12-31 15:38:18,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:18,075 INFO:     Epoch: 50
2022-12-31 15:38:19,671 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47960692445437114, 'Total loss': 0.47960692445437114} | train loss {'Reaction outcome loss': 0.27514140973815987, 'Total loss': 0.27514140973815987}
2022-12-31 15:38:19,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:19,673 INFO:     Epoch: 51
2022-12-31 15:38:21,255 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4402645617723465, 'Total loss': 0.4402645617723465} | train loss {'Reaction outcome loss': 0.25885421184365787, 'Total loss': 0.25885421184365787}
2022-12-31 15:38:21,255 INFO:     Found new best model at epoch 51
2022-12-31 15:38:21,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:21,256 INFO:     Epoch: 52
2022-12-31 15:38:22,871 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4829570442438126, 'Total loss': 0.4829570442438126} | train loss {'Reaction outcome loss': 0.2573066332374082, 'Total loss': 0.2573066332374082}
2022-12-31 15:38:22,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:22,872 INFO:     Epoch: 53
2022-12-31 15:38:24,454 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47877668937047324, 'Total loss': 0.47877668937047324} | train loss {'Reaction outcome loss': 0.25946995480866225, 'Total loss': 0.25946995480866225}
2022-12-31 15:38:24,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:24,455 INFO:     Epoch: 54
2022-12-31 15:38:26,029 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4633772055308024, 'Total loss': 0.4633772055308024} | train loss {'Reaction outcome loss': 0.2625507327076389, 'Total loss': 0.2625507327076389}
2022-12-31 15:38:26,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:26,030 INFO:     Epoch: 55
2022-12-31 15:38:27,648 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5003924429416656, 'Total loss': 0.5003924429416656} | train loss {'Reaction outcome loss': 0.2584582644995752, 'Total loss': 0.2584582644995752}
2022-12-31 15:38:27,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:27,648 INFO:     Epoch: 56
2022-12-31 15:38:29,268 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48930703004201254, 'Total loss': 0.48930703004201254} | train loss {'Reaction outcome loss': 0.2538896247662686, 'Total loss': 0.2538896247662686}
2022-12-31 15:38:29,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:29,268 INFO:     Epoch: 57
2022-12-31 15:38:30,898 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5453552454710007, 'Total loss': 0.5453552454710007} | train loss {'Reaction outcome loss': 0.2533275652335677, 'Total loss': 0.2533275652335677}
2022-12-31 15:38:30,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:30,898 INFO:     Epoch: 58
2022-12-31 15:38:32,486 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4754827390114466, 'Total loss': 0.4754827390114466} | train loss {'Reaction outcome loss': 0.24904788944583672, 'Total loss': 0.24904788944583672}
2022-12-31 15:38:32,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:32,486 INFO:     Epoch: 59
2022-12-31 15:38:34,078 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4871078987916311, 'Total loss': 0.4871078987916311} | train loss {'Reaction outcome loss': 0.2454771264132126, 'Total loss': 0.2454771264132126}
2022-12-31 15:38:34,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:34,078 INFO:     Epoch: 60
2022-12-31 15:38:35,674 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4909548898537954, 'Total loss': 0.4909548898537954} | train loss {'Reaction outcome loss': 0.245469157120056, 'Total loss': 0.245469157120056}
2022-12-31 15:38:35,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:35,674 INFO:     Epoch: 61
2022-12-31 15:38:37,264 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47499561806519824, 'Total loss': 0.47499561806519824} | train loss {'Reaction outcome loss': 0.24307930934833083, 'Total loss': 0.24307930934833083}
2022-12-31 15:38:37,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:37,265 INFO:     Epoch: 62
2022-12-31 15:38:38,856 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5019359946250915, 'Total loss': 0.5019359946250915} | train loss {'Reaction outcome loss': 0.23853251602903228, 'Total loss': 0.23853251602903228}
2022-12-31 15:38:38,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:38,857 INFO:     Epoch: 63
2022-12-31 15:38:40,447 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.514120097955068, 'Total loss': 0.514120097955068} | train loss {'Reaction outcome loss': 0.23682647381291722, 'Total loss': 0.23682647381291722}
2022-12-31 15:38:40,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:40,448 INFO:     Epoch: 64
2022-12-31 15:38:42,091 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43848053355856487, 'Total loss': 0.43848053355856487} | train loss {'Reaction outcome loss': 0.24369624654179092, 'Total loss': 0.24369624654179092}
2022-12-31 15:38:42,091 INFO:     Found new best model at epoch 64
2022-12-31 15:38:42,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:42,093 INFO:     Epoch: 65
2022-12-31 15:38:43,732 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4767837385336558, 'Total loss': 0.4767837385336558} | train loss {'Reaction outcome loss': 0.23851451964114176, 'Total loss': 0.23851451964114176}
2022-12-31 15:38:43,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:43,733 INFO:     Epoch: 66
2022-12-31 15:38:45,395 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45793360471725464, 'Total loss': 0.45793360471725464} | train loss {'Reaction outcome loss': 0.23475078618897624, 'Total loss': 0.23475078618897624}
2022-12-31 15:38:45,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:45,396 INFO:     Epoch: 67
2022-12-31 15:38:47,012 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44536617000897727, 'Total loss': 0.44536617000897727} | train loss {'Reaction outcome loss': 0.23101711815612003, 'Total loss': 0.23101711815612003}
2022-12-31 15:38:47,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:47,012 INFO:     Epoch: 68
2022-12-31 15:38:48,640 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48811971545219424, 'Total loss': 0.48811971545219424} | train loss {'Reaction outcome loss': 0.23046096271900085, 'Total loss': 0.23046096271900085}
2022-12-31 15:38:48,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:48,640 INFO:     Epoch: 69
2022-12-31 15:38:50,270 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43678732626140115, 'Total loss': 0.43678732626140115} | train loss {'Reaction outcome loss': 0.22995901373624392, 'Total loss': 0.22995901373624392}
2022-12-31 15:38:50,270 INFO:     Found new best model at epoch 69
2022-12-31 15:38:50,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:50,271 INFO:     Epoch: 70
2022-12-31 15:38:51,851 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45863465617100396, 'Total loss': 0.45863465617100396} | train loss {'Reaction outcome loss': 0.23280712726761352, 'Total loss': 0.23280712726761352}
2022-12-31 15:38:51,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:51,852 INFO:     Epoch: 71
2022-12-31 15:38:53,440 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49439952870210013, 'Total loss': 0.49439952870210013} | train loss {'Reaction outcome loss': 0.23595825390337588, 'Total loss': 0.23595825390337588}
2022-12-31 15:38:53,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:53,440 INFO:     Epoch: 72
2022-12-31 15:38:55,034 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4855043162902196, 'Total loss': 0.4855043162902196} | train loss {'Reaction outcome loss': 0.2211692146547548, 'Total loss': 0.2211692146547548}
2022-12-31 15:38:55,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:55,035 INFO:     Epoch: 73
2022-12-31 15:38:56,628 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49773011604944867, 'Total loss': 0.49773011604944867} | train loss {'Reaction outcome loss': 0.22328369528901226, 'Total loss': 0.22328369528901226}
2022-12-31 15:38:56,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:56,628 INFO:     Epoch: 74
2022-12-31 15:38:58,223 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4729499061902364, 'Total loss': 0.4729499061902364} | train loss {'Reaction outcome loss': 0.22848537796255433, 'Total loss': 0.22848537796255433}
2022-12-31 15:38:58,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:58,223 INFO:     Epoch: 75
2022-12-31 15:38:59,811 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5362746745347977, 'Total loss': 0.5362746745347977} | train loss {'Reaction outcome loss': 0.22429124924999017, 'Total loss': 0.22429124924999017}
2022-12-31 15:38:59,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:38:59,811 INFO:     Epoch: 76
2022-12-31 15:39:01,426 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48867383499940237, 'Total loss': 0.48867383499940237} | train loss {'Reaction outcome loss': 0.22242695538006424, 'Total loss': 0.22242695538006424}
2022-12-31 15:39:01,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:01,427 INFO:     Epoch: 77
2022-12-31 15:39:03,033 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49942999084790546, 'Total loss': 0.49942999084790546} | train loss {'Reaction outcome loss': 0.2160952712712816, 'Total loss': 0.2160952712712816}
2022-12-31 15:39:03,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:03,034 INFO:     Epoch: 78
2022-12-31 15:39:04,663 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46006000886360804, 'Total loss': 0.46006000886360804} | train loss {'Reaction outcome loss': 0.22430059568267383, 'Total loss': 0.22430059568267383}
2022-12-31 15:39:04,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:04,663 INFO:     Epoch: 79
2022-12-31 15:39:06,292 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48320099512736003, 'Total loss': 0.48320099512736003} | train loss {'Reaction outcome loss': 0.22236540908805835, 'Total loss': 0.22236540908805835}
2022-12-31 15:39:06,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:06,292 INFO:     Epoch: 80
2022-12-31 15:39:07,897 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4703572650750478, 'Total loss': 0.4703572650750478} | train loss {'Reaction outcome loss': 0.21802756052477892, 'Total loss': 0.21802756052477892}
2022-12-31 15:39:07,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:07,897 INFO:     Epoch: 81
2022-12-31 15:39:09,488 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.528654279311498, 'Total loss': 0.528654279311498} | train loss {'Reaction outcome loss': 0.21656431455588165, 'Total loss': 0.21656431455588165}
2022-12-31 15:39:09,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:09,488 INFO:     Epoch: 82
2022-12-31 15:39:11,069 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47266940077145897, 'Total loss': 0.47266940077145897} | train loss {'Reaction outcome loss': 0.22382824318039984, 'Total loss': 0.22382824318039984}
2022-12-31 15:39:11,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:11,070 INFO:     Epoch: 83
2022-12-31 15:39:12,693 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42851015043755375, 'Total loss': 0.42851015043755375} | train loss {'Reaction outcome loss': 0.20810622296163014, 'Total loss': 0.20810622296163014}
2022-12-31 15:39:12,693 INFO:     Found new best model at epoch 83
2022-12-31 15:39:12,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:12,695 INFO:     Epoch: 84
2022-12-31 15:39:14,269 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5274196247259776, 'Total loss': 0.5274196247259776} | train loss {'Reaction outcome loss': 0.21410667383190476, 'Total loss': 0.21410667383190476}
2022-12-31 15:39:14,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:14,270 INFO:     Epoch: 85
2022-12-31 15:39:15,884 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.502672282854716, 'Total loss': 0.502672282854716} | train loss {'Reaction outcome loss': 0.21659520242513317, 'Total loss': 0.21659520242513317}
2022-12-31 15:39:15,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:15,884 INFO:     Epoch: 86
2022-12-31 15:39:17,503 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49314484000205994, 'Total loss': 0.49314484000205994} | train loss {'Reaction outcome loss': 0.20682742154641903, 'Total loss': 0.20682742154641903}
2022-12-31 15:39:17,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:17,504 INFO:     Epoch: 87
2022-12-31 15:39:19,085 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49901170035203296, 'Total loss': 0.49901170035203296} | train loss {'Reaction outcome loss': 0.21091905567835975, 'Total loss': 0.21091905567835975}
2022-12-31 15:39:19,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:19,085 INFO:     Epoch: 88
2022-12-31 15:39:20,667 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45828005373477937, 'Total loss': 0.45828005373477937} | train loss {'Reaction outcome loss': 0.21362191919005397, 'Total loss': 0.21362191919005397}
2022-12-31 15:39:20,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:20,667 INFO:     Epoch: 89
2022-12-31 15:39:22,254 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46033922433853147, 'Total loss': 0.46033922433853147} | train loss {'Reaction outcome loss': 0.20576975809243053, 'Total loss': 0.20576975809243053}
2022-12-31 15:39:22,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:22,254 INFO:     Epoch: 90
2022-12-31 15:39:23,841 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4789521853129069, 'Total loss': 0.4789521853129069} | train loss {'Reaction outcome loss': 0.20138592755374235, 'Total loss': 0.20138592755374235}
2022-12-31 15:39:23,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:23,841 INFO:     Epoch: 91
2022-12-31 15:39:25,429 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4909918447335561, 'Total loss': 0.4909918447335561} | train loss {'Reaction outcome loss': 0.20429776724250542, 'Total loss': 0.20429776724250542}
2022-12-31 15:39:25,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:25,430 INFO:     Epoch: 92
2022-12-31 15:39:27,005 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44066722442706424, 'Total loss': 0.44066722442706424} | train loss {'Reaction outcome loss': 0.20318775614484763, 'Total loss': 0.20318775614484763}
2022-12-31 15:39:27,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:27,005 INFO:     Epoch: 93
2022-12-31 15:39:28,590 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47785584231217704, 'Total loss': 0.47785584231217704} | train loss {'Reaction outcome loss': 0.20432305728313904, 'Total loss': 0.20432305728313904}
2022-12-31 15:39:28,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:28,590 INFO:     Epoch: 94
2022-12-31 15:39:30,191 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43504608074824014, 'Total loss': 0.43504608074824014} | train loss {'Reaction outcome loss': 0.1975661450553508, 'Total loss': 0.1975661450553508}
2022-12-31 15:39:30,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:30,191 INFO:     Epoch: 95
2022-12-31 15:39:31,814 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5017901450395584, 'Total loss': 0.5017901450395584} | train loss {'Reaction outcome loss': 0.19558771663505733, 'Total loss': 0.19558771663505733}
2022-12-31 15:39:31,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:31,815 INFO:     Epoch: 96
2022-12-31 15:39:33,399 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4750950237115224, 'Total loss': 0.4750950237115224} | train loss {'Reaction outcome loss': 0.2015592042772925, 'Total loss': 0.2015592042772925}
2022-12-31 15:39:33,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:33,400 INFO:     Epoch: 97
2022-12-31 15:39:34,986 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4630023419857025, 'Total loss': 0.4630023419857025} | train loss {'Reaction outcome loss': 0.1976379432166234, 'Total loss': 0.1976379432166234}
2022-12-31 15:39:34,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:34,986 INFO:     Epoch: 98
2022-12-31 15:39:36,557 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5108521481355032, 'Total loss': 0.5108521481355032} | train loss {'Reaction outcome loss': 0.19767953091106572, 'Total loss': 0.19767953091106572}
2022-12-31 15:39:36,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:36,557 INFO:     Epoch: 99
2022-12-31 15:39:38,153 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48503112892309824, 'Total loss': 0.48503112892309824} | train loss {'Reaction outcome loss': 0.20025177149873077, 'Total loss': 0.20025177149873077}
2022-12-31 15:39:38,153 INFO:     Best model found after epoch 84 of 100.
2022-12-31 15:39:38,153 INFO:   Done with stage: TRAINING
2022-12-31 15:39:38,153 INFO:   Starting stage: EVALUATION
2022-12-31 15:39:38,294 INFO:   Done with stage: EVALUATION
2022-12-31 15:39:38,294 INFO:   Leaving out SEQ value Fold_7
2022-12-31 15:39:38,307 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 15:39:38,307 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:39:38,957 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:39:38,957 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:39:39,026 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:39:39,027 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:39:39,027 INFO:     No hyperparam tuning for this model
2022-12-31 15:39:39,027 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:39:39,027 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:39:39,028 INFO:     None feature selector for col prot
2022-12-31 15:39:39,028 INFO:     None feature selector for col prot
2022-12-31 15:39:39,028 INFO:     None feature selector for col prot
2022-12-31 15:39:39,029 INFO:     None feature selector for col chem
2022-12-31 15:39:39,029 INFO:     None feature selector for col chem
2022-12-31 15:39:39,029 INFO:     None feature selector for col chem
2022-12-31 15:39:39,029 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:39:39,029 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:39:39,031 INFO:     Number of params in model 223921
2022-12-31 15:39:39,034 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:39:39,034 INFO:   Starting stage: TRAINING
2022-12-31 15:39:39,081 INFO:     Val loss before train {'Reaction outcome loss': 0.9995859424273174, 'Total loss': 0.9995859424273174}
2022-12-31 15:39:39,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:39,081 INFO:     Epoch: 0
2022-12-31 15:39:40,687 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6330883711576462, 'Total loss': 0.6330883711576462} | train loss {'Reaction outcome loss': 0.8173585965530107, 'Total loss': 0.8173585965530107}
2022-12-31 15:39:40,688 INFO:     Found new best model at epoch 0
2022-12-31 15:39:40,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:40,689 INFO:     Epoch: 1
2022-12-31 15:39:42,297 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5546206454435985, 'Total loss': 0.5546206454435985} | train loss {'Reaction outcome loss': 0.5891171021366808, 'Total loss': 0.5891171021366808}
2022-12-31 15:39:42,297 INFO:     Found new best model at epoch 1
2022-12-31 15:39:42,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:42,299 INFO:     Epoch: 2
2022-12-31 15:39:43,904 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5144466797510783, 'Total loss': 0.5144466797510783} | train loss {'Reaction outcome loss': 0.532038859511971, 'Total loss': 0.532038859511971}
2022-12-31 15:39:43,905 INFO:     Found new best model at epoch 2
2022-12-31 15:39:43,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:43,906 INFO:     Epoch: 3
2022-12-31 15:39:45,501 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4806840499242147, 'Total loss': 0.4806840499242147} | train loss {'Reaction outcome loss': 0.5035918950496597, 'Total loss': 0.5035918950496597}
2022-12-31 15:39:45,501 INFO:     Found new best model at epoch 3
2022-12-31 15:39:45,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:45,502 INFO:     Epoch: 4
2022-12-31 15:39:47,111 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5211010913054148, 'Total loss': 0.5211010913054148} | train loss {'Reaction outcome loss': 0.48891941471435535, 'Total loss': 0.48891941471435535}
2022-12-31 15:39:47,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:47,111 INFO:     Epoch: 5
2022-12-31 15:39:48,759 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5026173532009125, 'Total loss': 0.5026173532009125} | train loss {'Reaction outcome loss': 0.478934701868343, 'Total loss': 0.478934701868343}
2022-12-31 15:39:48,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:48,759 INFO:     Epoch: 6
2022-12-31 15:39:50,378 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48502117991447447, 'Total loss': 0.48502117991447447} | train loss {'Reaction outcome loss': 0.4696427508919678, 'Total loss': 0.4696427508919678}
2022-12-31 15:39:50,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:50,378 INFO:     Epoch: 7
2022-12-31 15:39:51,981 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4578041593233744, 'Total loss': 0.4578041593233744} | train loss {'Reaction outcome loss': 0.46399613773779746, 'Total loss': 0.46399613773779746}
2022-12-31 15:39:51,981 INFO:     Found new best model at epoch 7
2022-12-31 15:39:51,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:51,982 INFO:     Epoch: 8
2022-12-31 15:39:53,578 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49410779774188995, 'Total loss': 0.49410779774188995} | train loss {'Reaction outcome loss': 0.4495047050047437, 'Total loss': 0.4495047050047437}
2022-12-31 15:39:53,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:53,578 INFO:     Epoch: 9
2022-12-31 15:39:55,179 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4678181250890096, 'Total loss': 0.4678181250890096} | train loss {'Reaction outcome loss': 0.44499478292809497, 'Total loss': 0.44499478292809497}
2022-12-31 15:39:55,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:55,179 INFO:     Epoch: 10
2022-12-31 15:39:56,774 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4365434358517329, 'Total loss': 0.4365434358517329} | train loss {'Reaction outcome loss': 0.4395778770373616, 'Total loss': 0.4395778770373616}
2022-12-31 15:39:56,774 INFO:     Found new best model at epoch 10
2022-12-31 15:39:56,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:56,775 INFO:     Epoch: 11
2022-12-31 15:39:58,379 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4751127392053604, 'Total loss': 0.4751127392053604} | train loss {'Reaction outcome loss': 0.43079346122509304, 'Total loss': 0.43079346122509304}
2022-12-31 15:39:58,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:58,379 INFO:     Epoch: 12
2022-12-31 15:39:59,992 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4648723026116689, 'Total loss': 0.4648723026116689} | train loss {'Reaction outcome loss': 0.42503847832714176, 'Total loss': 0.42503847832714176}
2022-12-31 15:39:59,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:39:59,992 INFO:     Epoch: 13
2022-12-31 15:40:01,606 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4758326500654221, 'Total loss': 0.4758326500654221} | train loss {'Reaction outcome loss': 0.42743183037649424, 'Total loss': 0.42743183037649424}
2022-12-31 15:40:01,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:01,607 INFO:     Epoch: 14
2022-12-31 15:40:03,207 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4432080924510956, 'Total loss': 0.4432080924510956} | train loss {'Reaction outcome loss': 0.41307981199305843, 'Total loss': 0.41307981199305843}
2022-12-31 15:40:03,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:03,208 INFO:     Epoch: 15
2022-12-31 15:40:04,813 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43835988144079846, 'Total loss': 0.43835988144079846} | train loss {'Reaction outcome loss': 0.40802523036510935, 'Total loss': 0.40802523036510935}
2022-12-31 15:40:04,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:04,813 INFO:     Epoch: 16
2022-12-31 15:40:06,455 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4466333657503128, 'Total loss': 0.4466333657503128} | train loss {'Reaction outcome loss': 0.40089426854026877, 'Total loss': 0.40089426854026877}
2022-12-31 15:40:06,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:06,456 INFO:     Epoch: 17
2022-12-31 15:40:08,115 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4194195012251536, 'Total loss': 0.4194195012251536} | train loss {'Reaction outcome loss': 0.3982618613040835, 'Total loss': 0.3982618613040835}
2022-12-31 15:40:08,116 INFO:     Found new best model at epoch 17
2022-12-31 15:40:08,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:08,117 INFO:     Epoch: 18
2022-12-31 15:40:09,749 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41804792881011965, 'Total loss': 0.41804792881011965} | train loss {'Reaction outcome loss': 0.38979685793392066, 'Total loss': 0.38979685793392066}
2022-12-31 15:40:09,749 INFO:     Found new best model at epoch 18
2022-12-31 15:40:09,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:09,751 INFO:     Epoch: 19
2022-12-31 15:40:11,366 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.440390357375145, 'Total loss': 0.440390357375145} | train loss {'Reaction outcome loss': 0.3899620200645192, 'Total loss': 0.3899620200645192}
2022-12-31 15:40:11,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:11,367 INFO:     Epoch: 20
2022-12-31 15:40:12,978 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43925048112869264, 'Total loss': 0.43925048112869264} | train loss {'Reaction outcome loss': 0.3801554745661653, 'Total loss': 0.3801554745661653}
2022-12-31 15:40:12,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:12,979 INFO:     Epoch: 21
2022-12-31 15:40:14,585 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41465619802474973, 'Total loss': 0.41465619802474973} | train loss {'Reaction outcome loss': 0.37800859121962144, 'Total loss': 0.37800859121962144}
2022-12-31 15:40:14,585 INFO:     Found new best model at epoch 21
2022-12-31 15:40:14,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:14,587 INFO:     Epoch: 22
2022-12-31 15:40:16,223 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4369029631217321, 'Total loss': 0.4369029631217321} | train loss {'Reaction outcome loss': 0.3721495345772819, 'Total loss': 0.3721495345772819}
2022-12-31 15:40:16,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:16,224 INFO:     Epoch: 23
2022-12-31 15:40:17,868 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4209812621275584, 'Total loss': 0.4209812621275584} | train loss {'Reaction outcome loss': 0.36416123030095326, 'Total loss': 0.36416123030095326}
2022-12-31 15:40:17,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:17,868 INFO:     Epoch: 24
2022-12-31 15:40:19,504 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4153111030658086, 'Total loss': 0.4153111030658086} | train loss {'Reaction outcome loss': 0.36700061767863024, 'Total loss': 0.36700061767863024}
2022-12-31 15:40:19,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:19,504 INFO:     Epoch: 25
2022-12-31 15:40:21,106 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43091341356436413, 'Total loss': 0.43091341356436413} | train loss {'Reaction outcome loss': 0.35646498444009345, 'Total loss': 0.35646498444009345}
2022-12-31 15:40:21,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:21,107 INFO:     Epoch: 26
2022-12-31 15:40:22,748 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43052707811196644, 'Total loss': 0.43052707811196644} | train loss {'Reaction outcome loss': 0.35310709627096404, 'Total loss': 0.35310709627096404}
2022-12-31 15:40:22,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:22,748 INFO:     Epoch: 27
2022-12-31 15:40:24,357 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39975178937117256, 'Total loss': 0.39975178937117256} | train loss {'Reaction outcome loss': 0.35286197784467727, 'Total loss': 0.35286197784467727}
2022-12-31 15:40:24,357 INFO:     Found new best model at epoch 27
2022-12-31 15:40:24,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:24,358 INFO:     Epoch: 28
2022-12-31 15:40:25,968 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41597976088523864, 'Total loss': 0.41597976088523864} | train loss {'Reaction outcome loss': 0.34098869153308525, 'Total loss': 0.34098869153308525}
2022-12-31 15:40:25,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:25,968 INFO:     Epoch: 29
2022-12-31 15:40:27,598 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4342522988716761, 'Total loss': 0.4342522988716761} | train loss {'Reaction outcome loss': 0.3360853143412929, 'Total loss': 0.3360853143412929}
2022-12-31 15:40:27,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:27,598 INFO:     Epoch: 30
2022-12-31 15:40:29,236 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38198411613702776, 'Total loss': 0.38198411613702776} | train loss {'Reaction outcome loss': 0.338679314063129, 'Total loss': 0.338679314063129}
2022-12-31 15:40:29,236 INFO:     Found new best model at epoch 30
2022-12-31 15:40:29,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:29,237 INFO:     Epoch: 31
2022-12-31 15:40:30,853 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4023641933997472, 'Total loss': 0.4023641933997472} | train loss {'Reaction outcome loss': 0.32977017668825626, 'Total loss': 0.32977017668825626}
2022-12-31 15:40:30,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:30,853 INFO:     Epoch: 32
2022-12-31 15:40:32,475 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3794256865978241, 'Total loss': 0.3794256865978241} | train loss {'Reaction outcome loss': 0.3250375965253756, 'Total loss': 0.3250375965253756}
2022-12-31 15:40:32,477 INFO:     Found new best model at epoch 32
2022-12-31 15:40:32,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:32,478 INFO:     Epoch: 33
2022-12-31 15:40:34,110 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4025439411401749, 'Total loss': 0.4025439411401749} | train loss {'Reaction outcome loss': 0.32113123876093097, 'Total loss': 0.32113123876093097}
2022-12-31 15:40:34,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:34,110 INFO:     Epoch: 34
2022-12-31 15:40:35,728 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41223278393348056, 'Total loss': 0.41223278393348056} | train loss {'Reaction outcome loss': 0.3235288544655492, 'Total loss': 0.3235288544655492}
2022-12-31 15:40:35,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:35,728 INFO:     Epoch: 35
2022-12-31 15:40:37,372 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41156090299288434, 'Total loss': 0.41156090299288434} | train loss {'Reaction outcome loss': 0.3189912577721186, 'Total loss': 0.3189912577721186}
2022-12-31 15:40:37,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:37,372 INFO:     Epoch: 36
2022-12-31 15:40:38,996 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39883691469828286, 'Total loss': 0.39883691469828286} | train loss {'Reaction outcome loss': 0.31270729508318196, 'Total loss': 0.31270729508318196}
2022-12-31 15:40:38,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:38,997 INFO:     Epoch: 37
2022-12-31 15:40:40,602 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3852277934551239, 'Total loss': 0.3852277934551239} | train loss {'Reaction outcome loss': 0.3012327176085018, 'Total loss': 0.3012327176085018}
2022-12-31 15:40:40,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:40,602 INFO:     Epoch: 38
2022-12-31 15:40:42,207 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39303530355294547, 'Total loss': 0.39303530355294547} | train loss {'Reaction outcome loss': 0.30453344262356363, 'Total loss': 0.30453344262356363}
2022-12-31 15:40:42,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:42,207 INFO:     Epoch: 39
2022-12-31 15:40:43,814 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4148236483335495, 'Total loss': 0.4148236483335495} | train loss {'Reaction outcome loss': 0.3022516380578602, 'Total loss': 0.3022516380578602}
2022-12-31 15:40:43,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:43,815 INFO:     Epoch: 40
2022-12-31 15:40:45,421 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3989896277586619, 'Total loss': 0.3989896277586619} | train loss {'Reaction outcome loss': 0.29449768769235385, 'Total loss': 0.29449768769235385}
2022-12-31 15:40:45,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:45,421 INFO:     Epoch: 41
2022-12-31 15:40:47,036 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4006092697381973, 'Total loss': 0.4006092697381973} | train loss {'Reaction outcome loss': 0.29123783579587076, 'Total loss': 0.29123783579587076}
2022-12-31 15:40:47,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:47,036 INFO:     Epoch: 42
2022-12-31 15:40:48,627 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4315030922492345, 'Total loss': 0.4315030922492345} | train loss {'Reaction outcome loss': 0.28966202390538226, 'Total loss': 0.28966202390538226}
2022-12-31 15:40:48,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:48,627 INFO:     Epoch: 43
2022-12-31 15:40:50,288 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3699980676174164, 'Total loss': 0.3699980676174164} | train loss {'Reaction outcome loss': 0.28889044745411685, 'Total loss': 0.28889044745411685}
2022-12-31 15:40:50,288 INFO:     Found new best model at epoch 43
2022-12-31 15:40:50,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:50,289 INFO:     Epoch: 44
2022-12-31 15:40:51,926 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3717900425195694, 'Total loss': 0.3717900425195694} | train loss {'Reaction outcome loss': 0.2870056512311693, 'Total loss': 0.2870056512311693}
2022-12-31 15:40:51,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:51,927 INFO:     Epoch: 45
2022-12-31 15:40:53,543 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4002601991097132, 'Total loss': 0.4002601991097132} | train loss {'Reaction outcome loss': 0.2804686958609075, 'Total loss': 0.2804686958609075}
2022-12-31 15:40:53,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:53,543 INFO:     Epoch: 46
2022-12-31 15:40:55,184 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40496038099129994, 'Total loss': 0.40496038099129994} | train loss {'Reaction outcome loss': 0.2852913416680016, 'Total loss': 0.2852913416680016}
2022-12-31 15:40:55,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:55,184 INFO:     Epoch: 47
2022-12-31 15:40:56,834 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3789206157128016, 'Total loss': 0.3789206157128016} | train loss {'Reaction outcome loss': 0.27577097730085737, 'Total loss': 0.27577097730085737}
2022-12-31 15:40:56,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:56,834 INFO:     Epoch: 48
2022-12-31 15:40:58,433 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4246688465277354, 'Total loss': 0.4246688465277354} | train loss {'Reaction outcome loss': 0.2782598568751924, 'Total loss': 0.2782598568751924}
2022-12-31 15:40:58,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:40:58,433 INFO:     Epoch: 49
2022-12-31 15:41:00,032 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3625180751085281, 'Total loss': 0.3625180751085281} | train loss {'Reaction outcome loss': 0.26394988427658156, 'Total loss': 0.26394988427658156}
2022-12-31 15:41:00,033 INFO:     Found new best model at epoch 49
2022-12-31 15:41:00,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:00,034 INFO:     Epoch: 50
2022-12-31 15:41:01,685 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39299800246953964, 'Total loss': 0.39299800246953964} | train loss {'Reaction outcome loss': 0.2662378005374102, 'Total loss': 0.2662378005374102}
2022-12-31 15:41:01,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:01,685 INFO:     Epoch: 51
2022-12-31 15:41:03,334 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3969136938452721, 'Total loss': 0.3969136938452721} | train loss {'Reaction outcome loss': 0.2720490883067519, 'Total loss': 0.2720490883067519}
2022-12-31 15:41:03,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:03,335 INFO:     Epoch: 52
2022-12-31 15:41:04,981 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41475663979848226, 'Total loss': 0.41475663979848226} | train loss {'Reaction outcome loss': 0.2633604248750296, 'Total loss': 0.2633604248750296}
2022-12-31 15:41:04,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:04,981 INFO:     Epoch: 53
2022-12-31 15:41:06,574 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37639857158064843, 'Total loss': 0.37639857158064843} | train loss {'Reaction outcome loss': 0.2608190446365826, 'Total loss': 0.2608190446365826}
2022-12-31 15:41:06,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:06,574 INFO:     Epoch: 54
2022-12-31 15:41:08,187 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3980858981609344, 'Total loss': 0.3980858981609344} | train loss {'Reaction outcome loss': 0.25958209453883585, 'Total loss': 0.25958209453883585}
2022-12-31 15:41:08,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:08,187 INFO:     Epoch: 55
2022-12-31 15:41:09,815 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4294439842303594, 'Total loss': 0.4294439842303594} | train loss {'Reaction outcome loss': 0.25730033177169653, 'Total loss': 0.25730033177169653}
2022-12-31 15:41:09,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:09,816 INFO:     Epoch: 56
2022-12-31 15:41:11,466 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3897769391536713, 'Total loss': 0.3897769391536713} | train loss {'Reaction outcome loss': 0.25460265843123736, 'Total loss': 0.25460265843123736}
2022-12-31 15:41:11,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:11,466 INFO:     Epoch: 57
2022-12-31 15:41:13,116 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41113714973131815, 'Total loss': 0.41113714973131815} | train loss {'Reaction outcome loss': 0.25322269912580503, 'Total loss': 0.25322269912580503}
2022-12-31 15:41:13,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:13,116 INFO:     Epoch: 58
2022-12-31 15:41:14,762 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3835938925544421, 'Total loss': 0.3835938925544421} | train loss {'Reaction outcome loss': 0.25338006303359883, 'Total loss': 0.25338006303359883}
2022-12-31 15:41:14,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:14,763 INFO:     Epoch: 59
2022-12-31 15:41:16,355 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39628635545571644, 'Total loss': 0.39628635545571644} | train loss {'Reaction outcome loss': 0.2501754169940733, 'Total loss': 0.2501754169940733}
2022-12-31 15:41:16,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:16,355 INFO:     Epoch: 60
2022-12-31 15:41:17,957 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3693231781323751, 'Total loss': 0.3693231781323751} | train loss {'Reaction outcome loss': 0.24656939891163623, 'Total loss': 0.24656939891163623}
2022-12-31 15:41:17,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:17,958 INFO:     Epoch: 61
2022-12-31 15:41:19,555 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3763318156202634, 'Total loss': 0.3763318156202634} | train loss {'Reaction outcome loss': 0.251265751903991, 'Total loss': 0.251265751903991}
2022-12-31 15:41:19,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:19,555 INFO:     Epoch: 62
2022-12-31 15:41:21,191 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3972882052262624, 'Total loss': 0.3972882052262624} | train loss {'Reaction outcome loss': 0.25149508057303377, 'Total loss': 0.25149508057303377}
2022-12-31 15:41:21,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:21,191 INFO:     Epoch: 63
2022-12-31 15:41:22,837 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39212870399157207, 'Total loss': 0.39212870399157207} | train loss {'Reaction outcome loss': 0.24697284665402522, 'Total loss': 0.24697284665402522}
2022-12-31 15:41:22,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:22,838 INFO:     Epoch: 64
2022-12-31 15:41:24,448 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.36202166477839154, 'Total loss': 0.36202166477839154} | train loss {'Reaction outcome loss': 0.24840766980248882, 'Total loss': 0.24840766980248882}
2022-12-31 15:41:24,448 INFO:     Found new best model at epoch 64
2022-12-31 15:41:24,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:24,449 INFO:     Epoch: 65
2022-12-31 15:41:26,088 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38950667331616085, 'Total loss': 0.38950667331616085} | train loss {'Reaction outcome loss': 0.24435540155544608, 'Total loss': 0.24435540155544608}
2022-12-31 15:41:26,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:26,088 INFO:     Epoch: 66
2022-12-31 15:41:27,719 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40583884219328564, 'Total loss': 0.40583884219328564} | train loss {'Reaction outcome loss': 0.23835945847555187, 'Total loss': 0.23835945847555187}
2022-12-31 15:41:27,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:27,719 INFO:     Epoch: 67
2022-12-31 15:41:29,366 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.35893472929795583, 'Total loss': 0.35893472929795583} | train loss {'Reaction outcome loss': 0.2360664785298307, 'Total loss': 0.2360664785298307}
2022-12-31 15:41:29,367 INFO:     Found new best model at epoch 67
2022-12-31 15:41:29,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:29,368 INFO:     Epoch: 68
2022-12-31 15:41:30,972 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38014244437217715, 'Total loss': 0.38014244437217715} | train loss {'Reaction outcome loss': 0.23667868673263473, 'Total loss': 0.23667868673263473}
2022-12-31 15:41:30,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:30,973 INFO:     Epoch: 69
2022-12-31 15:41:32,611 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3814739018678665, 'Total loss': 0.3814739018678665} | train loss {'Reaction outcome loss': 0.2375787820277016, 'Total loss': 0.2375787820277016}
2022-12-31 15:41:32,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:32,611 INFO:     Epoch: 70
2022-12-31 15:41:34,201 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.36689150234063467, 'Total loss': 0.36689150234063467} | train loss {'Reaction outcome loss': 0.23653767107303392, 'Total loss': 0.23653767107303392}
2022-12-31 15:41:34,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:34,202 INFO:     Epoch: 71
2022-12-31 15:41:35,803 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3599020595351855, 'Total loss': 0.3599020595351855} | train loss {'Reaction outcome loss': 0.23743025134468876, 'Total loss': 0.23743025134468876}
2022-12-31 15:41:35,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:35,804 INFO:     Epoch: 72
2022-12-31 15:41:37,446 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3810583710670471, 'Total loss': 0.3810583710670471} | train loss {'Reaction outcome loss': 0.2307290585530041, 'Total loss': 0.2307290585530041}
2022-12-31 15:41:37,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:37,446 INFO:     Epoch: 73
2022-12-31 15:41:39,093 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3560530131061872, 'Total loss': 0.3560530131061872} | train loss {'Reaction outcome loss': 0.2309536879700659, 'Total loss': 0.2309536879700659}
2022-12-31 15:41:39,093 INFO:     Found new best model at epoch 73
2022-12-31 15:41:39,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:39,094 INFO:     Epoch: 74
2022-12-31 15:41:40,710 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.35736332337061566, 'Total loss': 0.35736332337061566} | train loss {'Reaction outcome loss': 0.22773375268016913, 'Total loss': 0.22773375268016913}
2022-12-31 15:41:40,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:40,711 INFO:     Epoch: 75
2022-12-31 15:41:42,317 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.35978101243575417, 'Total loss': 0.35978101243575417} | train loss {'Reaction outcome loss': 0.22668777871540738, 'Total loss': 0.22668777871540738}
2022-12-31 15:41:42,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:42,318 INFO:     Epoch: 76
2022-12-31 15:41:43,944 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.372256675362587, 'Total loss': 0.372256675362587} | train loss {'Reaction outcome loss': 0.2287567036515539, 'Total loss': 0.2287567036515539}
2022-12-31 15:41:43,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:43,944 INFO:     Epoch: 77
2022-12-31 15:41:45,558 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37634010910987853, 'Total loss': 0.37634010910987853} | train loss {'Reaction outcome loss': 0.22337637081849876, 'Total loss': 0.22337637081849876}
2022-12-31 15:41:45,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:45,558 INFO:     Epoch: 78
2022-12-31 15:41:47,170 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.35752321084340416, 'Total loss': 0.35752321084340416} | train loss {'Reaction outcome loss': 0.2218347548739144, 'Total loss': 0.2218347548739144}
2022-12-31 15:41:47,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:47,170 INFO:     Epoch: 79
2022-12-31 15:41:48,792 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3600767960151037, 'Total loss': 0.3600767960151037} | train loss {'Reaction outcome loss': 0.2177405589283696, 'Total loss': 0.2177405589283696}
2022-12-31 15:41:48,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:48,792 INFO:     Epoch: 80
2022-12-31 15:41:50,438 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38080196181933085, 'Total loss': 0.38080196181933085} | train loss {'Reaction outcome loss': 0.21980416139971048, 'Total loss': 0.21980416139971048}
2022-12-31 15:41:50,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:50,438 INFO:     Epoch: 81
2022-12-31 15:41:52,059 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.402420862019062, 'Total loss': 0.402420862019062} | train loss {'Reaction outcome loss': 0.22474723490835957, 'Total loss': 0.22474723490835957}
2022-12-31 15:41:52,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:52,059 INFO:     Epoch: 82
2022-12-31 15:41:53,656 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3578408430020014, 'Total loss': 0.3578408430020014} | train loss {'Reaction outcome loss': 0.22156591917176324, 'Total loss': 0.22156591917176324}
2022-12-31 15:41:53,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:53,657 INFO:     Epoch: 83
2022-12-31 15:41:55,297 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40093205521504083, 'Total loss': 0.40093205521504083} | train loss {'Reaction outcome loss': 0.21812723040419366, 'Total loss': 0.21812723040419366}
2022-12-31 15:41:55,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:55,297 INFO:     Epoch: 84
2022-12-31 15:41:56,947 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3837129900852839, 'Total loss': 0.3837129900852839} | train loss {'Reaction outcome loss': 0.21538049068691928, 'Total loss': 0.21538049068691928}
2022-12-31 15:41:56,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:56,948 INFO:     Epoch: 85
2022-12-31 15:41:58,599 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4040520037213961, 'Total loss': 0.4040520037213961} | train loss {'Reaction outcome loss': 0.21321340296619204, 'Total loss': 0.21321340296619204}
2022-12-31 15:41:58,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:41:58,599 INFO:     Epoch: 86
2022-12-31 15:42:00,249 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3311702062686284, 'Total loss': 0.3311702062686284} | train loss {'Reaction outcome loss': 0.21640775904113205, 'Total loss': 0.21640775904113205}
2022-12-31 15:42:00,249 INFO:     Found new best model at epoch 86
2022-12-31 15:42:00,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:00,250 INFO:     Epoch: 87
2022-12-31 15:42:01,845 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4044947296380997, 'Total loss': 0.4044947296380997} | train loss {'Reaction outcome loss': 0.21361809617937258, 'Total loss': 0.21361809617937258}
2022-12-31 15:42:01,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:01,845 INFO:     Epoch: 88
2022-12-31 15:42:03,450 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.35636034806569417, 'Total loss': 0.35636034806569417} | train loss {'Reaction outcome loss': 0.21967734175226533, 'Total loss': 0.21967734175226533}
2022-12-31 15:42:03,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:03,450 INFO:     Epoch: 89
2022-12-31 15:42:05,064 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38907466232776644, 'Total loss': 0.38907466232776644} | train loss {'Reaction outcome loss': 0.21089181034331503, 'Total loss': 0.21089181034331503}
2022-12-31 15:42:05,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:05,066 INFO:     Epoch: 90
2022-12-31 15:42:06,679 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39329555531342825, 'Total loss': 0.39329555531342825} | train loss {'Reaction outcome loss': 0.21185935965137362, 'Total loss': 0.21185935965137362}
2022-12-31 15:42:06,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:06,679 INFO:     Epoch: 91
2022-12-31 15:42:08,292 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3469241221745809, 'Total loss': 0.3469241221745809} | train loss {'Reaction outcome loss': 0.20987997246428733, 'Total loss': 0.20987997246428733}
2022-12-31 15:42:08,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:08,292 INFO:     Epoch: 92
2022-12-31 15:42:09,893 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3498378604650497, 'Total loss': 0.3498378604650497} | train loss {'Reaction outcome loss': 0.2099962882657236, 'Total loss': 0.2099962882657236}
2022-12-31 15:42:09,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:09,893 INFO:     Epoch: 93
2022-12-31 15:42:11,491 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36969667077064516, 'Total loss': 0.36969667077064516} | train loss {'Reaction outcome loss': 0.2041238160208809, 'Total loss': 0.2041238160208809}
2022-12-31 15:42:11,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:11,492 INFO:     Epoch: 94
2022-12-31 15:42:13,096 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3881303419669469, 'Total loss': 0.3881303419669469} | train loss {'Reaction outcome loss': 0.20667980386058563, 'Total loss': 0.20667980386058563}
2022-12-31 15:42:13,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:13,096 INFO:     Epoch: 95
2022-12-31 15:42:14,712 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.340652534365654, 'Total loss': 0.340652534365654} | train loss {'Reaction outcome loss': 0.20325462852305454, 'Total loss': 0.20325462852305454}
2022-12-31 15:42:14,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:14,712 INFO:     Epoch: 96
2022-12-31 15:42:16,327 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38532651563485465, 'Total loss': 0.38532651563485465} | train loss {'Reaction outcome loss': 0.20692760256599863, 'Total loss': 0.20692760256599863}
2022-12-31 15:42:16,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:16,327 INFO:     Epoch: 97
2022-12-31 15:42:17,972 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3725759754578272, 'Total loss': 0.3725759754578272} | train loss {'Reaction outcome loss': 0.20316969393500353, 'Total loss': 0.20316969393500353}
2022-12-31 15:42:17,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:17,972 INFO:     Epoch: 98
2022-12-31 15:42:19,604 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37082156439622244, 'Total loss': 0.37082156439622244} | train loss {'Reaction outcome loss': 0.2060153901254227, 'Total loss': 0.2060153901254227}
2022-12-31 15:42:19,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:19,604 INFO:     Epoch: 99
2022-12-31 15:42:21,225 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4203600466251373, 'Total loss': 0.4203600466251373} | train loss {'Reaction outcome loss': 0.20205987934426603, 'Total loss': 0.20205987934426603}
2022-12-31 15:42:21,225 INFO:     Best model found after epoch 87 of 100.
2022-12-31 15:42:21,225 INFO:   Done with stage: TRAINING
2022-12-31 15:42:21,225 INFO:   Starting stage: EVALUATION
2022-12-31 15:42:21,348 INFO:   Done with stage: EVALUATION
2022-12-31 15:42:21,348 INFO:   Leaving out SEQ value Fold_8
2022-12-31 15:42:21,361 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 15:42:21,361 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:42:22,027 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:42:22,027 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:42:22,096 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:42:22,096 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:42:22,096 INFO:     No hyperparam tuning for this model
2022-12-31 15:42:22,096 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:42:22,096 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:42:22,097 INFO:     None feature selector for col prot
2022-12-31 15:42:22,097 INFO:     None feature selector for col prot
2022-12-31 15:42:22,097 INFO:     None feature selector for col prot
2022-12-31 15:42:22,098 INFO:     None feature selector for col chem
2022-12-31 15:42:22,098 INFO:     None feature selector for col chem
2022-12-31 15:42:22,098 INFO:     None feature selector for col chem
2022-12-31 15:42:22,098 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:42:22,098 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:42:22,100 INFO:     Number of params in model 223921
2022-12-31 15:42:22,103 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:42:22,103 INFO:   Starting stage: TRAINING
2022-12-31 15:42:22,148 INFO:     Val loss before train {'Reaction outcome loss': 1.0883402903874715, 'Total loss': 1.0883402903874715}
2022-12-31 15:42:22,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:22,149 INFO:     Epoch: 0
2022-12-31 15:42:23,791 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7042020559310913, 'Total loss': 0.7042020559310913} | train loss {'Reaction outcome loss': 0.819889226037523, 'Total loss': 0.819889226037523}
2022-12-31 15:42:23,791 INFO:     Found new best model at epoch 0
2022-12-31 15:42:23,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:23,792 INFO:     Epoch: 1
2022-12-31 15:42:25,432 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5704047381877899, 'Total loss': 0.5704047381877899} | train loss {'Reaction outcome loss': 0.6085602907409918, 'Total loss': 0.6085602907409918}
2022-12-31 15:42:25,432 INFO:     Found new best model at epoch 1
2022-12-31 15:42:25,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:25,433 INFO:     Epoch: 2
2022-12-31 15:42:27,019 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5435177783171335, 'Total loss': 0.5435177783171335} | train loss {'Reaction outcome loss': 0.5372468243906463, 'Total loss': 0.5372468243906463}
2022-12-31 15:42:27,019 INFO:     Found new best model at epoch 2
2022-12-31 15:42:27,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:27,020 INFO:     Epoch: 3
2022-12-31 15:42:28,639 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4943423201640447, 'Total loss': 0.4943423201640447} | train loss {'Reaction outcome loss': 0.5257536272680305, 'Total loss': 0.5257536272680305}
2022-12-31 15:42:28,639 INFO:     Found new best model at epoch 3
2022-12-31 15:42:28,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:28,640 INFO:     Epoch: 4
2022-12-31 15:42:30,249 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5196372340122859, 'Total loss': 0.5196372340122859} | train loss {'Reaction outcome loss': 0.49002028856488905, 'Total loss': 0.49002028856488905}
2022-12-31 15:42:30,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:30,249 INFO:     Epoch: 5
2022-12-31 15:42:31,893 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5074904878934224, 'Total loss': 0.5074904878934224} | train loss {'Reaction outcome loss': 0.48086996550462546, 'Total loss': 0.48086996550462546}
2022-12-31 15:42:31,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:31,894 INFO:     Epoch: 6
2022-12-31 15:42:33,538 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5065726419289907, 'Total loss': 0.5065726419289907} | train loss {'Reaction outcome loss': 0.46951339814973914, 'Total loss': 0.46951339814973914}
2022-12-31 15:42:33,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:33,538 INFO:     Epoch: 7
2022-12-31 15:42:35,179 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47459163069725036, 'Total loss': 0.47459163069725036} | train loss {'Reaction outcome loss': 0.4634890976516729, 'Total loss': 0.4634890976516729}
2022-12-31 15:42:35,179 INFO:     Found new best model at epoch 7
2022-12-31 15:42:35,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:35,180 INFO:     Epoch: 8
2022-12-31 15:42:36,771 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48600971897443135, 'Total loss': 0.48600971897443135} | train loss {'Reaction outcome loss': 0.45533281539404846, 'Total loss': 0.45533281539404846}
2022-12-31 15:42:36,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:36,771 INFO:     Epoch: 9
2022-12-31 15:42:38,376 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4732790847619375, 'Total loss': 0.4732790847619375} | train loss {'Reaction outcome loss': 0.45614523417653813, 'Total loss': 0.45614523417653813}
2022-12-31 15:42:38,376 INFO:     Found new best model at epoch 9
2022-12-31 15:42:38,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:38,377 INFO:     Epoch: 10
2022-12-31 15:42:39,997 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5390982786814372, 'Total loss': 0.5390982786814372} | train loss {'Reaction outcome loss': 0.4472114033997059, 'Total loss': 0.4472114033997059}
2022-12-31 15:42:39,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:39,998 INFO:     Epoch: 11
2022-12-31 15:42:41,598 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4803603063027064, 'Total loss': 0.4803603063027064} | train loss {'Reaction outcome loss': 0.496894525151615, 'Total loss': 0.496894525151615}
2022-12-31 15:42:41,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:41,598 INFO:     Epoch: 12
2022-12-31 15:42:43,198 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.453228892882665, 'Total loss': 0.453228892882665} | train loss {'Reaction outcome loss': 0.44172892517045786, 'Total loss': 0.44172892517045786}
2022-12-31 15:42:43,198 INFO:     Found new best model at epoch 12
2022-12-31 15:42:43,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:43,199 INFO:     Epoch: 13
2022-12-31 15:42:44,830 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45784854888916016, 'Total loss': 0.45784854888916016} | train loss {'Reaction outcome loss': 0.4312058208177906, 'Total loss': 0.4312058208177906}
2022-12-31 15:42:44,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:44,830 INFO:     Epoch: 14
2022-12-31 15:42:46,084 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.470962131023407, 'Total loss': 0.470962131023407} | train loss {'Reaction outcome loss': 0.4242603654527794, 'Total loss': 0.4242603654527794}
2022-12-31 15:42:46,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:46,085 INFO:     Epoch: 15
2022-12-31 15:42:47,161 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47066130439440407, 'Total loss': 0.47066130439440407} | train loss {'Reaction outcome loss': 0.41820844387014705, 'Total loss': 0.41820844387014705}
2022-12-31 15:42:47,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:47,161 INFO:     Epoch: 16
2022-12-31 15:42:48,215 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42031275828679404, 'Total loss': 0.42031275828679404} | train loss {'Reaction outcome loss': 0.4118814353331918, 'Total loss': 0.4118814353331918}
2022-12-31 15:42:48,215 INFO:     Found new best model at epoch 16
2022-12-31 15:42:48,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:48,216 INFO:     Epoch: 17
2022-12-31 15:42:49,274 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4568765347202619, 'Total loss': 0.4568765347202619} | train loss {'Reaction outcome loss': 0.4057627018082185, 'Total loss': 0.4057627018082185}
2022-12-31 15:42:49,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:49,274 INFO:     Epoch: 18
2022-12-31 15:42:50,533 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.473509023586909, 'Total loss': 0.473509023586909} | train loss {'Reaction outcome loss': 0.3966798330724671, 'Total loss': 0.3966798330724671}
2022-12-31 15:42:50,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:50,533 INFO:     Epoch: 19
2022-12-31 15:42:52,157 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4395125339428584, 'Total loss': 0.4395125339428584} | train loss {'Reaction outcome loss': 0.4090697002475676, 'Total loss': 0.4090697002475676}
2022-12-31 15:42:52,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:52,158 INFO:     Epoch: 20
2022-12-31 15:42:53,756 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42269300123055775, 'Total loss': 0.42269300123055775} | train loss {'Reaction outcome loss': 0.4264748819894495, 'Total loss': 0.4264748819894495}
2022-12-31 15:42:53,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:53,757 INFO:     Epoch: 21
2022-12-31 15:42:55,370 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45598731487989425, 'Total loss': 0.45598731487989425} | train loss {'Reaction outcome loss': 0.3854006050303038, 'Total loss': 0.3854006050303038}
2022-12-31 15:42:55,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:55,370 INFO:     Epoch: 22
2022-12-31 15:42:56,985 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4291314830382665, 'Total loss': 0.4291314830382665} | train loss {'Reaction outcome loss': 0.3769772658833181, 'Total loss': 0.3769772658833181}
2022-12-31 15:42:56,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:56,985 INFO:     Epoch: 23
2022-12-31 15:42:58,618 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42071680128574374, 'Total loss': 0.42071680128574374} | train loss {'Reaction outcome loss': 0.3673941053760548, 'Total loss': 0.3673941053760548}
2022-12-31 15:42:58,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:42:58,618 INFO:     Epoch: 24
2022-12-31 15:43:00,224 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4363915205001831, 'Total loss': 0.4363915205001831} | train loss {'Reaction outcome loss': 0.3639288544047462, 'Total loss': 0.3639288544047462}
2022-12-31 15:43:00,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:00,224 INFO:     Epoch: 25
2022-12-31 15:43:01,827 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45158004959424336, 'Total loss': 0.45158004959424336} | train loss {'Reaction outcome loss': 0.36068279558421107, 'Total loss': 0.36068279558421107}
2022-12-31 15:43:01,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:01,827 INFO:     Epoch: 26
2022-12-31 15:43:03,418 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.36072176893552144, 'Total loss': 0.36072176893552144} | train loss {'Reaction outcome loss': 0.35201562647125684, 'Total loss': 0.35201562647125684}
2022-12-31 15:43:03,418 INFO:     Found new best model at epoch 26
2022-12-31 15:43:03,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:03,419 INFO:     Epoch: 27
2022-12-31 15:43:05,022 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4124151607354482, 'Total loss': 0.4124151607354482} | train loss {'Reaction outcome loss': 0.34810168619362125, 'Total loss': 0.34810168619362125}
2022-12-31 15:43:05,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:05,022 INFO:     Epoch: 28
2022-12-31 15:43:06,623 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.37628112236658734, 'Total loss': 0.37628112236658734} | train loss {'Reaction outcome loss': 0.3407576784754739, 'Total loss': 0.3407576784754739}
2022-12-31 15:43:06,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:06,624 INFO:     Epoch: 29
2022-12-31 15:43:08,216 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4256081839402517, 'Total loss': 0.4256081839402517} | train loss {'Reaction outcome loss': 0.34225900374028995, 'Total loss': 0.34225900374028995}
2022-12-31 15:43:08,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:08,217 INFO:     Epoch: 30
2022-12-31 15:43:09,853 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4103418156504631, 'Total loss': 0.4103418156504631} | train loss {'Reaction outcome loss': 0.35355686121687724, 'Total loss': 0.35355686121687724}
2022-12-31 15:43:09,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:09,853 INFO:     Epoch: 31
2022-12-31 15:43:11,464 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3984400729338328, 'Total loss': 0.3984400729338328} | train loss {'Reaction outcome loss': 0.3307709910137498, 'Total loss': 0.3307709910137498}
2022-12-31 15:43:11,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:11,465 INFO:     Epoch: 32
2022-12-31 15:43:13,094 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4523208806912104, 'Total loss': 0.4523208806912104} | train loss {'Reaction outcome loss': 0.33337113447487354, 'Total loss': 0.33337113447487354}
2022-12-31 15:43:13,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:13,095 INFO:     Epoch: 33
2022-12-31 15:43:14,748 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4158251037200292, 'Total loss': 0.4158251037200292} | train loss {'Reaction outcome loss': 0.357348254898671, 'Total loss': 0.357348254898671}
2022-12-31 15:43:14,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:14,748 INFO:     Epoch: 34
2022-12-31 15:43:16,387 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43639136056105293, 'Total loss': 0.43639136056105293} | train loss {'Reaction outcome loss': 0.32000725505792577, 'Total loss': 0.32000725505792577}
2022-12-31 15:43:16,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:16,388 INFO:     Epoch: 35
2022-12-31 15:43:17,974 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4006141126155853, 'Total loss': 0.4006141126155853} | train loss {'Reaction outcome loss': 0.34081881975778716, 'Total loss': 0.34081881975778716}
2022-12-31 15:43:17,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:17,974 INFO:     Epoch: 36
2022-12-31 15:43:19,576 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40924556155999503, 'Total loss': 0.40924556155999503} | train loss {'Reaction outcome loss': 0.3077630336055586, 'Total loss': 0.3077630336055586}
2022-12-31 15:43:19,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:19,576 INFO:     Epoch: 37
2022-12-31 15:43:21,223 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.35460996677478157, 'Total loss': 0.35460996677478157} | train loss {'Reaction outcome loss': 0.30971525855851645, 'Total loss': 0.30971525855851645}
2022-12-31 15:43:21,223 INFO:     Found new best model at epoch 37
2022-12-31 15:43:21,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:21,224 INFO:     Epoch: 38
2022-12-31 15:43:22,847 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42750657399495445, 'Total loss': 0.42750657399495445} | train loss {'Reaction outcome loss': 0.30222246554014576, 'Total loss': 0.30222246554014576}
2022-12-31 15:43:22,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:22,848 INFO:     Epoch: 39
2022-12-31 15:43:24,461 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4012367308139801, 'Total loss': 0.4012367308139801} | train loss {'Reaction outcome loss': 0.2995731580392559, 'Total loss': 0.2995731580392559}
2022-12-31 15:43:24,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:24,462 INFO:     Epoch: 40
2022-12-31 15:43:26,076 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38308197756608325, 'Total loss': 0.38308197756608325} | train loss {'Reaction outcome loss': 0.2917536665698972, 'Total loss': 0.2917536665698972}
2022-12-31 15:43:26,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:26,076 INFO:     Epoch: 41
2022-12-31 15:43:27,677 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42579702933629354, 'Total loss': 0.42579702933629354} | train loss {'Reaction outcome loss': 0.2956229814638694, 'Total loss': 0.2956229814638694}
2022-12-31 15:43:27,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:27,677 INFO:     Epoch: 42
2022-12-31 15:43:29,289 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38988745510578154, 'Total loss': 0.38988745510578154} | train loss {'Reaction outcome loss': 0.2898562408197482, 'Total loss': 0.2898562408197482}
2022-12-31 15:43:29,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:29,289 INFO:     Epoch: 43
2022-12-31 15:43:30,900 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.37841475506623584, 'Total loss': 0.37841475506623584} | train loss {'Reaction outcome loss': 0.29298893074830656, 'Total loss': 0.29298893074830656}
2022-12-31 15:43:30,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:30,901 INFO:     Epoch: 44
2022-12-31 15:43:32,543 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43207550843556725, 'Total loss': 0.43207550843556725} | train loss {'Reaction outcome loss': 0.2877396215698209, 'Total loss': 0.2877396215698209}
2022-12-31 15:43:32,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:32,543 INFO:     Epoch: 45
2022-12-31 15:43:34,159 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38663807610670725, 'Total loss': 0.38663807610670725} | train loss {'Reaction outcome loss': 0.2850019074548323, 'Total loss': 0.2850019074548323}
2022-12-31 15:43:34,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:34,159 INFO:     Epoch: 46
2022-12-31 15:43:35,787 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39097902675469715, 'Total loss': 0.39097902675469715} | train loss {'Reaction outcome loss': 0.2770676286155071, 'Total loss': 0.2770676286155071}
2022-12-31 15:43:35,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:35,788 INFO:     Epoch: 47
2022-12-31 15:43:37,399 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3642687022686005, 'Total loss': 0.3642687022686005} | train loss {'Reaction outcome loss': 0.27242957031948195, 'Total loss': 0.27242957031948195}
2022-12-31 15:43:37,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:37,399 INFO:     Epoch: 48
2022-12-31 15:43:39,011 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3987068990866343, 'Total loss': 0.3987068990866343} | train loss {'Reaction outcome loss': 0.2833255564497001, 'Total loss': 0.2833255564497001}
2022-12-31 15:43:39,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:39,011 INFO:     Epoch: 49
2022-12-31 15:43:40,611 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42040570775667824, 'Total loss': 0.42040570775667824} | train loss {'Reaction outcome loss': 0.2977155615994032, 'Total loss': 0.2977155615994032}
2022-12-31 15:43:40,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:40,611 INFO:     Epoch: 50
2022-12-31 15:43:42,242 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3893548011779785, 'Total loss': 0.3893548011779785} | train loss {'Reaction outcome loss': 0.3337858603057269, 'Total loss': 0.3337858603057269}
2022-12-31 15:43:42,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:42,242 INFO:     Epoch: 51
2022-12-31 15:43:43,855 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3797031770149867, 'Total loss': 0.3797031770149867} | train loss {'Reaction outcome loss': 0.2781150398195546, 'Total loss': 0.2781150398195546}
2022-12-31 15:43:43,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:43,855 INFO:     Epoch: 52
2022-12-31 15:43:45,473 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.34940551469723385, 'Total loss': 0.34940551469723385} | train loss {'Reaction outcome loss': 0.27387522948974685, 'Total loss': 0.27387522948974685}
2022-12-31 15:43:45,473 INFO:     Found new best model at epoch 52
2022-12-31 15:43:45,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:45,474 INFO:     Epoch: 53
2022-12-31 15:43:47,113 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.378188348809878, 'Total loss': 0.378188348809878} | train loss {'Reaction outcome loss': 0.2725279015772369, 'Total loss': 0.2725279015772369}
2022-12-31 15:43:47,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:47,114 INFO:     Epoch: 54
2022-12-31 15:43:48,736 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37816472550233204, 'Total loss': 0.37816472550233204} | train loss {'Reaction outcome loss': 0.3181394569607843, 'Total loss': 0.3181394569607843}
2022-12-31 15:43:48,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:48,736 INFO:     Epoch: 55
2022-12-31 15:43:50,392 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3991587907075882, 'Total loss': 0.3991587907075882} | train loss {'Reaction outcome loss': 0.2645731363782956, 'Total loss': 0.2645731363782956}
2022-12-31 15:43:50,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:50,392 INFO:     Epoch: 56
2022-12-31 15:43:52,020 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4010426451762517, 'Total loss': 0.4010426451762517} | train loss {'Reaction outcome loss': 0.2650960396529864, 'Total loss': 0.2650960396529864}
2022-12-31 15:43:52,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:52,021 INFO:     Epoch: 57
2022-12-31 15:43:53,634 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3668815662463506, 'Total loss': 0.3668815662463506} | train loss {'Reaction outcome loss': 0.2616794986179098, 'Total loss': 0.2616794986179098}
2022-12-31 15:43:53,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:53,634 INFO:     Epoch: 58
2022-12-31 15:43:55,254 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3877133468786875, 'Total loss': 0.3877133468786875} | train loss {'Reaction outcome loss': 0.2539957447001591, 'Total loss': 0.2539957447001591}
2022-12-31 15:43:55,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:55,254 INFO:     Epoch: 59
2022-12-31 15:43:56,873 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.35788124104340874, 'Total loss': 0.35788124104340874} | train loss {'Reaction outcome loss': 0.2557218660452012, 'Total loss': 0.2557218660452012}
2022-12-31 15:43:56,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:56,873 INFO:     Epoch: 60
2022-12-31 15:43:58,487 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3837535614768664, 'Total loss': 0.3837535614768664} | train loss {'Reaction outcome loss': 0.2534388160652336, 'Total loss': 0.2534388160652336}
2022-12-31 15:43:58,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:43:58,487 INFO:     Epoch: 61
2022-12-31 15:44:00,117 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4152095794677734, 'Total loss': 0.4152095794677734} | train loss {'Reaction outcome loss': 0.2556513850093166, 'Total loss': 0.2556513850093166}
2022-12-31 15:44:00,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:00,117 INFO:     Epoch: 62
2022-12-31 15:44:01,769 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38919653246800107, 'Total loss': 0.38919653246800107} | train loss {'Reaction outcome loss': 0.2504218060641796, 'Total loss': 0.2504218060641796}
2022-12-31 15:44:01,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:01,770 INFO:     Epoch: 63
2022-12-31 15:44:03,384 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.35846604307492574, 'Total loss': 0.35846604307492574} | train loss {'Reaction outcome loss': 0.24548097164032684, 'Total loss': 0.24548097164032684}
2022-12-31 15:44:03,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:03,384 INFO:     Epoch: 64
2022-12-31 15:44:05,037 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37345281839370725, 'Total loss': 0.37345281839370725} | train loss {'Reaction outcome loss': 0.24574342656474008, 'Total loss': 0.24574342656474008}
2022-12-31 15:44:05,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:05,037 INFO:     Epoch: 65
2022-12-31 15:44:06,695 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37051160633563995, 'Total loss': 0.37051160633563995} | train loss {'Reaction outcome loss': 0.24565588427282384, 'Total loss': 0.24565588427282384}
2022-12-31 15:44:06,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:06,696 INFO:     Epoch: 66
2022-12-31 15:44:08,297 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39102652470270793, 'Total loss': 0.39102652470270793} | train loss {'Reaction outcome loss': 0.24537807124400296, 'Total loss': 0.24537807124400296}
2022-12-31 15:44:08,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:08,297 INFO:     Epoch: 67
2022-12-31 15:44:09,909 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40830793579419455, 'Total loss': 0.40830793579419455} | train loss {'Reaction outcome loss': 0.24532560428496505, 'Total loss': 0.24532560428496505}
2022-12-31 15:44:09,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:09,910 INFO:     Epoch: 68
2022-12-31 15:44:11,524 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3785179073611895, 'Total loss': 0.3785179073611895} | train loss {'Reaction outcome loss': 0.2491844111473124, 'Total loss': 0.2491844111473124}
2022-12-31 15:44:11,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:11,525 INFO:     Epoch: 69
2022-12-31 15:44:13,156 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39138775343696275, 'Total loss': 0.39138775343696275} | train loss {'Reaction outcome loss': 0.23145918567340984, 'Total loss': 0.23145918567340984}
2022-12-31 15:44:13,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:13,156 INFO:     Epoch: 70
2022-12-31 15:44:14,805 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4149415026108424, 'Total loss': 0.4149415026108424} | train loss {'Reaction outcome loss': 0.23426144264985982, 'Total loss': 0.23426144264985982}
2022-12-31 15:44:14,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:14,805 INFO:     Epoch: 71
2022-12-31 15:44:16,430 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4411932686964671, 'Total loss': 0.4411932686964671} | train loss {'Reaction outcome loss': 0.2431844364032588, 'Total loss': 0.2431844364032588}
2022-12-31 15:44:16,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:16,430 INFO:     Epoch: 72
2022-12-31 15:44:18,077 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39893584648768105, 'Total loss': 0.39893584648768105} | train loss {'Reaction outcome loss': 0.24159007480509742, 'Total loss': 0.24159007480509742}
2022-12-31 15:44:18,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:18,078 INFO:     Epoch: 73
2022-12-31 15:44:19,732 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37644179264704386, 'Total loss': 0.37644179264704386} | train loss {'Reaction outcome loss': 0.23389132625854234, 'Total loss': 0.23389132625854234}
2022-12-31 15:44:19,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:19,732 INFO:     Epoch: 74
2022-12-31 15:44:21,334 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40515174468358356, 'Total loss': 0.40515174468358356} | train loss {'Reaction outcome loss': 0.22972637253806696, 'Total loss': 0.22972637253806696}
2022-12-31 15:44:21,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:21,335 INFO:     Epoch: 75
2022-12-31 15:44:22,986 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41333011984825135, 'Total loss': 0.41333011984825135} | train loss {'Reaction outcome loss': 0.22930761329073415, 'Total loss': 0.22930761329073415}
2022-12-31 15:44:22,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:22,986 INFO:     Epoch: 76
2022-12-31 15:44:24,623 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4149992227554321, 'Total loss': 0.4149992227554321} | train loss {'Reaction outcome loss': 0.23502819142911746, 'Total loss': 0.23502819142911746}
2022-12-31 15:44:24,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:24,624 INFO:     Epoch: 77
2022-12-31 15:44:26,251 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3762760395805041, 'Total loss': 0.3762760395805041} | train loss {'Reaction outcome loss': 0.26091532458456745, 'Total loss': 0.26091532458456745}
2022-12-31 15:44:26,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:26,252 INFO:     Epoch: 78
2022-12-31 15:44:27,892 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39589446981747944, 'Total loss': 0.39589446981747944} | train loss {'Reaction outcome loss': 0.2305915185817234, 'Total loss': 0.2305915185817234}
2022-12-31 15:44:27,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:27,892 INFO:     Epoch: 79
2022-12-31 15:44:29,531 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.392940092086792, 'Total loss': 0.392940092086792} | train loss {'Reaction outcome loss': 0.2289610623071591, 'Total loss': 0.2289610623071591}
2022-12-31 15:44:29,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:29,532 INFO:     Epoch: 80
2022-12-31 15:44:31,157 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4046651581923167, 'Total loss': 0.4046651581923167} | train loss {'Reaction outcome loss': 0.22655781262479993, 'Total loss': 0.22655781262479993}
2022-12-31 15:44:31,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:31,157 INFO:     Epoch: 81
2022-12-31 15:44:32,769 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3867186576128006, 'Total loss': 0.3867186576128006} | train loss {'Reaction outcome loss': 0.2213722645824748, 'Total loss': 0.2213722645824748}
2022-12-31 15:44:32,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:32,769 INFO:     Epoch: 82
2022-12-31 15:44:34,375 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3671826769908269, 'Total loss': 0.3671826769908269} | train loss {'Reaction outcome loss': 0.22681376582308524, 'Total loss': 0.22681376582308524}
2022-12-31 15:44:34,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:34,375 INFO:     Epoch: 83
2022-12-31 15:44:36,026 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.35018463631471, 'Total loss': 0.35018463631471} | train loss {'Reaction outcome loss': 0.2184337837055521, 'Total loss': 0.2184337837055521}
2022-12-31 15:44:36,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:36,026 INFO:     Epoch: 84
2022-12-31 15:44:37,655 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.376632005472978, 'Total loss': 0.376632005472978} | train loss {'Reaction outcome loss': 0.21992456298861382, 'Total loss': 0.21992456298861382}
2022-12-31 15:44:37,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:37,656 INFO:     Epoch: 85
2022-12-31 15:44:39,263 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3706512192885081, 'Total loss': 0.3706512192885081} | train loss {'Reaction outcome loss': 0.217556176372929, 'Total loss': 0.217556176372929}
2022-12-31 15:44:39,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:39,263 INFO:     Epoch: 86
2022-12-31 15:44:40,887 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38534129162629444, 'Total loss': 0.38534129162629444} | train loss {'Reaction outcome loss': 0.2187078840004793, 'Total loss': 0.2187078840004793}
2022-12-31 15:44:40,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:40,888 INFO:     Epoch: 87
2022-12-31 15:44:42,529 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3784759700298309, 'Total loss': 0.3784759700298309} | train loss {'Reaction outcome loss': 0.2246374493782017, 'Total loss': 0.2246374493782017}
2022-12-31 15:44:42,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:42,529 INFO:     Epoch: 88
2022-12-31 15:44:44,157 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4129969716072083, 'Total loss': 0.4129969716072083} | train loss {'Reaction outcome loss': 0.2162759739229037, 'Total loss': 0.2162759739229037}
2022-12-31 15:44:44,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:44,157 INFO:     Epoch: 89
2022-12-31 15:44:45,781 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4144438644250234, 'Total loss': 0.4144438644250234} | train loss {'Reaction outcome loss': 0.2143567782064117, 'Total loss': 0.2143567782064117}
2022-12-31 15:44:45,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:45,781 INFO:     Epoch: 90
2022-12-31 15:44:47,390 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.37432383596897123, 'Total loss': 0.37432383596897123} | train loss {'Reaction outcome loss': 0.221767988122588, 'Total loss': 0.221767988122588}
2022-12-31 15:44:47,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:47,391 INFO:     Epoch: 91
2022-12-31 15:44:49,020 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39076571265856425, 'Total loss': 0.39076571265856425} | train loss {'Reaction outcome loss': 0.20726033474296646, 'Total loss': 0.20726033474296646}
2022-12-31 15:44:49,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:49,021 INFO:     Epoch: 92
2022-12-31 15:44:50,665 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40751901467641194, 'Total loss': 0.40751901467641194} | train loss {'Reaction outcome loss': 0.2242364478392699, 'Total loss': 0.2242364478392699}
2022-12-31 15:44:50,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:50,665 INFO:     Epoch: 93
2022-12-31 15:44:52,320 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4452215373516083, 'Total loss': 0.4452215373516083} | train loss {'Reaction outcome loss': 0.21526857396668714, 'Total loss': 0.21526857396668714}
2022-12-31 15:44:52,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:52,320 INFO:     Epoch: 94
2022-12-31 15:44:53,952 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39648485084374746, 'Total loss': 0.39648485084374746} | train loss {'Reaction outcome loss': 0.255071027303437, 'Total loss': 0.255071027303437}
2022-12-31 15:44:53,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:53,952 INFO:     Epoch: 95
2022-12-31 15:44:55,598 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4191618492205938, 'Total loss': 0.4191618492205938} | train loss {'Reaction outcome loss': 0.21161923481744505, 'Total loss': 0.21161923481744505}
2022-12-31 15:44:55,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:55,599 INFO:     Epoch: 96
2022-12-31 15:44:57,231 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3753163715203603, 'Total loss': 0.3753163715203603} | train loss {'Reaction outcome loss': 0.2142495913532279, 'Total loss': 0.2142495913532279}
2022-12-31 15:44:57,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:57,232 INFO:     Epoch: 97
2022-12-31 15:44:58,852 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38147299985090893, 'Total loss': 0.38147299985090893} | train loss {'Reaction outcome loss': 0.21022824900548742, 'Total loss': 0.21022824900548742}
2022-12-31 15:44:58,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:44:58,852 INFO:     Epoch: 98
2022-12-31 15:45:00,501 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39838009476661684, 'Total loss': 0.39838009476661684} | train loss {'Reaction outcome loss': 0.21328276855806969, 'Total loss': 0.21328276855806969}
2022-12-31 15:45:00,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:00,501 INFO:     Epoch: 99
2022-12-31 15:45:02,126 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42507498562335966, 'Total loss': 0.42507498562335966} | train loss {'Reaction outcome loss': 0.2077847280517639, 'Total loss': 0.2077847280517639}
2022-12-31 15:45:02,127 INFO:     Best model found after epoch 53 of 100.
2022-12-31 15:45:02,127 INFO:   Done with stage: TRAINING
2022-12-31 15:45:02,127 INFO:   Starting stage: EVALUATION
2022-12-31 15:45:02,255 INFO:   Done with stage: EVALUATION
2022-12-31 15:45:02,255 INFO:   Leaving out SEQ value Fold_9
2022-12-31 15:45:02,268 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 15:45:02,268 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:45:02,918 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:45:02,918 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:45:02,987 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:45:02,987 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:45:02,987 INFO:     No hyperparam tuning for this model
2022-12-31 15:45:02,987 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:45:02,987 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:45:02,988 INFO:     None feature selector for col prot
2022-12-31 15:45:02,988 INFO:     None feature selector for col prot
2022-12-31 15:45:02,988 INFO:     None feature selector for col prot
2022-12-31 15:45:02,989 INFO:     None feature selector for col chem
2022-12-31 15:45:02,989 INFO:     None feature selector for col chem
2022-12-31 15:45:02,989 INFO:     None feature selector for col chem
2022-12-31 15:45:02,989 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:45:02,989 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:45:02,991 INFO:     Number of params in model 223921
2022-12-31 15:45:02,994 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:45:02,994 INFO:   Starting stage: TRAINING
2022-12-31 15:45:03,040 INFO:     Val loss before train {'Reaction outcome loss': 0.9962918440500895, 'Total loss': 0.9962918440500895}
2022-12-31 15:45:03,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:03,041 INFO:     Epoch: 0
2022-12-31 15:45:04,702 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7031247973442077, 'Total loss': 0.7031247973442077} | train loss {'Reaction outcome loss': 0.8184313609496782, 'Total loss': 0.8184313609496782}
2022-12-31 15:45:04,702 INFO:     Found new best model at epoch 0
2022-12-31 15:45:04,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:04,703 INFO:     Epoch: 1
2022-12-31 15:45:06,365 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.527260293563207, 'Total loss': 0.527260293563207} | train loss {'Reaction outcome loss': 0.6149993043944293, 'Total loss': 0.6149993043944293}
2022-12-31 15:45:06,366 INFO:     Found new best model at epoch 1
2022-12-31 15:45:06,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:06,367 INFO:     Epoch: 2
2022-12-31 15:45:08,005 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5117271463076274, 'Total loss': 0.5117271463076274} | train loss {'Reaction outcome loss': 0.5345717898775094, 'Total loss': 0.5345717898775094}
2022-12-31 15:45:08,005 INFO:     Found new best model at epoch 2
2022-12-31 15:45:08,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:08,006 INFO:     Epoch: 3
2022-12-31 15:45:09,649 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5763397177060445, 'Total loss': 0.5763397177060445} | train loss {'Reaction outcome loss': 0.5104582846057114, 'Total loss': 0.5104582846057114}
2022-12-31 15:45:09,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:09,650 INFO:     Epoch: 4
2022-12-31 15:45:11,269 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4799716591835022, 'Total loss': 0.4799716591835022} | train loss {'Reaction outcome loss': 0.4959464133431335, 'Total loss': 0.4959464133431335}
2022-12-31 15:45:11,269 INFO:     Found new best model at epoch 4
2022-12-31 15:45:11,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:11,270 INFO:     Epoch: 5
2022-12-31 15:45:12,920 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47207638025283816, 'Total loss': 0.47207638025283816} | train loss {'Reaction outcome loss': 0.4816423510386195, 'Total loss': 0.4816423510386195}
2022-12-31 15:45:12,921 INFO:     Found new best model at epoch 5
2022-12-31 15:45:12,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:12,922 INFO:     Epoch: 6
2022-12-31 15:45:14,568 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4827169636885325, 'Total loss': 0.4827169636885325} | train loss {'Reaction outcome loss': 0.4780666805023751, 'Total loss': 0.4780666805023751}
2022-12-31 15:45:14,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:14,569 INFO:     Epoch: 7
2022-12-31 15:45:16,200 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4528141995271047, 'Total loss': 0.4528141995271047} | train loss {'Reaction outcome loss': 0.4657651167699146, 'Total loss': 0.4657651167699146}
2022-12-31 15:45:16,200 INFO:     Found new best model at epoch 7
2022-12-31 15:45:16,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:16,201 INFO:     Epoch: 8
2022-12-31 15:45:17,820 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4634354869524638, 'Total loss': 0.4634354869524638} | train loss {'Reaction outcome loss': 0.4601128206248748, 'Total loss': 0.4601128206248748}
2022-12-31 15:45:17,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:17,820 INFO:     Epoch: 9
2022-12-31 15:45:19,463 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43757501244544983, 'Total loss': 0.43757501244544983} | train loss {'Reaction outcome loss': 0.4526128505864298, 'Total loss': 0.4526128505864298}
2022-12-31 15:45:19,463 INFO:     Found new best model at epoch 9
2022-12-31 15:45:19,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:19,464 INFO:     Epoch: 10
2022-12-31 15:45:21,078 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4542993406454722, 'Total loss': 0.4542993406454722} | train loss {'Reaction outcome loss': 0.4454128970845942, 'Total loss': 0.4454128970845942}
2022-12-31 15:45:21,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:21,078 INFO:     Epoch: 11
2022-12-31 15:45:22,712 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4493232250213623, 'Total loss': 0.4493232250213623} | train loss {'Reaction outcome loss': 0.4370206809108438, 'Total loss': 0.4370206809108438}
2022-12-31 15:45:22,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:22,712 INFO:     Epoch: 12
2022-12-31 15:45:24,341 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45340855916341144, 'Total loss': 0.45340855916341144} | train loss {'Reaction outcome loss': 0.4326069052684178, 'Total loss': 0.4326069052684178}
2022-12-31 15:45:24,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:24,343 INFO:     Epoch: 13
2022-12-31 15:45:25,965 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4570519715547562, 'Total loss': 0.4570519715547562} | train loss {'Reaction outcome loss': 0.4239064242542866, 'Total loss': 0.4239064242542866}
2022-12-31 15:45:25,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:25,965 INFO:     Epoch: 14
2022-12-31 15:45:27,597 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43898895184199016, 'Total loss': 0.43898895184199016} | train loss {'Reaction outcome loss': 0.42516825297033745, 'Total loss': 0.42516825297033745}
2022-12-31 15:45:27,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:27,598 INFO:     Epoch: 15
2022-12-31 15:45:29,206 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4609673102696737, 'Total loss': 0.4609673102696737} | train loss {'Reaction outcome loss': 0.41540278370630007, 'Total loss': 0.41540278370630007}
2022-12-31 15:45:29,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:29,206 INFO:     Epoch: 16
2022-12-31 15:45:30,838 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41808379292488096, 'Total loss': 0.41808379292488096} | train loss {'Reaction outcome loss': 0.4103327176066297, 'Total loss': 0.4103327176066297}
2022-12-31 15:45:30,839 INFO:     Found new best model at epoch 16
2022-12-31 15:45:30,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:30,840 INFO:     Epoch: 17
2022-12-31 15:45:32,474 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44076263904571533, 'Total loss': 0.44076263904571533} | train loss {'Reaction outcome loss': 0.4100638173439873, 'Total loss': 0.4100638173439873}
2022-12-31 15:45:32,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:32,475 INFO:     Epoch: 18
2022-12-31 15:45:34,080 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4248566389083862, 'Total loss': 0.4248566389083862} | train loss {'Reaction outcome loss': 0.4009355173752196, 'Total loss': 0.4009355173752196}
2022-12-31 15:45:34,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:34,081 INFO:     Epoch: 19
2022-12-31 15:45:35,686 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45226648449897766, 'Total loss': 0.45226648449897766} | train loss {'Reaction outcome loss': 0.3977081042711055, 'Total loss': 0.3977081042711055}
2022-12-31 15:45:35,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:35,686 INFO:     Epoch: 20
2022-12-31 15:45:37,327 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4424513300259908, 'Total loss': 0.4424513300259908} | train loss {'Reaction outcome loss': 0.39918361545039427, 'Total loss': 0.39918361545039427}
2022-12-31 15:45:37,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:37,327 INFO:     Epoch: 21
2022-12-31 15:45:38,928 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4251954744259516, 'Total loss': 0.4251954744259516} | train loss {'Reaction outcome loss': 0.38701723494469475, 'Total loss': 0.38701723494469475}
2022-12-31 15:45:38,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:38,928 INFO:     Epoch: 22
2022-12-31 15:45:40,544 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38856007158756256, 'Total loss': 0.38856007158756256} | train loss {'Reaction outcome loss': 0.3758967459632171, 'Total loss': 0.3758967459632171}
2022-12-31 15:45:40,544 INFO:     Found new best model at epoch 22
2022-12-31 15:45:40,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:40,545 INFO:     Epoch: 23
2022-12-31 15:45:42,162 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40694887240727745, 'Total loss': 0.40694887240727745} | train loss {'Reaction outcome loss': 0.3819793360812139, 'Total loss': 0.3819793360812139}
2022-12-31 15:45:42,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:42,162 INFO:     Epoch: 24
2022-12-31 15:45:43,765 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4708374202251434, 'Total loss': 0.4708374202251434} | train loss {'Reaction outcome loss': 0.36580946812883613, 'Total loss': 0.36580946812883613}
2022-12-31 15:45:43,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:43,765 INFO:     Epoch: 25
2022-12-31 15:45:45,363 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4054683665434519, 'Total loss': 0.4054683665434519} | train loss {'Reaction outcome loss': 0.36492483734761766, 'Total loss': 0.36492483734761766}
2022-12-31 15:45:45,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:45,363 INFO:     Epoch: 26
2022-12-31 15:45:46,976 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39827923675378163, 'Total loss': 0.39827923675378163} | train loss {'Reaction outcome loss': 0.36121763579466715, 'Total loss': 0.36121763579466715}
2022-12-31 15:45:46,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:46,977 INFO:     Epoch: 27
2022-12-31 15:45:48,607 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4095301936070124, 'Total loss': 0.4095301936070124} | train loss {'Reaction outcome loss': 0.35860351322467576, 'Total loss': 0.35860351322467576}
2022-12-31 15:45:48,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:48,608 INFO:     Epoch: 28
2022-12-31 15:45:50,255 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3853564043839773, 'Total loss': 0.3853564043839773} | train loss {'Reaction outcome loss': 0.350507527858772, 'Total loss': 0.350507527858772}
2022-12-31 15:45:50,255 INFO:     Found new best model at epoch 28
2022-12-31 15:45:50,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:50,256 INFO:     Epoch: 29
2022-12-31 15:45:51,868 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4285474677880605, 'Total loss': 0.4285474677880605} | train loss {'Reaction outcome loss': 0.3538281181390105, 'Total loss': 0.3538281181390105}
2022-12-31 15:45:51,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:51,868 INFO:     Epoch: 30
2022-12-31 15:45:53,475 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38538356125354767, 'Total loss': 0.38538356125354767} | train loss {'Reaction outcome loss': 0.34807113056417405, 'Total loss': 0.34807113056417405}
2022-12-31 15:45:53,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:53,475 INFO:     Epoch: 31
2022-12-31 15:45:55,091 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39087532460689545, 'Total loss': 0.39087532460689545} | train loss {'Reaction outcome loss': 0.34053356273079605, 'Total loss': 0.34053356273079605}
2022-12-31 15:45:55,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:55,092 INFO:     Epoch: 32
2022-12-31 15:45:56,698 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3702344099680583, 'Total loss': 0.3702344099680583} | train loss {'Reaction outcome loss': 0.33987277057627047, 'Total loss': 0.33987277057627047}
2022-12-31 15:45:56,698 INFO:     Found new best model at epoch 32
2022-12-31 15:45:56,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:56,699 INFO:     Epoch: 33
2022-12-31 15:45:58,359 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42584507664044696, 'Total loss': 0.42584507664044696} | train loss {'Reaction outcome loss': 0.33466945978601054, 'Total loss': 0.33466945978601054}
2022-12-31 15:45:58,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:58,359 INFO:     Epoch: 34
2022-12-31 15:45:59,975 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3818297843138377, 'Total loss': 0.3818297843138377} | train loss {'Reaction outcome loss': 0.3249620132228958, 'Total loss': 0.3249620132228958}
2022-12-31 15:45:59,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:45:59,975 INFO:     Epoch: 35
2022-12-31 15:46:01,585 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39035638570785525, 'Total loss': 0.39035638570785525} | train loss {'Reaction outcome loss': 0.3188312773454921, 'Total loss': 0.3188312773454921}
2022-12-31 15:46:01,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:01,586 INFO:     Epoch: 36
2022-12-31 15:46:03,202 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4051431894302368, 'Total loss': 0.4051431894302368} | train loss {'Reaction outcome loss': 0.3202438964525285, 'Total loss': 0.3202438964525285}
2022-12-31 15:46:03,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:03,202 INFO:     Epoch: 37
2022-12-31 15:46:04,818 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38903059586882593, 'Total loss': 0.38903059586882593} | train loss {'Reaction outcome loss': 0.31389711122112585, 'Total loss': 0.31389711122112585}
2022-12-31 15:46:04,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:04,819 INFO:     Epoch: 38
2022-12-31 15:46:06,444 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3538688600063324, 'Total loss': 0.3538688600063324} | train loss {'Reaction outcome loss': 0.316066674888134, 'Total loss': 0.316066674888134}
2022-12-31 15:46:06,444 INFO:     Found new best model at epoch 38
2022-12-31 15:46:06,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:06,445 INFO:     Epoch: 39
2022-12-31 15:46:08,044 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41969514787197115, 'Total loss': 0.41969514787197115} | train loss {'Reaction outcome loss': 0.31033665491839607, 'Total loss': 0.31033665491839607}
2022-12-31 15:46:08,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:08,044 INFO:     Epoch: 40
2022-12-31 15:46:09,694 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37989430824915565, 'Total loss': 0.37989430824915565} | train loss {'Reaction outcome loss': 0.3049814353700364, 'Total loss': 0.3049814353700364}
2022-12-31 15:46:09,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:09,695 INFO:     Epoch: 41
2022-12-31 15:46:11,301 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3859920521577199, 'Total loss': 0.3859920521577199} | train loss {'Reaction outcome loss': 0.30242606966557917, 'Total loss': 0.30242606966557917}
2022-12-31 15:46:11,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:11,301 INFO:     Epoch: 42
2022-12-31 15:46:12,914 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3810805430014928, 'Total loss': 0.3810805430014928} | train loss {'Reaction outcome loss': 0.29563242179553434, 'Total loss': 0.29563242179553434}
2022-12-31 15:46:12,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:12,915 INFO:     Epoch: 43
2022-12-31 15:46:14,510 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41887816588083904, 'Total loss': 0.41887816588083904} | train loss {'Reaction outcome loss': 0.29110349330123153, 'Total loss': 0.29110349330123153}
2022-12-31 15:46:14,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:14,511 INFO:     Epoch: 44
2022-12-31 15:46:16,124 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39422979255517326, 'Total loss': 0.39422979255517326} | train loss {'Reaction outcome loss': 0.28866363663750866, 'Total loss': 0.28866363663750866}
2022-12-31 15:46:16,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:16,124 INFO:     Epoch: 45
2022-12-31 15:46:17,738 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.37765974601109825, 'Total loss': 0.37765974601109825} | train loss {'Reaction outcome loss': 0.2899030122758034, 'Total loss': 0.2899030122758034}
2022-12-31 15:46:17,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:17,738 INFO:     Epoch: 46
2022-12-31 15:46:19,337 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38628808160622913, 'Total loss': 0.38628808160622913} | train loss {'Reaction outcome loss': 0.28461350944390795, 'Total loss': 0.28461350944390795}
2022-12-31 15:46:19,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:19,337 INFO:     Epoch: 47
2022-12-31 15:46:20,956 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3826495716969172, 'Total loss': 0.3826495716969172} | train loss {'Reaction outcome loss': 0.27930130823666655, 'Total loss': 0.27930130823666655}
2022-12-31 15:46:20,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:20,956 INFO:     Epoch: 48
2022-12-31 15:46:22,603 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4105579321583112, 'Total loss': 0.4105579321583112} | train loss {'Reaction outcome loss': 0.27745714655905857, 'Total loss': 0.27745714655905857}
2022-12-31 15:46:22,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:22,603 INFO:     Epoch: 49
2022-12-31 15:46:24,220 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.394249127805233, 'Total loss': 0.394249127805233} | train loss {'Reaction outcome loss': 0.27314408716917143, 'Total loss': 0.27314408716917143}
2022-12-31 15:46:24,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:24,220 INFO:     Epoch: 50
2022-12-31 15:46:25,838 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3814562400182088, 'Total loss': 0.3814562400182088} | train loss {'Reaction outcome loss': 0.2732408185513011, 'Total loss': 0.2732408185513011}
2022-12-31 15:46:25,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:25,839 INFO:     Epoch: 51
2022-12-31 15:46:27,452 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3803375045458476, 'Total loss': 0.3803375045458476} | train loss {'Reaction outcome loss': 0.2722927910084113, 'Total loss': 0.2722927910084113}
2022-12-31 15:46:27,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:27,452 INFO:     Epoch: 52
2022-12-31 15:46:29,072 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3969101866086324, 'Total loss': 0.3969101866086324} | train loss {'Reaction outcome loss': 0.26719694936964056, 'Total loss': 0.26719694936964056}
2022-12-31 15:46:29,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:29,073 INFO:     Epoch: 53
2022-12-31 15:46:30,729 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4073825498421987, 'Total loss': 0.4073825498421987} | train loss {'Reaction outcome loss': 0.2664159982455121, 'Total loss': 0.2664159982455121}
2022-12-31 15:46:30,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:30,729 INFO:     Epoch: 54
2022-12-31 15:46:32,360 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38731577396392824, 'Total loss': 0.38731577396392824} | train loss {'Reaction outcome loss': 0.2596477349877142, 'Total loss': 0.2596477349877142}
2022-12-31 15:46:32,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:32,360 INFO:     Epoch: 55
2022-12-31 15:46:33,991 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4009945789972941, 'Total loss': 0.4009945789972941} | train loss {'Reaction outcome loss': 0.26027184863329367, 'Total loss': 0.26027184863329367}
2022-12-31 15:46:33,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:33,991 INFO:     Epoch: 56
2022-12-31 15:46:35,615 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3948946277300517, 'Total loss': 0.3948946277300517} | train loss {'Reaction outcome loss': 0.2645685385764721, 'Total loss': 0.2645685385764721}
2022-12-31 15:46:35,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:35,615 INFO:     Epoch: 57
2022-12-31 15:46:37,232 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37641888360182446, 'Total loss': 0.37641888360182446} | train loss {'Reaction outcome loss': 0.2598786998123253, 'Total loss': 0.2598786998123253}
2022-12-31 15:46:37,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:37,232 INFO:     Epoch: 58
2022-12-31 15:46:38,884 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4247300068537394, 'Total loss': 0.4247300068537394} | train loss {'Reaction outcome loss': 0.2549754535436415, 'Total loss': 0.2549754535436415}
2022-12-31 15:46:38,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:38,884 INFO:     Epoch: 59
2022-12-31 15:46:40,534 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38435881535212196, 'Total loss': 0.38435881535212196} | train loss {'Reaction outcome loss': 0.25570003635213046, 'Total loss': 0.25570003635213046}
2022-12-31 15:46:40,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:40,534 INFO:     Epoch: 60
2022-12-31 15:46:42,162 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39745943546295165, 'Total loss': 0.39745943546295165} | train loss {'Reaction outcome loss': 0.25465885709823255, 'Total loss': 0.25465885709823255}
2022-12-31 15:46:42,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:42,162 INFO:     Epoch: 61
2022-12-31 15:46:43,814 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3804516459504763, 'Total loss': 0.3804516459504763} | train loss {'Reaction outcome loss': 0.24182087076753916, 'Total loss': 0.24182087076753916}
2022-12-31 15:46:43,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:43,814 INFO:     Epoch: 62
2022-12-31 15:46:45,466 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3724440107742945, 'Total loss': 0.3724440107742945} | train loss {'Reaction outcome loss': 0.2527734191469606, 'Total loss': 0.2527734191469606}
2022-12-31 15:46:45,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:45,467 INFO:     Epoch: 63
2022-12-31 15:46:47,064 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38832016636927924, 'Total loss': 0.38832016636927924} | train loss {'Reaction outcome loss': 0.24330553996783516, 'Total loss': 0.24330553996783516}
2022-12-31 15:46:47,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:47,064 INFO:     Epoch: 64
2022-12-31 15:46:48,696 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4131113847096761, 'Total loss': 0.4131113847096761} | train loss {'Reaction outcome loss': 0.24066292230940897, 'Total loss': 0.24066292230940897}
2022-12-31 15:46:48,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:48,696 INFO:     Epoch: 65
2022-12-31 15:46:50,349 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3785315950711568, 'Total loss': 0.3785315950711568} | train loss {'Reaction outcome loss': 0.2500522014775754, 'Total loss': 0.2500522014775754}
2022-12-31 15:46:50,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:50,349 INFO:     Epoch: 66
2022-12-31 15:46:51,953 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37373503744602204, 'Total loss': 0.37373503744602204} | train loss {'Reaction outcome loss': 0.24579773345686468, 'Total loss': 0.24579773345686468}
2022-12-31 15:46:51,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:51,953 INFO:     Epoch: 67
2022-12-31 15:46:53,584 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40070279538631437, 'Total loss': 0.40070279538631437} | train loss {'Reaction outcome loss': 0.23778621283517848, 'Total loss': 0.23778621283517848}
2022-12-31 15:46:53,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:53,584 INFO:     Epoch: 68
2022-12-31 15:46:55,234 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39076052655776344, 'Total loss': 0.39076052655776344} | train loss {'Reaction outcome loss': 0.24047761988096503, 'Total loss': 0.24047761988096503}
2022-12-31 15:46:55,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:55,235 INFO:     Epoch: 69
2022-12-31 15:46:56,867 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41134769916534425, 'Total loss': 0.41134769916534425} | train loss {'Reaction outcome loss': 0.23418108791462566, 'Total loss': 0.23418108791462566}
2022-12-31 15:46:56,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:56,868 INFO:     Epoch: 70
2022-12-31 15:46:58,525 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3881019800901413, 'Total loss': 0.3881019800901413} | train loss {'Reaction outcome loss': 0.2278583734178586, 'Total loss': 0.2278583734178586}
2022-12-31 15:46:58,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:46:58,525 INFO:     Epoch: 71
2022-12-31 15:47:00,156 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3954058587551117, 'Total loss': 0.3954058587551117} | train loss {'Reaction outcome loss': 0.2322541860298721, 'Total loss': 0.2322541860298721}
2022-12-31 15:47:00,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:00,156 INFO:     Epoch: 72
2022-12-31 15:47:01,788 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.373884720603625, 'Total loss': 0.373884720603625} | train loss {'Reaction outcome loss': 0.22803346771034091, 'Total loss': 0.22803346771034091}
2022-12-31 15:47:01,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:01,788 INFO:     Epoch: 73
2022-12-31 15:47:03,445 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40510130127271016, 'Total loss': 0.40510130127271016} | train loss {'Reaction outcome loss': 0.22828882317048654, 'Total loss': 0.22828882317048654}
2022-12-31 15:47:03,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:03,445 INFO:     Epoch: 74
2022-12-31 15:47:05,076 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38750216861565906, 'Total loss': 0.38750216861565906} | train loss {'Reaction outcome loss': 0.22692660108504528, 'Total loss': 0.22692660108504528}
2022-12-31 15:47:05,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:05,076 INFO:     Epoch: 75
2022-12-31 15:47:06,720 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3951317230860392, 'Total loss': 0.3951317230860392} | train loss {'Reaction outcome loss': 0.2289950204307099, 'Total loss': 0.2289950204307099}
2022-12-31 15:47:06,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:06,721 INFO:     Epoch: 76
2022-12-31 15:47:08,371 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3911797265211741, 'Total loss': 0.3911797265211741} | train loss {'Reaction outcome loss': 0.2244563711141421, 'Total loss': 0.2244563711141421}
2022-12-31 15:47:08,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:08,371 INFO:     Epoch: 77
2022-12-31 15:47:09,980 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40595923562844594, 'Total loss': 0.40595923562844594} | train loss {'Reaction outcome loss': 0.22682482269777504, 'Total loss': 0.22682482269777504}
2022-12-31 15:47:09,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:09,981 INFO:     Epoch: 78
2022-12-31 15:47:11,592 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4189496487379074, 'Total loss': 0.4189496487379074} | train loss {'Reaction outcome loss': 0.2233242580687311, 'Total loss': 0.2233242580687311}
2022-12-31 15:47:11,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:11,592 INFO:     Epoch: 79
2022-12-31 15:47:13,215 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4330937405427297, 'Total loss': 0.4330937405427297} | train loss {'Reaction outcome loss': 0.21947191280417064, 'Total loss': 0.21947191280417064}
2022-12-31 15:47:13,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:13,215 INFO:     Epoch: 80
2022-12-31 15:47:14,815 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40973834196726483, 'Total loss': 0.40973834196726483} | train loss {'Reaction outcome loss': 0.2254502411582087, 'Total loss': 0.2254502411582087}
2022-12-31 15:47:14,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:14,815 INFO:     Epoch: 81
2022-12-31 15:47:16,427 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42078180809815724, 'Total loss': 0.42078180809815724} | train loss {'Reaction outcome loss': 0.2208574350640877, 'Total loss': 0.2208574350640877}
2022-12-31 15:47:16,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:16,428 INFO:     Epoch: 82
2022-12-31 15:47:18,050 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4106340905030568, 'Total loss': 0.4106340905030568} | train loss {'Reaction outcome loss': 0.21590091328435856, 'Total loss': 0.21590091328435856}
2022-12-31 15:47:18,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:18,050 INFO:     Epoch: 83
2022-12-31 15:47:19,675 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48686757882436116, 'Total loss': 0.48686757882436116} | train loss {'Reaction outcome loss': 0.21155257415134016, 'Total loss': 0.21155257415134016}
2022-12-31 15:47:19,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:19,675 INFO:     Epoch: 84
2022-12-31 15:47:21,331 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4001980652411779, 'Total loss': 0.4001980652411779} | train loss {'Reaction outcome loss': 0.2173235238956738, 'Total loss': 0.2173235238956738}
2022-12-31 15:47:21,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:21,332 INFO:     Epoch: 85
2022-12-31 15:47:22,963 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43576178749402367, 'Total loss': 0.43576178749402367} | train loss {'Reaction outcome loss': 0.21648346929935341, 'Total loss': 0.21648346929935341}
2022-12-31 15:47:22,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:22,963 INFO:     Epoch: 86
2022-12-31 15:47:24,597 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41210504770278933, 'Total loss': 0.41210504770278933} | train loss {'Reaction outcome loss': 0.21236021967692173, 'Total loss': 0.21236021967692173}
2022-12-31 15:47:24,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:24,597 INFO:     Epoch: 87
2022-12-31 15:47:26,237 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4507454474767049, 'Total loss': 0.4507454474767049} | train loss {'Reaction outcome loss': 0.2101353939743679, 'Total loss': 0.2101353939743679}
2022-12-31 15:47:26,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:26,237 INFO:     Epoch: 88
2022-12-31 15:47:27,835 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4413205474615097, 'Total loss': 0.4413205474615097} | train loss {'Reaction outcome loss': 0.21446166223163854, 'Total loss': 0.21446166223163854}
2022-12-31 15:47:27,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:27,835 INFO:     Epoch: 89
2022-12-31 15:47:29,447 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43864718774954475, 'Total loss': 0.43864718774954475} | train loss {'Reaction outcome loss': 0.21289265011554914, 'Total loss': 0.21289265011554914}
2022-12-31 15:47:29,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:29,448 INFO:     Epoch: 90
2022-12-31 15:47:31,059 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.397625553359588, 'Total loss': 0.397625553359588} | train loss {'Reaction outcome loss': 0.20398089676987824, 'Total loss': 0.20398089676987824}
2022-12-31 15:47:31,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:31,059 INFO:     Epoch: 91
2022-12-31 15:47:32,672 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41346441954374313, 'Total loss': 0.41346441954374313} | train loss {'Reaction outcome loss': 0.20562371994883144, 'Total loss': 0.20562371994883144}
2022-12-31 15:47:32,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:32,673 INFO:     Epoch: 92
2022-12-31 15:47:34,313 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40391602416833244, 'Total loss': 0.40391602416833244} | train loss {'Reaction outcome loss': 0.2144115708351458, 'Total loss': 0.2144115708351458}
2022-12-31 15:47:34,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:34,314 INFO:     Epoch: 93
2022-12-31 15:47:35,935 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4333604296048482, 'Total loss': 0.4333604296048482} | train loss {'Reaction outcome loss': 0.21002888769274478, 'Total loss': 0.21002888769274478}
2022-12-31 15:47:35,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:35,935 INFO:     Epoch: 94
2022-12-31 15:47:37,538 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4017039010922114, 'Total loss': 0.4017039010922114} | train loss {'Reaction outcome loss': 0.20899608444812495, 'Total loss': 0.20899608444812495}
2022-12-31 15:47:37,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:37,538 INFO:     Epoch: 95
2022-12-31 15:47:39,169 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4148339827855428, 'Total loss': 0.4148339827855428} | train loss {'Reaction outcome loss': 0.20879280577255716, 'Total loss': 0.20879280577255716}
2022-12-31 15:47:39,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:39,170 INFO:     Epoch: 96
2022-12-31 15:47:40,797 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4037495026985804, 'Total loss': 0.4037495026985804} | train loss {'Reaction outcome loss': 0.1971397698261785, 'Total loss': 0.1971397698261785}
2022-12-31 15:47:40,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:40,798 INFO:     Epoch: 97
2022-12-31 15:47:42,409 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4597247083981832, 'Total loss': 0.4597247083981832} | train loss {'Reaction outcome loss': 0.19948184205763822, 'Total loss': 0.19948184205763822}
2022-12-31 15:47:42,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:42,409 INFO:     Epoch: 98
2022-12-31 15:47:44,027 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3953472231825193, 'Total loss': 0.3953472231825193} | train loss {'Reaction outcome loss': 0.2057966124266386, 'Total loss': 0.2057966124266386}
2022-12-31 15:47:44,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:44,028 INFO:     Epoch: 99
2022-12-31 15:47:45,654 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3999988347291946, 'Total loss': 0.3999988347291946} | train loss {'Reaction outcome loss': 0.20178853402364771, 'Total loss': 0.20178853402364771}
2022-12-31 15:47:45,654 INFO:     Best model found after epoch 39 of 100.
2022-12-31 15:47:45,654 INFO:   Done with stage: TRAINING
2022-12-31 15:47:45,654 INFO:   Starting stage: EVALUATION
2022-12-31 15:47:45,777 INFO:   Done with stage: EVALUATION
2022-12-31 15:47:45,786 INFO:   Leaving out SEQ value Fold_0
2022-12-31 15:47:45,799 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 15:47:45,799 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:47:46,454 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:47:46,454 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:47:46,523 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:47:46,523 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:47:46,523 INFO:     No hyperparam tuning for this model
2022-12-31 15:47:46,523 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:47:46,523 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:47:46,524 INFO:     None feature selector for col prot
2022-12-31 15:47:46,524 INFO:     None feature selector for col prot
2022-12-31 15:47:46,524 INFO:     None feature selector for col prot
2022-12-31 15:47:46,525 INFO:     None feature selector for col chem
2022-12-31 15:47:46,525 INFO:     None feature selector for col chem
2022-12-31 15:47:46,525 INFO:     None feature selector for col chem
2022-12-31 15:47:46,525 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:47:46,525 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:47:46,527 INFO:     Number of params in model 223921
2022-12-31 15:47:46,530 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:47:46,530 INFO:   Starting stage: TRAINING
2022-12-31 15:47:46,575 INFO:     Val loss before train {'Reaction outcome loss': 0.9413756012916565, 'Total loss': 0.9413756012916565}
2022-12-31 15:47:46,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:46,575 INFO:     Epoch: 0
2022-12-31 15:47:48,225 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6904817561308543, 'Total loss': 0.6904817561308543} | train loss {'Reaction outcome loss': 0.8622198346732319, 'Total loss': 0.8622198346732319}
2022-12-31 15:47:48,225 INFO:     Found new best model at epoch 0
2022-12-31 15:47:48,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:48,226 INFO:     Epoch: 1
2022-12-31 15:47:49,840 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5931632836659749, 'Total loss': 0.5931632836659749} | train loss {'Reaction outcome loss': 0.6266753365812094, 'Total loss': 0.6266753365812094}
2022-12-31 15:47:49,841 INFO:     Found new best model at epoch 1
2022-12-31 15:47:49,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:49,842 INFO:     Epoch: 2
2022-12-31 15:47:51,456 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5786124527454376, 'Total loss': 0.5786124527454376} | train loss {'Reaction outcome loss': 0.5309456433000825, 'Total loss': 0.5309456433000825}
2022-12-31 15:47:51,456 INFO:     Found new best model at epoch 2
2022-12-31 15:47:51,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:51,457 INFO:     Epoch: 3
2022-12-31 15:47:53,082 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.540379802385966, 'Total loss': 0.540379802385966} | train loss {'Reaction outcome loss': 0.5027760398385209, 'Total loss': 0.5027760398385209}
2022-12-31 15:47:53,082 INFO:     Found new best model at epoch 3
2022-12-31 15:47:53,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:53,083 INFO:     Epoch: 4
2022-12-31 15:47:54,687 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5982102235158284, 'Total loss': 0.5982102235158284} | train loss {'Reaction outcome loss': 0.5037178324292535, 'Total loss': 0.5037178324292535}
2022-12-31 15:47:54,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:54,687 INFO:     Epoch: 5
2022-12-31 15:47:56,303 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5697459598382314, 'Total loss': 0.5697459598382314} | train loss {'Reaction outcome loss': 0.5237487439552079, 'Total loss': 0.5237487439552079}
2022-12-31 15:47:56,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:56,303 INFO:     Epoch: 6
2022-12-31 15:47:57,927 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5092866738637288, 'Total loss': 0.5092866738637288} | train loss {'Reaction outcome loss': 0.4966746797596199, 'Total loss': 0.4966746797596199}
2022-12-31 15:47:57,927 INFO:     Found new best model at epoch 6
2022-12-31 15:47:57,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:57,928 INFO:     Epoch: 7
2022-12-31 15:47:59,537 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.560748948653539, 'Total loss': 0.560748948653539} | train loss {'Reaction outcome loss': 0.48283090156273567, 'Total loss': 0.48283090156273567}
2022-12-31 15:47:59,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:47:59,537 INFO:     Epoch: 8
2022-12-31 15:48:01,158 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5318193574746449, 'Total loss': 0.5318193574746449} | train loss {'Reaction outcome loss': 0.5053896058523781, 'Total loss': 0.5053896058523781}
2022-12-31 15:48:01,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:01,158 INFO:     Epoch: 9
2022-12-31 15:48:02,781 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5377224733432134, 'Total loss': 0.5377224733432134} | train loss {'Reaction outcome loss': 0.4509729156135649, 'Total loss': 0.4509729156135649}
2022-12-31 15:48:02,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:02,781 INFO:     Epoch: 10
2022-12-31 15:48:04,380 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5413320004940033, 'Total loss': 0.5413320004940033} | train loss {'Reaction outcome loss': 0.44623524660056463, 'Total loss': 0.44623524660056463}
2022-12-31 15:48:04,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:04,380 INFO:     Epoch: 11
2022-12-31 15:48:05,996 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5458723684151967, 'Total loss': 0.5458723684151967} | train loss {'Reaction outcome loss': 0.4379624735860937, 'Total loss': 0.4379624735860937}
2022-12-31 15:48:05,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:05,997 INFO:     Epoch: 12
2022-12-31 15:48:07,619 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49831098119417827, 'Total loss': 0.49831098119417827} | train loss {'Reaction outcome loss': 0.43112697092937713, 'Total loss': 0.43112697092937713}
2022-12-31 15:48:07,620 INFO:     Found new best model at epoch 12
2022-12-31 15:48:07,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:07,621 INFO:     Epoch: 13
2022-12-31 15:48:09,242 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5048982381820679, 'Total loss': 0.5048982381820679} | train loss {'Reaction outcome loss': 0.4315000789601059, 'Total loss': 0.4315000789601059}
2022-12-31 15:48:09,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:09,243 INFO:     Epoch: 14
2022-12-31 15:48:10,862 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5192113995552063, 'Total loss': 0.5192113995552063} | train loss {'Reaction outcome loss': 0.4271043427828429, 'Total loss': 0.4271043427828429}
2022-12-31 15:48:10,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:10,862 INFO:     Epoch: 15
2022-12-31 15:48:12,465 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5165575742721558, 'Total loss': 0.5165575742721558} | train loss {'Reaction outcome loss': 0.418706389335136, 'Total loss': 0.418706389335136}
2022-12-31 15:48:12,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:12,466 INFO:     Epoch: 16
2022-12-31 15:48:14,084 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5141241689523061, 'Total loss': 0.5141241689523061} | train loss {'Reaction outcome loss': 0.41588652857403824, 'Total loss': 0.41588652857403824}
2022-12-31 15:48:14,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:14,085 INFO:     Epoch: 17
2022-12-31 15:48:15,700 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5401655226945877, 'Total loss': 0.5401655226945877} | train loss {'Reaction outcome loss': 0.4245189156524999, 'Total loss': 0.4245189156524999}
2022-12-31 15:48:15,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:15,700 INFO:     Epoch: 18
2022-12-31 15:48:17,297 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4734666069348653, 'Total loss': 0.4734666069348653} | train loss {'Reaction outcome loss': 0.4142835859944909, 'Total loss': 0.4142835859944909}
2022-12-31 15:48:17,297 INFO:     Found new best model at epoch 18
2022-12-31 15:48:17,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:17,298 INFO:     Epoch: 19
2022-12-31 15:48:18,914 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5212391932805379, 'Total loss': 0.5212391932805379} | train loss {'Reaction outcome loss': 0.40521765069739113, 'Total loss': 0.40521765069739113}
2022-12-31 15:48:18,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:18,914 INFO:     Epoch: 20
2022-12-31 15:48:20,528 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4853124002615611, 'Total loss': 0.4853124002615611} | train loss {'Reaction outcome loss': 0.40185766911431064, 'Total loss': 0.40185766911431064}
2022-12-31 15:48:20,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:20,529 INFO:     Epoch: 21
2022-12-31 15:48:22,140 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4949137171109517, 'Total loss': 0.4949137171109517} | train loss {'Reaction outcome loss': 0.4044760266939799, 'Total loss': 0.4044760266939799}
2022-12-31 15:48:22,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:22,141 INFO:     Epoch: 22
2022-12-31 15:48:23,757 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4911125292380651, 'Total loss': 0.4911125292380651} | train loss {'Reaction outcome loss': 0.41810432563711336, 'Total loss': 0.41810432563711336}
2022-12-31 15:48:23,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:23,757 INFO:     Epoch: 23
2022-12-31 15:48:25,368 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.465257594982783, 'Total loss': 0.465257594982783} | train loss {'Reaction outcome loss': 0.39414117627007805, 'Total loss': 0.39414117627007805}
2022-12-31 15:48:25,368 INFO:     Found new best model at epoch 23
2022-12-31 15:48:25,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:25,369 INFO:     Epoch: 24
2022-12-31 15:48:26,964 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5039173334836959, 'Total loss': 0.5039173334836959} | train loss {'Reaction outcome loss': 0.3891254359674033, 'Total loss': 0.3891254359674033}
2022-12-31 15:48:26,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:26,965 INFO:     Epoch: 25
2022-12-31 15:48:28,583 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46764017442862194, 'Total loss': 0.46764017442862194} | train loss {'Reaction outcome loss': 0.387540543175208, 'Total loss': 0.387540543175208}
2022-12-31 15:48:28,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:28,584 INFO:     Epoch: 26
2022-12-31 15:48:30,194 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49735175967216494, 'Total loss': 0.49735175967216494} | train loss {'Reaction outcome loss': 0.3852011721728427, 'Total loss': 0.3852011721728427}
2022-12-31 15:48:30,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:30,195 INFO:     Epoch: 27
2022-12-31 15:48:31,815 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5110931813716888, 'Total loss': 0.5110931813716888} | train loss {'Reaction outcome loss': 0.3787117974319752, 'Total loss': 0.3787117974319752}
2022-12-31 15:48:31,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:31,815 INFO:     Epoch: 28
2022-12-31 15:48:33,432 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47489422261714936, 'Total loss': 0.47489422261714936} | train loss {'Reaction outcome loss': 0.3848436530774368, 'Total loss': 0.3848436530774368}
2022-12-31 15:48:33,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:33,432 INFO:     Epoch: 29
2022-12-31 15:48:35,029 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.520749443769455, 'Total loss': 0.520749443769455} | train loss {'Reaction outcome loss': 0.37685966354025446, 'Total loss': 0.37685966354025446}
2022-12-31 15:48:35,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:35,030 INFO:     Epoch: 30
2022-12-31 15:48:36,681 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4675256719191869, 'Total loss': 0.4675256719191869} | train loss {'Reaction outcome loss': 0.4084075362138126, 'Total loss': 0.4084075362138126}
2022-12-31 15:48:36,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:36,681 INFO:     Epoch: 31
2022-12-31 15:48:38,316 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48076077103614806, 'Total loss': 0.48076077103614806} | train loss {'Reaction outcome loss': 0.38177536892565683, 'Total loss': 0.38177536892565683}
2022-12-31 15:48:38,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:38,316 INFO:     Epoch: 32
2022-12-31 15:48:39,939 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48219863573710126, 'Total loss': 0.48219863573710126} | train loss {'Reaction outcome loss': 0.36153899872864503, 'Total loss': 0.36153899872864503}
2022-12-31 15:48:39,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:39,940 INFO:     Epoch: 33
2022-12-31 15:48:41,584 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4792785187562307, 'Total loss': 0.4792785187562307} | train loss {'Reaction outcome loss': 0.35842796603421867, 'Total loss': 0.35842796603421867}
2022-12-31 15:48:41,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:41,584 INFO:     Epoch: 34
2022-12-31 15:48:43,222 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4673747797807058, 'Total loss': 0.4673747797807058} | train loss {'Reaction outcome loss': 0.3568856025357609, 'Total loss': 0.3568856025357609}
2022-12-31 15:48:43,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:43,222 INFO:     Epoch: 35
2022-12-31 15:48:44,823 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4828283727169037, 'Total loss': 0.4828283727169037} | train loss {'Reaction outcome loss': 0.3439722180821949, 'Total loss': 0.3439722180821949}
2022-12-31 15:48:44,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:44,825 INFO:     Epoch: 36
2022-12-31 15:48:46,437 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4717253635327021, 'Total loss': 0.4717253635327021} | train loss {'Reaction outcome loss': 0.33826963389731024, 'Total loss': 0.33826963389731024}
2022-12-31 15:48:46,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:46,437 INFO:     Epoch: 37
2022-12-31 15:48:48,050 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.434658678372701, 'Total loss': 0.434658678372701} | train loss {'Reaction outcome loss': 0.33449429579996975, 'Total loss': 0.33449429579996975}
2022-12-31 15:48:48,051 INFO:     Found new best model at epoch 37
2022-12-31 15:48:48,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:48,052 INFO:     Epoch: 38
2022-12-31 15:48:49,678 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5336714347203573, 'Total loss': 0.5336714347203573} | train loss {'Reaction outcome loss': 0.3429362186217222, 'Total loss': 0.3429362186217222}
2022-12-31 15:48:49,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:49,678 INFO:     Epoch: 39
2022-12-31 15:48:51,286 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48424964944521587, 'Total loss': 0.48424964944521587} | train loss {'Reaction outcome loss': 0.3622413729789896, 'Total loss': 0.3622413729789896}
2022-12-31 15:48:51,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:51,287 INFO:     Epoch: 40
2022-12-31 15:48:52,900 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4827109714349111, 'Total loss': 0.4827109714349111} | train loss {'Reaction outcome loss': 0.3326713460619035, 'Total loss': 0.3326713460619035}
2022-12-31 15:48:52,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:52,900 INFO:     Epoch: 41
2022-12-31 15:48:54,499 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47687990168730415, 'Total loss': 0.47687990168730415} | train loss {'Reaction outcome loss': 0.32593963519278646, 'Total loss': 0.32593963519278646}
2022-12-31 15:48:54,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:54,499 INFO:     Epoch: 42
2022-12-31 15:48:56,116 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4788053770860036, 'Total loss': 0.4788053770860036} | train loss {'Reaction outcome loss': 0.3278907990569006, 'Total loss': 0.3278907990569006}
2022-12-31 15:48:56,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:56,116 INFO:     Epoch: 43
2022-12-31 15:48:57,726 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5271712323029836, 'Total loss': 0.5271712323029836} | train loss {'Reaction outcome loss': 0.3230707310140133, 'Total loss': 0.3230707310140133}
2022-12-31 15:48:57,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:57,726 INFO:     Epoch: 44
2022-12-31 15:48:59,368 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46084725062052406, 'Total loss': 0.46084725062052406} | train loss {'Reaction outcome loss': 0.3475186370677598, 'Total loss': 0.3475186370677598}
2022-12-31 15:48:59,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:48:59,369 INFO:     Epoch: 45
2022-12-31 15:49:01,009 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47979440093040465, 'Total loss': 0.47979440093040465} | train loss {'Reaction outcome loss': 0.3181106841792285, 'Total loss': 0.3181106841792285}
2022-12-31 15:49:01,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:01,009 INFO:     Epoch: 46
2022-12-31 15:49:02,627 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4418983479340871, 'Total loss': 0.4418983479340871} | train loss {'Reaction outcome loss': 0.3168222912649651, 'Total loss': 0.3168222912649651}
2022-12-31 15:49:02,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:02,628 INFO:     Epoch: 47
2022-12-31 15:49:04,240 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47363197803497314, 'Total loss': 0.47363197803497314} | train loss {'Reaction outcome loss': 0.3133205822618354, 'Total loss': 0.3133205822618354}
2022-12-31 15:49:04,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:04,241 INFO:     Epoch: 48
2022-12-31 15:49:05,852 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4807992120583852, 'Total loss': 0.4807992120583852} | train loss {'Reaction outcome loss': 0.30756204916447727, 'Total loss': 0.30756204916447727}
2022-12-31 15:49:05,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:05,852 INFO:     Epoch: 49
2022-12-31 15:49:07,468 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47003427644570667, 'Total loss': 0.47003427644570667} | train loss {'Reaction outcome loss': 0.30124357630721416, 'Total loss': 0.30124357630721416}
2022-12-31 15:49:07,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:07,468 INFO:     Epoch: 50
2022-12-31 15:49:09,093 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41651605467001596, 'Total loss': 0.41651605467001596} | train loss {'Reaction outcome loss': 0.30063453110536403, 'Total loss': 0.30063453110536403}
2022-12-31 15:49:09,093 INFO:     Found new best model at epoch 50
2022-12-31 15:49:09,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:09,094 INFO:     Epoch: 51
2022-12-31 15:49:10,705 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4531942089398702, 'Total loss': 0.4531942089398702} | train loss {'Reaction outcome loss': 0.29601614448483154, 'Total loss': 0.29601614448483154}
2022-12-31 15:49:10,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:10,705 INFO:     Epoch: 52
2022-12-31 15:49:12,305 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4431623160839081, 'Total loss': 0.4431623160839081} | train loss {'Reaction outcome loss': 0.2943534971670811, 'Total loss': 0.2943534971670811}
2022-12-31 15:49:12,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:12,305 INFO:     Epoch: 53
2022-12-31 15:49:13,920 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43430163512627284, 'Total loss': 0.43430163512627284} | train loss {'Reaction outcome loss': 0.2957046409863034, 'Total loss': 0.2957046409863034}
2022-12-31 15:49:13,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:13,920 INFO:     Epoch: 54
2022-12-31 15:49:15,519 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.411989430586497, 'Total loss': 0.411989430586497} | train loss {'Reaction outcome loss': 0.28803849057436787, 'Total loss': 0.28803849057436787}
2022-12-31 15:49:15,519 INFO:     Found new best model at epoch 54
2022-12-31 15:49:15,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:15,520 INFO:     Epoch: 55
2022-12-31 15:49:17,159 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42803354064623517, 'Total loss': 0.42803354064623517} | train loss {'Reaction outcome loss': 0.2876085357915988, 'Total loss': 0.2876085357915988}
2022-12-31 15:49:17,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:17,159 INFO:     Epoch: 56
2022-12-31 15:49:18,802 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4227420886357625, 'Total loss': 0.4227420886357625} | train loss {'Reaction outcome loss': 0.28481742685434636, 'Total loss': 0.28481742685434636}
2022-12-31 15:49:18,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:18,802 INFO:     Epoch: 57
2022-12-31 15:49:20,428 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.452940105398496, 'Total loss': 0.452940105398496} | train loss {'Reaction outcome loss': 0.284838735341496, 'Total loss': 0.284838735341496}
2022-12-31 15:49:20,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:20,429 INFO:     Epoch: 58
2022-12-31 15:49:22,042 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46344796419143675, 'Total loss': 0.46344796419143675} | train loss {'Reaction outcome loss': 0.2765182027217014, 'Total loss': 0.2765182027217014}
2022-12-31 15:49:22,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:22,042 INFO:     Epoch: 59
2022-12-31 15:49:23,653 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43487444818019866, 'Total loss': 0.43487444818019866} | train loss {'Reaction outcome loss': 0.2681706828146201, 'Total loss': 0.2681706828146201}
2022-12-31 15:49:23,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:23,653 INFO:     Epoch: 60
2022-12-31 15:49:25,275 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4558911442756653, 'Total loss': 0.4558911442756653} | train loss {'Reaction outcome loss': 0.2690998036961663, 'Total loss': 0.2690998036961663}
2022-12-31 15:49:25,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:25,276 INFO:     Epoch: 61
2022-12-31 15:49:26,926 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4554047425587972, 'Total loss': 0.4554047425587972} | train loss {'Reaction outcome loss': 0.269480020702442, 'Total loss': 0.269480020702442}
2022-12-31 15:49:26,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:26,927 INFO:     Epoch: 62
2022-12-31 15:49:28,564 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42533105512460073, 'Total loss': 0.42533105512460073} | train loss {'Reaction outcome loss': 0.2692877845737435, 'Total loss': 0.2692877845737435}
2022-12-31 15:49:28,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:28,564 INFO:     Epoch: 63
2022-12-31 15:49:30,191 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4469659487406413, 'Total loss': 0.4469659487406413} | train loss {'Reaction outcome loss': 0.2681905830935305, 'Total loss': 0.2681905830935305}
2022-12-31 15:49:30,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:30,191 INFO:     Epoch: 64
2022-12-31 15:49:31,847 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4400568773349126, 'Total loss': 0.4400568773349126} | train loss {'Reaction outcome loss': 0.2670654122895307, 'Total loss': 0.2670654122895307}
2022-12-31 15:49:31,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:31,847 INFO:     Epoch: 65
2022-12-31 15:49:33,491 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47816284497578937, 'Total loss': 0.47816284497578937} | train loss {'Reaction outcome loss': 0.26035727090240235, 'Total loss': 0.26035727090240235}
2022-12-31 15:49:33,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:33,491 INFO:     Epoch: 66
2022-12-31 15:49:35,100 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4568590064843496, 'Total loss': 0.4568590064843496} | train loss {'Reaction outcome loss': 0.269930365192957, 'Total loss': 0.269930365192957}
2022-12-31 15:49:35,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:35,100 INFO:     Epoch: 67
2022-12-31 15:49:36,743 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4103749684989452, 'Total loss': 0.4103749684989452} | train loss {'Reaction outcome loss': 0.26340914601587717, 'Total loss': 0.26340914601587717}
2022-12-31 15:49:36,743 INFO:     Found new best model at epoch 67
2022-12-31 15:49:36,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:36,744 INFO:     Epoch: 68
2022-12-31 15:49:38,371 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4116265078385671, 'Total loss': 0.4116265078385671} | train loss {'Reaction outcome loss': 0.26260784791955294, 'Total loss': 0.26260784791955294}
2022-12-31 15:49:38,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:38,371 INFO:     Epoch: 69
2022-12-31 15:49:39,979 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42150046229362487, 'Total loss': 0.42150046229362487} | train loss {'Reaction outcome loss': 0.2619751750696552, 'Total loss': 0.2619751750696552}
2022-12-31 15:49:39,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:39,980 INFO:     Epoch: 70
2022-12-31 15:49:41,586 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.443580491344134, 'Total loss': 0.443580491344134} | train loss {'Reaction outcome loss': 0.2537220671744591, 'Total loss': 0.2537220671744591}
2022-12-31 15:49:41,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:41,586 INFO:     Epoch: 71
2022-12-31 15:49:43,186 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42750333150227865, 'Total loss': 0.42750333150227865} | train loss {'Reaction outcome loss': 0.25053256624918163, 'Total loss': 0.25053256624918163}
2022-12-31 15:49:43,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:43,186 INFO:     Epoch: 72
2022-12-31 15:49:44,818 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45226244926452636, 'Total loss': 0.45226244926452636} | train loss {'Reaction outcome loss': 0.24989107516027972, 'Total loss': 0.24989107516027972}
2022-12-31 15:49:44,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:44,818 INFO:     Epoch: 73
2022-12-31 15:49:46,421 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48781576951344807, 'Total loss': 0.48781576951344807} | train loss {'Reaction outcome loss': 0.24836261412533728, 'Total loss': 0.24836261412533728}
2022-12-31 15:49:46,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:46,421 INFO:     Epoch: 74
2022-12-31 15:49:48,039 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4602451185385386, 'Total loss': 0.4602451185385386} | train loss {'Reaction outcome loss': 0.25756784128295124, 'Total loss': 0.25756784128295124}
2022-12-31 15:49:48,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:48,039 INFO:     Epoch: 75
2022-12-31 15:49:49,684 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4157236377398173, 'Total loss': 0.4157236377398173} | train loss {'Reaction outcome loss': 0.24685637733099333, 'Total loss': 0.24685637733099333}
2022-12-31 15:49:49,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:49,684 INFO:     Epoch: 76
2022-12-31 15:49:51,333 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4226439823706945, 'Total loss': 0.4226439823706945} | train loss {'Reaction outcome loss': 0.24144263739319707, 'Total loss': 0.24144263739319707}
2022-12-31 15:49:51,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:51,333 INFO:     Epoch: 77
2022-12-31 15:49:52,953 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43684245844682057, 'Total loss': 0.43684245844682057} | train loss {'Reaction outcome loss': 0.2450535654459837, 'Total loss': 0.2450535654459837}
2022-12-31 15:49:52,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:52,953 INFO:     Epoch: 78
2022-12-31 15:49:54,602 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4660887281099955, 'Total loss': 0.4660887281099955} | train loss {'Reaction outcome loss': 0.23877731179211126, 'Total loss': 0.23877731179211126}
2022-12-31 15:49:54,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:54,602 INFO:     Epoch: 79
2022-12-31 15:49:56,249 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43127970000108085, 'Total loss': 0.43127970000108085} | train loss {'Reaction outcome loss': 0.23875728501361268, 'Total loss': 0.23875728501361268}
2022-12-31 15:49:56,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:56,251 INFO:     Epoch: 80
2022-12-31 15:49:57,858 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4723936786254247, 'Total loss': 0.4723936786254247} | train loss {'Reaction outcome loss': 0.23938210536658333, 'Total loss': 0.23938210536658333}
2022-12-31 15:49:57,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:57,858 INFO:     Epoch: 81
2022-12-31 15:49:59,473 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45907123188177745, 'Total loss': 0.45907123188177745} | train loss {'Reaction outcome loss': 0.23809622809288988, 'Total loss': 0.23809622809288988}
2022-12-31 15:49:59,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:49:59,473 INFO:     Epoch: 82
2022-12-31 15:50:01,089 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4130723724762599, 'Total loss': 0.4130723724762599} | train loss {'Reaction outcome loss': 0.23951724335168273, 'Total loss': 0.23951724335168273}
2022-12-31 15:50:01,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:01,090 INFO:     Epoch: 83
2022-12-31 15:50:02,728 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4727668205897013, 'Total loss': 0.4727668205897013} | train loss {'Reaction outcome loss': 0.23091072868555784, 'Total loss': 0.23091072868555784}
2022-12-31 15:50:02,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:02,729 INFO:     Epoch: 84
2022-12-31 15:50:04,369 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42504371802012125, 'Total loss': 0.42504371802012125} | train loss {'Reaction outcome loss': 0.2363574622279924, 'Total loss': 0.2363574622279924}
2022-12-31 15:50:04,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:04,369 INFO:     Epoch: 85
2022-12-31 15:50:05,992 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4270963033040365, 'Total loss': 0.4270963033040365} | train loss {'Reaction outcome loss': 0.2345252159703059, 'Total loss': 0.2345252159703059}
2022-12-31 15:50:05,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:05,992 INFO:     Epoch: 86
2022-12-31 15:50:07,607 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4071136936545372, 'Total loss': 0.4071136936545372} | train loss {'Reaction outcome loss': 0.22953853159265566, 'Total loss': 0.22953853159265566}
2022-12-31 15:50:07,607 INFO:     Found new best model at epoch 86
2022-12-31 15:50:07,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:07,608 INFO:     Epoch: 87
2022-12-31 15:50:09,212 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43607347706953686, 'Total loss': 0.43607347706953686} | train loss {'Reaction outcome loss': 0.22840778966328007, 'Total loss': 0.22840778966328007}
2022-12-31 15:50:09,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:09,212 INFO:     Epoch: 88
2022-12-31 15:50:10,803 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43465936978658043, 'Total loss': 0.43465936978658043} | train loss {'Reaction outcome loss': 0.23204072734907918, 'Total loss': 0.23204072734907918}
2022-12-31 15:50:10,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:10,803 INFO:     Epoch: 89
2022-12-31 15:50:12,440 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4063624252875646, 'Total loss': 0.4063624252875646} | train loss {'Reaction outcome loss': 0.2190473263484476, 'Total loss': 0.2190473263484476}
2022-12-31 15:50:12,441 INFO:     Found new best model at epoch 89
2022-12-31 15:50:12,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:12,442 INFO:     Epoch: 90
2022-12-31 15:50:14,058 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42322963575522105, 'Total loss': 0.42322963575522105} | train loss {'Reaction outcome loss': 0.22281614487460963, 'Total loss': 0.22281614487460963}
2022-12-31 15:50:14,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:14,058 INFO:     Epoch: 91
2022-12-31 15:50:15,684 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44317104319731393, 'Total loss': 0.44317104319731393} | train loss {'Reaction outcome loss': 0.22836810000328536, 'Total loss': 0.22836810000328536}
2022-12-31 15:50:15,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:15,685 INFO:     Epoch: 92
2022-12-31 15:50:17,314 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45767265756924946, 'Total loss': 0.45767265756924946} | train loss {'Reaction outcome loss': 0.21942325942720178, 'Total loss': 0.21942325942720178}
2022-12-31 15:50:17,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:17,315 INFO:     Epoch: 93
2022-12-31 15:50:18,951 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40122584501902264, 'Total loss': 0.40122584501902264} | train loss {'Reaction outcome loss': 0.22245346564981763, 'Total loss': 0.22245346564981763}
2022-12-31 15:50:18,951 INFO:     Found new best model at epoch 93
2022-12-31 15:50:18,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:18,952 INFO:     Epoch: 94
2022-12-31 15:50:20,559 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4458619753519694, 'Total loss': 0.4458619753519694} | train loss {'Reaction outcome loss': 0.22021370520562175, 'Total loss': 0.22021370520562175}
2022-12-31 15:50:20,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:20,559 INFO:     Epoch: 95
2022-12-31 15:50:22,206 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42082491219043733, 'Total loss': 0.42082491219043733} | train loss {'Reaction outcome loss': 0.2173141016645114, 'Total loss': 0.2173141016645114}
2022-12-31 15:50:22,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:22,206 INFO:     Epoch: 96
2022-12-31 15:50:23,855 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4299681703249613, 'Total loss': 0.4299681703249613} | train loss {'Reaction outcome loss': 0.22433849185646346, 'Total loss': 0.22433849185646346}
2022-12-31 15:50:23,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:23,856 INFO:     Epoch: 97
2022-12-31 15:50:25,463 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41954657435417175, 'Total loss': 0.41954657435417175} | train loss {'Reaction outcome loss': 0.221988286546337, 'Total loss': 0.221988286546337}
2022-12-31 15:50:25,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:25,464 INFO:     Epoch: 98
2022-12-31 15:50:27,082 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41842047274112704, 'Total loss': 0.41842047274112704} | train loss {'Reaction outcome loss': 0.21095751196591425, 'Total loss': 0.21095751196591425}
2022-12-31 15:50:27,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:27,082 INFO:     Epoch: 99
2022-12-31 15:50:28,687 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3815211261312167, 'Total loss': 0.3815211261312167} | train loss {'Reaction outcome loss': 0.22304376625032526, 'Total loss': 0.22304376625032526}
2022-12-31 15:50:28,688 INFO:     Found new best model at epoch 99
2022-12-31 15:50:28,688 INFO:     Best model found after epoch 100 of 100.
2022-12-31 15:50:28,689 INFO:   Done with stage: TRAINING
2022-12-31 15:50:28,689 INFO:   Starting stage: EVALUATION
2022-12-31 15:50:28,819 INFO:   Done with stage: EVALUATION
2022-12-31 15:50:28,819 INFO:   Leaving out SEQ value Fold_1
2022-12-31 15:50:28,832 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 15:50:28,832 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:50:29,482 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:50:29,482 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:50:29,550 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:50:29,550 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:50:29,551 INFO:     No hyperparam tuning for this model
2022-12-31 15:50:29,551 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:50:29,551 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:50:29,551 INFO:     None feature selector for col prot
2022-12-31 15:50:29,552 INFO:     None feature selector for col prot
2022-12-31 15:50:29,552 INFO:     None feature selector for col prot
2022-12-31 15:50:29,552 INFO:     None feature selector for col chem
2022-12-31 15:50:29,552 INFO:     None feature selector for col chem
2022-12-31 15:50:29,552 INFO:     None feature selector for col chem
2022-12-31 15:50:29,552 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:50:29,552 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:50:29,554 INFO:     Number of params in model 223921
2022-12-31 15:50:29,557 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:50:29,557 INFO:   Starting stage: TRAINING
2022-12-31 15:50:29,601 INFO:     Val loss before train {'Reaction outcome loss': 0.8920915087064107, 'Total loss': 0.8920915087064107}
2022-12-31 15:50:29,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:29,602 INFO:     Epoch: 0
2022-12-31 15:50:31,230 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6178418179353078, 'Total loss': 0.6178418179353078} | train loss {'Reaction outcome loss': 0.8260886273954225, 'Total loss': 0.8260886273954225}
2022-12-31 15:50:31,231 INFO:     Found new best model at epoch 0
2022-12-31 15:50:31,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:31,232 INFO:     Epoch: 1
2022-12-31 15:50:32,846 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.47402586142222086, 'Total loss': 0.47402586142222086} | train loss {'Reaction outcome loss': 0.6055879462375373, 'Total loss': 0.6055879462375373}
2022-12-31 15:50:32,846 INFO:     Found new best model at epoch 1
2022-12-31 15:50:32,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:32,847 INFO:     Epoch: 2
2022-12-31 15:50:34,477 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44168840646743773, 'Total loss': 0.44168840646743773} | train loss {'Reaction outcome loss': 0.5250487512220507, 'Total loss': 0.5250487512220507}
2022-12-31 15:50:34,478 INFO:     Found new best model at epoch 2
2022-12-31 15:50:34,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:34,479 INFO:     Epoch: 3
2022-12-31 15:50:36,137 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4071475138266881, 'Total loss': 0.4071475138266881} | train loss {'Reaction outcome loss': 0.504444233911193, 'Total loss': 0.504444233911193}
2022-12-31 15:50:36,137 INFO:     Found new best model at epoch 3
2022-12-31 15:50:36,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:36,138 INFO:     Epoch: 4
2022-12-31 15:50:37,743 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4112862209479014, 'Total loss': 0.4112862209479014} | train loss {'Reaction outcome loss': 0.491491983415208, 'Total loss': 0.491491983415208}
2022-12-31 15:50:37,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:37,744 INFO:     Epoch: 5
2022-12-31 15:50:39,402 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4198935925960541, 'Total loss': 0.4198935925960541} | train loss {'Reaction outcome loss': 0.4905389994382858, 'Total loss': 0.4905389994382858}
2022-12-31 15:50:39,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:39,402 INFO:     Epoch: 6
2022-12-31 15:50:41,053 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43873814145723977, 'Total loss': 0.43873814145723977} | train loss {'Reaction outcome loss': 0.5551882681531318, 'Total loss': 0.5551882681531318}
2022-12-31 15:50:41,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:41,053 INFO:     Epoch: 7
2022-12-31 15:50:42,686 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40047886272271477, 'Total loss': 0.40047886272271477} | train loss {'Reaction outcome loss': 0.49358646883258084, 'Total loss': 0.49358646883258084}
2022-12-31 15:50:42,686 INFO:     Found new best model at epoch 7
2022-12-31 15:50:42,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:42,687 INFO:     Epoch: 8
2022-12-31 15:50:44,307 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4387652824322383, 'Total loss': 0.4387652824322383} | train loss {'Reaction outcome loss': 0.46446576709116716, 'Total loss': 0.46446576709116716}
2022-12-31 15:50:44,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:44,308 INFO:     Epoch: 9
2022-12-31 15:50:45,929 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.416491307814916, 'Total loss': 0.416491307814916} | train loss {'Reaction outcome loss': 0.47923781936718285, 'Total loss': 0.47923781936718285}
2022-12-31 15:50:45,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:45,929 INFO:     Epoch: 10
2022-12-31 15:50:47,517 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39950710733731587, 'Total loss': 0.39950710733731587} | train loss {'Reaction outcome loss': 0.45793634167184, 'Total loss': 0.45793634167184}
2022-12-31 15:50:47,517 INFO:     Found new best model at epoch 10
2022-12-31 15:50:47,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:47,518 INFO:     Epoch: 11
2022-12-31 15:50:49,140 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39512105484803517, 'Total loss': 0.39512105484803517} | train loss {'Reaction outcome loss': 0.46900777291992435, 'Total loss': 0.46900777291992435}
2022-12-31 15:50:49,140 INFO:     Found new best model at epoch 11
2022-12-31 15:50:49,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:49,141 INFO:     Epoch: 12
2022-12-31 15:50:50,765 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4127951184908549, 'Total loss': 0.4127951184908549} | train loss {'Reaction outcome loss': 0.4458648828566884, 'Total loss': 0.4458648828566884}
2022-12-31 15:50:50,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:50,766 INFO:     Epoch: 13
2022-12-31 15:50:52,375 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.37981317241986595, 'Total loss': 0.37981317241986595} | train loss {'Reaction outcome loss': 0.4344841098763805, 'Total loss': 0.4344841098763805}
2022-12-31 15:50:52,375 INFO:     Found new best model at epoch 13
2022-12-31 15:50:52,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:52,376 INFO:     Epoch: 14
2022-12-31 15:50:53,993 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44531806707382204, 'Total loss': 0.44531806707382204} | train loss {'Reaction outcome loss': 0.4423940726368185, 'Total loss': 0.4423940726368185}
2022-12-31 15:50:53,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:53,994 INFO:     Epoch: 15
2022-12-31 15:50:55,592 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40427656173706056, 'Total loss': 0.40427656173706056} | train loss {'Reaction outcome loss': 0.43152025093972357, 'Total loss': 0.43152025093972357}
2022-12-31 15:50:55,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:55,592 INFO:     Epoch: 16
2022-12-31 15:50:57,223 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38744456668694816, 'Total loss': 0.38744456668694816} | train loss {'Reaction outcome loss': 0.4256755802687595, 'Total loss': 0.4256755802687595}
2022-12-31 15:50:57,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:57,223 INFO:     Epoch: 17
2022-12-31 15:50:58,865 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3992051949103673, 'Total loss': 0.3992051949103673} | train loss {'Reaction outcome loss': 0.4193006586873958, 'Total loss': 0.4193006586873958}
2022-12-31 15:50:58,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:50:58,865 INFO:     Epoch: 18
2022-12-31 15:51:00,491 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3881853878498077, 'Total loss': 0.3881853878498077} | train loss {'Reaction outcome loss': 0.4094353137281386, 'Total loss': 0.4094353137281386}
2022-12-31 15:51:00,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:00,491 INFO:     Epoch: 19
2022-12-31 15:51:02,123 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.36903635362784065, 'Total loss': 0.36903635362784065} | train loss {'Reaction outcome loss': 0.40782770765540394, 'Total loss': 0.40782770765540394}
2022-12-31 15:51:02,123 INFO:     Found new best model at epoch 19
2022-12-31 15:51:02,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:02,124 INFO:     Epoch: 20
2022-12-31 15:51:03,746 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3779698133468628, 'Total loss': 0.3779698133468628} | train loss {'Reaction outcome loss': 0.39794503863732394, 'Total loss': 0.39794503863732394}
2022-12-31 15:51:03,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:03,746 INFO:     Epoch: 21
2022-12-31 15:51:05,341 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3722873081763585, 'Total loss': 0.3722873081763585} | train loss {'Reaction outcome loss': 0.3921846922848077, 'Total loss': 0.3921846922848077}
2022-12-31 15:51:05,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:05,341 INFO:     Epoch: 22
2022-12-31 15:51:06,975 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.37078058620293936, 'Total loss': 0.37078058620293936} | train loss {'Reaction outcome loss': 0.3928239060282383, 'Total loss': 0.3928239060282383}
2022-12-31 15:51:06,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:06,976 INFO:     Epoch: 23
2022-12-31 15:51:08,626 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.37830324669679005, 'Total loss': 0.37830324669679005} | train loss {'Reaction outcome loss': 0.37433248770747946, 'Total loss': 0.37433248770747946}
2022-12-31 15:51:08,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:08,626 INFO:     Epoch: 24
2022-12-31 15:51:10,226 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3853823781013489, 'Total loss': 0.3853823781013489} | train loss {'Reaction outcome loss': 0.37421249145172886, 'Total loss': 0.37421249145172886}
2022-12-31 15:51:10,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:10,227 INFO:     Epoch: 25
2022-12-31 15:51:11,835 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39707343180974325, 'Total loss': 0.39707343180974325} | train loss {'Reaction outcome loss': 0.378333266419561, 'Total loss': 0.378333266419561}
2022-12-31 15:51:11,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:11,836 INFO:     Epoch: 26
2022-12-31 15:51:13,439 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38260300358136495, 'Total loss': 0.38260300358136495} | train loss {'Reaction outcome loss': 0.40505211940035224, 'Total loss': 0.40505211940035224}
2022-12-31 15:51:13,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:13,440 INFO:     Epoch: 27
2022-12-31 15:51:15,035 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3647640724976858, 'Total loss': 0.3647640724976858} | train loss {'Reaction outcome loss': 0.3645990623656384, 'Total loss': 0.3645990623656384}
2022-12-31 15:51:15,035 INFO:     Found new best model at epoch 27
2022-12-31 15:51:15,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:15,036 INFO:     Epoch: 28
2022-12-31 15:51:16,643 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.349308846394221, 'Total loss': 0.349308846394221} | train loss {'Reaction outcome loss': 0.3573950875037079, 'Total loss': 0.3573950875037079}
2022-12-31 15:51:16,643 INFO:     Found new best model at epoch 28
2022-12-31 15:51:16,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:16,644 INFO:     Epoch: 29
2022-12-31 15:51:18,240 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3794228196144104, 'Total loss': 0.3794228196144104} | train loss {'Reaction outcome loss': 0.3535968210586968, 'Total loss': 0.3535968210586968}
2022-12-31 15:51:18,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:18,241 INFO:     Epoch: 30
2022-12-31 15:51:19,874 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4035811682542165, 'Total loss': 0.4035811682542165} | train loss {'Reaction outcome loss': 0.3455045948587898, 'Total loss': 0.3455045948587898}
2022-12-31 15:51:19,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:19,874 INFO:     Epoch: 31
2022-12-31 15:51:21,478 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.390978966653347, 'Total loss': 0.390978966653347} | train loss {'Reaction outcome loss': 0.39517190507140715, 'Total loss': 0.39517190507140715}
2022-12-31 15:51:21,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:21,478 INFO:     Epoch: 32
2022-12-31 15:51:23,099 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4019636705517769, 'Total loss': 0.4019636705517769} | train loss {'Reaction outcome loss': 0.34159827880237414, 'Total loss': 0.34159827880237414}
2022-12-31 15:51:23,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:23,099 INFO:     Epoch: 33
2022-12-31 15:51:24,725 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4243125915527344, 'Total loss': 0.4243125915527344} | train loss {'Reaction outcome loss': 0.3417015865283168, 'Total loss': 0.3417015865283168}
2022-12-31 15:51:24,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:24,725 INFO:     Epoch: 34
2022-12-31 15:51:26,331 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3648108243942261, 'Total loss': 0.3648108243942261} | train loss {'Reaction outcome loss': 0.360307329526657, 'Total loss': 0.360307329526657}
2022-12-31 15:51:26,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:26,332 INFO:     Epoch: 35
2022-12-31 15:51:27,954 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3912379110852877, 'Total loss': 0.3912379110852877} | train loss {'Reaction outcome loss': 0.3281974464594184, 'Total loss': 0.3281974464594184}
2022-12-31 15:51:27,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:27,954 INFO:     Epoch: 36
2022-12-31 15:51:29,584 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.36909930109977723, 'Total loss': 0.36909930109977723} | train loss {'Reaction outcome loss': 0.32146681602571864, 'Total loss': 0.32146681602571864}
2022-12-31 15:51:29,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:29,584 INFO:     Epoch: 37
2022-12-31 15:51:31,187 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.362263031800588, 'Total loss': 0.362263031800588} | train loss {'Reaction outcome loss': 0.31710227509957156, 'Total loss': 0.31710227509957156}
2022-12-31 15:51:31,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:31,187 INFO:     Epoch: 38
2022-12-31 15:51:32,780 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.35333572030067445, 'Total loss': 0.35333572030067445} | train loss {'Reaction outcome loss': 0.3105489422670107, 'Total loss': 0.3105489422670107}
2022-12-31 15:51:32,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:32,780 INFO:     Epoch: 39
2022-12-31 15:51:34,409 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.34779200653235115, 'Total loss': 0.34779200653235115} | train loss {'Reaction outcome loss': 0.3093122785128113, 'Total loss': 0.3093122785128113}
2022-12-31 15:51:34,409 INFO:     Found new best model at epoch 39
2022-12-31 15:51:34,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:34,410 INFO:     Epoch: 40
2022-12-31 15:51:36,041 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3815697600444158, 'Total loss': 0.3815697600444158} | train loss {'Reaction outcome loss': 0.3070160085470348, 'Total loss': 0.3070160085470348}
2022-12-31 15:51:36,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:36,041 INFO:     Epoch: 41
2022-12-31 15:51:37,657 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3737701485554377, 'Total loss': 0.3737701485554377} | train loss {'Reaction outcome loss': 0.29936005080083344, 'Total loss': 0.29936005080083344}
2022-12-31 15:51:37,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:37,658 INFO:     Epoch: 42
2022-12-31 15:51:39,293 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3334059645732244, 'Total loss': 0.3334059645732244} | train loss {'Reaction outcome loss': 0.30203015822917223, 'Total loss': 0.30203015822917223}
2022-12-31 15:51:39,294 INFO:     Found new best model at epoch 42
2022-12-31 15:51:39,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:39,295 INFO:     Epoch: 43
2022-12-31 15:51:40,891 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.353802361090978, 'Total loss': 0.353802361090978} | train loss {'Reaction outcome loss': 0.29380510384351877, 'Total loss': 0.29380510384351877}
2022-12-31 15:51:40,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:40,891 INFO:     Epoch: 44
2022-12-31 15:51:42,494 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3674384574095408, 'Total loss': 0.3674384574095408} | train loss {'Reaction outcome loss': 0.29180351124080556, 'Total loss': 0.29180351124080556}
2022-12-31 15:51:42,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:42,495 INFO:     Epoch: 45
2022-12-31 15:51:44,101 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3342158814271291, 'Total loss': 0.3342158814271291} | train loss {'Reaction outcome loss': 0.29254765830051654, 'Total loss': 0.29254765830051654}
2022-12-31 15:51:44,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:44,101 INFO:     Epoch: 46
2022-12-31 15:51:45,705 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41241586407025654, 'Total loss': 0.41241586407025654} | train loss {'Reaction outcome loss': 0.29581142714975966, 'Total loss': 0.29581142714975966}
2022-12-31 15:51:45,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:45,705 INFO:     Epoch: 47
2022-12-31 15:51:47,324 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3725115974744161, 'Total loss': 0.3725115974744161} | train loss {'Reaction outcome loss': 0.33071113478497177, 'Total loss': 0.33071113478497177}
2022-12-31 15:51:47,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:47,325 INFO:     Epoch: 48
2022-12-31 15:51:48,976 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3436479240655899, 'Total loss': 0.3436479240655899} | train loss {'Reaction outcome loss': 0.2782510799736791, 'Total loss': 0.2782510799736791}
2022-12-31 15:51:48,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:48,976 INFO:     Epoch: 49
2022-12-31 15:51:50,587 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3620752384265264, 'Total loss': 0.3620752384265264} | train loss {'Reaction outcome loss': 0.2728504500878246, 'Total loss': 0.2728504500878246}
2022-12-31 15:51:50,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:50,588 INFO:     Epoch: 50
2022-12-31 15:51:52,217 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37382828096548715, 'Total loss': 0.37382828096548715} | train loss {'Reaction outcome loss': 0.27274932309080835, 'Total loss': 0.27274932309080835}
2022-12-31 15:51:52,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:52,217 INFO:     Epoch: 51
2022-12-31 15:51:53,865 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.332991332312425, 'Total loss': 0.332991332312425} | train loss {'Reaction outcome loss': 0.2652685354017497, 'Total loss': 0.2652685354017497}
2022-12-31 15:51:53,865 INFO:     Found new best model at epoch 51
2022-12-31 15:51:53,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:53,866 INFO:     Epoch: 52
2022-12-31 15:51:55,465 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.33574224983652434, 'Total loss': 0.33574224983652434} | train loss {'Reaction outcome loss': 0.2722583778499477, 'Total loss': 0.2722583778499477}
2022-12-31 15:51:55,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:55,465 INFO:     Epoch: 53
2022-12-31 15:51:57,090 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3432276755571365, 'Total loss': 0.3432276755571365} | train loss {'Reaction outcome loss': 0.26571965286764654, 'Total loss': 0.26571965286764654}
2022-12-31 15:51:57,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:57,091 INFO:     Epoch: 54
2022-12-31 15:51:58,691 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37868141432603203, 'Total loss': 0.37868141432603203} | train loss {'Reaction outcome loss': 0.26584408587465685, 'Total loss': 0.26584408587465685}
2022-12-31 15:51:58,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:51:58,691 INFO:     Epoch: 55
2022-12-31 15:52:00,291 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3431595526635647, 'Total loss': 0.3431595526635647} | train loss {'Reaction outcome loss': 0.2573522957382142, 'Total loss': 0.2573522957382142}
2022-12-31 15:52:00,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:00,292 INFO:     Epoch: 56
2022-12-31 15:52:01,895 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.339567972222964, 'Total loss': 0.339567972222964} | train loss {'Reaction outcome loss': 0.2571689161687981, 'Total loss': 0.2571689161687981}
2022-12-31 15:52:01,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:01,896 INFO:     Epoch: 57
2022-12-31 15:52:03,484 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3564856596291065, 'Total loss': 0.3564856596291065} | train loss {'Reaction outcome loss': 0.26333890805305954, 'Total loss': 0.26333890805305954}
2022-12-31 15:52:03,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:03,485 INFO:     Epoch: 58
2022-12-31 15:52:05,111 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3261745164791743, 'Total loss': 0.3261745164791743} | train loss {'Reaction outcome loss': 0.2553811547332916, 'Total loss': 0.2553811547332916}
2022-12-31 15:52:05,111 INFO:     Found new best model at epoch 58
2022-12-31 15:52:05,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:05,112 INFO:     Epoch: 59
2022-12-31 15:52:06,752 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3304296642541885, 'Total loss': 0.3304296642541885} | train loss {'Reaction outcome loss': 0.26593935992096324, 'Total loss': 0.26593935992096324}
2022-12-31 15:52:06,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:06,752 INFO:     Epoch: 60
2022-12-31 15:52:08,361 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3344837521513303, 'Total loss': 0.3344837521513303} | train loss {'Reaction outcome loss': 0.2500802435359852, 'Total loss': 0.2500802435359852}
2022-12-31 15:52:08,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:08,361 INFO:     Epoch: 61
2022-12-31 15:52:09,994 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3527051647504171, 'Total loss': 0.3527051647504171} | train loss {'Reaction outcome loss': 0.24595378775932436, 'Total loss': 0.24595378775932436}
2022-12-31 15:52:09,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:09,994 INFO:     Epoch: 62
2022-12-31 15:52:11,639 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3293127735455831, 'Total loss': 0.3293127735455831} | train loss {'Reaction outcome loss': 0.2610524190265847, 'Total loss': 0.2610524190265847}
2022-12-31 15:52:11,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:11,639 INFO:     Epoch: 63
2022-12-31 15:52:13,262 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3841074973344803, 'Total loss': 0.3841074973344803} | train loss {'Reaction outcome loss': 0.3172108320472614, 'Total loss': 0.3172108320472614}
2022-12-31 15:52:13,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:13,263 INFO:     Epoch: 64
2022-12-31 15:52:14,869 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38755085517962773, 'Total loss': 0.38755085517962773} | train loss {'Reaction outcome loss': 0.2812875628714328, 'Total loss': 0.2812875628714328}
2022-12-31 15:52:14,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:14,870 INFO:     Epoch: 65
2022-12-31 15:52:16,474 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38111184562246003, 'Total loss': 0.38111184562246003} | train loss {'Reaction outcome loss': 0.34932893511933694, 'Total loss': 0.34932893511933694}
2022-12-31 15:52:16,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:16,474 INFO:     Epoch: 66
2022-12-31 15:52:18,088 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3378035535415014, 'Total loss': 0.3378035535415014} | train loss {'Reaction outcome loss': 0.3438515705246296, 'Total loss': 0.3438515705246296}
2022-12-31 15:52:18,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:18,088 INFO:     Epoch: 67
2022-12-31 15:52:19,732 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3666707972685496, 'Total loss': 0.3666707972685496} | train loss {'Reaction outcome loss': 0.2714949199302203, 'Total loss': 0.2714949199302203}
2022-12-31 15:52:19,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:19,732 INFO:     Epoch: 68
2022-12-31 15:52:21,377 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3492959638436635, 'Total loss': 0.3492959638436635} | train loss {'Reaction outcome loss': 0.2532226719043177, 'Total loss': 0.2532226719043177}
2022-12-31 15:52:21,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:21,378 INFO:     Epoch: 69
2022-12-31 15:52:22,966 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3471834729115168, 'Total loss': 0.3471834729115168} | train loss {'Reaction outcome loss': 0.2477398682318196, 'Total loss': 0.2477398682318196}
2022-12-31 15:52:22,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:22,966 INFO:     Epoch: 70
2022-12-31 15:52:24,570 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.33795015066862105, 'Total loss': 0.33795015066862105} | train loss {'Reaction outcome loss': 0.24549939168914073, 'Total loss': 0.24549939168914073}
2022-12-31 15:52:24,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:24,571 INFO:     Epoch: 71
2022-12-31 15:52:26,159 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.35633598268032074, 'Total loss': 0.35633598268032074} | train loss {'Reaction outcome loss': 0.24974555533001389, 'Total loss': 0.24974555533001389}
2022-12-31 15:52:26,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:26,159 INFO:     Epoch: 72
2022-12-31 15:52:27,793 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3314557115236918, 'Total loss': 0.3314557115236918} | train loss {'Reaction outcome loss': 0.24760129172827347, 'Total loss': 0.24760129172827347}
2022-12-31 15:52:27,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:27,793 INFO:     Epoch: 73
2022-12-31 15:52:29,434 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.33543261190255486, 'Total loss': 0.33543261190255486} | train loss {'Reaction outcome loss': 0.23682158286860416, 'Total loss': 0.23682158286860416}
2022-12-31 15:52:29,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:29,434 INFO:     Epoch: 74
2022-12-31 15:52:31,030 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3164674758911133, 'Total loss': 0.3164674758911133} | train loss {'Reaction outcome loss': 0.2381180763992049, 'Total loss': 0.2381180763992049}
2022-12-31 15:52:31,031 INFO:     Found new best model at epoch 74
2022-12-31 15:52:31,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:31,032 INFO:     Epoch: 75
2022-12-31 15:52:32,639 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3383251582582792, 'Total loss': 0.3383251582582792} | train loss {'Reaction outcome loss': 0.23159025314911877, 'Total loss': 0.23159025314911877}
2022-12-31 15:52:32,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:32,639 INFO:     Epoch: 76
2022-12-31 15:52:34,246 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.35665713002284366, 'Total loss': 0.35665713002284366} | train loss {'Reaction outcome loss': 0.23309995564109093, 'Total loss': 0.23309995564109093}
2022-12-31 15:52:34,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:34,247 INFO:     Epoch: 77
2022-12-31 15:52:35,839 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3283483847975731, 'Total loss': 0.3283483847975731} | train loss {'Reaction outcome loss': 0.23628464540915034, 'Total loss': 0.23628464540915034}
2022-12-31 15:52:35,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:35,839 INFO:     Epoch: 78
2022-12-31 15:52:37,448 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3323894759019216, 'Total loss': 0.3323894759019216} | train loss {'Reaction outcome loss': 0.23558905118303644, 'Total loss': 0.23558905118303644}
2022-12-31 15:52:37,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:37,448 INFO:     Epoch: 79
2022-12-31 15:52:39,057 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3590053377052148, 'Total loss': 0.3590053377052148} | train loss {'Reaction outcome loss': 0.2328346985463134, 'Total loss': 0.2328346985463134}
2022-12-31 15:52:39,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:39,057 INFO:     Epoch: 80
2022-12-31 15:52:40,672 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.35537774314483006, 'Total loss': 0.35537774314483006} | train loss {'Reaction outcome loss': 0.23525164958656483, 'Total loss': 0.23525164958656483}
2022-12-31 15:52:40,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:40,673 INFO:     Epoch: 81
2022-12-31 15:52:42,312 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.36384960214296974, 'Total loss': 0.36384960214296974} | train loss {'Reaction outcome loss': 0.2299065394934429, 'Total loss': 0.2299065394934429}
2022-12-31 15:52:42,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:42,312 INFO:     Epoch: 82
2022-12-31 15:52:43,954 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.32902245173851646, 'Total loss': 0.32902245173851646} | train loss {'Reaction outcome loss': 0.237310654537778, 'Total loss': 0.237310654537778}
2022-12-31 15:52:43,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:43,954 INFO:     Epoch: 83
2022-12-31 15:52:45,568 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3074997047583262, 'Total loss': 0.3074997047583262} | train loss {'Reaction outcome loss': 0.22726087423507124, 'Total loss': 0.22726087423507124}
2022-12-31 15:52:45,568 INFO:     Found new best model at epoch 83
2022-12-31 15:52:45,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:45,569 INFO:     Epoch: 84
2022-12-31 15:52:47,183 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.35055521527926126, 'Total loss': 0.35055521527926126} | train loss {'Reaction outcome loss': 0.2249272306739906, 'Total loss': 0.2249272306739906}
2022-12-31 15:52:47,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:47,183 INFO:     Epoch: 85
2022-12-31 15:52:48,783 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4070359567801158, 'Total loss': 0.4070359567801158} | train loss {'Reaction outcome loss': 0.23062735557745118, 'Total loss': 0.23062735557745118}
2022-12-31 15:52:48,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:48,783 INFO:     Epoch: 86
2022-12-31 15:52:50,407 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39268445372581484, 'Total loss': 0.39268445372581484} | train loss {'Reaction outcome loss': 0.2535350087463208, 'Total loss': 0.2535350087463208}
2022-12-31 15:52:50,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:50,408 INFO:     Epoch: 87
2022-12-31 15:52:52,044 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.31888168106476467, 'Total loss': 0.31888168106476467} | train loss {'Reaction outcome loss': 0.32921022727943794, 'Total loss': 0.32921022727943794}
2022-12-31 15:52:52,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:52,044 INFO:     Epoch: 88
2022-12-31 15:52:53,662 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.36064088096221286, 'Total loss': 0.36064088096221286} | train loss {'Reaction outcome loss': 0.23415050626576028, 'Total loss': 0.23415050626576028}
2022-12-31 15:52:53,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:53,662 INFO:     Epoch: 89
2022-12-31 15:52:55,285 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.320133305589358, 'Total loss': 0.320133305589358} | train loss {'Reaction outcome loss': 0.22661347411464533, 'Total loss': 0.22661347411464533}
2022-12-31 15:52:55,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:55,285 INFO:     Epoch: 90
2022-12-31 15:52:56,913 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.32120253245035807, 'Total loss': 0.32120253245035807} | train loss {'Reaction outcome loss': 0.2166926323780385, 'Total loss': 0.2166926323780385}
2022-12-31 15:52:56,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:56,914 INFO:     Epoch: 91
2022-12-31 15:52:58,513 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.33182764798402786, 'Total loss': 0.33182764798402786} | train loss {'Reaction outcome loss': 0.21033044907338647, 'Total loss': 0.21033044907338647}
2022-12-31 15:52:58,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:52:58,513 INFO:     Epoch: 92
2022-12-31 15:53:00,124 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3247642991443475, 'Total loss': 0.3247642991443475} | train loss {'Reaction outcome loss': 0.21081454125469198, 'Total loss': 0.21081454125469198}
2022-12-31 15:53:00,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:00,124 INFO:     Epoch: 93
2022-12-31 15:53:01,737 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3191781630118688, 'Total loss': 0.3191781630118688} | train loss {'Reaction outcome loss': 0.21896190952571962, 'Total loss': 0.21896190952571962}
2022-12-31 15:53:01,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:01,737 INFO:     Epoch: 94
2022-12-31 15:53:03,356 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.34288990298906963, 'Total loss': 0.34288990298906963} | train loss {'Reaction outcome loss': 0.22392189291971643, 'Total loss': 0.22392189291971643}
2022-12-31 15:53:03,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:03,357 INFO:     Epoch: 95
2022-12-31 15:53:04,968 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3665982156991959, 'Total loss': 0.3665982156991959} | train loss {'Reaction outcome loss': 0.21349161660064186, 'Total loss': 0.21349161660064186}
2022-12-31 15:53:04,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:04,968 INFO:     Epoch: 96
2022-12-31 15:53:06,577 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3512871185938517, 'Total loss': 0.3512871185938517} | train loss {'Reaction outcome loss': 0.21522680543822006, 'Total loss': 0.21522680543822006}
2022-12-31 15:53:06,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:06,577 INFO:     Epoch: 97
2022-12-31 15:53:08,169 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.33910763760407764, 'Total loss': 0.33910763760407764} | train loss {'Reaction outcome loss': 0.21607255480364035, 'Total loss': 0.21607255480364035}
2022-12-31 15:53:08,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:08,169 INFO:     Epoch: 98
2022-12-31 15:53:09,782 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3372354875008265, 'Total loss': 0.3372354875008265} | train loss {'Reaction outcome loss': 0.20592808488257014, 'Total loss': 0.20592808488257014}
2022-12-31 15:53:09,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:09,783 INFO:     Epoch: 99
2022-12-31 15:53:11,382 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3760100583235423, 'Total loss': 0.3760100583235423} | train loss {'Reaction outcome loss': 0.21337954835220496, 'Total loss': 0.21337954835220496}
2022-12-31 15:53:11,383 INFO:     Best model found after epoch 84 of 100.
2022-12-31 15:53:11,383 INFO:   Done with stage: TRAINING
2022-12-31 15:53:11,383 INFO:   Starting stage: EVALUATION
2022-12-31 15:53:11,512 INFO:   Done with stage: EVALUATION
2022-12-31 15:53:11,512 INFO:   Leaving out SEQ value Fold_2
2022-12-31 15:53:11,525 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2022-12-31 15:53:11,525 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:53:12,170 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:53:12,170 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:53:12,238 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:53:12,238 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:53:12,238 INFO:     No hyperparam tuning for this model
2022-12-31 15:53:12,238 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:53:12,239 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:53:12,239 INFO:     None feature selector for col prot
2022-12-31 15:53:12,239 INFO:     None feature selector for col prot
2022-12-31 15:53:12,240 INFO:     None feature selector for col prot
2022-12-31 15:53:12,240 INFO:     None feature selector for col chem
2022-12-31 15:53:12,240 INFO:     None feature selector for col chem
2022-12-31 15:53:12,240 INFO:     None feature selector for col chem
2022-12-31 15:53:12,240 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:53:12,240 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:53:12,242 INFO:     Number of params in model 223921
2022-12-31 15:53:12,245 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:53:12,245 INFO:   Starting stage: TRAINING
2022-12-31 15:53:12,289 INFO:     Val loss before train {'Reaction outcome loss': 1.044358205795288, 'Total loss': 1.044358205795288}
2022-12-31 15:53:12,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:12,289 INFO:     Epoch: 0
2022-12-31 15:53:13,875 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7208321273326874, 'Total loss': 0.7208321273326874} | train loss {'Reaction outcome loss': 0.8129813337897902, 'Total loss': 0.8129813337897902}
2022-12-31 15:53:13,875 INFO:     Found new best model at epoch 0
2022-12-31 15:53:13,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:13,876 INFO:     Epoch: 1
2022-12-31 15:53:15,453 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5699654539426168, 'Total loss': 0.5699654539426168} | train loss {'Reaction outcome loss': 0.5992483292668508, 'Total loss': 0.5992483292668508}
2022-12-31 15:53:15,453 INFO:     Found new best model at epoch 1
2022-12-31 15:53:15,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:15,454 INFO:     Epoch: 2
2022-12-31 15:53:17,029 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.488520344098409, 'Total loss': 0.488520344098409} | train loss {'Reaction outcome loss': 0.5356054018454358, 'Total loss': 0.5356054018454358}
2022-12-31 15:53:17,029 INFO:     Found new best model at epoch 2
2022-12-31 15:53:17,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:17,030 INFO:     Epoch: 3
2022-12-31 15:53:18,610 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4674004713694255, 'Total loss': 0.4674004713694255} | train loss {'Reaction outcome loss': 0.5058420544070951, 'Total loss': 0.5058420544070951}
2022-12-31 15:53:18,610 INFO:     Found new best model at epoch 3
2022-12-31 15:53:18,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:18,611 INFO:     Epoch: 4
2022-12-31 15:53:20,062 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47345332702000936, 'Total loss': 0.47345332702000936} | train loss {'Reaction outcome loss': 0.4905853438641312, 'Total loss': 0.4905853438641312}
2022-12-31 15:53:20,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:20,062 INFO:     Epoch: 5
2022-12-31 15:53:21,128 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.481671072045962, 'Total loss': 0.481671072045962} | train loss {'Reaction outcome loss': 0.47863904301530763, 'Total loss': 0.47863904301530763}
2022-12-31 15:53:21,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:21,129 INFO:     Epoch: 6
2022-12-31 15:53:22,192 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4415783166885376, 'Total loss': 0.4415783166885376} | train loss {'Reaction outcome loss': 0.4674205771231563, 'Total loss': 0.4674205771231563}
2022-12-31 15:53:22,192 INFO:     Found new best model at epoch 6
2022-12-31 15:53:22,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:22,193 INFO:     Epoch: 7
2022-12-31 15:53:23,265 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44739361181855203, 'Total loss': 0.44739361181855203} | train loss {'Reaction outcome loss': 0.4599827834270977, 'Total loss': 0.4599827834270977}
2022-12-31 15:53:23,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:23,265 INFO:     Epoch: 8
2022-12-31 15:53:24,326 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4388479625185331, 'Total loss': 0.4388479625185331} | train loss {'Reaction outcome loss': 0.4565191339852625, 'Total loss': 0.4565191339852625}
2022-12-31 15:53:24,326 INFO:     Found new best model at epoch 8
2022-12-31 15:53:24,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:24,327 INFO:     Epoch: 9
2022-12-31 15:53:25,913 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4853049834569295, 'Total loss': 0.4853049834569295} | train loss {'Reaction outcome loss': 0.4459219477603356, 'Total loss': 0.4459219477603356}
2022-12-31 15:53:25,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:25,914 INFO:     Epoch: 10
2022-12-31 15:53:27,512 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43334847887357075, 'Total loss': 0.43334847887357075} | train loss {'Reaction outcome loss': 0.44145567979100003, 'Total loss': 0.44145567979100003}
2022-12-31 15:53:27,512 INFO:     Found new best model at epoch 10
2022-12-31 15:53:27,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:27,513 INFO:     Epoch: 11
2022-12-31 15:53:29,113 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48497230807940167, 'Total loss': 0.48497230807940167} | train loss {'Reaction outcome loss': 0.4321546819597153, 'Total loss': 0.4321546819597153}
2022-12-31 15:53:29,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:29,113 INFO:     Epoch: 12
2022-12-31 15:53:30,689 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43907924393812814, 'Total loss': 0.43907924393812814} | train loss {'Reaction outcome loss': 0.4284925415177187, 'Total loss': 0.4284925415177187}
2022-12-31 15:53:30,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:30,690 INFO:     Epoch: 13
2022-12-31 15:53:32,269 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4141674199452003, 'Total loss': 0.4141674199452003} | train loss {'Reaction outcome loss': 0.41963420615864855, 'Total loss': 0.41963420615864855}
2022-12-31 15:53:32,270 INFO:     Found new best model at epoch 13
2022-12-31 15:53:32,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:32,271 INFO:     Epoch: 14
2022-12-31 15:53:33,849 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4351805587609609, 'Total loss': 0.4351805587609609} | train loss {'Reaction outcome loss': 0.4103579119507677, 'Total loss': 0.4103579119507677}
2022-12-31 15:53:33,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:33,849 INFO:     Epoch: 15
2022-12-31 15:53:35,467 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45463316241900126, 'Total loss': 0.45463316241900126} | train loss {'Reaction outcome loss': 0.4052916726997858, 'Total loss': 0.4052916726997858}
2022-12-31 15:53:35,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:35,467 INFO:     Epoch: 16
2022-12-31 15:53:37,088 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4283407419919968, 'Total loss': 0.4283407419919968} | train loss {'Reaction outcome loss': 0.40212370339794795, 'Total loss': 0.40212370339794795}
2022-12-31 15:53:37,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:37,088 INFO:     Epoch: 17
2022-12-31 15:53:38,705 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4288212219874064, 'Total loss': 0.4288212219874064} | train loss {'Reaction outcome loss': 0.39493735915400446, 'Total loss': 0.39493735915400446}
2022-12-31 15:53:38,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:38,706 INFO:     Epoch: 18
2022-12-31 15:53:40,324 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44380052586396534, 'Total loss': 0.44380052586396534} | train loss {'Reaction outcome loss': 0.39009828147962966, 'Total loss': 0.39009828147962966}
2022-12-31 15:53:40,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:40,324 INFO:     Epoch: 19
2022-12-31 15:53:41,888 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4174797356128693, 'Total loss': 0.4174797356128693} | train loss {'Reaction outcome loss': 0.3858746882954207, 'Total loss': 0.3858746882954207}
2022-12-31 15:53:41,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:41,888 INFO:     Epoch: 20
2022-12-31 15:53:43,459 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48114238381385804, 'Total loss': 0.48114238381385804} | train loss {'Reaction outcome loss': 0.38203152535806284, 'Total loss': 0.38203152535806284}
2022-12-31 15:53:43,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:43,460 INFO:     Epoch: 21
2022-12-31 15:53:45,038 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46143621802330015, 'Total loss': 0.46143621802330015} | train loss {'Reaction outcome loss': 0.37880735544700905, 'Total loss': 0.37880735544700905}
2022-12-31 15:53:45,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:45,039 INFO:     Epoch: 22
2022-12-31 15:53:46,615 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4464982976516088, 'Total loss': 0.4464982976516088} | train loss {'Reaction outcome loss': 0.3733775511219053, 'Total loss': 0.3733775511219053}
2022-12-31 15:53:46,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:46,616 INFO:     Epoch: 23
2022-12-31 15:53:48,194 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4407740930716197, 'Total loss': 0.4407740930716197} | train loss {'Reaction outcome loss': 0.36842846952901115, 'Total loss': 0.36842846952901115}
2022-12-31 15:53:48,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:48,195 INFO:     Epoch: 24
2022-12-31 15:53:49,780 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39741047223409015, 'Total loss': 0.39741047223409015} | train loss {'Reaction outcome loss': 0.36021245130753604, 'Total loss': 0.36021245130753604}
2022-12-31 15:53:49,780 INFO:     Found new best model at epoch 24
2022-12-31 15:53:49,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:49,781 INFO:     Epoch: 25
2022-12-31 15:53:51,358 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43364530404408774, 'Total loss': 0.43364530404408774} | train loss {'Reaction outcome loss': 0.35624999143320696, 'Total loss': 0.35624999143320696}
2022-12-31 15:53:51,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:51,358 INFO:     Epoch: 26
2022-12-31 15:53:52,957 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4754942188660304, 'Total loss': 0.4754942188660304} | train loss {'Reaction outcome loss': 0.3508377461470801, 'Total loss': 0.3508377461470801}
2022-12-31 15:53:52,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:52,958 INFO:     Epoch: 27
2022-12-31 15:53:54,575 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4357310007015864, 'Total loss': 0.4357310007015864} | train loss {'Reaction outcome loss': 0.3544365563103414, 'Total loss': 0.3544365563103414}
2022-12-31 15:53:54,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:54,575 INFO:     Epoch: 28
2022-12-31 15:53:56,161 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45460026562213895, 'Total loss': 0.45460026562213895} | train loss {'Reaction outcome loss': 0.3478821968845336, 'Total loss': 0.3478821968845336}
2022-12-31 15:53:56,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:56,162 INFO:     Epoch: 29
2022-12-31 15:53:57,737 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41131118734677635, 'Total loss': 0.41131118734677635} | train loss {'Reaction outcome loss': 0.3384324922140454, 'Total loss': 0.3384324922140454}
2022-12-31 15:53:57,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:57,737 INFO:     Epoch: 30
2022-12-31 15:53:59,305 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39588267480333644, 'Total loss': 0.39588267480333644} | train loss {'Reaction outcome loss': 0.33353860126430257, 'Total loss': 0.33353860126430257}
2022-12-31 15:53:59,305 INFO:     Found new best model at epoch 30
2022-12-31 15:53:59,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:53:59,306 INFO:     Epoch: 31
2022-12-31 15:54:00,865 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3938304444154104, 'Total loss': 0.3938304444154104} | train loss {'Reaction outcome loss': 0.3361921862482585, 'Total loss': 0.3361921862482585}
2022-12-31 15:54:00,865 INFO:     Found new best model at epoch 31
2022-12-31 15:54:00,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:00,866 INFO:     Epoch: 32
2022-12-31 15:54:02,475 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39676407178243, 'Total loss': 0.39676407178243} | train loss {'Reaction outcome loss': 0.33393830773025424, 'Total loss': 0.33393830773025424}
2022-12-31 15:54:02,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:02,476 INFO:     Epoch: 33
2022-12-31 15:54:04,085 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4351499338944753, 'Total loss': 0.4351499338944753} | train loss {'Reaction outcome loss': 0.3260619526529664, 'Total loss': 0.3260619526529664}
2022-12-31 15:54:04,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:04,085 INFO:     Epoch: 34
2022-12-31 15:54:05,694 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38719765345255536, 'Total loss': 0.38719765345255536} | train loss {'Reaction outcome loss': 0.3312828983163042, 'Total loss': 0.3312828983163042}
2022-12-31 15:54:05,694 INFO:     Found new best model at epoch 34
2022-12-31 15:54:05,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:05,695 INFO:     Epoch: 35
2022-12-31 15:54:07,280 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4093924552202225, 'Total loss': 0.4093924552202225} | train loss {'Reaction outcome loss': 0.3177630050843272, 'Total loss': 0.3177630050843272}
2022-12-31 15:54:07,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:07,280 INFO:     Epoch: 36
2022-12-31 15:54:08,853 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38907539943854014, 'Total loss': 0.38907539943854014} | train loss {'Reaction outcome loss': 0.31941630408112853, 'Total loss': 0.31941630408112853}
2022-12-31 15:54:08,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:08,853 INFO:     Epoch: 37
2022-12-31 15:54:10,446 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41189945340156553, 'Total loss': 0.41189945340156553} | train loss {'Reaction outcome loss': 0.3069455143050514, 'Total loss': 0.3069455143050514}
2022-12-31 15:54:10,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:10,447 INFO:     Epoch: 38
2022-12-31 15:54:12,055 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41773197452227273, 'Total loss': 0.41773197452227273} | train loss {'Reaction outcome loss': 0.313484864604979, 'Total loss': 0.313484864604979}
2022-12-31 15:54:12,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:12,055 INFO:     Epoch: 39
2022-12-31 15:54:13,639 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.373125385461996, 'Total loss': 0.373125385461996} | train loss {'Reaction outcome loss': 0.3076985028891986, 'Total loss': 0.3076985028891986}
2022-12-31 15:54:13,639 INFO:     Found new best model at epoch 39
2022-12-31 15:54:13,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:13,640 INFO:     Epoch: 40
2022-12-31 15:54:15,226 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.376139397919178, 'Total loss': 0.376139397919178} | train loss {'Reaction outcome loss': 0.30192569966300825, 'Total loss': 0.30192569966300825}
2022-12-31 15:54:15,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:15,227 INFO:     Epoch: 41
2022-12-31 15:54:16,796 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4126043995221456, 'Total loss': 0.4126043995221456} | train loss {'Reaction outcome loss': 0.30111092502230646, 'Total loss': 0.30111092502230646}
2022-12-31 15:54:16,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:16,796 INFO:     Epoch: 42
2022-12-31 15:54:18,384 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43794058362642924, 'Total loss': 0.43794058362642924} | train loss {'Reaction outcome loss': 0.2966840157622121, 'Total loss': 0.2966840157622121}
2022-12-31 15:54:18,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:18,384 INFO:     Epoch: 43
2022-12-31 15:54:19,973 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38595790714025496, 'Total loss': 0.38595790714025496} | train loss {'Reaction outcome loss': 0.28948013734663547, 'Total loss': 0.28948013734663547}
2022-12-31 15:54:19,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:19,973 INFO:     Epoch: 44
2022-12-31 15:54:21,562 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4018302877744039, 'Total loss': 0.4018302877744039} | train loss {'Reaction outcome loss': 0.29079242882308487, 'Total loss': 0.29079242882308487}
2022-12-31 15:54:21,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:21,562 INFO:     Epoch: 45
2022-12-31 15:54:23,166 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.36043210327625275, 'Total loss': 0.36043210327625275} | train loss {'Reaction outcome loss': 0.27935886695101253, 'Total loss': 0.27935886695101253}
2022-12-31 15:54:23,167 INFO:     Found new best model at epoch 45
2022-12-31 15:54:23,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:23,167 INFO:     Epoch: 46
2022-12-31 15:54:24,771 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3983149552717805, 'Total loss': 0.3983149552717805} | train loss {'Reaction outcome loss': 0.2814764971415275, 'Total loss': 0.2814764971415275}
2022-12-31 15:54:24,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:24,771 INFO:     Epoch: 47
2022-12-31 15:54:26,347 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3921223401402434, 'Total loss': 0.3921223401402434} | train loss {'Reaction outcome loss': 0.27968996099275417, 'Total loss': 0.27968996099275417}
2022-12-31 15:54:26,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:26,348 INFO:     Epoch: 48
2022-12-31 15:54:27,952 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38451573917021353, 'Total loss': 0.38451573917021353} | train loss {'Reaction outcome loss': 0.2815776979241424, 'Total loss': 0.2815776979241424}
2022-12-31 15:54:27,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:27,953 INFO:     Epoch: 49
2022-12-31 15:54:29,547 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4090668012698491, 'Total loss': 0.4090668012698491} | train loss {'Reaction outcome loss': 0.27440710785039235, 'Total loss': 0.27440710785039235}
2022-12-31 15:54:29,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:29,547 INFO:     Epoch: 50
2022-12-31 15:54:31,134 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37561490188042324, 'Total loss': 0.37561490188042324} | train loss {'Reaction outcome loss': 0.27715349692260205, 'Total loss': 0.27715349692260205}
2022-12-31 15:54:31,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:31,135 INFO:     Epoch: 51
2022-12-31 15:54:32,722 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4267147809267044, 'Total loss': 0.4267147809267044} | train loss {'Reaction outcome loss': 0.2746827412410416, 'Total loss': 0.2746827412410416}
2022-12-31 15:54:32,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:32,723 INFO:     Epoch: 52
2022-12-31 15:54:34,310 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3655259589354197, 'Total loss': 0.3655259589354197} | train loss {'Reaction outcome loss': 0.27436740446244656, 'Total loss': 0.27436740446244656}
2022-12-31 15:54:34,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:34,311 INFO:     Epoch: 53
2022-12-31 15:54:35,905 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3603027145067851, 'Total loss': 0.3603027145067851} | train loss {'Reaction outcome loss': 0.2675920419010069, 'Total loss': 0.2675920419010069}
2022-12-31 15:54:35,905 INFO:     Found new best model at epoch 53
2022-12-31 15:54:35,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:35,906 INFO:     Epoch: 54
2022-12-31 15:54:37,496 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40377062087257704, 'Total loss': 0.40377062087257704} | train loss {'Reaction outcome loss': 0.26514852754909174, 'Total loss': 0.26514852754909174}
2022-12-31 15:54:37,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:37,497 INFO:     Epoch: 55
2022-12-31 15:54:39,084 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.382085447323819, 'Total loss': 0.382085447323819} | train loss {'Reaction outcome loss': 0.2625430734395101, 'Total loss': 0.2625430734395101}
2022-12-31 15:54:39,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:39,084 INFO:     Epoch: 56
2022-12-31 15:54:40,706 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3670509845018387, 'Total loss': 0.3670509845018387} | train loss {'Reaction outcome loss': 0.26136616910240745, 'Total loss': 0.26136616910240745}
2022-12-31 15:54:40,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:40,707 INFO:     Epoch: 57
2022-12-31 15:54:42,299 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38577395379543306, 'Total loss': 0.38577395379543306} | train loss {'Reaction outcome loss': 0.25705632456059385, 'Total loss': 0.25705632456059385}
2022-12-31 15:54:42,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:42,299 INFO:     Epoch: 58
2022-12-31 15:54:43,884 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39552038510640464, 'Total loss': 0.39552038510640464} | train loss {'Reaction outcome loss': 0.26034808659245606, 'Total loss': 0.26034808659245606}
2022-12-31 15:54:43,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:43,885 INFO:     Epoch: 59
2022-12-31 15:54:45,478 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4011032938957214, 'Total loss': 0.4011032938957214} | train loss {'Reaction outcome loss': 0.25653634163313904, 'Total loss': 0.25653634163313904}
2022-12-31 15:54:45,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:45,478 INFO:     Epoch: 60
2022-12-31 15:54:47,073 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3993571996688843, 'Total loss': 0.3993571996688843} | train loss {'Reaction outcome loss': 0.2567071839273526, 'Total loss': 0.2567071839273526}
2022-12-31 15:54:47,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:47,073 INFO:     Epoch: 61
2022-12-31 15:54:48,665 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37788384705781936, 'Total loss': 0.37788384705781936} | train loss {'Reaction outcome loss': 0.25003338788680707, 'Total loss': 0.25003338788680707}
2022-12-31 15:54:48,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:48,665 INFO:     Epoch: 62
2022-12-31 15:54:50,250 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4454641451438268, 'Total loss': 0.4454641451438268} | train loss {'Reaction outcome loss': 0.244752023073525, 'Total loss': 0.244752023073525}
2022-12-31 15:54:50,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:50,251 INFO:     Epoch: 63
2022-12-31 15:54:51,836 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3604480038086573, 'Total loss': 0.3604480038086573} | train loss {'Reaction outcome loss': 0.24507036002359708, 'Total loss': 0.24507036002359708}
2022-12-31 15:54:51,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:51,837 INFO:     Epoch: 64
2022-12-31 15:54:53,416 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3897646789749463, 'Total loss': 0.3897646789749463} | train loss {'Reaction outcome loss': 0.24844637473295975, 'Total loss': 0.24844637473295975}
2022-12-31 15:54:53,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:53,417 INFO:     Epoch: 65
2022-12-31 15:54:55,004 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3670163085063299, 'Total loss': 0.3670163085063299} | train loss {'Reaction outcome loss': 0.24738345612734006, 'Total loss': 0.24738345612734006}
2022-12-31 15:54:55,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:55,005 INFO:     Epoch: 66
2022-12-31 15:54:56,571 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3757117678721746, 'Total loss': 0.3757117678721746} | train loss {'Reaction outcome loss': 0.2452219002141284, 'Total loss': 0.2452219002141284}
2022-12-31 15:54:56,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:56,572 INFO:     Epoch: 67
2022-12-31 15:54:58,153 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3688271005948385, 'Total loss': 0.3688271005948385} | train loss {'Reaction outcome loss': 0.24232651893997983, 'Total loss': 0.24232651893997983}
2022-12-31 15:54:58,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:58,153 INFO:     Epoch: 68
2022-12-31 15:54:59,739 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38956359028816223, 'Total loss': 0.38956359028816223} | train loss {'Reaction outcome loss': 0.23669071891430998, 'Total loss': 0.23669071891430998}
2022-12-31 15:54:59,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:54:59,739 INFO:     Epoch: 69
2022-12-31 15:55:01,342 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3672519077857335, 'Total loss': 0.3672519077857335} | train loss {'Reaction outcome loss': 0.2390743649231332, 'Total loss': 0.2390743649231332}
2022-12-31 15:55:01,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:01,342 INFO:     Epoch: 70
2022-12-31 15:55:02,931 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.391302353143692, 'Total loss': 0.391302353143692} | train loss {'Reaction outcome loss': 0.2343886703445243, 'Total loss': 0.2343886703445243}
2022-12-31 15:55:02,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:02,933 INFO:     Epoch: 71
2022-12-31 15:55:04,513 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3855359047651291, 'Total loss': 0.3855359047651291} | train loss {'Reaction outcome loss': 0.23343008108492047, 'Total loss': 0.23343008108492047}
2022-12-31 15:55:04,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:04,513 INFO:     Epoch: 72
2022-12-31 15:55:06,124 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3897390325864156, 'Total loss': 0.3897390325864156} | train loss {'Reaction outcome loss': 0.22960414253587652, 'Total loss': 0.22960414253587652}
2022-12-31 15:55:06,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:06,125 INFO:     Epoch: 73
2022-12-31 15:55:07,738 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4043774823347727, 'Total loss': 0.4043774823347727} | train loss {'Reaction outcome loss': 0.22881485776790172, 'Total loss': 0.22881485776790172}
2022-12-31 15:55:07,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:07,738 INFO:     Epoch: 74
2022-12-31 15:55:09,323 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39168888131777446, 'Total loss': 0.39168888131777446} | train loss {'Reaction outcome loss': 0.23393376251318357, 'Total loss': 0.23393376251318357}
2022-12-31 15:55:09,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:09,324 INFO:     Epoch: 75
2022-12-31 15:55:10,917 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37528311610221865, 'Total loss': 0.37528311610221865} | train loss {'Reaction outcome loss': 0.23700793120473954, 'Total loss': 0.23700793120473954}
2022-12-31 15:55:10,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:10,918 INFO:     Epoch: 76
2022-12-31 15:55:12,492 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3874581625064214, 'Total loss': 0.3874581625064214} | train loss {'Reaction outcome loss': 0.23652635641203595, 'Total loss': 0.23652635641203595}
2022-12-31 15:55:12,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:12,492 INFO:     Epoch: 77
2022-12-31 15:55:14,065 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4022380401690801, 'Total loss': 0.4022380401690801} | train loss {'Reaction outcome loss': 0.22650861019110546, 'Total loss': 0.22650861019110546}
2022-12-31 15:55:14,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:14,065 INFO:     Epoch: 78
2022-12-31 15:55:15,690 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4227759579817454, 'Total loss': 0.4227759579817454} | train loss {'Reaction outcome loss': 0.22447000577276044, 'Total loss': 0.22447000577276044}
2022-12-31 15:55:15,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:15,690 INFO:     Epoch: 79
2022-12-31 15:55:17,282 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3787747253974279, 'Total loss': 0.3787747253974279} | train loss {'Reaction outcome loss': 0.2249494944785024, 'Total loss': 0.2249494944785024}
2022-12-31 15:55:17,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:17,282 INFO:     Epoch: 80
2022-12-31 15:55:18,875 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37808202306429545, 'Total loss': 0.37808202306429545} | train loss {'Reaction outcome loss': 0.22374214868428963, 'Total loss': 0.22374214868428963}
2022-12-31 15:55:18,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:18,875 INFO:     Epoch: 81
2022-12-31 15:55:20,449 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3739875376224518, 'Total loss': 0.3739875376224518} | train loss {'Reaction outcome loss': 0.22013795183373552, 'Total loss': 0.22013795183373552}
2022-12-31 15:55:20,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:20,450 INFO:     Epoch: 82
2022-12-31 15:55:22,068 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37844177211324376, 'Total loss': 0.37844177211324376} | train loss {'Reaction outcome loss': 0.21645119995208684, 'Total loss': 0.21645119995208684}
2022-12-31 15:55:22,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:22,069 INFO:     Epoch: 83
2022-12-31 15:55:23,668 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38450777580340706, 'Total loss': 0.38450777580340706} | train loss {'Reaction outcome loss': 0.21366664519829065, 'Total loss': 0.21366664519829065}
2022-12-31 15:55:23,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:23,668 INFO:     Epoch: 84
2022-12-31 15:55:25,289 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38279737656315166, 'Total loss': 0.38279737656315166} | train loss {'Reaction outcome loss': 0.21857822415628556, 'Total loss': 0.21857822415628556}
2022-12-31 15:55:25,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:25,290 INFO:     Epoch: 85
2022-12-31 15:55:26,889 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3993407210956017, 'Total loss': 0.3993407210956017} | train loss {'Reaction outcome loss': 0.21615841224569676, 'Total loss': 0.21615841224569676}
2022-12-31 15:55:26,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:26,890 INFO:     Epoch: 86
2022-12-31 15:55:28,478 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.34648199876149494, 'Total loss': 0.34648199876149494} | train loss {'Reaction outcome loss': 0.20973694096302195, 'Total loss': 0.20973694096302195}
2022-12-31 15:55:28,479 INFO:     Found new best model at epoch 86
2022-12-31 15:55:28,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:28,480 INFO:     Epoch: 87
2022-12-31 15:55:30,049 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.413084327429533, 'Total loss': 0.413084327429533} | train loss {'Reaction outcome loss': 0.22569528343740206, 'Total loss': 0.22569528343740206}
2022-12-31 15:55:30,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:30,049 INFO:     Epoch: 88
2022-12-31 15:55:31,620 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.375475506298244, 'Total loss': 0.375475506298244} | train loss {'Reaction outcome loss': 0.21873856372306488, 'Total loss': 0.21873856372306488}
2022-12-31 15:55:31,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:31,621 INFO:     Epoch: 89
2022-12-31 15:55:33,246 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41836639245351154, 'Total loss': 0.41836639245351154} | train loss {'Reaction outcome loss': 0.21143183125203607, 'Total loss': 0.21143183125203607}
2022-12-31 15:55:33,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:33,247 INFO:     Epoch: 90
2022-12-31 15:55:34,866 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3801998898386955, 'Total loss': 0.3801998898386955} | train loss {'Reaction outcome loss': 0.2130576257947901, 'Total loss': 0.2130576257947901}
2022-12-31 15:55:34,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:34,867 INFO:     Epoch: 91
2022-12-31 15:55:36,462 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4435750037431717, 'Total loss': 0.4435750037431717} | train loss {'Reaction outcome loss': 0.21719221110933382, 'Total loss': 0.21719221110933382}
2022-12-31 15:55:36,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:36,462 INFO:     Epoch: 92
2022-12-31 15:55:38,054 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39140178511540097, 'Total loss': 0.39140178511540097} | train loss {'Reaction outcome loss': 0.21112344941172434, 'Total loss': 0.21112344941172434}
2022-12-31 15:55:38,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:38,054 INFO:     Epoch: 93
2022-12-31 15:55:39,636 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39994743863741555, 'Total loss': 0.39994743863741555} | train loss {'Reaction outcome loss': 0.21068683401011343, 'Total loss': 0.21068683401011343}
2022-12-31 15:55:39,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:39,637 INFO:     Epoch: 94
2022-12-31 15:55:41,224 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3978622550765673, 'Total loss': 0.3978622550765673} | train loss {'Reaction outcome loss': 0.20736771637773163, 'Total loss': 0.20736771637773163}
2022-12-31 15:55:41,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:41,225 INFO:     Epoch: 95
2022-12-31 15:55:42,788 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35102401077747347, 'Total loss': 0.35102401077747347} | train loss {'Reaction outcome loss': 0.20926612366087102, 'Total loss': 0.20926612366087102}
2022-12-31 15:55:42,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:42,788 INFO:     Epoch: 96
2022-12-31 15:55:44,396 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37547396769126257, 'Total loss': 0.37547396769126257} | train loss {'Reaction outcome loss': 0.2062986685973472, 'Total loss': 0.2062986685973472}
2022-12-31 15:55:44,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:44,396 INFO:     Epoch: 97
2022-12-31 15:55:46,007 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4538712198535601, 'Total loss': 0.4538712198535601} | train loss {'Reaction outcome loss': 0.20301385621481827, 'Total loss': 0.20301385621481827}
2022-12-31 15:55:46,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:46,007 INFO:     Epoch: 98
2022-12-31 15:55:47,584 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3450454651998977, 'Total loss': 0.3450454651998977} | train loss {'Reaction outcome loss': 0.20798498051192926, 'Total loss': 0.20798498051192926}
2022-12-31 15:55:47,584 INFO:     Found new best model at epoch 98
2022-12-31 15:55:47,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:47,585 INFO:     Epoch: 99
2022-12-31 15:55:49,197 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39228547861178714, 'Total loss': 0.39228547861178714} | train loss {'Reaction outcome loss': 0.20683264092463188, 'Total loss': 0.20683264092463188}
2022-12-31 15:55:49,198 INFO:     Best model found after epoch 99 of 100.
2022-12-31 15:55:49,198 INFO:   Done with stage: TRAINING
2022-12-31 15:55:49,198 INFO:   Starting stage: EVALUATION
2022-12-31 15:55:49,345 INFO:   Done with stage: EVALUATION
2022-12-31 15:55:49,345 INFO:   Leaving out SEQ value Fold_3
2022-12-31 15:55:49,358 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2022-12-31 15:55:49,358 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:55:50,005 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:55:50,005 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:55:50,072 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:55:50,072 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:55:50,072 INFO:     No hyperparam tuning for this model
2022-12-31 15:55:50,072 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:55:50,072 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:55:50,073 INFO:     None feature selector for col prot
2022-12-31 15:55:50,073 INFO:     None feature selector for col prot
2022-12-31 15:55:50,073 INFO:     None feature selector for col prot
2022-12-31 15:55:50,073 INFO:     None feature selector for col chem
2022-12-31 15:55:50,074 INFO:     None feature selector for col chem
2022-12-31 15:55:50,074 INFO:     None feature selector for col chem
2022-12-31 15:55:50,074 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:55:50,074 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:55:50,075 INFO:     Number of params in model 223921
2022-12-31 15:55:50,079 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:55:50,079 INFO:   Starting stage: TRAINING
2022-12-31 15:55:50,122 INFO:     Val loss before train {'Reaction outcome loss': 1.0670479357242584, 'Total loss': 1.0670479357242584}
2022-12-31 15:55:50,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:50,122 INFO:     Epoch: 0
2022-12-31 15:55:51,700 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6786387046178182, 'Total loss': 0.6786387046178182} | train loss {'Reaction outcome loss': 0.8045194155615634, 'Total loss': 0.8045194155615634}
2022-12-31 15:55:51,701 INFO:     Found new best model at epoch 0
2022-12-31 15:55:51,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:51,702 INFO:     Epoch: 1
2022-12-31 15:55:53,291 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5314551492532095, 'Total loss': 0.5314551492532095} | train loss {'Reaction outcome loss': 0.5965416207084796, 'Total loss': 0.5965416207084796}
2022-12-31 15:55:53,291 INFO:     Found new best model at epoch 1
2022-12-31 15:55:53,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:53,293 INFO:     Epoch: 2
2022-12-31 15:55:54,912 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49477843443552655, 'Total loss': 0.49477843443552655} | train loss {'Reaction outcome loss': 0.5225520511174994, 'Total loss': 0.5225520511174994}
2022-12-31 15:55:54,912 INFO:     Found new best model at epoch 2
2022-12-31 15:55:54,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:54,913 INFO:     Epoch: 3
2022-12-31 15:55:56,507 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.478241258362929, 'Total loss': 0.478241258362929} | train loss {'Reaction outcome loss': 0.4942150614138459, 'Total loss': 0.4942150614138459}
2022-12-31 15:55:56,507 INFO:     Found new best model at epoch 3
2022-12-31 15:55:56,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:56,508 INFO:     Epoch: 4
2022-12-31 15:55:58,093 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5271474301815033, 'Total loss': 0.5271474301815033} | train loss {'Reaction outcome loss': 0.4871657375260033, 'Total loss': 0.4871657375260033}
2022-12-31 15:55:58,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:58,093 INFO:     Epoch: 5
2022-12-31 15:55:59,689 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47682016690572104, 'Total loss': 0.47682016690572104} | train loss {'Reaction outcome loss': 0.47440227382297445, 'Total loss': 0.47440227382297445}
2022-12-31 15:55:59,689 INFO:     Found new best model at epoch 5
2022-12-31 15:55:59,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:55:59,690 INFO:     Epoch: 6
2022-12-31 15:56:01,251 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4813025534152985, 'Total loss': 0.4813025534152985} | train loss {'Reaction outcome loss': 0.4644081901030347, 'Total loss': 0.4644081901030347}
2022-12-31 15:56:01,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:01,251 INFO:     Epoch: 7
2022-12-31 15:56:02,860 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4811277727286021, 'Total loss': 0.4811277727286021} | train loss {'Reaction outcome loss': 0.4587056659354495, 'Total loss': 0.4587056659354495}
2022-12-31 15:56:02,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:02,861 INFO:     Epoch: 8
2022-12-31 15:56:04,440 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46929622292518614, 'Total loss': 0.46929622292518614} | train loss {'Reaction outcome loss': 0.4464653709497839, 'Total loss': 0.4464653709497839}
2022-12-31 15:56:04,442 INFO:     Found new best model at epoch 8
2022-12-31 15:56:04,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:04,443 INFO:     Epoch: 9
2022-12-31 15:56:05,999 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46040560603141784, 'Total loss': 0.46040560603141784} | train loss {'Reaction outcome loss': 0.4432779375147556, 'Total loss': 0.4432779375147556}
2022-12-31 15:56:05,999 INFO:     Found new best model at epoch 9
2022-12-31 15:56:06,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:06,000 INFO:     Epoch: 10
2022-12-31 15:56:07,551 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46416712055603665, 'Total loss': 0.46416712055603665} | train loss {'Reaction outcome loss': 0.43471420292374835, 'Total loss': 0.43471420292374835}
2022-12-31 15:56:07,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:07,552 INFO:     Epoch: 11
2022-12-31 15:56:09,172 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44743700623512267, 'Total loss': 0.44743700623512267} | train loss {'Reaction outcome loss': 0.4285045664248871, 'Total loss': 0.4285045664248871}
2022-12-31 15:56:09,172 INFO:     Found new best model at epoch 11
2022-12-31 15:56:09,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:09,173 INFO:     Epoch: 12
2022-12-31 15:56:10,752 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47617451548576356, 'Total loss': 0.47617451548576356} | train loss {'Reaction outcome loss': 0.4191662309574465, 'Total loss': 0.4191662309574465}
2022-12-31 15:56:10,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:10,753 INFO:     Epoch: 13
2022-12-31 15:56:12,336 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4588448276122411, 'Total loss': 0.4588448276122411} | train loss {'Reaction outcome loss': 0.4198594655003055, 'Total loss': 0.4198594655003055}
2022-12-31 15:56:12,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:12,336 INFO:     Epoch: 14
2022-12-31 15:56:13,921 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4608850320180257, 'Total loss': 0.4608850320180257} | train loss {'Reaction outcome loss': 0.41065842086428644, 'Total loss': 0.41065842086428644}
2022-12-31 15:56:13,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:13,922 INFO:     Epoch: 15
2022-12-31 15:56:15,492 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46657653351624806, 'Total loss': 0.46657653351624806} | train loss {'Reaction outcome loss': 0.40369386203944463, 'Total loss': 0.40369386203944463}
2022-12-31 15:56:15,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:15,493 INFO:     Epoch: 16
2022-12-31 15:56:17,067 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4646766056617101, 'Total loss': 0.4646766056617101} | train loss {'Reaction outcome loss': 0.39475337396688565, 'Total loss': 0.39475337396688565}
2022-12-31 15:56:17,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:17,067 INFO:     Epoch: 17
2022-12-31 15:56:18,666 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44558356404304506, 'Total loss': 0.44558356404304506} | train loss {'Reaction outcome loss': 0.3937412104208531, 'Total loss': 0.3937412104208531}
2022-12-31 15:56:18,666 INFO:     Found new best model at epoch 17
2022-12-31 15:56:18,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:18,667 INFO:     Epoch: 18
2022-12-31 15:56:20,249 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41147574931383135, 'Total loss': 0.41147574931383135} | train loss {'Reaction outcome loss': 0.38270520143953196, 'Total loss': 0.38270520143953196}
2022-12-31 15:56:20,249 INFO:     Found new best model at epoch 18
2022-12-31 15:56:20,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:20,250 INFO:     Epoch: 19
2022-12-31 15:56:21,834 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46149555246035256, 'Total loss': 0.46149555246035256} | train loss {'Reaction outcome loss': 0.37935859652242976, 'Total loss': 0.37935859652242976}
2022-12-31 15:56:21,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:21,834 INFO:     Epoch: 20
2022-12-31 15:56:23,402 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4499999344348907, 'Total loss': 0.4499999344348907} | train loss {'Reaction outcome loss': 0.3722622329403554, 'Total loss': 0.3722622329403554}
2022-12-31 15:56:23,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:23,403 INFO:     Epoch: 21
2022-12-31 15:56:24,988 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4710852265357971, 'Total loss': 0.4710852265357971} | train loss {'Reaction outcome loss': 0.37077202557197797, 'Total loss': 0.37077202557197797}
2022-12-31 15:56:24,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:24,989 INFO:     Epoch: 22
2022-12-31 15:56:26,561 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4527418116728465, 'Total loss': 0.4527418116728465} | train loss {'Reaction outcome loss': 0.3601426836859256, 'Total loss': 0.3601426836859256}
2022-12-31 15:56:26,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:26,562 INFO:     Epoch: 23
2022-12-31 15:56:28,146 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42087464928627016, 'Total loss': 0.42087464928627016} | train loss {'Reaction outcome loss': 0.3515906488433535, 'Total loss': 0.3515906488433535}
2022-12-31 15:56:28,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:28,147 INFO:     Epoch: 24
2022-12-31 15:56:29,730 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43554487923781077, 'Total loss': 0.43554487923781077} | train loss {'Reaction outcome loss': 0.3488519061150586, 'Total loss': 0.3488519061150586}
2022-12-31 15:56:29,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:29,731 INFO:     Epoch: 25
2022-12-31 15:56:31,316 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3975226809581121, 'Total loss': 0.3975226809581121} | train loss {'Reaction outcome loss': 0.34569071740516877, 'Total loss': 0.34569071740516877}
2022-12-31 15:56:31,316 INFO:     Found new best model at epoch 25
2022-12-31 15:56:31,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:31,317 INFO:     Epoch: 26
2022-12-31 15:56:32,885 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4292174458503723, 'Total loss': 0.4292174458503723} | train loss {'Reaction outcome loss': 0.3409485238092192, 'Total loss': 0.3409485238092192}
2022-12-31 15:56:32,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:32,885 INFO:     Epoch: 27
2022-12-31 15:56:34,459 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42717902759710946, 'Total loss': 0.42717902759710946} | train loss {'Reaction outcome loss': 0.33664891516920387, 'Total loss': 0.33664891516920387}
2022-12-31 15:56:34,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:34,461 INFO:     Epoch: 28
2022-12-31 15:56:36,078 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.427164680759112, 'Total loss': 0.427164680759112} | train loss {'Reaction outcome loss': 0.32616018743092723, 'Total loss': 0.32616018743092723}
2022-12-31 15:56:36,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:36,078 INFO:     Epoch: 29
2022-12-31 15:56:37,671 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47506763438383737, 'Total loss': 0.47506763438383737} | train loss {'Reaction outcome loss': 0.3240587137831973, 'Total loss': 0.3240587137831973}
2022-12-31 15:56:37,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:37,671 INFO:     Epoch: 30
2022-12-31 15:56:39,254 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4306840757528941, 'Total loss': 0.4306840757528941} | train loss {'Reaction outcome loss': 0.32054967114296345, 'Total loss': 0.32054967114296345}
2022-12-31 15:56:39,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:39,255 INFO:     Epoch: 31
2022-12-31 15:56:40,840 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42505763669808705, 'Total loss': 0.42505763669808705} | train loss {'Reaction outcome loss': 0.312560758288826, 'Total loss': 0.312560758288826}
2022-12-31 15:56:40,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:40,841 INFO:     Epoch: 32
2022-12-31 15:56:42,417 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3928486853837967, 'Total loss': 0.3928486853837967} | train loss {'Reaction outcome loss': 0.3151619347066677, 'Total loss': 0.3151619347066677}
2022-12-31 15:56:42,417 INFO:     Found new best model at epoch 32
2022-12-31 15:56:42,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:42,418 INFO:     Epoch: 33
2022-12-31 15:56:43,983 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42109564940134686, 'Total loss': 0.42109564940134686} | train loss {'Reaction outcome loss': 0.3055574703700428, 'Total loss': 0.3055574703700428}
2022-12-31 15:56:43,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:43,983 INFO:     Epoch: 34
2022-12-31 15:56:45,567 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44052385886510215, 'Total loss': 0.44052385886510215} | train loss {'Reaction outcome loss': 0.3044308986775989, 'Total loss': 0.3044308986775989}
2022-12-31 15:56:45,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:45,567 INFO:     Epoch: 35
2022-12-31 15:56:47,155 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4321604460477829, 'Total loss': 0.4321604460477829} | train loss {'Reaction outcome loss': 0.29892763271377976, 'Total loss': 0.29892763271377976}
2022-12-31 15:56:47,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:47,155 INFO:     Epoch: 36
2022-12-31 15:56:48,751 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4285533756017685, 'Total loss': 0.4285533756017685} | train loss {'Reaction outcome loss': 0.2961728217362038, 'Total loss': 0.2961728217362038}
2022-12-31 15:56:48,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:48,751 INFO:     Epoch: 37
2022-12-31 15:56:50,332 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42757340172926583, 'Total loss': 0.42757340172926583} | train loss {'Reaction outcome loss': 0.28846986874992997, 'Total loss': 0.28846986874992997}
2022-12-31 15:56:50,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:50,332 INFO:     Epoch: 38
2022-12-31 15:56:51,914 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4017587393522263, 'Total loss': 0.4017587393522263} | train loss {'Reaction outcome loss': 0.2865054924384694, 'Total loss': 0.2865054924384694}
2022-12-31 15:56:51,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:51,915 INFO:     Epoch: 39
2022-12-31 15:56:53,503 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45551647345225016, 'Total loss': 0.45551647345225016} | train loss {'Reaction outcome loss': 0.2840835671885647, 'Total loss': 0.2840835671885647}
2022-12-31 15:56:53,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:53,504 INFO:     Epoch: 40
2022-12-31 15:56:55,103 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38814229567845665, 'Total loss': 0.38814229567845665} | train loss {'Reaction outcome loss': 0.2815365938407908, 'Total loss': 0.2815365938407908}
2022-12-31 15:56:55,103 INFO:     Found new best model at epoch 40
2022-12-31 15:56:55,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:55,104 INFO:     Epoch: 41
2022-12-31 15:56:56,685 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4184712365269661, 'Total loss': 0.4184712365269661} | train loss {'Reaction outcome loss': 0.2756687518332937, 'Total loss': 0.2756687518332937}
2022-12-31 15:56:56,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:56,685 INFO:     Epoch: 42
2022-12-31 15:56:58,270 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.37813725719849267, 'Total loss': 0.37813725719849267} | train loss {'Reaction outcome loss': 0.2751861296979044, 'Total loss': 0.2751861296979044}
2022-12-31 15:56:58,270 INFO:     Found new best model at epoch 42
2022-12-31 15:56:58,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:58,271 INFO:     Epoch: 43
2022-12-31 15:56:59,844 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4151570608218511, 'Total loss': 0.4151570608218511} | train loss {'Reaction outcome loss': 0.2696621184446935, 'Total loss': 0.2696621184446935}
2022-12-31 15:56:59,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:56:59,844 INFO:     Epoch: 44
2022-12-31 15:57:01,426 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46560610830783844, 'Total loss': 0.46560610830783844} | train loss {'Reaction outcome loss': 0.2726019252559026, 'Total loss': 0.2726019252559026}
2022-12-31 15:57:01,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:01,426 INFO:     Epoch: 45
2022-12-31 15:57:03,029 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.37988918324311577, 'Total loss': 0.37988918324311577} | train loss {'Reaction outcome loss': 0.2708230298356156, 'Total loss': 0.2708230298356156}
2022-12-31 15:57:03,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:03,029 INFO:     Epoch: 46
2022-12-31 15:57:04,625 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4009836107182006, 'Total loss': 0.4009836107182006} | train loss {'Reaction outcome loss': 0.2656505051038032, 'Total loss': 0.2656505051038032}
2022-12-31 15:57:04,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:04,625 INFO:     Epoch: 47
2022-12-31 15:57:06,212 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4371556927760442, 'Total loss': 0.4371556927760442} | train loss {'Reaction outcome loss': 0.2583015177027766, 'Total loss': 0.2583015177027766}
2022-12-31 15:57:06,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:06,212 INFO:     Epoch: 48
2022-12-31 15:57:07,796 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37550060351689657, 'Total loss': 0.37550060351689657} | train loss {'Reaction outcome loss': 0.26057069486770024, 'Total loss': 0.26057069486770024}
2022-12-31 15:57:07,796 INFO:     Found new best model at epoch 48
2022-12-31 15:57:07,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:07,797 INFO:     Epoch: 49
2022-12-31 15:57:09,366 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.386124885144333, 'Total loss': 0.386124885144333} | train loss {'Reaction outcome loss': 0.25700651973870847, 'Total loss': 0.25700651973870847}
2022-12-31 15:57:09,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:09,366 INFO:     Epoch: 50
2022-12-31 15:57:10,936 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42439027031262716, 'Total loss': 0.42439027031262716} | train loss {'Reaction outcome loss': 0.2548731394469518, 'Total loss': 0.2548731394469518}
2022-12-31 15:57:10,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:10,937 INFO:     Epoch: 51
2022-12-31 15:57:12,551 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44002586752176287, 'Total loss': 0.44002586752176287} | train loss {'Reaction outcome loss': 0.25310406306023087, 'Total loss': 0.25310406306023087}
2022-12-31 15:57:12,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:12,552 INFO:     Epoch: 52
2022-12-31 15:57:14,141 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40935849299033483, 'Total loss': 0.40935849299033483} | train loss {'Reaction outcome loss': 0.2515696579679792, 'Total loss': 0.2515696579679792}
2022-12-31 15:57:14,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:14,142 INFO:     Epoch: 53
2022-12-31 15:57:15,744 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42072573602199553, 'Total loss': 0.42072573602199553} | train loss {'Reaction outcome loss': 0.2485039772197769, 'Total loss': 0.2485039772197769}
2022-12-31 15:57:15,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:15,744 INFO:     Epoch: 54
2022-12-31 15:57:17,349 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4366919716199239, 'Total loss': 0.4366919716199239} | train loss {'Reaction outcome loss': 0.24447054400820134, 'Total loss': 0.24447054400820134}
2022-12-31 15:57:17,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:17,350 INFO:     Epoch: 55
2022-12-31 15:57:18,943 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45615011751651763, 'Total loss': 0.45615011751651763} | train loss {'Reaction outcome loss': 0.24900213903936513, 'Total loss': 0.24900213903936513}
2022-12-31 15:57:18,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:18,944 INFO:     Epoch: 56
2022-12-31 15:57:20,518 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39230035841464994, 'Total loss': 0.39230035841464994} | train loss {'Reaction outcome loss': 0.2347170487802297, 'Total loss': 0.2347170487802297}
2022-12-31 15:57:20,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:20,519 INFO:     Epoch: 57
2022-12-31 15:57:22,101 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39161488811175027, 'Total loss': 0.39161488811175027} | train loss {'Reaction outcome loss': 0.24310043423928018, 'Total loss': 0.24310043423928018}
2022-12-31 15:57:22,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:22,101 INFO:     Epoch: 58
2022-12-31 15:57:23,683 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4152668952941895, 'Total loss': 0.4152668952941895} | train loss {'Reaction outcome loss': 0.24090038727955185, 'Total loss': 0.24090038727955185}
2022-12-31 15:57:23,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:23,683 INFO:     Epoch: 59
2022-12-31 15:57:25,267 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4105182230472565, 'Total loss': 0.4105182230472565} | train loss {'Reaction outcome loss': 0.23693330933741977, 'Total loss': 0.23693330933741977}
2022-12-31 15:57:25,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:25,267 INFO:     Epoch: 60
2022-12-31 15:57:26,840 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4550021544098854, 'Total loss': 0.4550021544098854} | train loss {'Reaction outcome loss': 0.23832619748322287, 'Total loss': 0.23832619748322287}
2022-12-31 15:57:26,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:26,840 INFO:     Epoch: 61
2022-12-31 15:57:28,422 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3971591889858246, 'Total loss': 0.3971591889858246} | train loss {'Reaction outcome loss': 0.23569132134703252, 'Total loss': 0.23569132134703252}
2022-12-31 15:57:28,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:28,422 INFO:     Epoch: 62
2022-12-31 15:57:30,019 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43045518894990287, 'Total loss': 0.43045518894990287} | train loss {'Reaction outcome loss': 0.23255883749725634, 'Total loss': 0.23255883749725634}
2022-12-31 15:57:30,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:30,020 INFO:     Epoch: 63
2022-12-31 15:57:31,633 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3693118135134379, 'Total loss': 0.3693118135134379} | train loss {'Reaction outcome loss': 0.22906387571204193, 'Total loss': 0.22906387571204193}
2022-12-31 15:57:31,633 INFO:     Found new best model at epoch 63
2022-12-31 15:57:31,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:31,634 INFO:     Epoch: 64
2022-12-31 15:57:33,253 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3891620675722758, 'Total loss': 0.3891620675722758} | train loss {'Reaction outcome loss': 0.22527515900585923, 'Total loss': 0.22527515900585923}
2022-12-31 15:57:33,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:33,253 INFO:     Epoch: 65
2022-12-31 15:57:34,883 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4310504128535589, 'Total loss': 0.4310504128535589} | train loss {'Reaction outcome loss': 0.22700047409814883, 'Total loss': 0.22700047409814883}
2022-12-31 15:57:34,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:34,883 INFO:     Epoch: 66
2022-12-31 15:57:36,461 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40623740951220194, 'Total loss': 0.40623740951220194} | train loss {'Reaction outcome loss': 0.2260911735324567, 'Total loss': 0.2260911735324567}
2022-12-31 15:57:36,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:36,461 INFO:     Epoch: 67
2022-12-31 15:57:38,054 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39268478751182556, 'Total loss': 0.39268478751182556} | train loss {'Reaction outcome loss': 0.22484115399145332, 'Total loss': 0.22484115399145332}
2022-12-31 15:57:38,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:38,055 INFO:     Epoch: 68
2022-12-31 15:57:39,647 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4212200264135996, 'Total loss': 0.4212200264135996} | train loss {'Reaction outcome loss': 0.22066073324118923, 'Total loss': 0.22066073324118923}
2022-12-31 15:57:39,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:39,647 INFO:     Epoch: 69
2022-12-31 15:57:41,244 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44125715345144273, 'Total loss': 0.44125715345144273} | train loss {'Reaction outcome loss': 0.22993998714753622, 'Total loss': 0.22993998714753622}
2022-12-31 15:57:41,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:41,246 INFO:     Epoch: 70
2022-12-31 15:57:42,824 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39940056403477986, 'Total loss': 0.39940056403477986} | train loss {'Reaction outcome loss': 0.2178892633461864, 'Total loss': 0.2178892633461864}
2022-12-31 15:57:42,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:42,825 INFO:     Epoch: 71
2022-12-31 15:57:44,406 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4162306129932404, 'Total loss': 0.4162306129932404} | train loss {'Reaction outcome loss': 0.22558949525533348, 'Total loss': 0.22558949525533348}
2022-12-31 15:57:44,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:44,406 INFO:     Epoch: 72
2022-12-31 15:57:46,007 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40731548617283503, 'Total loss': 0.40731548617283503} | train loss {'Reaction outcome loss': 0.21613907491671422, 'Total loss': 0.21613907491671422}
2022-12-31 15:57:46,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:46,007 INFO:     Epoch: 73
2022-12-31 15:57:47,585 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39873170852661133, 'Total loss': 0.39873170852661133} | train loss {'Reaction outcome loss': 0.21407305438250193, 'Total loss': 0.21407305438250193}
2022-12-31 15:57:47,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:47,586 INFO:     Epoch: 74
2022-12-31 15:57:49,175 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38970327029625573, 'Total loss': 0.38970327029625573} | train loss {'Reaction outcome loss': 0.21921696695344475, 'Total loss': 0.21921696695344475}
2022-12-31 15:57:49,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:49,175 INFO:     Epoch: 75
2022-12-31 15:57:50,782 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49713570723930994, 'Total loss': 0.49713570723930994} | train loss {'Reaction outcome loss': 0.2166846792086464, 'Total loss': 0.2166846792086464}
2022-12-31 15:57:50,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:50,782 INFO:     Epoch: 76
2022-12-31 15:57:52,393 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.407888351380825, 'Total loss': 0.407888351380825} | train loss {'Reaction outcome loss': 0.22312486678279414, 'Total loss': 0.22312486678279414}
2022-12-31 15:57:52,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:52,393 INFO:     Epoch: 77
2022-12-31 15:57:53,930 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.432075788329045, 'Total loss': 0.432075788329045} | train loss {'Reaction outcome loss': 0.21136297454638234, 'Total loss': 0.21136297454638234}
2022-12-31 15:57:53,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:53,930 INFO:     Epoch: 78
2022-12-31 15:57:54,994 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38854035884141924, 'Total loss': 0.38854035884141924} | train loss {'Reaction outcome loss': 0.21908398615918037, 'Total loss': 0.21908398615918037}
2022-12-31 15:57:54,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:54,994 INFO:     Epoch: 79
2022-12-31 15:57:56,062 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4147811810175578, 'Total loss': 0.4147811810175578} | train loss {'Reaction outcome loss': 0.2159431381804037, 'Total loss': 0.2159431381804037}
2022-12-31 15:57:56,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:56,063 INFO:     Epoch: 80
2022-12-31 15:57:57,122 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4261711726586024, 'Total loss': 0.4261711726586024} | train loss {'Reaction outcome loss': 0.2039376578853909, 'Total loss': 0.2039376578853909}
2022-12-31 15:57:57,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:57,122 INFO:     Epoch: 81
2022-12-31 15:57:58,178 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4159025212128957, 'Total loss': 0.4159025212128957} | train loss {'Reaction outcome loss': 0.21142507486072853, 'Total loss': 0.21142507486072853}
2022-12-31 15:57:58,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:58,178 INFO:     Epoch: 82
2022-12-31 15:57:59,652 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42106512784957884, 'Total loss': 0.42106512784957884} | train loss {'Reaction outcome loss': 0.21317762920007494, 'Total loss': 0.21317762920007494}
2022-12-31 15:57:59,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:57:59,653 INFO:     Epoch: 83
2022-12-31 15:58:01,259 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3720145548383395, 'Total loss': 0.3720145548383395} | train loss {'Reaction outcome loss': 0.20358917704779944, 'Total loss': 0.20358917704779944}
2022-12-31 15:58:01,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:01,260 INFO:     Epoch: 84
2022-12-31 15:58:02,837 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.39140455226103466, 'Total loss': 0.39140455226103466} | train loss {'Reaction outcome loss': 0.20274638136457032, 'Total loss': 0.20274638136457032}
2022-12-31 15:58:02,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:02,837 INFO:     Epoch: 85
2022-12-31 15:58:04,439 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4286195144057274, 'Total loss': 0.4286195144057274} | train loss {'Reaction outcome loss': 0.2070578586488852, 'Total loss': 0.2070578586488852}
2022-12-31 15:58:04,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:04,439 INFO:     Epoch: 86
2022-12-31 15:58:06,058 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3921954164902369, 'Total loss': 0.3921954164902369} | train loss {'Reaction outcome loss': 0.2089088399416846, 'Total loss': 0.2089088399416846}
2022-12-31 15:58:06,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:06,059 INFO:     Epoch: 87
2022-12-31 15:58:07,663 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40755633811155956, 'Total loss': 0.40755633811155956} | train loss {'Reaction outcome loss': 0.204809318691822, 'Total loss': 0.204809318691822}
2022-12-31 15:58:07,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:07,663 INFO:     Epoch: 88
2022-12-31 15:58:09,253 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39751308063666024, 'Total loss': 0.39751308063666024} | train loss {'Reaction outcome loss': 0.20065150511660698, 'Total loss': 0.20065150511660698}
2022-12-31 15:58:09,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:09,253 INFO:     Epoch: 89
2022-12-31 15:58:10,868 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4022081424792608, 'Total loss': 0.4022081424792608} | train loss {'Reaction outcome loss': 0.19745435951470064, 'Total loss': 0.19745435951470064}
2022-12-31 15:58:10,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:10,868 INFO:     Epoch: 90
2022-12-31 15:58:12,437 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4192304362853368, 'Total loss': 0.4192304362853368} | train loss {'Reaction outcome loss': 0.20004794769319, 'Total loss': 0.20004794769319}
2022-12-31 15:58:12,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:12,438 INFO:     Epoch: 91
2022-12-31 15:58:14,046 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42540915459394457, 'Total loss': 0.42540915459394457} | train loss {'Reaction outcome loss': 0.19831159414304247, 'Total loss': 0.19831159414304247}
2022-12-31 15:58:14,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:14,046 INFO:     Epoch: 92
2022-12-31 15:58:15,648 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4113624796271324, 'Total loss': 0.4113624796271324} | train loss {'Reaction outcome loss': 0.1966226677379375, 'Total loss': 0.1966226677379375}
2022-12-31 15:58:15,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:15,648 INFO:     Epoch: 93
2022-12-31 15:58:17,252 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3951277719810605, 'Total loss': 0.3951277719810605} | train loss {'Reaction outcome loss': 0.19320300068857485, 'Total loss': 0.19320300068857485}
2022-12-31 15:58:17,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:17,252 INFO:     Epoch: 94
2022-12-31 15:58:18,846 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4008197655280431, 'Total loss': 0.4008197655280431} | train loss {'Reaction outcome loss': 0.1961039921605609, 'Total loss': 0.1961039921605609}
2022-12-31 15:58:18,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:18,846 INFO:     Epoch: 95
2022-12-31 15:58:20,426 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4625591367483139, 'Total loss': 0.4625591367483139} | train loss {'Reaction outcome loss': 0.19814239621739765, 'Total loss': 0.19814239621739765}
2022-12-31 15:58:20,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:20,427 INFO:     Epoch: 96
2022-12-31 15:58:22,010 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3896060009797414, 'Total loss': 0.3896060009797414} | train loss {'Reaction outcome loss': 0.19439806337588608, 'Total loss': 0.19439806337588608}
2022-12-31 15:58:22,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:22,010 INFO:     Epoch: 97
2022-12-31 15:58:23,624 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4290364633003871, 'Total loss': 0.4290364633003871} | train loss {'Reaction outcome loss': 0.19983495216098413, 'Total loss': 0.19983495216098413}
2022-12-31 15:58:23,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:23,624 INFO:     Epoch: 98
2022-12-31 15:58:25,236 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42948482036590574, 'Total loss': 0.42948482036590574} | train loss {'Reaction outcome loss': 0.1982756649106191, 'Total loss': 0.1982756649106191}
2022-12-31 15:58:25,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:25,236 INFO:     Epoch: 99
2022-12-31 15:58:26,803 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41872167537609734, 'Total loss': 0.41872167537609734} | train loss {'Reaction outcome loss': 0.19133219536655063, 'Total loss': 0.19133219536655063}
2022-12-31 15:58:26,803 INFO:     Best model found after epoch 64 of 100.
2022-12-31 15:58:26,803 INFO:   Done with stage: TRAINING
2022-12-31 15:58:26,803 INFO:   Starting stage: EVALUATION
2022-12-31 15:58:26,948 INFO:   Done with stage: EVALUATION
2022-12-31 15:58:26,948 INFO:   Leaving out SEQ value Fold_4
2022-12-31 15:58:26,961 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 15:58:26,961 INFO:   Starting stage: FEATURE SCALING
2022-12-31 15:58:27,632 INFO:   Done with stage: FEATURE SCALING
2022-12-31 15:58:27,632 INFO:   Starting stage: SCALING TARGETS
2022-12-31 15:58:27,702 INFO:   Done with stage: SCALING TARGETS
2022-12-31 15:58:27,702 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:58:27,702 INFO:     No hyperparam tuning for this model
2022-12-31 15:58:27,702 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 15:58:27,702 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 15:58:27,703 INFO:     None feature selector for col prot
2022-12-31 15:58:27,703 INFO:     None feature selector for col prot
2022-12-31 15:58:27,703 INFO:     None feature selector for col prot
2022-12-31 15:58:27,703 INFO:     None feature selector for col chem
2022-12-31 15:58:27,703 INFO:     None feature selector for col chem
2022-12-31 15:58:27,704 INFO:     None feature selector for col chem
2022-12-31 15:58:27,704 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 15:58:27,704 INFO:   Starting stage: BUILD MODEL
2022-12-31 15:58:27,705 INFO:     Number of params in model 223921
2022-12-31 15:58:27,709 INFO:   Done with stage: BUILD MODEL
2022-12-31 15:58:27,709 INFO:   Starting stage: TRAINING
2022-12-31 15:58:27,753 INFO:     Val loss before train {'Reaction outcome loss': 0.9204048117001852, 'Total loss': 0.9204048117001852}
2022-12-31 15:58:27,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:27,753 INFO:     Epoch: 0
2022-12-31 15:58:29,382 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6302304625511169, 'Total loss': 0.6302304625511169} | train loss {'Reaction outcome loss': 0.8082150819069212, 'Total loss': 0.8082150819069212}
2022-12-31 15:58:29,382 INFO:     Found new best model at epoch 0
2022-12-31 15:58:29,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:29,383 INFO:     Epoch: 1
2022-12-31 15:58:31,006 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5678970297177632, 'Total loss': 0.5678970297177632} | train loss {'Reaction outcome loss': 0.6013526251600108, 'Total loss': 0.6013526251600108}
2022-12-31 15:58:31,007 INFO:     Found new best model at epoch 1
2022-12-31 15:58:31,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:31,008 INFO:     Epoch: 2
2022-12-31 15:58:32,657 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5106304665406545, 'Total loss': 0.5106304665406545} | train loss {'Reaction outcome loss': 0.5340112358977218, 'Total loss': 0.5340112358977218}
2022-12-31 15:58:32,657 INFO:     Found new best model at epoch 2
2022-12-31 15:58:32,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:32,659 INFO:     Epoch: 3
2022-12-31 15:58:34,305 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4848588983217875, 'Total loss': 0.4848588983217875} | train loss {'Reaction outcome loss': 0.508182467643965, 'Total loss': 0.508182467643965}
2022-12-31 15:58:34,305 INFO:     Found new best model at epoch 3
2022-12-31 15:58:34,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:34,306 INFO:     Epoch: 4
2022-12-31 15:58:35,926 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4562110642592112, 'Total loss': 0.4562110642592112} | train loss {'Reaction outcome loss': 0.49421793190150487, 'Total loss': 0.49421793190150487}
2022-12-31 15:58:35,926 INFO:     Found new best model at epoch 4
2022-12-31 15:58:35,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:35,927 INFO:     Epoch: 5
2022-12-31 15:58:37,556 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48460972905158994, 'Total loss': 0.48460972905158994} | train loss {'Reaction outcome loss': 0.4836309048135358, 'Total loss': 0.4836309048135358}
2022-12-31 15:58:37,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:37,556 INFO:     Epoch: 6
2022-12-31 15:58:39,189 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47102954387664797, 'Total loss': 0.47102954387664797} | train loss {'Reaction outcome loss': 0.47251951210335275, 'Total loss': 0.47251951210335275}
2022-12-31 15:58:39,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:39,189 INFO:     Epoch: 7
2022-12-31 15:58:40,800 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4435552924871445, 'Total loss': 0.4435552924871445} | train loss {'Reaction outcome loss': 0.4685691346545512, 'Total loss': 0.4685691346545512}
2022-12-31 15:58:40,800 INFO:     Found new best model at epoch 7
2022-12-31 15:58:40,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:40,801 INFO:     Epoch: 8
2022-12-31 15:58:42,409 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4537108560403188, 'Total loss': 0.4537108560403188} | train loss {'Reaction outcome loss': 0.4572725677963629, 'Total loss': 0.4572725677963629}
2022-12-31 15:58:42,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:42,409 INFO:     Epoch: 9
2022-12-31 15:58:44,013 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4613575537999471, 'Total loss': 0.4613575537999471} | train loss {'Reaction outcome loss': 0.45346147255023894, 'Total loss': 0.45346147255023894}
2022-12-31 15:58:44,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:44,015 INFO:     Epoch: 10
2022-12-31 15:58:45,651 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4204832057158152, 'Total loss': 0.4204832057158152} | train loss {'Reaction outcome loss': 0.4472364113003769, 'Total loss': 0.4472364113003769}
2022-12-31 15:58:45,651 INFO:     Found new best model at epoch 10
2022-12-31 15:58:45,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:45,652 INFO:     Epoch: 11
2022-12-31 15:58:47,268 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42758950690428416, 'Total loss': 0.42758950690428416} | train loss {'Reaction outcome loss': 0.44015873777629666, 'Total loss': 0.44015873777629666}
2022-12-31 15:58:47,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:47,268 INFO:     Epoch: 12
2022-12-31 15:58:48,856 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4117415229479472, 'Total loss': 0.4117415229479472} | train loss {'Reaction outcome loss': 0.43670381906876066, 'Total loss': 0.43670381906876066}
2022-12-31 15:58:48,856 INFO:     Found new best model at epoch 12
2022-12-31 15:58:48,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:48,857 INFO:     Epoch: 13
2022-12-31 15:58:50,479 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41999276330073676, 'Total loss': 0.41999276330073676} | train loss {'Reaction outcome loss': 0.4243254331528925, 'Total loss': 0.4243254331528925}
2022-12-31 15:58:50,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:50,480 INFO:     Epoch: 14
2022-12-31 15:58:52,107 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42060140570004784, 'Total loss': 0.42060140570004784} | train loss {'Reaction outcome loss': 0.42371679417493113, 'Total loss': 0.42371679417493113}
2022-12-31 15:58:52,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:52,108 INFO:     Epoch: 15
2022-12-31 15:58:53,734 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41468677123387654, 'Total loss': 0.41468677123387654} | train loss {'Reaction outcome loss': 0.41987657885904345, 'Total loss': 0.41987657885904345}
2022-12-31 15:58:53,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:53,734 INFO:     Epoch: 16
2022-12-31 15:58:55,379 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4128689428170522, 'Total loss': 0.4128689428170522} | train loss {'Reaction outcome loss': 0.40957799365589337, 'Total loss': 0.40957799365589337}
2022-12-31 15:58:55,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:55,379 INFO:     Epoch: 17
2022-12-31 15:58:57,011 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39358756244182586, 'Total loss': 0.39358756244182586} | train loss {'Reaction outcome loss': 0.40588283296741734, 'Total loss': 0.40588283296741734}
2022-12-31 15:58:57,011 INFO:     Found new best model at epoch 17
2022-12-31 15:58:57,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:57,012 INFO:     Epoch: 18
2022-12-31 15:58:58,659 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40671621561050414, 'Total loss': 0.40671621561050414} | train loss {'Reaction outcome loss': 0.3948812933927839, 'Total loss': 0.3948812933927839}
2022-12-31 15:58:58,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:58:58,659 INFO:     Epoch: 19
2022-12-31 15:59:00,312 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39962754348913826, 'Total loss': 0.39962754348913826} | train loss {'Reaction outcome loss': 0.39400495314425943, 'Total loss': 0.39400495314425943}
2022-12-31 15:59:00,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:00,313 INFO:     Epoch: 20
2022-12-31 15:59:01,942 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3809271067380905, 'Total loss': 0.3809271067380905} | train loss {'Reaction outcome loss': 0.38932329222613726, 'Total loss': 0.38932329222613726}
2022-12-31 15:59:01,942 INFO:     Found new best model at epoch 20
2022-12-31 15:59:01,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:01,943 INFO:     Epoch: 21
2022-12-31 15:59:03,606 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42602954705556234, 'Total loss': 0.42602954705556234} | train loss {'Reaction outcome loss': 0.3840633025023051, 'Total loss': 0.3840633025023051}
2022-12-31 15:59:03,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:03,607 INFO:     Epoch: 22
2022-12-31 15:59:05,257 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39613249798615774, 'Total loss': 0.39613249798615774} | train loss {'Reaction outcome loss': 0.37487459561992637, 'Total loss': 0.37487459561992637}
2022-12-31 15:59:05,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:05,258 INFO:     Epoch: 23
2022-12-31 15:59:06,867 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39518842796484627, 'Total loss': 0.39518842796484627} | train loss {'Reaction outcome loss': 0.3801529401583792, 'Total loss': 0.3801529401583792}
2022-12-31 15:59:06,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:06,867 INFO:     Epoch: 24
2022-12-31 15:59:08,512 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38070491353670755, 'Total loss': 0.38070491353670755} | train loss {'Reaction outcome loss': 0.37048328006202996, 'Total loss': 0.37048328006202996}
2022-12-31 15:59:08,512 INFO:     Found new best model at epoch 24
2022-12-31 15:59:08,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:08,513 INFO:     Epoch: 25
2022-12-31 15:59:10,159 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39828013082345326, 'Total loss': 0.39828013082345326} | train loss {'Reaction outcome loss': 0.362412154540043, 'Total loss': 0.362412154540043}
2022-12-31 15:59:10,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:10,159 INFO:     Epoch: 26
2022-12-31 15:59:11,789 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3931069483359655, 'Total loss': 0.3931069483359655} | train loss {'Reaction outcome loss': 0.3576635608671482, 'Total loss': 0.3576635608671482}
2022-12-31 15:59:11,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:11,790 INFO:     Epoch: 27
2022-12-31 15:59:13,449 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.37814324299494423, 'Total loss': 0.37814324299494423} | train loss {'Reaction outcome loss': 0.35234905416246787, 'Total loss': 0.35234905416246787}
2022-12-31 15:59:13,449 INFO:     Found new best model at epoch 27
2022-12-31 15:59:13,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:13,450 INFO:     Epoch: 28
2022-12-31 15:59:15,104 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.406431171298027, 'Total loss': 0.406431171298027} | train loss {'Reaction outcome loss': 0.3505364275581139, 'Total loss': 0.3505364275581139}
2022-12-31 15:59:15,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:15,104 INFO:     Epoch: 29
2022-12-31 15:59:16,730 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3688148538271586, 'Total loss': 0.3688148538271586} | train loss {'Reaction outcome loss': 0.34619325185564453, 'Total loss': 0.34619325185564453}
2022-12-31 15:59:16,730 INFO:     Found new best model at epoch 29
2022-12-31 15:59:16,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:16,731 INFO:     Epoch: 30
2022-12-31 15:59:18,379 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38373423914114635, 'Total loss': 0.38373423914114635} | train loss {'Reaction outcome loss': 0.337578619497455, 'Total loss': 0.337578619497455}
2022-12-31 15:59:18,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:18,379 INFO:     Epoch: 31
2022-12-31 15:59:20,029 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3857415248950323, 'Total loss': 0.3857415248950323} | train loss {'Reaction outcome loss': 0.3322570168477103, 'Total loss': 0.3322570168477103}
2022-12-31 15:59:20,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:20,030 INFO:     Epoch: 32
2022-12-31 15:59:21,655 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4110270828008652, 'Total loss': 0.4110270828008652} | train loss {'Reaction outcome loss': 0.3282749316107065, 'Total loss': 0.3282749316107065}
2022-12-31 15:59:21,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:21,655 INFO:     Epoch: 33
2022-12-31 15:59:23,301 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3617726465066274, 'Total loss': 0.3617726465066274} | train loss {'Reaction outcome loss': 0.3241026902887365, 'Total loss': 0.3241026902887365}
2022-12-31 15:59:23,301 INFO:     Found new best model at epoch 33
2022-12-31 15:59:23,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:23,302 INFO:     Epoch: 34
2022-12-31 15:59:24,927 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39222467740376793, 'Total loss': 0.39222467740376793} | train loss {'Reaction outcome loss': 0.31245167568218407, 'Total loss': 0.31245167568218407}
2022-12-31 15:59:24,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:24,928 INFO:     Epoch: 35
2022-12-31 15:59:26,558 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39864683598279954, 'Total loss': 0.39864683598279954} | train loss {'Reaction outcome loss': 0.31629474160500165, 'Total loss': 0.31629474160500165}
2022-12-31 15:59:26,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:26,559 INFO:     Epoch: 36
2022-12-31 15:59:28,176 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3902733902136485, 'Total loss': 0.3902733902136485} | train loss {'Reaction outcome loss': 0.308795041798039, 'Total loss': 0.308795041798039}
2022-12-31 15:59:28,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:28,176 INFO:     Epoch: 37
2022-12-31 15:59:29,781 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41012451350688933, 'Total loss': 0.41012451350688933} | train loss {'Reaction outcome loss': 0.3078637790432476, 'Total loss': 0.3078637790432476}
2022-12-31 15:59:29,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:29,781 INFO:     Epoch: 38
2022-12-31 15:59:31,396 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4113806347052256, 'Total loss': 0.4113806347052256} | train loss {'Reaction outcome loss': 0.3020254739960286, 'Total loss': 0.3020254739960286}
2022-12-31 15:59:31,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:31,396 INFO:     Epoch: 39
2022-12-31 15:59:33,013 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40147119760513306, 'Total loss': 0.40147119760513306} | train loss {'Reaction outcome loss': 0.29700988949367285, 'Total loss': 0.29700988949367285}
2022-12-31 15:59:33,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:33,013 INFO:     Epoch: 40
2022-12-31 15:59:34,634 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37183672736088436, 'Total loss': 0.37183672736088436} | train loss {'Reaction outcome loss': 0.2984455967933908, 'Total loss': 0.2984455967933908}
2022-12-31 15:59:34,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:34,635 INFO:     Epoch: 41
2022-12-31 15:59:36,262 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37416926672061285, 'Total loss': 0.37416926672061285} | train loss {'Reaction outcome loss': 0.2948533209437498, 'Total loss': 0.2948533209437498}
2022-12-31 15:59:36,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:36,262 INFO:     Epoch: 42
2022-12-31 15:59:37,911 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.37601752281188966, 'Total loss': 0.37601752281188966} | train loss {'Reaction outcome loss': 0.28808858861561715, 'Total loss': 0.28808858861561715}
2022-12-31 15:59:37,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:37,911 INFO:     Epoch: 43
2022-12-31 15:59:39,519 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.35974333236614864, 'Total loss': 0.35974333236614864} | train loss {'Reaction outcome loss': 0.29239257380689093, 'Total loss': 0.29239257380689093}
2022-12-31 15:59:39,520 INFO:     Found new best model at epoch 43
2022-12-31 15:59:39,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:39,521 INFO:     Epoch: 44
2022-12-31 15:59:41,157 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41095762650171913, 'Total loss': 0.41095762650171913} | train loss {'Reaction outcome loss': 0.2861547510842339, 'Total loss': 0.2861547510842339}
2022-12-31 15:59:41,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:41,158 INFO:     Epoch: 45
2022-12-31 15:59:42,802 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3366735855738322, 'Total loss': 0.3366735855738322} | train loss {'Reaction outcome loss': 0.2762676064153656, 'Total loss': 0.2762676064153656}
2022-12-31 15:59:42,802 INFO:     Found new best model at epoch 45
2022-12-31 15:59:42,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:42,803 INFO:     Epoch: 46
2022-12-31 15:59:44,427 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3832310636838277, 'Total loss': 0.3832310636838277} | train loss {'Reaction outcome loss': 0.2727613453803725, 'Total loss': 0.2727613453803725}
2022-12-31 15:59:44,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:44,427 INFO:     Epoch: 47
2022-12-31 15:59:46,080 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3758986582358678, 'Total loss': 0.3758986582358678} | train loss {'Reaction outcome loss': 0.2723145087447945, 'Total loss': 0.2723145087447945}
2022-12-31 15:59:46,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:46,081 INFO:     Epoch: 48
2022-12-31 15:59:47,702 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3685001447796822, 'Total loss': 0.3685001447796822} | train loss {'Reaction outcome loss': 0.2695091581409158, 'Total loss': 0.2695091581409158}
2022-12-31 15:59:47,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:47,703 INFO:     Epoch: 49
2022-12-31 15:59:49,328 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.36671560605367026, 'Total loss': 0.36671560605367026} | train loss {'Reaction outcome loss': 0.271676622956507, 'Total loss': 0.271676622956507}
2022-12-31 15:59:49,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:49,329 INFO:     Epoch: 50
2022-12-31 15:59:50,963 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.35563145726919176, 'Total loss': 0.35563145726919176} | train loss {'Reaction outcome loss': 0.2642025411034857, 'Total loss': 0.2642025411034857}
2022-12-31 15:59:50,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:50,963 INFO:     Epoch: 51
2022-12-31 15:59:52,575 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3900146861871084, 'Total loss': 0.3900146861871084} | train loss {'Reaction outcome loss': 0.26356265096780623, 'Total loss': 0.26356265096780623}
2022-12-31 15:59:52,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:52,575 INFO:     Epoch: 52
2022-12-31 15:59:54,196 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3254209970434507, 'Total loss': 0.3254209970434507} | train loss {'Reaction outcome loss': 0.26450725698621697, 'Total loss': 0.26450725698621697}
2022-12-31 15:59:54,196 INFO:     Found new best model at epoch 52
2022-12-31 15:59:54,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:54,197 INFO:     Epoch: 53
2022-12-31 15:59:55,818 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3725518763065338, 'Total loss': 0.3725518763065338} | train loss {'Reaction outcome loss': 0.25525484933427095, 'Total loss': 0.25525484933427095}
2022-12-31 15:59:55,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:55,820 INFO:     Epoch: 54
2022-12-31 15:59:57,422 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3991186410188675, 'Total loss': 0.3991186410188675} | train loss {'Reaction outcome loss': 0.2542285730235198, 'Total loss': 0.2542285730235198}
2022-12-31 15:59:57,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:57,422 INFO:     Epoch: 55
2022-12-31 15:59:59,061 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38277748723824817, 'Total loss': 0.38277748723824817} | train loss {'Reaction outcome loss': 0.2585287295241541, 'Total loss': 0.2585287295241541}
2022-12-31 15:59:59,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 15:59:59,061 INFO:     Epoch: 56
2022-12-31 16:00:00,687 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3639829034606616, 'Total loss': 0.3639829034606616} | train loss {'Reaction outcome loss': 0.2517396109279528, 'Total loss': 0.2517396109279528}
2022-12-31 16:00:00,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:00,687 INFO:     Epoch: 57
2022-12-31 16:00:02,308 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.34482811292012533, 'Total loss': 0.34482811292012533} | train loss {'Reaction outcome loss': 0.2553398739075833, 'Total loss': 0.2553398739075833}
2022-12-31 16:00:02,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:02,309 INFO:     Epoch: 58
2022-12-31 16:00:03,951 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39829301337401074, 'Total loss': 0.39829301337401074} | train loss {'Reaction outcome loss': 0.2524776172820842, 'Total loss': 0.2524776172820842}
2022-12-31 16:00:03,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:03,952 INFO:     Epoch: 59
2022-12-31 16:00:05,573 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3532599260409673, 'Total loss': 0.3532599260409673} | train loss {'Reaction outcome loss': 0.24764726590701389, 'Total loss': 0.24764726590701389}
2022-12-31 16:00:05,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:05,573 INFO:     Epoch: 60
2022-12-31 16:00:07,182 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.33986394479870796, 'Total loss': 0.33986394479870796} | train loss {'Reaction outcome loss': 0.24868487192835617, 'Total loss': 0.24868487192835617}
2022-12-31 16:00:07,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:07,182 INFO:     Epoch: 61
2022-12-31 16:00:08,812 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37248508085807164, 'Total loss': 0.37248508085807164} | train loss {'Reaction outcome loss': 0.2462418894098554, 'Total loss': 0.2462418894098554}
2022-12-31 16:00:08,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:08,812 INFO:     Epoch: 62
2022-12-31 16:00:10,446 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3645104944705963, 'Total loss': 0.3645104944705963} | train loss {'Reaction outcome loss': 0.24669395182080003, 'Total loss': 0.24669395182080003}
2022-12-31 16:00:10,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:10,447 INFO:     Epoch: 63
2022-12-31 16:00:12,064 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.34849027792612713, 'Total loss': 0.34849027792612713} | train loss {'Reaction outcome loss': 0.23851804238902102, 'Total loss': 0.23851804238902102}
2022-12-31 16:00:12,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:12,064 INFO:     Epoch: 64
2022-12-31 16:00:13,685 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.403483376900355, 'Total loss': 0.403483376900355} | train loss {'Reaction outcome loss': 0.2415234961745326, 'Total loss': 0.2415234961745326}
2022-12-31 16:00:13,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:13,685 INFO:     Epoch: 65
2022-12-31 16:00:15,282 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38034981737534207, 'Total loss': 0.38034981737534207} | train loss {'Reaction outcome loss': 0.24763157044534004, 'Total loss': 0.24763157044534004}
2022-12-31 16:00:15,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:15,283 INFO:     Epoch: 66
2022-12-31 16:00:16,910 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3539521296819051, 'Total loss': 0.3539521296819051} | train loss {'Reaction outcome loss': 0.2357701671709868, 'Total loss': 0.2357701671709868}
2022-12-31 16:00:16,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:16,910 INFO:     Epoch: 67
2022-12-31 16:00:18,530 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.35796108742554983, 'Total loss': 0.35796108742554983} | train loss {'Reaction outcome loss': 0.2333986443410281, 'Total loss': 0.2333986443410281}
2022-12-31 16:00:18,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:18,530 INFO:     Epoch: 68
2022-12-31 16:00:20,161 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3696358596285184, 'Total loss': 0.3696358596285184} | train loss {'Reaction outcome loss': 0.2414004013265083, 'Total loss': 0.2414004013265083}
2022-12-31 16:00:20,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:20,161 INFO:     Epoch: 69
2022-12-31 16:00:21,812 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.34987274507681526, 'Total loss': 0.34987274507681526} | train loss {'Reaction outcome loss': 0.2231875186775969, 'Total loss': 0.2231875186775969}
2022-12-31 16:00:21,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:21,813 INFO:     Epoch: 70
2022-12-31 16:00:23,436 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3712147086858749, 'Total loss': 0.3712147086858749} | train loss {'Reaction outcome loss': 0.23318569666104197, 'Total loss': 0.23318569666104197}
2022-12-31 16:00:23,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:23,437 INFO:     Epoch: 71
2022-12-31 16:00:25,044 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3729866683483124, 'Total loss': 0.3729866683483124} | train loss {'Reaction outcome loss': 0.22842490240017, 'Total loss': 0.22842490240017}
2022-12-31 16:00:25,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:25,044 INFO:     Epoch: 72
2022-12-31 16:00:26,665 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.36199754377206167, 'Total loss': 0.36199754377206167} | train loss {'Reaction outcome loss': 0.22927327763410252, 'Total loss': 0.22927327763410252}
2022-12-31 16:00:26,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:26,666 INFO:     Epoch: 73
2022-12-31 16:00:28,288 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38046010335286456, 'Total loss': 0.38046010335286456} | train loss {'Reaction outcome loss': 0.2234535112654259, 'Total loss': 0.2234535112654259}
2022-12-31 16:00:28,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:28,288 INFO:     Epoch: 74
2022-12-31 16:00:29,919 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3549162964026133, 'Total loss': 0.3549162964026133} | train loss {'Reaction outcome loss': 0.23018777705325547, 'Total loss': 0.23018777705325547}
2022-12-31 16:00:29,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:29,919 INFO:     Epoch: 75
2022-12-31 16:00:31,543 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3780349651972453, 'Total loss': 0.3780349651972453} | train loss {'Reaction outcome loss': 0.22354302422180503, 'Total loss': 0.22354302422180503}
2022-12-31 16:00:31,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:31,544 INFO:     Epoch: 76
2022-12-31 16:00:33,148 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3978438933690389, 'Total loss': 0.3978438933690389} | train loss {'Reaction outcome loss': 0.21984442071955557, 'Total loss': 0.21984442071955557}
2022-12-31 16:00:33,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:33,148 INFO:     Epoch: 77
2022-12-31 16:00:34,808 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41234805385271706, 'Total loss': 0.41234805385271706} | train loss {'Reaction outcome loss': 0.22317621384206016, 'Total loss': 0.22317621384206016}
2022-12-31 16:00:34,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:34,809 INFO:     Epoch: 78
2022-12-31 16:00:36,442 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42444127301375073, 'Total loss': 0.42444127301375073} | train loss {'Reaction outcome loss': 0.22023076373774436, 'Total loss': 0.22023076373774436}
2022-12-31 16:00:36,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:36,443 INFO:     Epoch: 79
2022-12-31 16:00:38,046 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38029392759005226, 'Total loss': 0.38029392759005226} | train loss {'Reaction outcome loss': 0.22551064631676415, 'Total loss': 0.22551064631676415}
2022-12-31 16:00:38,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:38,047 INFO:     Epoch: 80
2022-12-31 16:00:39,666 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3058202683925629, 'Total loss': 0.3058202683925629} | train loss {'Reaction outcome loss': 0.21912211462156006, 'Total loss': 0.21912211462156006}
2022-12-31 16:00:39,667 INFO:     Found new best model at epoch 80
2022-12-31 16:00:39,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:39,668 INFO:     Epoch: 81
2022-12-31 16:00:41,302 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40884849031766257, 'Total loss': 0.40884849031766257} | train loss {'Reaction outcome loss': 0.21964313683607734, 'Total loss': 0.21964313683607734}
2022-12-31 16:00:41,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:41,302 INFO:     Epoch: 82
2022-12-31 16:00:42,915 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3708460912108421, 'Total loss': 0.3708460912108421} | train loss {'Reaction outcome loss': 0.21333351841579706, 'Total loss': 0.21333351841579706}
2022-12-31 16:00:42,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:42,916 INFO:     Epoch: 83
2022-12-31 16:00:44,540 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3858158667882284, 'Total loss': 0.3858158667882284} | train loss {'Reaction outcome loss': 0.2152873337107445, 'Total loss': 0.2152873337107445}
2022-12-31 16:00:44,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:44,540 INFO:     Epoch: 84
2022-12-31 16:00:46,182 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.35891979237397514, 'Total loss': 0.35891979237397514} | train loss {'Reaction outcome loss': 0.21741495797888036, 'Total loss': 0.21741495797888036}
2022-12-31 16:00:46,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:46,182 INFO:     Epoch: 85
2022-12-31 16:00:47,786 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37314699093500775, 'Total loss': 0.37314699093500775} | train loss {'Reaction outcome loss': 0.21245491618310716, 'Total loss': 0.21245491618310716}
2022-12-31 16:00:47,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:47,787 INFO:     Epoch: 86
2022-12-31 16:00:49,409 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39702662229537966, 'Total loss': 0.39702662229537966} | train loss {'Reaction outcome loss': 0.216139270449965, 'Total loss': 0.216139270449965}
2022-12-31 16:00:49,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:49,409 INFO:     Epoch: 87
2022-12-31 16:00:51,018 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.36587210247914, 'Total loss': 0.36587210247914} | train loss {'Reaction outcome loss': 0.21395697624889953, 'Total loss': 0.21395697624889953}
2022-12-31 16:00:51,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:51,019 INFO:     Epoch: 88
2022-12-31 16:00:52,646 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4054538071155548, 'Total loss': 0.4054538071155548} | train loss {'Reaction outcome loss': 0.20648580809739092, 'Total loss': 0.20648580809739092}
2022-12-31 16:00:52,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:52,646 INFO:     Epoch: 89
2022-12-31 16:00:54,311 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3455893024802208, 'Total loss': 0.3455893024802208} | train loss {'Reaction outcome loss': 0.21530391421801132, 'Total loss': 0.21530391421801132}
2022-12-31 16:00:54,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:54,311 INFO:     Epoch: 90
2022-12-31 16:00:55,914 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4150030215581258, 'Total loss': 0.4150030215581258} | train loss {'Reaction outcome loss': 0.20895504258196493, 'Total loss': 0.20895504258196493}
2022-12-31 16:00:55,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:55,914 INFO:     Epoch: 91
2022-12-31 16:00:57,537 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4144447922706604, 'Total loss': 0.4144447922706604} | train loss {'Reaction outcome loss': 0.20793237542525095, 'Total loss': 0.20793237542525095}
2022-12-31 16:00:57,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:57,537 INFO:     Epoch: 92
2022-12-31 16:00:59,157 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3909768452246984, 'Total loss': 0.3909768452246984} | train loss {'Reaction outcome loss': 0.21045593287970615, 'Total loss': 0.21045593287970615}
2022-12-31 16:00:59,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:00:59,157 INFO:     Epoch: 93
2022-12-31 16:01:00,760 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3535938173532486, 'Total loss': 0.3535938173532486} | train loss {'Reaction outcome loss': 0.2122053141480426, 'Total loss': 0.2122053141480426}
2022-12-31 16:01:00,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:00,760 INFO:     Epoch: 94
2022-12-31 16:01:02,407 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38124997715155284, 'Total loss': 0.38124997715155284} | train loss {'Reaction outcome loss': 0.20317185844970523, 'Total loss': 0.20317185844970523}
2022-12-31 16:01:02,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:02,407 INFO:     Epoch: 95
2022-12-31 16:01:04,059 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3579056074221929, 'Total loss': 0.3579056074221929} | train loss {'Reaction outcome loss': 0.19949728798538124, 'Total loss': 0.19949728798538124}
2022-12-31 16:01:04,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:04,059 INFO:     Epoch: 96
2022-12-31 16:01:05,673 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3804977883895238, 'Total loss': 0.3804977883895238} | train loss {'Reaction outcome loss': 0.2057433353051113, 'Total loss': 0.2057433353051113}
2022-12-31 16:01:05,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:05,673 INFO:     Epoch: 97
2022-12-31 16:01:07,289 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3908192286888758, 'Total loss': 0.3908192286888758} | train loss {'Reaction outcome loss': 0.20790001232889802, 'Total loss': 0.20790001232889802}
2022-12-31 16:01:07,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:07,290 INFO:     Epoch: 98
2022-12-31 16:01:08,938 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37972853854298594, 'Total loss': 0.37972853854298594} | train loss {'Reaction outcome loss': 0.21112263185183924, 'Total loss': 0.21112263185183924}
2022-12-31 16:01:08,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:08,939 INFO:     Epoch: 99
2022-12-31 16:01:10,538 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37631808618704476, 'Total loss': 0.37631808618704476} | train loss {'Reaction outcome loss': 0.1980274085036146, 'Total loss': 0.1980274085036146}
2022-12-31 16:01:10,538 INFO:     Best model found after epoch 81 of 100.
2022-12-31 16:01:10,538 INFO:   Done with stage: TRAINING
2022-12-31 16:01:10,538 INFO:   Starting stage: EVALUATION
2022-12-31 16:01:10,660 INFO:   Done with stage: EVALUATION
2022-12-31 16:01:10,660 INFO:   Leaving out SEQ value Fold_5
2022-12-31 16:01:10,673 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 16:01:10,673 INFO:   Starting stage: FEATURE SCALING
2022-12-31 16:01:11,323 INFO:   Done with stage: FEATURE SCALING
2022-12-31 16:01:11,323 INFO:   Starting stage: SCALING TARGETS
2022-12-31 16:01:11,391 INFO:   Done with stage: SCALING TARGETS
2022-12-31 16:01:11,391 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 16:01:11,391 INFO:     No hyperparam tuning for this model
2022-12-31 16:01:11,391 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 16:01:11,391 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 16:01:11,392 INFO:     None feature selector for col prot
2022-12-31 16:01:11,392 INFO:     None feature selector for col prot
2022-12-31 16:01:11,392 INFO:     None feature selector for col prot
2022-12-31 16:01:11,393 INFO:     None feature selector for col chem
2022-12-31 16:01:11,393 INFO:     None feature selector for col chem
2022-12-31 16:01:11,393 INFO:     None feature selector for col chem
2022-12-31 16:01:11,393 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 16:01:11,393 INFO:   Starting stage: BUILD MODEL
2022-12-31 16:01:11,395 INFO:     Number of params in model 223921
2022-12-31 16:01:11,398 INFO:   Done with stage: BUILD MODEL
2022-12-31 16:01:11,398 INFO:   Starting stage: TRAINING
2022-12-31 16:01:11,442 INFO:     Val loss before train {'Reaction outcome loss': 1.0517299890518188, 'Total loss': 1.0517299890518188}
2022-12-31 16:01:11,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:11,442 INFO:     Epoch: 0
2022-12-31 16:01:13,057 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7965059200922648, 'Total loss': 0.7965059200922648} | train loss {'Reaction outcome loss': 0.8317232687760444, 'Total loss': 0.8317232687760444}
2022-12-31 16:01:13,057 INFO:     Found new best model at epoch 0
2022-12-31 16:01:13,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:13,058 INFO:     Epoch: 1
2022-12-31 16:01:14,639 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5876236955324808, 'Total loss': 0.5876236955324808} | train loss {'Reaction outcome loss': 0.6130450421223675, 'Total loss': 0.6130450421223675}
2022-12-31 16:01:14,639 INFO:     Found new best model at epoch 1
2022-12-31 16:01:14,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:14,640 INFO:     Epoch: 2
2022-12-31 16:01:16,235 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.601345294713974, 'Total loss': 0.601345294713974} | train loss {'Reaction outcome loss': 0.5352858446375297, 'Total loss': 0.5352858446375297}
2022-12-31 16:01:16,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:16,235 INFO:     Epoch: 3
2022-12-31 16:01:17,818 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5462619284788768, 'Total loss': 0.5462619284788768} | train loss {'Reaction outcome loss': 0.5118155696422514, 'Total loss': 0.5118155696422514}
2022-12-31 16:01:17,819 INFO:     Found new best model at epoch 3
2022-12-31 16:01:17,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:17,819 INFO:     Epoch: 4
2022-12-31 16:01:19,430 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5359733740488688, 'Total loss': 0.5359733740488688} | train loss {'Reaction outcome loss': 0.5019281823052107, 'Total loss': 0.5019281823052107}
2022-12-31 16:01:19,431 INFO:     Found new best model at epoch 4
2022-12-31 16:01:19,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:19,432 INFO:     Epoch: 5
2022-12-31 16:01:21,065 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5631910363833109, 'Total loss': 0.5631910363833109} | train loss {'Reaction outcome loss': 0.48063494368408716, 'Total loss': 0.48063494368408716}
2022-12-31 16:01:21,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:21,065 INFO:     Epoch: 6
2022-12-31 16:01:22,672 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49395853479703267, 'Total loss': 0.49395853479703267} | train loss {'Reaction outcome loss': 0.4674637230643391, 'Total loss': 0.4674637230643391}
2022-12-31 16:01:22,672 INFO:     Found new best model at epoch 6
2022-12-31 16:01:22,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:22,673 INFO:     Epoch: 7
2022-12-31 16:01:24,265 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5673256705204646, 'Total loss': 0.5673256705204646} | train loss {'Reaction outcome loss': 0.46016741783296977, 'Total loss': 0.46016741783296977}
2022-12-31 16:01:24,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:24,265 INFO:     Epoch: 8
2022-12-31 16:01:25,858 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5087872763474782, 'Total loss': 0.5087872763474782} | train loss {'Reaction outcome loss': 0.45300566492071986, 'Total loss': 0.45300566492071986}
2022-12-31 16:01:25,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:25,859 INFO:     Epoch: 9
2022-12-31 16:01:27,431 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4850293835004171, 'Total loss': 0.4850293835004171} | train loss {'Reaction outcome loss': 0.44796041578707035, 'Total loss': 0.44796041578707035}
2022-12-31 16:01:27,432 INFO:     Found new best model at epoch 9
2022-12-31 16:01:27,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:27,433 INFO:     Epoch: 10
2022-12-31 16:01:29,021 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48267318258682884, 'Total loss': 0.48267318258682884} | train loss {'Reaction outcome loss': 0.43847577012803435, 'Total loss': 0.43847577012803435}
2022-12-31 16:01:29,021 INFO:     Found new best model at epoch 10
2022-12-31 16:01:29,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:29,022 INFO:     Epoch: 11
2022-12-31 16:01:30,660 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4914821336666743, 'Total loss': 0.4914821336666743} | train loss {'Reaction outcome loss': 0.43525963233117637, 'Total loss': 0.43525963233117637}
2022-12-31 16:01:30,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:30,660 INFO:     Epoch: 12
2022-12-31 16:01:32,271 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.470337982972463, 'Total loss': 0.470337982972463} | train loss {'Reaction outcome loss': 0.42907849133667286, 'Total loss': 0.42907849133667286}
2022-12-31 16:01:32,271 INFO:     Found new best model at epoch 12
2022-12-31 16:01:32,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:32,272 INFO:     Epoch: 13
2022-12-31 16:01:33,909 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49086467921733856, 'Total loss': 0.49086467921733856} | train loss {'Reaction outcome loss': 0.42140473534155937, 'Total loss': 0.42140473534155937}
2022-12-31 16:01:33,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:33,909 INFO:     Epoch: 14
2022-12-31 16:01:35,525 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46143518884976703, 'Total loss': 0.46143518884976703} | train loss {'Reaction outcome loss': 0.4157571579961881, 'Total loss': 0.4157571579961881}
2022-12-31 16:01:35,525 INFO:     Found new best model at epoch 14
2022-12-31 16:01:35,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:35,526 INFO:     Epoch: 15
2022-12-31 16:01:37,137 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44935158764322597, 'Total loss': 0.44935158764322597} | train loss {'Reaction outcome loss': 0.40675153017696675, 'Total loss': 0.40675153017696675}
2022-12-31 16:01:37,137 INFO:     Found new best model at epoch 15
2022-12-31 16:01:37,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:37,138 INFO:     Epoch: 16
2022-12-31 16:01:38,750 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45850244065125784, 'Total loss': 0.45850244065125784} | train loss {'Reaction outcome loss': 0.4039833319720125, 'Total loss': 0.4039833319720125}
2022-12-31 16:01:38,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:38,750 INFO:     Epoch: 17
2022-12-31 16:01:40,340 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4489932676156362, 'Total loss': 0.4489932676156362} | train loss {'Reaction outcome loss': 0.3972131123453596, 'Total loss': 0.3972131123453596}
2022-12-31 16:01:40,341 INFO:     Found new best model at epoch 17
2022-12-31 16:01:40,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:40,342 INFO:     Epoch: 18
2022-12-31 16:01:41,947 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46312750975290934, 'Total loss': 0.46312750975290934} | train loss {'Reaction outcome loss': 0.38949386748301723, 'Total loss': 0.38949386748301723}
2022-12-31 16:01:41,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:41,947 INFO:     Epoch: 19
2022-12-31 16:01:43,544 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46672810514767965, 'Total loss': 0.46672810514767965} | train loss {'Reaction outcome loss': 0.3839777277605812, 'Total loss': 0.3839777277605812}
2022-12-31 16:01:43,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:43,546 INFO:     Epoch: 20
2022-12-31 16:01:45,139 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4509139915307363, 'Total loss': 0.4509139915307363} | train loss {'Reaction outcome loss': 0.37974354276691913, 'Total loss': 0.37974354276691913}
2022-12-31 16:01:45,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:45,139 INFO:     Epoch: 21
2022-12-31 16:01:46,778 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4713099837303162, 'Total loss': 0.4713099837303162} | train loss {'Reaction outcome loss': 0.3707587513664778, 'Total loss': 0.3707587513664778}
2022-12-31 16:01:46,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:46,778 INFO:     Epoch: 22
2022-12-31 16:01:48,395 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.465225609143575, 'Total loss': 0.465225609143575} | train loss {'Reaction outcome loss': 0.36664081299609513, 'Total loss': 0.36664081299609513}
2022-12-31 16:01:48,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:48,395 INFO:     Epoch: 23
2022-12-31 16:01:50,000 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45161780416965486, 'Total loss': 0.45161780416965486} | train loss {'Reaction outcome loss': 0.3662876993907194, 'Total loss': 0.3662876993907194}
2022-12-31 16:01:50,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:50,001 INFO:     Epoch: 24
2022-12-31 16:01:51,629 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4235704044500987, 'Total loss': 0.4235704044500987} | train loss {'Reaction outcome loss': 0.35944482749395995, 'Total loss': 0.35944482749395995}
2022-12-31 16:01:51,630 INFO:     Found new best model at epoch 24
2022-12-31 16:01:51,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:51,631 INFO:     Epoch: 25
2022-12-31 16:01:53,226 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4538757771253586, 'Total loss': 0.4538757771253586} | train loss {'Reaction outcome loss': 0.3498151484659336, 'Total loss': 0.3498151484659336}
2022-12-31 16:01:53,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:53,226 INFO:     Epoch: 26
2022-12-31 16:01:54,830 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4392892907063166, 'Total loss': 0.4392892907063166} | train loss {'Reaction outcome loss': 0.3432736110730763, 'Total loss': 0.3432736110730763}
2022-12-31 16:01:54,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:54,831 INFO:     Epoch: 27
2022-12-31 16:01:56,451 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45362069507439934, 'Total loss': 0.45362069507439934} | train loss {'Reaction outcome loss': 0.33890363650165334, 'Total loss': 0.33890363650165334}
2022-12-31 16:01:56,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:56,451 INFO:     Epoch: 28
2022-12-31 16:01:58,047 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4586207062005997, 'Total loss': 0.4586207062005997} | train loss {'Reaction outcome loss': 0.3292036366778134, 'Total loss': 0.3292036366778134}
2022-12-31 16:01:58,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:58,047 INFO:     Epoch: 29
2022-12-31 16:01:59,651 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41421009302139283, 'Total loss': 0.41421009302139283} | train loss {'Reaction outcome loss': 0.32474533523548477, 'Total loss': 0.32474533523548477}
2022-12-31 16:01:59,651 INFO:     Found new best model at epoch 29
2022-12-31 16:01:59,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:01:59,652 INFO:     Epoch: 30
2022-12-31 16:02:01,252 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4296227882305781, 'Total loss': 0.4296227882305781} | train loss {'Reaction outcome loss': 0.3282228870874774, 'Total loss': 0.3282228870874774}
2022-12-31 16:02:01,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:01,252 INFO:     Epoch: 31
2022-12-31 16:02:02,874 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39292102058728534, 'Total loss': 0.39292102058728534} | train loss {'Reaction outcome loss': 0.32285531311139576, 'Total loss': 0.32285531311139576}
2022-12-31 16:02:02,875 INFO:     Found new best model at epoch 31
2022-12-31 16:02:02,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:02,876 INFO:     Epoch: 32
2022-12-31 16:02:04,476 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40329845050970714, 'Total loss': 0.40329845050970714} | train loss {'Reaction outcome loss': 0.30380641481410847, 'Total loss': 0.30380641481410847}
2022-12-31 16:02:04,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:04,476 INFO:     Epoch: 33
2022-12-31 16:02:06,094 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41087251901626587, 'Total loss': 0.41087251901626587} | train loss {'Reaction outcome loss': 0.30999167116671583, 'Total loss': 0.30999167116671583}
2022-12-31 16:02:06,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:06,094 INFO:     Epoch: 34
2022-12-31 16:02:07,674 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4048467288414637, 'Total loss': 0.4048467288414637} | train loss {'Reaction outcome loss': 0.30650766029355736, 'Total loss': 0.30650766029355736}
2022-12-31 16:02:07,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:07,674 INFO:     Epoch: 35
2022-12-31 16:02:09,298 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3794830545783043, 'Total loss': 0.3794830545783043} | train loss {'Reaction outcome loss': 0.299537326243237, 'Total loss': 0.299537326243237}
2022-12-31 16:02:09,299 INFO:     Found new best model at epoch 35
2022-12-31 16:02:09,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:09,300 INFO:     Epoch: 36
2022-12-31 16:02:10,914 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41190195779005684, 'Total loss': 0.41190195779005684} | train loss {'Reaction outcome loss': 0.3015426704863997, 'Total loss': 0.3015426704863997}
2022-12-31 16:02:10,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:10,914 INFO:     Epoch: 37
2022-12-31 16:02:12,525 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3945278892914454, 'Total loss': 0.3945278892914454} | train loss {'Reaction outcome loss': 0.29695759815619377, 'Total loss': 0.29695759815619377}
2022-12-31 16:02:12,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:12,525 INFO:     Epoch: 38
2022-12-31 16:02:14,142 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3819348563750585, 'Total loss': 0.3819348563750585} | train loss {'Reaction outcome loss': 0.2962065915012882, 'Total loss': 0.2962065915012882}
2022-12-31 16:02:14,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:14,142 INFO:     Epoch: 39
2022-12-31 16:02:15,753 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4136144091685613, 'Total loss': 0.4136144091685613} | train loss {'Reaction outcome loss': 0.27974990978293174, 'Total loss': 0.27974990978293174}
2022-12-31 16:02:15,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:15,753 INFO:     Epoch: 40
2022-12-31 16:02:17,368 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40474229951699575, 'Total loss': 0.40474229951699575} | train loss {'Reaction outcome loss': 0.28342399902533005, 'Total loss': 0.28342399902533005}
2022-12-31 16:02:17,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:17,368 INFO:     Epoch: 41
2022-12-31 16:02:19,019 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37887929181257884, 'Total loss': 0.37887929181257884} | train loss {'Reaction outcome loss': 0.27283899414006374, 'Total loss': 0.27283899414006374}
2022-12-31 16:02:19,020 INFO:     Found new best model at epoch 41
2022-12-31 16:02:19,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:19,021 INFO:     Epoch: 42
2022-12-31 16:02:20,660 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4115278522173564, 'Total loss': 0.4115278522173564} | train loss {'Reaction outcome loss': 0.276941213947143, 'Total loss': 0.276941213947143}
2022-12-31 16:02:20,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:20,660 INFO:     Epoch: 43
2022-12-31 16:02:22,281 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41349947849909463, 'Total loss': 0.41349947849909463} | train loss {'Reaction outcome loss': 0.2670678082262132, 'Total loss': 0.2670678082262132}
2022-12-31 16:02:22,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:22,281 INFO:     Epoch: 44
2022-12-31 16:02:23,919 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4117218921581904, 'Total loss': 0.4117218921581904} | train loss {'Reaction outcome loss': 0.27275462691284663, 'Total loss': 0.27275462691284663}
2022-12-31 16:02:23,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:23,919 INFO:     Epoch: 45
2022-12-31 16:02:25,554 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4217368503411611, 'Total loss': 0.4217368503411611} | train loss {'Reaction outcome loss': 0.27252476291907746, 'Total loss': 0.27252476291907746}
2022-12-31 16:02:25,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:25,555 INFO:     Epoch: 46
2022-12-31 16:02:27,152 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4261462638775508, 'Total loss': 0.4261462638775508} | train loss {'Reaction outcome loss': 0.26061413964650926, 'Total loss': 0.26061413964650926}
2022-12-31 16:02:27,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:27,152 INFO:     Epoch: 47
2022-12-31 16:02:28,790 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3940132945775986, 'Total loss': 0.3940132945775986} | train loss {'Reaction outcome loss': 0.2645572867026947, 'Total loss': 0.2645572867026947}
2022-12-31 16:02:28,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:28,790 INFO:     Epoch: 48
2022-12-31 16:02:30,429 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41729925374190013, 'Total loss': 0.41729925374190013} | train loss {'Reaction outcome loss': 0.2673086380130564, 'Total loss': 0.2673086380130564}
2022-12-31 16:02:30,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:30,429 INFO:     Epoch: 49
2022-12-31 16:02:32,024 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4282434031367302, 'Total loss': 0.4282434031367302} | train loss {'Reaction outcome loss': 0.25279714212664506, 'Total loss': 0.25279714212664506}
2022-12-31 16:02:32,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:32,024 INFO:     Epoch: 50
2022-12-31 16:02:33,648 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41304931541283924, 'Total loss': 0.41304931541283924} | train loss {'Reaction outcome loss': 0.2528829757314529, 'Total loss': 0.2528829757314529}
2022-12-31 16:02:33,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:33,648 INFO:     Epoch: 51
2022-12-31 16:02:35,251 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39383513331413267, 'Total loss': 0.39383513331413267} | train loss {'Reaction outcome loss': 0.25637205911759475, 'Total loss': 0.25637205911759475}
2022-12-31 16:02:35,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:35,251 INFO:     Epoch: 52
2022-12-31 16:02:36,852 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3386512272059917, 'Total loss': 0.3386512272059917} | train loss {'Reaction outcome loss': 0.25024874392815316, 'Total loss': 0.25024874392815316}
2022-12-31 16:02:36,852 INFO:     Found new best model at epoch 52
2022-12-31 16:02:36,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:36,853 INFO:     Epoch: 53
2022-12-31 16:02:38,453 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4070519457260768, 'Total loss': 0.4070519457260768} | train loss {'Reaction outcome loss': 0.24376056770229862, 'Total loss': 0.24376056770229862}
2022-12-31 16:02:38,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:38,454 INFO:     Epoch: 54
2022-12-31 16:02:40,073 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3813299983739853, 'Total loss': 0.3813299983739853} | train loss {'Reaction outcome loss': 0.2455277457615755, 'Total loss': 0.2455277457615755}
2022-12-31 16:02:40,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:40,073 INFO:     Epoch: 55
2022-12-31 16:02:41,712 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.397170889377594, 'Total loss': 0.397170889377594} | train loss {'Reaction outcome loss': 0.24185347056057113, 'Total loss': 0.24185347056057113}
2022-12-31 16:02:41,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:41,712 INFO:     Epoch: 56
2022-12-31 16:02:43,339 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4068616966406504, 'Total loss': 0.4068616966406504} | train loss {'Reaction outcome loss': 0.24550671383303446, 'Total loss': 0.24550671383303446}
2022-12-31 16:02:43,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:43,339 INFO:     Epoch: 57
2022-12-31 16:02:44,936 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40673275887966154, 'Total loss': 0.40673275887966154} | train loss {'Reaction outcome loss': 0.2324721538427755, 'Total loss': 0.2324721538427755}
2022-12-31 16:02:44,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:44,936 INFO:     Epoch: 58
2022-12-31 16:02:46,561 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3917174934099118, 'Total loss': 0.3917174934099118} | train loss {'Reaction outcome loss': 0.23862270881714176, 'Total loss': 0.23862270881714176}
2022-12-31 16:02:46,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:46,561 INFO:     Epoch: 59
2022-12-31 16:02:48,163 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4171890457471212, 'Total loss': 0.4171890457471212} | train loss {'Reaction outcome loss': 0.238224234166861, 'Total loss': 0.238224234166861}
2022-12-31 16:02:48,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:48,164 INFO:     Epoch: 60
2022-12-31 16:02:49,763 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41494635691245396, 'Total loss': 0.41494635691245396} | train loss {'Reaction outcome loss': 0.23456106241112643, 'Total loss': 0.23456106241112643}
2022-12-31 16:02:49,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:49,763 INFO:     Epoch: 61
2022-12-31 16:02:51,370 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43557535111904144, 'Total loss': 0.43557535111904144} | train loss {'Reaction outcome loss': 0.23761685508011032, 'Total loss': 0.23761685508011032}
2022-12-31 16:02:51,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:51,371 INFO:     Epoch: 62
2022-12-31 16:02:53,007 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4348465318481127, 'Total loss': 0.4348465318481127} | train loss {'Reaction outcome loss': 0.2354333679511273, 'Total loss': 0.2354333679511273}
2022-12-31 16:02:53,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:53,008 INFO:     Epoch: 63
2022-12-31 16:02:54,598 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3893632749716441, 'Total loss': 0.3893632749716441} | train loss {'Reaction outcome loss': 0.22795306873528193, 'Total loss': 0.22795306873528193}
2022-12-31 16:02:54,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:54,599 INFO:     Epoch: 64
2022-12-31 16:02:56,200 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3984492709239324, 'Total loss': 0.3984492709239324} | train loss {'Reaction outcome loss': 0.22881149910526336, 'Total loss': 0.22881149910526336}
2022-12-31 16:02:56,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:56,201 INFO:     Epoch: 65
2022-12-31 16:02:57,792 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38117188873390356, 'Total loss': 0.38117188873390356} | train loss {'Reaction outcome loss': 0.22644049111400208, 'Total loss': 0.22644049111400208}
2022-12-31 16:02:57,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:57,792 INFO:     Epoch: 66
2022-12-31 16:02:59,381 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3834151109059652, 'Total loss': 0.3834151109059652} | train loss {'Reaction outcome loss': 0.22276831716027137, 'Total loss': 0.22276831716027137}
2022-12-31 16:02:59,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:02:59,381 INFO:     Epoch: 67
2022-12-31 16:03:00,990 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3971956600745519, 'Total loss': 0.3971956600745519} | train loss {'Reaction outcome loss': 0.22199573397745181, 'Total loss': 0.22199573397745181}
2022-12-31 16:03:00,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:00,991 INFO:     Epoch: 68
2022-12-31 16:03:02,583 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.367072165509065, 'Total loss': 0.367072165509065} | train loss {'Reaction outcome loss': 0.22440416643219271, 'Total loss': 0.22440416643219271}
2022-12-31 16:03:02,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:02,583 INFO:     Epoch: 69
2022-12-31 16:03:04,182 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3581751157840093, 'Total loss': 0.3581751157840093} | train loss {'Reaction outcome loss': 0.22184888687474233, 'Total loss': 0.22184888687474233}
2022-12-31 16:03:04,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:04,182 INFO:     Epoch: 70
2022-12-31 16:03:05,782 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.391612442334493, 'Total loss': 0.391612442334493} | train loss {'Reaction outcome loss': 0.21552523436283108, 'Total loss': 0.21552523436283108}
2022-12-31 16:03:05,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:05,782 INFO:     Epoch: 71
2022-12-31 16:03:07,376 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3754304011662801, 'Total loss': 0.3754304011662801} | train loss {'Reaction outcome loss': 0.21499154468604031, 'Total loss': 0.21499154468604031}
2022-12-31 16:03:07,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:07,376 INFO:     Epoch: 72
2022-12-31 16:03:08,978 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3842014819383621, 'Total loss': 0.3842014819383621} | train loss {'Reaction outcome loss': 0.21373436795071746, 'Total loss': 0.21373436795071746}
2022-12-31 16:03:08,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:08,978 INFO:     Epoch: 73
2022-12-31 16:03:10,582 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4105635682741801, 'Total loss': 0.4105635682741801} | train loss {'Reaction outcome loss': 0.21357909476479692, 'Total loss': 0.21357909476479692}
2022-12-31 16:03:10,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:10,582 INFO:     Epoch: 74
2022-12-31 16:03:12,169 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3691477159659068, 'Total loss': 0.3691477159659068} | train loss {'Reaction outcome loss': 0.2186276538018817, 'Total loss': 0.2186276538018817}
2022-12-31 16:03:12,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:12,169 INFO:     Epoch: 75
2022-12-31 16:03:13,772 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3845014452934265, 'Total loss': 0.3845014452934265} | train loss {'Reaction outcome loss': 0.21404884591100426, 'Total loss': 0.21404884591100426}
2022-12-31 16:03:13,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:13,773 INFO:     Epoch: 76
2022-12-31 16:03:15,380 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38978960116704303, 'Total loss': 0.38978960116704303} | train loss {'Reaction outcome loss': 0.2065099049121631, 'Total loss': 0.2065099049121631}
2022-12-31 16:03:15,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:15,381 INFO:     Epoch: 77
2022-12-31 16:03:16,970 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40335097710291545, 'Total loss': 0.40335097710291545} | train loss {'Reaction outcome loss': 0.21029134544741063, 'Total loss': 0.21029134544741063}
2022-12-31 16:03:16,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:16,971 INFO:     Epoch: 78
2022-12-31 16:03:18,574 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45861873825391136, 'Total loss': 0.45861873825391136} | train loss {'Reaction outcome loss': 0.2094081669372853, 'Total loss': 0.2094081669372853}
2022-12-31 16:03:18,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:18,574 INFO:     Epoch: 79
2022-12-31 16:03:20,181 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38268375396728516, 'Total loss': 0.38268375396728516} | train loss {'Reaction outcome loss': 0.20709781591392998, 'Total loss': 0.20709781591392998}
2022-12-31 16:03:20,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:20,182 INFO:     Epoch: 80
2022-12-31 16:03:21,767 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3689904282490412, 'Total loss': 0.3689904282490412} | train loss {'Reaction outcome loss': 0.20935633801685197, 'Total loss': 0.20935633801685197}
2022-12-31 16:03:21,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:21,767 INFO:     Epoch: 81
2022-12-31 16:03:23,372 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40451122721036276, 'Total loss': 0.40451122721036276} | train loss {'Reaction outcome loss': 0.20561244170161058, 'Total loss': 0.20561244170161058}
2022-12-31 16:03:23,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:23,372 INFO:     Epoch: 82
2022-12-31 16:03:24,960 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3923534353574117, 'Total loss': 0.3923534353574117} | train loss {'Reaction outcome loss': 0.2051989541178311, 'Total loss': 0.2051989541178311}
2022-12-31 16:03:24,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:24,961 INFO:     Epoch: 83
2022-12-31 16:03:26,564 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3929111828406652, 'Total loss': 0.3929111828406652} | train loss {'Reaction outcome loss': 0.20208906487011127, 'Total loss': 0.20208906487011127}
2022-12-31 16:03:26,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:26,564 INFO:     Epoch: 84
2022-12-31 16:03:28,167 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37549272874991096, 'Total loss': 0.37549272874991096} | train loss {'Reaction outcome loss': 0.20501281650070727, 'Total loss': 0.20501281650070727}
2022-12-31 16:03:28,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:28,167 INFO:     Epoch: 85
2022-12-31 16:03:29,762 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39210014740626015, 'Total loss': 0.39210014740626015} | train loss {'Reaction outcome loss': 0.20655418576563905, 'Total loss': 0.20655418576563905}
2022-12-31 16:03:29,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:29,762 INFO:     Epoch: 86
2022-12-31 16:03:31,364 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3472407291332881, 'Total loss': 0.3472407291332881} | train loss {'Reaction outcome loss': 0.19891573730040424, 'Total loss': 0.19891573730040424}
2022-12-31 16:03:31,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:31,365 INFO:     Epoch: 87
2022-12-31 16:03:32,966 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4336772491534551, 'Total loss': 0.4336772491534551} | train loss {'Reaction outcome loss': 0.1942298668946554, 'Total loss': 0.1942298668946554}
2022-12-31 16:03:32,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:32,967 INFO:     Epoch: 88
2022-12-31 16:03:34,551 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.36033793340126674, 'Total loss': 0.36033793340126674} | train loss {'Reaction outcome loss': 0.1904268763367984, 'Total loss': 0.1904268763367984}
2022-12-31 16:03:34,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:34,551 INFO:     Epoch: 89
2022-12-31 16:03:36,152 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3959277262290319, 'Total loss': 0.3959277262290319} | train loss {'Reaction outcome loss': 0.20658790570323485, 'Total loss': 0.20658790570323485}
2022-12-31 16:03:36,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:36,153 INFO:     Epoch: 90
2022-12-31 16:03:37,753 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42389842768510183, 'Total loss': 0.42389842768510183} | train loss {'Reaction outcome loss': 0.1992510281686746, 'Total loss': 0.1992510281686746}
2022-12-31 16:03:37,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:37,754 INFO:     Epoch: 91
2022-12-31 16:03:39,353 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.35795672833919523, 'Total loss': 0.35795672833919523} | train loss {'Reaction outcome loss': 0.19792526985185532, 'Total loss': 0.19792526985185532}
2022-12-31 16:03:39,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:39,353 INFO:     Epoch: 92
2022-12-31 16:03:40,962 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3649787425994873, 'Total loss': 0.3649787425994873} | train loss {'Reaction outcome loss': 0.20078544854356425, 'Total loss': 0.20078544854356425}
2022-12-31 16:03:40,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:40,962 INFO:     Epoch: 93
2022-12-31 16:03:42,560 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4308734744787216, 'Total loss': 0.4308734744787216} | train loss {'Reaction outcome loss': 0.19401069532699175, 'Total loss': 0.19401069532699175}
2022-12-31 16:03:42,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:42,560 INFO:     Epoch: 94
2022-12-31 16:03:44,171 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.381572907914718, 'Total loss': 0.381572907914718} | train loss {'Reaction outcome loss': 0.1935161457900094, 'Total loss': 0.1935161457900094}
2022-12-31 16:03:44,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:44,172 INFO:     Epoch: 95
2022-12-31 16:03:45,807 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3955225040515264, 'Total loss': 0.3955225040515264} | train loss {'Reaction outcome loss': 0.19510123896392156, 'Total loss': 0.19510123896392156}
2022-12-31 16:03:45,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:45,807 INFO:     Epoch: 96
2022-12-31 16:03:47,428 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3427148811519146, 'Total loss': 0.3427148811519146} | train loss {'Reaction outcome loss': 0.19851540063038794, 'Total loss': 0.19851540063038794}
2022-12-31 16:03:47,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:47,428 INFO:     Epoch: 97
2022-12-31 16:03:49,042 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3562289838989576, 'Total loss': 0.3562289838989576} | train loss {'Reaction outcome loss': 0.1860765254696029, 'Total loss': 0.1860765254696029}
2022-12-31 16:03:49,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:49,043 INFO:     Epoch: 98
2022-12-31 16:03:50,653 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3923049499591192, 'Total loss': 0.3923049499591192} | train loss {'Reaction outcome loss': 0.18896768113299117, 'Total loss': 0.18896768113299117}
2022-12-31 16:03:50,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:50,653 INFO:     Epoch: 99
2022-12-31 16:03:52,233 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38409555355707803, 'Total loss': 0.38409555355707803} | train loss {'Reaction outcome loss': 0.19564117329453465, 'Total loss': 0.19564117329453465}
2022-12-31 16:03:52,233 INFO:     Best model found after epoch 53 of 100.
2022-12-31 16:03:52,233 INFO:   Done with stage: TRAINING
2022-12-31 16:03:52,233 INFO:   Starting stage: EVALUATION
2022-12-31 16:03:52,367 INFO:   Done with stage: EVALUATION
2022-12-31 16:03:52,367 INFO:   Leaving out SEQ value Fold_6
2022-12-31 16:03:52,380 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 16:03:52,380 INFO:   Starting stage: FEATURE SCALING
2022-12-31 16:03:53,026 INFO:   Done with stage: FEATURE SCALING
2022-12-31 16:03:53,027 INFO:   Starting stage: SCALING TARGETS
2022-12-31 16:03:53,096 INFO:   Done with stage: SCALING TARGETS
2022-12-31 16:03:53,096 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 16:03:53,096 INFO:     No hyperparam tuning for this model
2022-12-31 16:03:53,096 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 16:03:53,096 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 16:03:53,097 INFO:     None feature selector for col prot
2022-12-31 16:03:53,097 INFO:     None feature selector for col prot
2022-12-31 16:03:53,097 INFO:     None feature selector for col prot
2022-12-31 16:03:53,097 INFO:     None feature selector for col chem
2022-12-31 16:03:53,097 INFO:     None feature selector for col chem
2022-12-31 16:03:53,097 INFO:     None feature selector for col chem
2022-12-31 16:03:53,098 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 16:03:53,098 INFO:   Starting stage: BUILD MODEL
2022-12-31 16:03:53,099 INFO:     Number of params in model 223921
2022-12-31 16:03:53,102 INFO:   Done with stage: BUILD MODEL
2022-12-31 16:03:53,103 INFO:   Starting stage: TRAINING
2022-12-31 16:03:53,146 INFO:     Val loss before train {'Reaction outcome loss': 0.9959683616956075, 'Total loss': 0.9959683616956075}
2022-12-31 16:03:53,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:53,146 INFO:     Epoch: 0
2022-12-31 16:03:54,803 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6355711817741394, 'Total loss': 0.6355711817741394} | train loss {'Reaction outcome loss': 0.8127445362320015, 'Total loss': 0.8127445362320015}
2022-12-31 16:03:54,803 INFO:     Found new best model at epoch 0
2022-12-31 16:03:54,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:54,804 INFO:     Epoch: 1
2022-12-31 16:03:56,437 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.504647171497345, 'Total loss': 0.504647171497345} | train loss {'Reaction outcome loss': 0.5946860139658304, 'Total loss': 0.5946860139658304}
2022-12-31 16:03:56,438 INFO:     Found new best model at epoch 1
2022-12-31 16:03:56,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:56,439 INFO:     Epoch: 2
2022-12-31 16:03:58,082 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47563582062721255, 'Total loss': 0.47563582062721255} | train loss {'Reaction outcome loss': 0.5271613862002369, 'Total loss': 0.5271613862002369}
2022-12-31 16:03:58,083 INFO:     Found new best model at epoch 2
2022-12-31 16:03:58,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:58,084 INFO:     Epoch: 3
2022-12-31 16:03:59,705 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47947272658348083, 'Total loss': 0.47947272658348083} | train loss {'Reaction outcome loss': 0.4998769357746689, 'Total loss': 0.4998769357746689}
2022-12-31 16:03:59,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:03:59,705 INFO:     Epoch: 4
2022-12-31 16:04:01,318 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44109011789162955, 'Total loss': 0.44109011789162955} | train loss {'Reaction outcome loss': 0.48961054859178593, 'Total loss': 0.48961054859178593}
2022-12-31 16:04:01,319 INFO:     Found new best model at epoch 4
2022-12-31 16:04:01,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:01,320 INFO:     Epoch: 5
2022-12-31 16:04:02,937 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.448217644294103, 'Total loss': 0.448217644294103} | train loss {'Reaction outcome loss': 0.47607270445311545, 'Total loss': 0.47607270445311545}
2022-12-31 16:04:02,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:02,938 INFO:     Epoch: 6
2022-12-31 16:04:04,563 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43115187088648477, 'Total loss': 0.43115187088648477} | train loss {'Reaction outcome loss': 0.4660970740262352, 'Total loss': 0.4660970740262352}
2022-12-31 16:04:04,563 INFO:     Found new best model at epoch 6
2022-12-31 16:04:04,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:04,564 INFO:     Epoch: 7
2022-12-31 16:04:06,180 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43642352024714154, 'Total loss': 0.43642352024714154} | train loss {'Reaction outcome loss': 0.4603484923873998, 'Total loss': 0.4603484923873998}
2022-12-31 16:04:06,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:06,180 INFO:     Epoch: 8
2022-12-31 16:04:07,838 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41967695554097495, 'Total loss': 0.41967695554097495} | train loss {'Reaction outcome loss': 0.45008498266177915, 'Total loss': 0.45008498266177915}
2022-12-31 16:04:07,838 INFO:     Found new best model at epoch 8
2022-12-31 16:04:07,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:07,839 INFO:     Epoch: 9
2022-12-31 16:04:09,501 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4079584499200185, 'Total loss': 0.4079584499200185} | train loss {'Reaction outcome loss': 0.4433054920514568, 'Total loss': 0.4433054920514568}
2022-12-31 16:04:09,501 INFO:     Found new best model at epoch 9
2022-12-31 16:04:09,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:09,502 INFO:     Epoch: 10
2022-12-31 16:04:11,105 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44378960927327477, 'Total loss': 0.44378960927327477} | train loss {'Reaction outcome loss': 0.444708634826896, 'Total loss': 0.444708634826896}
2022-12-31 16:04:11,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:11,106 INFO:     Epoch: 11
2022-12-31 16:04:12,735 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43815027674039203, 'Total loss': 0.43815027674039203} | train loss {'Reaction outcome loss': 0.43228569785502846, 'Total loss': 0.43228569785502846}
2022-12-31 16:04:12,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:12,736 INFO:     Epoch: 12
2022-12-31 16:04:14,360 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41978894074757894, 'Total loss': 0.41978894074757894} | train loss {'Reaction outcome loss': 0.42671540602772673, 'Total loss': 0.42671540602772673}
2022-12-31 16:04:14,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:14,360 INFO:     Epoch: 13
2022-12-31 16:04:15,991 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.38429287672042844, 'Total loss': 0.38429287672042844} | train loss {'Reaction outcome loss': 0.4209675766823524, 'Total loss': 0.4209675766823524}
2022-12-31 16:04:15,991 INFO:     Found new best model at epoch 13
2022-12-31 16:04:15,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:15,992 INFO:     Epoch: 14
2022-12-31 16:04:17,648 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3882193331917127, 'Total loss': 0.3882193331917127} | train loss {'Reaction outcome loss': 0.4149520403641656, 'Total loss': 0.4149520403641656}
2022-12-31 16:04:17,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:17,648 INFO:     Epoch: 15
2022-12-31 16:04:19,287 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39414986272652947, 'Total loss': 0.39414986272652947} | train loss {'Reaction outcome loss': 0.41686508597449706, 'Total loss': 0.41686508597449706}
2022-12-31 16:04:19,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:19,287 INFO:     Epoch: 16
2022-12-31 16:04:20,924 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.374677570660909, 'Total loss': 0.374677570660909} | train loss {'Reaction outcome loss': 0.40233870991085413, 'Total loss': 0.40233870991085413}
2022-12-31 16:04:20,924 INFO:     Found new best model at epoch 16
2022-12-31 16:04:20,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:20,925 INFO:     Epoch: 17
2022-12-31 16:04:22,578 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4020712991555532, 'Total loss': 0.4020712991555532} | train loss {'Reaction outcome loss': 0.4020107185152033, 'Total loss': 0.4020107185152033}
2022-12-31 16:04:22,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:22,578 INFO:     Epoch: 18
2022-12-31 16:04:24,192 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.35138046940167744, 'Total loss': 0.35138046940167744} | train loss {'Reaction outcome loss': 0.39376274146650675, 'Total loss': 0.39376274146650675}
2022-12-31 16:04:24,192 INFO:     Found new best model at epoch 18
2022-12-31 16:04:24,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:24,193 INFO:     Epoch: 19
2022-12-31 16:04:25,816 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38023848136266075, 'Total loss': 0.38023848136266075} | train loss {'Reaction outcome loss': 0.3831692204578689, 'Total loss': 0.3831692204578689}
2022-12-31 16:04:25,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:25,817 INFO:     Epoch: 20
2022-12-31 16:04:27,459 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3803051233291626, 'Total loss': 0.3803051233291626} | train loss {'Reaction outcome loss': 0.3797287013018605, 'Total loss': 0.3797287013018605}
2022-12-31 16:04:27,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:27,461 INFO:     Epoch: 21
2022-12-31 16:04:29,080 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3540354023377101, 'Total loss': 0.3540354023377101} | train loss {'Reaction outcome loss': 0.37279052402998997, 'Total loss': 0.37279052402998997}
2022-12-31 16:04:29,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:29,080 INFO:     Epoch: 22
2022-12-31 16:04:30,720 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3840772350629171, 'Total loss': 0.3840772350629171} | train loss {'Reaction outcome loss': 0.3676315539311416, 'Total loss': 0.3676315539311416}
2022-12-31 16:04:30,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:30,721 INFO:     Epoch: 23
2022-12-31 16:04:32,384 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3826530913511912, 'Total loss': 0.3826530913511912} | train loss {'Reaction outcome loss': 0.3699583898059728, 'Total loss': 0.3699583898059728}
2022-12-31 16:04:32,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:32,385 INFO:     Epoch: 24
2022-12-31 16:04:33,996 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3935444603363673, 'Total loss': 0.3935444603363673} | train loss {'Reaction outcome loss': 0.36242936868960246, 'Total loss': 0.36242936868960246}
2022-12-31 16:04:33,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:33,997 INFO:     Epoch: 25
2022-12-31 16:04:35,622 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3462140296896299, 'Total loss': 0.3462140296896299} | train loss {'Reaction outcome loss': 0.35290653430705465, 'Total loss': 0.35290653430705465}
2022-12-31 16:04:35,622 INFO:     Found new best model at epoch 25
2022-12-31 16:04:35,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:35,623 INFO:     Epoch: 26
2022-12-31 16:04:37,236 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.35707841714223226, 'Total loss': 0.35707841714223226} | train loss {'Reaction outcome loss': 0.35315924073276966, 'Total loss': 0.35315924073276966}
2022-12-31 16:04:37,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:37,236 INFO:     Epoch: 27
2022-12-31 16:04:38,852 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3577234476804733, 'Total loss': 0.3577234476804733} | train loss {'Reaction outcome loss': 0.34609885836551335, 'Total loss': 0.34609885836551335}
2022-12-31 16:04:38,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:38,852 INFO:     Epoch: 28
2022-12-31 16:04:40,474 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3525172233581543, 'Total loss': 0.3525172233581543} | train loss {'Reaction outcome loss': 0.3382886194687888, 'Total loss': 0.3382886194687888}
2022-12-31 16:04:40,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:40,474 INFO:     Epoch: 29
2022-12-31 16:04:42,099 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3578905383745829, 'Total loss': 0.3578905383745829} | train loss {'Reaction outcome loss': 0.33291654927582087, 'Total loss': 0.33291654927582087}
2022-12-31 16:04:42,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:42,099 INFO:     Epoch: 30
2022-12-31 16:04:43,731 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3682982583840688, 'Total loss': 0.3682982583840688} | train loss {'Reaction outcome loss': 0.3338194768943081, 'Total loss': 0.3338194768943081}
2022-12-31 16:04:43,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:43,731 INFO:     Epoch: 31
2022-12-31 16:04:45,354 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39081906378269193, 'Total loss': 0.39081906378269193} | train loss {'Reaction outcome loss': 0.3291692737799259, 'Total loss': 0.3291692737799259}
2022-12-31 16:04:45,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:45,354 INFO:     Epoch: 32
2022-12-31 16:04:46,960 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3613301048676173, 'Total loss': 0.3613301048676173} | train loss {'Reaction outcome loss': 0.3219441235442024, 'Total loss': 0.3219441235442024}
2022-12-31 16:04:46,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:46,961 INFO:     Epoch: 33
2022-12-31 16:04:48,581 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3468063086271286, 'Total loss': 0.3468063086271286} | train loss {'Reaction outcome loss': 0.3152659981904908, 'Total loss': 0.3152659981904908}
2022-12-31 16:04:48,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:48,582 INFO:     Epoch: 34
2022-12-31 16:04:50,208 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.380646018187205, 'Total loss': 0.380646018187205} | train loss {'Reaction outcome loss': 0.3144240976186866, 'Total loss': 0.3144240976186866}
2022-12-31 16:04:50,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:50,208 INFO:     Epoch: 35
2022-12-31 16:04:51,817 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3633721609910329, 'Total loss': 0.3633721609910329} | train loss {'Reaction outcome loss': 0.31655050042196303, 'Total loss': 0.31655050042196303}
2022-12-31 16:04:51,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:51,817 INFO:     Epoch: 36
2022-12-31 16:04:53,445 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3458607296148936, 'Total loss': 0.3458607296148936} | train loss {'Reaction outcome loss': 0.31437088538378155, 'Total loss': 0.31437088538378155}
2022-12-31 16:04:53,446 INFO:     Found new best model at epoch 36
2022-12-31 16:04:53,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:53,447 INFO:     Epoch: 37
2022-12-31 16:04:55,070 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3477381894985835, 'Total loss': 0.3477381894985835} | train loss {'Reaction outcome loss': 0.30311987070292773, 'Total loss': 0.30311987070292773}
2022-12-31 16:04:55,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:55,071 INFO:     Epoch: 38
2022-12-31 16:04:56,680 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.35146008133888246, 'Total loss': 0.35146008133888246} | train loss {'Reaction outcome loss': 0.3004772856239808, 'Total loss': 0.3004772856239808}
2022-12-31 16:04:56,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:56,681 INFO:     Epoch: 39
2022-12-31 16:04:58,306 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.35601966828107834, 'Total loss': 0.35601966828107834} | train loss {'Reaction outcome loss': 0.2976647403884666, 'Total loss': 0.2976647403884666}
2022-12-31 16:04:58,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:58,307 INFO:     Epoch: 40
2022-12-31 16:04:59,927 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3940051992734273, 'Total loss': 0.3940051992734273} | train loss {'Reaction outcome loss': 0.29481988160833983, 'Total loss': 0.29481988160833983}
2022-12-31 16:04:59,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:04:59,927 INFO:     Epoch: 41
2022-12-31 16:05:01,541 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3520703136920929, 'Total loss': 0.3520703136920929} | train loss {'Reaction outcome loss': 0.2900535641675176, 'Total loss': 0.2900535641675176}
2022-12-31 16:05:01,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:01,541 INFO:     Epoch: 42
2022-12-31 16:05:03,164 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3580141723155975, 'Total loss': 0.3580141723155975} | train loss {'Reaction outcome loss': 0.2934325488035429, 'Total loss': 0.2934325488035429}
2022-12-31 16:05:03,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:03,165 INFO:     Epoch: 43
2022-12-31 16:05:04,795 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.35145902236302695, 'Total loss': 0.35145902236302695} | train loss {'Reaction outcome loss': 0.29054385041717157, 'Total loss': 0.29054385041717157}
2022-12-31 16:05:04,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:04,795 INFO:     Epoch: 44
2022-12-31 16:05:06,420 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3639323194821676, 'Total loss': 0.3639323194821676} | train loss {'Reaction outcome loss': 0.28611754133813216, 'Total loss': 0.28611754133813216}
2022-12-31 16:05:06,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:06,421 INFO:     Epoch: 45
2022-12-31 16:05:08,043 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.33544578750928244, 'Total loss': 0.33544578750928244} | train loss {'Reaction outcome loss': 0.28460725000134873, 'Total loss': 0.28460725000134873}
2022-12-31 16:05:08,043 INFO:     Found new best model at epoch 45
2022-12-31 16:05:08,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:08,044 INFO:     Epoch: 46
2022-12-31 16:05:09,651 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.344871985912323, 'Total loss': 0.344871985912323} | train loss {'Reaction outcome loss': 0.2832671256218146, 'Total loss': 0.2832671256218146}
2022-12-31 16:05:09,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:09,652 INFO:     Epoch: 47
2022-12-31 16:05:11,315 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3347235490878423, 'Total loss': 0.3347235490878423} | train loss {'Reaction outcome loss': 0.2781757302178803, 'Total loss': 0.2781757302178803}
2022-12-31 16:05:11,315 INFO:     Found new best model at epoch 47
2022-12-31 16:05:11,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:11,316 INFO:     Epoch: 48
2022-12-31 16:05:12,964 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4119254310925802, 'Total loss': 0.4119254310925802} | train loss {'Reaction outcome loss': 0.2657678992443782, 'Total loss': 0.2657678992443782}
2022-12-31 16:05:12,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:12,964 INFO:     Epoch: 49
2022-12-31 16:05:14,576 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.32815515995025635, 'Total loss': 0.32815515995025635} | train loss {'Reaction outcome loss': 0.27683321144499073, 'Total loss': 0.27683321144499073}
2022-12-31 16:05:14,576 INFO:     Found new best model at epoch 49
2022-12-31 16:05:14,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:14,577 INFO:     Epoch: 50
2022-12-31 16:05:16,199 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.32004900376001993, 'Total loss': 0.32004900376001993} | train loss {'Reaction outcome loss': 0.2681361812062642, 'Total loss': 0.2681361812062642}
2022-12-31 16:05:16,200 INFO:     Found new best model at epoch 50
2022-12-31 16:05:16,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:16,201 INFO:     Epoch: 51
2022-12-31 16:05:17,816 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3527940680583318, 'Total loss': 0.3527940680583318} | train loss {'Reaction outcome loss': 0.26289661593116576, 'Total loss': 0.26289661593116576}
2022-12-31 16:05:17,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:17,816 INFO:     Epoch: 52
2022-12-31 16:05:19,442 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3355683654546738, 'Total loss': 0.3355683654546738} | train loss {'Reaction outcome loss': 0.2734583333497766, 'Total loss': 0.2734583333497766}
2022-12-31 16:05:19,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:19,443 INFO:     Epoch: 53
2022-12-31 16:05:21,099 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3398809949556986, 'Total loss': 0.3398809949556986} | train loss {'Reaction outcome loss': 0.27025191826133954, 'Total loss': 0.27025191826133954}
2022-12-31 16:05:21,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:21,099 INFO:     Epoch: 54
2022-12-31 16:05:22,736 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38633332699537276, 'Total loss': 0.38633332699537276} | train loss {'Reaction outcome loss': 0.2606419608507991, 'Total loss': 0.2606419608507991}
2022-12-31 16:05:22,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:22,737 INFO:     Epoch: 55
2022-12-31 16:05:24,354 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3543367038170497, 'Total loss': 0.3543367038170497} | train loss {'Reaction outcome loss': 0.26494378981177125, 'Total loss': 0.26494378981177125}
2022-12-31 16:05:24,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:24,354 INFO:     Epoch: 56
2022-12-31 16:05:25,971 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3505411922931671, 'Total loss': 0.3505411922931671} | train loss {'Reaction outcome loss': 0.2587192892517209, 'Total loss': 0.2587192892517209}
2022-12-31 16:05:25,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:25,971 INFO:     Epoch: 57
2022-12-31 16:05:27,577 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.33703582088152567, 'Total loss': 0.33703582088152567} | train loss {'Reaction outcome loss': 0.25450108091377177, 'Total loss': 0.25450108091377177}
2022-12-31 16:05:27,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:27,577 INFO:     Epoch: 58
2022-12-31 16:05:29,194 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3289714852968852, 'Total loss': 0.3289714852968852} | train loss {'Reaction outcome loss': 0.2602052899205297, 'Total loss': 0.2602052899205297}
2022-12-31 16:05:29,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:29,195 INFO:     Epoch: 59
2022-12-31 16:05:30,811 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38396520018577573, 'Total loss': 0.38396520018577573} | train loss {'Reaction outcome loss': 0.24636118478454408, 'Total loss': 0.24636118478454408}
2022-12-31 16:05:30,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:30,811 INFO:     Epoch: 60
2022-12-31 16:05:32,427 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3392531514167786, 'Total loss': 0.3392531514167786} | train loss {'Reaction outcome loss': 0.2580313990060711, 'Total loss': 0.2580313990060711}
2022-12-31 16:05:32,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:32,427 INFO:     Epoch: 61
2022-12-31 16:05:34,055 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.34717359244823454, 'Total loss': 0.34717359244823454} | train loss {'Reaction outcome loss': 0.24854111210157295, 'Total loss': 0.24854111210157295}
2022-12-31 16:05:34,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:34,055 INFO:     Epoch: 62
2022-12-31 16:05:35,677 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.34635335505008696, 'Total loss': 0.34635335505008696} | train loss {'Reaction outcome loss': 0.2495970992297472, 'Total loss': 0.2495970992297472}
2022-12-31 16:05:35,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:35,678 INFO:     Epoch: 63
2022-12-31 16:05:37,275 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3409319748481115, 'Total loss': 0.3409319748481115} | train loss {'Reaction outcome loss': 0.2500032760498756, 'Total loss': 0.2500032760498756}
2022-12-31 16:05:37,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:37,275 INFO:     Epoch: 64
2022-12-31 16:05:38,923 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3181765834490458, 'Total loss': 0.3181765834490458} | train loss {'Reaction outcome loss': 0.24525815782402827, 'Total loss': 0.24525815782402827}
2022-12-31 16:05:38,924 INFO:     Found new best model at epoch 64
2022-12-31 16:05:38,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:38,925 INFO:     Epoch: 65
2022-12-31 16:05:40,554 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3288384517033895, 'Total loss': 0.3288384517033895} | train loss {'Reaction outcome loss': 0.24651000756326566, 'Total loss': 0.24651000756326566}
2022-12-31 16:05:40,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:40,554 INFO:     Epoch: 66
2022-12-31 16:05:42,184 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3394893447558085, 'Total loss': 0.3394893447558085} | train loss {'Reaction outcome loss': 0.24093799085931228, 'Total loss': 0.24093799085931228}
2022-12-31 16:05:42,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:42,184 INFO:     Epoch: 67
2022-12-31 16:05:43,800 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3712526841710011, 'Total loss': 0.3712526841710011} | train loss {'Reaction outcome loss': 0.2420327946550418, 'Total loss': 0.2420327946550418}
2022-12-31 16:05:43,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:43,800 INFO:     Epoch: 68
2022-12-31 16:05:45,420 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3082469080885251, 'Total loss': 0.3082469080885251} | train loss {'Reaction outcome loss': 0.24132047865257367, 'Total loss': 0.24132047865257367}
2022-12-31 16:05:45,420 INFO:     Found new best model at epoch 68
2022-12-31 16:05:45,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:45,421 INFO:     Epoch: 69
2022-12-31 16:05:47,055 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.34370720088481904, 'Total loss': 0.34370720088481904} | train loss {'Reaction outcome loss': 0.24334666466454738, 'Total loss': 0.24334666466454738}
2022-12-31 16:05:47,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:47,056 INFO:     Epoch: 70
2022-12-31 16:05:48,684 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3253704582651456, 'Total loss': 0.3253704582651456} | train loss {'Reaction outcome loss': 0.23609224537098344, 'Total loss': 0.23609224537098344}
2022-12-31 16:05:48,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:48,684 INFO:     Epoch: 71
2022-12-31 16:05:50,304 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.32330992023150124, 'Total loss': 0.32330992023150124} | train loss {'Reaction outcome loss': 0.2407721582840496, 'Total loss': 0.2407721582840496}
2022-12-31 16:05:50,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:50,304 INFO:     Epoch: 72
2022-12-31 16:05:51,961 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4033875639239947, 'Total loss': 0.4033875639239947} | train loss {'Reaction outcome loss': 0.23992737996583596, 'Total loss': 0.23992737996583596}
2022-12-31 16:05:51,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:51,962 INFO:     Epoch: 73
2022-12-31 16:05:53,613 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.33513155778249104, 'Total loss': 0.33513155778249104} | train loss {'Reaction outcome loss': 0.22920271654072005, 'Total loss': 0.22920271654072005}
2022-12-31 16:05:53,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:53,614 INFO:     Epoch: 74
2022-12-31 16:05:55,251 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.32266436219215394, 'Total loss': 0.32266436219215394} | train loss {'Reaction outcome loss': 0.23298368706546105, 'Total loss': 0.23298368706546105}
2022-12-31 16:05:55,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:55,251 INFO:     Epoch: 75
2022-12-31 16:05:56,909 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.33356137772401173, 'Total loss': 0.33356137772401173} | train loss {'Reaction outcome loss': 0.23119936106450828, 'Total loss': 0.23119936106450828}
2022-12-31 16:05:56,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:56,909 INFO:     Epoch: 76
2022-12-31 16:05:58,545 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.31830722590287525, 'Total loss': 0.31830722590287525} | train loss {'Reaction outcome loss': 0.22272668359296846, 'Total loss': 0.22272668359296846}
2022-12-31 16:05:58,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:05:58,546 INFO:     Epoch: 77
2022-12-31 16:06:00,147 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.33360512008269627, 'Total loss': 0.33360512008269627} | train loss {'Reaction outcome loss': 0.23024428231029734, 'Total loss': 0.23024428231029734}
2022-12-31 16:06:00,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:00,147 INFO:     Epoch: 78
2022-12-31 16:06:01,798 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3424365242322286, 'Total loss': 0.3424365242322286} | train loss {'Reaction outcome loss': 0.23090435013121216, 'Total loss': 0.23090435013121216}
2022-12-31 16:06:01,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:01,798 INFO:     Epoch: 79
2022-12-31 16:06:03,453 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.34202513347069424, 'Total loss': 0.34202513347069424} | train loss {'Reaction outcome loss': 0.22236796052931448, 'Total loss': 0.22236796052931448}
2022-12-31 16:06:03,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:03,453 INFO:     Epoch: 80
2022-12-31 16:06:05,063 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.29837950666745505, 'Total loss': 0.29837950666745505} | train loss {'Reaction outcome loss': 0.22612689994948004, 'Total loss': 0.22612689994948004}
2022-12-31 16:06:05,063 INFO:     Found new best model at epoch 80
2022-12-31 16:06:05,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:05,064 INFO:     Epoch: 81
2022-12-31 16:06:06,678 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.32959432154893875, 'Total loss': 0.32959432154893875} | train loss {'Reaction outcome loss': 0.22361012585192167, 'Total loss': 0.22361012585192167}
2022-12-31 16:06:06,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:06,678 INFO:     Epoch: 82
2022-12-31 16:06:08,278 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.35634691814581554, 'Total loss': 0.35634691814581554} | train loss {'Reaction outcome loss': 0.2253525662588944, 'Total loss': 0.2253525662588944}
2022-12-31 16:06:08,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:08,279 INFO:     Epoch: 83
2022-12-31 16:06:09,900 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.32008991787830987, 'Total loss': 0.32008991787830987} | train loss {'Reaction outcome loss': 0.21976423556731495, 'Total loss': 0.21976423556731495}
2022-12-31 16:06:09,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:09,900 INFO:     Epoch: 84
2022-12-31 16:06:11,548 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.31296614607175194, 'Total loss': 0.31296614607175194} | train loss {'Reaction outcome loss': 0.2118590483811788, 'Total loss': 0.2118590483811788}
2022-12-31 16:06:11,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:11,549 INFO:     Epoch: 85
2022-12-31 16:06:13,156 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.35289697448412577, 'Total loss': 0.35289697448412577} | train loss {'Reaction outcome loss': 0.214660142504674, 'Total loss': 0.214660142504674}
2022-12-31 16:06:13,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:13,156 INFO:     Epoch: 86
2022-12-31 16:06:14,807 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.33291232883930205, 'Total loss': 0.33291232883930205} | train loss {'Reaction outcome loss': 0.22810541373082446, 'Total loss': 0.22810541373082446}
2022-12-31 16:06:14,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:14,809 INFO:     Epoch: 87
2022-12-31 16:06:16,458 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.34922351539134977, 'Total loss': 0.34922351539134977} | train loss {'Reaction outcome loss': 0.21410706042167513, 'Total loss': 0.21410706042167513}
2022-12-31 16:06:16,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:16,459 INFO:     Epoch: 88
2022-12-31 16:06:18,080 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.35976767440636953, 'Total loss': 0.35976767440636953} | train loss {'Reaction outcome loss': 0.21723085639171222, 'Total loss': 0.21723085639171222}
2022-12-31 16:06:18,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:18,080 INFO:     Epoch: 89
2022-12-31 16:06:19,693 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3585275868574778, 'Total loss': 0.3585275868574778} | train loss {'Reaction outcome loss': 0.21731568578402058, 'Total loss': 0.21731568578402058}
2022-12-31 16:06:19,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:19,694 INFO:     Epoch: 90
2022-12-31 16:06:21,315 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3239962791403135, 'Total loss': 0.3239962791403135} | train loss {'Reaction outcome loss': 0.21236535882247806, 'Total loss': 0.21236535882247806}
2022-12-31 16:06:21,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:21,316 INFO:     Epoch: 91
2022-12-31 16:06:22,910 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.34741264780362446, 'Total loss': 0.34741264780362446} | train loss {'Reaction outcome loss': 0.21014743087147547, 'Total loss': 0.21014743087147547}
2022-12-31 16:06:22,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:22,911 INFO:     Epoch: 92
2022-12-31 16:06:24,521 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3391544669866562, 'Total loss': 0.3391544669866562} | train loss {'Reaction outcome loss': 0.2139517156346718, 'Total loss': 0.2139517156346718}
2022-12-31 16:06:24,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:24,522 INFO:     Epoch: 93
2022-12-31 16:06:26,120 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.32556740889946617, 'Total loss': 0.32556740889946617} | train loss {'Reaction outcome loss': 0.20386615531377844, 'Total loss': 0.20386615531377844}
2022-12-31 16:06:26,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:26,121 INFO:     Epoch: 94
2022-12-31 16:06:27,756 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3182789956529935, 'Total loss': 0.3182789956529935} | train loss {'Reaction outcome loss': 0.2033166574912704, 'Total loss': 0.2033166574912704}
2022-12-31 16:06:27,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:27,756 INFO:     Epoch: 95
2022-12-31 16:06:29,387 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3197920317451159, 'Total loss': 0.3197920317451159} | train loss {'Reaction outcome loss': 0.20468724926510012, 'Total loss': 0.20468724926510012}
2022-12-31 16:06:29,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:29,387 INFO:     Epoch: 96
2022-12-31 16:06:30,987 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3205399766564369, 'Total loss': 0.3205399766564369} | train loss {'Reaction outcome loss': 0.20870814639200802, 'Total loss': 0.20870814639200802}
2022-12-31 16:06:30,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:30,987 INFO:     Epoch: 97
2022-12-31 16:06:32,613 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.32768930395444235, 'Total loss': 0.32768930395444235} | train loss {'Reaction outcome loss': 0.20445770647255737, 'Total loss': 0.20445770647255737}
2022-12-31 16:06:32,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:32,613 INFO:     Epoch: 98
2022-12-31 16:06:34,220 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3470340117812157, 'Total loss': 0.3470340117812157} | train loss {'Reaction outcome loss': 0.209754503476652, 'Total loss': 0.209754503476652}
2022-12-31 16:06:34,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:34,221 INFO:     Epoch: 99
2022-12-31 16:06:35,820 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3367101808389028, 'Total loss': 0.3367101808389028} | train loss {'Reaction outcome loss': 0.2035575584014239, 'Total loss': 0.2035575584014239}
2022-12-31 16:06:35,821 INFO:     Best model found after epoch 81 of 100.
2022-12-31 16:06:35,821 INFO:   Done with stage: TRAINING
2022-12-31 16:06:35,821 INFO:   Starting stage: EVALUATION
2022-12-31 16:06:35,943 INFO:   Done with stage: EVALUATION
2022-12-31 16:06:35,944 INFO:   Leaving out SEQ value Fold_7
2022-12-31 16:06:35,956 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 16:06:35,956 INFO:   Starting stage: FEATURE SCALING
2022-12-31 16:06:36,602 INFO:   Done with stage: FEATURE SCALING
2022-12-31 16:06:36,602 INFO:   Starting stage: SCALING TARGETS
2022-12-31 16:06:36,671 INFO:   Done with stage: SCALING TARGETS
2022-12-31 16:06:36,671 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 16:06:36,671 INFO:     No hyperparam tuning for this model
2022-12-31 16:06:36,671 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 16:06:36,671 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 16:06:36,672 INFO:     None feature selector for col prot
2022-12-31 16:06:36,672 INFO:     None feature selector for col prot
2022-12-31 16:06:36,672 INFO:     None feature selector for col prot
2022-12-31 16:06:36,673 INFO:     None feature selector for col chem
2022-12-31 16:06:36,673 INFO:     None feature selector for col chem
2022-12-31 16:06:36,673 INFO:     None feature selector for col chem
2022-12-31 16:06:36,673 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 16:06:36,673 INFO:   Starting stage: BUILD MODEL
2022-12-31 16:06:36,675 INFO:     Number of params in model 223921
2022-12-31 16:06:36,678 INFO:   Done with stage: BUILD MODEL
2022-12-31 16:06:36,678 INFO:   Starting stage: TRAINING
2022-12-31 16:06:36,724 INFO:     Val loss before train {'Reaction outcome loss': 1.0246840198834737, 'Total loss': 1.0246840198834737}
2022-12-31 16:06:36,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:36,725 INFO:     Epoch: 0
2022-12-31 16:06:38,351 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6871007343133291, 'Total loss': 0.6871007343133291} | train loss {'Reaction outcome loss': 0.8132397594865048, 'Total loss': 0.8132397594865048}
2022-12-31 16:06:38,351 INFO:     Found new best model at epoch 0
2022-12-31 16:06:38,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:38,352 INFO:     Epoch: 1
2022-12-31 16:06:39,960 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5545869211355845, 'Total loss': 0.5545869211355845} | train loss {'Reaction outcome loss': 0.5925196870784897, 'Total loss': 0.5925196870784897}
2022-12-31 16:06:39,960 INFO:     Found new best model at epoch 1
2022-12-31 16:06:39,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:39,961 INFO:     Epoch: 2
2022-12-31 16:06:41,559 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5075721591711044, 'Total loss': 0.5075721591711044} | train loss {'Reaction outcome loss': 0.5282105059507521, 'Total loss': 0.5282105059507521}
2022-12-31 16:06:41,559 INFO:     Found new best model at epoch 2
2022-12-31 16:06:41,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:41,560 INFO:     Epoch: 3
2022-12-31 16:06:43,168 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5111157556374868, 'Total loss': 0.5111157556374868} | train loss {'Reaction outcome loss': 0.5047952377839209, 'Total loss': 0.5047952377839209}
2022-12-31 16:06:43,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:43,169 INFO:     Epoch: 4
2022-12-31 16:06:44,784 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.503666611512502, 'Total loss': 0.503666611512502} | train loss {'Reaction outcome loss': 0.4941137124269878, 'Total loss': 0.4941137124269878}
2022-12-31 16:06:44,784 INFO:     Found new best model at epoch 4
2022-12-31 16:06:44,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:44,785 INFO:     Epoch: 5
2022-12-31 16:06:46,400 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4829389373461405, 'Total loss': 0.4829389373461405} | train loss {'Reaction outcome loss': 0.4832477375380829, 'Total loss': 0.4832477375380829}
2022-12-31 16:06:46,400 INFO:     Found new best model at epoch 5
2022-12-31 16:06:46,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:46,402 INFO:     Epoch: 6
2022-12-31 16:06:48,010 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4832035760084788, 'Total loss': 0.4832035760084788} | train loss {'Reaction outcome loss': 0.46800172721651057, 'Total loss': 0.46800172721651057}
2022-12-31 16:06:48,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:48,010 INFO:     Epoch: 7
2022-12-31 16:06:49,607 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46077536046504974, 'Total loss': 0.46077536046504974} | train loss {'Reaction outcome loss': 0.4605343944867165, 'Total loss': 0.4605343944867165}
2022-12-31 16:06:49,608 INFO:     Found new best model at epoch 7
2022-12-31 16:06:49,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:49,609 INFO:     Epoch: 8
2022-12-31 16:06:51,218 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46956261098384855, 'Total loss': 0.46956261098384855} | train loss {'Reaction outcome loss': 0.4576490239008239, 'Total loss': 0.4576490239008239}
2022-12-31 16:06:51,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:51,218 INFO:     Epoch: 9
2022-12-31 16:06:52,824 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4657353361447652, 'Total loss': 0.4657353361447652} | train loss {'Reaction outcome loss': 0.45059102547728197, 'Total loss': 0.45059102547728197}
2022-12-31 16:06:52,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:52,824 INFO:     Epoch: 10
2022-12-31 16:06:54,423 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47627707521120705, 'Total loss': 0.47627707521120705} | train loss {'Reaction outcome loss': 0.4424715762426707, 'Total loss': 0.4424715762426707}
2022-12-31 16:06:54,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:54,423 INFO:     Epoch: 11
2022-12-31 16:06:56,044 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4582119107246399, 'Total loss': 0.4582119107246399} | train loss {'Reaction outcome loss': 0.4396000630373559, 'Total loss': 0.4396000630373559}
2022-12-31 16:06:56,045 INFO:     Found new best model at epoch 11
2022-12-31 16:06:56,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:56,046 INFO:     Epoch: 12
2022-12-31 16:06:57,674 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4612320969502131, 'Total loss': 0.4612320969502131} | train loss {'Reaction outcome loss': 0.43230952134201245, 'Total loss': 0.43230952134201245}
2022-12-31 16:06:57,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:57,674 INFO:     Epoch: 13
2022-12-31 16:06:59,317 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4648728946844737, 'Total loss': 0.4648728946844737} | train loss {'Reaction outcome loss': 0.42950555488521014, 'Total loss': 0.42950555488521014}
2022-12-31 16:06:59,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:06:59,317 INFO:     Epoch: 14
2022-12-31 16:07:00,972 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4509951114654541, 'Total loss': 0.4509951114654541} | train loss {'Reaction outcome loss': 0.41879098402464005, 'Total loss': 0.41879098402464005}
2022-12-31 16:07:00,972 INFO:     Found new best model at epoch 14
2022-12-31 16:07:00,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:00,973 INFO:     Epoch: 15
2022-12-31 16:07:02,590 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4714104096094767, 'Total loss': 0.4714104096094767} | train loss {'Reaction outcome loss': 0.41985573756780864, 'Total loss': 0.41985573756780864}
2022-12-31 16:07:02,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:02,590 INFO:     Epoch: 16
2022-12-31 16:07:04,240 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4580734888712565, 'Total loss': 0.4580734888712565} | train loss {'Reaction outcome loss': 0.4095361422384259, 'Total loss': 0.4095361422384259}
2022-12-31 16:07:04,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:04,241 INFO:     Epoch: 17
2022-12-31 16:07:05,862 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48142574230829877, 'Total loss': 0.48142574230829877} | train loss {'Reaction outcome loss': 0.4049966333682787, 'Total loss': 0.4049966333682787}
2022-12-31 16:07:05,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:05,862 INFO:     Epoch: 18
2022-12-31 16:07:07,473 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43933012237151464, 'Total loss': 0.43933012237151464} | train loss {'Reaction outcome loss': 0.40030343679960023, 'Total loss': 0.40030343679960023}
2022-12-31 16:07:07,473 INFO:     Found new best model at epoch 18
2022-12-31 16:07:07,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:07,474 INFO:     Epoch: 19
2022-12-31 16:07:09,082 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4477838377157847, 'Total loss': 0.4477838377157847} | train loss {'Reaction outcome loss': 0.394465403947374, 'Total loss': 0.394465403947374}
2022-12-31 16:07:09,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:09,083 INFO:     Epoch: 20
2022-12-31 16:07:10,691 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45924402475357057, 'Total loss': 0.45924402475357057} | train loss {'Reaction outcome loss': 0.392399146103902, 'Total loss': 0.392399146103902}
2022-12-31 16:07:10,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:10,691 INFO:     Epoch: 21
2022-12-31 16:07:12,302 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4369849681854248, 'Total loss': 0.4369849681854248} | train loss {'Reaction outcome loss': 0.3833990052127236, 'Total loss': 0.3833990052127236}
2022-12-31 16:07:12,303 INFO:     Found new best model at epoch 21
2022-12-31 16:07:12,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:12,304 INFO:     Epoch: 22
2022-12-31 16:07:13,956 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45197385251522065, 'Total loss': 0.45197385251522065} | train loss {'Reaction outcome loss': 0.37630249222316897, 'Total loss': 0.37630249222316897}
2022-12-31 16:07:13,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:13,957 INFO:     Epoch: 23
2022-12-31 16:07:15,597 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4571065376202265, 'Total loss': 0.4571065376202265} | train loss {'Reaction outcome loss': 0.3725563275631154, 'Total loss': 0.3725563275631154}
2022-12-31 16:07:15,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:15,597 INFO:     Epoch: 24
2022-12-31 16:07:17,228 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4336212694644928, 'Total loss': 0.4336212694644928} | train loss {'Reaction outcome loss': 0.3705671503332978, 'Total loss': 0.3705671503332978}
2022-12-31 16:07:17,228 INFO:     Found new best model at epoch 24
2022-12-31 16:07:17,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:17,229 INFO:     Epoch: 25
2022-12-31 16:07:18,843 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44941433469454445, 'Total loss': 0.44941433469454445} | train loss {'Reaction outcome loss': 0.360646982391496, 'Total loss': 0.360646982391496}
2022-12-31 16:07:18,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:18,843 INFO:     Epoch: 26
2022-12-31 16:07:20,456 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4707614322503408, 'Total loss': 0.4707614322503408} | train loss {'Reaction outcome loss': 0.35613387605235897, 'Total loss': 0.35613387605235897}
2022-12-31 16:07:20,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:20,457 INFO:     Epoch: 27
2022-12-31 16:07:22,068 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45134125351905824, 'Total loss': 0.45134125351905824} | train loss {'Reaction outcome loss': 0.35456836387676455, 'Total loss': 0.35456836387676455}
2022-12-31 16:07:22,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:22,069 INFO:     Epoch: 28
2022-12-31 16:07:23,715 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42723065813382466, 'Total loss': 0.42723065813382466} | train loss {'Reaction outcome loss': 0.3448187187583008, 'Total loss': 0.3448187187583008}
2022-12-31 16:07:23,715 INFO:     Found new best model at epoch 28
2022-12-31 16:07:23,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:23,716 INFO:     Epoch: 29
2022-12-31 16:07:25,309 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4381124993165334, 'Total loss': 0.4381124993165334} | train loss {'Reaction outcome loss': 0.35046024015341426, 'Total loss': 0.35046024015341426}
2022-12-31 16:07:25,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:25,309 INFO:     Epoch: 30
2022-12-31 16:07:26,945 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4469046105941137, 'Total loss': 0.4469046105941137} | train loss {'Reaction outcome loss': 0.33469891459395307, 'Total loss': 0.33469891459395307}
2022-12-31 16:07:26,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:26,946 INFO:     Epoch: 31
2022-12-31 16:07:28,558 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.464443501830101, 'Total loss': 0.464443501830101} | train loss {'Reaction outcome loss': 0.3326446726003709, 'Total loss': 0.3326446726003709}
2022-12-31 16:07:28,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:28,558 INFO:     Epoch: 32
2022-12-31 16:07:30,160 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46036412914594016, 'Total loss': 0.46036412914594016} | train loss {'Reaction outcome loss': 0.3293934992181695, 'Total loss': 0.3293934992181695}
2022-12-31 16:07:30,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:30,160 INFO:     Epoch: 33
2022-12-31 16:07:31,814 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.449508410692215, 'Total loss': 0.449508410692215} | train loss {'Reaction outcome loss': 0.3290886764653323, 'Total loss': 0.3290886764653323}
2022-12-31 16:07:31,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:31,814 INFO:     Epoch: 34
2022-12-31 16:07:33,422 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4322555402914683, 'Total loss': 0.4322555402914683} | train loss {'Reaction outcome loss': 0.32497943840947824, 'Total loss': 0.32497943840947824}
2022-12-31 16:07:33,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:33,423 INFO:     Epoch: 35
2022-12-31 16:07:35,016 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43860474129517873, 'Total loss': 0.43860474129517873} | train loss {'Reaction outcome loss': 0.3184173789265354, 'Total loss': 0.3184173789265354}
2022-12-31 16:07:35,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:35,016 INFO:     Epoch: 36
2022-12-31 16:07:36,626 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4330354909102122, 'Total loss': 0.4330354909102122} | train loss {'Reaction outcome loss': 0.3106498652228595, 'Total loss': 0.3106498652228595}
2022-12-31 16:07:36,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:36,627 INFO:     Epoch: 37
2022-12-31 16:07:38,235 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4345543215672175, 'Total loss': 0.4345543215672175} | train loss {'Reaction outcome loss': 0.30641672032673434, 'Total loss': 0.30641672032673434}
2022-12-31 16:07:38,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:38,236 INFO:     Epoch: 38
2022-12-31 16:07:39,862 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45023746490478517, 'Total loss': 0.45023746490478517} | train loss {'Reaction outcome loss': 0.3114386311184198, 'Total loss': 0.3114386311184198}
2022-12-31 16:07:39,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:39,863 INFO:     Epoch: 39
2022-12-31 16:07:41,494 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42840114533901213, 'Total loss': 0.42840114533901213} | train loss {'Reaction outcome loss': 0.3044665516606307, 'Total loss': 0.3044665516606307}
2022-12-31 16:07:41,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:41,495 INFO:     Epoch: 40
2022-12-31 16:07:43,090 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4414532154798508, 'Total loss': 0.4414532154798508} | train loss {'Reaction outcome loss': 0.3011726505435761, 'Total loss': 0.3011726505435761}
2022-12-31 16:07:43,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:43,090 INFO:     Epoch: 41
2022-12-31 16:07:44,724 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4381486177444458, 'Total loss': 0.4381486177444458} | train loss {'Reaction outcome loss': 0.30086747501785144, 'Total loss': 0.30086747501785144}
2022-12-31 16:07:44,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:44,724 INFO:     Epoch: 42
2022-12-31 16:07:46,359 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43839315672715506, 'Total loss': 0.43839315672715506} | train loss {'Reaction outcome loss': 0.2929698923058028, 'Total loss': 0.2929698923058028}
2022-12-31 16:07:46,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:46,359 INFO:     Epoch: 43
2022-12-31 16:07:47,974 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44690470695495604, 'Total loss': 0.44690470695495604} | train loss {'Reaction outcome loss': 0.28851318154954736, 'Total loss': 0.28851318154954736}
2022-12-31 16:07:47,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:47,974 INFO:     Epoch: 44
2022-12-31 16:07:49,611 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4677874485651652, 'Total loss': 0.4677874485651652} | train loss {'Reaction outcome loss': 0.28916877933142415, 'Total loss': 0.28916877933142415}
2022-12-31 16:07:49,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:49,611 INFO:     Epoch: 45
2022-12-31 16:07:51,231 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42578495740890504, 'Total loss': 0.42578495740890504} | train loss {'Reaction outcome loss': 0.28824210453388494, 'Total loss': 0.28824210453388494}
2022-12-31 16:07:51,232 INFO:     Found new best model at epoch 45
2022-12-31 16:07:51,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:51,233 INFO:     Epoch: 46
2022-12-31 16:07:52,827 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41531504690647125, 'Total loss': 0.41531504690647125} | train loss {'Reaction outcome loss': 0.2769049642748781, 'Total loss': 0.2769049642748781}
2022-12-31 16:07:52,827 INFO:     Found new best model at epoch 46
2022-12-31 16:07:52,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:52,828 INFO:     Epoch: 47
2022-12-31 16:07:54,438 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43460490306218463, 'Total loss': 0.43460490306218463} | train loss {'Reaction outcome loss': 0.2770418369678599, 'Total loss': 0.2770418369678599}
2022-12-31 16:07:54,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:54,439 INFO:     Epoch: 48
2022-12-31 16:07:56,050 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4437077929576238, 'Total loss': 0.4437077929576238} | train loss {'Reaction outcome loss': 0.27470982263019367, 'Total loss': 0.27470982263019367}
2022-12-31 16:07:56,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:56,050 INFO:     Epoch: 49
2022-12-31 16:07:57,681 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.434161044160525, 'Total loss': 0.434161044160525} | train loss {'Reaction outcome loss': 0.2712234339343942, 'Total loss': 0.2712234339343942}
2022-12-31 16:07:57,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:57,682 INFO:     Epoch: 50
2022-12-31 16:07:59,294 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4349076191584269, 'Total loss': 0.4349076191584269} | train loss {'Reaction outcome loss': 0.27413531665821367, 'Total loss': 0.27413531665821367}
2022-12-31 16:07:59,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:07:59,295 INFO:     Epoch: 51
2022-12-31 16:08:00,926 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45546128153800963, 'Total loss': 0.45546128153800963} | train loss {'Reaction outcome loss': 0.26828165463968734, 'Total loss': 0.26828165463968734}
2022-12-31 16:08:00,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:00,926 INFO:     Epoch: 52
2022-12-31 16:08:02,560 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42860009769598645, 'Total loss': 0.42860009769598645} | train loss {'Reaction outcome loss': 0.2704074201493487, 'Total loss': 0.2704074201493487}
2022-12-31 16:08:02,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:02,561 INFO:     Epoch: 53
2022-12-31 16:08:04,195 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4410231997569402, 'Total loss': 0.4410231997569402} | train loss {'Reaction outcome loss': 0.26458021542494475, 'Total loss': 0.26458021542494475}
2022-12-31 16:08:04,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:04,196 INFO:     Epoch: 54
2022-12-31 16:08:05,795 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43032873968283336, 'Total loss': 0.43032873968283336} | train loss {'Reaction outcome loss': 0.2657660328739387, 'Total loss': 0.2657660328739387}
2022-12-31 16:08:05,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:05,795 INFO:     Epoch: 55
2022-12-31 16:08:07,438 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41973119775454204, 'Total loss': 0.41973119775454204} | train loss {'Reaction outcome loss': 0.2698076770435817, 'Total loss': 0.2698076770435817}
2022-12-31 16:08:07,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:07,438 INFO:     Epoch: 56
2022-12-31 16:08:09,081 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42481067577997844, 'Total loss': 0.42481067577997844} | train loss {'Reaction outcome loss': 0.251839967289879, 'Total loss': 0.251839967289879}
2022-12-31 16:08:09,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:09,081 INFO:     Epoch: 57
2022-12-31 16:08:10,709 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39644852131605146, 'Total loss': 0.39644852131605146} | train loss {'Reaction outcome loss': 0.259899540928727, 'Total loss': 0.259899540928727}
2022-12-31 16:08:10,709 INFO:     Found new best model at epoch 57
2022-12-31 16:08:10,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:10,710 INFO:     Epoch: 58
2022-12-31 16:08:12,327 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43280860980351765, 'Total loss': 0.43280860980351765} | train loss {'Reaction outcome loss': 0.2540461279667026, 'Total loss': 0.2540461279667026}
2022-12-31 16:08:12,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:12,327 INFO:     Epoch: 59
2022-12-31 16:08:13,941 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46036663154761, 'Total loss': 0.46036663154761} | train loss {'Reaction outcome loss': 0.2582489706320345, 'Total loss': 0.2582489706320345}
2022-12-31 16:08:13,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:13,941 INFO:     Epoch: 60
2022-12-31 16:08:15,541 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42816973229249317, 'Total loss': 0.42816973229249317} | train loss {'Reaction outcome loss': 0.25292373261673357, 'Total loss': 0.25292373261673357}
2022-12-31 16:08:15,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:15,542 INFO:     Epoch: 61
2022-12-31 16:08:17,155 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4450656493504842, 'Total loss': 0.4450656493504842} | train loss {'Reaction outcome loss': 0.2483130535547914, 'Total loss': 0.2483130535547914}
2022-12-31 16:08:17,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:17,155 INFO:     Epoch: 62
2022-12-31 16:08:18,769 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43903061946233113, 'Total loss': 0.43903061946233113} | train loss {'Reaction outcome loss': 0.24909684835304421, 'Total loss': 0.24909684835304421}
2022-12-31 16:08:18,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:18,769 INFO:     Epoch: 63
2022-12-31 16:08:20,369 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42221639851729076, 'Total loss': 0.42221639851729076} | train loss {'Reaction outcome loss': 0.2508684377444888, 'Total loss': 0.2508684377444888}
2022-12-31 16:08:20,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:20,369 INFO:     Epoch: 64
2022-12-31 16:08:21,983 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41543271342913307, 'Total loss': 0.41543271342913307} | train loss {'Reaction outcome loss': 0.2440481159553631, 'Total loss': 0.2440481159553631}
2022-12-31 16:08:21,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:21,985 INFO:     Epoch: 65
2022-12-31 16:08:23,586 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4150416702032089, 'Total loss': 0.4150416702032089} | train loss {'Reaction outcome loss': 0.2469452700917256, 'Total loss': 0.2469452700917256}
2022-12-31 16:08:23,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:23,587 INFO:     Epoch: 66
2022-12-31 16:08:25,229 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40523647765318555, 'Total loss': 0.40523647765318555} | train loss {'Reaction outcome loss': 0.24076643599607453, 'Total loss': 0.24076643599607453}
2022-12-31 16:08:25,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:25,229 INFO:     Epoch: 67
2022-12-31 16:08:26,877 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42894928256670634, 'Total loss': 0.42894928256670634} | train loss {'Reaction outcome loss': 0.24171093876880428, 'Total loss': 0.24171093876880428}
2022-12-31 16:08:26,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:26,878 INFO:     Epoch: 68
2022-12-31 16:08:28,418 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41476696034272514, 'Total loss': 0.41476696034272514} | train loss {'Reaction outcome loss': 0.2407756773250628, 'Total loss': 0.2407756773250628}
2022-12-31 16:08:28,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:28,418 INFO:     Epoch: 69
2022-12-31 16:08:29,517 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4359862099091212, 'Total loss': 0.4359862099091212} | train loss {'Reaction outcome loss': 0.23291159944360007, 'Total loss': 0.23291159944360007}
2022-12-31 16:08:29,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:29,517 INFO:     Epoch: 70
2022-12-31 16:08:30,606 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4401204615831375, 'Total loss': 0.4401204615831375} | train loss {'Reaction outcome loss': 0.23484711944787942, 'Total loss': 0.23484711944787942}
2022-12-31 16:08:30,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:30,606 INFO:     Epoch: 71
2022-12-31 16:08:31,700 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4048111418883006, 'Total loss': 0.4048111418883006} | train loss {'Reaction outcome loss': 0.23396232344936377, 'Total loss': 0.23396232344936377}
2022-12-31 16:08:31,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:31,700 INFO:     Epoch: 72
2022-12-31 16:08:32,786 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.451884134610494, 'Total loss': 0.451884134610494} | train loss {'Reaction outcome loss': 0.22990096602521648, 'Total loss': 0.22990096602521648}
2022-12-31 16:08:32,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:32,786 INFO:     Epoch: 73
2022-12-31 16:08:34,416 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4036433493097623, 'Total loss': 0.4036433493097623} | train loss {'Reaction outcome loss': 0.2261041259453615, 'Total loss': 0.2261041259453615}
2022-12-31 16:08:34,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:34,416 INFO:     Epoch: 74
2022-12-31 16:08:36,071 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49264774123827615, 'Total loss': 0.49264774123827615} | train loss {'Reaction outcome loss': 0.23393772895505066, 'Total loss': 0.23393772895505066}
2022-12-31 16:08:36,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:36,072 INFO:     Epoch: 75
2022-12-31 16:08:37,727 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4181928386290868, 'Total loss': 0.4181928386290868} | train loss {'Reaction outcome loss': 0.2276999908986935, 'Total loss': 0.2276999908986935}
2022-12-31 16:08:37,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:37,727 INFO:     Epoch: 76
2022-12-31 16:08:39,363 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4178576370080312, 'Total loss': 0.4178576370080312} | train loss {'Reaction outcome loss': 0.22612579068041236, 'Total loss': 0.22612579068041236}
2022-12-31 16:08:39,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:39,363 INFO:     Epoch: 77
2022-12-31 16:08:40,966 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43223655422528584, 'Total loss': 0.43223655422528584} | train loss {'Reaction outcome loss': 0.22642376737850667, 'Total loss': 0.22642376737850667}
2022-12-31 16:08:40,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:40,967 INFO:     Epoch: 78
2022-12-31 16:08:42,569 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4231070190668106, 'Total loss': 0.4231070190668106} | train loss {'Reaction outcome loss': 0.2316709065655186, 'Total loss': 0.2316709065655186}
2022-12-31 16:08:42,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:42,570 INFO:     Epoch: 79
2022-12-31 16:08:44,184 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3978395144144694, 'Total loss': 0.3978395144144694} | train loss {'Reaction outcome loss': 0.22775173225920875, 'Total loss': 0.22775173225920875}
2022-12-31 16:08:44,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:44,184 INFO:     Epoch: 80
2022-12-31 16:08:45,798 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4256725569566091, 'Total loss': 0.4256725569566091} | train loss {'Reaction outcome loss': 0.22560726158616776, 'Total loss': 0.22560726158616776}
2022-12-31 16:08:45,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:45,799 INFO:     Epoch: 81
2022-12-31 16:08:47,440 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40324078102906546, 'Total loss': 0.40324078102906546} | train loss {'Reaction outcome loss': 0.22026690142733527, 'Total loss': 0.22026690142733527}
2022-12-31 16:08:47,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:47,440 INFO:     Epoch: 82
2022-12-31 16:08:49,043 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4296253681182861, 'Total loss': 0.4296253681182861} | train loss {'Reaction outcome loss': 0.21972354353550108, 'Total loss': 0.21972354353550108}
2022-12-31 16:08:49,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:49,044 INFO:     Epoch: 83
2022-12-31 16:08:50,668 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4493750145037969, 'Total loss': 0.4493750145037969} | train loss {'Reaction outcome loss': 0.21718378656876647, 'Total loss': 0.21718378656876647}
2022-12-31 16:08:50,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:50,668 INFO:     Epoch: 84
2022-12-31 16:08:52,296 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3951493601004283, 'Total loss': 0.3951493601004283} | train loss {'Reaction outcome loss': 0.219740679410256, 'Total loss': 0.219740679410256}
2022-12-31 16:08:52,297 INFO:     Found new best model at epoch 84
2022-12-31 16:08:52,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:52,298 INFO:     Epoch: 85
2022-12-31 16:08:53,925 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43724523882071176, 'Total loss': 0.43724523882071176} | train loss {'Reaction outcome loss': 0.21524909473888387, 'Total loss': 0.21524909473888387}
2022-12-31 16:08:53,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:53,925 INFO:     Epoch: 86
2022-12-31 16:08:55,550 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4108668237924576, 'Total loss': 0.4108668237924576} | train loss {'Reaction outcome loss': 0.22077854943969405, 'Total loss': 0.22077854943969405}
2022-12-31 16:08:55,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:55,550 INFO:     Epoch: 87
2022-12-31 16:08:57,192 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4221057633558909, 'Total loss': 0.4221057633558909} | train loss {'Reaction outcome loss': 0.2194277040041741, 'Total loss': 0.2194277040041741}
2022-12-31 16:08:57,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:57,192 INFO:     Epoch: 88
2022-12-31 16:08:58,799 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4401454389095306, 'Total loss': 0.4401454389095306} | train loss {'Reaction outcome loss': 0.21064639028282803, 'Total loss': 0.21064639028282803}
2022-12-31 16:08:58,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:08:58,800 INFO:     Epoch: 89
2022-12-31 16:09:00,407 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4361411730448405, 'Total loss': 0.4361411730448405} | train loss {'Reaction outcome loss': 0.2193281251990946, 'Total loss': 0.2193281251990946}
2022-12-31 16:09:00,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:00,407 INFO:     Epoch: 90
2022-12-31 16:09:02,050 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41812408169110615, 'Total loss': 0.41812408169110615} | train loss {'Reaction outcome loss': 0.2098478384632012, 'Total loss': 0.2098478384632012}
2022-12-31 16:09:02,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:02,050 INFO:     Epoch: 91
2022-12-31 16:09:03,702 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4286951909462611, 'Total loss': 0.4286951909462611} | train loss {'Reaction outcome loss': 0.21281648156256666, 'Total loss': 0.21281648156256666}
2022-12-31 16:09:03,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:03,702 INFO:     Epoch: 92
2022-12-31 16:09:05,356 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41822607616583507, 'Total loss': 0.41822607616583507} | train loss {'Reaction outcome loss': 0.21532155775098594, 'Total loss': 0.21532155775098594}
2022-12-31 16:09:05,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:05,356 INFO:     Epoch: 93
2022-12-31 16:09:06,979 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42996226449807484, 'Total loss': 0.42996226449807484} | train loss {'Reaction outcome loss': 0.21537191568056815, 'Total loss': 0.21537191568056815}
2022-12-31 16:09:06,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:06,979 INFO:     Epoch: 94
2022-12-31 16:09:08,631 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4279908021291097, 'Total loss': 0.4279908021291097} | train loss {'Reaction outcome loss': 0.21616988001048348, 'Total loss': 0.21616988001048348}
2022-12-31 16:09:08,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:08,631 INFO:     Epoch: 95
2022-12-31 16:09:10,239 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4317294577757517, 'Total loss': 0.4317294577757517} | train loss {'Reaction outcome loss': 0.21038364097207032, 'Total loss': 0.21038364097207032}
2022-12-31 16:09:10,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:10,239 INFO:     Epoch: 96
2022-12-31 16:09:11,887 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4606900654733181, 'Total loss': 0.4606900654733181} | train loss {'Reaction outcome loss': 0.21350709690514025, 'Total loss': 0.21350709690514025}
2022-12-31 16:09:11,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:11,888 INFO:     Epoch: 97
2022-12-31 16:09:13,540 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43949443896611534, 'Total loss': 0.43949443896611534} | train loss {'Reaction outcome loss': 0.20862914768420832, 'Total loss': 0.20862914768420832}
2022-12-31 16:09:13,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:13,541 INFO:     Epoch: 98
2022-12-31 16:09:15,172 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42919986496369045, 'Total loss': 0.42919986496369045} | train loss {'Reaction outcome loss': 0.20757575077256893, 'Total loss': 0.20757575077256893}
2022-12-31 16:09:15,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:15,173 INFO:     Epoch: 99
2022-12-31 16:09:16,777 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.443747878074646, 'Total loss': 0.443747878074646} | train loss {'Reaction outcome loss': 0.20151626287761149, 'Total loss': 0.20151626287761149}
2022-12-31 16:09:16,777 INFO:     Best model found after epoch 85 of 100.
2022-12-31 16:09:16,777 INFO:   Done with stage: TRAINING
2022-12-31 16:09:16,777 INFO:   Starting stage: EVALUATION
2022-12-31 16:09:16,900 INFO:   Done with stage: EVALUATION
2022-12-31 16:09:16,900 INFO:   Leaving out SEQ value Fold_8
2022-12-31 16:09:16,913 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 16:09:16,913 INFO:   Starting stage: FEATURE SCALING
2022-12-31 16:09:17,565 INFO:   Done with stage: FEATURE SCALING
2022-12-31 16:09:17,565 INFO:   Starting stage: SCALING TARGETS
2022-12-31 16:09:17,633 INFO:   Done with stage: SCALING TARGETS
2022-12-31 16:09:17,633 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 16:09:17,633 INFO:     No hyperparam tuning for this model
2022-12-31 16:09:17,633 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 16:09:17,633 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 16:09:17,634 INFO:     None feature selector for col prot
2022-12-31 16:09:17,634 INFO:     None feature selector for col prot
2022-12-31 16:09:17,634 INFO:     None feature selector for col prot
2022-12-31 16:09:17,635 INFO:     None feature selector for col chem
2022-12-31 16:09:17,635 INFO:     None feature selector for col chem
2022-12-31 16:09:17,635 INFO:     None feature selector for col chem
2022-12-31 16:09:17,635 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 16:09:17,635 INFO:   Starting stage: BUILD MODEL
2022-12-31 16:09:17,638 INFO:     Number of params in model 223921
2022-12-31 16:09:17,641 INFO:   Done with stage: BUILD MODEL
2022-12-31 16:09:17,641 INFO:   Starting stage: TRAINING
2022-12-31 16:09:17,688 INFO:     Val loss before train {'Reaction outcome loss': 0.9636035601298014, 'Total loss': 0.9636035601298014}
2022-12-31 16:09:17,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:17,689 INFO:     Epoch: 0
2022-12-31 16:09:19,290 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6432753403981527, 'Total loss': 0.6432753403981527} | train loss {'Reaction outcome loss': 0.8056139901389171, 'Total loss': 0.8056139901389171}
2022-12-31 16:09:19,290 INFO:     Found new best model at epoch 0
2022-12-31 16:09:19,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:19,291 INFO:     Epoch: 1
2022-12-31 16:09:20,905 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.45783736805121106, 'Total loss': 0.45783736805121106} | train loss {'Reaction outcome loss': 0.5905734246229604, 'Total loss': 0.5905734246229604}
2022-12-31 16:09:20,905 INFO:     Found new best model at epoch 1
2022-12-31 16:09:20,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:20,906 INFO:     Epoch: 2
2022-12-31 16:09:22,503 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4736247529586156, 'Total loss': 0.4736247529586156} | train loss {'Reaction outcome loss': 0.5162933910958958, 'Total loss': 0.5162933910958958}
2022-12-31 16:09:22,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:22,504 INFO:     Epoch: 3
2022-12-31 16:09:24,106 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44478390415509544, 'Total loss': 0.44478390415509544} | train loss {'Reaction outcome loss': 0.49407801749932506, 'Total loss': 0.49407801749932506}
2022-12-31 16:09:24,106 INFO:     Found new best model at epoch 3
2022-12-31 16:09:24,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:24,107 INFO:     Epoch: 4
2022-12-31 16:09:25,702 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4624721904595693, 'Total loss': 0.4624721904595693} | train loss {'Reaction outcome loss': 0.47880964171494883, 'Total loss': 0.47880964171494883}
2022-12-31 16:09:25,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:25,702 INFO:     Epoch: 5
2022-12-31 16:09:27,296 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46018275419871013, 'Total loss': 0.46018275419871013} | train loss {'Reaction outcome loss': 0.46462082667072324, 'Total loss': 0.46462082667072324}
2022-12-31 16:09:27,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:27,296 INFO:     Epoch: 6
2022-12-31 16:09:28,893 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45615466833114626, 'Total loss': 0.45615466833114626} | train loss {'Reaction outcome loss': 0.45283710874997785, 'Total loss': 0.45283710874997785}
2022-12-31 16:09:28,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:28,894 INFO:     Epoch: 7
2022-12-31 16:09:30,500 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42719888091087344, 'Total loss': 0.42719888091087344} | train loss {'Reaction outcome loss': 0.4475415636696955, 'Total loss': 0.4475415636696955}
2022-12-31 16:09:30,500 INFO:     Found new best model at epoch 7
2022-12-31 16:09:30,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:30,501 INFO:     Epoch: 8
2022-12-31 16:09:32,117 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41457166175047555, 'Total loss': 0.41457166175047555} | train loss {'Reaction outcome loss': 0.4410243351964185, 'Total loss': 0.4410243351964185}
2022-12-31 16:09:32,117 INFO:     Found new best model at epoch 8
2022-12-31 16:09:32,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:32,118 INFO:     Epoch: 9
2022-12-31 16:09:33,742 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4315854787826538, 'Total loss': 0.4315854787826538} | train loss {'Reaction outcome loss': 0.4328996718582446, 'Total loss': 0.4328996718582446}
2022-12-31 16:09:33,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:33,742 INFO:     Epoch: 10
2022-12-31 16:09:35,338 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44610695640246073, 'Total loss': 0.44610695640246073} | train loss {'Reaction outcome loss': 0.43073542655384456, 'Total loss': 0.43073542655384456}
2022-12-31 16:09:35,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:35,339 INFO:     Epoch: 11
2022-12-31 16:09:36,930 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44940679768721264, 'Total loss': 0.44940679768721264} | train loss {'Reaction outcome loss': 0.4186365084763426, 'Total loss': 0.4186365084763426}
2022-12-31 16:09:36,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:36,930 INFO:     Epoch: 12
2022-12-31 16:09:38,548 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41258482734362284, 'Total loss': 0.41258482734362284} | train loss {'Reaction outcome loss': 0.4158678934467535, 'Total loss': 0.4158678934467535}
2022-12-31 16:09:38,548 INFO:     Found new best model at epoch 12
2022-12-31 16:09:38,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:38,549 INFO:     Epoch: 13
2022-12-31 16:09:40,183 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4444381346305211, 'Total loss': 0.4444381346305211} | train loss {'Reaction outcome loss': 0.40668943513483896, 'Total loss': 0.40668943513483896}
2022-12-31 16:09:40,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:40,184 INFO:     Epoch: 14
2022-12-31 16:09:41,819 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4416046172380447, 'Total loss': 0.4416046172380447} | train loss {'Reaction outcome loss': 0.405250700013916, 'Total loss': 0.405250700013916}
2022-12-31 16:09:41,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:41,820 INFO:     Epoch: 15
2022-12-31 16:09:43,422 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.434662276506424, 'Total loss': 0.434662276506424} | train loss {'Reaction outcome loss': 0.3926009694862105, 'Total loss': 0.3926009694862105}
2022-12-31 16:09:43,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:43,423 INFO:     Epoch: 16
2022-12-31 16:09:45,026 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41287795702616376, 'Total loss': 0.41287795702616376} | train loss {'Reaction outcome loss': 0.3912326943428412, 'Total loss': 0.3912326943428412}
2022-12-31 16:09:45,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:45,027 INFO:     Epoch: 17
2022-12-31 16:09:46,626 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4416822175184886, 'Total loss': 0.4416822175184886} | train loss {'Reaction outcome loss': 0.38796181435676386, 'Total loss': 0.38796181435676386}
2022-12-31 16:09:46,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:46,627 INFO:     Epoch: 18
2022-12-31 16:09:48,243 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4213897407054901, 'Total loss': 0.4213897407054901} | train loss {'Reaction outcome loss': 0.384857214715359, 'Total loss': 0.384857214715359}
2022-12-31 16:09:48,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:48,244 INFO:     Epoch: 19
2022-12-31 16:09:49,838 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3941975037256877, 'Total loss': 0.3941975037256877} | train loss {'Reaction outcome loss': 0.37584615025642143, 'Total loss': 0.37584615025642143}
2022-12-31 16:09:49,838 INFO:     Found new best model at epoch 19
2022-12-31 16:09:49,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:49,839 INFO:     Epoch: 20
2022-12-31 16:09:51,472 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44932807286580406, 'Total loss': 0.44932807286580406} | train loss {'Reaction outcome loss': 0.3631866135410149, 'Total loss': 0.3631866135410149}
2022-12-31 16:09:51,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:51,472 INFO:     Epoch: 21
2022-12-31 16:09:53,049 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4454733282327652, 'Total loss': 0.4454733282327652} | train loss {'Reaction outcome loss': 0.3629102421938068, 'Total loss': 0.3629102421938068}
2022-12-31 16:09:53,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:53,050 INFO:     Epoch: 22
2022-12-31 16:09:54,666 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42894579470157623, 'Total loss': 0.42894579470157623} | train loss {'Reaction outcome loss': 0.3631223854846763, 'Total loss': 0.3631223854846763}
2022-12-31 16:09:54,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:54,666 INFO:     Epoch: 23
2022-12-31 16:09:56,281 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4422951857248942, 'Total loss': 0.4422951857248942} | train loss {'Reaction outcome loss': 0.3583865563527946, 'Total loss': 0.3583865563527946}
2022-12-31 16:09:56,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:56,281 INFO:     Epoch: 24
2022-12-31 16:09:57,877 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.37358301182587944, 'Total loss': 0.37358301182587944} | train loss {'Reaction outcome loss': 0.35047566640551076, 'Total loss': 0.35047566640551076}
2022-12-31 16:09:57,877 INFO:     Found new best model at epoch 24
2022-12-31 16:09:57,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:57,878 INFO:     Epoch: 25
2022-12-31 16:09:59,473 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41904649237791697, 'Total loss': 0.41904649237791697} | train loss {'Reaction outcome loss': 0.3411482846921813, 'Total loss': 0.3411482846921813}
2022-12-31 16:09:59,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:09:59,474 INFO:     Epoch: 26
2022-12-31 16:10:01,069 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44177848398685454, 'Total loss': 0.44177848398685454} | train loss {'Reaction outcome loss': 0.3407565639184339, 'Total loss': 0.3407565639184339}
2022-12-31 16:10:01,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:01,069 INFO:     Epoch: 27
2022-12-31 16:10:02,698 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39654192129770915, 'Total loss': 0.39654192129770915} | train loss {'Reaction outcome loss': 0.33683452578465434, 'Total loss': 0.33683452578465434}
2022-12-31 16:10:02,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:02,699 INFO:     Epoch: 28
2022-12-31 16:10:04,298 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3935014004508654, 'Total loss': 0.3935014004508654} | train loss {'Reaction outcome loss': 0.3270264900676961, 'Total loss': 0.3270264900676961}
2022-12-31 16:10:04,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:04,298 INFO:     Epoch: 29
2022-12-31 16:10:05,896 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39904818336168923, 'Total loss': 0.39904818336168923} | train loss {'Reaction outcome loss': 0.3223437456699618, 'Total loss': 0.3223437456699618}
2022-12-31 16:10:05,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:05,897 INFO:     Epoch: 30
2022-12-31 16:10:07,493 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38970973938703535, 'Total loss': 0.38970973938703535} | train loss {'Reaction outcome loss': 0.3198429221817612, 'Total loss': 0.3198429221817612}
2022-12-31 16:10:07,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:07,493 INFO:     Epoch: 31
2022-12-31 16:10:09,086 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3901732842127482, 'Total loss': 0.3901732842127482} | train loss {'Reaction outcome loss': 0.31836566774949543, 'Total loss': 0.31836566774949543}
2022-12-31 16:10:09,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:09,086 INFO:     Epoch: 32
2022-12-31 16:10:10,680 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3767547974983851, 'Total loss': 0.3767547974983851} | train loss {'Reaction outcome loss': 0.3177846874361926, 'Total loss': 0.3177846874361926}
2022-12-31 16:10:10,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:10,681 INFO:     Epoch: 33
2022-12-31 16:10:12,291 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4051763415336609, 'Total loss': 0.4051763415336609} | train loss {'Reaction outcome loss': 0.30462653187178346, 'Total loss': 0.30462653187178346}
2022-12-31 16:10:12,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:12,291 INFO:     Epoch: 34
2022-12-31 16:10:13,901 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.36357875963052116, 'Total loss': 0.36357875963052116} | train loss {'Reaction outcome loss': 0.29939903892631076, 'Total loss': 0.29939903892631076}
2022-12-31 16:10:13,901 INFO:     Found new best model at epoch 34
2022-12-31 16:10:13,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:13,902 INFO:     Epoch: 35
2022-12-31 16:10:15,533 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38285356561342876, 'Total loss': 0.38285356561342876} | train loss {'Reaction outcome loss': 0.3053891793926702, 'Total loss': 0.3053891793926702}
2022-12-31 16:10:15,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:15,533 INFO:     Epoch: 36
2022-12-31 16:10:17,169 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.34351940751075744, 'Total loss': 0.34351940751075744} | train loss {'Reaction outcome loss': 0.2985079166119116, 'Total loss': 0.2985079166119116}
2022-12-31 16:10:17,169 INFO:     Found new best model at epoch 36
2022-12-31 16:10:17,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:17,170 INFO:     Epoch: 37
2022-12-31 16:10:18,790 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3755957454442978, 'Total loss': 0.3755957454442978} | train loss {'Reaction outcome loss': 0.2932561636922786, 'Total loss': 0.2932561636922786}
2022-12-31 16:10:18,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:18,791 INFO:     Epoch: 38
2022-12-31 16:10:20,395 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.37780915896097816, 'Total loss': 0.37780915896097816} | train loss {'Reaction outcome loss': 0.29485589883079494, 'Total loss': 0.29485589883079494}
2022-12-31 16:10:20,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:20,396 INFO:     Epoch: 39
2022-12-31 16:10:22,005 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3847434639930725, 'Total loss': 0.3847434639930725} | train loss {'Reaction outcome loss': 0.28166245583472027, 'Total loss': 0.28166245583472027}
2022-12-31 16:10:22,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:22,005 INFO:     Epoch: 40
2022-12-31 16:10:23,636 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.36562854051589966, 'Total loss': 0.36562854051589966} | train loss {'Reaction outcome loss': 0.28044140926242744, 'Total loss': 0.28044140926242744}
2022-12-31 16:10:23,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:23,637 INFO:     Epoch: 41
2022-12-31 16:10:25,236 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39034889340400697, 'Total loss': 0.39034889340400697} | train loss {'Reaction outcome loss': 0.27906792519790846, 'Total loss': 0.27906792519790846}
2022-12-31 16:10:25,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:25,236 INFO:     Epoch: 42
2022-12-31 16:10:26,867 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4058793067932129, 'Total loss': 0.4058793067932129} | train loss {'Reaction outcome loss': 0.27702376470785506, 'Total loss': 0.27702376470785506}
2022-12-31 16:10:26,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:26,867 INFO:     Epoch: 43
2022-12-31 16:10:28,475 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.34642436703046164, 'Total loss': 0.34642436703046164} | train loss {'Reaction outcome loss': 0.26900182336052186, 'Total loss': 0.26900182336052186}
2022-12-31 16:10:28,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:28,475 INFO:     Epoch: 44
2022-12-31 16:10:30,108 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38182102541128793, 'Total loss': 0.38182102541128793} | train loss {'Reaction outcome loss': 0.26803526203453976, 'Total loss': 0.26803526203453976}
2022-12-31 16:10:30,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:30,109 INFO:     Epoch: 45
2022-12-31 16:10:31,714 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.362059053281943, 'Total loss': 0.362059053281943} | train loss {'Reaction outcome loss': 0.26814202750849464, 'Total loss': 0.26814202750849464}
2022-12-31 16:10:31,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:31,715 INFO:     Epoch: 46
2022-12-31 16:10:33,344 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3750726024309794, 'Total loss': 0.3750726024309794} | train loss {'Reaction outcome loss': 0.2580304531666049, 'Total loss': 0.2580304531666049}
2022-12-31 16:10:33,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:33,344 INFO:     Epoch: 47
2022-12-31 16:10:34,947 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.36052980124950407, 'Total loss': 0.36052980124950407} | train loss {'Reaction outcome loss': 0.2652179018805062, 'Total loss': 0.2652179018805062}
2022-12-31 16:10:34,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:34,947 INFO:     Epoch: 48
2022-12-31 16:10:36,544 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39952803154786426, 'Total loss': 0.39952803154786426} | train loss {'Reaction outcome loss': 0.2608432052453069, 'Total loss': 0.2608432052453069}
2022-12-31 16:10:36,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:36,545 INFO:     Epoch: 49
2022-12-31 16:10:38,133 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.35298092166582745, 'Total loss': 0.35298092166582745} | train loss {'Reaction outcome loss': 0.25341794483472396, 'Total loss': 0.25341794483472396}
2022-12-31 16:10:38,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:38,133 INFO:     Epoch: 50
2022-12-31 16:10:39,732 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3677643398443858, 'Total loss': 0.3677643398443858} | train loss {'Reaction outcome loss': 0.25786306772952095, 'Total loss': 0.25786306772952095}
2022-12-31 16:10:39,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:39,732 INFO:     Epoch: 51
2022-12-31 16:10:41,341 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3573085869352023, 'Total loss': 0.3573085869352023} | train loss {'Reaction outcome loss': 0.2530250286982551, 'Total loss': 0.2530250286982551}
2022-12-31 16:10:41,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:41,341 INFO:     Epoch: 52
2022-12-31 16:10:42,974 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3532492319742839, 'Total loss': 0.3532492319742839} | train loss {'Reaction outcome loss': 0.25297298571978605, 'Total loss': 0.25297298571978605}
2022-12-31 16:10:42,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:42,974 INFO:     Epoch: 53
2022-12-31 16:10:44,573 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3904174447059631, 'Total loss': 0.3904174447059631} | train loss {'Reaction outcome loss': 0.24459163315702964, 'Total loss': 0.24459163315702964}
2022-12-31 16:10:44,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:44,573 INFO:     Epoch: 54
2022-12-31 16:10:46,162 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40366758008797965, 'Total loss': 0.40366758008797965} | train loss {'Reaction outcome loss': 0.24369131834892027, 'Total loss': 0.24369131834892027}
2022-12-31 16:10:46,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:46,162 INFO:     Epoch: 55
2022-12-31 16:10:47,761 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.36223881840705874, 'Total loss': 0.36223881840705874} | train loss {'Reaction outcome loss': 0.23803230471582743, 'Total loss': 0.23803230471582743}
2022-12-31 16:10:47,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:47,761 INFO:     Epoch: 56
2022-12-31 16:10:49,370 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3556895837187767, 'Total loss': 0.3556895837187767} | train loss {'Reaction outcome loss': 0.2458620888663687, 'Total loss': 0.2458620888663687}
2022-12-31 16:10:49,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:49,370 INFO:     Epoch: 57
2022-12-31 16:10:51,001 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3884642615914345, 'Total loss': 0.3884642615914345} | train loss {'Reaction outcome loss': 0.24089093097098116, 'Total loss': 0.24089093097098116}
2022-12-31 16:10:51,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:51,001 INFO:     Epoch: 58
2022-12-31 16:10:52,605 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.352553191781044, 'Total loss': 0.352553191781044} | train loss {'Reaction outcome loss': 0.23543744492786425, 'Total loss': 0.23543744492786425}
2022-12-31 16:10:52,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:52,606 INFO:     Epoch: 59
2022-12-31 16:10:54,202 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3946434189875921, 'Total loss': 0.3946434189875921} | train loss {'Reaction outcome loss': 0.23349048997391098, 'Total loss': 0.23349048997391098}
2022-12-31 16:10:54,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:54,202 INFO:     Epoch: 60
2022-12-31 16:10:55,783 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37850258598725, 'Total loss': 0.37850258598725} | train loss {'Reaction outcome loss': 0.23505931353726744, 'Total loss': 0.23505931353726744}
2022-12-31 16:10:55,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:55,783 INFO:     Epoch: 61
2022-12-31 16:10:57,414 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3412881173193455, 'Total loss': 0.3412881173193455} | train loss {'Reaction outcome loss': 0.2311975977716655, 'Total loss': 0.2311975977716655}
2022-12-31 16:10:57,414 INFO:     Found new best model at epoch 61
2022-12-31 16:10:57,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:57,415 INFO:     Epoch: 62
2022-12-31 16:10:58,992 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3463249775270621, 'Total loss': 0.3463249775270621} | train loss {'Reaction outcome loss': 0.22705101563737992, 'Total loss': 0.22705101563737992}
2022-12-31 16:10:58,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:10:58,992 INFO:     Epoch: 63
2022-12-31 16:11:00,585 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39714012841383617, 'Total loss': 0.39714012841383617} | train loss {'Reaction outcome loss': 0.22726363676470995, 'Total loss': 0.22726363676470995}
2022-12-31 16:11:00,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:00,586 INFO:     Epoch: 64
2022-12-31 16:11:02,180 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.35327272017796835, 'Total loss': 0.35327272017796835} | train loss {'Reaction outcome loss': 0.2247380170984751, 'Total loss': 0.2247380170984751}
2022-12-31 16:11:02,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:02,180 INFO:     Epoch: 65
2022-12-31 16:11:03,775 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.35643338561058047, 'Total loss': 0.35643338561058047} | train loss {'Reaction outcome loss': 0.22564571059179783, 'Total loss': 0.22564571059179783}
2022-12-31 16:11:03,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:03,776 INFO:     Epoch: 66
2022-12-31 16:11:05,362 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3465286244948705, 'Total loss': 0.3465286244948705} | train loss {'Reaction outcome loss': 0.2166401938582859, 'Total loss': 0.2166401938582859}
2022-12-31 16:11:05,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:05,362 INFO:     Epoch: 67
2022-12-31 16:11:06,990 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3444197684526443, 'Total loss': 0.3444197684526443} | train loss {'Reaction outcome loss': 0.22141116074401967, 'Total loss': 0.22141116074401967}
2022-12-31 16:11:06,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:06,991 INFO:     Epoch: 68
2022-12-31 16:11:08,607 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3700204183657964, 'Total loss': 0.3700204183657964} | train loss {'Reaction outcome loss': 0.22428295725997346, 'Total loss': 0.22428295725997346}
2022-12-31 16:11:08,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:08,607 INFO:     Epoch: 69
2022-12-31 16:11:10,238 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3611637353897095, 'Total loss': 0.3611637353897095} | train loss {'Reaction outcome loss': 0.21870435144154043, 'Total loss': 0.21870435144154043}
2022-12-31 16:11:10,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:10,238 INFO:     Epoch: 70
2022-12-31 16:11:11,871 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38674144123991333, 'Total loss': 0.38674144123991333} | train loss {'Reaction outcome loss': 0.220813589755201, 'Total loss': 0.220813589755201}
2022-12-31 16:11:11,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:11,871 INFO:     Epoch: 71
2022-12-31 16:11:13,494 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.34761007130146027, 'Total loss': 0.34761007130146027} | train loss {'Reaction outcome loss': 0.2170659336023522, 'Total loss': 0.2170659336023522}
2022-12-31 16:11:13,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:13,495 INFO:     Epoch: 72
2022-12-31 16:11:15,117 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3161977032820384, 'Total loss': 0.3161977032820384} | train loss {'Reaction outcome loss': 0.21428663453195979, 'Total loss': 0.21428663453195979}
2022-12-31 16:11:15,118 INFO:     Found new best model at epoch 72
2022-12-31 16:11:15,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:15,119 INFO:     Epoch: 73
2022-12-31 16:11:16,689 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4014507551987966, 'Total loss': 0.4014507551987966} | train loss {'Reaction outcome loss': 0.21722692160792376, 'Total loss': 0.21722692160792376}
2022-12-31 16:11:16,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:16,690 INFO:     Epoch: 74
2022-12-31 16:11:18,288 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39373385111490883, 'Total loss': 0.39373385111490883} | train loss {'Reaction outcome loss': 0.21682586938305928, 'Total loss': 0.21682586938305928}
2022-12-31 16:11:18,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:18,288 INFO:     Epoch: 75
2022-12-31 16:11:19,881 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.36028590202331545, 'Total loss': 0.36028590202331545} | train loss {'Reaction outcome loss': 0.20932519097343413, 'Total loss': 0.20932519097343413}
2022-12-31 16:11:19,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:19,882 INFO:     Epoch: 76
2022-12-31 16:11:21,458 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3305925905704498, 'Total loss': 0.3305925905704498} | train loss {'Reaction outcome loss': 0.2039094016798874, 'Total loss': 0.2039094016798874}
2022-12-31 16:11:21,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:21,458 INFO:     Epoch: 77
2022-12-31 16:11:23,061 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37593869666258495, 'Total loss': 0.37593869666258495} | train loss {'Reaction outcome loss': 0.20136336258945675, 'Total loss': 0.20136336258945675}
2022-12-31 16:11:23,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:23,062 INFO:     Epoch: 78
2022-12-31 16:11:24,682 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3533428728580475, 'Total loss': 0.3533428728580475} | train loss {'Reaction outcome loss': 0.210358570594966, 'Total loss': 0.210358570594966}
2022-12-31 16:11:24,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:24,682 INFO:     Epoch: 79
2022-12-31 16:11:26,291 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3416455626487732, 'Total loss': 0.3416455626487732} | train loss {'Reaction outcome loss': 0.20632807541992107, 'Total loss': 0.20632807541992107}
2022-12-31 16:11:26,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:26,291 INFO:     Epoch: 80
2022-12-31 16:11:27,908 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.36899336824814477, 'Total loss': 0.36899336824814477} | train loss {'Reaction outcome loss': 0.2030008873990635, 'Total loss': 0.2030008873990635}
2022-12-31 16:11:27,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:27,912 INFO:     Epoch: 81
2022-12-31 16:11:29,505 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.36562141478061677, 'Total loss': 0.36562141478061677} | train loss {'Reaction outcome loss': 0.2076478987442751, 'Total loss': 0.2076478987442751}
2022-12-31 16:11:29,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:29,505 INFO:     Epoch: 82
2022-12-31 16:11:31,108 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36945001482963563, 'Total loss': 0.36945001482963563} | train loss {'Reaction outcome loss': 0.20012821832902894, 'Total loss': 0.20012821832902894}
2022-12-31 16:11:31,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:31,109 INFO:     Epoch: 83
2022-12-31 16:11:32,720 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.344805032449464, 'Total loss': 0.344805032449464} | train loss {'Reaction outcome loss': 0.20095739886844463, 'Total loss': 0.20095739886844463}
2022-12-31 16:11:32,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:32,720 INFO:     Epoch: 84
2022-12-31 16:11:34,333 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3509072959423065, 'Total loss': 0.3509072959423065} | train loss {'Reaction outcome loss': 0.2034318647789259, 'Total loss': 0.2034318647789259}
2022-12-31 16:11:34,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:34,333 INFO:     Epoch: 85
2022-12-31 16:11:35,928 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.33856041928132374, 'Total loss': 0.33856041928132374} | train loss {'Reaction outcome loss': 0.19896472772977647, 'Total loss': 0.19896472772977647}
2022-12-31 16:11:35,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:35,928 INFO:     Epoch: 86
2022-12-31 16:11:37,535 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.390637061993281, 'Total loss': 0.390637061993281} | train loss {'Reaction outcome loss': 0.19934629179183802, 'Total loss': 0.19934629179183802}
2022-12-31 16:11:37,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:37,536 INFO:     Epoch: 87
2022-12-31 16:11:39,157 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.35269062022368114, 'Total loss': 0.35269062022368114} | train loss {'Reaction outcome loss': 0.19658774407376556, 'Total loss': 0.19658774407376556}
2022-12-31 16:11:39,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:39,158 INFO:     Epoch: 88
2022-12-31 16:11:40,743 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3860739012559255, 'Total loss': 0.3860739012559255} | train loss {'Reaction outcome loss': 0.18701788807546135, 'Total loss': 0.18701788807546135}
2022-12-31 16:11:40,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:40,743 INFO:     Epoch: 89
2022-12-31 16:11:42,365 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3786167790492376, 'Total loss': 0.3786167790492376} | train loss {'Reaction outcome loss': 0.1971935445075705, 'Total loss': 0.1971935445075705}
2022-12-31 16:11:42,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:42,365 INFO:     Epoch: 90
2022-12-31 16:11:43,980 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.37024208456277846, 'Total loss': 0.37024208456277846} | train loss {'Reaction outcome loss': 0.1940079542747053, 'Total loss': 0.1940079542747053}
2022-12-31 16:11:43,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:43,981 INFO:     Epoch: 91
2022-12-31 16:11:45,598 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3909012089172999, 'Total loss': 0.3909012089172999} | train loss {'Reaction outcome loss': 0.1939014157783376, 'Total loss': 0.1939014157783376}
2022-12-31 16:11:45,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:45,598 INFO:     Epoch: 92
2022-12-31 16:11:47,224 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37627431750297546, 'Total loss': 0.37627431750297546} | train loss {'Reaction outcome loss': 0.19507753878260833, 'Total loss': 0.19507753878260833}
2022-12-31 16:11:47,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:47,224 INFO:     Epoch: 93
2022-12-31 16:11:48,853 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3630485365788142, 'Total loss': 0.3630485365788142} | train loss {'Reaction outcome loss': 0.2041867662911188, 'Total loss': 0.2041867662911188}
2022-12-31 16:11:48,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:48,853 INFO:     Epoch: 94
2022-12-31 16:11:50,452 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4058128036558628, 'Total loss': 0.4058128036558628} | train loss {'Reaction outcome loss': 0.18352519445474783, 'Total loss': 0.18352519445474783}
2022-12-31 16:11:50,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:50,453 INFO:     Epoch: 95
2022-12-31 16:11:52,059 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3647926946481069, 'Total loss': 0.3647926946481069} | train loss {'Reaction outcome loss': 0.19106215696414783, 'Total loss': 0.19106215696414783}
2022-12-31 16:11:52,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:52,059 INFO:     Epoch: 96
2022-12-31 16:11:53,655 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3753318359454473, 'Total loss': 0.3753318359454473} | train loss {'Reaction outcome loss': 0.1941222334042681, 'Total loss': 0.1941222334042681}
2022-12-31 16:11:53,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:53,655 INFO:     Epoch: 97
2022-12-31 16:11:55,256 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.35536168366670606, 'Total loss': 0.35536168366670606} | train loss {'Reaction outcome loss': 0.19091255971006232, 'Total loss': 0.19091255971006232}
2022-12-31 16:11:55,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:55,256 INFO:     Epoch: 98
2022-12-31 16:11:56,868 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3748761206865311, 'Total loss': 0.3748761206865311} | train loss {'Reaction outcome loss': 0.19146977784451993, 'Total loss': 0.19146977784451993}
2022-12-31 16:11:56,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:56,868 INFO:     Epoch: 99
2022-12-31 16:11:58,477 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3614391495784124, 'Total loss': 0.3614391495784124} | train loss {'Reaction outcome loss': 0.18701797163617, 'Total loss': 0.18701797163617}
2022-12-31 16:11:58,477 INFO:     Best model found after epoch 73 of 100.
2022-12-31 16:11:58,477 INFO:   Done with stage: TRAINING
2022-12-31 16:11:58,477 INFO:   Starting stage: EVALUATION
2022-12-31 16:11:58,611 INFO:   Done with stage: EVALUATION
2022-12-31 16:11:58,611 INFO:   Leaving out SEQ value Fold_9
2022-12-31 16:11:58,624 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 16:11:58,632 INFO:   Starting stage: FEATURE SCALING
2022-12-31 16:11:59,280 INFO:   Done with stage: FEATURE SCALING
2022-12-31 16:11:59,280 INFO:   Starting stage: SCALING TARGETS
2022-12-31 16:11:59,349 INFO:   Done with stage: SCALING TARGETS
2022-12-31 16:11:59,349 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 16:11:59,349 INFO:     No hyperparam tuning for this model
2022-12-31 16:11:59,349 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 16:11:59,349 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 16:11:59,350 INFO:     None feature selector for col prot
2022-12-31 16:11:59,350 INFO:     None feature selector for col prot
2022-12-31 16:11:59,350 INFO:     None feature selector for col prot
2022-12-31 16:11:59,351 INFO:     None feature selector for col chem
2022-12-31 16:11:59,351 INFO:     None feature selector for col chem
2022-12-31 16:11:59,351 INFO:     None feature selector for col chem
2022-12-31 16:11:59,351 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 16:11:59,351 INFO:   Starting stage: BUILD MODEL
2022-12-31 16:11:59,353 INFO:     Number of params in model 223921
2022-12-31 16:11:59,356 INFO:   Done with stage: BUILD MODEL
2022-12-31 16:11:59,356 INFO:   Starting stage: TRAINING
2022-12-31 16:11:59,401 INFO:     Val loss before train {'Reaction outcome loss': 0.876593820254008, 'Total loss': 0.876593820254008}
2022-12-31 16:11:59,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:11:59,401 INFO:     Epoch: 0
2022-12-31 16:12:01,056 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6179227272669474, 'Total loss': 0.6179227272669474} | train loss {'Reaction outcome loss': 0.8320345213697276, 'Total loss': 0.8320345213697276}
2022-12-31 16:12:01,056 INFO:     Found new best model at epoch 0
2022-12-31 16:12:01,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:01,057 INFO:     Epoch: 1
2022-12-31 16:12:02,661 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4967813789844513, 'Total loss': 0.4967813789844513} | train loss {'Reaction outcome loss': 0.603018349258478, 'Total loss': 0.603018349258478}
2022-12-31 16:12:02,662 INFO:     Found new best model at epoch 1
2022-12-31 16:12:02,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:02,663 INFO:     Epoch: 2
2022-12-31 16:12:04,286 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47577056487401326, 'Total loss': 0.47577056487401326} | train loss {'Reaction outcome loss': 0.5346770069766992, 'Total loss': 0.5346770069766992}
2022-12-31 16:12:04,286 INFO:     Found new best model at epoch 2
2022-12-31 16:12:04,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:04,287 INFO:     Epoch: 3
2022-12-31 16:12:05,900 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48088006575902303, 'Total loss': 0.48088006575902303} | train loss {'Reaction outcome loss': 0.5074110878396121, 'Total loss': 0.5074110878396121}
2022-12-31 16:12:05,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:05,901 INFO:     Epoch: 4
2022-12-31 16:12:07,518 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46676353414853416, 'Total loss': 0.46676353414853416} | train loss {'Reaction outcome loss': 0.49436247596241506, 'Total loss': 0.49436247596241506}
2022-12-31 16:12:07,518 INFO:     Found new best model at epoch 4
2022-12-31 16:12:07,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:07,519 INFO:     Epoch: 5
2022-12-31 16:12:09,123 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4717627078294754, 'Total loss': 0.4717627078294754} | train loss {'Reaction outcome loss': 0.48091754166658174, 'Total loss': 0.48091754166658174}
2022-12-31 16:12:09,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:09,124 INFO:     Epoch: 6
2022-12-31 16:12:10,744 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45669474204381305, 'Total loss': 0.45669474204381305} | train loss {'Reaction outcome loss': 0.47756090553121017, 'Total loss': 0.47756090553121017}
2022-12-31 16:12:10,744 INFO:     Found new best model at epoch 6
2022-12-31 16:12:10,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:10,745 INFO:     Epoch: 7
2022-12-31 16:12:12,393 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4519601653019587, 'Total loss': 0.4519601653019587} | train loss {'Reaction outcome loss': 0.46821837718951576, 'Total loss': 0.46821837718951576}
2022-12-31 16:12:12,393 INFO:     Found new best model at epoch 7
2022-12-31 16:12:12,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:12,394 INFO:     Epoch: 8
2022-12-31 16:12:14,030 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4541878432035446, 'Total loss': 0.4541878432035446} | train loss {'Reaction outcome loss': 0.4581606031432479, 'Total loss': 0.4581606031432479}
2022-12-31 16:12:14,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:14,031 INFO:     Epoch: 9
2022-12-31 16:12:15,667 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4151867429415385, 'Total loss': 0.4151867429415385} | train loss {'Reaction outcome loss': 0.4562168927722029, 'Total loss': 0.4562168927722029}
2022-12-31 16:12:15,667 INFO:     Found new best model at epoch 9
2022-12-31 16:12:15,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:15,668 INFO:     Epoch: 10
2022-12-31 16:12:17,287 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4287267108758291, 'Total loss': 0.4287267108758291} | train loss {'Reaction outcome loss': 0.4445553957232499, 'Total loss': 0.4445553957232499}
2022-12-31 16:12:17,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:17,288 INFO:     Epoch: 11
2022-12-31 16:12:18,903 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4459975004196167, 'Total loss': 0.4459975004196167} | train loss {'Reaction outcome loss': 0.4382638386333032, 'Total loss': 0.4382638386333032}
2022-12-31 16:12:18,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:18,903 INFO:     Epoch: 12
2022-12-31 16:12:20,519 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44892401893933614, 'Total loss': 0.44892401893933614} | train loss {'Reaction outcome loss': 0.4366971152138624, 'Total loss': 0.4366971152138624}
2022-12-31 16:12:20,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:20,520 INFO:     Epoch: 13
2022-12-31 16:12:22,170 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43484556674957275, 'Total loss': 0.43484556674957275} | train loss {'Reaction outcome loss': 0.4241201343411573, 'Total loss': 0.4241201343411573}
2022-12-31 16:12:22,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:22,171 INFO:     Epoch: 14
2022-12-31 16:12:23,796 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43622472484906516, 'Total loss': 0.43622472484906516} | train loss {'Reaction outcome loss': 0.4179829750411777, 'Total loss': 0.4179829750411777}
2022-12-31 16:12:23,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:23,796 INFO:     Epoch: 15
2022-12-31 16:12:25,414 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4219915747642517, 'Total loss': 0.4219915747642517} | train loss {'Reaction outcome loss': 0.4131980986209983, 'Total loss': 0.4131980986209983}
2022-12-31 16:12:25,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:25,414 INFO:     Epoch: 16
2022-12-31 16:12:27,020 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4174774597088496, 'Total loss': 0.4174774597088496} | train loss {'Reaction outcome loss': 0.408334058275722, 'Total loss': 0.408334058275722}
2022-12-31 16:12:27,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:27,021 INFO:     Epoch: 17
2022-12-31 16:12:28,617 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43448275327682495, 'Total loss': 0.43448275327682495} | train loss {'Reaction outcome loss': 0.40177542164867963, 'Total loss': 0.40177542164867963}
2022-12-31 16:12:28,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:28,617 INFO:     Epoch: 18
2022-12-31 16:12:30,234 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4258932093779246, 'Total loss': 0.4258932093779246} | train loss {'Reaction outcome loss': 0.40169937827957236, 'Total loss': 0.40169937827957236}
2022-12-31 16:12:30,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:30,234 INFO:     Epoch: 19
2022-12-31 16:12:31,856 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4336162785689036, 'Total loss': 0.4336162785689036} | train loss {'Reaction outcome loss': 0.3936734136584003, 'Total loss': 0.3936734136584003}
2022-12-31 16:12:31,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:31,856 INFO:     Epoch: 20
2022-12-31 16:12:33,474 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3985275447368622, 'Total loss': 0.3985275447368622} | train loss {'Reaction outcome loss': 0.38646186995807535, 'Total loss': 0.38646186995807535}
2022-12-31 16:12:33,475 INFO:     Found new best model at epoch 20
2022-12-31 16:12:33,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:33,476 INFO:     Epoch: 21
2022-12-31 16:12:35,073 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4352401554584503, 'Total loss': 0.4352401554584503} | train loss {'Reaction outcome loss': 0.3793615222730361, 'Total loss': 0.3793615222730361}
2022-12-31 16:12:35,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:35,073 INFO:     Epoch: 22
2022-12-31 16:12:36,697 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.406160040696462, 'Total loss': 0.406160040696462} | train loss {'Reaction outcome loss': 0.37616504319953575, 'Total loss': 0.37616504319953575}
2022-12-31 16:12:36,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:36,697 INFO:     Epoch: 23
2022-12-31 16:12:38,328 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4260496576627096, 'Total loss': 0.4260496576627096} | train loss {'Reaction outcome loss': 0.37031846001260116, 'Total loss': 0.37031846001260116}
2022-12-31 16:12:38,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:38,328 INFO:     Epoch: 24
2022-12-31 16:12:39,975 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40285766224066416, 'Total loss': 0.40285766224066416} | train loss {'Reaction outcome loss': 0.3650155979803753, 'Total loss': 0.3650155979803753}
2022-12-31 16:12:39,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:39,976 INFO:     Epoch: 25
2022-12-31 16:12:41,606 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41792288025220237, 'Total loss': 0.41792288025220237} | train loss {'Reaction outcome loss': 0.3567005010718473, 'Total loss': 0.3567005010718473}
2022-12-31 16:12:41,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:41,606 INFO:     Epoch: 26
2022-12-31 16:12:43,220 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3991524825493495, 'Total loss': 0.3991524825493495} | train loss {'Reaction outcome loss': 0.3538470047690808, 'Total loss': 0.3538470047690808}
2022-12-31 16:12:43,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:43,220 INFO:     Epoch: 27
2022-12-31 16:12:44,821 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3948120882113775, 'Total loss': 0.3948120882113775} | train loss {'Reaction outcome loss': 0.35051226215134457, 'Total loss': 0.35051226215134457}
2022-12-31 16:12:44,821 INFO:     Found new best model at epoch 27
2022-12-31 16:12:44,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:44,822 INFO:     Epoch: 28
2022-12-31 16:12:46,442 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4223409056663513, 'Total loss': 0.4223409056663513} | train loss {'Reaction outcome loss': 0.33739648209313194, 'Total loss': 0.33739648209313194}
2022-12-31 16:12:46,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:46,443 INFO:     Epoch: 29
2022-12-31 16:12:48,081 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4150867561499278, 'Total loss': 0.4150867561499278} | train loss {'Reaction outcome loss': 0.33771055568318936, 'Total loss': 0.33771055568318936}
2022-12-31 16:12:48,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:48,082 INFO:     Epoch: 30
2022-12-31 16:12:49,734 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3965656747420629, 'Total loss': 0.3965656747420629} | train loss {'Reaction outcome loss': 0.33800394192929734, 'Total loss': 0.33800394192929734}
2022-12-31 16:12:49,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:49,735 INFO:     Epoch: 31
2022-12-31 16:12:51,365 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.388063911596934, 'Total loss': 0.388063911596934} | train loss {'Reaction outcome loss': 0.3239388812723358, 'Total loss': 0.3239388812723358}
2022-12-31 16:12:51,365 INFO:     Found new best model at epoch 31
2022-12-31 16:12:51,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:51,366 INFO:     Epoch: 32
2022-12-31 16:12:52,970 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4365675131479899, 'Total loss': 0.4365675131479899} | train loss {'Reaction outcome loss': 0.32708446243071815, 'Total loss': 0.32708446243071815}
2022-12-31 16:12:52,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:52,971 INFO:     Epoch: 33
2022-12-31 16:12:54,576 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4057509665687879, 'Total loss': 0.4057509665687879} | train loss {'Reaction outcome loss': 0.3197259451615681, 'Total loss': 0.3197259451615681}
2022-12-31 16:12:54,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:54,576 INFO:     Epoch: 34
2022-12-31 16:12:56,190 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4190859436988831, 'Total loss': 0.4190859436988831} | train loss {'Reaction outcome loss': 0.31444630806842006, 'Total loss': 0.31444630806842006}
2022-12-31 16:12:56,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:56,190 INFO:     Epoch: 35
2022-12-31 16:12:57,814 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39036915500958763, 'Total loss': 0.39036915500958763} | train loss {'Reaction outcome loss': 0.3183300548942511, 'Total loss': 0.3183300548942511}
2022-12-31 16:12:57,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:57,814 INFO:     Epoch: 36
2022-12-31 16:12:59,446 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4301143765449524, 'Total loss': 0.4301143765449524} | train loss {'Reaction outcome loss': 0.3118459850899364, 'Total loss': 0.3118459850899364}
2022-12-31 16:12:59,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:12:59,446 INFO:     Epoch: 37
2022-12-31 16:13:01,094 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3841636916001638, 'Total loss': 0.3841636916001638} | train loss {'Reaction outcome loss': 0.30362276665678095, 'Total loss': 0.30362276665678095}
2022-12-31 16:13:01,094 INFO:     Found new best model at epoch 37
2022-12-31 16:13:01,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:01,095 INFO:     Epoch: 38
2022-12-31 16:13:02,512 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4125199367602666, 'Total loss': 0.4125199367602666} | train loss {'Reaction outcome loss': 0.30249086852161894, 'Total loss': 0.30249086852161894}
2022-12-31 16:13:02,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:02,513 INFO:     Epoch: 39
2022-12-31 16:13:03,584 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3808399687210719, 'Total loss': 0.3808399687210719} | train loss {'Reaction outcome loss': 0.2980874747925502, 'Total loss': 0.2980874747925502}
2022-12-31 16:13:03,585 INFO:     Found new best model at epoch 39
2022-12-31 16:13:03,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:03,586 INFO:     Epoch: 40
2022-12-31 16:13:04,663 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42724179128805795, 'Total loss': 0.42724179128805795} | train loss {'Reaction outcome loss': 0.2873361777877334, 'Total loss': 0.2873361777877334}
2022-12-31 16:13:04,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:04,664 INFO:     Epoch: 41
2022-12-31 16:13:05,730 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42208055406808853, 'Total loss': 0.42208055406808853} | train loss {'Reaction outcome loss': 0.29624860298009553, 'Total loss': 0.29624860298009553}
2022-12-31 16:13:05,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:05,730 INFO:     Epoch: 42
2022-12-31 16:13:06,868 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40123812754948934, 'Total loss': 0.40123812754948934} | train loss {'Reaction outcome loss': 0.28934440892256985, 'Total loss': 0.28934440892256985}
2022-12-31 16:13:06,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:06,868 INFO:     Epoch: 43
2022-12-31 16:13:08,502 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4183692087729772, 'Total loss': 0.4183692087729772} | train loss {'Reaction outcome loss': 0.2902788397341644, 'Total loss': 0.2902788397341644}
2022-12-31 16:13:08,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:08,504 INFO:     Epoch: 44
2022-12-31 16:13:10,119 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4497558295726776, 'Total loss': 0.4497558295726776} | train loss {'Reaction outcome loss': 0.28743202943986934, 'Total loss': 0.28743202943986934}
2022-12-31 16:13:10,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:10,120 INFO:     Epoch: 45
2022-12-31 16:13:11,714 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39680255254109703, 'Total loss': 0.39680255254109703} | train loss {'Reaction outcome loss': 0.2803001215795748, 'Total loss': 0.2803001215795748}
2022-12-31 16:13:11,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:11,714 INFO:     Epoch: 46
2022-12-31 16:13:13,327 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38330848813056945, 'Total loss': 0.38330848813056945} | train loss {'Reaction outcome loss': 0.27968132774268245, 'Total loss': 0.27968132774268245}
2022-12-31 16:13:13,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:13,327 INFO:     Epoch: 47
2022-12-31 16:13:14,970 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3835480233033498, 'Total loss': 0.3835480233033498} | train loss {'Reaction outcome loss': 0.28148212002771855, 'Total loss': 0.28148212002771855}
2022-12-31 16:13:14,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:14,971 INFO:     Epoch: 48
2022-12-31 16:13:16,578 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41525425339738525, 'Total loss': 0.41525425339738525} | train loss {'Reaction outcome loss': 0.2723249695146127, 'Total loss': 0.2723249695146127}
2022-12-31 16:13:16,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:16,579 INFO:     Epoch: 49
2022-12-31 16:13:18,169 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38649378170569737, 'Total loss': 0.38649378170569737} | train loss {'Reaction outcome loss': 0.27037014446426383, 'Total loss': 0.27037014446426383}
2022-12-31 16:13:18,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:18,170 INFO:     Epoch: 50
2022-12-31 16:13:19,807 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4009971474607786, 'Total loss': 0.4009971474607786} | train loss {'Reaction outcome loss': 0.2733955193539604, 'Total loss': 0.2733955193539604}
2022-12-31 16:13:19,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:19,807 INFO:     Epoch: 51
2022-12-31 16:13:21,410 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42519452373186745, 'Total loss': 0.42519452373186745} | train loss {'Reaction outcome loss': 0.2670469535682821, 'Total loss': 0.2670469535682821}
2022-12-31 16:13:21,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:21,410 INFO:     Epoch: 52
2022-12-31 16:13:23,022 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39605081677436826, 'Total loss': 0.39605081677436826} | train loss {'Reaction outcome loss': 0.2667317956094277, 'Total loss': 0.2667317956094277}
2022-12-31 16:13:23,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:23,022 INFO:     Epoch: 53
2022-12-31 16:13:24,637 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4079407125711441, 'Total loss': 0.4079407125711441} | train loss {'Reaction outcome loss': 0.26157686999235774, 'Total loss': 0.26157686999235774}
2022-12-31 16:13:24,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:24,637 INFO:     Epoch: 54
2022-12-31 16:13:26,240 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4139240652322769, 'Total loss': 0.4139240652322769} | train loss {'Reaction outcome loss': 0.2647824174243728, 'Total loss': 0.2647824174243728}
2022-12-31 16:13:26,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:26,240 INFO:     Epoch: 55
2022-12-31 16:13:27,855 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4000428398450216, 'Total loss': 0.4000428398450216} | train loss {'Reaction outcome loss': 0.26157042774159983, 'Total loss': 0.26157042774159983}
2022-12-31 16:13:27,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:27,855 INFO:     Epoch: 56
2022-12-31 16:13:29,449 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4151809533437093, 'Total loss': 0.4151809533437093} | train loss {'Reaction outcome loss': 0.269985489937265, 'Total loss': 0.269985489937265}
2022-12-31 16:13:29,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:29,449 INFO:     Epoch: 57
2022-12-31 16:13:31,100 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3849872320890427, 'Total loss': 0.3849872320890427} | train loss {'Reaction outcome loss': 0.25855489330709197, 'Total loss': 0.25855489330709197}
2022-12-31 16:13:31,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:31,100 INFO:     Epoch: 58
2022-12-31 16:13:32,731 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42129869361718497, 'Total loss': 0.42129869361718497} | train loss {'Reaction outcome loss': 0.2516411007768626, 'Total loss': 0.2516411007768626}
2022-12-31 16:13:32,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:32,732 INFO:     Epoch: 59
2022-12-31 16:13:34,333 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3971505175034205, 'Total loss': 0.3971505175034205} | train loss {'Reaction outcome loss': 0.2521924586354718, 'Total loss': 0.2521924586354718}
2022-12-31 16:13:34,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:34,334 INFO:     Epoch: 60
2022-12-31 16:13:35,948 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4243757208188375, 'Total loss': 0.4243757208188375} | train loss {'Reaction outcome loss': 0.24923361258897325, 'Total loss': 0.24923361258897325}
2022-12-31 16:13:35,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:35,948 INFO:     Epoch: 61
2022-12-31 16:13:37,569 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.432204503317674, 'Total loss': 0.432204503317674} | train loss {'Reaction outcome loss': 0.24688447491410406, 'Total loss': 0.24688447491410406}
2022-12-31 16:13:37,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:37,570 INFO:     Epoch: 62
2022-12-31 16:13:39,199 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43452467719713844, 'Total loss': 0.43452467719713844} | train loss {'Reaction outcome loss': 0.24976417983105467, 'Total loss': 0.24976417983105467}
2022-12-31 16:13:39,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:39,201 INFO:     Epoch: 63
2022-12-31 16:13:40,854 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37808885673681897, 'Total loss': 0.37808885673681897} | train loss {'Reaction outcome loss': 0.25236583218005376, 'Total loss': 0.25236583218005376}
2022-12-31 16:13:40,854 INFO:     Found new best model at epoch 63
2022-12-31 16:13:40,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:40,855 INFO:     Epoch: 64
2022-12-31 16:13:42,473 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4065229117870331, 'Total loss': 0.4065229117870331} | train loss {'Reaction outcome loss': 0.24962922240799085, 'Total loss': 0.24962922240799085}
2022-12-31 16:13:42,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:42,473 INFO:     Epoch: 65
2022-12-31 16:13:44,070 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38863948434591294, 'Total loss': 0.38863948434591294} | train loss {'Reaction outcome loss': 0.2378400139887195, 'Total loss': 0.2378400139887195}
2022-12-31 16:13:44,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:44,071 INFO:     Epoch: 66
2022-12-31 16:13:45,693 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3809202924370766, 'Total loss': 0.3809202924370766} | train loss {'Reaction outcome loss': 0.24115850674223813, 'Total loss': 0.24115850674223813}
2022-12-31 16:13:45,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:45,694 INFO:     Epoch: 67
2022-12-31 16:13:47,327 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42850310206413267, 'Total loss': 0.42850310206413267} | train loss {'Reaction outcome loss': 0.24427470953509695, 'Total loss': 0.24427470953509695}
2022-12-31 16:13:47,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:47,327 INFO:     Epoch: 68
2022-12-31 16:13:48,965 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41357850333054863, 'Total loss': 0.41357850333054863} | train loss {'Reaction outcome loss': 0.23514731211540715, 'Total loss': 0.23514731211540715}
2022-12-31 16:13:48,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:48,965 INFO:     Epoch: 69
2022-12-31 16:13:50,594 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4039914608001709, 'Total loss': 0.4039914608001709} | train loss {'Reaction outcome loss': 0.2353962364771306, 'Total loss': 0.2353962364771306}
2022-12-31 16:13:50,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:50,595 INFO:     Epoch: 70
2022-12-31 16:13:52,198 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43220156033833823, 'Total loss': 0.43220156033833823} | train loss {'Reaction outcome loss': 0.2368036623277604, 'Total loss': 0.2368036623277604}
2022-12-31 16:13:52,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:52,199 INFO:     Epoch: 71
2022-12-31 16:13:53,812 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40682904918988544, 'Total loss': 0.40682904918988544} | train loss {'Reaction outcome loss': 0.23733610797350696, 'Total loss': 0.23733610797350696}
2022-12-31 16:13:53,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:53,812 INFO:     Epoch: 72
2022-12-31 16:13:55,425 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39953528344631195, 'Total loss': 0.39953528344631195} | train loss {'Reaction outcome loss': 0.2347205746448212, 'Total loss': 0.2347205746448212}
2022-12-31 16:13:55,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:55,425 INFO:     Epoch: 73
2022-12-31 16:13:57,024 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41351577738920847, 'Total loss': 0.41351577738920847} | train loss {'Reaction outcome loss': 0.2323655900057903, 'Total loss': 0.2323655900057903}
2022-12-31 16:13:57,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:57,024 INFO:     Epoch: 74
2022-12-31 16:13:58,645 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4036938001712163, 'Total loss': 0.4036938001712163} | train loss {'Reaction outcome loss': 0.23020838804892685, 'Total loss': 0.23020838804892685}
2022-12-31 16:13:58,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:13:58,646 INFO:     Epoch: 75
2022-12-31 16:14:00,299 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.402801779905955, 'Total loss': 0.402801779905955} | train loss {'Reaction outcome loss': 0.22966406221370406, 'Total loss': 0.22966406221370406}
2022-12-31 16:14:00,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:00,300 INFO:     Epoch: 76
2022-12-31 16:14:01,916 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40289093752702076, 'Total loss': 0.40289093752702076} | train loss {'Reaction outcome loss': 0.23419220195511617, 'Total loss': 0.23419220195511617}
2022-12-31 16:14:01,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:01,916 INFO:     Epoch: 77
2022-12-31 16:14:03,528 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4135236978530884, 'Total loss': 0.4135236978530884} | train loss {'Reaction outcome loss': 0.2290895450322314, 'Total loss': 0.2290895450322314}
2022-12-31 16:14:03,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:03,529 INFO:     Epoch: 78
2022-12-31 16:14:05,140 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4100313266118368, 'Total loss': 0.4100313266118368} | train loss {'Reaction outcome loss': 0.2225138256729779, 'Total loss': 0.2225138256729779}
2022-12-31 16:14:05,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:05,140 INFO:     Epoch: 79
2022-12-31 16:14:06,739 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4629409611225128, 'Total loss': 0.4629409611225128} | train loss {'Reaction outcome loss': 0.22452486440915922, 'Total loss': 0.22452486440915922}
2022-12-31 16:14:06,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:06,740 INFO:     Epoch: 80
2022-12-31 16:14:08,356 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44743249913056693, 'Total loss': 0.44743249913056693} | train loss {'Reaction outcome loss': 0.22747696837955003, 'Total loss': 0.22747696837955003}
2022-12-31 16:14:08,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:08,356 INFO:     Epoch: 81
2022-12-31 16:14:09,998 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43481696049372354, 'Total loss': 0.43481696049372354} | train loss {'Reaction outcome loss': 0.22821591721867826, 'Total loss': 0.22821591721867826}
2022-12-31 16:14:09,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:09,999 INFO:     Epoch: 82
2022-12-31 16:14:11,637 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3997484465440114, 'Total loss': 0.3997484465440114} | train loss {'Reaction outcome loss': 0.2240915260671063, 'Total loss': 0.2240915260671063}
2022-12-31 16:14:11,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:11,638 INFO:     Epoch: 83
2022-12-31 16:14:13,284 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43112160116434095, 'Total loss': 0.43112160116434095} | train loss {'Reaction outcome loss': 0.22781722985934263, 'Total loss': 0.22781722985934263}
2022-12-31 16:14:13,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:13,284 INFO:     Epoch: 84
2022-12-31 16:14:14,894 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41707289814949033, 'Total loss': 0.41707289814949033} | train loss {'Reaction outcome loss': 0.22204593749925333, 'Total loss': 0.22204593749925333}
2022-12-31 16:14:14,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:14,895 INFO:     Epoch: 85
2022-12-31 16:14:16,506 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4139741614460945, 'Total loss': 0.4139741614460945} | train loss {'Reaction outcome loss': 0.2162442714083496, 'Total loss': 0.2162442714083496}
2022-12-31 16:14:16,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:16,507 INFO:     Epoch: 86
2022-12-31 16:14:18,119 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4183039610584577, 'Total loss': 0.4183039610584577} | train loss {'Reaction outcome loss': 0.2116402488954984, 'Total loss': 0.2116402488954984}
2022-12-31 16:14:18,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:18,119 INFO:     Epoch: 87
2022-12-31 16:14:19,744 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41759688754876456, 'Total loss': 0.41759688754876456} | train loss {'Reaction outcome loss': 0.2215187920640737, 'Total loss': 0.2215187920640737}
2022-12-31 16:14:19,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:19,744 INFO:     Epoch: 88
2022-12-31 16:14:21,389 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4164632851878802, 'Total loss': 0.4164632851878802} | train loss {'Reaction outcome loss': 0.21642146320065436, 'Total loss': 0.21642146320065436}
2022-12-31 16:14:21,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:21,389 INFO:     Epoch: 89
2022-12-31 16:14:23,029 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40014021992683413, 'Total loss': 0.40014021992683413} | train loss {'Reaction outcome loss': 0.22141243837477928, 'Total loss': 0.22141243837477928}
2022-12-31 16:14:23,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:23,029 INFO:     Epoch: 90
2022-12-31 16:14:24,638 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4004518955945969, 'Total loss': 0.4004518955945969} | train loss {'Reaction outcome loss': 0.21599184785589629, 'Total loss': 0.21599184785589629}
2022-12-31 16:14:24,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:24,638 INFO:     Epoch: 91
2022-12-31 16:14:26,249 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4193687369426092, 'Total loss': 0.4193687369426092} | train loss {'Reaction outcome loss': 0.21278212013039133, 'Total loss': 0.21278212013039133}
2022-12-31 16:14:26,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:26,250 INFO:     Epoch: 92
2022-12-31 16:14:27,863 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4971066743135452, 'Total loss': 0.4971066743135452} | train loss {'Reaction outcome loss': 0.2128402414170198, 'Total loss': 0.2128402414170198}
2022-12-31 16:14:27,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:27,863 INFO:     Epoch: 93
2022-12-31 16:14:29,474 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42788561483224236, 'Total loss': 0.42788561483224236} | train loss {'Reaction outcome loss': 0.2117407143801881, 'Total loss': 0.2117407143801881}
2022-12-31 16:14:29,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:29,475 INFO:     Epoch: 94
2022-12-31 16:14:31,100 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4165084878603617, 'Total loss': 0.4165084878603617} | train loss {'Reaction outcome loss': 0.207795696568403, 'Total loss': 0.207795696568403}
2022-12-31 16:14:31,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:31,100 INFO:     Epoch: 95
2022-12-31 16:14:32,738 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41448228458563485, 'Total loss': 0.41448228458563485} | train loss {'Reaction outcome loss': 0.21917796842350426, 'Total loss': 0.21917796842350426}
2022-12-31 16:14:32,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:32,738 INFO:     Epoch: 96
2022-12-31 16:14:34,389 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4074709286292394, 'Total loss': 0.4074709286292394} | train loss {'Reaction outcome loss': 0.2090778012326263, 'Total loss': 0.2090778012326263}
2022-12-31 16:14:34,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:34,390 INFO:     Epoch: 97
2022-12-31 16:14:36,044 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43412373661994935, 'Total loss': 0.43412373661994935} | train loss {'Reaction outcome loss': 0.21557605402739147, 'Total loss': 0.21557605402739147}
2022-12-31 16:14:36,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:36,045 INFO:     Epoch: 98
2022-12-31 16:14:37,675 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4175446232159932, 'Total loss': 0.4175446232159932} | train loss {'Reaction outcome loss': 0.20891563111532896, 'Total loss': 0.20891563111532896}
2022-12-31 16:14:37,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 16:14:37,676 INFO:     Epoch: 99
2022-12-31 16:14:39,289 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4534631450970968, 'Total loss': 0.4534631450970968} | train loss {'Reaction outcome loss': 0.2008283567086992, 'Total loss': 0.2008283567086992}
2022-12-31 16:14:39,289 INFO:     Best model found after epoch 64 of 100.
2022-12-31 16:14:39,289 INFO:   Done with stage: TRAINING
2022-12-31 16:14:39,289 INFO:   Starting stage: EVALUATION
2022-12-31 16:14:39,413 INFO:   Done with stage: EVALUATION
2022-12-31 16:14:39,413 INFO: Done with stage: RUNNING SPLITS
2022-12-31 16:14:39,413 INFO: Starting stage: COMPUTE METRICS
2022-12-31 16:14:40,623 INFO: Done with stage: COMPUTE METRICS
2022-12-31 16:14:40,624 INFO: Starting stage: EXPORT RESULTS
2022-12-31 16:14:40,642 INFO:   Final results averaged over 50 folds: 
2022-12-31 16:14:40,645 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.186619           NaN  0.341031       NaN
2022-12-31 16:14:42,278 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-12-31 16:14:42,283 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-12-31 16:14:42,285 DEBUG:   interactive is False
2022-12-31 16:14:42,285 DEBUG:   platform is linux
2022-12-31 16:14:42,285 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.sql.naming', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-12-31 16:14:42,461 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-12-31 16:14:42,463 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-12-31 16:14:42,891 DEBUG:   Loaded backend agg version unknown.
2022-12-31 16:14:42,893 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-31 16:14:42,893 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 16:14:42,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 16:14:42,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 16:14:42,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 16:14:42,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 16:14:42,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 16:14:42,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,895 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 16:14:42,895 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,895 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,895 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-31 16:14:42,895 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 16:14:42,895 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 16:14:42,895 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,895 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,895 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,895 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,895 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,895 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,895 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,895 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,895 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,895 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-31 16:14:42,895 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,896 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,896 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,896 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,896 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 16:14:42,896 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 16:14:42,896 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,896 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,896 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,896 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 16:14:42,896 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,896 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-31 16:14:42,933 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-12-31 16:14:42,934 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,934 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,934 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,934 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 16:14:42,934 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 16:14:42,934 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 16:14:42,934 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,934 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,934 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,934 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,934 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 16:14:42,934 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 16:14:42,935 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,935 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,935 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,935 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 16:14:42,935 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,935 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 16:14:42,935 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,935 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,935 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-31 16:14:42,935 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 16:14:42,935 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 16:14:42,935 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,935 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,935 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,935 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,935 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,935 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,936 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,936 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,936 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,936 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-31 16:14:42,936 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,936 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,936 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,936 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,936 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 16:14:42,936 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 16:14:42,936 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,936 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,936 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,936 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 16:14:42,936 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,936 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-31 16:14:42,945 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-31 16:14:42,945 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,945 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,945 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,945 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 16:14:42,946 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 16:14:42,946 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 16:14:42,946 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,946 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,946 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,946 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,946 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 16:14:42,946 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 16:14:42,946 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,946 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,946 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,946 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 16:14:42,946 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 16:14:42,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-31 16:14:42,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 16:14:42,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 16:14:42,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,948 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-31 16:14:42,948 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,948 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,948 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,948 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,948 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 16:14:42,948 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 16:14:42,948 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,948 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,948 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 16:14:42,948 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 16:14:42,948 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 16:14:42,948 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-31 16:14:43,334 INFO: Done with stage: EXPORT RESULTS
2022-12-31 16:14:43,334 INFO: Starting stage: SAVE MODEL
2022-12-31 16:14:43,388 INFO: Done with stage: SAVE MODEL
2022-12-31 16:14:43,388 INFO: Wall time for program:  8089.38 seconds
