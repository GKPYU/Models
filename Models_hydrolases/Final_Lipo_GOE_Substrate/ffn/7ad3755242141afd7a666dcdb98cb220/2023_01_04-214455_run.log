2023-01-05 13:03:35,858 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/7ad3755242141afd7a666dcdb98cb220/2023_01_04-214455",
  "seed": 3,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.95,
  "val_size": 0.05,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 5,
  "hidden_size": 30,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2023-01-05 13:03:35,867 INFO: Starting stage: BUILD FEATURIZERS
2023-01-05 13:03:35,869 INFO:   Creating esm representation model
2023-01-05 13:03:35,869 INFO:   Done esm representation model
2023-01-05 13:03:35,870 INFO: Done with stage: BUILD FEATURIZERS
2023-01-05 13:03:35,870 INFO: Starting stage: BUILDING DATASET
2023-01-05 13:03:35,925 INFO: Done with stage: BUILDING DATASET
2023-01-05 13:03:35,925 INFO: Starting stage: FEATURIZING DATA
2023-01-05 13:03:35,925 INFO:   Featurizing proteins
2023-01-05 13:03:35,927 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2023-01-05 13:03:35,961 INFO:   Loaded feature cache of size 489
2023-01-05 13:03:35,962 INFO:   Starting to pool ESM Embeddings
2023-01-05 13:03:36,087 INFO:   Featurizing molecules
2023-01-05 13:03:36,089 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2023-01-05 13:03:36,091 INFO:   Loaded feature cache of size 498
2023-01-05 13:03:37,445 INFO: Done with stage: FEATURIZING DATA
2023-01-05 13:03:37,445 INFO: Starting stage: RUNNING SPLITS
2023-01-05 13:03:37,454 INFO:   Leaving out SEQ value Fold_0
2023-01-05 13:03:37,469 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 13:03:37,469 INFO:   Starting stage: FEATURE SCALING
2023-01-05 13:03:38,136 INFO:   Done with stage: FEATURE SCALING
2023-01-05 13:03:38,136 INFO:   Starting stage: SCALING TARGETS
2023-01-05 13:03:38,204 INFO:   Done with stage: SCALING TARGETS
2023-01-05 13:03:38,204 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:03:38,204 INFO:     No hyperparam tuning for this model
2023-01-05 13:03:38,204 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:03:38,204 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 13:03:38,205 INFO:     None feature selector for col prot
2023-01-05 13:03:38,205 INFO:     None feature selector for col prot
2023-01-05 13:03:38,205 INFO:     None feature selector for col prot
2023-01-05 13:03:38,206 INFO:     None feature selector for col chem
2023-01-05 13:03:38,206 INFO:     None feature selector for col chem
2023-01-05 13:03:38,206 INFO:     None feature selector for col chem
2023-01-05 13:03:38,206 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 13:03:38,206 INFO:   Starting stage: BUILD MODEL
2023-01-05 13:03:38,208 INFO:     Number of params in model 72901
2023-01-05 13:03:38,208 INFO:   Done with stage: BUILD MODEL
2023-01-05 13:03:38,208 INFO:   Starting stage: TRAINING
2023-01-05 13:03:39,901 INFO:     Val loss before train {'Reaction outcome loss': 1.0187528530756633, 'Total loss': 1.0187528530756633}
2023-01-05 13:03:39,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:39,901 INFO:     Epoch: 0
2023-01-05 13:03:42,037 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8825184822082519, 'Total loss': 0.8825184822082519} | train loss {'Reaction outcome loss': 0.9252432556379409, 'Total loss': 0.9252432556379409}
2023-01-05 13:03:42,037 INFO:     Found new best model at epoch 0
2023-01-05 13:03:42,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:42,038 INFO:     Epoch: 1
2023-01-05 13:03:44,178 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6962901949882507, 'Total loss': 0.6962901949882507} | train loss {'Reaction outcome loss': 0.7718254658547077, 'Total loss': 0.7718254658547077}
2023-01-05 13:03:44,178 INFO:     Found new best model at epoch 1
2023-01-05 13:03:44,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:44,179 INFO:     Epoch: 2
2023-01-05 13:03:46,315 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5746453473965327, 'Total loss': 0.5746453473965327} | train loss {'Reaction outcome loss': 0.6061656766540402, 'Total loss': 0.6061656766540402}
2023-01-05 13:03:46,316 INFO:     Found new best model at epoch 2
2023-01-05 13:03:46,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:46,317 INFO:     Epoch: 3
2023-01-05 13:03:48,457 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5571531136830647, 'Total loss': 0.5571531136830647} | train loss {'Reaction outcome loss': 0.541952520554319, 'Total loss': 0.541952520554319}
2023-01-05 13:03:48,457 INFO:     Found new best model at epoch 3
2023-01-05 13:03:48,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:48,459 INFO:     Epoch: 4
2023-01-05 13:03:50,597 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5335725208123525, 'Total loss': 0.5335725208123525} | train loss {'Reaction outcome loss': 0.5172712863474102, 'Total loss': 0.5172712863474102}
2023-01-05 13:03:50,597 INFO:     Found new best model at epoch 4
2023-01-05 13:03:50,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:50,598 INFO:     Epoch: 5
2023-01-05 13:03:52,719 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5464949349562327, 'Total loss': 0.5464949349562327} | train loss {'Reaction outcome loss': 0.5020068623534926, 'Total loss': 0.5020068623534926}
2023-01-05 13:03:52,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:52,719 INFO:     Epoch: 6
2023-01-05 13:03:54,826 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4898594290018082, 'Total loss': 0.4898594290018082} | train loss {'Reaction outcome loss': 0.48938868246672357, 'Total loss': 0.48938868246672357}
2023-01-05 13:03:54,826 INFO:     Found new best model at epoch 6
2023-01-05 13:03:54,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:54,828 INFO:     Epoch: 7
2023-01-05 13:03:56,986 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.470485898355643, 'Total loss': 0.470485898355643} | train loss {'Reaction outcome loss': 0.4855459248954123, 'Total loss': 0.4855459248954123}
2023-01-05 13:03:56,986 INFO:     Found new best model at epoch 7
2023-01-05 13:03:56,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:56,988 INFO:     Epoch: 8
2023-01-05 13:03:59,137 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5224242488543193, 'Total loss': 0.5224242488543193} | train loss {'Reaction outcome loss': 0.48172206948801277, 'Total loss': 0.48172206948801277}
2023-01-05 13:03:59,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:03:59,138 INFO:     Epoch: 9
2023-01-05 13:04:01,296 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5069370021422704, 'Total loss': 0.5069370021422704} | train loss {'Reaction outcome loss': 0.4743029590928074, 'Total loss': 0.4743029590928074}
2023-01-05 13:04:01,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:01,296 INFO:     Epoch: 10
2023-01-05 13:04:03,438 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4741711636384328, 'Total loss': 0.4741711636384328} | train loss {'Reaction outcome loss': 0.4755935740449053, 'Total loss': 0.4755935740449053}
2023-01-05 13:04:03,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:03,438 INFO:     Epoch: 11
2023-01-05 13:04:05,345 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4929596960544586, 'Total loss': 0.4929596960544586} | train loss {'Reaction outcome loss': 0.4654094069759488, 'Total loss': 0.4654094069759488}
2023-01-05 13:04:05,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:05,345 INFO:     Epoch: 12
2023-01-05 13:04:07,468 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.512382835149765, 'Total loss': 0.512382835149765} | train loss {'Reaction outcome loss': 0.46242665715051656, 'Total loss': 0.46242665715051656}
2023-01-05 13:04:07,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:07,468 INFO:     Epoch: 13
2023-01-05 13:04:09,594 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48407849073410036, 'Total loss': 0.48407849073410036} | train loss {'Reaction outcome loss': 0.45699129403729144, 'Total loss': 0.45699129403729144}
2023-01-05 13:04:09,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:09,594 INFO:     Epoch: 14
2023-01-05 13:04:11,726 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46876443922519684, 'Total loss': 0.46876443922519684} | train loss {'Reaction outcome loss': 0.461031002002758, 'Total loss': 0.461031002002758}
2023-01-05 13:04:11,726 INFO:     Found new best model at epoch 14
2023-01-05 13:04:11,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:11,727 INFO:     Epoch: 15
2023-01-05 13:04:13,908 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4610316246747971, 'Total loss': 0.4610316246747971} | train loss {'Reaction outcome loss': 0.45118511541859135, 'Total loss': 0.45118511541859135}
2023-01-05 13:04:13,909 INFO:     Found new best model at epoch 15
2023-01-05 13:04:13,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:13,911 INFO:     Epoch: 16
2023-01-05 13:04:16,040 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4807853400707245, 'Total loss': 0.4807853400707245} | train loss {'Reaction outcome loss': 0.4426814031688285, 'Total loss': 0.4426814031688285}
2023-01-05 13:04:16,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:16,040 INFO:     Epoch: 17
2023-01-05 13:04:18,165 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.467411063114802, 'Total loss': 0.467411063114802} | train loss {'Reaction outcome loss': 0.4445772876232972, 'Total loss': 0.4445772876232972}
2023-01-05 13:04:18,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:18,165 INFO:     Epoch: 18
2023-01-05 13:04:20,272 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4596586267153422, 'Total loss': 0.4596586267153422} | train loss {'Reaction outcome loss': 0.4369634863726058, 'Total loss': 0.4369634863726058}
2023-01-05 13:04:20,273 INFO:     Found new best model at epoch 18
2023-01-05 13:04:20,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:20,275 INFO:     Epoch: 19
2023-01-05 13:04:22,405 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4910510748624802, 'Total loss': 0.4910510748624802} | train loss {'Reaction outcome loss': 0.43900300840755085, 'Total loss': 0.43900300840755085}
2023-01-05 13:04:22,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:22,406 INFO:     Epoch: 20
2023-01-05 13:04:24,544 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4605217824379603, 'Total loss': 0.4605217824379603} | train loss {'Reaction outcome loss': 0.431725881311483, 'Total loss': 0.431725881311483}
2023-01-05 13:04:24,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:24,544 INFO:     Epoch: 21
2023-01-05 13:04:26,684 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5181460440158844, 'Total loss': 0.5181460440158844} | train loss {'Reaction outcome loss': 0.43408579128238306, 'Total loss': 0.43408579128238306}
2023-01-05 13:04:26,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:26,684 INFO:     Epoch: 22
2023-01-05 13:04:28,800 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.496645188331604, 'Total loss': 0.496645188331604} | train loss {'Reaction outcome loss': 0.4220214474932615, 'Total loss': 0.4220214474932615}
2023-01-05 13:04:28,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:28,800 INFO:     Epoch: 23
2023-01-05 13:04:30,933 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4642544815937678, 'Total loss': 0.4642544815937678} | train loss {'Reaction outcome loss': 0.42045987340120167, 'Total loss': 0.42045987340120167}
2023-01-05 13:04:30,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:30,933 INFO:     Epoch: 24
2023-01-05 13:04:33,056 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4779929598172506, 'Total loss': 0.4779929598172506} | train loss {'Reaction outcome loss': 0.4168883240969354, 'Total loss': 0.4168883240969354}
2023-01-05 13:04:33,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:33,057 INFO:     Epoch: 25
2023-01-05 13:04:35,193 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4735405097405116, 'Total loss': 0.4735405097405116} | train loss {'Reaction outcome loss': 0.4208405443600246, 'Total loss': 0.4208405443600246}
2023-01-05 13:04:35,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:35,193 INFO:     Epoch: 26
2023-01-05 13:04:37,325 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44626243511835734, 'Total loss': 0.44626243511835734} | train loss {'Reaction outcome loss': 0.4173860153381204, 'Total loss': 0.4173860153381204}
2023-01-05 13:04:37,325 INFO:     Found new best model at epoch 26
2023-01-05 13:04:37,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:37,327 INFO:     Epoch: 27
2023-01-05 13:04:39,454 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4701622188091278, 'Total loss': 0.4701622188091278} | train loss {'Reaction outcome loss': 0.40995097354109034, 'Total loss': 0.40995097354109034}
2023-01-05 13:04:39,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:39,454 INFO:     Epoch: 28
2023-01-05 13:04:41,592 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4584098428487778, 'Total loss': 0.4584098428487778} | train loss {'Reaction outcome loss': 0.40487192530225924, 'Total loss': 0.40487192530225924}
2023-01-05 13:04:41,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:41,592 INFO:     Epoch: 29
2023-01-05 13:04:43,712 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4239849110444387, 'Total loss': 0.4239849110444387} | train loss {'Reaction outcome loss': 0.40228523297624275, 'Total loss': 0.40228523297624275}
2023-01-05 13:04:43,712 INFO:     Found new best model at epoch 29
2023-01-05 13:04:43,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:43,713 INFO:     Epoch: 30
2023-01-05 13:04:45,852 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4994141737620036, 'Total loss': 0.4994141737620036} | train loss {'Reaction outcome loss': 0.39886203784864027, 'Total loss': 0.39886203784864027}
2023-01-05 13:04:45,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:45,852 INFO:     Epoch: 31
2023-01-05 13:04:47,990 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4610437750816345, 'Total loss': 0.4610437750816345} | train loss {'Reaction outcome loss': 0.39961160757602787, 'Total loss': 0.39961160757602787}
2023-01-05 13:04:47,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:47,991 INFO:     Epoch: 32
2023-01-05 13:04:50,147 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44997879763444265, 'Total loss': 0.44997879763444265} | train loss {'Reaction outcome loss': 0.39239763004548384, 'Total loss': 0.39239763004548384}
2023-01-05 13:04:50,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:50,148 INFO:     Epoch: 33
2023-01-05 13:04:52,261 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4612077196439107, 'Total loss': 0.4612077196439107} | train loss {'Reaction outcome loss': 0.39078521703953273, 'Total loss': 0.39078521703953273}
2023-01-05 13:04:52,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:52,261 INFO:     Epoch: 34
2023-01-05 13:04:54,388 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4191462203860283, 'Total loss': 0.4191462203860283} | train loss {'Reaction outcome loss': 0.390615802483408, 'Total loss': 0.390615802483408}
2023-01-05 13:04:54,389 INFO:     Found new best model at epoch 34
2023-01-05 13:04:54,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:54,390 INFO:     Epoch: 35
2023-01-05 13:04:56,533 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4808600564797719, 'Total loss': 0.4808600564797719} | train loss {'Reaction outcome loss': 0.38951182398167283, 'Total loss': 0.38951182398167283}
2023-01-05 13:04:56,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:56,534 INFO:     Epoch: 36
2023-01-05 13:04:58,693 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4176069547732671, 'Total loss': 0.4176069547732671} | train loss {'Reaction outcome loss': 0.3843125932655492, 'Total loss': 0.3843125932655492}
2023-01-05 13:04:58,693 INFO:     Found new best model at epoch 36
2023-01-05 13:04:58,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:04:58,695 INFO:     Epoch: 37
2023-01-05 13:05:00,857 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45803290903568267, 'Total loss': 0.45803290903568267} | train loss {'Reaction outcome loss': 0.3773170910475455, 'Total loss': 0.3773170910475455}
2023-01-05 13:05:00,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:00,857 INFO:     Epoch: 38
2023-01-05 13:05:02,993 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43739471634229027, 'Total loss': 0.43739471634229027} | train loss {'Reaction outcome loss': 0.3697262112829056, 'Total loss': 0.3697262112829056}
2023-01-05 13:05:02,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:02,993 INFO:     Epoch: 39
2023-01-05 13:05:05,154 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4202206254005432, 'Total loss': 0.4202206254005432} | train loss {'Reaction outcome loss': 0.36577247839161764, 'Total loss': 0.36577247839161764}
2023-01-05 13:05:05,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:05,154 INFO:     Epoch: 40
2023-01-05 13:05:07,309 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40695221722126007, 'Total loss': 0.40695221722126007} | train loss {'Reaction outcome loss': 0.3641161722414223, 'Total loss': 0.3641161722414223}
2023-01-05 13:05:07,309 INFO:     Found new best model at epoch 40
2023-01-05 13:05:07,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:07,310 INFO:     Epoch: 41
2023-01-05 13:05:09,514 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4100290874640147, 'Total loss': 0.4100290874640147} | train loss {'Reaction outcome loss': 0.36594522834479154, 'Total loss': 0.36594522834479154}
2023-01-05 13:05:09,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:09,515 INFO:     Epoch: 42
2023-01-05 13:05:11,710 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44319169968366623, 'Total loss': 0.44319169968366623} | train loss {'Reaction outcome loss': 0.3589614247937342, 'Total loss': 0.3589614247937342}
2023-01-05 13:05:11,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:11,710 INFO:     Epoch: 43
2023-01-05 13:05:13,859 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4468059907356898, 'Total loss': 0.4468059907356898} | train loss {'Reaction outcome loss': 0.3552003821337616, 'Total loss': 0.3552003821337616}
2023-01-05 13:05:13,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:13,859 INFO:     Epoch: 44
2023-01-05 13:05:15,983 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4268499652544657, 'Total loss': 0.4268499652544657} | train loss {'Reaction outcome loss': 0.35507246879212584, 'Total loss': 0.35507246879212584}
2023-01-05 13:05:15,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:15,984 INFO:     Epoch: 45
2023-01-05 13:05:18,128 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40663059453169503, 'Total loss': 0.40663059453169503} | train loss {'Reaction outcome loss': 0.35083058996351213, 'Total loss': 0.35083058996351213}
2023-01-05 13:05:18,128 INFO:     Found new best model at epoch 45
2023-01-05 13:05:18,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:18,129 INFO:     Epoch: 46
2023-01-05 13:05:20,291 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4102566808462143, 'Total loss': 0.4102566808462143} | train loss {'Reaction outcome loss': 0.34940443763802775, 'Total loss': 0.34940443763802775}
2023-01-05 13:05:20,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:20,292 INFO:     Epoch: 47
2023-01-05 13:05:22,436 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43602430522441865, 'Total loss': 0.43602430522441865} | train loss {'Reaction outcome loss': 0.3478588409066855, 'Total loss': 0.3478588409066855}
2023-01-05 13:05:22,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:22,436 INFO:     Epoch: 48
2023-01-05 13:05:24,571 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40412315328915915, 'Total loss': 0.40412315328915915} | train loss {'Reaction outcome loss': 0.340659266740302, 'Total loss': 0.340659266740302}
2023-01-05 13:05:24,571 INFO:     Found new best model at epoch 48
2023-01-05 13:05:24,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:24,572 INFO:     Epoch: 49
2023-01-05 13:05:26,717 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4286048084497452, 'Total loss': 0.4286048084497452} | train loss {'Reaction outcome loss': 0.34135669276063696, 'Total loss': 0.34135669276063696}
2023-01-05 13:05:26,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:26,718 INFO:     Epoch: 50
2023-01-05 13:05:28,843 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4169953614473343, 'Total loss': 0.4169953614473343} | train loss {'Reaction outcome loss': 0.3333059806963463, 'Total loss': 0.3333059806963463}
2023-01-05 13:05:28,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:28,843 INFO:     Epoch: 51
2023-01-05 13:05:30,999 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39113988876342776, 'Total loss': 0.39113988876342776} | train loss {'Reaction outcome loss': 0.33495559846306894, 'Total loss': 0.33495559846306894}
2023-01-05 13:05:30,999 INFO:     Found new best model at epoch 51
2023-01-05 13:05:31,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:31,001 INFO:     Epoch: 52
2023-01-05 13:05:33,148 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40555504659811653, 'Total loss': 0.40555504659811653} | train loss {'Reaction outcome loss': 0.3250869135935228, 'Total loss': 0.3250869135935228}
2023-01-05 13:05:33,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:33,149 INFO:     Epoch: 53
2023-01-05 13:05:35,291 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4509067157904307, 'Total loss': 0.4509067157904307} | train loss {'Reaction outcome loss': 0.3296999367765891, 'Total loss': 0.3296999367765891}
2023-01-05 13:05:35,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:35,291 INFO:     Epoch: 54
2023-01-05 13:05:37,445 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43382969895998635, 'Total loss': 0.43382969895998635} | train loss {'Reaction outcome loss': 0.32569671793407573, 'Total loss': 0.32569671793407573}
2023-01-05 13:05:37,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:37,445 INFO:     Epoch: 55
2023-01-05 13:05:39,569 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4135046064853668, 'Total loss': 0.4135046064853668} | train loss {'Reaction outcome loss': 0.33252620153920553, 'Total loss': 0.33252620153920553}
2023-01-05 13:05:39,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:39,569 INFO:     Epoch: 56
2023-01-05 13:05:41,715 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40095994373162586, 'Total loss': 0.40095994373162586} | train loss {'Reaction outcome loss': 0.3190241345774123, 'Total loss': 0.3190241345774123}
2023-01-05 13:05:41,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:41,716 INFO:     Epoch: 57
2023-01-05 13:05:43,904 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4560313234726588, 'Total loss': 0.4560313234726588} | train loss {'Reaction outcome loss': 0.32057188392613395, 'Total loss': 0.32057188392613395}
2023-01-05 13:05:43,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:43,905 INFO:     Epoch: 58
2023-01-05 13:05:46,076 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.415835477411747, 'Total loss': 0.415835477411747} | train loss {'Reaction outcome loss': 0.3171949071379808, 'Total loss': 0.3171949071379808}
2023-01-05 13:05:46,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:46,077 INFO:     Epoch: 59
2023-01-05 13:05:48,200 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43920680582523347, 'Total loss': 0.43920680582523347} | train loss {'Reaction outcome loss': 0.30938725694741087, 'Total loss': 0.30938725694741087}
2023-01-05 13:05:48,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:48,200 INFO:     Epoch: 60
2023-01-05 13:05:50,324 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44105364779631295, 'Total loss': 0.44105364779631295} | train loss {'Reaction outcome loss': 0.3043880136308325, 'Total loss': 0.3043880136308325}
2023-01-05 13:05:50,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:50,325 INFO:     Epoch: 61
2023-01-05 13:05:52,478 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41194510261217754, 'Total loss': 0.41194510261217754} | train loss {'Reaction outcome loss': 0.30760432917611064, 'Total loss': 0.30760432917611064}
2023-01-05 13:05:52,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:52,479 INFO:     Epoch: 62
2023-01-05 13:05:54,618 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45589829981327057, 'Total loss': 0.45589829981327057} | train loss {'Reaction outcome loss': 0.31015446945008285, 'Total loss': 0.31015446945008285}
2023-01-05 13:05:54,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:54,618 INFO:     Epoch: 63
2023-01-05 13:05:56,761 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4021605292956034, 'Total loss': 0.4021605292956034} | train loss {'Reaction outcome loss': 0.3019979601732759, 'Total loss': 0.3019979601732759}
2023-01-05 13:05:56,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:56,762 INFO:     Epoch: 64
2023-01-05 13:05:58,904 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39310353149970373, 'Total loss': 0.39310353149970373} | train loss {'Reaction outcome loss': 0.2989777677552604, 'Total loss': 0.2989777677552604}
2023-01-05 13:05:58,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:05:58,904 INFO:     Epoch: 65
2023-01-05 13:06:01,044 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4414338787396749, 'Total loss': 0.4414338787396749} | train loss {'Reaction outcome loss': 0.2960817015340941, 'Total loss': 0.2960817015340941}
2023-01-05 13:06:01,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:01,044 INFO:     Epoch: 66
2023-01-05 13:06:03,171 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4233022650082906, 'Total loss': 0.4233022650082906} | train loss {'Reaction outcome loss': 0.30262424601685434, 'Total loss': 0.30262424601685434}
2023-01-05 13:06:03,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:03,172 INFO:     Epoch: 67
2023-01-05 13:06:05,342 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3933225154876709, 'Total loss': 0.3933225154876709} | train loss {'Reaction outcome loss': 0.3000683548959184, 'Total loss': 0.3000683548959184}
2023-01-05 13:06:05,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:05,342 INFO:     Epoch: 68
2023-01-05 13:06:07,494 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3821854094664256, 'Total loss': 0.3821854094664256} | train loss {'Reaction outcome loss': 0.2956098899409011, 'Total loss': 0.2956098899409011}
2023-01-05 13:06:07,494 INFO:     Found new best model at epoch 68
2023-01-05 13:06:07,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:07,495 INFO:     Epoch: 69
2023-01-05 13:06:09,621 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.379767499367396, 'Total loss': 0.379767499367396} | train loss {'Reaction outcome loss': 0.29302078796612036, 'Total loss': 0.29302078796612036}
2023-01-05 13:06:09,621 INFO:     Found new best model at epoch 69
2023-01-05 13:06:09,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:09,623 INFO:     Epoch: 70
2023-01-05 13:06:11,747 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38324656436840693, 'Total loss': 0.38324656436840693} | train loss {'Reaction outcome loss': 0.2830529618776325, 'Total loss': 0.2830529618776325}
2023-01-05 13:06:11,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:11,747 INFO:     Epoch: 71
2023-01-05 13:06:13,859 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39450116753578185, 'Total loss': 0.39450116753578185} | train loss {'Reaction outcome loss': 0.2900174346858219, 'Total loss': 0.2900174346858219}
2023-01-05 13:06:13,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:13,860 INFO:     Epoch: 72
2023-01-05 13:06:15,987 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47457162439823153, 'Total loss': 0.47457162439823153} | train loss {'Reaction outcome loss': 0.2942715520414459, 'Total loss': 0.2942715520414459}
2023-01-05 13:06:15,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:15,988 INFO:     Epoch: 73
2023-01-05 13:06:18,129 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41038604974746706, 'Total loss': 0.41038604974746706} | train loss {'Reaction outcome loss': 0.2967478800633233, 'Total loss': 0.2967478800633233}
2023-01-05 13:06:18,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:18,129 INFO:     Epoch: 74
2023-01-05 13:06:20,264 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42493287126223245, 'Total loss': 0.42493287126223245} | train loss {'Reaction outcome loss': 0.2870505377377346, 'Total loss': 0.2870505377377346}
2023-01-05 13:06:20,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:20,265 INFO:     Epoch: 75
2023-01-05 13:06:22,386 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4144350270430247, 'Total loss': 0.4144350270430247} | train loss {'Reaction outcome loss': 0.28011348613089243, 'Total loss': 0.28011348613089243}
2023-01-05 13:06:22,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:22,386 INFO:     Epoch: 76
2023-01-05 13:06:24,512 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41174159944057465, 'Total loss': 0.41174159944057465} | train loss {'Reaction outcome loss': 0.27962763632064336, 'Total loss': 0.27962763632064336}
2023-01-05 13:06:24,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:24,512 INFO:     Epoch: 77
2023-01-05 13:06:26,623 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39452384908994037, 'Total loss': 0.39452384908994037} | train loss {'Reaction outcome loss': 0.2780115430826669, 'Total loss': 0.2780115430826669}
2023-01-05 13:06:26,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:26,624 INFO:     Epoch: 78
2023-01-05 13:06:28,764 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4131966600815455, 'Total loss': 0.4131966600815455} | train loss {'Reaction outcome loss': 0.282317904871462, 'Total loss': 0.282317904871462}
2023-01-05 13:06:28,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:28,765 INFO:     Epoch: 79
2023-01-05 13:06:30,906 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40872287849585215, 'Total loss': 0.40872287849585215} | train loss {'Reaction outcome loss': 0.27700352592345995, 'Total loss': 0.27700352592345995}
2023-01-05 13:06:30,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:30,906 INFO:     Epoch: 80
2023-01-05 13:06:33,048 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3987670381863912, 'Total loss': 0.3987670381863912} | train loss {'Reaction outcome loss': 0.2808606426330495, 'Total loss': 0.2808606426330495}
2023-01-05 13:06:33,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:33,050 INFO:     Epoch: 81
2023-01-05 13:06:35,200 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41741352279980976, 'Total loss': 0.41741352279980976} | train loss {'Reaction outcome loss': 0.2798425920525968, 'Total loss': 0.2798425920525968}
2023-01-05 13:06:35,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:35,200 INFO:     Epoch: 82
2023-01-05 13:06:37,354 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.433209032813708, 'Total loss': 0.433209032813708} | train loss {'Reaction outcome loss': 0.26730359431642753, 'Total loss': 0.26730359431642753}
2023-01-05 13:06:37,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:37,355 INFO:     Epoch: 83
2023-01-05 13:06:39,514 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.424560022354126, 'Total loss': 0.424560022354126} | train loss {'Reaction outcome loss': 0.2726828373163502, 'Total loss': 0.2726828373163502}
2023-01-05 13:06:39,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:39,515 INFO:     Epoch: 84
2023-01-05 13:06:41,663 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4520752191543579, 'Total loss': 0.4520752191543579} | train loss {'Reaction outcome loss': 0.2722486069787553, 'Total loss': 0.2722486069787553}
2023-01-05 13:06:41,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:41,664 INFO:     Epoch: 85
2023-01-05 13:06:43,795 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.409439621369044, 'Total loss': 0.409439621369044} | train loss {'Reaction outcome loss': 0.27009989935290685, 'Total loss': 0.27009989935290685}
2023-01-05 13:06:43,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:43,796 INFO:     Epoch: 86
2023-01-05 13:06:45,938 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.421921381354332, 'Total loss': 0.421921381354332} | train loss {'Reaction outcome loss': 0.2702719107911591, 'Total loss': 0.2702719107911591}
2023-01-05 13:06:45,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:45,939 INFO:     Epoch: 87
2023-01-05 13:06:48,107 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4258486534158389, 'Total loss': 0.4258486534158389} | train loss {'Reaction outcome loss': 0.2659775383579425, 'Total loss': 0.2659775383579425}
2023-01-05 13:06:48,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:48,107 INFO:     Epoch: 88
2023-01-05 13:06:50,273 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4167678952217102, 'Total loss': 0.4167678952217102} | train loss {'Reaction outcome loss': 0.2733740289269131, 'Total loss': 0.2733740289269131}
2023-01-05 13:06:50,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:50,274 INFO:     Epoch: 89
2023-01-05 13:06:52,421 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4024511267741521, 'Total loss': 0.4024511267741521} | train loss {'Reaction outcome loss': 0.2701567705079313, 'Total loss': 0.2701567705079313}
2023-01-05 13:06:52,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:52,422 INFO:     Epoch: 90
2023-01-05 13:06:54,569 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.421700390179952, 'Total loss': 0.421700390179952} | train loss {'Reaction outcome loss': 0.26681234354098693, 'Total loss': 0.26681234354098693}
2023-01-05 13:06:54,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:54,569 INFO:     Epoch: 91
2023-01-05 13:06:56,738 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41721997459729515, 'Total loss': 0.41721997459729515} | train loss {'Reaction outcome loss': 0.25995106820440117, 'Total loss': 0.25995106820440117}
2023-01-05 13:06:56,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:56,739 INFO:     Epoch: 92
2023-01-05 13:06:58,907 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41697030266125995, 'Total loss': 0.41697030266125995} | train loss {'Reaction outcome loss': 0.2749868188285347, 'Total loss': 0.2749868188285347}
2023-01-05 13:06:58,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:06:58,908 INFO:     Epoch: 93
2023-01-05 13:07:01,029 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41902851810057956, 'Total loss': 0.41902851810057956} | train loss {'Reaction outcome loss': 0.25732964337863123, 'Total loss': 0.25732964337863123}
2023-01-05 13:07:01,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:01,029 INFO:     Epoch: 94
2023-01-05 13:07:03,214 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3947485181192557, 'Total loss': 0.3947485181192557} | train loss {'Reaction outcome loss': 0.2677728498027056, 'Total loss': 0.2677728498027056}
2023-01-05 13:07:03,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:03,215 INFO:     Epoch: 95
2023-01-05 13:07:05,380 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3925074090560277, 'Total loss': 0.3925074090560277} | train loss {'Reaction outcome loss': 0.2553047966007348, 'Total loss': 0.2553047966007348}
2023-01-05 13:07:05,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:05,380 INFO:     Epoch: 96
2023-01-05 13:07:07,521 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42858701944351196, 'Total loss': 0.42858701944351196} | train loss {'Reaction outcome loss': 0.25474989568262835, 'Total loss': 0.25474989568262835}
2023-01-05 13:07:07,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:07,521 INFO:     Epoch: 97
2023-01-05 13:07:09,663 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43733415404955545, 'Total loss': 0.43733415404955545} | train loss {'Reaction outcome loss': 0.25514613080176185, 'Total loss': 0.25514613080176185}
2023-01-05 13:07:09,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:09,664 INFO:     Epoch: 98
2023-01-05 13:07:11,780 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.406326554218928, 'Total loss': 0.406326554218928} | train loss {'Reaction outcome loss': 0.2573644260606377, 'Total loss': 0.2573644260606377}
2023-01-05 13:07:11,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:11,780 INFO:     Epoch: 99
2023-01-05 13:07:13,918 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38360554426908494, 'Total loss': 0.38360554426908494} | train loss {'Reaction outcome loss': 0.25617434882009643, 'Total loss': 0.25617434882009643}
2023-01-05 13:07:13,918 INFO:     Best model found after epoch 70 of 100.
2023-01-05 13:07:13,919 INFO:   Done with stage: TRAINING
2023-01-05 13:07:13,919 INFO:   Starting stage: EVALUATION
2023-01-05 13:07:14,064 INFO:   Done with stage: EVALUATION
2023-01-05 13:07:14,064 INFO:   Leaving out SEQ value Fold_1
2023-01-05 13:07:14,077 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 13:07:14,077 INFO:   Starting stage: FEATURE SCALING
2023-01-05 13:07:14,749 INFO:   Done with stage: FEATURE SCALING
2023-01-05 13:07:14,750 INFO:   Starting stage: SCALING TARGETS
2023-01-05 13:07:14,820 INFO:   Done with stage: SCALING TARGETS
2023-01-05 13:07:14,820 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:07:14,820 INFO:     No hyperparam tuning for this model
2023-01-05 13:07:14,820 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:07:14,820 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 13:07:14,821 INFO:     None feature selector for col prot
2023-01-05 13:07:14,821 INFO:     None feature selector for col prot
2023-01-05 13:07:14,821 INFO:     None feature selector for col prot
2023-01-05 13:07:14,821 INFO:     None feature selector for col chem
2023-01-05 13:07:14,821 INFO:     None feature selector for col chem
2023-01-05 13:07:14,821 INFO:     None feature selector for col chem
2023-01-05 13:07:14,822 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 13:07:14,822 INFO:   Starting stage: BUILD MODEL
2023-01-05 13:07:14,823 INFO:     Number of params in model 72901
2023-01-05 13:07:14,826 INFO:   Done with stage: BUILD MODEL
2023-01-05 13:07:14,826 INFO:   Starting stage: TRAINING
2023-01-05 13:07:14,885 INFO:     Val loss before train {'Reaction outcome loss': 1.0321546018123626, 'Total loss': 1.0321546018123626}
2023-01-05 13:07:14,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:14,886 INFO:     Epoch: 0
2023-01-05 13:07:17,040 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.901903243859609, 'Total loss': 0.901903243859609} | train loss {'Reaction outcome loss': 0.9250668977940644, 'Total loss': 0.9250668977940644}
2023-01-05 13:07:17,040 INFO:     Found new best model at epoch 0
2023-01-05 13:07:17,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:17,041 INFO:     Epoch: 1
2023-01-05 13:07:19,191 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6305004735787709, 'Total loss': 0.6305004735787709} | train loss {'Reaction outcome loss': 0.7313958347460383, 'Total loss': 0.7313958347460383}
2023-01-05 13:07:19,191 INFO:     Found new best model at epoch 1
2023-01-05 13:07:19,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:19,192 INFO:     Epoch: 2
2023-01-05 13:07:21,363 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5384613205989202, 'Total loss': 0.5384613205989202} | train loss {'Reaction outcome loss': 0.5955413652826911, 'Total loss': 0.5955413652826911}
2023-01-05 13:07:21,363 INFO:     Found new best model at epoch 2
2023-01-05 13:07:21,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:21,364 INFO:     Epoch: 3
2023-01-05 13:07:23,505 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5865639448165894, 'Total loss': 0.5865639448165894} | train loss {'Reaction outcome loss': 0.5407122305553892, 'Total loss': 0.5407122305553892}
2023-01-05 13:07:23,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:23,506 INFO:     Epoch: 4
2023-01-05 13:07:25,653 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5343293031056722, 'Total loss': 0.5343293031056722} | train loss {'Reaction outcome loss': 0.5383118087074895, 'Total loss': 0.5383118087074895}
2023-01-05 13:07:25,654 INFO:     Found new best model at epoch 4
2023-01-05 13:07:25,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:25,655 INFO:     Epoch: 5
2023-01-05 13:07:27,815 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5689893265565237, 'Total loss': 0.5689893265565237} | train loss {'Reaction outcome loss': 0.5138292949700701, 'Total loss': 0.5138292949700701}
2023-01-05 13:07:27,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:27,815 INFO:     Epoch: 6
2023-01-05 13:07:29,980 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5259645561377208, 'Total loss': 0.5259645561377208} | train loss {'Reaction outcome loss': 0.4899865298893006, 'Total loss': 0.4899865298893006}
2023-01-05 13:07:29,980 INFO:     Found new best model at epoch 6
2023-01-05 13:07:29,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:29,982 INFO:     Epoch: 7
2023-01-05 13:07:32,152 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5440926849842072, 'Total loss': 0.5440926849842072} | train loss {'Reaction outcome loss': 0.4787334489123221, 'Total loss': 0.4787334489123221}
2023-01-05 13:07:32,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:32,152 INFO:     Epoch: 8
2023-01-05 13:07:34,327 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5355246752500534, 'Total loss': 0.5355246752500534} | train loss {'Reaction outcome loss': 0.4719821017427856, 'Total loss': 0.4719821017427856}
2023-01-05 13:07:34,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:34,327 INFO:     Epoch: 9
2023-01-05 13:07:36,481 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5161075234413147, 'Total loss': 0.5161075234413147} | train loss {'Reaction outcome loss': 0.4599650637719078, 'Total loss': 0.4599650637719078}
2023-01-05 13:07:36,482 INFO:     Found new best model at epoch 9
2023-01-05 13:07:36,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:36,483 INFO:     Epoch: 10
2023-01-05 13:07:38,658 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5170242647329967, 'Total loss': 0.5170242647329967} | train loss {'Reaction outcome loss': 0.4618193721263737, 'Total loss': 0.4618193721263737}
2023-01-05 13:07:38,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:38,660 INFO:     Epoch: 11
2023-01-05 13:07:40,814 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5282942553361257, 'Total loss': 0.5282942553361257} | train loss {'Reaction outcome loss': 0.4821840339623716, 'Total loss': 0.4821840339623716}
2023-01-05 13:07:40,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:40,814 INFO:     Epoch: 12
2023-01-05 13:07:43,003 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4918012648820877, 'Total loss': 0.4918012648820877} | train loss {'Reaction outcome loss': 0.4539007090413403, 'Total loss': 0.4539007090413403}
2023-01-05 13:07:43,004 INFO:     Found new best model at epoch 12
2023-01-05 13:07:43,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:43,005 INFO:     Epoch: 13
2023-01-05 13:07:45,162 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.502666371067365, 'Total loss': 0.502666371067365} | train loss {'Reaction outcome loss': 0.45899352771432506, 'Total loss': 0.45899352771432506}
2023-01-05 13:07:45,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:45,163 INFO:     Epoch: 14
2023-01-05 13:07:47,315 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47890495260556537, 'Total loss': 0.47890495260556537} | train loss {'Reaction outcome loss': 0.4599796485909146, 'Total loss': 0.4599796485909146}
2023-01-05 13:07:47,315 INFO:     Found new best model at epoch 14
2023-01-05 13:07:47,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:47,316 INFO:     Epoch: 15
2023-01-05 13:07:49,486 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4982905189196269, 'Total loss': 0.4982905189196269} | train loss {'Reaction outcome loss': 0.43683851280830044, 'Total loss': 0.43683851280830044}
2023-01-05 13:07:49,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:49,487 INFO:     Epoch: 16
2023-01-05 13:07:51,644 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48276328841845195, 'Total loss': 0.48276328841845195} | train loss {'Reaction outcome loss': 0.43972986180713214, 'Total loss': 0.43972986180713214}
2023-01-05 13:07:51,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:51,645 INFO:     Epoch: 17
2023-01-05 13:07:53,809 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46394724448521935, 'Total loss': 0.46394724448521935} | train loss {'Reaction outcome loss': 0.4376983616123165, 'Total loss': 0.4376983616123165}
2023-01-05 13:07:53,809 INFO:     Found new best model at epoch 17
2023-01-05 13:07:53,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:53,811 INFO:     Epoch: 18
2023-01-05 13:07:55,970 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48771161437034605, 'Total loss': 0.48771161437034605} | train loss {'Reaction outcome loss': 0.4318710986889251, 'Total loss': 0.4318710986889251}
2023-01-05 13:07:55,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:55,970 INFO:     Epoch: 19
2023-01-05 13:07:58,135 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49996625383694965, 'Total loss': 0.49996625383694965} | train loss {'Reaction outcome loss': 0.41877975358216063, 'Total loss': 0.41877975358216063}
2023-01-05 13:07:58,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:07:58,136 INFO:     Epoch: 20
2023-01-05 13:08:00,331 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49647122621536255, 'Total loss': 0.49647122621536255} | train loss {'Reaction outcome loss': 0.416153898253443, 'Total loss': 0.416153898253443}
2023-01-05 13:08:00,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:00,332 INFO:     Epoch: 21
2023-01-05 13:08:02,535 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4664706955353419, 'Total loss': 0.4664706955353419} | train loss {'Reaction outcome loss': 0.41085057380247314, 'Total loss': 0.41085057380247314}
2023-01-05 13:08:02,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:02,535 INFO:     Epoch: 22
2023-01-05 13:08:04,755 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48551801045735676, 'Total loss': 0.48551801045735676} | train loss {'Reaction outcome loss': 0.4049588078396746, 'Total loss': 0.4049588078396746}
2023-01-05 13:08:04,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:04,755 INFO:     Epoch: 23
2023-01-05 13:08:06,979 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4977204461892446, 'Total loss': 0.4977204461892446} | train loss {'Reaction outcome loss': 0.40646961073566606, 'Total loss': 0.40646961073566606}
2023-01-05 13:08:06,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:06,979 INFO:     Epoch: 24
2023-01-05 13:08:09,188 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44112360204259554, 'Total loss': 0.44112360204259554} | train loss {'Reaction outcome loss': 0.4002125341513771, 'Total loss': 0.4002125341513771}
2023-01-05 13:08:09,188 INFO:     Found new best model at epoch 24
2023-01-05 13:08:09,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:09,189 INFO:     Epoch: 25
2023-01-05 13:08:11,327 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4777466177940369, 'Total loss': 0.4777466177940369} | train loss {'Reaction outcome loss': 0.3957745649270204, 'Total loss': 0.3957745649270204}
2023-01-05 13:08:11,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:11,327 INFO:     Epoch: 26
2023-01-05 13:08:13,397 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4628295550743739, 'Total loss': 0.4628295550743739} | train loss {'Reaction outcome loss': 0.393679093138443, 'Total loss': 0.393679093138443}
2023-01-05 13:08:13,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:13,397 INFO:     Epoch: 27
2023-01-05 13:08:15,605 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45897409518559773, 'Total loss': 0.45897409518559773} | train loss {'Reaction outcome loss': 0.3844504317241734, 'Total loss': 0.3844504317241734}
2023-01-05 13:08:15,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:15,607 INFO:     Epoch: 28
2023-01-05 13:08:17,836 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5013583282629649, 'Total loss': 0.5013583282629649} | train loss {'Reaction outcome loss': 0.3993268395216032, 'Total loss': 0.3993268395216032}
2023-01-05 13:08:17,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:17,836 INFO:     Epoch: 29
2023-01-05 13:08:20,037 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4590748111406962, 'Total loss': 0.4590748111406962} | train loss {'Reaction outcome loss': 0.3826685187596297, 'Total loss': 0.3826685187596297}
2023-01-05 13:08:20,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:20,038 INFO:     Epoch: 30
2023-01-05 13:08:22,218 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46595062414805094, 'Total loss': 0.46595062414805094} | train loss {'Reaction outcome loss': 0.38331555605013223, 'Total loss': 0.38331555605013223}
2023-01-05 13:08:22,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:22,219 INFO:     Epoch: 31
2023-01-05 13:08:24,396 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.446086131532987, 'Total loss': 0.446086131532987} | train loss {'Reaction outcome loss': 0.37243243914575863, 'Total loss': 0.37243243914575863}
2023-01-05 13:08:24,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:24,396 INFO:     Epoch: 32
2023-01-05 13:08:26,559 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48414467672506967, 'Total loss': 0.48414467672506967} | train loss {'Reaction outcome loss': 0.3735378706141383, 'Total loss': 0.3735378706141383}
2023-01-05 13:08:26,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:26,560 INFO:     Epoch: 33
2023-01-05 13:08:28,733 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.501287450393041, 'Total loss': 0.501287450393041} | train loss {'Reaction outcome loss': 0.3796685279711433, 'Total loss': 0.3796685279711433}
2023-01-05 13:08:28,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:28,733 INFO:     Epoch: 34
2023-01-05 13:08:30,900 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48476717273394265, 'Total loss': 0.48476717273394265} | train loss {'Reaction outcome loss': 0.39719971087491274, 'Total loss': 0.39719971087491274}
2023-01-05 13:08:30,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:30,900 INFO:     Epoch: 35
2023-01-05 13:08:33,074 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48863733410835264, 'Total loss': 0.48863733410835264} | train loss {'Reaction outcome loss': 0.36909047403155726, 'Total loss': 0.36909047403155726}
2023-01-05 13:08:33,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:33,075 INFO:     Epoch: 36
2023-01-05 13:08:35,235 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4668014129002889, 'Total loss': 0.4668014129002889} | train loss {'Reaction outcome loss': 0.3605879826700666, 'Total loss': 0.3605879826700666}
2023-01-05 13:08:35,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:35,237 INFO:     Epoch: 37
2023-01-05 13:08:37,409 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5047663986682892, 'Total loss': 0.5047663986682892} | train loss {'Reaction outcome loss': 0.3526235827096347, 'Total loss': 0.3526235827096347}
2023-01-05 13:08:37,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:37,410 INFO:     Epoch: 38
2023-01-05 13:08:39,569 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48669375975926715, 'Total loss': 0.48669375975926715} | train loss {'Reaction outcome loss': 0.3569993412078264, 'Total loss': 0.3569993412078264}
2023-01-05 13:08:39,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:39,570 INFO:     Epoch: 39
2023-01-05 13:08:41,815 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4764900068442027, 'Total loss': 0.4764900068442027} | train loss {'Reaction outcome loss': 0.3512626719653465, 'Total loss': 0.3512626719653465}
2023-01-05 13:08:41,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:41,815 INFO:     Epoch: 40
2023-01-05 13:08:43,974 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48887219031651813, 'Total loss': 0.48887219031651813} | train loss {'Reaction outcome loss': 0.3473537292169488, 'Total loss': 0.3473537292169488}
2023-01-05 13:08:43,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:43,974 INFO:     Epoch: 41
2023-01-05 13:08:46,140 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44512479106585184, 'Total loss': 0.44512479106585184} | train loss {'Reaction outcome loss': 0.38548205619461945, 'Total loss': 0.38548205619461945}
2023-01-05 13:08:46,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:46,141 INFO:     Epoch: 42
2023-01-05 13:08:48,316 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4469985475142797, 'Total loss': 0.4469985475142797} | train loss {'Reaction outcome loss': 0.3420438175054859, 'Total loss': 0.3420438175054859}
2023-01-05 13:08:48,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:48,317 INFO:     Epoch: 43
2023-01-05 13:08:50,481 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46180402239163715, 'Total loss': 0.46180402239163715} | train loss {'Reaction outcome loss': 0.3374704131822817, 'Total loss': 0.3374704131822817}
2023-01-05 13:08:50,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:50,481 INFO:     Epoch: 44
2023-01-05 13:08:52,643 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45029215117295585, 'Total loss': 0.45029215117295585} | train loss {'Reaction outcome loss': 0.33172287372070824, 'Total loss': 0.33172287372070824}
2023-01-05 13:08:52,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:52,644 INFO:     Epoch: 45
2023-01-05 13:08:54,787 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5006902138392131, 'Total loss': 0.5006902138392131} | train loss {'Reaction outcome loss': 0.3288056254608344, 'Total loss': 0.3288056254608344}
2023-01-05 13:08:54,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:54,787 INFO:     Epoch: 46
2023-01-05 13:08:56,908 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43846245209376017, 'Total loss': 0.43846245209376017} | train loss {'Reaction outcome loss': 0.33729782965088234, 'Total loss': 0.33729782965088234}
2023-01-05 13:08:56,909 INFO:     Found new best model at epoch 46
2023-01-05 13:08:56,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:56,910 INFO:     Epoch: 47
2023-01-05 13:08:59,055 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4648265262444814, 'Total loss': 0.4648265262444814} | train loss {'Reaction outcome loss': 0.3289778846992176, 'Total loss': 0.3289778846992176}
2023-01-05 13:08:59,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:08:59,055 INFO:     Epoch: 48
2023-01-05 13:09:01,209 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44225512941678363, 'Total loss': 0.44225512941678363} | train loss {'Reaction outcome loss': 0.32186338356763555, 'Total loss': 0.32186338356763555}
2023-01-05 13:09:01,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:01,209 INFO:     Epoch: 49
2023-01-05 13:09:03,367 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4558024168014526, 'Total loss': 0.4558024168014526} | train loss {'Reaction outcome loss': 0.3242171097216129, 'Total loss': 0.3242171097216129}
2023-01-05 13:09:03,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:03,367 INFO:     Epoch: 50
2023-01-05 13:09:05,510 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44483824670314787, 'Total loss': 0.44483824670314787} | train loss {'Reaction outcome loss': 0.32443212240584707, 'Total loss': 0.32443212240584707}
2023-01-05 13:09:05,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:05,511 INFO:     Epoch: 51
2023-01-05 13:09:07,661 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.455565278728803, 'Total loss': 0.455565278728803} | train loss {'Reaction outcome loss': 0.3164864317848604, 'Total loss': 0.3164864317848604}
2023-01-05 13:09:07,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:07,661 INFO:     Epoch: 52
2023-01-05 13:09:09,807 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4287409116824468, 'Total loss': 0.4287409116824468} | train loss {'Reaction outcome loss': 0.3101225460632739, 'Total loss': 0.3101225460632739}
2023-01-05 13:09:09,807 INFO:     Found new best model at epoch 52
2023-01-05 13:09:09,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:09,809 INFO:     Epoch: 53
2023-01-05 13:09:11,968 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43967755436897277, 'Total loss': 0.43967755436897277} | train loss {'Reaction outcome loss': 0.31503661460853927, 'Total loss': 0.31503661460853927}
2023-01-05 13:09:11,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:11,968 INFO:     Epoch: 54
2023-01-05 13:09:14,142 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4063158263762792, 'Total loss': 0.4063158263762792} | train loss {'Reaction outcome loss': 0.3044854468340497, 'Total loss': 0.3044854468340497}
2023-01-05 13:09:14,142 INFO:     Found new best model at epoch 54
2023-01-05 13:09:14,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:14,144 INFO:     Epoch: 55
2023-01-05 13:09:16,317 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4594194829463959, 'Total loss': 0.4594194829463959} | train loss {'Reaction outcome loss': 0.3042108612573719, 'Total loss': 0.3042108612573719}
2023-01-05 13:09:16,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:16,318 INFO:     Epoch: 56
2023-01-05 13:09:18,479 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4310087263584137, 'Total loss': 0.4310087263584137} | train loss {'Reaction outcome loss': 0.30248488503697235, 'Total loss': 0.30248488503697235}
2023-01-05 13:09:18,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:18,479 INFO:     Epoch: 57
2023-01-05 13:09:20,615 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4381762731820345, 'Total loss': 0.4381762731820345} | train loss {'Reaction outcome loss': 0.29923763536456705, 'Total loss': 0.29923763536456705}
2023-01-05 13:09:20,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:20,615 INFO:     Epoch: 58
2023-01-05 13:09:22,793 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4326683714985847, 'Total loss': 0.4326683714985847} | train loss {'Reaction outcome loss': 0.2963051548011709, 'Total loss': 0.2963051548011709}
2023-01-05 13:09:22,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:22,794 INFO:     Epoch: 59
2023-01-05 13:09:24,949 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47338196833928425, 'Total loss': 0.47338196833928425} | train loss {'Reaction outcome loss': 0.31191110060266825, 'Total loss': 0.31191110060266825}
2023-01-05 13:09:24,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:24,949 INFO:     Epoch: 60
2023-01-05 13:09:27,123 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47836409906546273, 'Total loss': 0.47836409906546273} | train loss {'Reaction outcome loss': 0.3724073392096097, 'Total loss': 0.3724073392096097}
2023-01-05 13:09:27,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:27,123 INFO:     Epoch: 61
2023-01-05 13:09:29,293 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49122103055318195, 'Total loss': 0.49122103055318195} | train loss {'Reaction outcome loss': 0.32309805560199506, 'Total loss': 0.32309805560199506}
2023-01-05 13:09:29,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:29,294 INFO:     Epoch: 62
2023-01-05 13:09:31,461 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4609501898288727, 'Total loss': 0.4609501898288727} | train loss {'Reaction outcome loss': 0.30963029819321347, 'Total loss': 0.30963029819321347}
2023-01-05 13:09:31,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:31,462 INFO:     Epoch: 63
2023-01-05 13:09:33,624 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4640102485815684, 'Total loss': 0.4640102485815684} | train loss {'Reaction outcome loss': 0.29861971896784584, 'Total loss': 0.29861971896784584}
2023-01-05 13:09:33,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:33,624 INFO:     Epoch: 64
2023-01-05 13:09:35,770 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46406605541706086, 'Total loss': 0.46406605541706086} | train loss {'Reaction outcome loss': 0.3147305027190326, 'Total loss': 0.3147305027190326}
2023-01-05 13:09:35,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:35,771 INFO:     Epoch: 65
2023-01-05 13:09:37,932 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4397544364134471, 'Total loss': 0.4397544364134471} | train loss {'Reaction outcome loss': 0.3376808907327148, 'Total loss': 0.3376808907327148}
2023-01-05 13:09:37,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:37,933 INFO:     Epoch: 66
2023-01-05 13:09:40,097 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47631071706612904, 'Total loss': 0.47631071706612904} | train loss {'Reaction outcome loss': 0.29988325905756885, 'Total loss': 0.29988325905756885}
2023-01-05 13:09:40,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:40,097 INFO:     Epoch: 67
2023-01-05 13:09:42,256 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45838309029738106, 'Total loss': 0.45838309029738106} | train loss {'Reaction outcome loss': 0.29336720857553295, 'Total loss': 0.29336720857553295}
2023-01-05 13:09:42,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:42,256 INFO:     Epoch: 68
2023-01-05 13:09:44,413 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42380578915278116, 'Total loss': 0.42380578915278116} | train loss {'Reaction outcome loss': 0.29201144847910904, 'Total loss': 0.29201144847910904}
2023-01-05 13:09:44,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:44,414 INFO:     Epoch: 69
2023-01-05 13:09:46,584 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4498868485291799, 'Total loss': 0.4498868485291799} | train loss {'Reaction outcome loss': 0.29625367859810375, 'Total loss': 0.29625367859810375}
2023-01-05 13:09:46,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:46,584 INFO:     Epoch: 70
2023-01-05 13:09:48,745 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44247600734233855, 'Total loss': 0.44247600734233855} | train loss {'Reaction outcome loss': 0.32769002125638985, 'Total loss': 0.32769002125638985}
2023-01-05 13:09:48,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:48,745 INFO:     Epoch: 71
2023-01-05 13:09:50,902 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43093638817469276, 'Total loss': 0.43093638817469276} | train loss {'Reaction outcome loss': 0.3060181251120926, 'Total loss': 0.3060181251120926}
2023-01-05 13:09:50,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:50,903 INFO:     Epoch: 72
2023-01-05 13:09:53,066 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42945950229962665, 'Total loss': 0.42945950229962665} | train loss {'Reaction outcome loss': 0.28180197060472617, 'Total loss': 0.28180197060472617}
2023-01-05 13:09:53,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:53,067 INFO:     Epoch: 73
2023-01-05 13:09:55,221 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4647154668966929, 'Total loss': 0.4647154668966929} | train loss {'Reaction outcome loss': 0.27543809582003514, 'Total loss': 0.27543809582003514}
2023-01-05 13:09:55,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:55,221 INFO:     Epoch: 74
2023-01-05 13:09:57,378 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44880271156628926, 'Total loss': 0.44880271156628926} | train loss {'Reaction outcome loss': 0.28761642835224455, 'Total loss': 0.28761642835224455}
2023-01-05 13:09:57,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:57,378 INFO:     Epoch: 75
2023-01-05 13:09:59,566 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44863337675730386, 'Total loss': 0.44863337675730386} | train loss {'Reaction outcome loss': 0.3261089426046912, 'Total loss': 0.3261089426046912}
2023-01-05 13:09:59,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:09:59,567 INFO:     Epoch: 76
2023-01-05 13:10:01,740 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4767003744840622, 'Total loss': 0.4767003744840622} | train loss {'Reaction outcome loss': 0.295278306308108, 'Total loss': 0.295278306308108}
2023-01-05 13:10:01,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:01,741 INFO:     Epoch: 77
2023-01-05 13:10:03,898 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4442366843422254, 'Total loss': 0.4442366843422254} | train loss {'Reaction outcome loss': 0.2824081795786143, 'Total loss': 0.2824081795786143}
2023-01-05 13:10:03,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:03,898 INFO:     Epoch: 78
2023-01-05 13:10:06,063 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4436156531174978, 'Total loss': 0.4436156531174978} | train loss {'Reaction outcome loss': 0.2813608587657918, 'Total loss': 0.2813608587657918}
2023-01-05 13:10:06,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:06,063 INFO:     Epoch: 79
2023-01-05 13:10:08,226 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5158222496509552, 'Total loss': 0.5158222496509552} | train loss {'Reaction outcome loss': 0.28610433928096973, 'Total loss': 0.28610433928096973}
2023-01-05 13:10:08,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:08,226 INFO:     Epoch: 80
2023-01-05 13:10:10,388 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4564675937096278, 'Total loss': 0.4564675937096278} | train loss {'Reaction outcome loss': 0.2803422979288397, 'Total loss': 0.2803422979288397}
2023-01-05 13:10:10,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:10,389 INFO:     Epoch: 81
2023-01-05 13:10:12,567 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4594805603226026, 'Total loss': 0.4594805603226026} | train loss {'Reaction outcome loss': 0.2716901470511389, 'Total loss': 0.2716901470511389}
2023-01-05 13:10:12,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:12,568 INFO:     Epoch: 82
2023-01-05 13:10:14,742 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4455749253431956, 'Total loss': 0.4455749253431956} | train loss {'Reaction outcome loss': 0.27573363112110266, 'Total loss': 0.27573363112110266}
2023-01-05 13:10:14,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:14,742 INFO:     Epoch: 83
2023-01-05 13:10:16,897 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44352284173170725, 'Total loss': 0.44352284173170725} | train loss {'Reaction outcome loss': 0.27098470333072805, 'Total loss': 0.27098470333072805}
2023-01-05 13:10:16,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:16,898 INFO:     Epoch: 84
2023-01-05 13:10:19,054 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46778404513994853, 'Total loss': 0.46778404513994853} | train loss {'Reaction outcome loss': 0.2654215740716925, 'Total loss': 0.2654215740716925}
2023-01-05 13:10:19,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:19,055 INFO:     Epoch: 85
2023-01-05 13:10:21,209 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4124012569586436, 'Total loss': 0.4124012569586436} | train loss {'Reaction outcome loss': 0.26447248656515276, 'Total loss': 0.26447248656515276}
2023-01-05 13:10:21,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:21,209 INFO:     Epoch: 86
2023-01-05 13:10:23,373 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40511054595311485, 'Total loss': 0.40511054595311485} | train loss {'Reaction outcome loss': 0.2635320269488358, 'Total loss': 0.2635320269488358}
2023-01-05 13:10:23,375 INFO:     Found new best model at epoch 86
2023-01-05 13:10:23,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:23,376 INFO:     Epoch: 87
2023-01-05 13:10:25,546 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42851039382318656, 'Total loss': 0.42851039382318656} | train loss {'Reaction outcome loss': 0.2616310371187232, 'Total loss': 0.2616310371187232}
2023-01-05 13:10:25,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:25,546 INFO:     Epoch: 88
2023-01-05 13:10:27,713 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4481407550474008, 'Total loss': 0.4481407550474008} | train loss {'Reaction outcome loss': 0.2646559816125048, 'Total loss': 0.2646559816125048}
2023-01-05 13:10:27,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:27,713 INFO:     Epoch: 89
2023-01-05 13:10:29,876 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4244475821654002, 'Total loss': 0.4244475821654002} | train loss {'Reaction outcome loss': 0.25973602611760516, 'Total loss': 0.25973602611760516}
2023-01-05 13:10:29,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:29,877 INFO:     Epoch: 90
2023-01-05 13:10:32,030 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4365529457728068, 'Total loss': 0.4365529457728068} | train loss {'Reaction outcome loss': 0.25789953755565215, 'Total loss': 0.25789953755565215}
2023-01-05 13:10:32,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:32,030 INFO:     Epoch: 91
2023-01-05 13:10:34,192 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45935042997201286, 'Total loss': 0.45935042997201286} | train loss {'Reaction outcome loss': 0.2615283567131922, 'Total loss': 0.2615283567131922}
2023-01-05 13:10:34,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:34,192 INFO:     Epoch: 92
2023-01-05 13:10:36,367 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41473128808041415, 'Total loss': 0.41473128808041415} | train loss {'Reaction outcome loss': 0.25395164515931107, 'Total loss': 0.25395164515931107}
2023-01-05 13:10:36,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:36,367 INFO:     Epoch: 93
2023-01-05 13:10:38,538 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4882928192615509, 'Total loss': 0.4882928192615509} | train loss {'Reaction outcome loss': 0.2594683200917696, 'Total loss': 0.2594683200917696}
2023-01-05 13:10:38,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:38,539 INFO:     Epoch: 94
2023-01-05 13:10:40,697 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43208659763137497, 'Total loss': 0.43208659763137497} | train loss {'Reaction outcome loss': 0.2553069373741206, 'Total loss': 0.2553069373741206}
2023-01-05 13:10:40,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:40,698 INFO:     Epoch: 95
2023-01-05 13:10:42,887 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46264806638161343, 'Total loss': 0.46264806638161343} | train loss {'Reaction outcome loss': 0.25393494486632934, 'Total loss': 0.25393494486632934}
2023-01-05 13:10:42,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:42,888 INFO:     Epoch: 96
2023-01-05 13:10:45,061 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45180313487847645, 'Total loss': 0.45180313487847645} | train loss {'Reaction outcome loss': 0.25465318325745023, 'Total loss': 0.25465318325745023}
2023-01-05 13:10:45,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:45,061 INFO:     Epoch: 97
2023-01-05 13:10:47,253 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4384655296802521, 'Total loss': 0.4384655296802521} | train loss {'Reaction outcome loss': 0.2790968808736922, 'Total loss': 0.2790968808736922}
2023-01-05 13:10:47,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:47,253 INFO:     Epoch: 98
2023-01-05 13:10:49,420 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42282905081907907, 'Total loss': 0.42282905081907907} | train loss {'Reaction outcome loss': 0.2545640403609699, 'Total loss': 0.2545640403609699}
2023-01-05 13:10:49,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:49,420 INFO:     Epoch: 99
2023-01-05 13:10:51,596 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46540839672088624, 'Total loss': 0.46540839672088624} | train loss {'Reaction outcome loss': 0.25159380164510314, 'Total loss': 0.25159380164510314}
2023-01-05 13:10:51,596 INFO:     Best model found after epoch 87 of 100.
2023-01-05 13:10:51,596 INFO:   Done with stage: TRAINING
2023-01-05 13:10:51,597 INFO:   Starting stage: EVALUATION
2023-01-05 13:10:51,729 INFO:   Done with stage: EVALUATION
2023-01-05 13:10:51,730 INFO:   Leaving out SEQ value Fold_2
2023-01-05 13:10:51,743 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 13:10:51,743 INFO:   Starting stage: FEATURE SCALING
2023-01-05 13:10:52,406 INFO:   Done with stage: FEATURE SCALING
2023-01-05 13:10:52,406 INFO:   Starting stage: SCALING TARGETS
2023-01-05 13:10:52,477 INFO:   Done with stage: SCALING TARGETS
2023-01-05 13:10:52,477 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:10:52,477 INFO:     No hyperparam tuning for this model
2023-01-05 13:10:52,477 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:10:52,477 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 13:10:52,478 INFO:     None feature selector for col prot
2023-01-05 13:10:52,478 INFO:     None feature selector for col prot
2023-01-05 13:10:52,478 INFO:     None feature selector for col prot
2023-01-05 13:10:52,479 INFO:     None feature selector for col chem
2023-01-05 13:10:52,479 INFO:     None feature selector for col chem
2023-01-05 13:10:52,479 INFO:     None feature selector for col chem
2023-01-05 13:10:52,479 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 13:10:52,479 INFO:   Starting stage: BUILD MODEL
2023-01-05 13:10:52,480 INFO:     Number of params in model 72901
2023-01-05 13:10:52,483 INFO:   Done with stage: BUILD MODEL
2023-01-05 13:10:52,484 INFO:   Starting stage: TRAINING
2023-01-05 13:10:52,542 INFO:     Val loss before train {'Reaction outcome loss': 0.9868196407953899, 'Total loss': 0.9868196407953899}
2023-01-05 13:10:52,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:52,542 INFO:     Epoch: 0
2023-01-05 13:10:54,694 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.765830413500468, 'Total loss': 0.765830413500468} | train loss {'Reaction outcome loss': 0.9059029896726538, 'Total loss': 0.9059029896726538}
2023-01-05 13:10:54,695 INFO:     Found new best model at epoch 0
2023-01-05 13:10:54,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:54,696 INFO:     Epoch: 1
2023-01-05 13:10:56,850 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5652305861314137, 'Total loss': 0.5652305861314137} | train loss {'Reaction outcome loss': 0.719995783225739, 'Total loss': 0.719995783225739}
2023-01-05 13:10:56,850 INFO:     Found new best model at epoch 1
2023-01-05 13:10:56,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:56,851 INFO:     Epoch: 2
2023-01-05 13:10:58,984 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5022250314553579, 'Total loss': 0.5022250314553579} | train loss {'Reaction outcome loss': 0.5811847605548062, 'Total loss': 0.5811847605548062}
2023-01-05 13:10:58,985 INFO:     Found new best model at epoch 2
2023-01-05 13:10:58,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:10:58,986 INFO:     Epoch: 3
2023-01-05 13:11:01,141 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4739004949728648, 'Total loss': 0.4739004949728648} | train loss {'Reaction outcome loss': 0.5289764652922476, 'Total loss': 0.5289764652922476}
2023-01-05 13:11:01,142 INFO:     Found new best model at epoch 3
2023-01-05 13:11:01,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:01,143 INFO:     Epoch: 4
2023-01-05 13:11:03,273 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5152660350004832, 'Total loss': 0.5152660350004832} | train loss {'Reaction outcome loss': 0.5134426656114313, 'Total loss': 0.5134426656114313}
2023-01-05 13:11:03,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:03,274 INFO:     Epoch: 5
2023-01-05 13:11:05,429 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5156726678212483, 'Total loss': 0.5156726678212483} | train loss {'Reaction outcome loss': 0.5028330632945993, 'Total loss': 0.5028330632945993}
2023-01-05 13:11:05,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:05,429 INFO:     Epoch: 6
2023-01-05 13:11:07,565 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4823006749153137, 'Total loss': 0.4823006749153137} | train loss {'Reaction outcome loss': 0.4910909790177267, 'Total loss': 0.4910909790177267}
2023-01-05 13:11:07,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:07,565 INFO:     Epoch: 7
2023-01-05 13:11:09,727 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4695942133665085, 'Total loss': 0.4695942133665085} | train loss {'Reaction outcome loss': 0.4833982235891915, 'Total loss': 0.4833982235891915}
2023-01-05 13:11:09,727 INFO:     Found new best model at epoch 7
2023-01-05 13:11:09,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:09,728 INFO:     Epoch: 8
2023-01-05 13:11:11,896 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48545093337694806, 'Total loss': 0.48545093337694806} | train loss {'Reaction outcome loss': 0.47957011375016784, 'Total loss': 0.47957011375016784}
2023-01-05 13:11:11,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:11,896 INFO:     Epoch: 9
2023-01-05 13:11:14,044 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4688350915908813, 'Total loss': 0.4688350915908813} | train loss {'Reaction outcome loss': 0.47097479620259325, 'Total loss': 0.47097479620259325}
2023-01-05 13:11:14,045 INFO:     Found new best model at epoch 9
2023-01-05 13:11:14,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:14,046 INFO:     Epoch: 10
2023-01-05 13:11:16,188 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4801686684290568, 'Total loss': 0.4801686684290568} | train loss {'Reaction outcome loss': 0.4695033516748484, 'Total loss': 0.4695033516748484}
2023-01-05 13:11:16,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:16,188 INFO:     Epoch: 11
2023-01-05 13:11:18,353 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47074023087819417, 'Total loss': 0.47074023087819417} | train loss {'Reaction outcome loss': 0.4624764977138994, 'Total loss': 0.4624764977138994}
2023-01-05 13:11:18,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:18,353 INFO:     Epoch: 12
2023-01-05 13:11:20,529 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4642261972030004, 'Total loss': 0.4642261972030004} | train loss {'Reaction outcome loss': 0.46001418284225815, 'Total loss': 0.46001418284225815}
2023-01-05 13:11:20,529 INFO:     Found new best model at epoch 12
2023-01-05 13:11:20,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:20,530 INFO:     Epoch: 13
2023-01-05 13:11:22,704 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4510780990123749, 'Total loss': 0.4510780990123749} | train loss {'Reaction outcome loss': 0.4531110213189335, 'Total loss': 0.4531110213189335}
2023-01-05 13:11:22,704 INFO:     Found new best model at epoch 13
2023-01-05 13:11:22,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:22,706 INFO:     Epoch: 14
2023-01-05 13:11:24,877 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.456544820467631, 'Total loss': 0.456544820467631} | train loss {'Reaction outcome loss': 0.448941568451705, 'Total loss': 0.448941568451705}
2023-01-05 13:11:24,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:24,878 INFO:     Epoch: 15
2023-01-05 13:11:27,032 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42659481167793273, 'Total loss': 0.42659481167793273} | train loss {'Reaction outcome loss': 0.4434607206355958, 'Total loss': 0.4434607206355958}
2023-01-05 13:11:27,032 INFO:     Found new best model at epoch 15
2023-01-05 13:11:27,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:27,033 INFO:     Epoch: 16
2023-01-05 13:11:29,192 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48247693677743275, 'Total loss': 0.48247693677743275} | train loss {'Reaction outcome loss': 0.4419730784910502, 'Total loss': 0.4419730784910502}
2023-01-05 13:11:29,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:29,194 INFO:     Epoch: 17
2023-01-05 13:11:31,349 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45213133891423546, 'Total loss': 0.45213133891423546} | train loss {'Reaction outcome loss': 0.43353627916875775, 'Total loss': 0.43353627916875775}
2023-01-05 13:11:31,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:31,349 INFO:     Epoch: 18
2023-01-05 13:11:33,490 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4196202645699183, 'Total loss': 0.4196202645699183} | train loss {'Reaction outcome loss': 0.4299742223306017, 'Total loss': 0.4299742223306017}
2023-01-05 13:11:33,490 INFO:     Found new best model at epoch 18
2023-01-05 13:11:33,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:33,492 INFO:     Epoch: 19
2023-01-05 13:11:35,635 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40386622250080106, 'Total loss': 0.40386622250080106} | train loss {'Reaction outcome loss': 0.4375335439875886, 'Total loss': 0.4375335439875886}
2023-01-05 13:11:35,636 INFO:     Found new best model at epoch 19
2023-01-05 13:11:35,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:35,637 INFO:     Epoch: 20
2023-01-05 13:11:37,780 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44369995991388955, 'Total loss': 0.44369995991388955} | train loss {'Reaction outcome loss': 0.42732020844142515, 'Total loss': 0.42732020844142515}
2023-01-05 13:11:37,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:37,780 INFO:     Epoch: 21
2023-01-05 13:11:39,916 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40929409066836037, 'Total loss': 0.40929409066836037} | train loss {'Reaction outcome loss': 0.4214335353840347, 'Total loss': 0.4214335353840347}
2023-01-05 13:11:39,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:39,916 INFO:     Epoch: 22
2023-01-05 13:11:42,082 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46176009277502694, 'Total loss': 0.46176009277502694} | train loss {'Reaction outcome loss': 0.4158144654644715, 'Total loss': 0.4158144654644715}
2023-01-05 13:11:42,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:42,082 INFO:     Epoch: 23
2023-01-05 13:11:44,323 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.439569898446401, 'Total loss': 0.439569898446401} | train loss {'Reaction outcome loss': 0.4116701625369407, 'Total loss': 0.4116701625369407}
2023-01-05 13:11:44,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:44,324 INFO:     Epoch: 24
2023-01-05 13:11:46,485 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43523718615372975, 'Total loss': 0.43523718615372975} | train loss {'Reaction outcome loss': 0.411437085205382, 'Total loss': 0.411437085205382}
2023-01-05 13:11:46,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:46,485 INFO:     Epoch: 25
2023-01-05 13:11:48,634 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4654855122168859, 'Total loss': 0.4654855122168859} | train loss {'Reaction outcome loss': 0.39920319751546385, 'Total loss': 0.39920319751546385}
2023-01-05 13:11:48,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:48,635 INFO:     Epoch: 26
2023-01-05 13:11:50,774 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4711101531982422, 'Total loss': 0.4711101531982422} | train loss {'Reaction outcome loss': 0.40292424250107545, 'Total loss': 0.40292424250107545}
2023-01-05 13:11:50,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:50,774 INFO:     Epoch: 27
2023-01-05 13:11:52,925 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4003590255975723, 'Total loss': 0.4003590255975723} | train loss {'Reaction outcome loss': 0.3987026215281897, 'Total loss': 0.3987026215281897}
2023-01-05 13:11:52,925 INFO:     Found new best model at epoch 27
2023-01-05 13:11:52,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:52,927 INFO:     Epoch: 28
2023-01-05 13:11:55,058 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4177408109108607, 'Total loss': 0.4177408109108607} | train loss {'Reaction outcome loss': 0.3889300689619758, 'Total loss': 0.3889300689619758}
2023-01-05 13:11:55,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:55,058 INFO:     Epoch: 29
2023-01-05 13:11:57,201 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4506461103757223, 'Total loss': 0.4506461103757223} | train loss {'Reaction outcome loss': 0.3872038816193958, 'Total loss': 0.3872038816193958}
2023-01-05 13:11:57,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:57,201 INFO:     Epoch: 30
2023-01-05 13:11:59,349 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40632430811723075, 'Total loss': 0.40632430811723075} | train loss {'Reaction outcome loss': 0.384321812417481, 'Total loss': 0.384321812417481}
2023-01-05 13:11:59,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:11:59,349 INFO:     Epoch: 31
2023-01-05 13:12:01,486 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4307403633991877, 'Total loss': 0.4307403633991877} | train loss {'Reaction outcome loss': 0.3853863769726002, 'Total loss': 0.3853863769726002}
2023-01-05 13:12:01,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:01,486 INFO:     Epoch: 32
2023-01-05 13:12:03,618 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.428199894229571, 'Total loss': 0.428199894229571} | train loss {'Reaction outcome loss': 0.38317697574367454, 'Total loss': 0.38317697574367454}
2023-01-05 13:12:03,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:03,618 INFO:     Epoch: 33
2023-01-05 13:12:05,744 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4296876788139343, 'Total loss': 0.4296876788139343} | train loss {'Reaction outcome loss': 0.3742721486058864, 'Total loss': 0.3742721486058864}
2023-01-05 13:12:05,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:05,746 INFO:     Epoch: 34
2023-01-05 13:12:07,883 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.438927149772644, 'Total loss': 0.438927149772644} | train loss {'Reaction outcome loss': 0.37010510661553986, 'Total loss': 0.37010510661553986}
2023-01-05 13:12:07,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:07,883 INFO:     Epoch: 35
2023-01-05 13:12:10,038 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40798004070917765, 'Total loss': 0.40798004070917765} | train loss {'Reaction outcome loss': 0.36766930369339584, 'Total loss': 0.36766930369339584}
2023-01-05 13:12:10,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:10,038 INFO:     Epoch: 36
2023-01-05 13:12:12,159 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4435660501321157, 'Total loss': 0.4435660501321157} | train loss {'Reaction outcome loss': 0.37182681797406614, 'Total loss': 0.37182681797406614}
2023-01-05 13:12:12,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:12,160 INFO:     Epoch: 37
2023-01-05 13:12:14,292 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43809326489766437, 'Total loss': 0.43809326489766437} | train loss {'Reaction outcome loss': 0.3616351259551642, 'Total loss': 0.3616351259551642}
2023-01-05 13:12:14,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:14,292 INFO:     Epoch: 38
2023-01-05 13:12:16,437 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.441525928179423, 'Total loss': 0.441525928179423} | train loss {'Reaction outcome loss': 0.3549124998460104, 'Total loss': 0.3549124998460104}
2023-01-05 13:12:16,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:16,437 INFO:     Epoch: 39
2023-01-05 13:12:18,569 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40959836579859255, 'Total loss': 0.40959836579859255} | train loss {'Reaction outcome loss': 0.3517920533843311, 'Total loss': 0.3517920533843311}
2023-01-05 13:12:18,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:18,570 INFO:     Epoch: 40
2023-01-05 13:12:20,509 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.462546173731486, 'Total loss': 0.462546173731486} | train loss {'Reaction outcome loss': 0.34891290250046675, 'Total loss': 0.34891290250046675}
2023-01-05 13:12:20,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:20,510 INFO:     Epoch: 41
2023-01-05 13:12:22,644 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4541594485441844, 'Total loss': 0.4541594485441844} | train loss {'Reaction outcome loss': 0.3477703784302477, 'Total loss': 0.3477703784302477}
2023-01-05 13:12:22,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:22,645 INFO:     Epoch: 42
2023-01-05 13:12:24,775 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39356529265642165, 'Total loss': 0.39356529265642165} | train loss {'Reaction outcome loss': 0.343338331978618, 'Total loss': 0.343338331978618}
2023-01-05 13:12:24,776 INFO:     Found new best model at epoch 42
2023-01-05 13:12:24,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:24,777 INFO:     Epoch: 43
2023-01-05 13:12:26,917 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4563207228978475, 'Total loss': 0.4563207228978475} | train loss {'Reaction outcome loss': 0.33806956246249625, 'Total loss': 0.33806956246249625}
2023-01-05 13:12:26,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:26,918 INFO:     Epoch: 44
2023-01-05 13:12:29,058 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4278847316900889, 'Total loss': 0.4278847316900889} | train loss {'Reaction outcome loss': 0.33541270806675866, 'Total loss': 0.33541270806675866}
2023-01-05 13:12:29,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:29,058 INFO:     Epoch: 45
2023-01-05 13:12:31,197 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41047953963279726, 'Total loss': 0.41047953963279726} | train loss {'Reaction outcome loss': 0.3325610382844022, 'Total loss': 0.3325610382844022}
2023-01-05 13:12:31,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:31,198 INFO:     Epoch: 46
2023-01-05 13:12:33,351 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42398979763189953, 'Total loss': 0.42398979763189953} | train loss {'Reaction outcome loss': 0.3347569287723892, 'Total loss': 0.3347569287723892}
2023-01-05 13:12:33,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:33,352 INFO:     Epoch: 47
2023-01-05 13:12:35,504 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4210319052139918, 'Total loss': 0.4210319052139918} | train loss {'Reaction outcome loss': 0.32391711834804476, 'Total loss': 0.32391711834804476}
2023-01-05 13:12:35,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:35,505 INFO:     Epoch: 48
2023-01-05 13:12:37,643 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38928964336713157, 'Total loss': 0.38928964336713157} | train loss {'Reaction outcome loss': 0.3300496127333615, 'Total loss': 0.3300496127333615}
2023-01-05 13:12:37,643 INFO:     Found new best model at epoch 48
2023-01-05 13:12:37,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:37,644 INFO:     Epoch: 49
2023-01-05 13:12:39,790 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43548475901285805, 'Total loss': 0.43548475901285805} | train loss {'Reaction outcome loss': 0.3246344533704576, 'Total loss': 0.3246344533704576}
2023-01-05 13:12:39,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:39,790 INFO:     Epoch: 50
2023-01-05 13:12:41,930 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44025446673234303, 'Total loss': 0.44025446673234303} | train loss {'Reaction outcome loss': 0.3230880603071425, 'Total loss': 0.3230880603071425}
2023-01-05 13:12:41,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:41,931 INFO:     Epoch: 51
2023-01-05 13:12:44,078 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4648759663105011, 'Total loss': 0.4648759663105011} | train loss {'Reaction outcome loss': 0.3223118598917465, 'Total loss': 0.3223118598917465}
2023-01-05 13:12:44,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:44,079 INFO:     Epoch: 52
2023-01-05 13:12:46,201 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4249368071556091, 'Total loss': 0.4249368071556091} | train loss {'Reaction outcome loss': 0.31846605694337643, 'Total loss': 0.31846605694337643}
2023-01-05 13:12:46,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:46,201 INFO:     Epoch: 53
2023-01-05 13:12:48,331 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4094677905241648, 'Total loss': 0.4094677905241648} | train loss {'Reaction outcome loss': 0.3183349078937328, 'Total loss': 0.3183349078937328}
2023-01-05 13:12:48,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:48,332 INFO:     Epoch: 54
2023-01-05 13:12:50,462 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4372489591439565, 'Total loss': 0.4372489591439565} | train loss {'Reaction outcome loss': 0.31328036368827955, 'Total loss': 0.31328036368827955}
2023-01-05 13:12:50,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:50,463 INFO:     Epoch: 55
2023-01-05 13:12:52,592 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4065602806707223, 'Total loss': 0.4065602806707223} | train loss {'Reaction outcome loss': 0.31051108183769077, 'Total loss': 0.31051108183769077}
2023-01-05 13:12:52,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:52,592 INFO:     Epoch: 56
2023-01-05 13:12:54,736 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48103928168614707, 'Total loss': 0.48103928168614707} | train loss {'Reaction outcome loss': 0.30236218290423955, 'Total loss': 0.30236218290423955}
2023-01-05 13:12:54,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:54,737 INFO:     Epoch: 57
2023-01-05 13:12:56,888 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4274812261263529, 'Total loss': 0.4274812261263529} | train loss {'Reaction outcome loss': 0.30325307773473936, 'Total loss': 0.30325307773473936}
2023-01-05 13:12:56,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:56,888 INFO:     Epoch: 58
2023-01-05 13:12:59,034 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4002273877461751, 'Total loss': 0.4002273877461751} | train loss {'Reaction outcome loss': 0.30807057069443955, 'Total loss': 0.30807057069443955}
2023-01-05 13:12:59,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:12:59,034 INFO:     Epoch: 59
2023-01-05 13:13:01,181 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42527999778588615, 'Total loss': 0.42527999778588615} | train loss {'Reaction outcome loss': 0.3071803798141715, 'Total loss': 0.3071803798141715}
2023-01-05 13:13:01,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:01,181 INFO:     Epoch: 60
2023-01-05 13:13:03,318 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3929017600913843, 'Total loss': 0.3929017600913843} | train loss {'Reaction outcome loss': 0.29679627579401485, 'Total loss': 0.29679627579401485}
2023-01-05 13:13:03,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:03,319 INFO:     Epoch: 61
2023-01-05 13:13:05,455 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41397571365038555, 'Total loss': 0.41397571365038555} | train loss {'Reaction outcome loss': 0.29723793889085454, 'Total loss': 0.29723793889085454}
2023-01-05 13:13:05,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:05,455 INFO:     Epoch: 62
2023-01-05 13:13:07,595 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47442384660243986, 'Total loss': 0.47442384660243986} | train loss {'Reaction outcome loss': 0.29493745445058894, 'Total loss': 0.29493745445058894}
2023-01-05 13:13:07,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:07,595 INFO:     Epoch: 63
2023-01-05 13:13:09,748 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39903356581926347, 'Total loss': 0.39903356581926347} | train loss {'Reaction outcome loss': 0.2981644656113434, 'Total loss': 0.2981644656113434}
2023-01-05 13:13:09,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:09,749 INFO:     Epoch: 64
2023-01-05 13:13:11,877 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4317177573839823, 'Total loss': 0.4317177573839823} | train loss {'Reaction outcome loss': 0.2925919899137029, 'Total loss': 0.2925919899137029}
2023-01-05 13:13:11,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:11,878 INFO:     Epoch: 65
2023-01-05 13:13:14,017 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4351950764656067, 'Total loss': 0.4351950764656067} | train loss {'Reaction outcome loss': 0.2959919072953718, 'Total loss': 0.2959919072953718}
2023-01-05 13:13:14,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:14,017 INFO:     Epoch: 66
2023-01-05 13:13:16,133 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41337867453694344, 'Total loss': 0.41337867453694344} | train loss {'Reaction outcome loss': 0.28998671178688934, 'Total loss': 0.28998671178688934}
2023-01-05 13:13:16,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:16,133 INFO:     Epoch: 67
2023-01-05 13:13:18,262 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.426704262693723, 'Total loss': 0.426704262693723} | train loss {'Reaction outcome loss': 0.2890575846363773, 'Total loss': 0.2890575846363773}
2023-01-05 13:13:18,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:18,263 INFO:     Epoch: 68
2023-01-05 13:13:20,411 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45278569459915163, 'Total loss': 0.45278569459915163} | train loss {'Reaction outcome loss': 0.2869927960792522, 'Total loss': 0.2869927960792522}
2023-01-05 13:13:20,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:20,412 INFO:     Epoch: 69
2023-01-05 13:13:22,547 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4056590142349402, 'Total loss': 0.4056590142349402} | train loss {'Reaction outcome loss': 0.2863591542201383, 'Total loss': 0.2863591542201383}
2023-01-05 13:13:22,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:22,547 INFO:     Epoch: 70
2023-01-05 13:13:24,703 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4044151730835438, 'Total loss': 0.4044151730835438} | train loss {'Reaction outcome loss': 0.29180817483436494, 'Total loss': 0.29180817483436494}
2023-01-05 13:13:24,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:24,703 INFO:     Epoch: 71
2023-01-05 13:13:26,852 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4273680756489436, 'Total loss': 0.4273680756489436} | train loss {'Reaction outcome loss': 0.28550256354795706, 'Total loss': 0.28550256354795706}
2023-01-05 13:13:26,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:26,852 INFO:     Epoch: 72
2023-01-05 13:13:28,969 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42972233692804973, 'Total loss': 0.42972233692804973} | train loss {'Reaction outcome loss': 0.281826203641219, 'Total loss': 0.281826203641219}
2023-01-05 13:13:28,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:28,969 INFO:     Epoch: 73
2023-01-05 13:13:31,121 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3867228110631307, 'Total loss': 0.3867228110631307} | train loss {'Reaction outcome loss': 0.28725637647326724, 'Total loss': 0.28725637647326724}
2023-01-05 13:13:31,122 INFO:     Found new best model at epoch 73
2023-01-05 13:13:31,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:31,123 INFO:     Epoch: 74
2023-01-05 13:13:33,268 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45554587530593077, 'Total loss': 0.45554587530593077} | train loss {'Reaction outcome loss': 0.2773453736398028, 'Total loss': 0.2773453736398028}
2023-01-05 13:13:33,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:33,269 INFO:     Epoch: 75
2023-01-05 13:13:35,381 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4529606988032659, 'Total loss': 0.4529606988032659} | train loss {'Reaction outcome loss': 0.2790672406349536, 'Total loss': 0.2790672406349536}
2023-01-05 13:13:35,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:35,381 INFO:     Epoch: 76
2023-01-05 13:13:37,518 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4339446226755778, 'Total loss': 0.4339446226755778} | train loss {'Reaction outcome loss': 0.2703884208963795, 'Total loss': 0.2703884208963795}
2023-01-05 13:13:37,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:37,518 INFO:     Epoch: 77
2023-01-05 13:13:39,644 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46066635350386304, 'Total loss': 0.46066635350386304} | train loss {'Reaction outcome loss': 0.268714771472982, 'Total loss': 0.268714771472982}
2023-01-05 13:13:39,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:39,644 INFO:     Epoch: 78
2023-01-05 13:13:41,791 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4584821343421936, 'Total loss': 0.4584821343421936} | train loss {'Reaction outcome loss': 0.27779342518648603, 'Total loss': 0.27779342518648603}
2023-01-05 13:13:41,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:41,791 INFO:     Epoch: 79
2023-01-05 13:13:43,931 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.415026393532753, 'Total loss': 0.415026393532753} | train loss {'Reaction outcome loss': 0.27061636024069435, 'Total loss': 0.27061636024069435}
2023-01-05 13:13:43,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:43,931 INFO:     Epoch: 80
2023-01-05 13:13:46,062 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41007535556952157, 'Total loss': 0.41007535556952157} | train loss {'Reaction outcome loss': 0.2599463429943327, 'Total loss': 0.2599463429943327}
2023-01-05 13:13:46,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:46,062 INFO:     Epoch: 81
2023-01-05 13:13:48,208 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4385491957267125, 'Total loss': 0.4385491957267125} | train loss {'Reaction outcome loss': 0.2701557008993058, 'Total loss': 0.2701557008993058}
2023-01-05 13:13:48,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:48,209 INFO:     Epoch: 82
2023-01-05 13:13:50,333 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4313334345817566, 'Total loss': 0.4313334345817566} | train loss {'Reaction outcome loss': 0.2669069460514701, 'Total loss': 0.2669069460514701}
2023-01-05 13:13:50,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:50,333 INFO:     Epoch: 83
2023-01-05 13:13:52,448 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4019792715087533, 'Total loss': 0.4019792715087533} | train loss {'Reaction outcome loss': 0.2606983545471679, 'Total loss': 0.2606983545471679}
2023-01-05 13:13:52,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:52,449 INFO:     Epoch: 84
2023-01-05 13:13:54,573 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3916482220093409, 'Total loss': 0.3916482220093409} | train loss {'Reaction outcome loss': 0.26375601103276886, 'Total loss': 0.26375601103276886}
2023-01-05 13:13:54,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:54,574 INFO:     Epoch: 85
2023-01-05 13:13:56,708 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4195950776338577, 'Total loss': 0.4195950776338577} | train loss {'Reaction outcome loss': 0.27257105132953807, 'Total loss': 0.27257105132953807}
2023-01-05 13:13:56,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:56,708 INFO:     Epoch: 86
2023-01-05 13:13:58,831 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4090808222691218, 'Total loss': 0.4090808222691218} | train loss {'Reaction outcome loss': 0.25640272815803905, 'Total loss': 0.25640272815803905}
2023-01-05 13:13:58,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:13:58,831 INFO:     Epoch: 87
2023-01-05 13:14:00,974 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4527472138404846, 'Total loss': 0.4527472138404846} | train loss {'Reaction outcome loss': 0.26731055914919016, 'Total loss': 0.26731055914919016}
2023-01-05 13:14:00,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:00,975 INFO:     Epoch: 88
2023-01-05 13:14:03,103 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39020519852638247, 'Total loss': 0.39020519852638247} | train loss {'Reaction outcome loss': 0.2572391686326527, 'Total loss': 0.2572391686326527}
2023-01-05 13:14:03,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:03,103 INFO:     Epoch: 89
2023-01-05 13:14:05,249 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39362883965174356, 'Total loss': 0.39362883965174356} | train loss {'Reaction outcome loss': 0.26670889336711323, 'Total loss': 0.26670889336711323}
2023-01-05 13:14:05,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:05,250 INFO:     Epoch: 90
2023-01-05 13:14:07,390 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4467718650897344, 'Total loss': 0.4467718650897344} | train loss {'Reaction outcome loss': 0.2613559324881096, 'Total loss': 0.2613559324881096}
2023-01-05 13:14:07,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:07,391 INFO:     Epoch: 91
2023-01-05 13:14:09,537 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4188599720597267, 'Total loss': 0.4188599720597267} | train loss {'Reaction outcome loss': 0.2720474589193042, 'Total loss': 0.2720474589193042}
2023-01-05 13:14:09,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:09,537 INFO:     Epoch: 92
2023-01-05 13:14:11,667 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44802016814549767, 'Total loss': 0.44802016814549767} | train loss {'Reaction outcome loss': 0.2597845524665473, 'Total loss': 0.2597845524665473}
2023-01-05 13:14:11,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:11,668 INFO:     Epoch: 93
2023-01-05 13:14:13,801 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3959337890148163, 'Total loss': 0.3959337890148163} | train loss {'Reaction outcome loss': 0.25447333013918594, 'Total loss': 0.25447333013918594}
2023-01-05 13:14:13,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:13,801 INFO:     Epoch: 94
2023-01-05 13:14:15,928 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4353535443544388, 'Total loss': 0.4353535443544388} | train loss {'Reaction outcome loss': 0.2515987932763912, 'Total loss': 0.2515987932763912}
2023-01-05 13:14:15,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:15,928 INFO:     Epoch: 95
2023-01-05 13:14:18,041 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4054779993991057, 'Total loss': 0.4054779993991057} | train loss {'Reaction outcome loss': 0.2636454058026438, 'Total loss': 0.2636454058026438}
2023-01-05 13:14:18,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:18,043 INFO:     Epoch: 96
2023-01-05 13:14:20,167 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4176024317741394, 'Total loss': 0.4176024317741394} | train loss {'Reaction outcome loss': 0.2634362639524998, 'Total loss': 0.2634362639524998}
2023-01-05 13:14:20,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:20,168 INFO:     Epoch: 97
2023-01-05 13:14:22,296 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4402011344830195, 'Total loss': 0.4402011344830195} | train loss {'Reaction outcome loss': 0.2519022380070072, 'Total loss': 0.2519022380070072}
2023-01-05 13:14:22,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:22,296 INFO:     Epoch: 98
2023-01-05 13:14:24,414 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4340943346420924, 'Total loss': 0.4340943346420924} | train loss {'Reaction outcome loss': 0.25132588725946436, 'Total loss': 0.25132588725946436}
2023-01-05 13:14:24,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:24,415 INFO:     Epoch: 99
2023-01-05 13:14:26,521 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4263601352771123, 'Total loss': 0.4263601352771123} | train loss {'Reaction outcome loss': 0.24483603654231453, 'Total loss': 0.24483603654231453}
2023-01-05 13:14:26,521 INFO:     Best model found after epoch 74 of 100.
2023-01-05 13:14:26,521 INFO:   Done with stage: TRAINING
2023-01-05 13:14:26,522 INFO:   Starting stage: EVALUATION
2023-01-05 13:14:26,667 INFO:   Done with stage: EVALUATION
2023-01-05 13:14:26,667 INFO:   Leaving out SEQ value Fold_3
2023-01-05 13:14:26,679 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-05 13:14:26,680 INFO:   Starting stage: FEATURE SCALING
2023-01-05 13:14:27,330 INFO:   Done with stage: FEATURE SCALING
2023-01-05 13:14:27,330 INFO:   Starting stage: SCALING TARGETS
2023-01-05 13:14:27,399 INFO:   Done with stage: SCALING TARGETS
2023-01-05 13:14:27,399 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:14:27,399 INFO:     No hyperparam tuning for this model
2023-01-05 13:14:27,399 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:14:27,399 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 13:14:27,400 INFO:     None feature selector for col prot
2023-01-05 13:14:27,400 INFO:     None feature selector for col prot
2023-01-05 13:14:27,400 INFO:     None feature selector for col prot
2023-01-05 13:14:27,401 INFO:     None feature selector for col chem
2023-01-05 13:14:27,401 INFO:     None feature selector for col chem
2023-01-05 13:14:27,401 INFO:     None feature selector for col chem
2023-01-05 13:14:27,401 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 13:14:27,401 INFO:   Starting stage: BUILD MODEL
2023-01-05 13:14:27,402 INFO:     Number of params in model 72901
2023-01-05 13:14:27,406 INFO:   Done with stage: BUILD MODEL
2023-01-05 13:14:27,406 INFO:   Starting stage: TRAINING
2023-01-05 13:14:27,464 INFO:     Val loss before train {'Reaction outcome loss': 1.0425872008005779, 'Total loss': 1.0425872008005779}
2023-01-05 13:14:27,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:27,464 INFO:     Epoch: 0
2023-01-05 13:14:29,581 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7679687837759653, 'Total loss': 0.7679687837759653} | train loss {'Reaction outcome loss': 0.9118451944576418, 'Total loss': 0.9118451944576418}
2023-01-05 13:14:29,581 INFO:     Found new best model at epoch 0
2023-01-05 13:14:29,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:29,582 INFO:     Epoch: 1
2023-01-05 13:14:31,691 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5692818760871887, 'Total loss': 0.5692818760871887} | train loss {'Reaction outcome loss': 0.7167037758989968, 'Total loss': 0.7167037758989968}
2023-01-05 13:14:31,691 INFO:     Found new best model at epoch 1
2023-01-05 13:14:31,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:31,692 INFO:     Epoch: 2
2023-01-05 13:14:33,803 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44655980033179127, 'Total loss': 0.44655980033179127} | train loss {'Reaction outcome loss': 0.5727709294245252, 'Total loss': 0.5727709294245252}
2023-01-05 13:14:33,803 INFO:     Found new best model at epoch 2
2023-01-05 13:14:33,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:33,805 INFO:     Epoch: 3
2023-01-05 13:14:35,915 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44204149742921195, 'Total loss': 0.44204149742921195} | train loss {'Reaction outcome loss': 0.5194961500123858, 'Total loss': 0.5194961500123858}
2023-01-05 13:14:35,915 INFO:     Found new best model at epoch 3
2023-01-05 13:14:35,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:35,916 INFO:     Epoch: 4
2023-01-05 13:14:38,025 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4342635174592336, 'Total loss': 0.4342635174592336} | train loss {'Reaction outcome loss': 0.501207740214478, 'Total loss': 0.501207740214478}
2023-01-05 13:14:38,026 INFO:     Found new best model at epoch 4
2023-01-05 13:14:38,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:38,028 INFO:     Epoch: 5
2023-01-05 13:14:40,145 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42724937399228413, 'Total loss': 0.42724937399228413} | train loss {'Reaction outcome loss': 0.4887676874100062, 'Total loss': 0.4887676874100062}
2023-01-05 13:14:40,145 INFO:     Found new best model at epoch 5
2023-01-05 13:14:40,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:40,146 INFO:     Epoch: 6
2023-01-05 13:14:42,272 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4136050596833229, 'Total loss': 0.4136050596833229} | train loss {'Reaction outcome loss': 0.47737236260488025, 'Total loss': 0.47737236260488025}
2023-01-05 13:14:42,273 INFO:     Found new best model at epoch 6
2023-01-05 13:14:42,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:42,274 INFO:     Epoch: 7
2023-01-05 13:14:44,384 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.406301545103391, 'Total loss': 0.406301545103391} | train loss {'Reaction outcome loss': 0.46542553455187385, 'Total loss': 0.46542553455187385}
2023-01-05 13:14:44,385 INFO:     Found new best model at epoch 7
2023-01-05 13:14:44,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:44,386 INFO:     Epoch: 8
2023-01-05 13:14:46,507 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47528859178225197, 'Total loss': 0.47528859178225197} | train loss {'Reaction outcome loss': 0.46362861916697773, 'Total loss': 0.46362861916697773}
2023-01-05 13:14:46,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:46,508 INFO:     Epoch: 9
2023-01-05 13:14:48,636 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4341858704884847, 'Total loss': 0.4341858704884847} | train loss {'Reaction outcome loss': 0.4597085437211603, 'Total loss': 0.4597085437211603}
2023-01-05 13:14:48,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:48,637 INFO:     Epoch: 10
2023-01-05 13:14:50,743 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.378071716427803, 'Total loss': 0.378071716427803} | train loss {'Reaction outcome loss': 0.4480474329522615, 'Total loss': 0.4480474329522615}
2023-01-05 13:14:50,743 INFO:     Found new best model at epoch 10
2023-01-05 13:14:50,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:50,745 INFO:     Epoch: 11
2023-01-05 13:14:52,857 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4001077915231387, 'Total loss': 0.4001077915231387} | train loss {'Reaction outcome loss': 0.440745257418534, 'Total loss': 0.440745257418534}
2023-01-05 13:14:52,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:52,857 INFO:     Epoch: 12
2023-01-05 13:14:54,973 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.425148872534434, 'Total loss': 0.425148872534434} | train loss {'Reaction outcome loss': 0.4393904056826201, 'Total loss': 0.4393904056826201}
2023-01-05 13:14:54,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:54,974 INFO:     Epoch: 13
2023-01-05 13:14:57,088 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40986196597417196, 'Total loss': 0.40986196597417196} | train loss {'Reaction outcome loss': 0.4386968705871888, 'Total loss': 0.4386968705871888}
2023-01-05 13:14:57,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:57,088 INFO:     Epoch: 14
2023-01-05 13:14:59,221 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.404279429713885, 'Total loss': 0.404279429713885} | train loss {'Reaction outcome loss': 0.42757911779453833, 'Total loss': 0.42757911779453833}
2023-01-05 13:14:59,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:14:59,222 INFO:     Epoch: 15
2023-01-05 13:15:01,325 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3929496556520462, 'Total loss': 0.3929496556520462} | train loss {'Reaction outcome loss': 0.42701737159292635, 'Total loss': 0.42701737159292635}
2023-01-05 13:15:01,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:01,326 INFO:     Epoch: 16
2023-01-05 13:15:03,458 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3770880450805028, 'Total loss': 0.3770880450805028} | train loss {'Reaction outcome loss': 0.42703452577120266, 'Total loss': 0.42703452577120266}
2023-01-05 13:15:03,458 INFO:     Found new best model at epoch 16
2023-01-05 13:15:03,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:03,459 INFO:     Epoch: 17
2023-01-05 13:15:05,578 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39013307690620425, 'Total loss': 0.39013307690620425} | train loss {'Reaction outcome loss': 0.4197932273919292, 'Total loss': 0.4197932273919292}
2023-01-05 13:15:05,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:05,578 INFO:     Epoch: 18
2023-01-05 13:15:07,692 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38923294643561046, 'Total loss': 0.38923294643561046} | train loss {'Reaction outcome loss': 0.41344424576337047, 'Total loss': 0.41344424576337047}
2023-01-05 13:15:07,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:07,692 INFO:     Epoch: 19
2023-01-05 13:15:09,859 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3656538188457489, 'Total loss': 0.3656538188457489} | train loss {'Reaction outcome loss': 0.41426706949173303, 'Total loss': 0.41426706949173303}
2023-01-05 13:15:09,859 INFO:     Found new best model at epoch 19
2023-01-05 13:15:09,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:09,861 INFO:     Epoch: 20
2023-01-05 13:15:12,039 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3655709390838941, 'Total loss': 0.3655709390838941} | train loss {'Reaction outcome loss': 0.409196818982873, 'Total loss': 0.409196818982873}
2023-01-05 13:15:12,039 INFO:     Found new best model at epoch 20
2023-01-05 13:15:12,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:12,040 INFO:     Epoch: 21
2023-01-05 13:15:14,194 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39675336678822837, 'Total loss': 0.39675336678822837} | train loss {'Reaction outcome loss': 0.4021561102068732, 'Total loss': 0.4021561102068732}
2023-01-05 13:15:14,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:14,195 INFO:     Epoch: 22
2023-01-05 13:15:16,378 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.35779817700386046, 'Total loss': 0.35779817700386046} | train loss {'Reaction outcome loss': 0.4028232347536351, 'Total loss': 0.4028232347536351}
2023-01-05 13:15:16,378 INFO:     Found new best model at epoch 22
2023-01-05 13:15:16,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:16,379 INFO:     Epoch: 23
2023-01-05 13:15:18,513 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3775030334790548, 'Total loss': 0.3775030334790548} | train loss {'Reaction outcome loss': 0.3973491431877182, 'Total loss': 0.3973491431877182}
2023-01-05 13:15:18,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:18,514 INFO:     Epoch: 24
2023-01-05 13:15:20,683 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.35638695359230044, 'Total loss': 0.35638695359230044} | train loss {'Reaction outcome loss': 0.3872488663150376, 'Total loss': 0.3872488663150376}
2023-01-05 13:15:20,683 INFO:     Found new best model at epoch 24
2023-01-05 13:15:20,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:20,684 INFO:     Epoch: 25
2023-01-05 13:15:22,841 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.34841897487640383, 'Total loss': 0.34841897487640383} | train loss {'Reaction outcome loss': 0.3930317855189207, 'Total loss': 0.3930317855189207}
2023-01-05 13:15:22,842 INFO:     Found new best model at epoch 25
2023-01-05 13:15:22,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:22,843 INFO:     Epoch: 26
2023-01-05 13:15:25,011 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3970697889725367, 'Total loss': 0.3970697889725367} | train loss {'Reaction outcome loss': 0.38863678353519016, 'Total loss': 0.38863678353519016}
2023-01-05 13:15:25,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:25,012 INFO:     Epoch: 27
2023-01-05 13:15:27,178 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.365693207581838, 'Total loss': 0.365693207581838} | train loss {'Reaction outcome loss': 0.3841981876545287, 'Total loss': 0.3841981876545287}
2023-01-05 13:15:27,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:27,178 INFO:     Epoch: 28
2023-01-05 13:15:29,319 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3574452579021454, 'Total loss': 0.3574452579021454} | train loss {'Reaction outcome loss': 0.38362124666736575, 'Total loss': 0.38362124666736575}
2023-01-05 13:15:29,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:29,319 INFO:     Epoch: 29
2023-01-05 13:15:31,502 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3743799606959025, 'Total loss': 0.3743799606959025} | train loss {'Reaction outcome loss': 0.3771574497772759, 'Total loss': 0.3771574497772759}
2023-01-05 13:15:31,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:31,503 INFO:     Epoch: 30
2023-01-05 13:15:33,676 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3450835198163986, 'Total loss': 0.3450835198163986} | train loss {'Reaction outcome loss': 0.37212452171473487, 'Total loss': 0.37212452171473487}
2023-01-05 13:15:33,676 INFO:     Found new best model at epoch 30
2023-01-05 13:15:33,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:33,678 INFO:     Epoch: 31
2023-01-05 13:15:35,838 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.34255190591017404, 'Total loss': 0.34255190591017404} | train loss {'Reaction outcome loss': 0.371267078245038, 'Total loss': 0.371267078245038}
2023-01-05 13:15:35,838 INFO:     Found new best model at epoch 31
2023-01-05 13:15:35,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:35,840 INFO:     Epoch: 32
2023-01-05 13:15:37,978 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.37587103943030037, 'Total loss': 0.37587103943030037} | train loss {'Reaction outcome loss': 0.3699518414111155, 'Total loss': 0.3699518414111155}
2023-01-05 13:15:37,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:37,979 INFO:     Epoch: 33
2023-01-05 13:15:40,102 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.35634226898352306, 'Total loss': 0.35634226898352306} | train loss {'Reaction outcome loss': 0.36895681499775046, 'Total loss': 0.36895681499775046}
2023-01-05 13:15:40,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:40,102 INFO:     Epoch: 34
2023-01-05 13:15:41,845 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3660546610752741, 'Total loss': 0.3660546610752741} | train loss {'Reaction outcome loss': 0.3654950660450652, 'Total loss': 0.3654950660450652}
2023-01-05 13:15:41,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:41,846 INFO:     Epoch: 35
2023-01-05 13:15:43,581 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3629339704910914, 'Total loss': 0.3629339704910914} | train loss {'Reaction outcome loss': 0.35316098871816126, 'Total loss': 0.35316098871816126}
2023-01-05 13:15:43,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:43,582 INFO:     Epoch: 36
2023-01-05 13:15:45,516 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38275919953982035, 'Total loss': 0.38275919953982035} | train loss {'Reaction outcome loss': 0.35617617799512136, 'Total loss': 0.35617617799512136}
2023-01-05 13:15:45,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:45,516 INFO:     Epoch: 37
2023-01-05 13:15:47,637 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3555322679380576, 'Total loss': 0.3555322679380576} | train loss {'Reaction outcome loss': 0.3516616389375331, 'Total loss': 0.3516616389375331}
2023-01-05 13:15:47,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:47,637 INFO:     Epoch: 38
2023-01-05 13:15:49,821 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.34833944886922835, 'Total loss': 0.34833944886922835} | train loss {'Reaction outcome loss': 0.3524212235124349, 'Total loss': 0.3524212235124349}
2023-01-05 13:15:49,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:49,821 INFO:     Epoch: 39
2023-01-05 13:15:51,939 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.34912288437287015, 'Total loss': 0.34912288437287015} | train loss {'Reaction outcome loss': 0.3458997824150258, 'Total loss': 0.3458997824150258}
2023-01-05 13:15:51,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:51,939 INFO:     Epoch: 40
2023-01-05 13:15:54,075 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.33003107011318206, 'Total loss': 0.33003107011318206} | train loss {'Reaction outcome loss': 0.347282107933201, 'Total loss': 0.347282107933201}
2023-01-05 13:15:54,075 INFO:     Found new best model at epoch 40
2023-01-05 13:15:54,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:54,077 INFO:     Epoch: 41
2023-01-05 13:15:56,186 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.365702619155248, 'Total loss': 0.365702619155248} | train loss {'Reaction outcome loss': 0.3386180654608016, 'Total loss': 0.3386180654608016}
2023-01-05 13:15:56,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:56,186 INFO:     Epoch: 42
2023-01-05 13:15:58,305 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.36582876443862916, 'Total loss': 0.36582876443862916} | train loss {'Reaction outcome loss': 0.3378531486620762, 'Total loss': 0.3378531486620762}
2023-01-05 13:15:58,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:15:58,306 INFO:     Epoch: 43
2023-01-05 13:16:00,420 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3829537053902944, 'Total loss': 0.3829537053902944} | train loss {'Reaction outcome loss': 0.3367988067744403, 'Total loss': 0.3367988067744403}
2023-01-05 13:16:00,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:00,422 INFO:     Epoch: 44
2023-01-05 13:16:02,529 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3886802459756533, 'Total loss': 0.3886802459756533} | train loss {'Reaction outcome loss': 0.3334596520805271, 'Total loss': 0.3334596520805271}
2023-01-05 13:16:02,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:02,530 INFO:     Epoch: 45
2023-01-05 13:16:04,643 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3522911181052526, 'Total loss': 0.3522911181052526} | train loss {'Reaction outcome loss': 0.3318223939500612, 'Total loss': 0.3318223939500612}
2023-01-05 13:16:04,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:04,644 INFO:     Epoch: 46
2023-01-05 13:16:06,770 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3987608850002289, 'Total loss': 0.3987608850002289} | train loss {'Reaction outcome loss': 0.3297529012184741, 'Total loss': 0.3297529012184741}
2023-01-05 13:16:06,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:06,771 INFO:     Epoch: 47
2023-01-05 13:16:08,899 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.36786961555480957, 'Total loss': 0.36786961555480957} | train loss {'Reaction outcome loss': 0.32859217804406404, 'Total loss': 0.32859217804406404}
2023-01-05 13:16:08,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:08,900 INFO:     Epoch: 48
2023-01-05 13:16:11,016 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.33015999595324197, 'Total loss': 0.33015999595324197} | train loss {'Reaction outcome loss': 0.3190714266027472, 'Total loss': 0.3190714266027472}
2023-01-05 13:16:11,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:11,016 INFO:     Epoch: 49
2023-01-05 13:16:13,145 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3219098274906476, 'Total loss': 0.3219098274906476} | train loss {'Reaction outcome loss': 0.31414932741120294, 'Total loss': 0.31414932741120294}
2023-01-05 13:16:13,145 INFO:     Found new best model at epoch 49
2023-01-05 13:16:13,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:13,147 INFO:     Epoch: 50
2023-01-05 13:16:15,299 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3749527861674627, 'Total loss': 0.3749527861674627} | train loss {'Reaction outcome loss': 0.32052878933749074, 'Total loss': 0.32052878933749074}
2023-01-05 13:16:15,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:15,299 INFO:     Epoch: 51
2023-01-05 13:16:17,439 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3258313534160455, 'Total loss': 0.3258313534160455} | train loss {'Reaction outcome loss': 0.31510808639145865, 'Total loss': 0.31510808639145865}
2023-01-05 13:16:17,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:17,439 INFO:     Epoch: 52
2023-01-05 13:16:19,559 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3636086752017339, 'Total loss': 0.3636086752017339} | train loss {'Reaction outcome loss': 0.3127158676236318, 'Total loss': 0.3127158676236318}
2023-01-05 13:16:19,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:19,560 INFO:     Epoch: 53
2023-01-05 13:16:21,689 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.35115305085976917, 'Total loss': 0.35115305085976917} | train loss {'Reaction outcome loss': 0.3091206313196803, 'Total loss': 0.3091206313196803}
2023-01-05 13:16:21,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:21,689 INFO:     Epoch: 54
2023-01-05 13:16:23,808 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39870176315307615, 'Total loss': 0.39870176315307615} | train loss {'Reaction outcome loss': 0.30680337894666676, 'Total loss': 0.30680337894666676}
2023-01-05 13:16:23,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:23,808 INFO:     Epoch: 55
2023-01-05 13:16:25,893 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3282497853040695, 'Total loss': 0.3282497853040695} | train loss {'Reaction outcome loss': 0.3081060607137495, 'Total loss': 0.3081060607137495}
2023-01-05 13:16:25,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:25,894 INFO:     Epoch: 56
2023-01-05 13:16:27,854 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.31503875758498906, 'Total loss': 0.31503875758498906} | train loss {'Reaction outcome loss': 0.3000316217926596, 'Total loss': 0.3000316217926596}
2023-01-05 13:16:27,854 INFO:     Found new best model at epoch 56
2023-01-05 13:16:27,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:27,856 INFO:     Epoch: 57
2023-01-05 13:16:29,971 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3221446911493937, 'Total loss': 0.3221446911493937} | train loss {'Reaction outcome loss': 0.2927909675037069, 'Total loss': 0.2927909675037069}
2023-01-05 13:16:29,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:29,971 INFO:     Epoch: 58
2023-01-05 13:16:32,086 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3447504997253418, 'Total loss': 0.3447504997253418} | train loss {'Reaction outcome loss': 0.2953750219993376, 'Total loss': 0.2953750219993376}
2023-01-05 13:16:32,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:32,086 INFO:     Epoch: 59
2023-01-05 13:16:34,208 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3570702850818634, 'Total loss': 0.3570702850818634} | train loss {'Reaction outcome loss': 0.29486180095490055, 'Total loss': 0.29486180095490055}
2023-01-05 13:16:34,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:34,208 INFO:     Epoch: 60
2023-01-05 13:16:36,340 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.340886719028155, 'Total loss': 0.340886719028155} | train loss {'Reaction outcome loss': 0.29230071239970706, 'Total loss': 0.29230071239970706}
2023-01-05 13:16:36,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:36,342 INFO:     Epoch: 61
2023-01-05 13:16:38,468 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.35635251700878146, 'Total loss': 0.35635251700878146} | train loss {'Reaction outcome loss': 0.2928810860700493, 'Total loss': 0.2928810860700493}
2023-01-05 13:16:38,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:38,468 INFO:     Epoch: 62
2023-01-05 13:16:40,599 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3311542054017385, 'Total loss': 0.3311542054017385} | train loss {'Reaction outcome loss': 0.2898838896840481, 'Total loss': 0.2898838896840481}
2023-01-05 13:16:40,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:40,599 INFO:     Epoch: 63
2023-01-05 13:16:42,724 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3712968721985817, 'Total loss': 0.3712968721985817} | train loss {'Reaction outcome loss': 0.28226475141310164, 'Total loss': 0.28226475141310164}
2023-01-05 13:16:42,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:42,724 INFO:     Epoch: 64
2023-01-05 13:16:44,848 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.35124079684416454, 'Total loss': 0.35124079684416454} | train loss {'Reaction outcome loss': 0.2857841951050882, 'Total loss': 0.2857841951050882}
2023-01-05 13:16:44,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:44,848 INFO:     Epoch: 65
2023-01-05 13:16:46,954 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.34405617266893385, 'Total loss': 0.34405617266893385} | train loss {'Reaction outcome loss': 0.28528238744285933, 'Total loss': 0.28528238744285933}
2023-01-05 13:16:46,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:46,954 INFO:     Epoch: 66
2023-01-05 13:16:49,086 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3647829194863637, 'Total loss': 0.3647829194863637} | train loss {'Reaction outcome loss': 0.2769926928011254, 'Total loss': 0.2769926928011254}
2023-01-05 13:16:49,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:49,086 INFO:     Epoch: 67
2023-01-05 13:16:51,222 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3507928168401122, 'Total loss': 0.3507928168401122} | train loss {'Reaction outcome loss': 0.28331965073681953, 'Total loss': 0.28331965073681953}
2023-01-05 13:16:51,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:51,222 INFO:     Epoch: 68
2023-01-05 13:16:53,361 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3114039187630018, 'Total loss': 0.3114039187630018} | train loss {'Reaction outcome loss': 0.27907636468178454, 'Total loss': 0.27907636468178454}
2023-01-05 13:16:53,361 INFO:     Found new best model at epoch 68
2023-01-05 13:16:53,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:53,362 INFO:     Epoch: 69
2023-01-05 13:16:55,467 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3512243390083313, 'Total loss': 0.3512243390083313} | train loss {'Reaction outcome loss': 0.2852722486666648, 'Total loss': 0.2852722486666648}
2023-01-05 13:16:55,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:55,468 INFO:     Epoch: 70
2023-01-05 13:16:57,583 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3358169953028361, 'Total loss': 0.3358169953028361} | train loss {'Reaction outcome loss': 0.27076024969015616, 'Total loss': 0.27076024969015616}
2023-01-05 13:16:57,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:57,584 INFO:     Epoch: 71
2023-01-05 13:16:59,711 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3458364595969518, 'Total loss': 0.3458364595969518} | train loss {'Reaction outcome loss': 0.27313972503716655, 'Total loss': 0.27313972503716655}
2023-01-05 13:16:59,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:16:59,711 INFO:     Epoch: 72
2023-01-05 13:17:01,834 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.32425872882207235, 'Total loss': 0.32425872882207235} | train loss {'Reaction outcome loss': 0.2796038543853593, 'Total loss': 0.2796038543853593}
2023-01-05 13:17:01,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:01,834 INFO:     Epoch: 73
2023-01-05 13:17:03,956 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.36501484711964927, 'Total loss': 0.36501484711964927} | train loss {'Reaction outcome loss': 0.27108554240158067, 'Total loss': 0.27108554240158067}
2023-01-05 13:17:03,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:03,957 INFO:     Epoch: 74
2023-01-05 13:17:06,072 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3257539709409078, 'Total loss': 0.3257539709409078} | train loss {'Reaction outcome loss': 0.26818591082722937, 'Total loss': 0.26818591082722937}
2023-01-05 13:17:06,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:06,072 INFO:     Epoch: 75
2023-01-05 13:17:08,209 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3977085307240486, 'Total loss': 0.3977085307240486} | train loss {'Reaction outcome loss': 0.2681387392219802, 'Total loss': 0.2681387392219802}
2023-01-05 13:17:08,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:08,210 INFO:     Epoch: 76
2023-01-05 13:17:10,328 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37046738316615424, 'Total loss': 0.37046738316615424} | train loss {'Reaction outcome loss': 0.2690798129054728, 'Total loss': 0.2690798129054728}
2023-01-05 13:17:10,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:10,328 INFO:     Epoch: 77
2023-01-05 13:17:12,457 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.337729474902153, 'Total loss': 0.337729474902153} | train loss {'Reaction outcome loss': 0.26658112508316983, 'Total loss': 0.26658112508316983}
2023-01-05 13:17:12,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:12,459 INFO:     Epoch: 78
2023-01-05 13:17:14,572 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3470080256462097, 'Total loss': 0.3470080256462097} | train loss {'Reaction outcome loss': 0.26747108994539814, 'Total loss': 0.26747108994539814}
2023-01-05 13:17:14,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:14,572 INFO:     Epoch: 79
2023-01-05 13:17:16,702 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3653993676106135, 'Total loss': 0.3653993676106135} | train loss {'Reaction outcome loss': 0.2557120585360485, 'Total loss': 0.2557120585360485}
2023-01-05 13:17:16,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:16,703 INFO:     Epoch: 80
2023-01-05 13:17:18,822 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3454166760047277, 'Total loss': 0.3454166760047277} | train loss {'Reaction outcome loss': 0.2566426346057895, 'Total loss': 0.2566426346057895}
2023-01-05 13:17:18,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:18,823 INFO:     Epoch: 81
2023-01-05 13:17:20,934 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.33174970547358196, 'Total loss': 0.33174970547358196} | train loss {'Reaction outcome loss': 0.2561736152923195, 'Total loss': 0.2561736152923195}
2023-01-05 13:17:20,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:20,934 INFO:     Epoch: 82
2023-01-05 13:17:22,693 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3338092789053917, 'Total loss': 0.3338092789053917} | train loss {'Reaction outcome loss': 0.26511721764570895, 'Total loss': 0.26511721764570895}
2023-01-05 13:17:22,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:22,694 INFO:     Epoch: 83
2023-01-05 13:17:24,438 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3664145112037659, 'Total loss': 0.3664145112037659} | train loss {'Reaction outcome loss': 0.2611096697237439, 'Total loss': 0.2611096697237439}
2023-01-05 13:17:24,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:24,439 INFO:     Epoch: 84
2023-01-05 13:17:26,383 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.31822323525945345, 'Total loss': 0.31822323525945345} | train loss {'Reaction outcome loss': 0.25076482872516465, 'Total loss': 0.25076482872516465}
2023-01-05 13:17:26,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:26,384 INFO:     Epoch: 85
2023-01-05 13:17:28,499 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3895966559648514, 'Total loss': 0.3895966559648514} | train loss {'Reaction outcome loss': 0.2504112554844675, 'Total loss': 0.2504112554844675}
2023-01-05 13:17:28,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:28,500 INFO:     Epoch: 86
2023-01-05 13:17:30,628 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37207888066768646, 'Total loss': 0.37207888066768646} | train loss {'Reaction outcome loss': 0.247689806151709, 'Total loss': 0.247689806151709}
2023-01-05 13:17:30,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:30,628 INFO:     Epoch: 87
2023-01-05 13:17:32,740 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.33536139925320946, 'Total loss': 0.33536139925320946} | train loss {'Reaction outcome loss': 0.2543097774453489, 'Total loss': 0.2543097774453489}
2023-01-05 13:17:32,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:32,742 INFO:     Epoch: 88
2023-01-05 13:17:34,864 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3343132977684339, 'Total loss': 0.3343132977684339} | train loss {'Reaction outcome loss': 0.2425780381966121, 'Total loss': 0.2425780381966121}
2023-01-05 13:17:34,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:34,864 INFO:     Epoch: 89
2023-01-05 13:17:36,986 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3582199821869532, 'Total loss': 0.3582199821869532} | train loss {'Reaction outcome loss': 0.2557974915686871, 'Total loss': 0.2557974915686871}
2023-01-05 13:17:36,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:36,986 INFO:     Epoch: 90
2023-01-05 13:17:39,098 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3360197633504868, 'Total loss': 0.3360197633504868} | train loss {'Reaction outcome loss': 0.24653382646435412, 'Total loss': 0.24653382646435412}
2023-01-05 13:17:39,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:39,099 INFO:     Epoch: 91
2023-01-05 13:17:41,233 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.31475446162124476, 'Total loss': 0.31475446162124476} | train loss {'Reaction outcome loss': 0.24253803745901892, 'Total loss': 0.24253803745901892}
2023-01-05 13:17:41,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:41,233 INFO:     Epoch: 92
2023-01-05 13:17:43,368 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3746565282344818, 'Total loss': 0.3746565282344818} | train loss {'Reaction outcome loss': 0.2436281683067774, 'Total loss': 0.2436281683067774}
2023-01-05 13:17:43,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:43,368 INFO:     Epoch: 93
2023-01-05 13:17:45,481 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3689123292764028, 'Total loss': 0.3689123292764028} | train loss {'Reaction outcome loss': 0.2404022379623678, 'Total loss': 0.2404022379623678}
2023-01-05 13:17:45,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:45,482 INFO:     Epoch: 94
2023-01-05 13:17:47,610 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3289648284514745, 'Total loss': 0.3289648284514745} | train loss {'Reaction outcome loss': 0.24987082188172313, 'Total loss': 0.24987082188172313}
2023-01-05 13:17:47,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:47,610 INFO:     Epoch: 95
2023-01-05 13:17:49,721 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3288963456948598, 'Total loss': 0.3288963456948598} | train loss {'Reaction outcome loss': 0.2390696999936526, 'Total loss': 0.2390696999936526}
2023-01-05 13:17:49,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:49,721 INFO:     Epoch: 96
2023-01-05 13:17:51,845 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.32983204821745554, 'Total loss': 0.32983204821745554} | train loss {'Reaction outcome loss': 0.2458327089563507, 'Total loss': 0.2458327089563507}
2023-01-05 13:17:51,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:51,846 INFO:     Epoch: 97
2023-01-05 13:17:53,981 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.32785782758146526, 'Total loss': 0.32785782758146526} | train loss {'Reaction outcome loss': 0.2393894696099567, 'Total loss': 0.2393894696099567}
2023-01-05 13:17:53,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:53,981 INFO:     Epoch: 98
2023-01-05 13:17:56,112 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.36473165452480316, 'Total loss': 0.36473165452480316} | train loss {'Reaction outcome loss': 0.24678347996570088, 'Total loss': 0.24678347996570088}
2023-01-05 13:17:56,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:56,114 INFO:     Epoch: 99
2023-01-05 13:17:58,234 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.32912101956705253, 'Total loss': 0.32912101956705253} | train loss {'Reaction outcome loss': 0.23820238469625613, 'Total loss': 0.23820238469625613}
2023-01-05 13:17:58,234 INFO:     Best model found after epoch 69 of 100.
2023-01-05 13:17:58,235 INFO:   Done with stage: TRAINING
2023-01-05 13:17:58,235 INFO:   Starting stage: EVALUATION
2023-01-05 13:17:58,386 INFO:   Done with stage: EVALUATION
2023-01-05 13:17:58,386 INFO:   Leaving out SEQ value Fold_4
2023-01-05 13:17:58,399 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 13:17:58,399 INFO:   Starting stage: FEATURE SCALING
2023-01-05 13:17:59,048 INFO:   Done with stage: FEATURE SCALING
2023-01-05 13:17:59,048 INFO:   Starting stage: SCALING TARGETS
2023-01-05 13:17:59,117 INFO:   Done with stage: SCALING TARGETS
2023-01-05 13:17:59,118 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:17:59,118 INFO:     No hyperparam tuning for this model
2023-01-05 13:17:59,118 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:17:59,118 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 13:17:59,119 INFO:     None feature selector for col prot
2023-01-05 13:17:59,119 INFO:     None feature selector for col prot
2023-01-05 13:17:59,119 INFO:     None feature selector for col prot
2023-01-05 13:17:59,119 INFO:     None feature selector for col chem
2023-01-05 13:17:59,119 INFO:     None feature selector for col chem
2023-01-05 13:17:59,119 INFO:     None feature selector for col chem
2023-01-05 13:17:59,120 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 13:17:59,120 INFO:   Starting stage: BUILD MODEL
2023-01-05 13:17:59,121 INFO:     Number of params in model 72901
2023-01-05 13:17:59,124 INFO:   Done with stage: BUILD MODEL
2023-01-05 13:17:59,124 INFO:   Starting stage: TRAINING
2023-01-05 13:17:59,184 INFO:     Val loss before train {'Reaction outcome loss': 1.0988352696100872, 'Total loss': 1.0988352696100872}
2023-01-05 13:17:59,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:17:59,184 INFO:     Epoch: 0
2023-01-05 13:18:01,336 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8874886711438497, 'Total loss': 0.8874886711438497} | train loss {'Reaction outcome loss': 0.9166263002848279, 'Total loss': 0.9166263002848279}
2023-01-05 13:18:01,336 INFO:     Found new best model at epoch 0
2023-01-05 13:18:01,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:01,337 INFO:     Epoch: 1
2023-01-05 13:18:03,489 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5957639336585998, 'Total loss': 0.5957639336585998} | train loss {'Reaction outcome loss': 0.7397256934124491, 'Total loss': 0.7397256934124491}
2023-01-05 13:18:03,490 INFO:     Found new best model at epoch 1
2023-01-05 13:18:03,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:03,491 INFO:     Epoch: 2
2023-01-05 13:18:05,652 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5065429985523224, 'Total loss': 0.5065429985523224} | train loss {'Reaction outcome loss': 0.5721630449195906, 'Total loss': 0.5721630449195906}
2023-01-05 13:18:05,653 INFO:     Found new best model at epoch 2
2023-01-05 13:18:05,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:05,654 INFO:     Epoch: 3
2023-01-05 13:18:07,798 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.476603372891744, 'Total loss': 0.476603372891744} | train loss {'Reaction outcome loss': 0.5355028607275175, 'Total loss': 0.5355028607275175}
2023-01-05 13:18:07,799 INFO:     Found new best model at epoch 3
2023-01-05 13:18:07,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:07,801 INFO:     Epoch: 4
2023-01-05 13:18:09,966 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4666991651058197, 'Total loss': 0.4666991651058197} | train loss {'Reaction outcome loss': 0.5266037610548454, 'Total loss': 0.5266037610548454}
2023-01-05 13:18:09,966 INFO:     Found new best model at epoch 4
2023-01-05 13:18:09,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:09,967 INFO:     Epoch: 5
2023-01-05 13:18:12,123 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.475540229678154, 'Total loss': 0.475540229678154} | train loss {'Reaction outcome loss': 0.4977859417381494, 'Total loss': 0.4977859417381494}
2023-01-05 13:18:12,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:12,123 INFO:     Epoch: 6
2023-01-05 13:18:14,286 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4617610325415929, 'Total loss': 0.4617610325415929} | train loss {'Reaction outcome loss': 0.492714226712385, 'Total loss': 0.492714226712385}
2023-01-05 13:18:14,287 INFO:     Found new best model at epoch 6
2023-01-05 13:18:14,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:14,289 INFO:     Epoch: 7
2023-01-05 13:18:16,443 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48784850239753724, 'Total loss': 0.48784850239753724} | train loss {'Reaction outcome loss': 0.48170436481418816, 'Total loss': 0.48170436481418816}
2023-01-05 13:18:16,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:16,443 INFO:     Epoch: 8
2023-01-05 13:18:18,599 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4534149299065272, 'Total loss': 0.4534149299065272} | train loss {'Reaction outcome loss': 0.48082773894935416, 'Total loss': 0.48082773894935416}
2023-01-05 13:18:18,599 INFO:     Found new best model at epoch 8
2023-01-05 13:18:18,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:18,600 INFO:     Epoch: 9
2023-01-05 13:18:20,757 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4718869596719742, 'Total loss': 0.4718869596719742} | train loss {'Reaction outcome loss': 0.47599599598164577, 'Total loss': 0.47599599598164577}
2023-01-05 13:18:20,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:20,759 INFO:     Epoch: 10
2023-01-05 13:18:22,906 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4569091846545537, 'Total loss': 0.4569091846545537} | train loss {'Reaction outcome loss': 0.4642321851502672, 'Total loss': 0.4642321851502672}
2023-01-05 13:18:22,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:22,906 INFO:     Epoch: 11
2023-01-05 13:18:25,042 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43810453116893766, 'Total loss': 0.43810453116893766} | train loss {'Reaction outcome loss': 0.4621911908135466, 'Total loss': 0.4621911908135466}
2023-01-05 13:18:25,042 INFO:     Found new best model at epoch 11
2023-01-05 13:18:25,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:25,043 INFO:     Epoch: 12
2023-01-05 13:18:27,214 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4280324319998423, 'Total loss': 0.4280324319998423} | train loss {'Reaction outcome loss': 0.4500739806318197, 'Total loss': 0.4500739806318197}
2023-01-05 13:18:27,216 INFO:     Found new best model at epoch 12
2023-01-05 13:18:27,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:27,217 INFO:     Epoch: 13
2023-01-05 13:18:29,387 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47929309705893197, 'Total loss': 0.47929309705893197} | train loss {'Reaction outcome loss': 0.44218521220339596, 'Total loss': 0.44218521220339596}
2023-01-05 13:18:29,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:29,387 INFO:     Epoch: 14
2023-01-05 13:18:31,558 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45695416033267977, 'Total loss': 0.45695416033267977} | train loss {'Reaction outcome loss': 0.45584343902874686, 'Total loss': 0.45584343902874686}
2023-01-05 13:18:31,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:31,558 INFO:     Epoch: 15
2023-01-05 13:18:33,732 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4572177151838938, 'Total loss': 0.4572177151838938} | train loss {'Reaction outcome loss': 0.4614530228942201, 'Total loss': 0.4614530228942201}
2023-01-05 13:18:33,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:33,733 INFO:     Epoch: 16
2023-01-05 13:18:35,893 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4356129686037699, 'Total loss': 0.4356129686037699} | train loss {'Reaction outcome loss': 0.43601625338466704, 'Total loss': 0.43601625338466704}
2023-01-05 13:18:35,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:35,893 INFO:     Epoch: 17
2023-01-05 13:18:38,036 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46313814918200175, 'Total loss': 0.46313814918200175} | train loss {'Reaction outcome loss': 0.43219916558102367, 'Total loss': 0.43219916558102367}
2023-01-05 13:18:38,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:38,036 INFO:     Epoch: 18
2023-01-05 13:18:40,210 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4271705408891042, 'Total loss': 0.4271705408891042} | train loss {'Reaction outcome loss': 0.42883856911077234, 'Total loss': 0.42883856911077234}
2023-01-05 13:18:40,212 INFO:     Found new best model at epoch 18
2023-01-05 13:18:40,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:40,213 INFO:     Epoch: 19
2023-01-05 13:18:42,378 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4472176104784012, 'Total loss': 0.4472176104784012} | train loss {'Reaction outcome loss': 0.42149056218234665, 'Total loss': 0.42149056218234665}
2023-01-05 13:18:42,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:42,378 INFO:     Epoch: 20
2023-01-05 13:18:44,548 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4207579414049784, 'Total loss': 0.4207579414049784} | train loss {'Reaction outcome loss': 0.41440509147165966, 'Total loss': 0.41440509147165966}
2023-01-05 13:18:44,548 INFO:     Found new best model at epoch 20
2023-01-05 13:18:44,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:44,549 INFO:     Epoch: 21
2023-01-05 13:18:46,713 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3983145445585251, 'Total loss': 0.3983145445585251} | train loss {'Reaction outcome loss': 0.41390044782715646, 'Total loss': 0.41390044782715646}
2023-01-05 13:18:46,714 INFO:     Found new best model at epoch 21
2023-01-05 13:18:46,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:46,715 INFO:     Epoch: 22
2023-01-05 13:18:48,884 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4147737443447113, 'Total loss': 0.4147737443447113} | train loss {'Reaction outcome loss': 0.4081950497854015, 'Total loss': 0.4081950497854015}
2023-01-05 13:18:48,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:48,884 INFO:     Epoch: 23
2023-01-05 13:18:51,068 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4155995359023412, 'Total loss': 0.4155995359023412} | train loss {'Reaction outcome loss': 0.4058337600334831, 'Total loss': 0.4058337600334831}
2023-01-05 13:18:51,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:51,070 INFO:     Epoch: 24
2023-01-05 13:18:53,241 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.411608890692393, 'Total loss': 0.411608890692393} | train loss {'Reaction outcome loss': 0.42536603962999187, 'Total loss': 0.42536603962999187}
2023-01-05 13:18:53,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:53,242 INFO:     Epoch: 25
2023-01-05 13:18:55,414 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43287389278411864, 'Total loss': 0.43287389278411864} | train loss {'Reaction outcome loss': 0.39796403628196975, 'Total loss': 0.39796403628196975}
2023-01-05 13:18:55,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:55,415 INFO:     Epoch: 26
2023-01-05 13:18:57,585 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4888478378454844, 'Total loss': 0.4888478378454844} | train loss {'Reaction outcome loss': 0.39230315271171107, 'Total loss': 0.39230315271171107}
2023-01-05 13:18:57,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:57,586 INFO:     Epoch: 27
2023-01-05 13:18:59,752 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4419511506954829, 'Total loss': 0.4419511506954829} | train loss {'Reaction outcome loss': 0.4957792432843775, 'Total loss': 0.4957792432843775}
2023-01-05 13:18:59,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:18:59,752 INFO:     Epoch: 28
2023-01-05 13:19:01,930 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41975552439689634, 'Total loss': 0.41975552439689634} | train loss {'Reaction outcome loss': 0.40902075174170127, 'Total loss': 0.40902075174170127}
2023-01-05 13:19:01,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:01,931 INFO:     Epoch: 29
2023-01-05 13:19:04,098 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4015502800544103, 'Total loss': 0.4015502800544103} | train loss {'Reaction outcome loss': 0.38278443253332534, 'Total loss': 0.38278443253332534}
2023-01-05 13:19:04,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:04,098 INFO:     Epoch: 30
2023-01-05 13:19:06,270 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3961451013882955, 'Total loss': 0.3961451013882955} | train loss {'Reaction outcome loss': 0.3819624401520992, 'Total loss': 0.3819624401520992}
2023-01-05 13:19:06,270 INFO:     Found new best model at epoch 30
2023-01-05 13:19:06,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:06,272 INFO:     Epoch: 31
2023-01-05 13:19:08,440 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4050840973854065, 'Total loss': 0.4050840973854065} | train loss {'Reaction outcome loss': 0.37764943479049945, 'Total loss': 0.37764943479049945}
2023-01-05 13:19:08,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:08,441 INFO:     Epoch: 32
2023-01-05 13:19:10,609 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40524246692657473, 'Total loss': 0.40524246692657473} | train loss {'Reaction outcome loss': 0.36671379177156876, 'Total loss': 0.36671379177156876}
2023-01-05 13:19:10,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:10,609 INFO:     Epoch: 33
2023-01-05 13:19:12,777 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.37856108049551646, 'Total loss': 0.37856108049551646} | train loss {'Reaction outcome loss': 0.36611697779617447, 'Total loss': 0.36611697779617447}
2023-01-05 13:19:12,778 INFO:     Found new best model at epoch 33
2023-01-05 13:19:12,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:12,779 INFO:     Epoch: 34
2023-01-05 13:19:14,951 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38819555640220643, 'Total loss': 0.38819555640220643} | train loss {'Reaction outcome loss': 0.364583743520189, 'Total loss': 0.364583743520189}
2023-01-05 13:19:14,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:14,951 INFO:     Epoch: 35
2023-01-05 13:19:17,135 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39662306308746337, 'Total loss': 0.39662306308746337} | train loss {'Reaction outcome loss': 0.3596433809497799, 'Total loss': 0.3596433809497799}
2023-01-05 13:19:17,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:17,135 INFO:     Epoch: 36
2023-01-05 13:19:19,318 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38150868316491443, 'Total loss': 0.38150868316491443} | train loss {'Reaction outcome loss': 0.35773088805633935, 'Total loss': 0.35773088805633935}
2023-01-05 13:19:19,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:19,319 INFO:     Epoch: 37
2023-01-05 13:19:21,498 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3825890630483627, 'Total loss': 0.3825890630483627} | train loss {'Reaction outcome loss': 0.3551586261141431, 'Total loss': 0.3551586261141431}
2023-01-05 13:19:21,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:21,498 INFO:     Epoch: 38
2023-01-05 13:19:23,649 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4188469042380651, 'Total loss': 0.4188469042380651} | train loss {'Reaction outcome loss': 0.3650135868701382, 'Total loss': 0.3650135868701382}
2023-01-05 13:19:23,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:23,650 INFO:     Epoch: 39
2023-01-05 13:19:25,819 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3850337386131287, 'Total loss': 0.3850337386131287} | train loss {'Reaction outcome loss': 0.4065563657887928, 'Total loss': 0.4065563657887928}
2023-01-05 13:19:25,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:25,821 INFO:     Epoch: 40
2023-01-05 13:19:27,982 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3801151086886724, 'Total loss': 0.3801151086886724} | train loss {'Reaction outcome loss': 0.3492798910373349, 'Total loss': 0.3492798910373349}
2023-01-05 13:19:27,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:27,982 INFO:     Epoch: 41
2023-01-05 13:19:30,161 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38076203465461733, 'Total loss': 0.38076203465461733} | train loss {'Reaction outcome loss': 0.33906821403913945, 'Total loss': 0.33906821403913945}
2023-01-05 13:19:30,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:30,162 INFO:     Epoch: 42
2023-01-05 13:19:32,352 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38996249487002693, 'Total loss': 0.38996249487002693} | train loss {'Reaction outcome loss': 0.3432313887321431, 'Total loss': 0.3432313887321431}
2023-01-05 13:19:32,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:32,353 INFO:     Epoch: 43
2023-01-05 13:19:34,499 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38315065602461496, 'Total loss': 0.38315065602461496} | train loss {'Reaction outcome loss': 0.3400789921971686, 'Total loss': 0.3400789921971686}
2023-01-05 13:19:34,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:34,500 INFO:     Epoch: 44
2023-01-05 13:19:36,679 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3845239281654358, 'Total loss': 0.3845239281654358} | train loss {'Reaction outcome loss': 0.3307507352768966, 'Total loss': 0.3307507352768966}
2023-01-05 13:19:36,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:36,681 INFO:     Epoch: 45
2023-01-05 13:19:38,843 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3950074543555578, 'Total loss': 0.3950074543555578} | train loss {'Reaction outcome loss': 0.32838471528995644, 'Total loss': 0.32838471528995644}
2023-01-05 13:19:38,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:38,843 INFO:     Epoch: 46
2023-01-05 13:19:41,021 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3920055905977885, 'Total loss': 0.3920055905977885} | train loss {'Reaction outcome loss': 0.32788019393582, 'Total loss': 0.32788019393582}
2023-01-05 13:19:41,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:41,021 INFO:     Epoch: 47
2023-01-05 13:19:43,197 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45112687945365904, 'Total loss': 0.45112687945365904} | train loss {'Reaction outcome loss': 0.3310379375015264, 'Total loss': 0.3310379375015264}
2023-01-05 13:19:43,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:43,198 INFO:     Epoch: 48
2023-01-05 13:19:45,369 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4098529557387034, 'Total loss': 0.4098529557387034} | train loss {'Reaction outcome loss': 0.4036545352605374, 'Total loss': 0.4036545352605374}
2023-01-05 13:19:45,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:45,369 INFO:     Epoch: 49
2023-01-05 13:19:47,538 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38791505843400953, 'Total loss': 0.38791505843400953} | train loss {'Reaction outcome loss': 0.3405049912415553, 'Total loss': 0.3405049912415553}
2023-01-05 13:19:47,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:47,539 INFO:     Epoch: 50
2023-01-05 13:19:49,712 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3774525115887324, 'Total loss': 0.3774525115887324} | train loss {'Reaction outcome loss': 0.32481217008097557, 'Total loss': 0.32481217008097557}
2023-01-05 13:19:49,712 INFO:     Found new best model at epoch 50
2023-01-05 13:19:49,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:49,713 INFO:     Epoch: 51
2023-01-05 13:19:51,897 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3502289603153865, 'Total loss': 0.3502289603153865} | train loss {'Reaction outcome loss': 0.3151022744216565, 'Total loss': 0.3151022744216565}
2023-01-05 13:19:51,897 INFO:     Found new best model at epoch 51
2023-01-05 13:19:51,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:51,898 INFO:     Epoch: 52
2023-01-05 13:19:54,065 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.35803222209215163, 'Total loss': 0.35803222209215163} | train loss {'Reaction outcome loss': 0.315214588436757, 'Total loss': 0.315214588436757}
2023-01-05 13:19:54,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:54,067 INFO:     Epoch: 53
2023-01-05 13:19:56,228 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37578794062137605, 'Total loss': 0.37578794062137605} | train loss {'Reaction outcome loss': 0.3048903818143763, 'Total loss': 0.3048903818143763}
2023-01-05 13:19:56,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:56,228 INFO:     Epoch: 54
2023-01-05 13:19:58,401 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4300190329551697, 'Total loss': 0.4300190329551697} | train loss {'Reaction outcome loss': 0.3117951471653003, 'Total loss': 0.3117951471653003}
2023-01-05 13:19:58,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:19:58,402 INFO:     Epoch: 55
2023-01-05 13:20:00,586 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3903060962756475, 'Total loss': 0.3903060962756475} | train loss {'Reaction outcome loss': 0.30178716226710356, 'Total loss': 0.30178716226710356}
2023-01-05 13:20:00,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:00,587 INFO:     Epoch: 56
2023-01-05 13:20:02,756 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3953679939111074, 'Total loss': 0.3953679939111074} | train loss {'Reaction outcome loss': 0.3086071409895827, 'Total loss': 0.3086071409895827}
2023-01-05 13:20:02,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:02,757 INFO:     Epoch: 57
2023-01-05 13:20:04,931 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3848958690961202, 'Total loss': 0.3848958690961202} | train loss {'Reaction outcome loss': 0.29646843093581515, 'Total loss': 0.29646843093581515}
2023-01-05 13:20:04,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:04,932 INFO:     Epoch: 58
2023-01-05 13:20:07,100 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3835278511047363, 'Total loss': 0.3835278511047363} | train loss {'Reaction outcome loss': 0.2994859922526276, 'Total loss': 0.2994859922526276}
2023-01-05 13:20:07,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:07,100 INFO:     Epoch: 59
2023-01-05 13:20:09,257 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41163448989391327, 'Total loss': 0.41163448989391327} | train loss {'Reaction outcome loss': 0.29347250956124155, 'Total loss': 0.29347250956124155}
2023-01-05 13:20:09,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:09,257 INFO:     Epoch: 60
2023-01-05 13:20:11,413 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37149774432182314, 'Total loss': 0.37149774432182314} | train loss {'Reaction outcome loss': 0.2863531727630618, 'Total loss': 0.2863531727630618}
2023-01-05 13:20:11,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:11,414 INFO:     Epoch: 61
2023-01-05 13:20:13,579 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40573109686374664, 'Total loss': 0.40573109686374664} | train loss {'Reaction outcome loss': 0.2852633247085327, 'Total loss': 0.2852633247085327}
2023-01-05 13:20:13,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:13,579 INFO:     Epoch: 62
2023-01-05 13:20:15,770 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.34574382851521174, 'Total loss': 0.34574382851521174} | train loss {'Reaction outcome loss': 0.2920750497310571, 'Total loss': 0.2920750497310571}
2023-01-05 13:20:15,770 INFO:     Found new best model at epoch 62
2023-01-05 13:20:15,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:15,772 INFO:     Epoch: 63
2023-01-05 13:20:17,937 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.35942118366559345, 'Total loss': 0.35942118366559345} | train loss {'Reaction outcome loss': 0.2921160057271861, 'Total loss': 0.2921160057271861}
2023-01-05 13:20:17,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:17,938 INFO:     Epoch: 64
2023-01-05 13:20:20,108 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3591172734896342, 'Total loss': 0.3591172734896342} | train loss {'Reaction outcome loss': 0.28538898102588195, 'Total loss': 0.28538898102588195}
2023-01-05 13:20:20,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:20,108 INFO:     Epoch: 65
2023-01-05 13:20:22,257 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3799887428681056, 'Total loss': 0.3799887428681056} | train loss {'Reaction outcome loss': 0.2814099937407435, 'Total loss': 0.2814099937407435}
2023-01-05 13:20:22,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:22,257 INFO:     Epoch: 66
2023-01-05 13:20:24,425 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3642321112255255, 'Total loss': 0.3642321112255255} | train loss {'Reaction outcome loss': 0.29196444118523673, 'Total loss': 0.29196444118523673}
2023-01-05 13:20:24,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:24,427 INFO:     Epoch: 67
2023-01-05 13:20:26,600 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39489241391420365, 'Total loss': 0.39489241391420365} | train loss {'Reaction outcome loss': 0.282113172761772, 'Total loss': 0.282113172761772}
2023-01-05 13:20:26,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:26,601 INFO:     Epoch: 68
2023-01-05 13:20:28,762 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3659575581550598, 'Total loss': 0.3659575581550598} | train loss {'Reaction outcome loss': 0.28788689884654095, 'Total loss': 0.28788689884654095}
2023-01-05 13:20:28,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:28,762 INFO:     Epoch: 69
2023-01-05 13:20:30,935 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.35598963499069214, 'Total loss': 0.35598963499069214} | train loss {'Reaction outcome loss': 0.2811880066032957, 'Total loss': 0.2811880066032957}
2023-01-05 13:20:30,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:30,936 INFO:     Epoch: 70
2023-01-05 13:20:33,111 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3732567166288694, 'Total loss': 0.3732567166288694} | train loss {'Reaction outcome loss': 0.27711980607347103, 'Total loss': 0.27711980607347103}
2023-01-05 13:20:33,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:33,111 INFO:     Epoch: 71
2023-01-05 13:20:35,067 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37594712575276695, 'Total loss': 0.37594712575276695} | train loss {'Reaction outcome loss': 0.2705886914830088, 'Total loss': 0.2705886914830088}
2023-01-05 13:20:35,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:35,067 INFO:     Epoch: 72
2023-01-05 13:20:37,239 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37602346042792, 'Total loss': 0.37602346042792} | train loss {'Reaction outcome loss': 0.27974484888229356, 'Total loss': 0.27974484888229356}
2023-01-05 13:20:37,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:37,240 INFO:     Epoch: 73
2023-01-05 13:20:39,416 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3706419636805852, 'Total loss': 0.3706419636805852} | train loss {'Reaction outcome loss': 0.26744653274173563, 'Total loss': 0.26744653274173563}
2023-01-05 13:20:39,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:39,417 INFO:     Epoch: 74
2023-01-05 13:20:41,597 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.350029456615448, 'Total loss': 0.350029456615448} | train loss {'Reaction outcome loss': 0.26642105309688435, 'Total loss': 0.26642105309688435}
2023-01-05 13:20:41,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:41,598 INFO:     Epoch: 75
2023-01-05 13:20:43,766 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.391512139638265, 'Total loss': 0.391512139638265} | train loss {'Reaction outcome loss': 0.2844454925372333, 'Total loss': 0.2844454925372333}
2023-01-05 13:20:43,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:43,767 INFO:     Epoch: 76
2023-01-05 13:20:45,917 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3778399869799614, 'Total loss': 0.3778399869799614} | train loss {'Reaction outcome loss': 0.30713990862494794, 'Total loss': 0.30713990862494794}
2023-01-05 13:20:45,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:45,917 INFO:     Epoch: 77
2023-01-05 13:20:48,074 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38036463856697084, 'Total loss': 0.38036463856697084} | train loss {'Reaction outcome loss': 0.2856035840889925, 'Total loss': 0.2856035840889925}
2023-01-05 13:20:48,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:48,075 INFO:     Epoch: 78
2023-01-05 13:20:50,244 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.35654519895712533, 'Total loss': 0.35654519895712533} | train loss {'Reaction outcome loss': 0.27002183807865326, 'Total loss': 0.27002183807865326}
2023-01-05 13:20:50,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:50,244 INFO:     Epoch: 79
2023-01-05 13:20:52,405 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41603485147158303, 'Total loss': 0.41603485147158303} | train loss {'Reaction outcome loss': 0.263518325224465, 'Total loss': 0.263518325224465}
2023-01-05 13:20:52,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:52,406 INFO:     Epoch: 80
2023-01-05 13:20:54,558 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3895084728797277, 'Total loss': 0.3895084728797277} | train loss {'Reaction outcome loss': 0.26882246608400473, 'Total loss': 0.26882246608400473}
2023-01-05 13:20:54,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:54,560 INFO:     Epoch: 81
2023-01-05 13:20:56,702 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3843973927199841, 'Total loss': 0.3843973927199841} | train loss {'Reaction outcome loss': 0.2565582118461506, 'Total loss': 0.2565582118461506}
2023-01-05 13:20:56,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:56,702 INFO:     Epoch: 82
2023-01-05 13:20:58,886 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3319650555650393, 'Total loss': 0.3319650555650393} | train loss {'Reaction outcome loss': 0.26491829739071376, 'Total loss': 0.26491829739071376}
2023-01-05 13:20:58,886 INFO:     Found new best model at epoch 82
2023-01-05 13:20:58,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:20:58,887 INFO:     Epoch: 83
2023-01-05 13:21:01,079 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.411420930425326, 'Total loss': 0.411420930425326} | train loss {'Reaction outcome loss': 0.25031600356695877, 'Total loss': 0.25031600356695877}
2023-01-05 13:21:01,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:01,081 INFO:     Epoch: 84
2023-01-05 13:21:03,233 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3692910701036453, 'Total loss': 0.3692910701036453} | train loss {'Reaction outcome loss': 0.25930303686122963, 'Total loss': 0.25930303686122963}
2023-01-05 13:21:03,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:03,234 INFO:     Epoch: 85
2023-01-05 13:21:05,380 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3887100234627724, 'Total loss': 0.3887100234627724} | train loss {'Reaction outcome loss': 0.26937810243343585, 'Total loss': 0.26937810243343585}
2023-01-05 13:21:05,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:05,382 INFO:     Epoch: 86
2023-01-05 13:21:07,506 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.34500355323155724, 'Total loss': 0.34500355323155724} | train loss {'Reaction outcome loss': 0.256837944911609, 'Total loss': 0.256837944911609}
2023-01-05 13:21:07,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:07,506 INFO:     Epoch: 87
2023-01-05 13:21:09,706 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.37174251675605774, 'Total loss': 0.37174251675605774} | train loss {'Reaction outcome loss': 0.24863055927689065, 'Total loss': 0.24863055927689065}
2023-01-05 13:21:09,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:09,706 INFO:     Epoch: 88
2023-01-05 13:21:11,868 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3889160672823588, 'Total loss': 0.3889160672823588} | train loss {'Reaction outcome loss': 0.24952962006500456, 'Total loss': 0.24952962006500456}
2023-01-05 13:21:11,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:11,869 INFO:     Epoch: 89
2023-01-05 13:21:14,011 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3782110591729482, 'Total loss': 0.3782110591729482} | train loss {'Reaction outcome loss': 0.25084180042058113, 'Total loss': 0.25084180042058113}
2023-01-05 13:21:14,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:14,011 INFO:     Epoch: 90
2023-01-05 13:21:16,162 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3824368288119634, 'Total loss': 0.3824368288119634} | train loss {'Reaction outcome loss': 0.2435245096305574, 'Total loss': 0.2435245096305574}
2023-01-05 13:21:16,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:16,162 INFO:     Epoch: 91
2023-01-05 13:21:18,316 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.36164495994647344, 'Total loss': 0.36164495994647344} | train loss {'Reaction outcome loss': 0.2495796285283691, 'Total loss': 0.2495796285283691}
2023-01-05 13:21:18,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:18,317 INFO:     Epoch: 92
2023-01-05 13:21:20,442 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.400786363085111, 'Total loss': 0.400786363085111} | train loss {'Reaction outcome loss': 0.24530580900592622, 'Total loss': 0.24530580900592622}
2023-01-05 13:21:20,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:20,442 INFO:     Epoch: 93
2023-01-05 13:21:22,603 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36677365899086, 'Total loss': 0.36677365899086} | train loss {'Reaction outcome loss': 0.24642305001886428, 'Total loss': 0.24642305001886428}
2023-01-05 13:21:22,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:22,605 INFO:     Epoch: 94
2023-01-05 13:21:24,746 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3828002691268921, 'Total loss': 0.3828002691268921} | train loss {'Reaction outcome loss': 0.24341460704823292, 'Total loss': 0.24341460704823292}
2023-01-05 13:21:24,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:24,746 INFO:     Epoch: 95
2023-01-05 13:21:26,910 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.36745704114437105, 'Total loss': 0.36745704114437105} | train loss {'Reaction outcome loss': 0.2461207107357357, 'Total loss': 0.2461207107357357}
2023-01-05 13:21:26,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:26,910 INFO:     Epoch: 96
2023-01-05 13:21:29,067 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3968533992767334, 'Total loss': 0.3968533992767334} | train loss {'Reaction outcome loss': 0.2500648272993124, 'Total loss': 0.2500648272993124}
2023-01-05 13:21:29,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:29,068 INFO:     Epoch: 97
2023-01-05 13:21:31,218 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3502181758483251, 'Total loss': 0.3502181758483251} | train loss {'Reaction outcome loss': 0.2827604203222649, 'Total loss': 0.2827604203222649}
2023-01-05 13:21:31,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:31,218 INFO:     Epoch: 98
2023-01-05 13:21:33,388 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4157079607248306, 'Total loss': 0.4157079607248306} | train loss {'Reaction outcome loss': 0.2336564831801798, 'Total loss': 0.2336564831801798}
2023-01-05 13:21:33,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:33,388 INFO:     Epoch: 99
2023-01-05 13:21:35,546 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4225742896397909, 'Total loss': 0.4225742896397909} | train loss {'Reaction outcome loss': 0.2384155398281966, 'Total loss': 0.2384155398281966}
2023-01-05 13:21:35,547 INFO:     Best model found after epoch 83 of 100.
2023-01-05 13:21:35,548 INFO:   Done with stage: TRAINING
2023-01-05 13:21:35,548 INFO:   Starting stage: EVALUATION
2023-01-05 13:21:35,680 INFO:   Done with stage: EVALUATION
2023-01-05 13:21:35,680 INFO:   Leaving out SEQ value Fold_5
2023-01-05 13:21:35,693 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 13:21:35,693 INFO:   Starting stage: FEATURE SCALING
2023-01-05 13:21:36,353 INFO:   Done with stage: FEATURE SCALING
2023-01-05 13:21:36,353 INFO:   Starting stage: SCALING TARGETS
2023-01-05 13:21:36,423 INFO:   Done with stage: SCALING TARGETS
2023-01-05 13:21:36,423 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:21:36,423 INFO:     No hyperparam tuning for this model
2023-01-05 13:21:36,423 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:21:36,423 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 13:21:36,424 INFO:     None feature selector for col prot
2023-01-05 13:21:36,424 INFO:     None feature selector for col prot
2023-01-05 13:21:36,424 INFO:     None feature selector for col prot
2023-01-05 13:21:36,425 INFO:     None feature selector for col chem
2023-01-05 13:21:36,425 INFO:     None feature selector for col chem
2023-01-05 13:21:36,425 INFO:     None feature selector for col chem
2023-01-05 13:21:36,425 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 13:21:36,425 INFO:   Starting stage: BUILD MODEL
2023-01-05 13:21:36,426 INFO:     Number of params in model 72901
2023-01-05 13:21:36,430 INFO:   Done with stage: BUILD MODEL
2023-01-05 13:21:36,430 INFO:   Starting stage: TRAINING
2023-01-05 13:21:36,489 INFO:     Val loss before train {'Reaction outcome loss': 1.0638819416364034, 'Total loss': 1.0638819416364034}
2023-01-05 13:21:36,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:36,489 INFO:     Epoch: 0
2023-01-05 13:21:38,641 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.882477863629659, 'Total loss': 0.882477863629659} | train loss {'Reaction outcome loss': 0.9369645885367325, 'Total loss': 0.9369645885367325}
2023-01-05 13:21:38,641 INFO:     Found new best model at epoch 0
2023-01-05 13:21:38,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:38,642 INFO:     Epoch: 1
2023-01-05 13:21:40,803 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6174433449904124, 'Total loss': 0.6174433449904124} | train loss {'Reaction outcome loss': 0.7229421374749095, 'Total loss': 0.7229421374749095}
2023-01-05 13:21:40,804 INFO:     Found new best model at epoch 1
2023-01-05 13:21:40,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:40,805 INFO:     Epoch: 2
2023-01-05 13:21:42,944 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5478839854399363, 'Total loss': 0.5478839854399363} | train loss {'Reaction outcome loss': 0.5768132655462925, 'Total loss': 0.5768132655462925}
2023-01-05 13:21:42,944 INFO:     Found new best model at epoch 2
2023-01-05 13:21:42,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:42,945 INFO:     Epoch: 3
2023-01-05 13:21:45,116 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5867463727792104, 'Total loss': 0.5867463727792104} | train loss {'Reaction outcome loss': 0.5475911383679055, 'Total loss': 0.5475911383679055}
2023-01-05 13:21:45,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:45,118 INFO:     Epoch: 4
2023-01-05 13:21:47,289 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5473487178484598, 'Total loss': 0.5473487178484598} | train loss {'Reaction outcome loss': 0.5183066730522483, 'Total loss': 0.5183066730522483}
2023-01-05 13:21:47,289 INFO:     Found new best model at epoch 4
2023-01-05 13:21:47,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:47,290 INFO:     Epoch: 5
2023-01-05 13:21:49,441 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5657637417316437, 'Total loss': 0.5657637417316437} | train loss {'Reaction outcome loss': 0.5073213309009114, 'Total loss': 0.5073213309009114}
2023-01-05 13:21:49,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:49,442 INFO:     Epoch: 6
2023-01-05 13:21:51,602 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5857988615830739, 'Total loss': 0.5857988615830739} | train loss {'Reaction outcome loss': 0.5005159576733907, 'Total loss': 0.5005159576733907}
2023-01-05 13:21:51,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:51,603 INFO:     Epoch: 7
2023-01-05 13:21:53,747 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5405642708142598, 'Total loss': 0.5405642708142598} | train loss {'Reaction outcome loss': 0.4918512708466986, 'Total loss': 0.4918512708466986}
2023-01-05 13:21:53,747 INFO:     Found new best model at epoch 7
2023-01-05 13:21:53,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:53,749 INFO:     Epoch: 8
2023-01-05 13:21:55,900 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5298573931058248, 'Total loss': 0.5298573931058248} | train loss {'Reaction outcome loss': 0.48809140145886637, 'Total loss': 0.48809140145886637}
2023-01-05 13:21:55,901 INFO:     Found new best model at epoch 8
2023-01-05 13:21:55,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:55,903 INFO:     Epoch: 9
2023-01-05 13:21:58,061 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5205070614814759, 'Total loss': 0.5205070614814759} | train loss {'Reaction outcome loss': 0.47739863784416864, 'Total loss': 0.47739863784416864}
2023-01-05 13:21:58,061 INFO:     Found new best model at epoch 9
2023-01-05 13:21:58,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:21:58,063 INFO:     Epoch: 10
2023-01-05 13:22:00,256 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5326546678940455, 'Total loss': 0.5326546678940455} | train loss {'Reaction outcome loss': 0.4708794478286544, 'Total loss': 0.4708794478286544}
2023-01-05 13:22:00,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:00,256 INFO:     Epoch: 11
2023-01-05 13:22:02,450 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5246345818042755, 'Total loss': 0.5246345818042755} | train loss {'Reaction outcome loss': 0.46623586129694095, 'Total loss': 0.46623586129694095}
2023-01-05 13:22:02,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:02,452 INFO:     Epoch: 12
2023-01-05 13:22:04,656 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5403831481933594, 'Total loss': 0.5403831481933594} | train loss {'Reaction outcome loss': 0.4623736730773353, 'Total loss': 0.4623736730773353}
2023-01-05 13:22:04,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:04,656 INFO:     Epoch: 13
2023-01-05 13:22:06,827 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5187060137589773, 'Total loss': 0.5187060137589773} | train loss {'Reaction outcome loss': 0.46172059284172196, 'Total loss': 0.46172059284172196}
2023-01-05 13:22:06,828 INFO:     Found new best model at epoch 13
2023-01-05 13:22:06,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:06,829 INFO:     Epoch: 14
2023-01-05 13:22:09,023 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5166813890139262, 'Total loss': 0.5166813890139262} | train loss {'Reaction outcome loss': 0.4549224262760169, 'Total loss': 0.4549224262760169}
2023-01-05 13:22:09,023 INFO:     Found new best model at epoch 14
2023-01-05 13:22:09,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:09,024 INFO:     Epoch: 15
2023-01-05 13:22:11,223 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5348655005296071, 'Total loss': 0.5348655005296071} | train loss {'Reaction outcome loss': 0.45714570511726366, 'Total loss': 0.45714570511726366}
2023-01-05 13:22:11,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:11,223 INFO:     Epoch: 16
2023-01-05 13:22:13,381 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.525560736656189, 'Total loss': 0.525560736656189} | train loss {'Reaction outcome loss': 0.4635552315824274, 'Total loss': 0.4635552315824274}
2023-01-05 13:22:13,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:13,383 INFO:     Epoch: 17
2023-01-05 13:22:15,542 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5358161290486654, 'Total loss': 0.5358161290486654} | train loss {'Reaction outcome loss': 0.4464887931489089, 'Total loss': 0.4464887931489089}
2023-01-05 13:22:15,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:15,542 INFO:     Epoch: 18
2023-01-05 13:22:17,680 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5135921428600947, 'Total loss': 0.5135921428600947} | train loss {'Reaction outcome loss': 0.4634425060391642, 'Total loss': 0.4634425060391642}
2023-01-05 13:22:17,681 INFO:     Found new best model at epoch 18
2023-01-05 13:22:17,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:17,682 INFO:     Epoch: 19
2023-01-05 13:22:19,831 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49348573982715604, 'Total loss': 0.49348573982715604} | train loss {'Reaction outcome loss': 0.4390752571972384, 'Total loss': 0.4390752571972384}
2023-01-05 13:22:19,832 INFO:     Found new best model at epoch 19
2023-01-05 13:22:19,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:19,834 INFO:     Epoch: 20
2023-01-05 13:22:21,990 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5184793690840404, 'Total loss': 0.5184793690840404} | train loss {'Reaction outcome loss': 0.4350804620678874, 'Total loss': 0.4350804620678874}
2023-01-05 13:22:21,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:21,990 INFO:     Epoch: 21
2023-01-05 13:22:24,160 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5078582346439362, 'Total loss': 0.5078582346439362} | train loss {'Reaction outcome loss': 0.4325718724546765, 'Total loss': 0.4325718724546765}
2023-01-05 13:22:24,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:24,160 INFO:     Epoch: 22
2023-01-05 13:22:26,325 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5392525792121887, 'Total loss': 0.5392525792121887} | train loss {'Reaction outcome loss': 0.4250357734660308, 'Total loss': 0.4250357734660308}
2023-01-05 13:22:26,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:26,326 INFO:     Epoch: 23
2023-01-05 13:22:28,484 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5161780039469401, 'Total loss': 0.5161780039469401} | train loss {'Reaction outcome loss': 0.4196489832458505, 'Total loss': 0.4196489832458505}
2023-01-05 13:22:28,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:28,484 INFO:     Epoch: 24
2023-01-05 13:22:30,649 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5258208851019541, 'Total loss': 0.5258208851019541} | train loss {'Reaction outcome loss': 0.42289569887562073, 'Total loss': 0.42289569887562073}
2023-01-05 13:22:30,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:30,649 INFO:     Epoch: 25
2023-01-05 13:22:32,809 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.530074151357015, 'Total loss': 0.530074151357015} | train loss {'Reaction outcome loss': 0.4149315090938256, 'Total loss': 0.4149315090938256}
2023-01-05 13:22:32,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:32,810 INFO:     Epoch: 26
2023-01-05 13:22:34,968 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5175439397493998, 'Total loss': 0.5175439397493998} | train loss {'Reaction outcome loss': 0.4129822367559309, 'Total loss': 0.4129822367559309}
2023-01-05 13:22:34,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:34,969 INFO:     Epoch: 27
2023-01-05 13:22:37,119 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5244185984134674, 'Total loss': 0.5244185984134674} | train loss {'Reaction outcome loss': 0.40790429419797397, 'Total loss': 0.40790429419797397}
2023-01-05 13:22:37,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:37,119 INFO:     Epoch: 28
2023-01-05 13:22:39,258 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.49307275215784707, 'Total loss': 0.49307275215784707} | train loss {'Reaction outcome loss': 0.4147194824788881, 'Total loss': 0.4147194824788881}
2023-01-05 13:22:39,259 INFO:     Found new best model at epoch 28
2023-01-05 13:22:39,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:39,261 INFO:     Epoch: 29
2023-01-05 13:22:41,419 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5182889898618063, 'Total loss': 0.5182889898618063} | train loss {'Reaction outcome loss': 0.41606883445511694, 'Total loss': 0.41606883445511694}
2023-01-05 13:22:41,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:41,419 INFO:     Epoch: 30
2023-01-05 13:22:43,603 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.500257553656896, 'Total loss': 0.500257553656896} | train loss {'Reaction outcome loss': 0.41573306344840943, 'Total loss': 0.41573306344840943}
2023-01-05 13:22:43,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:43,604 INFO:     Epoch: 31
2023-01-05 13:22:45,763 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5075060764948527, 'Total loss': 0.5075060764948527} | train loss {'Reaction outcome loss': 0.3944844788803375, 'Total loss': 0.3944844788803375}
2023-01-05 13:22:45,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:45,763 INFO:     Epoch: 32
2023-01-05 13:22:47,917 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5137050489584605, 'Total loss': 0.5137050489584605} | train loss {'Reaction outcome loss': 0.3986547093760843, 'Total loss': 0.3986547093760843}
2023-01-05 13:22:47,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:47,917 INFO:     Epoch: 33
2023-01-05 13:22:50,076 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5201092382272084, 'Total loss': 0.5201092382272084} | train loss {'Reaction outcome loss': 0.38628727918409783, 'Total loss': 0.38628727918409783}
2023-01-05 13:22:50,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:50,078 INFO:     Epoch: 34
2023-01-05 13:22:52,224 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4768338680267334, 'Total loss': 0.4768338680267334} | train loss {'Reaction outcome loss': 0.39054849876286596, 'Total loss': 0.39054849876286596}
2023-01-05 13:22:52,224 INFO:     Found new best model at epoch 34
2023-01-05 13:22:52,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:52,225 INFO:     Epoch: 35
2023-01-05 13:22:54,366 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5118158678213756, 'Total loss': 0.5118158678213756} | train loss {'Reaction outcome loss': 0.38333663978762383, 'Total loss': 0.38333663978762383}
2023-01-05 13:22:54,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:54,366 INFO:     Epoch: 36
2023-01-05 13:22:56,537 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47948962648709614, 'Total loss': 0.47948962648709614} | train loss {'Reaction outcome loss': 0.38206037821836997, 'Total loss': 0.38206037821836997}
2023-01-05 13:22:56,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:56,538 INFO:     Epoch: 37
2023-01-05 13:22:58,693 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4943821052710215, 'Total loss': 0.4943821052710215} | train loss {'Reaction outcome loss': 0.38401322900924995, 'Total loss': 0.38401322900924995}
2023-01-05 13:22:58,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:22:58,693 INFO:     Epoch: 38
2023-01-05 13:23:00,914 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49226256608963015, 'Total loss': 0.49226256608963015} | train loss {'Reaction outcome loss': 0.3903248811450043, 'Total loss': 0.3903248811450043}
2023-01-05 13:23:00,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:00,916 INFO:     Epoch: 39
2023-01-05 13:23:03,118 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47806329329808556, 'Total loss': 0.47806329329808556} | train loss {'Reaction outcome loss': 0.36671359113593033, 'Total loss': 0.36671359113593033}
2023-01-05 13:23:03,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:03,118 INFO:     Epoch: 40
2023-01-05 13:23:05,334 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5063376223047574, 'Total loss': 0.5063376223047574} | train loss {'Reaction outcome loss': 0.3711347530960389, 'Total loss': 0.3711347530960389}
2023-01-05 13:23:05,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:05,335 INFO:     Epoch: 41
2023-01-05 13:23:07,576 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5048351973295212, 'Total loss': 0.5048351973295212} | train loss {'Reaction outcome loss': 0.36083368765547924, 'Total loss': 0.36083368765547924}
2023-01-05 13:23:07,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:07,577 INFO:     Epoch: 42
2023-01-05 13:23:09,815 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5224153975645701, 'Total loss': 0.5224153975645701} | train loss {'Reaction outcome loss': 0.3687816068692052, 'Total loss': 0.3687816068692052}
2023-01-05 13:23:09,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:09,816 INFO:     Epoch: 43
2023-01-05 13:23:12,038 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4678140123685201, 'Total loss': 0.4678140123685201} | train loss {'Reaction outcome loss': 0.4353313357139047, 'Total loss': 0.4353313357139047}
2023-01-05 13:23:12,038 INFO:     Found new best model at epoch 43
2023-01-05 13:23:12,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:12,039 INFO:     Epoch: 44
2023-01-05 13:23:14,199 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48643192450205486, 'Total loss': 0.48643192450205486} | train loss {'Reaction outcome loss': 0.36301706963812636, 'Total loss': 0.36301706963812636}
2023-01-05 13:23:14,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:14,200 INFO:     Epoch: 45
2023-01-05 13:23:16,342 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4852177987496058, 'Total loss': 0.4852177987496058} | train loss {'Reaction outcome loss': 0.3581697055690355, 'Total loss': 0.3581697055690355}
2023-01-05 13:23:16,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:16,342 INFO:     Epoch: 46
2023-01-05 13:23:18,501 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49700552225112915, 'Total loss': 0.49700552225112915} | train loss {'Reaction outcome loss': 0.3527455838237707, 'Total loss': 0.3527455838237707}
2023-01-05 13:23:18,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:18,502 INFO:     Epoch: 47
2023-01-05 13:23:20,679 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4968426605065664, 'Total loss': 0.4968426605065664} | train loss {'Reaction outcome loss': 0.34875221020015684, 'Total loss': 0.34875221020015684}
2023-01-05 13:23:20,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:20,680 INFO:     Epoch: 48
2023-01-05 13:23:22,841 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.51078841984272, 'Total loss': 0.51078841984272} | train loss {'Reaction outcome loss': 0.3487306567499415, 'Total loss': 0.3487306567499415}
2023-01-05 13:23:22,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:22,841 INFO:     Epoch: 49
2023-01-05 13:23:24,989 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5047673583030701, 'Total loss': 0.5047673583030701} | train loss {'Reaction outcome loss': 0.342746693868466, 'Total loss': 0.342746693868466}
2023-01-05 13:23:24,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:24,991 INFO:     Epoch: 50
2023-01-05 13:23:27,151 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4934828758239746, 'Total loss': 0.4934828758239746} | train loss {'Reaction outcome loss': 0.34024087183406926, 'Total loss': 0.34024087183406926}
2023-01-05 13:23:27,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:27,152 INFO:     Epoch: 51
2023-01-05 13:23:29,308 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5030669053395589, 'Total loss': 0.5030669053395589} | train loss {'Reaction outcome loss': 0.34260758449849876, 'Total loss': 0.34260758449849876}
2023-01-05 13:23:29,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:29,308 INFO:     Epoch: 52
2023-01-05 13:23:31,456 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47628273367881774, 'Total loss': 0.47628273367881774} | train loss {'Reaction outcome loss': 0.33830229253330996, 'Total loss': 0.33830229253330996}
2023-01-05 13:23:31,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:31,457 INFO:     Epoch: 53
2023-01-05 13:23:33,646 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.503347231944402, 'Total loss': 0.503347231944402} | train loss {'Reaction outcome loss': 0.3319052270060216, 'Total loss': 0.3319052270060216}
2023-01-05 13:23:33,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:33,646 INFO:     Epoch: 54
2023-01-05 13:23:35,813 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4577154894669851, 'Total loss': 0.4577154894669851} | train loss {'Reaction outcome loss': 0.33108231942152494, 'Total loss': 0.33108231942152494}
2023-01-05 13:23:35,813 INFO:     Found new best model at epoch 54
2023-01-05 13:23:35,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:35,815 INFO:     Epoch: 55
2023-01-05 13:23:37,955 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5050284226735433, 'Total loss': 0.5050284226735433} | train loss {'Reaction outcome loss': 0.3270138247896904, 'Total loss': 0.3270138247896904}
2023-01-05 13:23:37,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:37,956 INFO:     Epoch: 56
2023-01-05 13:23:40,121 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5298705667257309, 'Total loss': 0.5298705667257309} | train loss {'Reaction outcome loss': 0.33373107896118925, 'Total loss': 0.33373107896118925}
2023-01-05 13:23:40,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:40,121 INFO:     Epoch: 57
2023-01-05 13:23:42,273 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.521697023510933, 'Total loss': 0.521697023510933} | train loss {'Reaction outcome loss': 0.3321112698936106, 'Total loss': 0.3321112698936106}
2023-01-05 13:23:42,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:42,275 INFO:     Epoch: 58
2023-01-05 13:23:44,457 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47159270743529, 'Total loss': 0.47159270743529} | train loss {'Reaction outcome loss': 0.32254901812951214, 'Total loss': 0.32254901812951214}
2023-01-05 13:23:44,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:44,457 INFO:     Epoch: 59
2023-01-05 13:23:46,633 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4966439465681712, 'Total loss': 0.4966439465681712} | train loss {'Reaction outcome loss': 0.3148497753418928, 'Total loss': 0.3148497753418928}
2023-01-05 13:23:46,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:46,633 INFO:     Epoch: 60
2023-01-05 13:23:48,798 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4760518083969752, 'Total loss': 0.4760518083969752} | train loss {'Reaction outcome loss': 0.3175744261673611, 'Total loss': 0.3175744261673611}
2023-01-05 13:23:48,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:48,799 INFO:     Epoch: 61
2023-01-05 13:23:50,959 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4542243311802546, 'Total loss': 0.4542243311802546} | train loss {'Reaction outcome loss': 0.3163496471091133, 'Total loss': 0.3163496471091133}
2023-01-05 13:23:50,959 INFO:     Found new best model at epoch 61
2023-01-05 13:23:50,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:50,960 INFO:     Epoch: 62
2023-01-05 13:23:53,118 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5345743844906489, 'Total loss': 0.5345743844906489} | train loss {'Reaction outcome loss': 0.31864268168051174, 'Total loss': 0.31864268168051174}
2023-01-05 13:23:53,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:53,118 INFO:     Epoch: 63
2023-01-05 13:23:55,294 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4974057495594025, 'Total loss': 0.4974057495594025} | train loss {'Reaction outcome loss': 0.3992918361980338, 'Total loss': 0.3992918361980338}
2023-01-05 13:23:55,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:55,295 INFO:     Epoch: 64
2023-01-05 13:23:57,456 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4973022003968557, 'Total loss': 0.4973022003968557} | train loss {'Reaction outcome loss': 0.31048181364177796, 'Total loss': 0.31048181364177796}
2023-01-05 13:23:57,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:57,456 INFO:     Epoch: 65
2023-01-05 13:23:59,654 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5345401803652445, 'Total loss': 0.5345401803652445} | train loss {'Reaction outcome loss': 0.32456120284463186, 'Total loss': 0.32456120284463186}
2023-01-05 13:23:59,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:23:59,655 INFO:     Epoch: 66
2023-01-05 13:24:01,811 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4689608613650004, 'Total loss': 0.4689608613650004} | train loss {'Reaction outcome loss': 0.38289359561505093, 'Total loss': 0.38289359561505093}
2023-01-05 13:24:01,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:01,811 INFO:     Epoch: 67
2023-01-05 13:24:03,965 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47918912867705027, 'Total loss': 0.47918912867705027} | train loss {'Reaction outcome loss': 0.3233582890108427, 'Total loss': 0.3233582890108427}
2023-01-05 13:24:03,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:03,966 INFO:     Epoch: 68
2023-01-05 13:24:06,125 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48729769587516786, 'Total loss': 0.48729769587516786} | train loss {'Reaction outcome loss': 0.30861727466833766, 'Total loss': 0.30861727466833766}
2023-01-05 13:24:06,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:06,127 INFO:     Epoch: 69
2023-01-05 13:24:08,265 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5301117340723673, 'Total loss': 0.5301117340723673} | train loss {'Reaction outcome loss': 0.3133639739134578, 'Total loss': 0.3133639739134578}
2023-01-05 13:24:08,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:08,265 INFO:     Epoch: 70
2023-01-05 13:24:10,431 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4885009149710337, 'Total loss': 0.4885009149710337} | train loss {'Reaction outcome loss': 0.3050203240759995, 'Total loss': 0.3050203240759995}
2023-01-05 13:24:10,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:10,431 INFO:     Epoch: 71
2023-01-05 13:24:12,578 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5076431632041931, 'Total loss': 0.5076431632041931} | train loss {'Reaction outcome loss': 0.3205585301747424, 'Total loss': 0.3205585301747424}
2023-01-05 13:24:12,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:12,579 INFO:     Epoch: 72
2023-01-05 13:24:14,735 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.506676909327507, 'Total loss': 0.506676909327507} | train loss {'Reaction outcome loss': 0.2980650854743821, 'Total loss': 0.2980650854743821}
2023-01-05 13:24:14,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:14,735 INFO:     Epoch: 73
2023-01-05 13:24:16,904 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5187405387560526, 'Total loss': 0.5187405387560526} | train loss {'Reaction outcome loss': 0.29525651742896764, 'Total loss': 0.29525651742896764}
2023-01-05 13:24:16,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:16,905 INFO:     Epoch: 74
2023-01-05 13:24:19,071 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47094421088695526, 'Total loss': 0.47094421088695526} | train loss {'Reaction outcome loss': 0.2922570792379438, 'Total loss': 0.2922570792379438}
2023-01-05 13:24:19,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:19,071 INFO:     Epoch: 75
2023-01-05 13:24:21,232 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5205628991127014, 'Total loss': 0.5205628991127014} | train loss {'Reaction outcome loss': 0.2961291539557852, 'Total loss': 0.2961291539557852}
2023-01-05 13:24:21,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:21,233 INFO:     Epoch: 76
2023-01-05 13:24:23,373 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48340537150700885, 'Total loss': 0.48340537150700885} | train loss {'Reaction outcome loss': 0.28611641721731085, 'Total loss': 0.28611641721731085}
2023-01-05 13:24:23,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:23,374 INFO:     Epoch: 77
2023-01-05 13:24:25,530 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48691211541493734, 'Total loss': 0.48691211541493734} | train loss {'Reaction outcome loss': 0.288593102849162, 'Total loss': 0.288593102849162}
2023-01-05 13:24:25,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:25,530 INFO:     Epoch: 78
2023-01-05 13:24:27,679 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5124043166637421, 'Total loss': 0.5124043166637421} | train loss {'Reaction outcome loss': 0.29079312023004866, 'Total loss': 0.29079312023004866}
2023-01-05 13:24:27,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:27,679 INFO:     Epoch: 79
2023-01-05 13:24:29,832 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.464827162027359, 'Total loss': 0.464827162027359} | train loss {'Reaction outcome loss': 0.2883104931251433, 'Total loss': 0.2883104931251433}
2023-01-05 13:24:29,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:29,834 INFO:     Epoch: 80
2023-01-05 13:24:31,995 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5040321747461954, 'Total loss': 0.5040321747461954} | train loss {'Reaction outcome loss': 0.2884996684701056, 'Total loss': 0.2884996684701056}
2023-01-05 13:24:31,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:31,995 INFO:     Epoch: 81
2023-01-05 13:24:34,154 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5085514773925145, 'Total loss': 0.5085514773925145} | train loss {'Reaction outcome loss': 0.29592665643903654, 'Total loss': 0.29592665643903654}
2023-01-05 13:24:34,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:34,155 INFO:     Epoch: 82
2023-01-05 13:24:36,331 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5551322599252065, 'Total loss': 0.5551322599252065} | train loss {'Reaction outcome loss': 0.444774106738792, 'Total loss': 0.444774106738792}
2023-01-05 13:24:36,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:36,332 INFO:     Epoch: 83
2023-01-05 13:24:38,486 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49826402763525646, 'Total loss': 0.49826402763525646} | train loss {'Reaction outcome loss': 0.33162203707826743, 'Total loss': 0.33162203707826743}
2023-01-05 13:24:38,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:38,486 INFO:     Epoch: 84
2023-01-05 13:24:40,432 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4782958040634791, 'Total loss': 0.4782958040634791} | train loss {'Reaction outcome loss': 0.3147647244369854, 'Total loss': 0.3147647244369854}
2023-01-05 13:24:40,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:40,433 INFO:     Epoch: 85
2023-01-05 13:24:42,607 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5289027631282807, 'Total loss': 0.5289027631282807} | train loss {'Reaction outcome loss': 0.3348182480566312, 'Total loss': 0.3348182480566312}
2023-01-05 13:24:42,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:42,607 INFO:     Epoch: 86
2023-01-05 13:24:44,792 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5083130389451981, 'Total loss': 0.5083130389451981} | train loss {'Reaction outcome loss': 0.3038121369117885, 'Total loss': 0.3038121369117885}
2023-01-05 13:24:44,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:44,792 INFO:     Epoch: 87
2023-01-05 13:24:46,940 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48983594924211504, 'Total loss': 0.48983594924211504} | train loss {'Reaction outcome loss': 0.29503826569408126, 'Total loss': 0.29503826569408126}
2023-01-05 13:24:46,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:46,942 INFO:     Epoch: 88
2023-01-05 13:24:49,120 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5060942153135936, 'Total loss': 0.5060942153135936} | train loss {'Reaction outcome loss': 0.2884900298499354, 'Total loss': 0.2884900298499354}
2023-01-05 13:24:49,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:49,120 INFO:     Epoch: 89
2023-01-05 13:24:51,295 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49838138222694395, 'Total loss': 0.49838138222694395} | train loss {'Reaction outcome loss': 0.28946618366973015, 'Total loss': 0.28946618366973015}
2023-01-05 13:24:51,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:51,295 INFO:     Epoch: 90
2023-01-05 13:24:53,468 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4889083484808604, 'Total loss': 0.4889083484808604} | train loss {'Reaction outcome loss': 0.28350086827539717, 'Total loss': 0.28350086827539717}
2023-01-05 13:24:53,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:53,469 INFO:     Epoch: 91
2023-01-05 13:24:55,635 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5128225276867548, 'Total loss': 0.5128225276867548} | train loss {'Reaction outcome loss': 0.2851945953996197, 'Total loss': 0.2851945953996197}
2023-01-05 13:24:55,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:55,635 INFO:     Epoch: 92
2023-01-05 13:24:57,798 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5342966397603353, 'Total loss': 0.5342966397603353} | train loss {'Reaction outcome loss': 0.2830372712291453, 'Total loss': 0.2830372712291453}
2023-01-05 13:24:57,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:57,799 INFO:     Epoch: 93
2023-01-05 13:24:59,965 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.514846126238505, 'Total loss': 0.514846126238505} | train loss {'Reaction outcome loss': 0.3096403990858707, 'Total loss': 0.3096403990858707}
2023-01-05 13:24:59,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:24:59,967 INFO:     Epoch: 94
2023-01-05 13:25:02,132 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5012333174546559, 'Total loss': 0.5012333174546559} | train loss {'Reaction outcome loss': 0.2836695362512082, 'Total loss': 0.2836695362512082}
2023-01-05 13:25:02,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:02,132 INFO:     Epoch: 95
2023-01-05 13:25:04,294 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49472642938296, 'Total loss': 0.49472642938296} | train loss {'Reaction outcome loss': 0.2808611539894364, 'Total loss': 0.2808611539894364}
2023-01-05 13:25:04,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:04,295 INFO:     Epoch: 96
2023-01-05 13:25:06,468 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.536496897538503, 'Total loss': 0.536496897538503} | train loss {'Reaction outcome loss': 0.27262488017499825, 'Total loss': 0.27262488017499825}
2023-01-05 13:25:06,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:06,470 INFO:     Epoch: 97
2023-01-05 13:25:08,621 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4953142563501994, 'Total loss': 0.4953142563501994} | train loss {'Reaction outcome loss': 0.2845411794673503, 'Total loss': 0.2845411794673503}
2023-01-05 13:25:08,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:08,621 INFO:     Epoch: 98
2023-01-05 13:25:10,774 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48945179680983225, 'Total loss': 0.48945179680983225} | train loss {'Reaction outcome loss': 0.27902290843089955, 'Total loss': 0.27902290843089955}
2023-01-05 13:25:10,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:10,775 INFO:     Epoch: 99
2023-01-05 13:25:12,927 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4765592406193415, 'Total loss': 0.4765592406193415} | train loss {'Reaction outcome loss': 0.27249343407026533, 'Total loss': 0.27249343407026533}
2023-01-05 13:25:12,927 INFO:     Best model found after epoch 62 of 100.
2023-01-05 13:25:12,927 INFO:   Done with stage: TRAINING
2023-01-05 13:25:12,927 INFO:   Starting stage: EVALUATION
2023-01-05 13:25:13,059 INFO:   Done with stage: EVALUATION
2023-01-05 13:25:13,059 INFO:   Leaving out SEQ value Fold_6
2023-01-05 13:25:13,072 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 13:25:13,072 INFO:   Starting stage: FEATURE SCALING
2023-01-05 13:25:13,738 INFO:   Done with stage: FEATURE SCALING
2023-01-05 13:25:13,738 INFO:   Starting stage: SCALING TARGETS
2023-01-05 13:25:13,809 INFO:   Done with stage: SCALING TARGETS
2023-01-05 13:25:13,809 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:25:13,809 INFO:     No hyperparam tuning for this model
2023-01-05 13:25:13,809 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:25:13,809 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 13:25:13,810 INFO:     None feature selector for col prot
2023-01-05 13:25:13,810 INFO:     None feature selector for col prot
2023-01-05 13:25:13,810 INFO:     None feature selector for col prot
2023-01-05 13:25:13,811 INFO:     None feature selector for col chem
2023-01-05 13:25:13,811 INFO:     None feature selector for col chem
2023-01-05 13:25:13,811 INFO:     None feature selector for col chem
2023-01-05 13:25:13,811 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 13:25:13,811 INFO:   Starting stage: BUILD MODEL
2023-01-05 13:25:13,812 INFO:     Number of params in model 72901
2023-01-05 13:25:13,815 INFO:   Done with stage: BUILD MODEL
2023-01-05 13:25:13,816 INFO:   Starting stage: TRAINING
2023-01-05 13:25:13,873 INFO:     Val loss before train {'Reaction outcome loss': 1.0508545319239297, 'Total loss': 1.0508545319239297}
2023-01-05 13:25:13,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:13,874 INFO:     Epoch: 0
2023-01-05 13:25:16,045 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8610659758249919, 'Total loss': 0.8610659758249919} | train loss {'Reaction outcome loss': 0.9268370115800024, 'Total loss': 0.9268370115800024}
2023-01-05 13:25:16,046 INFO:     Found new best model at epoch 0
2023-01-05 13:25:16,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:16,047 INFO:     Epoch: 1
2023-01-05 13:25:18,214 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6683778464794159, 'Total loss': 0.6683778464794159} | train loss {'Reaction outcome loss': 0.7381930747187094, 'Total loss': 0.7381930747187094}
2023-01-05 13:25:18,214 INFO:     Found new best model at epoch 1
2023-01-05 13:25:18,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:18,216 INFO:     Epoch: 2
2023-01-05 13:25:20,378 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5692374885082245, 'Total loss': 0.5692374885082245} | train loss {'Reaction outcome loss': 0.5960514663789247, 'Total loss': 0.5960514663789247}
2023-01-05 13:25:20,379 INFO:     Found new best model at epoch 2
2023-01-05 13:25:20,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:20,381 INFO:     Epoch: 3
2023-01-05 13:25:22,554 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5454462508360545, 'Total loss': 0.5454462508360545} | train loss {'Reaction outcome loss': 0.5456993444301591, 'Total loss': 0.5456993444301591}
2023-01-05 13:25:22,554 INFO:     Found new best model at epoch 3
2023-01-05 13:25:22,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:22,555 INFO:     Epoch: 4
2023-01-05 13:25:24,710 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5191910425821941, 'Total loss': 0.5191910425821941} | train loss {'Reaction outcome loss': 0.5227106857493466, 'Total loss': 0.5227106857493466}
2023-01-05 13:25:24,710 INFO:     Found new best model at epoch 4
2023-01-05 13:25:24,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:24,712 INFO:     Epoch: 5
2023-01-05 13:25:26,876 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5300674776236216, 'Total loss': 0.5300674776236216} | train loss {'Reaction outcome loss': 0.5080348349542825, 'Total loss': 0.5080348349542825}
2023-01-05 13:25:26,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:26,878 INFO:     Epoch: 6
2023-01-05 13:25:29,054 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.511618846654892, 'Total loss': 0.511618846654892} | train loss {'Reaction outcome loss': 0.4947158798091248, 'Total loss': 0.4947158798091248}
2023-01-05 13:25:29,054 INFO:     Found new best model at epoch 6
2023-01-05 13:25:29,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:29,056 INFO:     Epoch: 7
2023-01-05 13:25:31,225 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49879086365302405, 'Total loss': 0.49879086365302405} | train loss {'Reaction outcome loss': 0.48203767766160655, 'Total loss': 0.48203767766160655}
2023-01-05 13:25:31,225 INFO:     Found new best model at epoch 7
2023-01-05 13:25:31,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:31,227 INFO:     Epoch: 8
2023-01-05 13:25:33,389 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5001294990380605, 'Total loss': 0.5001294990380605} | train loss {'Reaction outcome loss': 0.4823295490728819, 'Total loss': 0.4823295490728819}
2023-01-05 13:25:33,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:33,390 INFO:     Epoch: 9
2023-01-05 13:25:35,560 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5154553294181824, 'Total loss': 0.5154553294181824} | train loss {'Reaction outcome loss': 0.4734190903630928, 'Total loss': 0.4734190903630928}
2023-01-05 13:25:35,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:35,560 INFO:     Epoch: 10
2023-01-05 13:25:37,725 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.483023934563001, 'Total loss': 0.483023934563001} | train loss {'Reaction outcome loss': 0.467508442619217, 'Total loss': 0.467508442619217}
2023-01-05 13:25:37,725 INFO:     Found new best model at epoch 10
2023-01-05 13:25:37,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:37,726 INFO:     Epoch: 11
2023-01-05 13:25:39,897 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48307328621546425, 'Total loss': 0.48307328621546425} | train loss {'Reaction outcome loss': 0.46213351781833045, 'Total loss': 0.46213351781833045}
2023-01-05 13:25:39,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:39,899 INFO:     Epoch: 12
2023-01-05 13:25:42,080 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5067931135495504, 'Total loss': 0.5067931135495504} | train loss {'Reaction outcome loss': 0.4637826737083683, 'Total loss': 0.4637826737083683}
2023-01-05 13:25:42,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:42,080 INFO:     Epoch: 13
2023-01-05 13:25:44,247 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47113641500473025, 'Total loss': 0.47113641500473025} | train loss {'Reaction outcome loss': 0.45000848755079054, 'Total loss': 0.45000848755079054}
2023-01-05 13:25:44,247 INFO:     Found new best model at epoch 13
2023-01-05 13:25:44,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:44,248 INFO:     Epoch: 14
2023-01-05 13:25:46,415 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4599835048119227, 'Total loss': 0.4599835048119227} | train loss {'Reaction outcome loss': 0.44847743326145817, 'Total loss': 0.44847743326145817}
2023-01-05 13:25:46,416 INFO:     Found new best model at epoch 14
2023-01-05 13:25:46,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:46,417 INFO:     Epoch: 15
2023-01-05 13:25:48,571 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4687444786230723, 'Total loss': 0.4687444786230723} | train loss {'Reaction outcome loss': 0.44530580001832776, 'Total loss': 0.44530580001832776}
2023-01-05 13:25:48,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:48,571 INFO:     Epoch: 16
2023-01-05 13:25:50,754 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47088412046432493, 'Total loss': 0.47088412046432493} | train loss {'Reaction outcome loss': 0.43824941054363115, 'Total loss': 0.43824941054363115}
2023-01-05 13:25:50,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:50,755 INFO:     Epoch: 17
2023-01-05 13:25:52,912 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48193174997965493, 'Total loss': 0.48193174997965493} | train loss {'Reaction outcome loss': 0.43771083260271093, 'Total loss': 0.43771083260271093}
2023-01-05 13:25:52,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:52,912 INFO:     Epoch: 18
2023-01-05 13:25:55,080 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4655633678038915, 'Total loss': 0.4655633678038915} | train loss {'Reaction outcome loss': 0.4370314073261371, 'Total loss': 0.4370314073261371}
2023-01-05 13:25:55,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:55,081 INFO:     Epoch: 19
2023-01-05 13:25:57,248 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4725661406914393, 'Total loss': 0.4725661406914393} | train loss {'Reaction outcome loss': 0.42479682436703775, 'Total loss': 0.42479682436703775}
2023-01-05 13:25:57,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:57,249 INFO:     Epoch: 20
2023-01-05 13:25:59,418 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44262342949708305, 'Total loss': 0.44262342949708305} | train loss {'Reaction outcome loss': 0.42073135599762956, 'Total loss': 0.42073135599762956}
2023-01-05 13:25:59,418 INFO:     Found new best model at epoch 20
2023-01-05 13:25:59,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:25:59,420 INFO:     Epoch: 21
2023-01-05 13:26:01,579 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4563243418931961, 'Total loss': 0.4563243418931961} | train loss {'Reaction outcome loss': 0.41299099776396253, 'Total loss': 0.41299099776396253}
2023-01-05 13:26:01,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:01,580 INFO:     Epoch: 22
2023-01-05 13:26:03,745 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44957343141237893, 'Total loss': 0.44957343141237893} | train loss {'Reaction outcome loss': 0.4168131432701104, 'Total loss': 0.4168131432701104}
2023-01-05 13:26:03,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:03,747 INFO:     Epoch: 23
2023-01-05 13:26:05,960 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4700598527987798, 'Total loss': 0.4700598527987798} | train loss {'Reaction outcome loss': 0.41180166228260806, 'Total loss': 0.41180166228260806}
2023-01-05 13:26:05,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:05,960 INFO:     Epoch: 24
2023-01-05 13:26:08,155 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47808827459812164, 'Total loss': 0.47808827459812164} | train loss {'Reaction outcome loss': 0.40374777043769505, 'Total loss': 0.40374777043769505}
2023-01-05 13:26:08,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:08,156 INFO:     Epoch: 25
2023-01-05 13:26:10,352 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4702266494433085, 'Total loss': 0.4702266494433085} | train loss {'Reaction outcome loss': 0.3976837987288671, 'Total loss': 0.3976837987288671}
2023-01-05 13:26:10,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:10,352 INFO:     Epoch: 26
2023-01-05 13:26:12,540 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4661031305789948, 'Total loss': 0.4661031305789948} | train loss {'Reaction outcome loss': 0.39979819754400836, 'Total loss': 0.39979819754400836}
2023-01-05 13:26:12,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:12,540 INFO:     Epoch: 27
2023-01-05 13:26:14,706 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.437365393837293, 'Total loss': 0.437365393837293} | train loss {'Reaction outcome loss': 0.3937406089923442, 'Total loss': 0.3937406089923442}
2023-01-05 13:26:14,708 INFO:     Found new best model at epoch 27
2023-01-05 13:26:14,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:14,709 INFO:     Epoch: 28
2023-01-05 13:26:16,877 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4501465141773224, 'Total loss': 0.4501465141773224} | train loss {'Reaction outcome loss': 0.38902026320730304, 'Total loss': 0.38902026320730304}
2023-01-05 13:26:16,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:16,877 INFO:     Epoch: 29
2023-01-05 13:26:19,016 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4463669533530871, 'Total loss': 0.4463669533530871} | train loss {'Reaction outcome loss': 0.3888932104198941, 'Total loss': 0.3888932104198941}
2023-01-05 13:26:19,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:19,016 INFO:     Epoch: 30
2023-01-05 13:26:21,137 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46114992797374726, 'Total loss': 0.46114992797374726} | train loss {'Reaction outcome loss': 0.3793663398668654, 'Total loss': 0.3793663398668654}
2023-01-05 13:26:21,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:21,138 INFO:     Epoch: 31
2023-01-05 13:26:23,269 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4611684521039327, 'Total loss': 0.4611684521039327} | train loss {'Reaction outcome loss': 0.37385023315353083, 'Total loss': 0.37385023315353083}
2023-01-05 13:26:23,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:23,269 INFO:     Epoch: 32
2023-01-05 13:26:25,423 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46337475975354514, 'Total loss': 0.46337475975354514} | train loss {'Reaction outcome loss': 0.3833061992745537, 'Total loss': 0.3833061992745537}
2023-01-05 13:26:25,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:25,424 INFO:     Epoch: 33
2023-01-05 13:26:27,590 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4789339601993561, 'Total loss': 0.4789339601993561} | train loss {'Reaction outcome loss': 0.36995560704101726, 'Total loss': 0.36995560704101726}
2023-01-05 13:26:27,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:27,590 INFO:     Epoch: 34
2023-01-05 13:26:29,756 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45571691195170083, 'Total loss': 0.45571691195170083} | train loss {'Reaction outcome loss': 0.3761421597229875, 'Total loss': 0.3761421597229875}
2023-01-05 13:26:29,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:29,756 INFO:     Epoch: 35
2023-01-05 13:26:31,899 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45808813273906707, 'Total loss': 0.45808813273906707} | train loss {'Reaction outcome loss': 0.3703234891410554, 'Total loss': 0.3703234891410554}
2023-01-05 13:26:31,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:31,900 INFO:     Epoch: 36
2023-01-05 13:26:34,054 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4575076599915822, 'Total loss': 0.4575076599915822} | train loss {'Reaction outcome loss': 0.3633000178780366, 'Total loss': 0.3633000178780366}
2023-01-05 13:26:34,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:34,054 INFO:     Epoch: 37
2023-01-05 13:26:36,206 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4609751512606939, 'Total loss': 0.4609751512606939} | train loss {'Reaction outcome loss': 0.36288790407486343, 'Total loss': 0.36288790407486343}
2023-01-05 13:26:36,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:36,206 INFO:     Epoch: 38
2023-01-05 13:26:38,382 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4498268455266953, 'Total loss': 0.4498268455266953} | train loss {'Reaction outcome loss': 0.35755692831230507, 'Total loss': 0.35755692831230507}
2023-01-05 13:26:38,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:38,383 INFO:     Epoch: 39
2023-01-05 13:26:40,565 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4700473487377167, 'Total loss': 0.4700473487377167} | train loss {'Reaction outcome loss': 0.3550124813799178, 'Total loss': 0.3550124813799178}
2023-01-05 13:26:40,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:40,566 INFO:     Epoch: 40
2023-01-05 13:26:42,730 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45761678119500476, 'Total loss': 0.45761678119500476} | train loss {'Reaction outcome loss': 0.35392985535980565, 'Total loss': 0.35392985535980565}
2023-01-05 13:26:42,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:42,731 INFO:     Epoch: 41
2023-01-05 13:26:44,906 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4954109291235606, 'Total loss': 0.4954109291235606} | train loss {'Reaction outcome loss': 0.3577966394729993, 'Total loss': 0.3577966394729993}
2023-01-05 13:26:44,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:44,907 INFO:     Epoch: 42
2023-01-05 13:26:47,080 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45732806126276654, 'Total loss': 0.45732806126276654} | train loss {'Reaction outcome loss': 0.34995656716048934, 'Total loss': 0.34995656716048934}
2023-01-05 13:26:47,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:47,080 INFO:     Epoch: 43
2023-01-05 13:26:49,259 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4644449015458425, 'Total loss': 0.4644449015458425} | train loss {'Reaction outcome loss': 0.3485494186355319, 'Total loss': 0.3485494186355319}
2023-01-05 13:26:49,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:49,260 INFO:     Epoch: 44
2023-01-05 13:26:51,445 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44707476695378623, 'Total loss': 0.44707476695378623} | train loss {'Reaction outcome loss': 0.34536982882458594, 'Total loss': 0.34536982882458594}
2023-01-05 13:26:51,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:51,445 INFO:     Epoch: 45
2023-01-05 13:26:53,611 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45323345561822254, 'Total loss': 0.45323345561822254} | train loss {'Reaction outcome loss': 0.3334237161472386, 'Total loss': 0.3334237161472386}
2023-01-05 13:26:53,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:53,611 INFO:     Epoch: 46
2023-01-05 13:26:55,784 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4713903804620107, 'Total loss': 0.4713903804620107} | train loss {'Reaction outcome loss': 0.3411460713977633, 'Total loss': 0.3411460713977633}
2023-01-05 13:26:55,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:55,786 INFO:     Epoch: 47
2023-01-05 13:26:57,969 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4450516569117705, 'Total loss': 0.4450516569117705} | train loss {'Reaction outcome loss': 0.33184524871651017, 'Total loss': 0.33184524871651017}
2023-01-05 13:26:57,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:26:57,969 INFO:     Epoch: 48
2023-01-05 13:27:00,142 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46843529442946114, 'Total loss': 0.46843529442946114} | train loss {'Reaction outcome loss': 0.33104322113715356, 'Total loss': 0.33104322113715356}
2023-01-05 13:27:00,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:00,142 INFO:     Epoch: 49
2023-01-05 13:27:02,323 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47463735441366833, 'Total loss': 0.47463735441366833} | train loss {'Reaction outcome loss': 0.32436823830116096, 'Total loss': 0.32436823830116096}
2023-01-05 13:27:02,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:02,324 INFO:     Epoch: 50
2023-01-05 13:27:04,499 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4510101358095805, 'Total loss': 0.4510101358095805} | train loss {'Reaction outcome loss': 0.33233305489113185, 'Total loss': 0.33233305489113185}
2023-01-05 13:27:04,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:04,499 INFO:     Epoch: 51
2023-01-05 13:27:06,665 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4682648758093516, 'Total loss': 0.4682648758093516} | train loss {'Reaction outcome loss': 0.3273273911394367, 'Total loss': 0.3273273911394367}
2023-01-05 13:27:06,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:06,666 INFO:     Epoch: 52
2023-01-05 13:27:08,843 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48359668950239815, 'Total loss': 0.48359668950239815} | train loss {'Reaction outcome loss': 0.32323706074742203, 'Total loss': 0.32323706074742203}
2023-01-05 13:27:08,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:08,843 INFO:     Epoch: 53
2023-01-05 13:27:11,013 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47496729493141177, 'Total loss': 0.47496729493141177} | train loss {'Reaction outcome loss': 0.321429451530806, 'Total loss': 0.321429451530806}
2023-01-05 13:27:11,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:11,013 INFO:     Epoch: 54
2023-01-05 13:27:13,180 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4879514197508494, 'Total loss': 0.4879514197508494} | train loss {'Reaction outcome loss': 0.3223231310690568, 'Total loss': 0.3223231310690568}
2023-01-05 13:27:13,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:13,181 INFO:     Epoch: 55
2023-01-05 13:27:15,358 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49565321803092954, 'Total loss': 0.49565321803092954} | train loss {'Reaction outcome loss': 0.3190884472338301, 'Total loss': 0.3190884472338301}
2023-01-05 13:27:15,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:15,359 INFO:     Epoch: 56
2023-01-05 13:27:17,524 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4653071969747543, 'Total loss': 0.4653071969747543} | train loss {'Reaction outcome loss': 0.3126722652774425, 'Total loss': 0.3126722652774425}
2023-01-05 13:27:17,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:17,524 INFO:     Epoch: 57
2023-01-05 13:27:19,704 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44480934540430705, 'Total loss': 0.44480934540430705} | train loss {'Reaction outcome loss': 0.3168895698088601, 'Total loss': 0.3168895698088601}
2023-01-05 13:27:19,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:19,705 INFO:     Epoch: 58
2023-01-05 13:27:21,890 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5043761670589447, 'Total loss': 0.5043761670589447} | train loss {'Reaction outcome loss': 0.31139265046545744, 'Total loss': 0.31139265046545744}
2023-01-05 13:27:21,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:21,890 INFO:     Epoch: 59
2023-01-05 13:27:24,082 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4549874653418859, 'Total loss': 0.4549874653418859} | train loss {'Reaction outcome loss': 0.303253527340691, 'Total loss': 0.303253527340691}
2023-01-05 13:27:24,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:24,083 INFO:     Epoch: 60
2023-01-05 13:27:26,268 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4716287950674693, 'Total loss': 0.4716287950674693} | train loss {'Reaction outcome loss': 0.30485527446016075, 'Total loss': 0.30485527446016075}
2023-01-05 13:27:26,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:26,268 INFO:     Epoch: 61
2023-01-05 13:27:28,437 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4615957031647364, 'Total loss': 0.4615957031647364} | train loss {'Reaction outcome loss': 0.30861644121391246, 'Total loss': 0.30861644121391246}
2023-01-05 13:27:28,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:28,437 INFO:     Epoch: 62
2023-01-05 13:27:30,619 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45578935543696086, 'Total loss': 0.45578935543696086} | train loss {'Reaction outcome loss': 0.307608399829333, 'Total loss': 0.307608399829333}
2023-01-05 13:27:30,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:30,620 INFO:     Epoch: 63
2023-01-05 13:27:32,796 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44945741395155586, 'Total loss': 0.44945741395155586} | train loss {'Reaction outcome loss': 0.29868315437317755, 'Total loss': 0.29868315437317755}
2023-01-05 13:27:32,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:32,796 INFO:     Epoch: 64
2023-01-05 13:27:34,975 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.464498233795166, 'Total loss': 0.464498233795166} | train loss {'Reaction outcome loss': 0.29748343184106185, 'Total loss': 0.29748343184106185}
2023-01-05 13:27:34,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:34,975 INFO:     Epoch: 65
2023-01-05 13:27:37,151 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4965706795454025, 'Total loss': 0.4965706795454025} | train loss {'Reaction outcome loss': 0.293172737314544, 'Total loss': 0.293172737314544}
2023-01-05 13:27:37,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:37,153 INFO:     Epoch: 66
2023-01-05 13:27:39,348 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4891309748093287, 'Total loss': 0.4891309748093287} | train loss {'Reaction outcome loss': 0.2985537964043742, 'Total loss': 0.2985537964043742}
2023-01-05 13:27:39,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:39,349 INFO:     Epoch: 67
2023-01-05 13:27:41,519 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4930003305276235, 'Total loss': 0.4930003305276235} | train loss {'Reaction outcome loss': 0.2935630973522629, 'Total loss': 0.2935630973522629}
2023-01-05 13:27:41,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:41,521 INFO:     Epoch: 68
2023-01-05 13:27:43,745 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45599956462780633, 'Total loss': 0.45599956462780633} | train loss {'Reaction outcome loss': 0.2946975657628977, 'Total loss': 0.2946975657628977}
2023-01-05 13:27:43,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:43,746 INFO:     Epoch: 69
2023-01-05 13:27:45,944 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46671767930189767, 'Total loss': 0.46671767930189767} | train loss {'Reaction outcome loss': 0.2859911836468571, 'Total loss': 0.2859911836468571}
2023-01-05 13:27:45,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:45,945 INFO:     Epoch: 70
2023-01-05 13:27:48,175 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4676918437083562, 'Total loss': 0.4676918437083562} | train loss {'Reaction outcome loss': 0.2879956501270459, 'Total loss': 0.2879956501270459}
2023-01-05 13:27:48,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:48,176 INFO:     Epoch: 71
2023-01-05 13:27:50,385 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4744206388791402, 'Total loss': 0.4744206388791402} | train loss {'Reaction outcome loss': 0.2815006955355298, 'Total loss': 0.2815006955355298}
2023-01-05 13:27:50,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:50,385 INFO:     Epoch: 72
2023-01-05 13:27:52,588 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4919425139824549, 'Total loss': 0.4919425139824549} | train loss {'Reaction outcome loss': 0.2763242384600403, 'Total loss': 0.2763242384600403}
2023-01-05 13:27:52,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:52,589 INFO:     Epoch: 73
2023-01-05 13:27:54,788 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5056701411803564, 'Total loss': 0.5056701411803564} | train loss {'Reaction outcome loss': 0.28440727573224356, 'Total loss': 0.28440727573224356}
2023-01-05 13:27:54,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:54,789 INFO:     Epoch: 74
2023-01-05 13:27:56,967 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4811430811882019, 'Total loss': 0.4811430811882019} | train loss {'Reaction outcome loss': 0.28241630909890475, 'Total loss': 0.28241630909890475}
2023-01-05 13:27:56,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:56,967 INFO:     Epoch: 75
2023-01-05 13:27:59,153 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5159440358479818, 'Total loss': 0.5159440358479818} | train loss {'Reaction outcome loss': 0.28005066099795195, 'Total loss': 0.28005066099795195}
2023-01-05 13:27:59,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:27:59,154 INFO:     Epoch: 76
2023-01-05 13:28:01,339 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4748564044634501, 'Total loss': 0.4748564044634501} | train loss {'Reaction outcome loss': 0.2788751878597461, 'Total loss': 0.2788751878597461}
2023-01-05 13:28:01,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:01,339 INFO:     Epoch: 77
2023-01-05 13:28:03,537 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4691198398669561, 'Total loss': 0.4691198398669561} | train loss {'Reaction outcome loss': 0.2776969253263749, 'Total loss': 0.2776969253263749}
2023-01-05 13:28:03,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:03,537 INFO:     Epoch: 78
2023-01-05 13:28:05,728 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4548671245574951, 'Total loss': 0.4548671245574951} | train loss {'Reaction outcome loss': 0.27025628478572256, 'Total loss': 0.27025628478572256}
2023-01-05 13:28:05,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:05,729 INFO:     Epoch: 79
2023-01-05 13:28:07,914 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48029050131638845, 'Total loss': 0.48029050131638845} | train loss {'Reaction outcome loss': 0.271327866301855, 'Total loss': 0.271327866301855}
2023-01-05 13:28:07,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:07,915 INFO:     Epoch: 80
2023-01-05 13:28:10,220 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4881900787353516, 'Total loss': 0.4881900787353516} | train loss {'Reaction outcome loss': 0.2757511002142722, 'Total loss': 0.2757511002142722}
2023-01-05 13:28:10,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:10,221 INFO:     Epoch: 81
2023-01-05 13:28:12,397 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4823552111784617, 'Total loss': 0.4823552111784617} | train loss {'Reaction outcome loss': 0.2712169042805257, 'Total loss': 0.2712169042805257}
2023-01-05 13:28:12,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:12,398 INFO:     Epoch: 82
2023-01-05 13:28:14,565 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47565608421961464, 'Total loss': 0.47565608421961464} | train loss {'Reaction outcome loss': 0.2686356502292604, 'Total loss': 0.2686356502292604}
2023-01-05 13:28:14,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:14,565 INFO:     Epoch: 83
2023-01-05 13:28:16,747 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48109231690565746, 'Total loss': 0.48109231690565746} | train loss {'Reaction outcome loss': 0.2671904856816526, 'Total loss': 0.2671904856816526}
2023-01-05 13:28:16,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:16,749 INFO:     Epoch: 84
2023-01-05 13:28:18,925 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49503983855247496, 'Total loss': 0.49503983855247496} | train loss {'Reaction outcome loss': 0.2657607912828991, 'Total loss': 0.2657607912828991}
2023-01-05 13:28:18,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:18,925 INFO:     Epoch: 85
2023-01-05 13:28:21,096 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5018846561511358, 'Total loss': 0.5018846561511358} | train loss {'Reaction outcome loss': 0.26054863300887254, 'Total loss': 0.26054863300887254}
2023-01-05 13:28:21,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:21,096 INFO:     Epoch: 86
2023-01-05 13:28:23,270 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.485137602686882, 'Total loss': 0.485137602686882} | train loss {'Reaction outcome loss': 0.26302964756742714, 'Total loss': 0.26302964756742714}
2023-01-05 13:28:23,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:23,271 INFO:     Epoch: 87
2023-01-05 13:28:25,452 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48702785025040307, 'Total loss': 0.48702785025040307} | train loss {'Reaction outcome loss': 0.26384018061662406, 'Total loss': 0.26384018061662406}
2023-01-05 13:28:25,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:25,452 INFO:     Epoch: 88
2023-01-05 13:28:27,614 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48213960230350494, 'Total loss': 0.48213960230350494} | train loss {'Reaction outcome loss': 0.26195038777745805, 'Total loss': 0.26195038777745805}
2023-01-05 13:28:27,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:27,615 INFO:     Epoch: 89
2023-01-05 13:28:29,789 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.521110886335373, 'Total loss': 0.521110886335373} | train loss {'Reaction outcome loss': 0.2601262689685778, 'Total loss': 0.2601262689685778}
2023-01-05 13:28:29,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:29,790 INFO:     Epoch: 90
2023-01-05 13:28:31,940 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4972342143456141, 'Total loss': 0.4972342143456141} | train loss {'Reaction outcome loss': 0.2570023652408205, 'Total loss': 0.2570023652408205}
2023-01-05 13:28:31,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:31,940 INFO:     Epoch: 91
2023-01-05 13:28:34,131 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4665882835785548, 'Total loss': 0.4665882835785548} | train loss {'Reaction outcome loss': 0.26459875965780083, 'Total loss': 0.26459875965780083}
2023-01-05 13:28:34,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:34,133 INFO:     Epoch: 92
2023-01-05 13:28:36,317 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5017429639895757, 'Total loss': 0.5017429639895757} | train loss {'Reaction outcome loss': 0.2509099580213051, 'Total loss': 0.2509099580213051}
2023-01-05 13:28:36,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:36,318 INFO:     Epoch: 93
2023-01-05 13:28:38,510 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4888987938563029, 'Total loss': 0.4888987938563029} | train loss {'Reaction outcome loss': 0.2571867336300521, 'Total loss': 0.2571867336300521}
2023-01-05 13:28:38,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:38,510 INFO:     Epoch: 94
2023-01-05 13:28:40,689 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47842177251974743, 'Total loss': 0.47842177251974743} | train loss {'Reaction outcome loss': 0.25292541923182965, 'Total loss': 0.25292541923182965}
2023-01-05 13:28:40,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:40,690 INFO:     Epoch: 95
2023-01-05 13:28:42,881 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5055506487687429, 'Total loss': 0.5055506487687429} | train loss {'Reaction outcome loss': 0.25418293989172697, 'Total loss': 0.25418293989172697}
2023-01-05 13:28:42,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:42,882 INFO:     Epoch: 96
2023-01-05 13:28:45,049 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46796629428863523, 'Total loss': 0.46796629428863523} | train loss {'Reaction outcome loss': 0.24954294920344214, 'Total loss': 0.24954294920344214}
2023-01-05 13:28:45,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:45,049 INFO:     Epoch: 97
2023-01-05 13:28:47,133 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5213869522015254, 'Total loss': 0.5213869522015254} | train loss {'Reaction outcome loss': 0.24651146175117913, 'Total loss': 0.24651146175117913}
2023-01-05 13:28:47,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:47,134 INFO:     Epoch: 98
2023-01-05 13:28:49,253 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44852935274442035, 'Total loss': 0.44852935274442035} | train loss {'Reaction outcome loss': 0.2512069767213255, 'Total loss': 0.2512069767213255}
2023-01-05 13:28:49,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:49,253 INFO:     Epoch: 99
2023-01-05 13:28:51,488 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5334604054689407, 'Total loss': 0.5334604054689407} | train loss {'Reaction outcome loss': 0.24430987214003874, 'Total loss': 0.24430987214003874}
2023-01-05 13:28:51,489 INFO:     Best model found after epoch 28 of 100.
2023-01-05 13:28:51,489 INFO:   Done with stage: TRAINING
2023-01-05 13:28:51,489 INFO:   Starting stage: EVALUATION
2023-01-05 13:28:51,617 INFO:   Done with stage: EVALUATION
2023-01-05 13:28:51,617 INFO:   Leaving out SEQ value Fold_7
2023-01-05 13:28:51,630 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 13:28:51,630 INFO:   Starting stage: FEATURE SCALING
2023-01-05 13:28:52,301 INFO:   Done with stage: FEATURE SCALING
2023-01-05 13:28:52,301 INFO:   Starting stage: SCALING TARGETS
2023-01-05 13:28:52,372 INFO:   Done with stage: SCALING TARGETS
2023-01-05 13:28:52,373 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:28:52,373 INFO:     No hyperparam tuning for this model
2023-01-05 13:28:52,373 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:28:52,373 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 13:28:52,373 INFO:     None feature selector for col prot
2023-01-05 13:28:52,374 INFO:     None feature selector for col prot
2023-01-05 13:28:52,374 INFO:     None feature selector for col prot
2023-01-05 13:28:52,374 INFO:     None feature selector for col chem
2023-01-05 13:28:52,374 INFO:     None feature selector for col chem
2023-01-05 13:28:52,374 INFO:     None feature selector for col chem
2023-01-05 13:28:52,374 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 13:28:52,375 INFO:   Starting stage: BUILD MODEL
2023-01-05 13:28:52,376 INFO:     Number of params in model 72901
2023-01-05 13:28:52,379 INFO:   Done with stage: BUILD MODEL
2023-01-05 13:28:52,379 INFO:   Starting stage: TRAINING
2023-01-05 13:28:52,440 INFO:     Val loss before train {'Reaction outcome loss': 0.9923887570699056, 'Total loss': 0.9923887570699056}
2023-01-05 13:28:52,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:52,440 INFO:     Epoch: 0
2023-01-05 13:28:54,654 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8413545568784078, 'Total loss': 0.8413545568784078} | train loss {'Reaction outcome loss': 0.9461246006514715, 'Total loss': 0.9461246006514715}
2023-01-05 13:28:54,654 INFO:     Found new best model at epoch 0
2023-01-05 13:28:54,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:54,655 INFO:     Epoch: 1
2023-01-05 13:28:56,870 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6869413197040558, 'Total loss': 0.6869413197040558} | train loss {'Reaction outcome loss': 0.7809283052287672, 'Total loss': 0.7809283052287672}
2023-01-05 13:28:56,870 INFO:     Found new best model at epoch 1
2023-01-05 13:28:56,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:56,871 INFO:     Epoch: 2
2023-01-05 13:28:59,092 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5414979457855225, 'Total loss': 0.5414979457855225} | train loss {'Reaction outcome loss': 0.6157531249266774, 'Total loss': 0.6157531249266774}
2023-01-05 13:28:59,093 INFO:     Found new best model at epoch 2
2023-01-05 13:28:59,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:28:59,094 INFO:     Epoch: 3
2023-01-05 13:29:01,286 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49476059675216677, 'Total loss': 0.49476059675216677} | train loss {'Reaction outcome loss': 0.5650670388578505, 'Total loss': 0.5650670388578505}
2023-01-05 13:29:01,287 INFO:     Found new best model at epoch 3
2023-01-05 13:29:01,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:01,288 INFO:     Epoch: 4
2023-01-05 13:29:03,498 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47797593077023826, 'Total loss': 0.47797593077023826} | train loss {'Reaction outcome loss': 0.5366675271180229, 'Total loss': 0.5366675271180229}
2023-01-05 13:29:03,499 INFO:     Found new best model at epoch 4
2023-01-05 13:29:03,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:03,501 INFO:     Epoch: 5
2023-01-05 13:29:05,720 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4783957928419113, 'Total loss': 0.4783957928419113} | train loss {'Reaction outcome loss': 0.5088936797397184, 'Total loss': 0.5088936797397184}
2023-01-05 13:29:05,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:05,720 INFO:     Epoch: 6
2023-01-05 13:29:07,924 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45103363196055096, 'Total loss': 0.45103363196055096} | train loss {'Reaction outcome loss': 0.4970124162247647, 'Total loss': 0.4970124162247647}
2023-01-05 13:29:07,925 INFO:     Found new best model at epoch 6
2023-01-05 13:29:07,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:07,927 INFO:     Epoch: 7
2023-01-05 13:29:10,151 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4443606684605281, 'Total loss': 0.4443606684605281} | train loss {'Reaction outcome loss': 0.4911267094557052, 'Total loss': 0.4911267094557052}
2023-01-05 13:29:10,151 INFO:     Found new best model at epoch 7
2023-01-05 13:29:10,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:10,152 INFO:     Epoch: 8
2023-01-05 13:29:12,341 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4414980361859004, 'Total loss': 0.4414980361859004} | train loss {'Reaction outcome loss': 0.4821546714990383, 'Total loss': 0.4821546714990383}
2023-01-05 13:29:12,341 INFO:     Found new best model at epoch 8
2023-01-05 13:29:12,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:12,343 INFO:     Epoch: 9
2023-01-05 13:29:14,566 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4319490124781927, 'Total loss': 0.4319490124781927} | train loss {'Reaction outcome loss': 0.47909131836470054, 'Total loss': 0.47909131836470054}
2023-01-05 13:29:14,567 INFO:     Found new best model at epoch 9
2023-01-05 13:29:14,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:14,568 INFO:     Epoch: 10
2023-01-05 13:29:16,790 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42341963748137157, 'Total loss': 0.42341963748137157} | train loss {'Reaction outcome loss': 0.4662677773588296, 'Total loss': 0.4662677773588296}
2023-01-05 13:29:16,790 INFO:     Found new best model at epoch 10
2023-01-05 13:29:16,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:16,792 INFO:     Epoch: 11
2023-01-05 13:29:19,014 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41713124215602876, 'Total loss': 0.41713124215602876} | train loss {'Reaction outcome loss': 0.4649743024290175, 'Total loss': 0.4649743024290175}
2023-01-05 13:29:19,014 INFO:     Found new best model at epoch 11
2023-01-05 13:29:19,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:19,015 INFO:     Epoch: 12
2023-01-05 13:29:21,238 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4244234065214793, 'Total loss': 0.4244234065214793} | train loss {'Reaction outcome loss': 0.458259338506268, 'Total loss': 0.458259338506268}
2023-01-05 13:29:21,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:21,240 INFO:     Epoch: 13
2023-01-05 13:29:23,456 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43558136026064553, 'Total loss': 0.43558136026064553} | train loss {'Reaction outcome loss': 0.4553792250909559, 'Total loss': 0.4553792250909559}
2023-01-05 13:29:23,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:23,456 INFO:     Epoch: 14
2023-01-05 13:29:25,708 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.427591036260128, 'Total loss': 0.427591036260128} | train loss {'Reaction outcome loss': 0.46107670896943065, 'Total loss': 0.46107670896943065}
2023-01-05 13:29:25,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:25,708 INFO:     Epoch: 15
2023-01-05 13:29:27,947 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4103192408879598, 'Total loss': 0.4103192408879598} | train loss {'Reaction outcome loss': 0.45171738573876413, 'Total loss': 0.45171738573876413}
2023-01-05 13:29:27,949 INFO:     Found new best model at epoch 15
2023-01-05 13:29:27,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:27,950 INFO:     Epoch: 16
2023-01-05 13:29:30,153 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4206945349772771, 'Total loss': 0.4206945349772771} | train loss {'Reaction outcome loss': 0.44101507974330056, 'Total loss': 0.44101507974330056}
2023-01-05 13:29:30,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:30,153 INFO:     Epoch: 17
2023-01-05 13:29:32,391 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42816823422908784, 'Total loss': 0.42816823422908784} | train loss {'Reaction outcome loss': 0.44296758500496397, 'Total loss': 0.44296758500496397}
2023-01-05 13:29:32,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:32,392 INFO:     Epoch: 18
2023-01-05 13:29:34,623 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4273483335971832, 'Total loss': 0.4273483335971832} | train loss {'Reaction outcome loss': 0.43873901121939224, 'Total loss': 0.43873901121939224}
2023-01-05 13:29:34,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:34,623 INFO:     Epoch: 19
2023-01-05 13:29:36,812 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43549763162930805, 'Total loss': 0.43549763162930805} | train loss {'Reaction outcome loss': 0.42712942638393975, 'Total loss': 0.42712942638393975}
2023-01-05 13:29:36,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:36,813 INFO:     Epoch: 20
2023-01-05 13:29:39,050 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40215979317824047, 'Total loss': 0.40215979317824047} | train loss {'Reaction outcome loss': 0.4267395626748507, 'Total loss': 0.4267395626748507}
2023-01-05 13:29:39,051 INFO:     Found new best model at epoch 20
2023-01-05 13:29:39,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:39,052 INFO:     Epoch: 21
2023-01-05 13:29:41,236 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39249656200408933, 'Total loss': 0.39249656200408933} | train loss {'Reaction outcome loss': 0.42257099800432724, 'Total loss': 0.42257099800432724}
2023-01-05 13:29:41,236 INFO:     Found new best model at epoch 21
2023-01-05 13:29:41,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:41,237 INFO:     Epoch: 22
2023-01-05 13:29:43,405 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39171940883000694, 'Total loss': 0.39171940883000694} | train loss {'Reaction outcome loss': 0.4238040555383254, 'Total loss': 0.4238040555383254}
2023-01-05 13:29:43,406 INFO:     Found new best model at epoch 22
2023-01-05 13:29:43,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:43,408 INFO:     Epoch: 23
2023-01-05 13:29:45,560 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42000593344370524, 'Total loss': 0.42000593344370524} | train loss {'Reaction outcome loss': 0.4178880995436423, 'Total loss': 0.4178880995436423}
2023-01-05 13:29:45,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:45,560 INFO:     Epoch: 24
2023-01-05 13:29:47,697 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3971243292093277, 'Total loss': 0.3971243292093277} | train loss {'Reaction outcome loss': 0.43075268411100126, 'Total loss': 0.43075268411100126}
2023-01-05 13:29:47,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:47,698 INFO:     Epoch: 25
2023-01-05 13:29:49,830 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40156836807727814, 'Total loss': 0.40156836807727814} | train loss {'Reaction outcome loss': 0.4099918387188497, 'Total loss': 0.4099918387188497}
2023-01-05 13:29:49,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:49,832 INFO:     Epoch: 26
2023-01-05 13:29:52,003 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39822255571683246, 'Total loss': 0.39822255571683246} | train loss {'Reaction outcome loss': 0.41104081141816423, 'Total loss': 0.41104081141816423}
2023-01-05 13:29:52,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:52,003 INFO:     Epoch: 27
2023-01-05 13:29:54,142 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4207301358381907, 'Total loss': 0.4207301358381907} | train loss {'Reaction outcome loss': 0.40689600758470484, 'Total loss': 0.40689600758470484}
2023-01-05 13:29:54,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:54,143 INFO:     Epoch: 28
2023-01-05 13:29:56,293 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4054894665877024, 'Total loss': 0.4054894665877024} | train loss {'Reaction outcome loss': 0.4100032876835346, 'Total loss': 0.4100032876835346}
2023-01-05 13:29:56,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:56,294 INFO:     Epoch: 29
2023-01-05 13:29:58,427 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4211582362651825, 'Total loss': 0.4211582362651825} | train loss {'Reaction outcome loss': 0.39982009093290655, 'Total loss': 0.39982009093290655}
2023-01-05 13:29:58,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:29:58,428 INFO:     Epoch: 30
2023-01-05 13:30:00,587 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3827651500701904, 'Total loss': 0.3827651500701904} | train loss {'Reaction outcome loss': 0.4015004603551579, 'Total loss': 0.4015004603551579}
2023-01-05 13:30:00,588 INFO:     Found new best model at epoch 30
2023-01-05 13:30:00,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:00,589 INFO:     Epoch: 31
2023-01-05 13:30:02,754 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39533655643463134, 'Total loss': 0.39533655643463134} | train loss {'Reaction outcome loss': 0.3943065011535442, 'Total loss': 0.3943065011535442}
2023-01-05 13:30:02,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:02,755 INFO:     Epoch: 32
2023-01-05 13:30:04,914 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43134734183549883, 'Total loss': 0.43134734183549883} | train loss {'Reaction outcome loss': 0.3939553259237521, 'Total loss': 0.3939553259237521}
2023-01-05 13:30:04,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:04,914 INFO:     Epoch: 33
2023-01-05 13:30:07,058 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4117271274328232, 'Total loss': 0.4117271274328232} | train loss {'Reaction outcome loss': 0.3982118590282735, 'Total loss': 0.3982118590282735}
2023-01-05 13:30:07,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:07,059 INFO:     Epoch: 34
2023-01-05 13:30:09,210 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43511027892430626, 'Total loss': 0.43511027892430626} | train loss {'Reaction outcome loss': 0.38206255812184425, 'Total loss': 0.38206255812184425}
2023-01-05 13:30:09,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:09,210 INFO:     Epoch: 35
2023-01-05 13:30:11,366 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.406801837682724, 'Total loss': 0.406801837682724} | train loss {'Reaction outcome loss': 0.3824041839752286, 'Total loss': 0.3824041839752286}
2023-01-05 13:30:11,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:11,367 INFO:     Epoch: 36
2023-01-05 13:30:13,526 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.382057053844134, 'Total loss': 0.382057053844134} | train loss {'Reaction outcome loss': 0.38546664246519946, 'Total loss': 0.38546664246519946}
2023-01-05 13:30:13,527 INFO:     Found new best model at epoch 36
2023-01-05 13:30:13,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:13,528 INFO:     Epoch: 37
2023-01-05 13:30:15,687 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42251626451810204, 'Total loss': 0.42251626451810204} | train loss {'Reaction outcome loss': 0.37963148625144444, 'Total loss': 0.37963148625144444}
2023-01-05 13:30:15,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:15,688 INFO:     Epoch: 38
2023-01-05 13:30:17,840 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39780489504337313, 'Total loss': 0.39780489504337313} | train loss {'Reaction outcome loss': 0.38068117052856565, 'Total loss': 0.38068117052856565}
2023-01-05 13:30:17,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:17,842 INFO:     Epoch: 39
2023-01-05 13:30:20,008 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43746735056241354, 'Total loss': 0.43746735056241354} | train loss {'Reaction outcome loss': 0.38759443139576394, 'Total loss': 0.38759443139576394}
2023-01-05 13:30:20,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:20,008 INFO:     Epoch: 40
2023-01-05 13:30:22,167 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3814602663119634, 'Total loss': 0.3814602663119634} | train loss {'Reaction outcome loss': 0.406211638302657, 'Total loss': 0.406211638302657}
2023-01-05 13:30:22,167 INFO:     Found new best model at epoch 40
2023-01-05 13:30:22,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:22,168 INFO:     Epoch: 41
2023-01-05 13:30:24,328 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.404229806860288, 'Total loss': 0.404229806860288} | train loss {'Reaction outcome loss': 0.37475947128689807, 'Total loss': 0.37475947128689807}
2023-01-05 13:30:24,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:24,329 INFO:     Epoch: 42
2023-01-05 13:30:26,498 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3991272697846095, 'Total loss': 0.3991272697846095} | train loss {'Reaction outcome loss': 0.3660455410625192, 'Total loss': 0.3660455410625192}
2023-01-05 13:30:26,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:26,498 INFO:     Epoch: 43
2023-01-05 13:30:28,654 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39857917626698813, 'Total loss': 0.39857917626698813} | train loss {'Reaction outcome loss': 0.36660464030453865, 'Total loss': 0.36660464030453865}
2023-01-05 13:30:28,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:28,654 INFO:     Epoch: 44
2023-01-05 13:30:30,823 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40005153715610503, 'Total loss': 0.40005153715610503} | train loss {'Reaction outcome loss': 0.3635139264085371, 'Total loss': 0.3635139264085371}
2023-01-05 13:30:30,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:30,824 INFO:     Epoch: 45
2023-01-05 13:30:32,976 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4439247007171313, 'Total loss': 0.4439247007171313} | train loss {'Reaction outcome loss': 0.36237295581014367, 'Total loss': 0.36237295581014367}
2023-01-05 13:30:32,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:32,976 INFO:     Epoch: 46
2023-01-05 13:30:35,156 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3846278786659241, 'Total loss': 0.3846278786659241} | train loss {'Reaction outcome loss': 0.35287252778484335, 'Total loss': 0.35287252778484335}
2023-01-05 13:30:35,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:35,157 INFO:     Epoch: 47
2023-01-05 13:30:37,323 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3984746197859446, 'Total loss': 0.3984746197859446} | train loss {'Reaction outcome loss': 0.3563236884390236, 'Total loss': 0.3563236884390236}
2023-01-05 13:30:37,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:37,323 INFO:     Epoch: 48
2023-01-05 13:30:39,479 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3834691147009532, 'Total loss': 0.3834691147009532} | train loss {'Reaction outcome loss': 0.3470834699833506, 'Total loss': 0.3470834699833506}
2023-01-05 13:30:39,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:39,479 INFO:     Epoch: 49
2023-01-05 13:30:41,651 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4381619115670522, 'Total loss': 0.4381619115670522} | train loss {'Reaction outcome loss': 0.34765115118437057, 'Total loss': 0.34765115118437057}
2023-01-05 13:30:41,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:41,652 INFO:     Epoch: 50
2023-01-05 13:30:43,825 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3853253727157911, 'Total loss': 0.3853253727157911} | train loss {'Reaction outcome loss': 0.39415957689609216, 'Total loss': 0.39415957689609216}
2023-01-05 13:30:43,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:43,826 INFO:     Epoch: 51
2023-01-05 13:30:45,981 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39088394145170846, 'Total loss': 0.39088394145170846} | train loss {'Reaction outcome loss': 0.34054857713117087, 'Total loss': 0.34054857713117087}
2023-01-05 13:30:45,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:45,981 INFO:     Epoch: 52
2023-01-05 13:30:48,143 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41522497137387593, 'Total loss': 0.41522497137387593} | train loss {'Reaction outcome loss': 0.33884685064760456, 'Total loss': 0.33884685064760456}
2023-01-05 13:30:48,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:48,145 INFO:     Epoch: 53
2023-01-05 13:30:50,296 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4004410852988561, 'Total loss': 0.4004410852988561} | train loss {'Reaction outcome loss': 0.33987845223990903, 'Total loss': 0.33987845223990903}
2023-01-05 13:30:50,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:50,296 INFO:     Epoch: 54
2023-01-05 13:30:52,440 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41348729928334554, 'Total loss': 0.41348729928334554} | train loss {'Reaction outcome loss': 0.34726957775706396, 'Total loss': 0.34726957775706396}
2023-01-05 13:30:52,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:52,441 INFO:     Epoch: 55
2023-01-05 13:30:54,605 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38760681251684825, 'Total loss': 0.38760681251684825} | train loss {'Reaction outcome loss': 0.33587148601456673, 'Total loss': 0.33587148601456673}
2023-01-05 13:30:54,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:54,605 INFO:     Epoch: 56
2023-01-05 13:30:56,747 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3968395988146464, 'Total loss': 0.3968395988146464} | train loss {'Reaction outcome loss': 0.3341872405696937, 'Total loss': 0.3341872405696937}
2023-01-05 13:30:56,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:56,747 INFO:     Epoch: 57
2023-01-05 13:30:58,928 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4179915209611257, 'Total loss': 0.4179915209611257} | train loss {'Reaction outcome loss': 0.32409422328450804, 'Total loss': 0.32409422328450804}
2023-01-05 13:30:58,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:30:58,929 INFO:     Epoch: 58
2023-01-05 13:31:01,083 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4102026015520096, 'Total loss': 0.4102026015520096} | train loss {'Reaction outcome loss': 0.32492010311408737, 'Total loss': 0.32492010311408737}
2023-01-05 13:31:01,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:01,084 INFO:     Epoch: 59
2023-01-05 13:31:03,244 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40495188037554425, 'Total loss': 0.40495188037554425} | train loss {'Reaction outcome loss': 0.3215355475946073, 'Total loss': 0.3215355475946073}
2023-01-05 13:31:03,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:03,244 INFO:     Epoch: 60
2023-01-05 13:31:05,406 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41491091847419737, 'Total loss': 0.41491091847419737} | train loss {'Reaction outcome loss': 0.31765221681812167, 'Total loss': 0.31765221681812167}
2023-01-05 13:31:05,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:05,407 INFO:     Epoch: 61
2023-01-05 13:31:07,562 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4268442889054616, 'Total loss': 0.4268442889054616} | train loss {'Reaction outcome loss': 0.3216914758777948, 'Total loss': 0.3216914758777948}
2023-01-05 13:31:07,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:07,563 INFO:     Epoch: 62
2023-01-05 13:31:09,722 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4505341877539953, 'Total loss': 0.4505341877539953} | train loss {'Reaction outcome loss': 0.32105624966831214, 'Total loss': 0.32105624966831214}
2023-01-05 13:31:09,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:09,723 INFO:     Epoch: 63
2023-01-05 13:31:11,881 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40228043496608734, 'Total loss': 0.40228043496608734} | train loss {'Reaction outcome loss': 0.31837709188339824, 'Total loss': 0.31837709188339824}
2023-01-05 13:31:11,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:11,882 INFO:     Epoch: 64
2023-01-05 13:31:14,031 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4176659087340037, 'Total loss': 0.4176659087340037} | train loss {'Reaction outcome loss': 0.31457377802850545, 'Total loss': 0.31457377802850545}
2023-01-05 13:31:14,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:14,031 INFO:     Epoch: 65
2023-01-05 13:31:16,172 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41637763877709705, 'Total loss': 0.41637763877709705} | train loss {'Reaction outcome loss': 0.3195425327732295, 'Total loss': 0.3195425327732295}
2023-01-05 13:31:16,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:16,174 INFO:     Epoch: 66
2023-01-05 13:31:18,361 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3897391453385353, 'Total loss': 0.3897391453385353} | train loss {'Reaction outcome loss': 0.30573784498214396, 'Total loss': 0.30573784498214396}
2023-01-05 13:31:18,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:18,361 INFO:     Epoch: 67
2023-01-05 13:31:20,535 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4418778568506241, 'Total loss': 0.4418778568506241} | train loss {'Reaction outcome loss': 0.3045435040974922, 'Total loss': 0.3045435040974922}
2023-01-05 13:31:20,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:20,535 INFO:     Epoch: 68
2023-01-05 13:31:22,677 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42390531798203784, 'Total loss': 0.42390531798203784} | train loss {'Reaction outcome loss': 0.3081713438623015, 'Total loss': 0.3081713438623015}
2023-01-05 13:31:22,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:22,679 INFO:     Epoch: 69
2023-01-05 13:31:24,822 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4264220436414083, 'Total loss': 0.4264220436414083} | train loss {'Reaction outcome loss': 0.3126251370244511, 'Total loss': 0.3126251370244511}
2023-01-05 13:31:24,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:24,822 INFO:     Epoch: 70
2023-01-05 13:31:26,971 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4063989142576853, 'Total loss': 0.4063989142576853} | train loss {'Reaction outcome loss': 0.3051557406754422, 'Total loss': 0.3051557406754422}
2023-01-05 13:31:26,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:26,973 INFO:     Epoch: 71
2023-01-05 13:31:29,113 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44352431495984396, 'Total loss': 0.44352431495984396} | train loss {'Reaction outcome loss': 0.2985222007255947, 'Total loss': 0.2985222007255947}
2023-01-05 13:31:29,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:29,114 INFO:     Epoch: 72
2023-01-05 13:31:31,254 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4201967845360438, 'Total loss': 0.4201967845360438} | train loss {'Reaction outcome loss': 0.30063880003117316, 'Total loss': 0.30063880003117316}
2023-01-05 13:31:31,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:31,255 INFO:     Epoch: 73
2023-01-05 13:31:33,405 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4561850349108378, 'Total loss': 0.4561850349108378} | train loss {'Reaction outcome loss': 0.2948951446333144, 'Total loss': 0.2948951446333144}
2023-01-05 13:31:33,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:33,406 INFO:     Epoch: 74
2023-01-05 13:31:35,568 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4943211336930593, 'Total loss': 0.4943211336930593} | train loss {'Reaction outcome loss': 0.2991186181543921, 'Total loss': 0.2991186181543921}
2023-01-05 13:31:35,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:35,568 INFO:     Epoch: 75
2023-01-05 13:31:37,737 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38916121125221254, 'Total loss': 0.38916121125221254} | train loss {'Reaction outcome loss': 0.29941290123995556, 'Total loss': 0.29941290123995556}
2023-01-05 13:31:37,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:37,737 INFO:     Epoch: 76
2023-01-05 13:31:39,898 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4655718182524045, 'Total loss': 0.4655718182524045} | train loss {'Reaction outcome loss': 0.28764787360170846, 'Total loss': 0.28764787360170846}
2023-01-05 13:31:39,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:39,899 INFO:     Epoch: 77
2023-01-05 13:31:42,042 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43338165084520974, 'Total loss': 0.43338165084520974} | train loss {'Reaction outcome loss': 0.2940238587561644, 'Total loss': 0.2940238587561644}
2023-01-05 13:31:42,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:42,043 INFO:     Epoch: 78
2023-01-05 13:31:44,195 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43784114917119343, 'Total loss': 0.43784114917119343} | train loss {'Reaction outcome loss': 0.29272800138679106, 'Total loss': 0.29272800138679106}
2023-01-05 13:31:44,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:44,196 INFO:     Epoch: 79
2023-01-05 13:31:46,352 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4132374366124471, 'Total loss': 0.4132374366124471} | train loss {'Reaction outcome loss': 0.30072758106499625, 'Total loss': 0.30072758106499625}
2023-01-05 13:31:46,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:46,352 INFO:     Epoch: 80
2023-01-05 13:31:48,500 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4502306958039602, 'Total loss': 0.4502306958039602} | train loss {'Reaction outcome loss': 0.28844618806750444, 'Total loss': 0.28844618806750444}
2023-01-05 13:31:48,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:48,501 INFO:     Epoch: 81
2023-01-05 13:31:50,661 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4347399731477102, 'Total loss': 0.4347399731477102} | train loss {'Reaction outcome loss': 0.3035280132477266, 'Total loss': 0.3035280132477266}
2023-01-05 13:31:50,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:50,662 INFO:     Epoch: 82
2023-01-05 13:31:52,805 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4723963389794032, 'Total loss': 0.4723963389794032} | train loss {'Reaction outcome loss': 0.40177278950476897, 'Total loss': 0.40177278950476897}
2023-01-05 13:31:52,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:52,805 INFO:     Epoch: 83
2023-01-05 13:31:54,954 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4358973781267802, 'Total loss': 0.4358973781267802} | train loss {'Reaction outcome loss': 0.3062021448441964, 'Total loss': 0.3062021448441964}
2023-01-05 13:31:54,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:54,954 INFO:     Epoch: 84
2023-01-05 13:31:57,098 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4566179762283961, 'Total loss': 0.4566179762283961} | train loss {'Reaction outcome loss': 0.2918901345321396, 'Total loss': 0.2918901345321396}
2023-01-05 13:31:57,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:57,099 INFO:     Epoch: 85
2023-01-05 13:31:59,259 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44964276949564613, 'Total loss': 0.44964276949564613} | train loss {'Reaction outcome loss': 0.28423360768921563, 'Total loss': 0.28423360768921563}
2023-01-05 13:31:59,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:31:59,260 INFO:     Epoch: 86
2023-01-05 13:32:01,418 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4425731798013051, 'Total loss': 0.4425731798013051} | train loss {'Reaction outcome loss': 0.284006404237437, 'Total loss': 0.284006404237437}
2023-01-05 13:32:01,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:01,418 INFO:     Epoch: 87
2023-01-05 13:32:03,567 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.427223764359951, 'Total loss': 0.427223764359951} | train loss {'Reaction outcome loss': 0.27947771252956294, 'Total loss': 0.27947771252956294}
2023-01-05 13:32:03,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:03,569 INFO:     Epoch: 88
2023-01-05 13:32:05,707 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43779870569705964, 'Total loss': 0.43779870569705964} | train loss {'Reaction outcome loss': 0.2778746041307307, 'Total loss': 0.2778746041307307}
2023-01-05 13:32:05,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:05,707 INFO:     Epoch: 89
2023-01-05 13:32:07,868 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38489755292733513, 'Total loss': 0.38489755292733513} | train loss {'Reaction outcome loss': 0.2789802766047364, 'Total loss': 0.2789802766047364}
2023-01-05 13:32:07,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:07,869 INFO:     Epoch: 90
2023-01-05 13:32:10,032 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43635146617889403, 'Total loss': 0.43635146617889403} | train loss {'Reaction outcome loss': 0.27833398319510877, 'Total loss': 0.27833398319510877}
2023-01-05 13:32:10,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:10,033 INFO:     Epoch: 91
2023-01-05 13:32:12,197 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44023930629094443, 'Total loss': 0.44023930629094443} | train loss {'Reaction outcome loss': 0.27744325332890224, 'Total loss': 0.27744325332890224}
2023-01-05 13:32:12,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:12,197 INFO:     Epoch: 92
2023-01-05 13:32:14,347 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4036742091178894, 'Total loss': 0.4036742091178894} | train loss {'Reaction outcome loss': 0.2795974450658094, 'Total loss': 0.2795974450658094}
2023-01-05 13:32:14,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:14,348 INFO:     Epoch: 93
2023-01-05 13:32:16,497 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4278097669283549, 'Total loss': 0.4278097669283549} | train loss {'Reaction outcome loss': 0.2748892328312175, 'Total loss': 0.2748892328312175}
2023-01-05 13:32:16,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:16,497 INFO:     Epoch: 94
2023-01-05 13:32:18,660 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4301005870103836, 'Total loss': 0.4301005870103836} | train loss {'Reaction outcome loss': 0.271289208517703, 'Total loss': 0.271289208517703}
2023-01-05 13:32:18,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:18,660 INFO:     Epoch: 95
2023-01-05 13:32:20,827 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45801227589448296, 'Total loss': 0.45801227589448296} | train loss {'Reaction outcome loss': 0.26767627658778836, 'Total loss': 0.26767627658778836}
2023-01-05 13:32:20,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:20,828 INFO:     Epoch: 96
2023-01-05 13:32:22,983 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4569800615310669, 'Total loss': 0.4569800615310669} | train loss {'Reaction outcome loss': 0.27237136280872737, 'Total loss': 0.27237136280872737}
2023-01-05 13:32:22,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:22,983 INFO:     Epoch: 97
2023-01-05 13:32:25,143 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44928307135899864, 'Total loss': 0.44928307135899864} | train loss {'Reaction outcome loss': 0.26759720899745065, 'Total loss': 0.26759720899745065}
2023-01-05 13:32:25,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:25,143 INFO:     Epoch: 98
2023-01-05 13:32:27,294 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4044601708650589, 'Total loss': 0.4044601708650589} | train loss {'Reaction outcome loss': 0.26648058021522086, 'Total loss': 0.26648058021522086}
2023-01-05 13:32:27,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:27,296 INFO:     Epoch: 99
2023-01-05 13:32:29,452 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3953394005695979, 'Total loss': 0.3953394005695979} | train loss {'Reaction outcome loss': 0.2641746667466815, 'Total loss': 0.2641746667466815}
2023-01-05 13:32:29,453 INFO:     Best model found after epoch 41 of 100.
2023-01-05 13:32:29,453 INFO:   Done with stage: TRAINING
2023-01-05 13:32:29,453 INFO:   Starting stage: EVALUATION
2023-01-05 13:32:29,585 INFO:   Done with stage: EVALUATION
2023-01-05 13:32:29,585 INFO:   Leaving out SEQ value Fold_8
2023-01-05 13:32:29,598 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 13:32:29,598 INFO:   Starting stage: FEATURE SCALING
2023-01-05 13:32:30,259 INFO:   Done with stage: FEATURE SCALING
2023-01-05 13:32:30,259 INFO:   Starting stage: SCALING TARGETS
2023-01-05 13:32:30,329 INFO:   Done with stage: SCALING TARGETS
2023-01-05 13:32:30,329 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:32:30,329 INFO:     No hyperparam tuning for this model
2023-01-05 13:32:30,329 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:32:30,329 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 13:32:30,330 INFO:     None feature selector for col prot
2023-01-05 13:32:30,330 INFO:     None feature selector for col prot
2023-01-05 13:32:30,330 INFO:     None feature selector for col prot
2023-01-05 13:32:30,331 INFO:     None feature selector for col chem
2023-01-05 13:32:30,331 INFO:     None feature selector for col chem
2023-01-05 13:32:30,331 INFO:     None feature selector for col chem
2023-01-05 13:32:30,331 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 13:32:30,331 INFO:   Starting stage: BUILD MODEL
2023-01-05 13:32:30,333 INFO:     Number of params in model 72901
2023-01-05 13:32:30,336 INFO:   Done with stage: BUILD MODEL
2023-01-05 13:32:30,336 INFO:   Starting stage: TRAINING
2023-01-05 13:32:30,395 INFO:     Val loss before train {'Reaction outcome loss': 1.0831913868586223, 'Total loss': 1.0831913868586223}
2023-01-05 13:32:30,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:30,396 INFO:     Epoch: 0
2023-01-05 13:32:32,577 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8316993276278178, 'Total loss': 0.8316993276278178} | train loss {'Reaction outcome loss': 0.8948790911948208, 'Total loss': 0.8948790911948208}
2023-01-05 13:32:32,578 INFO:     Found new best model at epoch 0
2023-01-05 13:32:32,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:32,579 INFO:     Epoch: 1
2023-01-05 13:32:34,804 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6810072104136149, 'Total loss': 0.6810072104136149} | train loss {'Reaction outcome loss': 0.7146664189732892, 'Total loss': 0.7146664189732892}
2023-01-05 13:32:34,805 INFO:     Found new best model at epoch 1
2023-01-05 13:32:34,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:34,806 INFO:     Epoch: 2
2023-01-05 13:32:37,012 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5603588084379832, 'Total loss': 0.5603588084379832} | train loss {'Reaction outcome loss': 0.5642248042976813, 'Total loss': 0.5642248042976813}
2023-01-05 13:32:37,012 INFO:     Found new best model at epoch 2
2023-01-05 13:32:37,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:37,013 INFO:     Epoch: 3
2023-01-05 13:32:39,195 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5447560290495554, 'Total loss': 0.5447560290495554} | train loss {'Reaction outcome loss': 0.5203172804969313, 'Total loss': 0.5203172804969313}
2023-01-05 13:32:39,196 INFO:     Found new best model at epoch 3
2023-01-05 13:32:39,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:39,198 INFO:     Epoch: 4
2023-01-05 13:32:41,337 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5299834211667379, 'Total loss': 0.5299834211667379} | train loss {'Reaction outcome loss': 0.49708893163539875, 'Total loss': 0.49708893163539875}
2023-01-05 13:32:41,337 INFO:     Found new best model at epoch 4
2023-01-05 13:32:41,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:41,339 INFO:     Epoch: 5
2023-01-05 13:32:43,490 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5387015203634898, 'Total loss': 0.5387015203634898} | train loss {'Reaction outcome loss': 0.4830201509196836, 'Total loss': 0.4830201509196836}
2023-01-05 13:32:43,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:43,490 INFO:     Epoch: 6
2023-01-05 13:32:45,645 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.525235656897227, 'Total loss': 0.525235656897227} | train loss {'Reaction outcome loss': 0.47864166666024, 'Total loss': 0.47864166666024}
2023-01-05 13:32:45,646 INFO:     Found new best model at epoch 6
2023-01-05 13:32:45,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:45,648 INFO:     Epoch: 7
2023-01-05 13:32:47,806 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5082375387350718, 'Total loss': 0.5082375387350718} | train loss {'Reaction outcome loss': 0.46284308868194746, 'Total loss': 0.46284308868194746}
2023-01-05 13:32:47,806 INFO:     Found new best model at epoch 7
2023-01-05 13:32:47,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:47,807 INFO:     Epoch: 8
2023-01-05 13:32:49,956 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4957662800947825, 'Total loss': 0.4957662800947825} | train loss {'Reaction outcome loss': 0.4639637057101253, 'Total loss': 0.4639637057101253}
2023-01-05 13:32:49,956 INFO:     Found new best model at epoch 8
2023-01-05 13:32:49,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:49,957 INFO:     Epoch: 9
2023-01-05 13:32:52,128 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4968565543492635, 'Total loss': 0.4968565543492635} | train loss {'Reaction outcome loss': 0.45233253854922006, 'Total loss': 0.45233253854922006}
2023-01-05 13:32:52,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:52,129 INFO:     Epoch: 10
2023-01-05 13:32:54,251 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5121304869651795, 'Total loss': 0.5121304869651795} | train loss {'Reaction outcome loss': 0.44491839742402306, 'Total loss': 0.44491839742402306}
2023-01-05 13:32:54,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:54,252 INFO:     Epoch: 11
2023-01-05 13:32:56,270 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5004934827486675, 'Total loss': 0.5004934827486675} | train loss {'Reaction outcome loss': 0.4396401735204222, 'Total loss': 0.4396401735204222}
2023-01-05 13:32:56,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:56,270 INFO:     Epoch: 12
2023-01-05 13:32:58,436 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5466097096602122, 'Total loss': 0.5466097096602122} | train loss {'Reaction outcome loss': 0.4344570939882998, 'Total loss': 0.4344570939882998}
2023-01-05 13:32:58,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:32:58,437 INFO:     Epoch: 13
2023-01-05 13:33:00,624 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4957549830277761, 'Total loss': 0.4957549830277761} | train loss {'Reaction outcome loss': 0.43384209861609047, 'Total loss': 0.43384209861609047}
2023-01-05 13:33:00,624 INFO:     Found new best model at epoch 13
2023-01-05 13:33:00,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:00,625 INFO:     Epoch: 14
2023-01-05 13:33:02,772 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5039620121320089, 'Total loss': 0.5039620121320089} | train loss {'Reaction outcome loss': 0.42702525189744867, 'Total loss': 0.42702525189744867}
2023-01-05 13:33:02,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:02,773 INFO:     Epoch: 15
2023-01-05 13:33:04,936 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.52022309700648, 'Total loss': 0.52022309700648} | train loss {'Reaction outcome loss': 0.4218844629904854, 'Total loss': 0.4218844629904854}
2023-01-05 13:33:04,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:04,936 INFO:     Epoch: 16
2023-01-05 13:33:07,097 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4854471544424693, 'Total loss': 0.4854471544424693} | train loss {'Reaction outcome loss': 0.4171985425996436, 'Total loss': 0.4171985425996436}
2023-01-05 13:33:07,097 INFO:     Found new best model at epoch 16
2023-01-05 13:33:07,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:07,099 INFO:     Epoch: 17
2023-01-05 13:33:09,278 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4979844073454539, 'Total loss': 0.4979844073454539} | train loss {'Reaction outcome loss': 0.4143187462315232, 'Total loss': 0.4143187462315232}
2023-01-05 13:33:09,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:09,279 INFO:     Epoch: 18
2023-01-05 13:33:11,443 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5045160472393035, 'Total loss': 0.5045160472393035} | train loss {'Reaction outcome loss': 0.4121288828793846, 'Total loss': 0.4121288828793846}
2023-01-05 13:33:11,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:11,444 INFO:     Epoch: 19
2023-01-05 13:33:13,602 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5112505555152893, 'Total loss': 0.5112505555152893} | train loss {'Reaction outcome loss': 0.41143481826093653, 'Total loss': 0.41143481826093653}
2023-01-05 13:33:13,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:13,604 INFO:     Epoch: 20
2023-01-05 13:33:15,795 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47075906495253245, 'Total loss': 0.47075906495253245} | train loss {'Reaction outcome loss': 0.40633929237077815, 'Total loss': 0.40633929237077815}
2023-01-05 13:33:15,795 INFO:     Found new best model at epoch 20
2023-01-05 13:33:15,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:15,796 INFO:     Epoch: 21
2023-01-05 13:33:17,963 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4620851919054985, 'Total loss': 0.4620851919054985} | train loss {'Reaction outcome loss': 0.39646902349558977, 'Total loss': 0.39646902349558977}
2023-01-05 13:33:17,963 INFO:     Found new best model at epoch 21
2023-01-05 13:33:17,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:17,964 INFO:     Epoch: 22
2023-01-05 13:33:20,132 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4887522578239441, 'Total loss': 0.4887522578239441} | train loss {'Reaction outcome loss': 0.39523529812747393, 'Total loss': 0.39523529812747393}
2023-01-05 13:33:20,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:20,134 INFO:     Epoch: 23
2023-01-05 13:33:22,308 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47404641409715015, 'Total loss': 0.47404641409715015} | train loss {'Reaction outcome loss': 0.39406345139126486, 'Total loss': 0.39406345139126486}
2023-01-05 13:33:22,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:22,308 INFO:     Epoch: 24
2023-01-05 13:33:24,474 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4696847329537074, 'Total loss': 0.4696847329537074} | train loss {'Reaction outcome loss': 0.3852438547981345, 'Total loss': 0.3852438547981345}
2023-01-05 13:33:24,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:24,475 INFO:     Epoch: 25
2023-01-05 13:33:26,642 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4882512013117472, 'Total loss': 0.4882512013117472} | train loss {'Reaction outcome loss': 0.38597860077012747, 'Total loss': 0.38597860077012747}
2023-01-05 13:33:26,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:26,643 INFO:     Epoch: 26
2023-01-05 13:33:28,806 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4570189078648885, 'Total loss': 0.4570189078648885} | train loss {'Reaction outcome loss': 0.38343159340671684, 'Total loss': 0.38343159340671684}
2023-01-05 13:33:28,807 INFO:     Found new best model at epoch 26
2023-01-05 13:33:28,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:28,808 INFO:     Epoch: 27
2023-01-05 13:33:30,951 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4687531689802806, 'Total loss': 0.4687531689802806} | train loss {'Reaction outcome loss': 0.3809033647072014, 'Total loss': 0.3809033647072014}
2023-01-05 13:33:30,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:30,953 INFO:     Epoch: 28
2023-01-05 13:33:33,108 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.49284004668394726, 'Total loss': 0.49284004668394726} | train loss {'Reaction outcome loss': 0.37588347397771554, 'Total loss': 0.37588347397771554}
2023-01-05 13:33:33,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:33,108 INFO:     Epoch: 29
2023-01-05 13:33:35,276 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46883116364479066, 'Total loss': 0.46883116364479066} | train loss {'Reaction outcome loss': 0.3732985059061636, 'Total loss': 0.3732985059061636}
2023-01-05 13:33:35,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:35,276 INFO:     Epoch: 30
2023-01-05 13:33:37,430 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46655731797218325, 'Total loss': 0.46655731797218325} | train loss {'Reaction outcome loss': 0.3683680586436165, 'Total loss': 0.3683680586436165}
2023-01-05 13:33:37,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:37,431 INFO:     Epoch: 31
2023-01-05 13:33:39,602 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49173686106999714, 'Total loss': 0.49173686106999714} | train loss {'Reaction outcome loss': 0.37119351671706036, 'Total loss': 0.37119351671706036}
2023-01-05 13:33:39,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:39,602 INFO:     Epoch: 32
2023-01-05 13:33:41,772 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49037735561529794, 'Total loss': 0.49037735561529794} | train loss {'Reaction outcome loss': 0.3625432845164723, 'Total loss': 0.3625432845164723}
2023-01-05 13:33:41,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:41,772 INFO:     Epoch: 33
2023-01-05 13:33:43,954 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4844003736972809, 'Total loss': 0.4844003736972809} | train loss {'Reaction outcome loss': 0.3595726744739157, 'Total loss': 0.3595726744739157}
2023-01-05 13:33:43,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:43,955 INFO:     Epoch: 34
2023-01-05 13:33:46,130 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4723939696947734, 'Total loss': 0.4723939696947734} | train loss {'Reaction outcome loss': 0.3566617306039437, 'Total loss': 0.3566617306039437}
2023-01-05 13:33:46,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:46,130 INFO:     Epoch: 35
2023-01-05 13:33:48,297 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4748340368270874, 'Total loss': 0.4748340368270874} | train loss {'Reaction outcome loss': 0.3551482424301361, 'Total loss': 0.3551482424301361}
2023-01-05 13:33:48,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:48,298 INFO:     Epoch: 36
2023-01-05 13:33:50,480 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5064456244309743, 'Total loss': 0.5064456244309743} | train loss {'Reaction outcome loss': 0.3496587787778369, 'Total loss': 0.3496587787778369}
2023-01-05 13:33:50,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:50,480 INFO:     Epoch: 37
2023-01-05 13:33:52,651 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5288637588421504, 'Total loss': 0.5288637588421504} | train loss {'Reaction outcome loss': 0.3482801482108311, 'Total loss': 0.3482801482108311}
2023-01-05 13:33:52,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:52,651 INFO:     Epoch: 38
2023-01-05 13:33:54,831 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47103072504202526, 'Total loss': 0.47103072504202526} | train loss {'Reaction outcome loss': 0.34248875256372274, 'Total loss': 0.34248875256372274}
2023-01-05 13:33:54,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:54,832 INFO:     Epoch: 39
2023-01-05 13:33:57,015 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4691171149412791, 'Total loss': 0.4691171149412791} | train loss {'Reaction outcome loss': 0.33890645640367634, 'Total loss': 0.33890645640367634}
2023-01-05 13:33:57,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:57,015 INFO:     Epoch: 40
2023-01-05 13:33:59,183 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46731289426485695, 'Total loss': 0.46731289426485695} | train loss {'Reaction outcome loss': 0.33825791972800284, 'Total loss': 0.33825791972800284}
2023-01-05 13:33:59,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:33:59,184 INFO:     Epoch: 41
2023-01-05 13:34:01,364 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47252091964085896, 'Total loss': 0.47252091964085896} | train loss {'Reaction outcome loss': 0.3371187093455869, 'Total loss': 0.3371187093455869}
2023-01-05 13:34:01,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:01,366 INFO:     Epoch: 42
2023-01-05 13:34:03,547 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4905878265698751, 'Total loss': 0.4905878265698751} | train loss {'Reaction outcome loss': 0.3263717376179859, 'Total loss': 0.3263717376179859}
2023-01-05 13:34:03,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:03,547 INFO:     Epoch: 43
2023-01-05 13:34:05,728 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4713548461596171, 'Total loss': 0.4713548461596171} | train loss {'Reaction outcome loss': 0.3280226662486038, 'Total loss': 0.3280226662486038}
2023-01-05 13:34:05,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:05,729 INFO:     Epoch: 44
2023-01-05 13:34:07,896 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5229392419258754, 'Total loss': 0.5229392419258754} | train loss {'Reaction outcome loss': 0.3273660369513267, 'Total loss': 0.3273660369513267}
2023-01-05 13:34:07,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:07,897 INFO:     Epoch: 45
2023-01-05 13:34:10,079 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49743531048297884, 'Total loss': 0.49743531048297884} | train loss {'Reaction outcome loss': 0.3212670818347793, 'Total loss': 0.3212670818347793}
2023-01-05 13:34:10,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:10,079 INFO:     Epoch: 46
2023-01-05 13:34:12,233 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46893442471822105, 'Total loss': 0.46893442471822105} | train loss {'Reaction outcome loss': 0.32588911158728684, 'Total loss': 0.32588911158728684}
2023-01-05 13:34:12,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:12,233 INFO:     Epoch: 47
2023-01-05 13:34:14,406 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4859483619530996, 'Total loss': 0.4859483619530996} | train loss {'Reaction outcome loss': 0.3186885950286681, 'Total loss': 0.3186885950286681}
2023-01-05 13:34:14,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:14,407 INFO:     Epoch: 48
2023-01-05 13:34:16,574 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4922488460938136, 'Total loss': 0.4922488460938136} | train loss {'Reaction outcome loss': 0.3149338586101248, 'Total loss': 0.3149338586101248}
2023-01-05 13:34:16,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:16,574 INFO:     Epoch: 49
2023-01-05 13:34:18,762 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5084892610708872, 'Total loss': 0.5084892610708872} | train loss {'Reaction outcome loss': 0.3086941393314178, 'Total loss': 0.3086941393314178}
2023-01-05 13:34:18,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:18,762 INFO:     Epoch: 50
2023-01-05 13:34:20,921 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5238886753718058, 'Total loss': 0.5238886753718058} | train loss {'Reaction outcome loss': 0.309832947200924, 'Total loss': 0.309832947200924}
2023-01-05 13:34:20,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:20,922 INFO:     Epoch: 51
2023-01-05 13:34:23,082 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4945030570030212, 'Total loss': 0.4945030570030212} | train loss {'Reaction outcome loss': 0.311744480988932, 'Total loss': 0.311744480988932}
2023-01-05 13:34:23,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:23,082 INFO:     Epoch: 52
2023-01-05 13:34:25,247 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48674047986666363, 'Total loss': 0.48674047986666363} | train loss {'Reaction outcome loss': 0.31080212951083047, 'Total loss': 0.31080212951083047}
2023-01-05 13:34:25,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:25,247 INFO:     Epoch: 53
2023-01-05 13:34:27,409 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5098717053731282, 'Total loss': 0.5098717053731282} | train loss {'Reaction outcome loss': 0.30598484349541283, 'Total loss': 0.30598484349541283}
2023-01-05 13:34:27,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:27,410 INFO:     Epoch: 54
2023-01-05 13:34:29,588 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5051333189010621, 'Total loss': 0.5051333189010621} | train loss {'Reaction outcome loss': 0.304347763086807, 'Total loss': 0.304347763086807}
2023-01-05 13:34:29,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:29,589 INFO:     Epoch: 55
2023-01-05 13:34:31,803 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5072052528460821, 'Total loss': 0.5072052528460821} | train loss {'Reaction outcome loss': 0.29587775378719994, 'Total loss': 0.29587775378719994}
2023-01-05 13:34:31,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:31,804 INFO:     Epoch: 56
2023-01-05 13:34:33,990 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5109656949838003, 'Total loss': 0.5109656949838003} | train loss {'Reaction outcome loss': 0.29084516951431005, 'Total loss': 0.29084516951431005}
2023-01-05 13:34:33,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:33,990 INFO:     Epoch: 57
2023-01-05 13:34:36,127 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4927308718363444, 'Total loss': 0.4927308718363444} | train loss {'Reaction outcome loss': 0.29716216228122316, 'Total loss': 0.29716216228122316}
2023-01-05 13:34:36,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:36,127 INFO:     Epoch: 58
2023-01-05 13:34:38,306 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49272135496139524, 'Total loss': 0.49272135496139524} | train loss {'Reaction outcome loss': 0.2915931111621916, 'Total loss': 0.2915931111621916}
2023-01-05 13:34:38,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:38,307 INFO:     Epoch: 59
2023-01-05 13:34:40,458 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.515339399377505, 'Total loss': 0.515339399377505} | train loss {'Reaction outcome loss': 0.28474243617337536, 'Total loss': 0.28474243617337536}
2023-01-05 13:34:40,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:40,459 INFO:     Epoch: 60
2023-01-05 13:34:42,643 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48185900251070657, 'Total loss': 0.48185900251070657} | train loss {'Reaction outcome loss': 0.2980070945399978, 'Total loss': 0.2980070945399978}
2023-01-05 13:34:42,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:42,643 INFO:     Epoch: 61
2023-01-05 13:34:44,820 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4797795325517654, 'Total loss': 0.4797795325517654} | train loss {'Reaction outcome loss': 0.2867009048131614, 'Total loss': 0.2867009048131614}
2023-01-05 13:34:44,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:44,821 INFO:     Epoch: 62
2023-01-05 13:34:46,963 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4862079719702403, 'Total loss': 0.4862079719702403} | train loss {'Reaction outcome loss': 0.28574453089184493, 'Total loss': 0.28574453089184493}
2023-01-05 13:34:46,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:46,963 INFO:     Epoch: 63
2023-01-05 13:34:49,132 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45930272539456685, 'Total loss': 0.45930272539456685} | train loss {'Reaction outcome loss': 0.2836010605937361, 'Total loss': 0.2836010605937361}
2023-01-05 13:34:49,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:49,134 INFO:     Epoch: 64
2023-01-05 13:34:51,301 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5263027767340342, 'Total loss': 0.5263027767340342} | train loss {'Reaction outcome loss': 0.28320720662709176, 'Total loss': 0.28320720662709176}
2023-01-05 13:34:51,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:51,302 INFO:     Epoch: 65
2023-01-05 13:34:53,478 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5062870482603709, 'Total loss': 0.5062870482603709} | train loss {'Reaction outcome loss': 0.28090745826598107, 'Total loss': 0.28090745826598107}
2023-01-05 13:34:53,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:53,479 INFO:     Epoch: 66
2023-01-05 13:34:55,647 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5278657575448354, 'Total loss': 0.5278657575448354} | train loss {'Reaction outcome loss': 0.283364770537249, 'Total loss': 0.283364770537249}
2023-01-05 13:34:55,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:55,649 INFO:     Epoch: 67
2023-01-05 13:34:57,832 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49030067026615143, 'Total loss': 0.49030067026615143} | train loss {'Reaction outcome loss': 0.28098930534150196, 'Total loss': 0.28098930534150196}
2023-01-05 13:34:57,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:57,832 INFO:     Epoch: 68
2023-01-05 13:34:59,682 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49488247036933897, 'Total loss': 0.49488247036933897} | train loss {'Reaction outcome loss': 0.27726177581407746, 'Total loss': 0.27726177581407746}
2023-01-05 13:34:59,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:34:59,684 INFO:     Epoch: 69
2023-01-05 13:35:01,456 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46857724090417224, 'Total loss': 0.46857724090417224} | train loss {'Reaction outcome loss': 0.27289880915723125, 'Total loss': 0.27289880915723125}
2023-01-05 13:35:01,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:01,456 INFO:     Epoch: 70
2023-01-05 13:35:03,372 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5122553726037343, 'Total loss': 0.5122553726037343} | train loss {'Reaction outcome loss': 0.26906601995875257, 'Total loss': 0.26906601995875257}
2023-01-05 13:35:03,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:03,373 INFO:     Epoch: 71
2023-01-05 13:35:05,552 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4925234387318293, 'Total loss': 0.4925234387318293} | train loss {'Reaction outcome loss': 0.26905410149090986, 'Total loss': 0.26905410149090986}
2023-01-05 13:35:05,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:05,553 INFO:     Epoch: 72
2023-01-05 13:35:07,724 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47214074730873107, 'Total loss': 0.47214074730873107} | train loss {'Reaction outcome loss': 0.2694642978858216, 'Total loss': 0.2694642978858216}
2023-01-05 13:35:07,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:07,726 INFO:     Epoch: 73
2023-01-05 13:35:09,883 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4952068199714025, 'Total loss': 0.4952068199714025} | train loss {'Reaction outcome loss': 0.27459038020740345, 'Total loss': 0.27459038020740345}
2023-01-05 13:35:09,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:09,883 INFO:     Epoch: 74
2023-01-05 13:35:12,049 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48099953631560005, 'Total loss': 0.48099953631560005} | train loss {'Reaction outcome loss': 0.2678248761995067, 'Total loss': 0.2678248761995067}
2023-01-05 13:35:12,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:12,050 INFO:     Epoch: 75
2023-01-05 13:35:14,222 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4608061780532201, 'Total loss': 0.4608061780532201} | train loss {'Reaction outcome loss': 0.26681144645820887, 'Total loss': 0.26681144645820887}
2023-01-05 13:35:14,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:14,223 INFO:     Epoch: 76
2023-01-05 13:35:16,387 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5066999018192291, 'Total loss': 0.5066999018192291} | train loss {'Reaction outcome loss': 0.2612940752105485, 'Total loss': 0.2612940752105485}
2023-01-05 13:35:16,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:16,388 INFO:     Epoch: 77
2023-01-05 13:35:18,563 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5295579036076864, 'Total loss': 0.5295579036076864} | train loss {'Reaction outcome loss': 0.2639932501993885, 'Total loss': 0.2639932501993885}
2023-01-05 13:35:18,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:18,565 INFO:     Epoch: 78
2023-01-05 13:35:20,724 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5016806269685428, 'Total loss': 0.5016806269685428} | train loss {'Reaction outcome loss': 0.2613299632249972, 'Total loss': 0.2613299632249972}
2023-01-05 13:35:20,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:20,724 INFO:     Epoch: 79
2023-01-05 13:35:22,909 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4894509454568227, 'Total loss': 0.4894509454568227} | train loss {'Reaction outcome loss': 0.25689652633419535, 'Total loss': 0.25689652633419535}
2023-01-05 13:35:22,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:22,910 INFO:     Epoch: 80
2023-01-05 13:35:25,095 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4975816080967585, 'Total loss': 0.4975816080967585} | train loss {'Reaction outcome loss': 0.258167684105114, 'Total loss': 0.258167684105114}
2023-01-05 13:35:25,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:25,095 INFO:     Epoch: 81
2023-01-05 13:35:27,277 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4639588877558708, 'Total loss': 0.4639588877558708} | train loss {'Reaction outcome loss': 0.2560296919304434, 'Total loss': 0.2560296919304434}
2023-01-05 13:35:27,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:27,277 INFO:     Epoch: 82
2023-01-05 13:35:29,461 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46963542997837066, 'Total loss': 0.46963542997837066} | train loss {'Reaction outcome loss': 0.2528936083727795, 'Total loss': 0.2528936083727795}
2023-01-05 13:35:29,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:29,462 INFO:     Epoch: 83
2023-01-05 13:35:31,639 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4616510381301244, 'Total loss': 0.4616510381301244} | train loss {'Reaction outcome loss': 0.25770371343052884, 'Total loss': 0.25770371343052884}
2023-01-05 13:35:31,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:31,639 INFO:     Epoch: 84
2023-01-05 13:35:33,814 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5204128722349802, 'Total loss': 0.5204128722349802} | train loss {'Reaction outcome loss': 0.2483147242062789, 'Total loss': 0.2483147242062789}
2023-01-05 13:35:33,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:33,814 INFO:     Epoch: 85
2023-01-05 13:35:35,997 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4774608939886093, 'Total loss': 0.4774608939886093} | train loss {'Reaction outcome loss': 0.2474261889039179, 'Total loss': 0.2474261889039179}
2023-01-05 13:35:35,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:35,998 INFO:     Epoch: 86
2023-01-05 13:35:38,155 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4853641867637634, 'Total loss': 0.4853641867637634} | train loss {'Reaction outcome loss': 0.25143421574458746, 'Total loss': 0.25143421574458746}
2023-01-05 13:35:38,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:38,155 INFO:     Epoch: 87
2023-01-05 13:35:40,333 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47746807237466177, 'Total loss': 0.47746807237466177} | train loss {'Reaction outcome loss': 0.25016744780465155, 'Total loss': 0.25016744780465155}
2023-01-05 13:35:40,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:40,334 INFO:     Epoch: 88
2023-01-05 13:35:42,501 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47647048234939576, 'Total loss': 0.47647048234939576} | train loss {'Reaction outcome loss': 0.2507443609731507, 'Total loss': 0.2507443609731507}
2023-01-05 13:35:42,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:42,502 INFO:     Epoch: 89
2023-01-05 13:35:44,667 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4742130349079768, 'Total loss': 0.4742130349079768} | train loss {'Reaction outcome loss': 0.24872237506460412, 'Total loss': 0.24872237506460412}
2023-01-05 13:35:44,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:44,667 INFO:     Epoch: 90
2023-01-05 13:35:46,853 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5009439845879873, 'Total loss': 0.5009439845879873} | train loss {'Reaction outcome loss': 0.2518673223991364, 'Total loss': 0.2518673223991364}
2023-01-05 13:35:46,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:46,854 INFO:     Epoch: 91
2023-01-05 13:35:49,042 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4787458270788193, 'Total loss': 0.4787458270788193} | train loss {'Reaction outcome loss': 0.23823380267872923, 'Total loss': 0.23823380267872923}
2023-01-05 13:35:49,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:49,042 INFO:     Epoch: 92
2023-01-05 13:35:51,221 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49136922955513, 'Total loss': 0.49136922955513} | train loss {'Reaction outcome loss': 0.24873258577599208, 'Total loss': 0.24873258577599208}
2023-01-05 13:35:51,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:51,221 INFO:     Epoch: 93
2023-01-05 13:35:53,409 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4762353539466858, 'Total loss': 0.4762353539466858} | train loss {'Reaction outcome loss': 0.24377807400555818, 'Total loss': 0.24377807400555818}
2023-01-05 13:35:53,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:53,411 INFO:     Epoch: 94
2023-01-05 13:35:55,580 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47457510431607564, 'Total loss': 0.47457510431607564} | train loss {'Reaction outcome loss': 0.24235050105204006, 'Total loss': 0.24235050105204006}
2023-01-05 13:35:55,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:55,580 INFO:     Epoch: 95
2023-01-05 13:35:57,771 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4586959977944692, 'Total loss': 0.4586959977944692} | train loss {'Reaction outcome loss': 0.23715879029799455, 'Total loss': 0.23715879029799455}
2023-01-05 13:35:57,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:57,772 INFO:     Epoch: 96
2023-01-05 13:35:59,971 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48457794785499575, 'Total loss': 0.48457794785499575} | train loss {'Reaction outcome loss': 0.24346836903788122, 'Total loss': 0.24346836903788122}
2023-01-05 13:35:59,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:35:59,972 INFO:     Epoch: 97
2023-01-05 13:36:02,162 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4662302494049072, 'Total loss': 0.4662302494049072} | train loss {'Reaction outcome loss': 0.23587857868643444, 'Total loss': 0.23587857868643444}
2023-01-05 13:36:02,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:02,163 INFO:     Epoch: 98
2023-01-05 13:36:04,351 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4938897649447123, 'Total loss': 0.4938897649447123} | train loss {'Reaction outcome loss': 0.23741557310580777, 'Total loss': 0.23741557310580777}
2023-01-05 13:36:04,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:04,352 INFO:     Epoch: 99
2023-01-05 13:36:06,530 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44995918969313303, 'Total loss': 0.44995918969313303} | train loss {'Reaction outcome loss': 0.2342149696316207, 'Total loss': 0.2342149696316207}
2023-01-05 13:36:06,531 INFO:     Found new best model at epoch 99
2023-01-05 13:36:06,532 INFO:     Best model found after epoch 100 of 100.
2023-01-05 13:36:06,532 INFO:   Done with stage: TRAINING
2023-01-05 13:36:06,532 INFO:   Starting stage: EVALUATION
2023-01-05 13:36:06,660 INFO:   Done with stage: EVALUATION
2023-01-05 13:36:06,660 INFO:   Leaving out SEQ value Fold_9
2023-01-05 13:36:06,673 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 13:36:06,673 INFO:   Starting stage: FEATURE SCALING
2023-01-05 13:36:07,333 INFO:   Done with stage: FEATURE SCALING
2023-01-05 13:36:07,333 INFO:   Starting stage: SCALING TARGETS
2023-01-05 13:36:07,405 INFO:   Done with stage: SCALING TARGETS
2023-01-05 13:36:07,405 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:36:07,405 INFO:     No hyperparam tuning for this model
2023-01-05 13:36:07,405 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:36:07,405 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 13:36:07,406 INFO:     None feature selector for col prot
2023-01-05 13:36:07,406 INFO:     None feature selector for col prot
2023-01-05 13:36:07,406 INFO:     None feature selector for col prot
2023-01-05 13:36:07,407 INFO:     None feature selector for col chem
2023-01-05 13:36:07,407 INFO:     None feature selector for col chem
2023-01-05 13:36:07,407 INFO:     None feature selector for col chem
2023-01-05 13:36:07,407 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 13:36:07,407 INFO:   Starting stage: BUILD MODEL
2023-01-05 13:36:07,409 INFO:     Number of params in model 72901
2023-01-05 13:36:07,412 INFO:   Done with stage: BUILD MODEL
2023-01-05 13:36:07,412 INFO:   Starting stage: TRAINING
2023-01-05 13:36:07,473 INFO:     Val loss before train {'Reaction outcome loss': 0.9706969738006592, 'Total loss': 0.9706969738006592}
2023-01-05 13:36:07,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:07,473 INFO:     Epoch: 0
2023-01-05 13:36:09,667 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7388257364432017, 'Total loss': 0.7388257364432017} | train loss {'Reaction outcome loss': 0.9195273503499771, 'Total loss': 0.9195273503499771}
2023-01-05 13:36:09,668 INFO:     Found new best model at epoch 0
2023-01-05 13:36:09,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:09,669 INFO:     Epoch: 1
2023-01-05 13:36:11,869 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5734738171100616, 'Total loss': 0.5734738171100616} | train loss {'Reaction outcome loss': 0.7458891362920135, 'Total loss': 0.7458891362920135}
2023-01-05 13:36:11,869 INFO:     Found new best model at epoch 1
2023-01-05 13:36:11,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:11,871 INFO:     Epoch: 2
2023-01-05 13:36:14,039 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5012343883514404, 'Total loss': 0.5012343883514404} | train loss {'Reaction outcome loss': 0.5919564458329755, 'Total loss': 0.5919564458329755}
2023-01-05 13:36:14,040 INFO:     Found new best model at epoch 2
2023-01-05 13:36:14,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:14,041 INFO:     Epoch: 3
2023-01-05 13:36:16,270 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46484667658805845, 'Total loss': 0.46484667658805845} | train loss {'Reaction outcome loss': 0.5389096585206606, 'Total loss': 0.5389096585206606}
2023-01-05 13:36:16,271 INFO:     Found new best model at epoch 3
2023-01-05 13:36:16,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:16,272 INFO:     Epoch: 4
2023-01-05 13:36:18,474 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4546794593334198, 'Total loss': 0.4546794593334198} | train loss {'Reaction outcome loss': 0.5186849403790188, 'Total loss': 0.5186849403790188}
2023-01-05 13:36:18,474 INFO:     Found new best model at epoch 4
2023-01-05 13:36:18,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:18,475 INFO:     Epoch: 5
2023-01-05 13:36:20,673 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44040507475535073, 'Total loss': 0.44040507475535073} | train loss {'Reaction outcome loss': 0.5033751702480798, 'Total loss': 0.5033751702480798}
2023-01-05 13:36:20,675 INFO:     Found new best model at epoch 5
2023-01-05 13:36:20,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:20,676 INFO:     Epoch: 6
2023-01-05 13:36:22,939 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42836678127447764, 'Total loss': 0.42836678127447764} | train loss {'Reaction outcome loss': 0.4917083771005004, 'Total loss': 0.4917083771005004}
2023-01-05 13:36:22,939 INFO:     Found new best model at epoch 6
2023-01-05 13:36:22,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:22,940 INFO:     Epoch: 7
2023-01-05 13:36:25,188 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42305304010709127, 'Total loss': 0.42305304010709127} | train loss {'Reaction outcome loss': 0.48543738377438556, 'Total loss': 0.48543738377438556}
2023-01-05 13:36:25,188 INFO:     Found new best model at epoch 7
2023-01-05 13:36:25,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:25,190 INFO:     Epoch: 8
2023-01-05 13:36:27,432 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43721596002578733, 'Total loss': 0.43721596002578733} | train loss {'Reaction outcome loss': 0.4744157129999533, 'Total loss': 0.4744157129999533}
2023-01-05 13:36:27,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:27,433 INFO:     Epoch: 9
2023-01-05 13:36:29,678 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4425711452960968, 'Total loss': 0.4425711452960968} | train loss {'Reaction outcome loss': 0.4677854457648222, 'Total loss': 0.4677854457648222}
2023-01-05 13:36:29,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:29,678 INFO:     Epoch: 10
2023-01-05 13:36:31,917 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39437103470166524, 'Total loss': 0.39437103470166524} | train loss {'Reaction outcome loss': 0.46299870419803507, 'Total loss': 0.46299870419803507}
2023-01-05 13:36:31,917 INFO:     Found new best model at epoch 10
2023-01-05 13:36:31,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:31,919 INFO:     Epoch: 11
2023-01-05 13:36:34,153 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.420679501692454, 'Total loss': 0.420679501692454} | train loss {'Reaction outcome loss': 0.4553241644740535, 'Total loss': 0.4553241644740535}
2023-01-05 13:36:34,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:34,154 INFO:     Epoch: 12
2023-01-05 13:36:36,385 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40346723596254985, 'Total loss': 0.40346723596254985} | train loss {'Reaction outcome loss': 0.4508787791651509, 'Total loss': 0.4508787791651509}
2023-01-05 13:36:36,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:36,385 INFO:     Epoch: 13
2023-01-05 13:36:38,644 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4294312298297882, 'Total loss': 0.4294312298297882} | train loss {'Reaction outcome loss': 0.44698661135422196, 'Total loss': 0.44698661135422196}
2023-01-05 13:36:38,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:38,645 INFO:     Epoch: 14
2023-01-05 13:36:40,903 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4204839954773585, 'Total loss': 0.4204839954773585} | train loss {'Reaction outcome loss': 0.441525244325507, 'Total loss': 0.441525244325507}
2023-01-05 13:36:40,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:40,903 INFO:     Epoch: 15
2023-01-05 13:36:43,125 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.408803195754687, 'Total loss': 0.408803195754687} | train loss {'Reaction outcome loss': 0.438652760500512, 'Total loss': 0.438652760500512}
2023-01-05 13:36:43,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:43,125 INFO:     Epoch: 16
2023-01-05 13:36:45,318 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4223660469055176, 'Total loss': 0.4223660469055176} | train loss {'Reaction outcome loss': 0.4300148287243361, 'Total loss': 0.4300148287243361}
2023-01-05 13:36:45,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:45,319 INFO:     Epoch: 17
2023-01-05 13:36:47,504 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4030087649822235, 'Total loss': 0.4030087649822235} | train loss {'Reaction outcome loss': 0.4292560928780249, 'Total loss': 0.4292560928780249}
2023-01-05 13:36:47,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:47,505 INFO:     Epoch: 18
2023-01-05 13:36:49,677 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38477179408073425, 'Total loss': 0.38477179408073425} | train loss {'Reaction outcome loss': 0.416096858330582, 'Total loss': 0.416096858330582}
2023-01-05 13:36:49,677 INFO:     Found new best model at epoch 18
2023-01-05 13:36:49,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:49,678 INFO:     Epoch: 19
2023-01-05 13:36:51,869 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38240413268407186, 'Total loss': 0.38240413268407186} | train loss {'Reaction outcome loss': 0.41772353735211093, 'Total loss': 0.41772353735211093}
2023-01-05 13:36:51,870 INFO:     Found new best model at epoch 19
2023-01-05 13:36:51,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:51,871 INFO:     Epoch: 20
2023-01-05 13:36:54,028 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4276238242785136, 'Total loss': 0.4276238242785136} | train loss {'Reaction outcome loss': 0.41490038099702087, 'Total loss': 0.41490038099702087}
2023-01-05 13:36:54,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:54,028 INFO:     Epoch: 21
2023-01-05 13:36:55,794 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4139098773399989, 'Total loss': 0.4139098773399989} | train loss {'Reaction outcome loss': 0.41420324340408887, 'Total loss': 0.41420324340408887}
2023-01-05 13:36:55,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:55,795 INFO:     Epoch: 22
2023-01-05 13:36:57,568 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4043377459049225, 'Total loss': 0.4043377459049225} | train loss {'Reaction outcome loss': 0.40818805750526677, 'Total loss': 0.40818805750526677}
2023-01-05 13:36:57,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:57,569 INFO:     Epoch: 23
2023-01-05 13:36:59,631 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3998321036497752, 'Total loss': 0.3998321036497752} | train loss {'Reaction outcome loss': 0.4058408364384613, 'Total loss': 0.4058408364384613}
2023-01-05 13:36:59,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:36:59,632 INFO:     Epoch: 24
2023-01-05 13:37:01,652 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3700311054786046, 'Total loss': 0.3700311054786046} | train loss {'Reaction outcome loss': 0.39985491795337585, 'Total loss': 0.39985491795337585}
2023-01-05 13:37:01,653 INFO:     Found new best model at epoch 24
2023-01-05 13:37:01,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:01,654 INFO:     Epoch: 25
2023-01-05 13:37:03,870 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41521998643875124, 'Total loss': 0.41521998643875124} | train loss {'Reaction outcome loss': 0.3954004775665512, 'Total loss': 0.3954004775665512}
2023-01-05 13:37:03,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:03,871 INFO:     Epoch: 26
2023-01-05 13:37:06,106 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.404606960217158, 'Total loss': 0.404606960217158} | train loss {'Reaction outcome loss': 0.39221590940272333, 'Total loss': 0.39221590940272333}
2023-01-05 13:37:06,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:06,106 INFO:     Epoch: 27
2023-01-05 13:37:08,335 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3739179829756419, 'Total loss': 0.3739179829756419} | train loss {'Reaction outcome loss': 0.3866050593850845, 'Total loss': 0.3866050593850845}
2023-01-05 13:37:08,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:08,335 INFO:     Epoch: 28
2023-01-05 13:37:10,545 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41710582772890725, 'Total loss': 0.41710582772890725} | train loss {'Reaction outcome loss': 0.37970400886737915, 'Total loss': 0.37970400886737915}
2023-01-05 13:37:10,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:10,545 INFO:     Epoch: 29
2023-01-05 13:37:12,768 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40418712397416434, 'Total loss': 0.40418712397416434} | train loss {'Reaction outcome loss': 0.377651197950117, 'Total loss': 0.377651197950117}
2023-01-05 13:37:12,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:12,769 INFO:     Epoch: 30
2023-01-05 13:37:15,006 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3879054605960846, 'Total loss': 0.3879054605960846} | train loss {'Reaction outcome loss': 0.3769046108268659, 'Total loss': 0.3769046108268659}
2023-01-05 13:37:15,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:15,006 INFO:     Epoch: 31
2023-01-05 13:37:17,246 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39291515747706096, 'Total loss': 0.39291515747706096} | train loss {'Reaction outcome loss': 0.37379798814923326, 'Total loss': 0.37379798814923326}
2023-01-05 13:37:17,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:17,246 INFO:     Epoch: 32
2023-01-05 13:37:19,488 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40928574999173484, 'Total loss': 0.40928574999173484} | train loss {'Reaction outcome loss': 0.368683509434496, 'Total loss': 0.368683509434496}
2023-01-05 13:37:19,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:19,488 INFO:     Epoch: 33
2023-01-05 13:37:21,670 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3633425012230873, 'Total loss': 0.3633425012230873} | train loss {'Reaction outcome loss': 0.36645881906958694, 'Total loss': 0.36645881906958694}
2023-01-05 13:37:21,671 INFO:     Found new best model at epoch 33
2023-01-05 13:37:21,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:21,673 INFO:     Epoch: 34
2023-01-05 13:37:23,860 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39495250284671785, 'Total loss': 0.39495250284671785} | train loss {'Reaction outcome loss': 0.35864182861542016, 'Total loss': 0.35864182861542016}
2023-01-05 13:37:23,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:23,860 INFO:     Epoch: 35
2023-01-05 13:37:26,107 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4034288803736369, 'Total loss': 0.4034288803736369} | train loss {'Reaction outcome loss': 0.35801597361852977, 'Total loss': 0.35801597361852977}
2023-01-05 13:37:26,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:26,107 INFO:     Epoch: 36
2023-01-05 13:37:28,298 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.35788916846116386, 'Total loss': 0.35788916846116386} | train loss {'Reaction outcome loss': 0.3537862985142732, 'Total loss': 0.3537862985142732}
2023-01-05 13:37:28,299 INFO:     Found new best model at epoch 36
2023-01-05 13:37:28,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:28,300 INFO:     Epoch: 37
2023-01-05 13:37:30,475 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4094599713881811, 'Total loss': 0.4094599713881811} | train loss {'Reaction outcome loss': 0.3533122586590719, 'Total loss': 0.3533122586590719}
2023-01-05 13:37:30,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:30,476 INFO:     Epoch: 38
2023-01-05 13:37:32,659 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3612300535043081, 'Total loss': 0.3612300535043081} | train loss {'Reaction outcome loss': 0.35883650683969365, 'Total loss': 0.35883650683969365}
2023-01-05 13:37:32,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:32,660 INFO:     Epoch: 39
2023-01-05 13:37:34,819 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4148052930831909, 'Total loss': 0.4148052930831909} | train loss {'Reaction outcome loss': 0.34661686632930155, 'Total loss': 0.34661686632930155}
2023-01-05 13:37:34,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:34,820 INFO:     Epoch: 40
2023-01-05 13:37:37,036 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3866614138086637, 'Total loss': 0.3866614138086637} | train loss {'Reaction outcome loss': 0.340864159341646, 'Total loss': 0.340864159341646}
2023-01-05 13:37:37,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:37,036 INFO:     Epoch: 41
2023-01-05 13:37:39,234 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3677787631750107, 'Total loss': 0.3677787631750107} | train loss {'Reaction outcome loss': 0.34063906386656023, 'Total loss': 0.34063906386656023}
2023-01-05 13:37:39,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:39,234 INFO:     Epoch: 42
2023-01-05 13:37:41,431 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.37725019405285515, 'Total loss': 0.37725019405285515} | train loss {'Reaction outcome loss': 0.3370806181581442, 'Total loss': 0.3370806181581442}
2023-01-05 13:37:41,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:41,432 INFO:     Epoch: 43
2023-01-05 13:37:43,613 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.36013003264864285, 'Total loss': 0.36013003264864285} | train loss {'Reaction outcome loss': 0.3340977751633105, 'Total loss': 0.3340977751633105}
2023-01-05 13:37:43,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:43,613 INFO:     Epoch: 44
2023-01-05 13:37:45,780 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.37841934760411583, 'Total loss': 0.37841934760411583} | train loss {'Reaction outcome loss': 0.3290363004101635, 'Total loss': 0.3290363004101635}
2023-01-05 13:37:45,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:45,780 INFO:     Epoch: 45
2023-01-05 13:37:47,965 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38338605165481565, 'Total loss': 0.38338605165481565} | train loss {'Reaction outcome loss': 0.32402499512322114, 'Total loss': 0.32402499512322114}
2023-01-05 13:37:47,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:47,965 INFO:     Epoch: 46
2023-01-05 13:37:50,156 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38537770658731463, 'Total loss': 0.38537770658731463} | train loss {'Reaction outcome loss': 0.32108476953009407, 'Total loss': 0.32108476953009407}
2023-01-05 13:37:50,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:50,157 INFO:     Epoch: 47
2023-01-05 13:37:52,341 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3737891733646393, 'Total loss': 0.3737891733646393} | train loss {'Reaction outcome loss': 0.31679830721676994, 'Total loss': 0.31679830721676994}
2023-01-05 13:37:52,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:52,342 INFO:     Epoch: 48
2023-01-05 13:37:54,523 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37251965403556825, 'Total loss': 0.37251965403556825} | train loss {'Reaction outcome loss': 0.31833683068625335, 'Total loss': 0.31833683068625335}
2023-01-05 13:37:54,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:54,523 INFO:     Epoch: 49
2023-01-05 13:37:56,696 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3931745409965515, 'Total loss': 0.3931745409965515} | train loss {'Reaction outcome loss': 0.30864135665476106, 'Total loss': 0.30864135665476106}
2023-01-05 13:37:56,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:56,696 INFO:     Epoch: 50
2023-01-05 13:37:58,895 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3736932228008906, 'Total loss': 0.3736932228008906} | train loss {'Reaction outcome loss': 0.3095749734164575, 'Total loss': 0.3095749734164575}
2023-01-05 13:37:58,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:37:58,896 INFO:     Epoch: 51
2023-01-05 13:38:01,121 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3556774497032166, 'Total loss': 0.3556774497032166} | train loss {'Reaction outcome loss': 0.30281807503760505, 'Total loss': 0.30281807503760505}
2023-01-05 13:38:01,121 INFO:     Found new best model at epoch 51
2023-01-05 13:38:01,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:01,122 INFO:     Epoch: 52
2023-01-05 13:38:03,318 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.35021098603804907, 'Total loss': 0.35021098603804907} | train loss {'Reaction outcome loss': 0.3068512123521915, 'Total loss': 0.3068512123521915}
2023-01-05 13:38:03,318 INFO:     Found new best model at epoch 52
2023-01-05 13:38:03,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:03,320 INFO:     Epoch: 53
2023-01-05 13:38:05,539 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40200574199358624, 'Total loss': 0.40200574199358624} | train loss {'Reaction outcome loss': 0.29922853572973274, 'Total loss': 0.29922853572973274}
2023-01-05 13:38:05,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:05,540 INFO:     Epoch: 54
2023-01-05 13:38:07,725 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3825465202331543, 'Total loss': 0.3825465202331543} | train loss {'Reaction outcome loss': 0.3011838301397618, 'Total loss': 0.3011838301397618}
2023-01-05 13:38:07,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:07,725 INFO:     Epoch: 55
2023-01-05 13:38:09,916 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37352153758207957, 'Total loss': 0.37352153758207957} | train loss {'Reaction outcome loss': 0.2979911315096845, 'Total loss': 0.2979911315096845}
2023-01-05 13:38:09,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:09,916 INFO:     Epoch: 56
2023-01-05 13:38:12,131 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3725652813911438, 'Total loss': 0.3725652813911438} | train loss {'Reaction outcome loss': 0.29340408164133663, 'Total loss': 0.29340408164133663}
2023-01-05 13:38:12,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:12,131 INFO:     Epoch: 57
2023-01-05 13:38:14,340 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37753909130891167, 'Total loss': 0.37753909130891167} | train loss {'Reaction outcome loss': 0.29830567107034933, 'Total loss': 0.29830567107034933}
2023-01-05 13:38:14,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:14,340 INFO:     Epoch: 58
2023-01-05 13:38:16,503 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3531570315361023, 'Total loss': 0.3531570315361023} | train loss {'Reaction outcome loss': 0.2938627811108417, 'Total loss': 0.2938627811108417}
2023-01-05 13:38:16,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:16,503 INFO:     Epoch: 59
2023-01-05 13:38:18,663 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3791856199502945, 'Total loss': 0.3791856199502945} | train loss {'Reaction outcome loss': 0.28777281808186095, 'Total loss': 0.28777281808186095}
2023-01-05 13:38:18,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:18,664 INFO:     Epoch: 60
2023-01-05 13:38:20,815 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3465763216217359, 'Total loss': 0.3465763216217359} | train loss {'Reaction outcome loss': 0.279985739086294, 'Total loss': 0.279985739086294}
2023-01-05 13:38:20,815 INFO:     Found new best model at epoch 60
2023-01-05 13:38:20,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:20,817 INFO:     Epoch: 61
2023-01-05 13:38:22,957 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3671920786301295, 'Total loss': 0.3671920786301295} | train loss {'Reaction outcome loss': 0.2866017980642267, 'Total loss': 0.2866017980642267}
2023-01-05 13:38:22,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:22,958 INFO:     Epoch: 62
2023-01-05 13:38:25,119 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3441889057556788, 'Total loss': 0.3441889057556788} | train loss {'Reaction outcome loss': 0.2832149435372667, 'Total loss': 0.2832149435372667}
2023-01-05 13:38:25,119 INFO:     Found new best model at epoch 62
2023-01-05 13:38:25,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:25,120 INFO:     Epoch: 63
2023-01-05 13:38:27,295 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3698864062627157, 'Total loss': 0.3698864062627157} | train loss {'Reaction outcome loss': 0.27753722428307204, 'Total loss': 0.27753722428307204}
2023-01-05 13:38:27,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:27,295 INFO:     Epoch: 64
2023-01-05 13:38:29,464 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3845144659280777, 'Total loss': 0.3845144659280777} | train loss {'Reaction outcome loss': 0.27340409736609633, 'Total loss': 0.27340409736609633}
2023-01-05 13:38:29,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:29,465 INFO:     Epoch: 65
2023-01-05 13:38:31,606 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3802661528189977, 'Total loss': 0.3802661528189977} | train loss {'Reaction outcome loss': 0.2779048790866072, 'Total loss': 0.2779048790866072}
2023-01-05 13:38:31,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:31,606 INFO:     Epoch: 66
2023-01-05 13:38:33,755 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.36834938327471417, 'Total loss': 0.36834938327471417} | train loss {'Reaction outcome loss': 0.2774929326659721, 'Total loss': 0.2774929326659721}
2023-01-05 13:38:33,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:33,755 INFO:     Epoch: 67
2023-01-05 13:38:35,915 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36340779562791187, 'Total loss': 0.36340779562791187} | train loss {'Reaction outcome loss': 0.271125269818392, 'Total loss': 0.271125269818392}
2023-01-05 13:38:35,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:35,916 INFO:     Epoch: 68
2023-01-05 13:38:38,083 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3626896450916926, 'Total loss': 0.3626896450916926} | train loss {'Reaction outcome loss': 0.27507011687873933, 'Total loss': 0.27507011687873933}
2023-01-05 13:38:38,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:38,083 INFO:     Epoch: 69
2023-01-05 13:38:40,250 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3698136905829112, 'Total loss': 0.3698136905829112} | train loss {'Reaction outcome loss': 0.2710836503910244, 'Total loss': 0.2710836503910244}
2023-01-05 13:38:40,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:40,250 INFO:     Epoch: 70
2023-01-05 13:38:42,414 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3667133008440336, 'Total loss': 0.3667133008440336} | train loss {'Reaction outcome loss': 0.26925641920968946, 'Total loss': 0.26925641920968946}
2023-01-05 13:38:42,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:42,414 INFO:     Epoch: 71
2023-01-05 13:38:44,566 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42290090322494506, 'Total loss': 0.42290090322494506} | train loss {'Reaction outcome loss': 0.2689601299201646, 'Total loss': 0.2689601299201646}
2023-01-05 13:38:44,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:44,567 INFO:     Epoch: 72
2023-01-05 13:38:46,753 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3508658436437448, 'Total loss': 0.3508658436437448} | train loss {'Reaction outcome loss': 0.27288826456838133, 'Total loss': 0.27288826456838133}
2023-01-05 13:38:46,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:46,753 INFO:     Epoch: 73
2023-01-05 13:38:48,909 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37794920404752097, 'Total loss': 0.37794920404752097} | train loss {'Reaction outcome loss': 0.2599584431478263, 'Total loss': 0.2599584431478263}
2023-01-05 13:38:48,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:48,910 INFO:     Epoch: 74
2023-01-05 13:38:51,076 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3889702687660853, 'Total loss': 0.3889702687660853} | train loss {'Reaction outcome loss': 0.2629307121683975, 'Total loss': 0.2629307121683975}
2023-01-05 13:38:51,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:51,077 INFO:     Epoch: 75
2023-01-05 13:38:53,241 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3995305816332499, 'Total loss': 0.3995305816332499} | train loss {'Reaction outcome loss': 0.26084621796310486, 'Total loss': 0.26084621796310486}
2023-01-05 13:38:53,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:53,241 INFO:     Epoch: 76
2023-01-05 13:38:55,387 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4160403847694397, 'Total loss': 0.4160403847694397} | train loss {'Reaction outcome loss': 0.2706956092792728, 'Total loss': 0.2706956092792728}
2023-01-05 13:38:55,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:55,387 INFO:     Epoch: 77
2023-01-05 13:38:57,548 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3698838512102763, 'Total loss': 0.3698838512102763} | train loss {'Reaction outcome loss': 0.25579573735863725, 'Total loss': 0.25579573735863725}
2023-01-05 13:38:57,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:57,549 INFO:     Epoch: 78
2023-01-05 13:38:59,727 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.36999540627002714, 'Total loss': 0.36999540627002714} | train loss {'Reaction outcome loss': 0.25931717073443994, 'Total loss': 0.25931717073443994}
2023-01-05 13:38:59,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:38:59,728 INFO:     Epoch: 79
2023-01-05 13:39:01,957 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40242397288481396, 'Total loss': 0.40242397288481396} | train loss {'Reaction outcome loss': 0.2548454319284926, 'Total loss': 0.2548454319284926}
2023-01-05 13:39:01,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:01,957 INFO:     Epoch: 80
2023-01-05 13:39:04,163 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.35940090914567313, 'Total loss': 0.35940090914567313} | train loss {'Reaction outcome loss': 0.260096271653468, 'Total loss': 0.260096271653468}
2023-01-05 13:39:04,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:04,163 INFO:     Epoch: 81
2023-01-05 13:39:06,330 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3731188287337621, 'Total loss': 0.3731188287337621} | train loss {'Reaction outcome loss': 0.2588307161610372, 'Total loss': 0.2588307161610372}
2023-01-05 13:39:06,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:06,331 INFO:     Epoch: 82
2023-01-05 13:39:08,494 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3594536225001017, 'Total loss': 0.3594536225001017} | train loss {'Reaction outcome loss': 0.25303517967892897, 'Total loss': 0.25303517967892897}
2023-01-05 13:39:08,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:08,494 INFO:     Epoch: 83
2023-01-05 13:39:10,653 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3921447684367498, 'Total loss': 0.3921447684367498} | train loss {'Reaction outcome loss': 0.25017474789427935, 'Total loss': 0.25017474789427935}
2023-01-05 13:39:10,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:10,653 INFO:     Epoch: 84
2023-01-05 13:39:12,804 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3566064437230428, 'Total loss': 0.3566064437230428} | train loss {'Reaction outcome loss': 0.2548876980164959, 'Total loss': 0.2548876980164959}
2023-01-05 13:39:12,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:12,804 INFO:     Epoch: 85
2023-01-05 13:39:14,974 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38195894807577135, 'Total loss': 0.38195894807577135} | train loss {'Reaction outcome loss': 0.25515088644752865, 'Total loss': 0.25515088644752865}
2023-01-05 13:39:14,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:14,975 INFO:     Epoch: 86
2023-01-05 13:39:17,126 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3680325518051783, 'Total loss': 0.3680325518051783} | train loss {'Reaction outcome loss': 0.2521318177615262, 'Total loss': 0.2521318177615262}
2023-01-05 13:39:17,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:17,126 INFO:     Epoch: 87
2023-01-05 13:39:19,285 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39671389063199364, 'Total loss': 0.39671389063199364} | train loss {'Reaction outcome loss': 0.2468248709484881, 'Total loss': 0.2468248709484881}
2023-01-05 13:39:19,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:19,286 INFO:     Epoch: 88
2023-01-05 13:39:21,448 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3207477326194445, 'Total loss': 0.3207477326194445} | train loss {'Reaction outcome loss': 0.24640936017816462, 'Total loss': 0.24640936017816462}
2023-01-05 13:39:21,448 INFO:     Found new best model at epoch 88
2023-01-05 13:39:21,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:21,449 INFO:     Epoch: 89
2023-01-05 13:39:23,616 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.34123750825723015, 'Total loss': 0.34123750825723015} | train loss {'Reaction outcome loss': 0.24734208115548004, 'Total loss': 0.24734208115548004}
2023-01-05 13:39:23,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:23,616 INFO:     Epoch: 90
2023-01-05 13:39:25,768 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3745568975806236, 'Total loss': 0.3745568975806236} | train loss {'Reaction outcome loss': 0.24886178955543342, 'Total loss': 0.24886178955543342}
2023-01-05 13:39:25,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:25,768 INFO:     Epoch: 91
2023-01-05 13:39:27,935 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.34884833892186484, 'Total loss': 0.34884833892186484} | train loss {'Reaction outcome loss': 0.25050920625940126, 'Total loss': 0.25050920625940126}
2023-01-05 13:39:27,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:27,936 INFO:     Epoch: 92
2023-01-05 13:39:30,148 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.36785823901494347, 'Total loss': 0.36785823901494347} | train loss {'Reaction outcome loss': 0.24629433149478602, 'Total loss': 0.24629433149478602}
2023-01-05 13:39:30,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:30,149 INFO:     Epoch: 93
2023-01-05 13:39:32,337 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.368046764532725, 'Total loss': 0.368046764532725} | train loss {'Reaction outcome loss': 0.243084808287046, 'Total loss': 0.243084808287046}
2023-01-05 13:39:32,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:32,337 INFO:     Epoch: 94
2023-01-05 13:39:34,529 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.36633363862832385, 'Total loss': 0.36633363862832385} | train loss {'Reaction outcome loss': 0.2477704935878623, 'Total loss': 0.2477704935878623}
2023-01-05 13:39:34,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:34,530 INFO:     Epoch: 95
2023-01-05 13:39:36,741 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3502504875262578, 'Total loss': 0.3502504875262578} | train loss {'Reaction outcome loss': 0.24306268812516965, 'Total loss': 0.24306268812516965}
2023-01-05 13:39:36,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:36,741 INFO:     Epoch: 96
2023-01-05 13:39:38,952 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3610428680976232, 'Total loss': 0.3610428680976232} | train loss {'Reaction outcome loss': 0.2369865622331089, 'Total loss': 0.2369865622331089}
2023-01-05 13:39:38,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:38,952 INFO:     Epoch: 97
2023-01-05 13:39:41,144 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38149718145529427, 'Total loss': 0.38149718145529427} | train loss {'Reaction outcome loss': 0.232570633097192, 'Total loss': 0.232570633097192}
2023-01-05 13:39:41,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:41,145 INFO:     Epoch: 98
2023-01-05 13:39:43,317 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3730650303264459, 'Total loss': 0.3730650303264459} | train loss {'Reaction outcome loss': 0.2430847983686287, 'Total loss': 0.2430847983686287}
2023-01-05 13:39:43,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:43,317 INFO:     Epoch: 99
2023-01-05 13:39:45,494 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.36971062123775483, 'Total loss': 0.36971062123775483} | train loss {'Reaction outcome loss': 0.24523210961250622, 'Total loss': 0.24523210961250622}
2023-01-05 13:39:45,494 INFO:     Best model found after epoch 89 of 100.
2023-01-05 13:39:45,494 INFO:   Done with stage: TRAINING
2023-01-05 13:39:45,495 INFO:   Starting stage: EVALUATION
2023-01-05 13:39:45,620 INFO:   Done with stage: EVALUATION
2023-01-05 13:39:45,629 INFO:   Leaving out SEQ value Fold_0
2023-01-05 13:39:45,642 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 13:39:45,642 INFO:   Starting stage: FEATURE SCALING
2023-01-05 13:39:46,293 INFO:   Done with stage: FEATURE SCALING
2023-01-05 13:39:46,293 INFO:   Starting stage: SCALING TARGETS
2023-01-05 13:39:46,364 INFO:   Done with stage: SCALING TARGETS
2023-01-05 13:39:46,364 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:39:46,364 INFO:     No hyperparam tuning for this model
2023-01-05 13:39:46,364 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:39:46,364 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 13:39:46,365 INFO:     None feature selector for col prot
2023-01-05 13:39:46,365 INFO:     None feature selector for col prot
2023-01-05 13:39:46,365 INFO:     None feature selector for col prot
2023-01-05 13:39:46,366 INFO:     None feature selector for col chem
2023-01-05 13:39:46,366 INFO:     None feature selector for col chem
2023-01-05 13:39:46,366 INFO:     None feature selector for col chem
2023-01-05 13:39:46,366 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 13:39:46,366 INFO:   Starting stage: BUILD MODEL
2023-01-05 13:39:46,367 INFO:     Number of params in model 72901
2023-01-05 13:39:46,371 INFO:   Done with stage: BUILD MODEL
2023-01-05 13:39:46,371 INFO:   Starting stage: TRAINING
2023-01-05 13:39:46,433 INFO:     Val loss before train {'Reaction outcome loss': 1.0187121470769247, 'Total loss': 1.0187121470769247}
2023-01-05 13:39:46,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:46,433 INFO:     Epoch: 0
2023-01-05 13:39:48,588 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8296522855758667, 'Total loss': 0.8296522855758667} | train loss {'Reaction outcome loss': 0.9449816031830154, 'Total loss': 0.9449816031830154}
2023-01-05 13:39:48,588 INFO:     Found new best model at epoch 0
2023-01-05 13:39:48,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:48,589 INFO:     Epoch: 1
2023-01-05 13:39:50,732 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6630491793155671, 'Total loss': 0.6630491793155671} | train loss {'Reaction outcome loss': 0.7573526761610142, 'Total loss': 0.7573526761610142}
2023-01-05 13:39:50,732 INFO:     Found new best model at epoch 1
2023-01-05 13:39:50,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:50,733 INFO:     Epoch: 2
2023-01-05 13:39:52,877 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5475878516832987, 'Total loss': 0.5475878516832987} | train loss {'Reaction outcome loss': 0.5928174974600764, 'Total loss': 0.5928174974600764}
2023-01-05 13:39:52,878 INFO:     Found new best model at epoch 2
2023-01-05 13:39:52,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:52,879 INFO:     Epoch: 3
2023-01-05 13:39:55,017 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5112326224644979, 'Total loss': 0.5112326224644979} | train loss {'Reaction outcome loss': 0.5367585057324736, 'Total loss': 0.5367585057324736}
2023-01-05 13:39:55,018 INFO:     Found new best model at epoch 3
2023-01-05 13:39:55,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:55,019 INFO:     Epoch: 4
2023-01-05 13:39:57,160 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5040176729361217, 'Total loss': 0.5040176729361217} | train loss {'Reaction outcome loss': 0.5072885965452577, 'Total loss': 0.5072885965452577}
2023-01-05 13:39:57,160 INFO:     Found new best model at epoch 4
2023-01-05 13:39:57,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:57,162 INFO:     Epoch: 5
2023-01-05 13:39:59,287 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49179271459579466, 'Total loss': 0.49179271459579466} | train loss {'Reaction outcome loss': 0.4987376573203254, 'Total loss': 0.4987376573203254}
2023-01-05 13:39:59,287 INFO:     Found new best model at epoch 5
2023-01-05 13:39:59,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:39:59,288 INFO:     Epoch: 6
2023-01-05 13:40:01,434 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4841463287671407, 'Total loss': 0.4841463287671407} | train loss {'Reaction outcome loss': 0.4884957950698198, 'Total loss': 0.4884957950698198}
2023-01-05 13:40:01,434 INFO:     Found new best model at epoch 6
2023-01-05 13:40:01,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:01,435 INFO:     Epoch: 7
2023-01-05 13:40:03,565 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5017120480537415, 'Total loss': 0.5017120480537415} | train loss {'Reaction outcome loss': 0.47593049577226604, 'Total loss': 0.47593049577226604}
2023-01-05 13:40:03,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:03,565 INFO:     Epoch: 8
2023-01-05 13:40:05,745 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48541544477144877, 'Total loss': 0.48541544477144877} | train loss {'Reaction outcome loss': 0.47761431170532304, 'Total loss': 0.47761431170532304}
2023-01-05 13:40:05,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:05,745 INFO:     Epoch: 9
2023-01-05 13:40:07,916 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47558276454607645, 'Total loss': 0.47558276454607645} | train loss {'Reaction outcome loss': 0.46397482712555976, 'Total loss': 0.46397482712555976}
2023-01-05 13:40:07,917 INFO:     Found new best model at epoch 9
2023-01-05 13:40:07,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:07,918 INFO:     Epoch: 10
2023-01-05 13:40:10,086 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48602533439795176, 'Total loss': 0.48602533439795176} | train loss {'Reaction outcome loss': 0.45986802000416455, 'Total loss': 0.45986802000416455}
2023-01-05 13:40:10,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:10,088 INFO:     Epoch: 11
2023-01-05 13:40:12,239 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4757633825143178, 'Total loss': 0.4757633825143178} | train loss {'Reaction outcome loss': 0.4542597565718376, 'Total loss': 0.4542597565718376}
2023-01-05 13:40:12,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:12,240 INFO:     Epoch: 12
2023-01-05 13:40:14,386 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4629702389240265, 'Total loss': 0.4629702389240265} | train loss {'Reaction outcome loss': 0.45451075708779104, 'Total loss': 0.45451075708779104}
2023-01-05 13:40:14,386 INFO:     Found new best model at epoch 12
2023-01-05 13:40:14,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:14,387 INFO:     Epoch: 13
2023-01-05 13:40:16,520 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.480859903494517, 'Total loss': 0.480859903494517} | train loss {'Reaction outcome loss': 0.44563044150815395, 'Total loss': 0.44563044150815395}
2023-01-05 13:40:16,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:16,521 INFO:     Epoch: 14
2023-01-05 13:40:18,657 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4510906934738159, 'Total loss': 0.4510906934738159} | train loss {'Reaction outcome loss': 0.4419951415790694, 'Total loss': 0.4419951415790694}
2023-01-05 13:40:18,658 INFO:     Found new best model at epoch 14
2023-01-05 13:40:18,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:18,659 INFO:     Epoch: 15
2023-01-05 13:40:20,807 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4370802082121372, 'Total loss': 0.4370802082121372} | train loss {'Reaction outcome loss': 0.43542604115757627, 'Total loss': 0.43542604115757627}
2023-01-05 13:40:20,807 INFO:     Found new best model at epoch 15
2023-01-05 13:40:20,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:20,808 INFO:     Epoch: 16
2023-01-05 13:40:22,941 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4683001716931661, 'Total loss': 0.4683001716931661} | train loss {'Reaction outcome loss': 0.4384068218297767, 'Total loss': 0.4384068218297767}
2023-01-05 13:40:22,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:22,941 INFO:     Epoch: 17
2023-01-05 13:40:25,078 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44159920861323676, 'Total loss': 0.44159920861323676} | train loss {'Reaction outcome loss': 0.4318124263064705, 'Total loss': 0.4318124263064705}
2023-01-05 13:40:25,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:25,079 INFO:     Epoch: 18
2023-01-05 13:40:27,205 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48632742563883463, 'Total loss': 0.48632742563883463} | train loss {'Reaction outcome loss': 0.4318764660589016, 'Total loss': 0.4318764660589016}
2023-01-05 13:40:27,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:27,205 INFO:     Epoch: 19
2023-01-05 13:40:29,335 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4491857310136159, 'Total loss': 0.4491857310136159} | train loss {'Reaction outcome loss': 0.42049166745077954, 'Total loss': 0.42049166745077954}
2023-01-05 13:40:29,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:29,336 INFO:     Epoch: 20
2023-01-05 13:40:31,459 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44724568724632263, 'Total loss': 0.44724568724632263} | train loss {'Reaction outcome loss': 0.4205336093249982, 'Total loss': 0.4205336093249982}
2023-01-05 13:40:31,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:31,459 INFO:     Epoch: 21
2023-01-05 13:40:33,598 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4738402128219604, 'Total loss': 0.4738402128219604} | train loss {'Reaction outcome loss': 0.417795038000293, 'Total loss': 0.417795038000293}
2023-01-05 13:40:33,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:33,598 INFO:     Epoch: 22
2023-01-05 13:40:35,738 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43742602864901226, 'Total loss': 0.43742602864901226} | train loss {'Reaction outcome loss': 0.4163690827188701, 'Total loss': 0.4163690827188701}
2023-01-05 13:40:35,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:35,738 INFO:     Epoch: 23
2023-01-05 13:40:37,866 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4662651787201563, 'Total loss': 0.4662651787201563} | train loss {'Reaction outcome loss': 0.4072780740875615, 'Total loss': 0.4072780740875615}
2023-01-05 13:40:37,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:37,867 INFO:     Epoch: 24
2023-01-05 13:40:40,010 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48305893143018086, 'Total loss': 0.48305893143018086} | train loss {'Reaction outcome loss': 0.41011475812453424, 'Total loss': 0.41011475812453424}
2023-01-05 13:40:40,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:40,011 INFO:     Epoch: 25
2023-01-05 13:40:42,139 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43954624931017555, 'Total loss': 0.43954624931017555} | train loss {'Reaction outcome loss': 0.40277721728776056, 'Total loss': 0.40277721728776056}
2023-01-05 13:40:42,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:42,140 INFO:     Epoch: 26
2023-01-05 13:40:44,268 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45727302034695944, 'Total loss': 0.45727302034695944} | train loss {'Reaction outcome loss': 0.3989669081557841, 'Total loss': 0.3989669081557841}
2023-01-05 13:40:44,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:44,268 INFO:     Epoch: 27
2023-01-05 13:40:46,440 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4579552789529165, 'Total loss': 0.4579552789529165} | train loss {'Reaction outcome loss': 0.39859259174796785, 'Total loss': 0.39859259174796785}
2023-01-05 13:40:46,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:46,441 INFO:     Epoch: 28
2023-01-05 13:40:48,609 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4520583430926005, 'Total loss': 0.4520583430926005} | train loss {'Reaction outcome loss': 0.39013176620767936, 'Total loss': 0.39013176620767936}
2023-01-05 13:40:48,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:48,610 INFO:     Epoch: 29
2023-01-05 13:40:50,764 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4472804874181747, 'Total loss': 0.4472804874181747} | train loss {'Reaction outcome loss': 0.39144018490927934, 'Total loss': 0.39144018490927934}
2023-01-05 13:40:50,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:50,765 INFO:     Epoch: 30
2023-01-05 13:40:52,894 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4162052273750305, 'Total loss': 0.4162052273750305} | train loss {'Reaction outcome loss': 0.38221566569413584, 'Total loss': 0.38221566569413584}
2023-01-05 13:40:52,895 INFO:     Found new best model at epoch 30
2023-01-05 13:40:52,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:52,896 INFO:     Epoch: 31
2023-01-05 13:40:55,051 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42065997918446857, 'Total loss': 0.42065997918446857} | train loss {'Reaction outcome loss': 0.37670259846605525, 'Total loss': 0.37670259846605525}
2023-01-05 13:40:55,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:55,051 INFO:     Epoch: 32
2023-01-05 13:40:57,193 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44641191959381105, 'Total loss': 0.44641191959381105} | train loss {'Reaction outcome loss': 0.3764592531225542, 'Total loss': 0.3764592531225542}
2023-01-05 13:40:57,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:57,193 INFO:     Epoch: 33
2023-01-05 13:40:59,336 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4501190563042959, 'Total loss': 0.4501190563042959} | train loss {'Reaction outcome loss': 0.3716162159277575, 'Total loss': 0.3716162159277575}
2023-01-05 13:40:59,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:40:59,336 INFO:     Epoch: 34
2023-01-05 13:41:01,475 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4323884924252828, 'Total loss': 0.4323884924252828} | train loss {'Reaction outcome loss': 0.3748584055906012, 'Total loss': 0.3748584055906012}
2023-01-05 13:41:01,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:01,476 INFO:     Epoch: 35
2023-01-05 13:41:03,612 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4485712766647339, 'Total loss': 0.4485712766647339} | train loss {'Reaction outcome loss': 0.36244046984471545, 'Total loss': 0.36244046984471545}
2023-01-05 13:41:03,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:03,612 INFO:     Epoch: 36
2023-01-05 13:41:05,731 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4603656450907389, 'Total loss': 0.4603656450907389} | train loss {'Reaction outcome loss': 0.3607553259680306, 'Total loss': 0.3607553259680306}
2023-01-05 13:41:05,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:05,732 INFO:     Epoch: 37
2023-01-05 13:41:07,686 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.442588076988856, 'Total loss': 0.442588076988856} | train loss {'Reaction outcome loss': 0.3590996808705539, 'Total loss': 0.3590996808705539}
2023-01-05 13:41:07,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:07,687 INFO:     Epoch: 38
2023-01-05 13:41:09,825 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43409223953882853, 'Total loss': 0.43409223953882853} | train loss {'Reaction outcome loss': 0.3598420887396936, 'Total loss': 0.3598420887396936}
2023-01-05 13:41:09,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:09,825 INFO:     Epoch: 39
2023-01-05 13:41:11,959 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.438430521885554, 'Total loss': 0.438430521885554} | train loss {'Reaction outcome loss': 0.35693333391779963, 'Total loss': 0.35693333391779963}
2023-01-05 13:41:11,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:11,959 INFO:     Epoch: 40
2023-01-05 13:41:14,080 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4533508082230886, 'Total loss': 0.4533508082230886} | train loss {'Reaction outcome loss': 0.340505755486062, 'Total loss': 0.340505755486062}
2023-01-05 13:41:14,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:14,080 INFO:     Epoch: 41
2023-01-05 13:41:16,211 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41406780779361724, 'Total loss': 0.41406780779361724} | train loss {'Reaction outcome loss': 0.34245070170638336, 'Total loss': 0.34245070170638336}
2023-01-05 13:41:16,211 INFO:     Found new best model at epoch 41
2023-01-05 13:41:16,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:16,212 INFO:     Epoch: 42
2023-01-05 13:41:18,359 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41789355377356213, 'Total loss': 0.41789355377356213} | train loss {'Reaction outcome loss': 0.33319445791905816, 'Total loss': 0.33319445791905816}
2023-01-05 13:41:18,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:18,359 INFO:     Epoch: 43
2023-01-05 13:41:20,506 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4747379203637441, 'Total loss': 0.4747379203637441} | train loss {'Reaction outcome loss': 0.33566073923759215, 'Total loss': 0.33566073923759215}
2023-01-05 13:41:20,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:20,506 INFO:     Epoch: 44
2023-01-05 13:41:22,657 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43217867612838745, 'Total loss': 0.43217867612838745} | train loss {'Reaction outcome loss': 0.33536041544301665, 'Total loss': 0.33536041544301665}
2023-01-05 13:41:22,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:22,658 INFO:     Epoch: 45
2023-01-05 13:41:24,851 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4401009023189545, 'Total loss': 0.4401009023189545} | train loss {'Reaction outcome loss': 0.3335073965526845, 'Total loss': 0.3335073965526845}
2023-01-05 13:41:24,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:24,852 INFO:     Epoch: 46
2023-01-05 13:41:27,003 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.454170032342275, 'Total loss': 0.454170032342275} | train loss {'Reaction outcome loss': 0.32449943409131393, 'Total loss': 0.32449943409131393}
2023-01-05 13:41:27,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:27,003 INFO:     Epoch: 47
2023-01-05 13:41:29,149 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.451750777165095, 'Total loss': 0.451750777165095} | train loss {'Reaction outcome loss': 0.32058307929576313, 'Total loss': 0.32058307929576313}
2023-01-05 13:41:29,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:29,150 INFO:     Epoch: 48
2023-01-05 13:41:31,302 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4717412104209264, 'Total loss': 0.4717412104209264} | train loss {'Reaction outcome loss': 0.3161500445465102, 'Total loss': 0.3161500445465102}
2023-01-05 13:41:31,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:31,303 INFO:     Epoch: 49
2023-01-05 13:41:33,453 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4090235238273939, 'Total loss': 0.4090235238273939} | train loss {'Reaction outcome loss': 0.32580661444659653, 'Total loss': 0.32580661444659653}
2023-01-05 13:41:33,453 INFO:     Found new best model at epoch 49
2023-01-05 13:41:33,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:33,455 INFO:     Epoch: 50
2023-01-05 13:41:35,604 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43236334522565206, 'Total loss': 0.43236334522565206} | train loss {'Reaction outcome loss': 0.31462278200762117, 'Total loss': 0.31462278200762117}
2023-01-05 13:41:35,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:35,605 INFO:     Epoch: 51
2023-01-05 13:41:37,772 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.418525160352389, 'Total loss': 0.418525160352389} | train loss {'Reaction outcome loss': 0.3082746058348974, 'Total loss': 0.3082746058348974}
2023-01-05 13:41:37,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:37,773 INFO:     Epoch: 52
2023-01-05 13:41:39,931 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4441746493180593, 'Total loss': 0.4441746493180593} | train loss {'Reaction outcome loss': 0.30397404716724025, 'Total loss': 0.30397404716724025}
2023-01-05 13:41:39,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:39,931 INFO:     Epoch: 53
2023-01-05 13:41:42,104 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40342220664024353, 'Total loss': 0.40342220664024353} | train loss {'Reaction outcome loss': 0.31067660246996115, 'Total loss': 0.31067660246996115}
2023-01-05 13:41:42,104 INFO:     Found new best model at epoch 53
2023-01-05 13:41:42,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:42,106 INFO:     Epoch: 54
2023-01-05 13:41:44,272 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4138132055600484, 'Total loss': 0.4138132055600484} | train loss {'Reaction outcome loss': 0.3015910465895695, 'Total loss': 0.3015910465895695}
2023-01-05 13:41:44,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:44,273 INFO:     Epoch: 55
2023-01-05 13:41:46,411 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43746384382247927, 'Total loss': 0.43746384382247927} | train loss {'Reaction outcome loss': 0.30013908739507633, 'Total loss': 0.30013908739507633}
2023-01-05 13:41:46,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:46,411 INFO:     Epoch: 56
2023-01-05 13:41:48,545 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3871882120768229, 'Total loss': 0.3871882120768229} | train loss {'Reaction outcome loss': 0.3033186502374002, 'Total loss': 0.3033186502374002}
2023-01-05 13:41:48,545 INFO:     Found new best model at epoch 56
2023-01-05 13:41:48,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:48,546 INFO:     Epoch: 57
2023-01-05 13:41:50,664 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39101828038692477, 'Total loss': 0.39101828038692477} | train loss {'Reaction outcome loss': 0.2949000943696847, 'Total loss': 0.2949000943696847}
2023-01-05 13:41:50,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:50,664 INFO:     Epoch: 58
2023-01-05 13:41:52,785 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42826475699742633, 'Total loss': 0.42826475699742633} | train loss {'Reaction outcome loss': 0.29846994460553583, 'Total loss': 0.29846994460553583}
2023-01-05 13:41:52,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:52,786 INFO:     Epoch: 59
2023-01-05 13:41:54,942 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43519838551680246, 'Total loss': 0.43519838551680246} | train loss {'Reaction outcome loss': 0.29690583284101346, 'Total loss': 0.29690583284101346}
2023-01-05 13:41:54,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:54,942 INFO:     Epoch: 60
2023-01-05 13:41:57,092 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4570750206708908, 'Total loss': 0.4570750206708908} | train loss {'Reaction outcome loss': 0.2853083927048384, 'Total loss': 0.2853083927048384}
2023-01-05 13:41:57,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:57,093 INFO:     Epoch: 61
2023-01-05 13:41:59,239 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43001494656006495, 'Total loss': 0.43001494656006495} | train loss {'Reaction outcome loss': 0.2864921238939584, 'Total loss': 0.2864921238939584}
2023-01-05 13:41:59,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:41:59,240 INFO:     Epoch: 62
2023-01-05 13:42:01,420 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42321617528796196, 'Total loss': 0.42321617528796196} | train loss {'Reaction outcome loss': 0.2858076467158368, 'Total loss': 0.2858076467158368}
2023-01-05 13:42:01,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:01,420 INFO:     Epoch: 63
2023-01-05 13:42:03,547 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42010574638843534, 'Total loss': 0.42010574638843534} | train loss {'Reaction outcome loss': 0.28133457042548776, 'Total loss': 0.28133457042548776}
2023-01-05 13:42:03,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:03,548 INFO:     Epoch: 64
2023-01-05 13:42:05,687 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4103148847818375, 'Total loss': 0.4103148847818375} | train loss {'Reaction outcome loss': 0.2881772766420006, 'Total loss': 0.2881772766420006}
2023-01-05 13:42:05,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:05,687 INFO:     Epoch: 65
2023-01-05 13:42:07,823 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39625516533851624, 'Total loss': 0.39625516533851624} | train loss {'Reaction outcome loss': 0.28045690343137425, 'Total loss': 0.28045690343137425}
2023-01-05 13:42:07,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:07,823 INFO:     Epoch: 66
2023-01-05 13:42:09,958 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44750597178936, 'Total loss': 0.44750597178936} | train loss {'Reaction outcome loss': 0.2781887148663293, 'Total loss': 0.2781887148663293}
2023-01-05 13:42:09,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:09,958 INFO:     Epoch: 67
2023-01-05 13:42:12,088 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39569883545239765, 'Total loss': 0.39569883545239765} | train loss {'Reaction outcome loss': 0.2755304341659929, 'Total loss': 0.2755304341659929}
2023-01-05 13:42:12,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:12,089 INFO:     Epoch: 68
2023-01-05 13:42:14,226 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3938392877578735, 'Total loss': 0.3938392877578735} | train loss {'Reaction outcome loss': 0.27215766590632445, 'Total loss': 0.27215766590632445}
2023-01-05 13:42:14,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:14,226 INFO:     Epoch: 69
2023-01-05 13:42:16,366 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41904379228750865, 'Total loss': 0.41904379228750865} | train loss {'Reaction outcome loss': 0.28220160347647477, 'Total loss': 0.28220160347647477}
2023-01-05 13:42:16,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:16,366 INFO:     Epoch: 70
2023-01-05 13:42:18,503 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.406012645115455, 'Total loss': 0.406012645115455} | train loss {'Reaction outcome loss': 0.2699031150444363, 'Total loss': 0.2699031150444363}
2023-01-05 13:42:18,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:18,504 INFO:     Epoch: 71
2023-01-05 13:42:20,661 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42260674635569256, 'Total loss': 0.42260674635569256} | train loss {'Reaction outcome loss': 0.2603367390858866, 'Total loss': 0.2603367390858866}
2023-01-05 13:42:20,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:20,662 INFO:     Epoch: 72
2023-01-05 13:42:22,799 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42309445639451343, 'Total loss': 0.42309445639451343} | train loss {'Reaction outcome loss': 0.27491463595715754, 'Total loss': 0.27491463595715754}
2023-01-05 13:42:22,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:22,799 INFO:     Epoch: 73
2023-01-05 13:42:24,939 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4122767150402069, 'Total loss': 0.4122767150402069} | train loss {'Reaction outcome loss': 0.2581513019917655, 'Total loss': 0.2581513019917655}
2023-01-05 13:42:24,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:24,939 INFO:     Epoch: 74
2023-01-05 13:42:27,060 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4212730248769124, 'Total loss': 0.4212730248769124} | train loss {'Reaction outcome loss': 0.2629381402320888, 'Total loss': 0.2629381402320888}
2023-01-05 13:42:27,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:27,060 INFO:     Epoch: 75
2023-01-05 13:42:29,205 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40992446144421896, 'Total loss': 0.40992446144421896} | train loss {'Reaction outcome loss': 0.2628907294753585, 'Total loss': 0.2628907294753585}
2023-01-05 13:42:29,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:29,206 INFO:     Epoch: 76
2023-01-05 13:42:31,358 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3830592838426431, 'Total loss': 0.3830592838426431} | train loss {'Reaction outcome loss': 0.26503823365825807, 'Total loss': 0.26503823365825807}
2023-01-05 13:42:31,358 INFO:     Found new best model at epoch 76
2023-01-05 13:42:31,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:31,359 INFO:     Epoch: 77
2023-01-05 13:42:33,497 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4229634553194046, 'Total loss': 0.4229634553194046} | train loss {'Reaction outcome loss': 0.2565164320089304, 'Total loss': 0.2565164320089304}
2023-01-05 13:42:33,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:33,497 INFO:     Epoch: 78
2023-01-05 13:42:35,623 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4132003396749496, 'Total loss': 0.4132003396749496} | train loss {'Reaction outcome loss': 0.25828846618125256, 'Total loss': 0.25828846618125256}
2023-01-05 13:42:35,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:35,624 INFO:     Epoch: 79
2023-01-05 13:42:37,798 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4386849840482076, 'Total loss': 0.4386849840482076} | train loss {'Reaction outcome loss': 0.255126762265054, 'Total loss': 0.255126762265054}
2023-01-05 13:42:37,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:37,798 INFO:     Epoch: 80
2023-01-05 13:42:39,974 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44321391383806863, 'Total loss': 0.44321391383806863} | train loss {'Reaction outcome loss': 0.2615709087954168, 'Total loss': 0.2615709087954168}
2023-01-05 13:42:39,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:39,974 INFO:     Epoch: 81
2023-01-05 13:42:42,136 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4214284400145213, 'Total loss': 0.4214284400145213} | train loss {'Reaction outcome loss': 0.2548152671134385, 'Total loss': 0.2548152671134385}
2023-01-05 13:42:42,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:42,136 INFO:     Epoch: 82
2023-01-05 13:42:44,292 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44797767301400504, 'Total loss': 0.44797767301400504} | train loss {'Reaction outcome loss': 0.25861534801903213, 'Total loss': 0.25861534801903213}
2023-01-05 13:42:44,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:44,292 INFO:     Epoch: 83
2023-01-05 13:42:46,441 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40147891640663147, 'Total loss': 0.40147891640663147} | train loss {'Reaction outcome loss': 0.25172885030127357, 'Total loss': 0.25172885030127357}
2023-01-05 13:42:46,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:46,441 INFO:     Epoch: 84
2023-01-05 13:42:48,592 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.425192994872729, 'Total loss': 0.425192994872729} | train loss {'Reaction outcome loss': 0.24644077616832116, 'Total loss': 0.24644077616832116}
2023-01-05 13:42:48,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:48,593 INFO:     Epoch: 85
2023-01-05 13:42:50,714 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45908755461374917, 'Total loss': 0.45908755461374917} | train loss {'Reaction outcome loss': 0.24920316262129885, 'Total loss': 0.24920316262129885}
2023-01-05 13:42:50,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:50,715 INFO:     Epoch: 86
2023-01-05 13:42:52,860 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3913652082284292, 'Total loss': 0.3913652082284292} | train loss {'Reaction outcome loss': 0.25242562857150597, 'Total loss': 0.25242562857150597}
2023-01-05 13:42:52,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:52,861 INFO:     Epoch: 87
2023-01-05 13:42:55,009 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44266778528690337, 'Total loss': 0.44266778528690337} | train loss {'Reaction outcome loss': 0.24766324625017433, 'Total loss': 0.24766324625017433}
2023-01-05 13:42:55,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:55,009 INFO:     Epoch: 88
2023-01-05 13:42:57,155 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41893279254436494, 'Total loss': 0.41893279254436494} | train loss {'Reaction outcome loss': 0.2507166192003519, 'Total loss': 0.2507166192003519}
2023-01-05 13:42:57,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:57,155 INFO:     Epoch: 89
2023-01-05 13:42:59,298 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40601106733083725, 'Total loss': 0.40601106733083725} | train loss {'Reaction outcome loss': 0.24951124715408052, 'Total loss': 0.24951124715408052}
2023-01-05 13:42:59,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:42:59,298 INFO:     Epoch: 90
2023-01-05 13:43:01,429 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44415291349093117, 'Total loss': 0.44415291349093117} | train loss {'Reaction outcome loss': 0.2440468899524995, 'Total loss': 0.2440468899524995}
2023-01-05 13:43:01,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:01,429 INFO:     Epoch: 91
2023-01-05 13:43:03,565 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4409973055124283, 'Total loss': 0.4409973055124283} | train loss {'Reaction outcome loss': 0.23971206229859895, 'Total loss': 0.23971206229859895}
2023-01-05 13:43:03,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:03,566 INFO:     Epoch: 92
2023-01-05 13:43:05,700 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45382357984781263, 'Total loss': 0.45382357984781263} | train loss {'Reaction outcome loss': 0.2409357198575226, 'Total loss': 0.2409357198575226}
2023-01-05 13:43:05,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:05,702 INFO:     Epoch: 93
2023-01-05 13:43:07,861 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4001878537237644, 'Total loss': 0.4001878537237644} | train loss {'Reaction outcome loss': 0.24359276134479982, 'Total loss': 0.24359276134479982}
2023-01-05 13:43:07,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:07,861 INFO:     Epoch: 94
2023-01-05 13:43:10,006 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3924363851547241, 'Total loss': 0.3924363851547241} | train loss {'Reaction outcome loss': 0.2367246598753072, 'Total loss': 0.2367246598753072}
2023-01-05 13:43:10,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:10,006 INFO:     Epoch: 95
2023-01-05 13:43:12,129 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3983292212088903, 'Total loss': 0.3983292212088903} | train loss {'Reaction outcome loss': 0.24070486505209965, 'Total loss': 0.24070486505209965}
2023-01-05 13:43:12,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:12,130 INFO:     Epoch: 96
2023-01-05 13:43:14,267 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4496182026962439, 'Total loss': 0.4496182026962439} | train loss {'Reaction outcome loss': 0.23449892724735022, 'Total loss': 0.23449892724735022}
2023-01-05 13:43:14,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:14,268 INFO:     Epoch: 97
2023-01-05 13:43:16,435 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42406962513923646, 'Total loss': 0.42406962513923646} | train loss {'Reaction outcome loss': 0.2438521252564379, 'Total loss': 0.2438521252564379}
2023-01-05 13:43:16,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:16,435 INFO:     Epoch: 98
2023-01-05 13:43:18,596 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42646267811457317, 'Total loss': 0.42646267811457317} | train loss {'Reaction outcome loss': 0.23705777218633325, 'Total loss': 0.23705777218633325}
2023-01-05 13:43:18,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:18,596 INFO:     Epoch: 99
2023-01-05 13:43:20,738 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4316835085550944, 'Total loss': 0.4316835085550944} | train loss {'Reaction outcome loss': 0.23791845848471144, 'Total loss': 0.23791845848471144}
2023-01-05 13:43:20,738 INFO:     Best model found after epoch 77 of 100.
2023-01-05 13:43:20,738 INFO:   Done with stage: TRAINING
2023-01-05 13:43:20,738 INFO:   Starting stage: EVALUATION
2023-01-05 13:43:20,879 INFO:   Done with stage: EVALUATION
2023-01-05 13:43:20,879 INFO:   Leaving out SEQ value Fold_1
2023-01-05 13:43:20,892 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 13:43:20,892 INFO:   Starting stage: FEATURE SCALING
2023-01-05 13:43:21,559 INFO:   Done with stage: FEATURE SCALING
2023-01-05 13:43:21,560 INFO:   Starting stage: SCALING TARGETS
2023-01-05 13:43:21,629 INFO:   Done with stage: SCALING TARGETS
2023-01-05 13:43:21,629 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:43:21,629 INFO:     No hyperparam tuning for this model
2023-01-05 13:43:21,629 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:43:21,629 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 13:43:21,630 INFO:     None feature selector for col prot
2023-01-05 13:43:21,630 INFO:     None feature selector for col prot
2023-01-05 13:43:21,630 INFO:     None feature selector for col prot
2023-01-05 13:43:21,631 INFO:     None feature selector for col chem
2023-01-05 13:43:21,631 INFO:     None feature selector for col chem
2023-01-05 13:43:21,631 INFO:     None feature selector for col chem
2023-01-05 13:43:21,631 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 13:43:21,631 INFO:   Starting stage: BUILD MODEL
2023-01-05 13:43:21,632 INFO:     Number of params in model 72901
2023-01-05 13:43:21,636 INFO:   Done with stage: BUILD MODEL
2023-01-05 13:43:21,636 INFO:   Starting stage: TRAINING
2023-01-05 13:43:21,697 INFO:     Val loss before train {'Reaction outcome loss': 0.99161430199941, 'Total loss': 0.99161430199941}
2023-01-05 13:43:21,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:21,697 INFO:     Epoch: 0
2023-01-05 13:43:23,850 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8226675669352214, 'Total loss': 0.8226675669352214} | train loss {'Reaction outcome loss': 0.9318304562220608, 'Total loss': 0.9318304562220608}
2023-01-05 13:43:23,850 INFO:     Found new best model at epoch 0
2023-01-05 13:43:23,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:23,851 INFO:     Epoch: 1
2023-01-05 13:43:25,983 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6037444760402043, 'Total loss': 0.6037444760402043} | train loss {'Reaction outcome loss': 0.7339690543004196, 'Total loss': 0.7339690543004196}
2023-01-05 13:43:25,984 INFO:     Found new best model at epoch 1
2023-01-05 13:43:25,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:25,985 INFO:     Epoch: 2
2023-01-05 13:43:28,148 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5370491842428843, 'Total loss': 0.5370491842428843} | train loss {'Reaction outcome loss': 0.5776571222465404, 'Total loss': 0.5776571222465404}
2023-01-05 13:43:28,148 INFO:     Found new best model at epoch 2
2023-01-05 13:43:28,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:28,150 INFO:     Epoch: 3
2023-01-05 13:43:30,305 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5431906700134277, 'Total loss': 0.5431906700134277} | train loss {'Reaction outcome loss': 0.5414630577076961, 'Total loss': 0.5414630577076961}
2023-01-05 13:43:30,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:30,305 INFO:     Epoch: 4
2023-01-05 13:43:32,444 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5241731246312459, 'Total loss': 0.5241731246312459} | train loss {'Reaction outcome loss': 0.5134250143964361, 'Total loss': 0.5134250143964361}
2023-01-05 13:43:32,444 INFO:     Found new best model at epoch 4
2023-01-05 13:43:32,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:32,446 INFO:     Epoch: 5
2023-01-05 13:43:34,603 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5495261391003926, 'Total loss': 0.5495261391003926} | train loss {'Reaction outcome loss': 0.500491531389038, 'Total loss': 0.500491531389038}
2023-01-05 13:43:34,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:34,604 INFO:     Epoch: 6
2023-01-05 13:43:36,741 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5131308952967326, 'Total loss': 0.5131308952967326} | train loss {'Reaction outcome loss': 0.4930504619205085, 'Total loss': 0.4930504619205085}
2023-01-05 13:43:36,742 INFO:     Found new best model at epoch 6
2023-01-05 13:43:36,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:36,744 INFO:     Epoch: 7
2023-01-05 13:43:38,884 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5019209365049998, 'Total loss': 0.5019209365049998} | train loss {'Reaction outcome loss': 0.4851685389332528, 'Total loss': 0.4851685389332528}
2023-01-05 13:43:38,884 INFO:     Found new best model at epoch 7
2023-01-05 13:43:38,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:38,886 INFO:     Epoch: 8
2023-01-05 13:43:41,045 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5036652902762095, 'Total loss': 0.5036652902762095} | train loss {'Reaction outcome loss': 0.4731462142654579, 'Total loss': 0.4731462142654579}
2023-01-05 13:43:41,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:41,045 INFO:     Epoch: 9
2023-01-05 13:43:43,180 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4854153176148733, 'Total loss': 0.4854153176148733} | train loss {'Reaction outcome loss': 0.46081973976679963, 'Total loss': 0.46081973976679963}
2023-01-05 13:43:43,180 INFO:     Found new best model at epoch 9
2023-01-05 13:43:43,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:43,182 INFO:     Epoch: 10
2023-01-05 13:43:45,346 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48899992406368253, 'Total loss': 0.48899992406368253} | train loss {'Reaction outcome loss': 0.46031497206783645, 'Total loss': 0.46031497206783645}
2023-01-05 13:43:45,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:45,347 INFO:     Epoch: 11
2023-01-05 13:43:47,494 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5106548527876537, 'Total loss': 0.5106548527876537} | train loss {'Reaction outcome loss': 0.45293472022035697, 'Total loss': 0.45293472022035697}
2023-01-05 13:43:47,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:47,494 INFO:     Epoch: 12
2023-01-05 13:43:49,629 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5038414696852366, 'Total loss': 0.5038414696852366} | train loss {'Reaction outcome loss': 0.44656186461122366, 'Total loss': 0.44656186461122366}
2023-01-05 13:43:49,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:49,629 INFO:     Epoch: 13
2023-01-05 13:43:51,794 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5352412819862366, 'Total loss': 0.5352412819862366} | train loss {'Reaction outcome loss': 0.4455418859737633, 'Total loss': 0.4455418859737633}
2023-01-05 13:43:51,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:51,794 INFO:     Epoch: 14
2023-01-05 13:43:53,957 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48393555283546447, 'Total loss': 0.48393555283546447} | train loss {'Reaction outcome loss': 0.4366247819016015, 'Total loss': 0.4366247819016015}
2023-01-05 13:43:53,957 INFO:     Found new best model at epoch 14
2023-01-05 13:43:53,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:53,959 INFO:     Epoch: 15
2023-01-05 13:43:56,095 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4771591285864512, 'Total loss': 0.4771591285864512} | train loss {'Reaction outcome loss': 0.4339597119140799, 'Total loss': 0.4339597119140799}
2023-01-05 13:43:56,096 INFO:     Found new best model at epoch 15
2023-01-05 13:43:56,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:56,097 INFO:     Epoch: 16
2023-01-05 13:43:58,273 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49567677776018776, 'Total loss': 0.49567677776018776} | train loss {'Reaction outcome loss': 0.42564848707105124, 'Total loss': 0.42564848707105124}
2023-01-05 13:43:58,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:43:58,273 INFO:     Epoch: 17
2023-01-05 13:44:00,427 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4769064704577128, 'Total loss': 0.4769064704577128} | train loss {'Reaction outcome loss': 0.42341331419718525, 'Total loss': 0.42341331419718525}
2023-01-05 13:44:00,427 INFO:     Found new best model at epoch 17
2023-01-05 13:44:00,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:00,428 INFO:     Epoch: 18
2023-01-05 13:44:02,600 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48724257449309033, 'Total loss': 0.48724257449309033} | train loss {'Reaction outcome loss': 0.4185074131636724, 'Total loss': 0.4185074131636724}
2023-01-05 13:44:02,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:02,600 INFO:     Epoch: 19
2023-01-05 13:44:04,780 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5103909552097321, 'Total loss': 0.5103909552097321} | train loss {'Reaction outcome loss': 0.41462282817402896, 'Total loss': 0.41462282817402896}
2023-01-05 13:44:04,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:04,780 INFO:     Epoch: 20
2023-01-05 13:44:06,930 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4781010647614797, 'Total loss': 0.4781010647614797} | train loss {'Reaction outcome loss': 0.4130605528008764, 'Total loss': 0.4130605528008764}
2023-01-05 13:44:06,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:06,931 INFO:     Epoch: 21
2023-01-05 13:44:09,097 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4776882727940877, 'Total loss': 0.4776882727940877} | train loss {'Reaction outcome loss': 0.40467140907897564, 'Total loss': 0.40467140907897564}
2023-01-05 13:44:09,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:09,097 INFO:     Epoch: 22
2023-01-05 13:44:11,270 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5050445437431336, 'Total loss': 0.5050445437431336} | train loss {'Reaction outcome loss': 0.4031543236253035, 'Total loss': 0.4031543236253035}
2023-01-05 13:44:11,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:11,270 INFO:     Epoch: 23
2023-01-05 13:44:13,436 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5050640900929769, 'Total loss': 0.5050640900929769} | train loss {'Reaction outcome loss': 0.39692704254475825, 'Total loss': 0.39692704254475825}
2023-01-05 13:44:13,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:13,436 INFO:     Epoch: 24
2023-01-05 13:44:15,599 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48642527461051943, 'Total loss': 0.48642527461051943} | train loss {'Reaction outcome loss': 0.39455217525471736, 'Total loss': 0.39455217525471736}
2023-01-05 13:44:15,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:15,599 INFO:     Epoch: 25
2023-01-05 13:44:17,759 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48978846371173856, 'Total loss': 0.48978846371173856} | train loss {'Reaction outcome loss': 0.39188081118529733, 'Total loss': 0.39188081118529733}
2023-01-05 13:44:17,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:17,759 INFO:     Epoch: 26
2023-01-05 13:44:19,909 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.480579549074173, 'Total loss': 0.480579549074173} | train loss {'Reaction outcome loss': 0.39022176601264597, 'Total loss': 0.39022176601264597}
2023-01-05 13:44:19,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:19,909 INFO:     Epoch: 27
2023-01-05 13:44:22,070 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4744399610906839, 'Total loss': 0.4744399610906839} | train loss {'Reaction outcome loss': 0.3840266799513441, 'Total loss': 0.3840266799513441}
2023-01-05 13:44:22,070 INFO:     Found new best model at epoch 27
2023-01-05 13:44:22,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:22,072 INFO:     Epoch: 28
2023-01-05 13:44:24,233 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4827906847000122, 'Total loss': 0.4827906847000122} | train loss {'Reaction outcome loss': 0.37862779825490755, 'Total loss': 0.37862779825490755}
2023-01-05 13:44:24,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:24,233 INFO:     Epoch: 29
2023-01-05 13:44:26,383 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47413709859053293, 'Total loss': 0.47413709859053293} | train loss {'Reaction outcome loss': 0.38330233475043823, 'Total loss': 0.38330233475043823}
2023-01-05 13:44:26,384 INFO:     Found new best model at epoch 29
2023-01-05 13:44:26,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:26,385 INFO:     Epoch: 30
2023-01-05 13:44:28,530 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46607573827107746, 'Total loss': 0.46607573827107746} | train loss {'Reaction outcome loss': 0.3723668935606732, 'Total loss': 0.3723668935606732}
2023-01-05 13:44:28,530 INFO:     Found new best model at epoch 30
2023-01-05 13:44:28,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:28,532 INFO:     Epoch: 31
2023-01-05 13:44:30,667 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47977916995684305, 'Total loss': 0.47977916995684305} | train loss {'Reaction outcome loss': 0.37335366268988945, 'Total loss': 0.37335366268988945}
2023-01-05 13:44:30,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:30,667 INFO:     Epoch: 32
2023-01-05 13:44:32,818 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4586101233959198, 'Total loss': 0.4586101233959198} | train loss {'Reaction outcome loss': 0.3661690437010605, 'Total loss': 0.3661690437010605}
2023-01-05 13:44:32,818 INFO:     Found new best model at epoch 32
2023-01-05 13:44:32,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:32,819 INFO:     Epoch: 33
2023-01-05 13:44:34,971 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5316819330056508, 'Total loss': 0.5316819330056508} | train loss {'Reaction outcome loss': 0.36260197754867757, 'Total loss': 0.36260197754867757}
2023-01-05 13:44:34,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:34,971 INFO:     Epoch: 34
2023-01-05 13:44:37,165 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.479844989379247, 'Total loss': 0.479844989379247} | train loss {'Reaction outcome loss': 0.3655663562163602, 'Total loss': 0.3655663562163602}
2023-01-05 13:44:37,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:37,167 INFO:     Epoch: 35
2023-01-05 13:44:39,322 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48396655718485515, 'Total loss': 0.48396655718485515} | train loss {'Reaction outcome loss': 0.35828204975075967, 'Total loss': 0.35828204975075967}
2023-01-05 13:44:39,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:39,322 INFO:     Epoch: 36
2023-01-05 13:44:41,468 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5217212557792663, 'Total loss': 0.5217212557792663} | train loss {'Reaction outcome loss': 0.3532523399178129, 'Total loss': 0.3532523399178129}
2023-01-05 13:44:41,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:41,469 INFO:     Epoch: 37
2023-01-05 13:44:43,623 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4888778418302536, 'Total loss': 0.4888778418302536} | train loss {'Reaction outcome loss': 0.35046719145165744, 'Total loss': 0.35046719145165744}
2023-01-05 13:44:43,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:43,624 INFO:     Epoch: 38
2023-01-05 13:44:45,785 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5278161029020946, 'Total loss': 0.5278161029020946} | train loss {'Reaction outcome loss': 0.34788350472702595, 'Total loss': 0.34788350472702595}
2023-01-05 13:44:45,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:45,785 INFO:     Epoch: 39
2023-01-05 13:44:47,924 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4643254001935323, 'Total loss': 0.4643254001935323} | train loss {'Reaction outcome loss': 0.35025739938999617, 'Total loss': 0.35025739938999617}
2023-01-05 13:44:47,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:47,924 INFO:     Epoch: 40
2023-01-05 13:44:50,074 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.49283940692742667, 'Total loss': 0.49283940692742667} | train loss {'Reaction outcome loss': 0.3472271724094222, 'Total loss': 0.3472271724094222}
2023-01-05 13:44:50,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:50,075 INFO:     Epoch: 41
2023-01-05 13:44:52,223 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4818157970905304, 'Total loss': 0.4818157970905304} | train loss {'Reaction outcome loss': 0.33624062246649805, 'Total loss': 0.33624062246649805}
2023-01-05 13:44:52,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:52,223 INFO:     Epoch: 42
2023-01-05 13:44:54,362 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5179300745328267, 'Total loss': 0.5179300745328267} | train loss {'Reaction outcome loss': 0.3390875726285642, 'Total loss': 0.3390875726285642}
2023-01-05 13:44:54,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:54,363 INFO:     Epoch: 43
2023-01-05 13:44:56,518 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4812206243475278, 'Total loss': 0.4812206243475278} | train loss {'Reaction outcome loss': 0.33516066622016205, 'Total loss': 0.33516066622016205}
2023-01-05 13:44:56,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:56,519 INFO:     Epoch: 44
2023-01-05 13:44:58,661 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4806879490613937, 'Total loss': 0.4806879490613937} | train loss {'Reaction outcome loss': 0.3327096788770091, 'Total loss': 0.3327096788770091}
2023-01-05 13:44:58,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:44:58,661 INFO:     Epoch: 45
2023-01-05 13:45:00,818 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46610250795880953, 'Total loss': 0.46610250795880953} | train loss {'Reaction outcome loss': 0.32869599373453723, 'Total loss': 0.32869599373453723}
2023-01-05 13:45:00,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:00,819 INFO:     Epoch: 46
2023-01-05 13:45:02,982 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4643261810143789, 'Total loss': 0.4643261810143789} | train loss {'Reaction outcome loss': 0.32462459960340584, 'Total loss': 0.32462459960340584}
2023-01-05 13:45:02,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:02,982 INFO:     Epoch: 47
2023-01-05 13:45:05,129 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.455209352572759, 'Total loss': 0.455209352572759} | train loss {'Reaction outcome loss': 0.3202212726303043, 'Total loss': 0.3202212726303043}
2023-01-05 13:45:05,129 INFO:     Found new best model at epoch 47
2023-01-05 13:45:05,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:05,131 INFO:     Epoch: 48
2023-01-05 13:45:07,293 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5205836236476898, 'Total loss': 0.5205836236476898} | train loss {'Reaction outcome loss': 0.3190801667090315, 'Total loss': 0.3190801667090315}
2023-01-05 13:45:07,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:07,293 INFO:     Epoch: 49
2023-01-05 13:45:09,445 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4797880291938782, 'Total loss': 0.4797880291938782} | train loss {'Reaction outcome loss': 0.313521608166451, 'Total loss': 0.313521608166451}
2023-01-05 13:45:09,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:09,445 INFO:     Epoch: 50
2023-01-05 13:45:11,581 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4926935076713562, 'Total loss': 0.4926935076713562} | train loss {'Reaction outcome loss': 0.3188898864535302, 'Total loss': 0.3188898864535302}
2023-01-05 13:45:11,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:11,582 INFO:     Epoch: 51
2023-01-05 13:45:13,744 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4603388135631879, 'Total loss': 0.4603388135631879} | train loss {'Reaction outcome loss': 0.31265188431380875, 'Total loss': 0.31265188431380875}
2023-01-05 13:45:13,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:13,746 INFO:     Epoch: 52
2023-01-05 13:45:15,692 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47232484420140586, 'Total loss': 0.47232484420140586} | train loss {'Reaction outcome loss': 0.314139745259372, 'Total loss': 0.314139745259372}
2023-01-05 13:45:15,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:15,693 INFO:     Epoch: 53
2023-01-05 13:45:17,843 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4844269136587779, 'Total loss': 0.4844269136587779} | train loss {'Reaction outcome loss': 0.3099155552076842, 'Total loss': 0.3099155552076842}
2023-01-05 13:45:17,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:17,843 INFO:     Epoch: 54
2023-01-05 13:45:20,016 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5045248210430145, 'Total loss': 0.5045248210430145} | train loss {'Reaction outcome loss': 0.3138901909718113, 'Total loss': 0.3138901909718113}
2023-01-05 13:45:20,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:20,017 INFO:     Epoch: 55
2023-01-05 13:45:22,164 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48392869035402936, 'Total loss': 0.48392869035402936} | train loss {'Reaction outcome loss': 0.3069958553316384, 'Total loss': 0.3069958553316384}
2023-01-05 13:45:22,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:22,164 INFO:     Epoch: 56
2023-01-05 13:45:24,299 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4757329175869624, 'Total loss': 0.4757329175869624} | train loss {'Reaction outcome loss': 0.3081557554376386, 'Total loss': 0.3081557554376386}
2023-01-05 13:45:24,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:24,299 INFO:     Epoch: 57
2023-01-05 13:45:26,464 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47473730544249215, 'Total loss': 0.47473730544249215} | train loss {'Reaction outcome loss': 0.30360482177649534, 'Total loss': 0.30360482177649534}
2023-01-05 13:45:26,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:26,464 INFO:     Epoch: 58
2023-01-05 13:45:28,600 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4736462781826655, 'Total loss': 0.4736462781826655} | train loss {'Reaction outcome loss': 0.30027660178224536, 'Total loss': 0.30027660178224536}
2023-01-05 13:45:28,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:28,600 INFO:     Epoch: 59
2023-01-05 13:45:30,746 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48435407678286235, 'Total loss': 0.48435407678286235} | train loss {'Reaction outcome loss': 0.3029324283728199, 'Total loss': 0.3029324283728199}
2023-01-05 13:45:30,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:30,747 INFO:     Epoch: 60
2023-01-05 13:45:32,910 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4688887437184652, 'Total loss': 0.4688887437184652} | train loss {'Reaction outcome loss': 0.2997990439707128, 'Total loss': 0.2997990439707128}
2023-01-05 13:45:32,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:32,911 INFO:     Epoch: 61
2023-01-05 13:45:35,050 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4469523737827937, 'Total loss': 0.4469523737827937} | train loss {'Reaction outcome loss': 0.2928621780236054, 'Total loss': 0.2928621780236054}
2023-01-05 13:45:35,050 INFO:     Found new best model at epoch 61
2023-01-05 13:45:35,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:35,051 INFO:     Epoch: 62
2023-01-05 13:45:37,218 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4845662020146847, 'Total loss': 0.4845662020146847} | train loss {'Reaction outcome loss': 0.2963356286232924, 'Total loss': 0.2963356286232924}
2023-01-05 13:45:37,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:37,218 INFO:     Epoch: 63
2023-01-05 13:45:39,382 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48064343531926473, 'Total loss': 0.48064343531926473} | train loss {'Reaction outcome loss': 0.28610666070378177, 'Total loss': 0.28610666070378177}
2023-01-05 13:45:39,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:39,382 INFO:     Epoch: 64
2023-01-05 13:45:41,531 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4662269910176595, 'Total loss': 0.4662269910176595} | train loss {'Reaction outcome loss': 0.2945507118464821, 'Total loss': 0.2945507118464821}
2023-01-05 13:45:41,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:41,531 INFO:     Epoch: 65
2023-01-05 13:45:43,685 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4927175879478455, 'Total loss': 0.4927175879478455} | train loss {'Reaction outcome loss': 0.29335778817044994, 'Total loss': 0.29335778817044994}
2023-01-05 13:45:43,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:43,686 INFO:     Epoch: 66
2023-01-05 13:45:45,830 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4955454349517822, 'Total loss': 0.4955454349517822} | train loss {'Reaction outcome loss': 0.2911227275447471, 'Total loss': 0.2911227275447471}
2023-01-05 13:45:45,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:45,830 INFO:     Epoch: 67
2023-01-05 13:45:48,045 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4881587525208791, 'Total loss': 0.4881587525208791} | train loss {'Reaction outcome loss': 0.28491540817394306, 'Total loss': 0.28491540817394306}
2023-01-05 13:45:48,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:48,045 INFO:     Epoch: 68
2023-01-05 13:45:50,248 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44101163434485596, 'Total loss': 0.44101163434485596} | train loss {'Reaction outcome loss': 0.2885144822652975, 'Total loss': 0.2885144822652975}
2023-01-05 13:45:50,249 INFO:     Found new best model at epoch 68
2023-01-05 13:45:50,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:50,250 INFO:     Epoch: 69
2023-01-05 13:45:52,461 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4795197496811549, 'Total loss': 0.4795197496811549} | train loss {'Reaction outcome loss': 0.2832139995438557, 'Total loss': 0.2832139995438557}
2023-01-05 13:45:52,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:52,461 INFO:     Epoch: 70
2023-01-05 13:45:54,681 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4989530732234319, 'Total loss': 0.4989530732234319} | train loss {'Reaction outcome loss': 0.2827361819613045, 'Total loss': 0.2827361819613045}
2023-01-05 13:45:54,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:54,682 INFO:     Epoch: 71
2023-01-05 13:45:56,903 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44341795643170673, 'Total loss': 0.44341795643170673} | train loss {'Reaction outcome loss': 0.2784997954774294, 'Total loss': 0.2784997954774294}
2023-01-05 13:45:56,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:56,903 INFO:     Epoch: 72
2023-01-05 13:45:59,057 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4968266467253367, 'Total loss': 0.4968266467253367} | train loss {'Reaction outcome loss': 0.28376444165397735, 'Total loss': 0.28376444165397735}
2023-01-05 13:45:59,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:45:59,057 INFO:     Epoch: 73
2023-01-05 13:46:01,207 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4768796622753143, 'Total loss': 0.4768796622753143} | train loss {'Reaction outcome loss': 0.27274393714474937, 'Total loss': 0.27274393714474937}
2023-01-05 13:46:01,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:01,207 INFO:     Epoch: 74
2023-01-05 13:46:03,358 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4940581858158112, 'Total loss': 0.4940581858158112} | train loss {'Reaction outcome loss': 0.2744219522161858, 'Total loss': 0.2744219522161858}
2023-01-05 13:46:03,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:03,359 INFO:     Epoch: 75
2023-01-05 13:46:05,513 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48010116318861645, 'Total loss': 0.48010116318861645} | train loss {'Reaction outcome loss': 0.28406832605110904, 'Total loss': 0.28406832605110904}
2023-01-05 13:46:05,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:05,513 INFO:     Epoch: 76
2023-01-05 13:46:07,662 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45181345840295156, 'Total loss': 0.45181345840295156} | train loss {'Reaction outcome loss': 0.27294709650378157, 'Total loss': 0.27294709650378157}
2023-01-05 13:46:07,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:07,662 INFO:     Epoch: 77
2023-01-05 13:46:09,795 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4976501484711965, 'Total loss': 0.4976501484711965} | train loss {'Reaction outcome loss': 0.2672189402387199, 'Total loss': 0.2672189402387199}
2023-01-05 13:46:09,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:09,795 INFO:     Epoch: 78
2023-01-05 13:46:11,939 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5158439715703328, 'Total loss': 0.5158439715703328} | train loss {'Reaction outcome loss': 0.2657617891248125, 'Total loss': 0.2657617891248125}
2023-01-05 13:46:11,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:11,939 INFO:     Epoch: 79
2023-01-05 13:46:14,084 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4766945699850718, 'Total loss': 0.4766945699850718} | train loss {'Reaction outcome loss': 0.2692941232264912, 'Total loss': 0.2692941232264912}
2023-01-05 13:46:14,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:14,084 INFO:     Epoch: 80
2023-01-05 13:46:16,217 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5145854185024897, 'Total loss': 0.5145854185024897} | train loss {'Reaction outcome loss': 0.2676609738451177, 'Total loss': 0.2676609738451177}
2023-01-05 13:46:16,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:16,217 INFO:     Epoch: 81
2023-01-05 13:46:18,355 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48012504825989405, 'Total loss': 0.48012504825989405} | train loss {'Reaction outcome loss': 0.26620469886782394, 'Total loss': 0.26620469886782394}
2023-01-05 13:46:18,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:18,355 INFO:     Epoch: 82
2023-01-05 13:46:20,492 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4912959709763527, 'Total loss': 0.4912959709763527} | train loss {'Reaction outcome loss': 0.26810493696494586, 'Total loss': 0.26810493696494586}
2023-01-05 13:46:20,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:20,493 INFO:     Epoch: 83
2023-01-05 13:46:22,627 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46486718753973644, 'Total loss': 0.46486718753973644} | train loss {'Reaction outcome loss': 0.2635447772790807, 'Total loss': 0.2635447772790807}
2023-01-05 13:46:22,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:22,627 INFO:     Epoch: 84
2023-01-05 13:46:24,768 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5262860208749771, 'Total loss': 0.5262860208749771} | train loss {'Reaction outcome loss': 0.25617034193536226, 'Total loss': 0.25617034193536226}
2023-01-05 13:46:24,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:24,768 INFO:     Epoch: 85
2023-01-05 13:46:26,893 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4824554940064748, 'Total loss': 0.4824554940064748} | train loss {'Reaction outcome loss': 0.26312972662331413, 'Total loss': 0.26312972662331413}
2023-01-05 13:46:26,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:26,894 INFO:     Epoch: 86
2023-01-05 13:46:29,019 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4789003739754359, 'Total loss': 0.4789003739754359} | train loss {'Reaction outcome loss': 0.2610099975318804, 'Total loss': 0.2610099975318804}
2023-01-05 13:46:29,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:29,019 INFO:     Epoch: 87
2023-01-05 13:46:31,142 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44676002164681755, 'Total loss': 0.44676002164681755} | train loss {'Reaction outcome loss': 0.2631597732173374, 'Total loss': 0.2631597732173374}
2023-01-05 13:46:31,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:31,143 INFO:     Epoch: 88
2023-01-05 13:46:33,295 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5332897275686264, 'Total loss': 0.5332897275686264} | train loss {'Reaction outcome loss': 0.2599115143156182, 'Total loss': 0.2599115143156182}
2023-01-05 13:46:33,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:33,296 INFO:     Epoch: 89
2023-01-05 13:46:35,514 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4801118910312653, 'Total loss': 0.4801118910312653} | train loss {'Reaction outcome loss': 0.25225542618954266, 'Total loss': 0.25225542618954266}
2023-01-05 13:46:35,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:35,514 INFO:     Epoch: 90
2023-01-05 13:46:37,711 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4402249972025553, 'Total loss': 0.4402249972025553} | train loss {'Reaction outcome loss': 0.26039519354048435, 'Total loss': 0.26039519354048435}
2023-01-05 13:46:37,711 INFO:     Found new best model at epoch 90
2023-01-05 13:46:37,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:37,712 INFO:     Epoch: 91
2023-01-05 13:46:39,873 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4802183787027995, 'Total loss': 0.4802183787027995} | train loss {'Reaction outcome loss': 0.25984667031515907, 'Total loss': 0.25984667031515907}
2023-01-05 13:46:39,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:39,874 INFO:     Epoch: 92
2023-01-05 13:46:42,013 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5043002863725027, 'Total loss': 0.5043002863725027} | train loss {'Reaction outcome loss': 0.25331380413369325, 'Total loss': 0.25331380413369325}
2023-01-05 13:46:42,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:42,013 INFO:     Epoch: 93
2023-01-05 13:46:44,174 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4595292826493581, 'Total loss': 0.4595292826493581} | train loss {'Reaction outcome loss': 0.252829074356569, 'Total loss': 0.252829074356569}
2023-01-05 13:46:44,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:44,174 INFO:     Epoch: 94
2023-01-05 13:46:46,320 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4834162612756093, 'Total loss': 0.4834162612756093} | train loss {'Reaction outcome loss': 0.2600730119721733, 'Total loss': 0.2600730119721733}
2023-01-05 13:46:46,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:46,320 INFO:     Epoch: 95
2023-01-05 13:46:48,463 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5003622988859813, 'Total loss': 0.5003622988859813} | train loss {'Reaction outcome loss': 0.2536514908564787, 'Total loss': 0.2536514908564787}
2023-01-05 13:46:48,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:48,463 INFO:     Epoch: 96
2023-01-05 13:46:50,585 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5016745994488399, 'Total loss': 0.5016745994488399} | train loss {'Reaction outcome loss': 0.2500513442893968, 'Total loss': 0.2500513442893968}
2023-01-05 13:46:50,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:50,586 INFO:     Epoch: 97
2023-01-05 13:46:52,708 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5033364584048589, 'Total loss': 0.5033364584048589} | train loss {'Reaction outcome loss': 0.24752480158731885, 'Total loss': 0.24752480158731885}
2023-01-05 13:46:52,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:52,708 INFO:     Epoch: 98
2023-01-05 13:46:54,820 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.468031857162714, 'Total loss': 0.468031857162714} | train loss {'Reaction outcome loss': 0.25538231832158825, 'Total loss': 0.25538231832158825}
2023-01-05 13:46:54,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:54,820 INFO:     Epoch: 99
2023-01-05 13:46:56,929 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4454246759414673, 'Total loss': 0.4454246759414673} | train loss {'Reaction outcome loss': 0.2507137556145661, 'Total loss': 0.2507137556145661}
2023-01-05 13:46:56,930 INFO:     Best model found after epoch 91 of 100.
2023-01-05 13:46:56,930 INFO:   Done with stage: TRAINING
2023-01-05 13:46:56,930 INFO:   Starting stage: EVALUATION
2023-01-05 13:46:57,070 INFO:   Done with stage: EVALUATION
2023-01-05 13:46:57,070 INFO:   Leaving out SEQ value Fold_2
2023-01-05 13:46:57,083 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 13:46:57,083 INFO:   Starting stage: FEATURE SCALING
2023-01-05 13:46:57,725 INFO:   Done with stage: FEATURE SCALING
2023-01-05 13:46:57,725 INFO:   Starting stage: SCALING TARGETS
2023-01-05 13:46:57,793 INFO:   Done with stage: SCALING TARGETS
2023-01-05 13:46:57,793 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:46:57,793 INFO:     No hyperparam tuning for this model
2023-01-05 13:46:57,793 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:46:57,793 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 13:46:57,794 INFO:     None feature selector for col prot
2023-01-05 13:46:57,794 INFO:     None feature selector for col prot
2023-01-05 13:46:57,794 INFO:     None feature selector for col prot
2023-01-05 13:46:57,794 INFO:     None feature selector for col chem
2023-01-05 13:46:57,795 INFO:     None feature selector for col chem
2023-01-05 13:46:57,795 INFO:     None feature selector for col chem
2023-01-05 13:46:57,795 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 13:46:57,795 INFO:   Starting stage: BUILD MODEL
2023-01-05 13:46:57,796 INFO:     Number of params in model 72901
2023-01-05 13:46:57,799 INFO:   Done with stage: BUILD MODEL
2023-01-05 13:46:57,799 INFO:   Starting stage: TRAINING
2023-01-05 13:46:57,860 INFO:     Val loss before train {'Reaction outcome loss': 0.8631513079007467, 'Total loss': 0.8631513079007467}
2023-01-05 13:46:57,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:57,860 INFO:     Epoch: 0
2023-01-05 13:46:59,976 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6957241912682851, 'Total loss': 0.6957241912682851} | train loss {'Reaction outcome loss': 0.9499079413684733, 'Total loss': 0.9499079413684733}
2023-01-05 13:46:59,976 INFO:     Found new best model at epoch 0
2023-01-05 13:46:59,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:46:59,978 INFO:     Epoch: 1
2023-01-05 13:47:02,086 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5515025039513906, 'Total loss': 0.5515025039513906} | train loss {'Reaction outcome loss': 0.7783590083593851, 'Total loss': 0.7783590083593851}
2023-01-05 13:47:02,086 INFO:     Found new best model at epoch 1
2023-01-05 13:47:02,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:02,088 INFO:     Epoch: 2
2023-01-05 13:47:04,214 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.546286412080129, 'Total loss': 0.546286412080129} | train loss {'Reaction outcome loss': 0.6193167047622876, 'Total loss': 0.6193167047622876}
2023-01-05 13:47:04,214 INFO:     Found new best model at epoch 2
2023-01-05 13:47:04,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:04,215 INFO:     Epoch: 3
2023-01-05 13:47:06,330 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5204137007395426, 'Total loss': 0.5204137007395426} | train loss {'Reaction outcome loss': 0.5513293452206112, 'Total loss': 0.5513293452206112}
2023-01-05 13:47:06,330 INFO:     Found new best model at epoch 3
2023-01-05 13:47:06,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:06,331 INFO:     Epoch: 4
2023-01-05 13:47:08,450 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5096971054871877, 'Total loss': 0.5096971054871877} | train loss {'Reaction outcome loss': 0.5264253098340261, 'Total loss': 0.5264253098340261}
2023-01-05 13:47:08,450 INFO:     Found new best model at epoch 4
2023-01-05 13:47:08,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:08,451 INFO:     Epoch: 5
2023-01-05 13:47:10,581 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49974324107170104, 'Total loss': 0.49974324107170104} | train loss {'Reaction outcome loss': 0.508004958485509, 'Total loss': 0.508004958485509}
2023-01-05 13:47:10,582 INFO:     Found new best model at epoch 5
2023-01-05 13:47:10,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:10,583 INFO:     Epoch: 6
2023-01-05 13:47:12,705 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5047093143065771, 'Total loss': 0.5047093143065771} | train loss {'Reaction outcome loss': 0.4944801998662425, 'Total loss': 0.4944801998662425}
2023-01-05 13:47:12,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:12,705 INFO:     Epoch: 7
2023-01-05 13:47:14,828 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5123353699843088, 'Total loss': 0.5123353699843088} | train loss {'Reaction outcome loss': 0.4904758536935726, 'Total loss': 0.4904758536935726}
2023-01-05 13:47:14,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:14,828 INFO:     Epoch: 8
2023-01-05 13:47:16,978 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5113651553789774, 'Total loss': 0.5113651553789774} | train loss {'Reaction outcome loss': 0.47907255087798334, 'Total loss': 0.47907255087798334}
2023-01-05 13:47:16,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:16,978 INFO:     Epoch: 9
2023-01-05 13:47:19,136 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47747882505257927, 'Total loss': 0.47747882505257927} | train loss {'Reaction outcome loss': 0.48029620017542507, 'Total loss': 0.48029620017542507}
2023-01-05 13:47:19,137 INFO:     Found new best model at epoch 9
2023-01-05 13:47:19,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:19,138 INFO:     Epoch: 10
2023-01-05 13:47:21,294 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5425383845965067, 'Total loss': 0.5425383845965067} | train loss {'Reaction outcome loss': 0.46673028760558954, 'Total loss': 0.46673028760558954}
2023-01-05 13:47:21,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:21,295 INFO:     Epoch: 11
2023-01-05 13:47:23,435 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.495774785677592, 'Total loss': 0.495774785677592} | train loss {'Reaction outcome loss': 0.4679684742684766, 'Total loss': 0.4679684742684766}
2023-01-05 13:47:23,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:23,435 INFO:     Epoch: 12
2023-01-05 13:47:25,568 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48597558637460075, 'Total loss': 0.48597558637460075} | train loss {'Reaction outcome loss': 0.45954705450015193, 'Total loss': 0.45954705450015193}
2023-01-05 13:47:25,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:25,570 INFO:     Epoch: 13
2023-01-05 13:47:27,695 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49628198742866514, 'Total loss': 0.49628198742866514} | train loss {'Reaction outcome loss': 0.45391126904950474, 'Total loss': 0.45391126904950474}
2023-01-05 13:47:27,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:27,695 INFO:     Epoch: 14
2023-01-05 13:47:29,824 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4981930762529373, 'Total loss': 0.4981930762529373} | train loss {'Reaction outcome loss': 0.45138173023641326, 'Total loss': 0.45138173023641326}
2023-01-05 13:47:29,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:29,824 INFO:     Epoch: 15
2023-01-05 13:47:31,933 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48517376085122427, 'Total loss': 0.48517376085122427} | train loss {'Reaction outcome loss': 0.44908944962225555, 'Total loss': 0.44908944962225555}
2023-01-05 13:47:31,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:31,934 INFO:     Epoch: 16
2023-01-05 13:47:34,079 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49309778412183125, 'Total loss': 0.49309778412183125} | train loss {'Reaction outcome loss': 0.44300681935288966, 'Total loss': 0.44300681935288966}
2023-01-05 13:47:34,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:34,079 INFO:     Epoch: 17
2023-01-05 13:47:36,186 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49004544417063395, 'Total loss': 0.49004544417063395} | train loss {'Reaction outcome loss': 0.4398254334053277, 'Total loss': 0.4398254334053277}
2023-01-05 13:47:36,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:36,187 INFO:     Epoch: 18
2023-01-05 13:47:38,303 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48641344904899597, 'Total loss': 0.48641344904899597} | train loss {'Reaction outcome loss': 0.43688986283955555, 'Total loss': 0.43688986283955555}
2023-01-05 13:47:38,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:38,304 INFO:     Epoch: 19
2023-01-05 13:47:40,420 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5048038303852082, 'Total loss': 0.5048038303852082} | train loss {'Reaction outcome loss': 0.4284241328309307, 'Total loss': 0.4284241328309307}
2023-01-05 13:47:40,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:40,420 INFO:     Epoch: 20
2023-01-05 13:47:42,535 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.517543375492096, 'Total loss': 0.517543375492096} | train loss {'Reaction outcome loss': 0.43134543013114196, 'Total loss': 0.43134543013114196}
2023-01-05 13:47:42,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:42,535 INFO:     Epoch: 21
2023-01-05 13:47:44,664 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4500114214917024, 'Total loss': 0.4500114214917024} | train loss {'Reaction outcome loss': 0.4253737515473104, 'Total loss': 0.4253737515473104}
2023-01-05 13:47:44,665 INFO:     Found new best model at epoch 21
2023-01-05 13:47:44,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:44,666 INFO:     Epoch: 22
2023-01-05 13:47:46,772 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49969126482804616, 'Total loss': 0.49969126482804616} | train loss {'Reaction outcome loss': 0.42407572384064013, 'Total loss': 0.42407572384064013}
2023-01-05 13:47:46,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:46,772 INFO:     Epoch: 23
2023-01-05 13:47:48,887 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46527819832166034, 'Total loss': 0.46527819832166034} | train loss {'Reaction outcome loss': 0.41310691882620804, 'Total loss': 0.41310691882620804}
2023-01-05 13:47:48,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:48,887 INFO:     Epoch: 24
2023-01-05 13:47:51,001 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47619887193044025, 'Total loss': 0.47619887193044025} | train loss {'Reaction outcome loss': 0.41287717324145984, 'Total loss': 0.41287717324145984}
2023-01-05 13:47:51,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:51,001 INFO:     Epoch: 25
2023-01-05 13:47:53,109 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47838502128918964, 'Total loss': 0.47838502128918964} | train loss {'Reaction outcome loss': 0.4170459301071071, 'Total loss': 0.4170459301071071}
2023-01-05 13:47:53,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:53,109 INFO:     Epoch: 26
2023-01-05 13:47:55,225 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5069245815277099, 'Total loss': 0.5069245815277099} | train loss {'Reaction outcome loss': 0.40772406328401284, 'Total loss': 0.40772406328401284}
2023-01-05 13:47:55,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:55,225 INFO:     Epoch: 27
2023-01-05 13:47:57,354 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.516339389483134, 'Total loss': 0.516339389483134} | train loss {'Reaction outcome loss': 0.4094614077755165, 'Total loss': 0.4094614077755165}
2023-01-05 13:47:57,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:57,354 INFO:     Epoch: 28
2023-01-05 13:47:59,481 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4424577241142591, 'Total loss': 0.4424577241142591} | train loss {'Reaction outcome loss': 0.40234310384635086, 'Total loss': 0.40234310384635086}
2023-01-05 13:47:59,481 INFO:     Found new best model at epoch 28
2023-01-05 13:47:59,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:47:59,482 INFO:     Epoch: 29
2023-01-05 13:48:01,606 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4665281514326731, 'Total loss': 0.4665281514326731} | train loss {'Reaction outcome loss': 0.4032012550603776, 'Total loss': 0.4032012550603776}
2023-01-05 13:48:01,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:01,608 INFO:     Epoch: 30
2023-01-05 13:48:03,731 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45306978225708006, 'Total loss': 0.45306978225708006} | train loss {'Reaction outcome loss': 0.3966521612290061, 'Total loss': 0.3966521612290061}
2023-01-05 13:48:03,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:03,731 INFO:     Epoch: 31
2023-01-05 13:48:05,855 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47822503248850506, 'Total loss': 0.47822503248850506} | train loss {'Reaction outcome loss': 0.3950627725912538, 'Total loss': 0.3950627725912538}
2023-01-05 13:48:05,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:05,855 INFO:     Epoch: 32
2023-01-05 13:48:07,964 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4462909718354543, 'Total loss': 0.4462909718354543} | train loss {'Reaction outcome loss': 0.39016668018185613, 'Total loss': 0.39016668018185613}
2023-01-05 13:48:07,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:07,965 INFO:     Epoch: 33
2023-01-05 13:48:10,077 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48651109635829926, 'Total loss': 0.48651109635829926} | train loss {'Reaction outcome loss': 0.38924729302798433, 'Total loss': 0.38924729302798433}
2023-01-05 13:48:10,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:10,078 INFO:     Epoch: 34
2023-01-05 13:48:12,194 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.462362880508105, 'Total loss': 0.462362880508105} | train loss {'Reaction outcome loss': 0.38839278683994277, 'Total loss': 0.38839278683994277}
2023-01-05 13:48:12,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:12,194 INFO:     Epoch: 35
2023-01-05 13:48:14,428 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46213623185952507, 'Total loss': 0.46213623185952507} | train loss {'Reaction outcome loss': 0.38500291234626, 'Total loss': 0.38500291234626}
2023-01-05 13:48:14,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:14,428 INFO:     Epoch: 36
2023-01-05 13:48:16,652 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44352151652177174, 'Total loss': 0.44352151652177174} | train loss {'Reaction outcome loss': 0.38149770354722445, 'Total loss': 0.38149770354722445}
2023-01-05 13:48:16,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:16,652 INFO:     Epoch: 37
2023-01-05 13:48:18,860 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46656307379404705, 'Total loss': 0.46656307379404705} | train loss {'Reaction outcome loss': 0.38222082600597934, 'Total loss': 0.38222082600597934}
2023-01-05 13:48:18,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:18,860 INFO:     Epoch: 38
2023-01-05 13:48:21,050 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4831298371156057, 'Total loss': 0.4831298371156057} | train loss {'Reaction outcome loss': 0.3747083044341414, 'Total loss': 0.3747083044341414}
2023-01-05 13:48:21,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:21,051 INFO:     Epoch: 39
2023-01-05 13:48:23,166 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4542282442251841, 'Total loss': 0.4542282442251841} | train loss {'Reaction outcome loss': 0.37590226449154235, 'Total loss': 0.37590226449154235}
2023-01-05 13:48:23,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:23,166 INFO:     Epoch: 40
2023-01-05 13:48:25,311 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4514682779709498, 'Total loss': 0.4514682779709498} | train loss {'Reaction outcome loss': 0.37287398946263417, 'Total loss': 0.37287398946263417}
2023-01-05 13:48:25,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:25,311 INFO:     Epoch: 41
2023-01-05 13:48:27,434 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4489149769147237, 'Total loss': 0.4489149769147237} | train loss {'Reaction outcome loss': 0.3666132106121643, 'Total loss': 0.3666132106121643}
2023-01-05 13:48:27,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:27,434 INFO:     Epoch: 42
2023-01-05 13:48:29,552 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4632687826951345, 'Total loss': 0.4632687826951345} | train loss {'Reaction outcome loss': 0.3636505978912006, 'Total loss': 0.3636505978912006}
2023-01-05 13:48:29,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:29,552 INFO:     Epoch: 43
2023-01-05 13:48:31,684 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.483674082159996, 'Total loss': 0.483674082159996} | train loss {'Reaction outcome loss': 0.36096864626248243, 'Total loss': 0.36096864626248243}
2023-01-05 13:48:31,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:31,684 INFO:     Epoch: 44
2023-01-05 13:48:33,803 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44003537595272063, 'Total loss': 0.44003537595272063} | train loss {'Reaction outcome loss': 0.3584879781955328, 'Total loss': 0.3584879781955328}
2023-01-05 13:48:33,803 INFO:     Found new best model at epoch 44
2023-01-05 13:48:33,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:33,805 INFO:     Epoch: 45
2023-01-05 13:48:35,923 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4210052082935969, 'Total loss': 0.4210052082935969} | train loss {'Reaction outcome loss': 0.355089800289044, 'Total loss': 0.355089800289044}
2023-01-05 13:48:35,923 INFO:     Found new best model at epoch 45
2023-01-05 13:48:35,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:35,924 INFO:     Epoch: 46
2023-01-05 13:48:38,048 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4410467306772868, 'Total loss': 0.4410467306772868} | train loss {'Reaction outcome loss': 0.3533922348703657, 'Total loss': 0.3533922348703657}
2023-01-05 13:48:38,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:38,049 INFO:     Epoch: 47
2023-01-05 13:48:40,177 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43727312684059144, 'Total loss': 0.43727312684059144} | train loss {'Reaction outcome loss': 0.35496202755323697, 'Total loss': 0.35496202755323697}
2023-01-05 13:48:40,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:40,177 INFO:     Epoch: 48
2023-01-05 13:48:42,281 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4345234513282776, 'Total loss': 0.4345234513282776} | train loss {'Reaction outcome loss': 0.35203575181873725, 'Total loss': 0.35203575181873725}
2023-01-05 13:48:42,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:42,281 INFO:     Epoch: 49
2023-01-05 13:48:44,403 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4310160112877687, 'Total loss': 0.4310160112877687} | train loss {'Reaction outcome loss': 0.3445569387988457, 'Total loss': 0.3445569387988457}
2023-01-05 13:48:44,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:44,404 INFO:     Epoch: 50
2023-01-05 13:48:46,527 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42114441891511284, 'Total loss': 0.42114441891511284} | train loss {'Reaction outcome loss': 0.33786268506349226, 'Total loss': 0.33786268506349226}
2023-01-05 13:48:46,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:46,528 INFO:     Epoch: 51
2023-01-05 13:48:48,643 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4304027646780014, 'Total loss': 0.4304027646780014} | train loss {'Reaction outcome loss': 0.34530662641529636, 'Total loss': 0.34530662641529636}
2023-01-05 13:48:48,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:48,643 INFO:     Epoch: 52
2023-01-05 13:48:50,767 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4394998570283254, 'Total loss': 0.4394998570283254} | train loss {'Reaction outcome loss': 0.33724520427785515, 'Total loss': 0.33724520427785515}
2023-01-05 13:48:50,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:50,768 INFO:     Epoch: 53
2023-01-05 13:48:52,877 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42979012727737426, 'Total loss': 0.42979012727737426} | train loss {'Reaction outcome loss': 0.3293209092029722, 'Total loss': 0.3293209092029722}
2023-01-05 13:48:52,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:52,878 INFO:     Epoch: 54
2023-01-05 13:48:54,988 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4668428435921669, 'Total loss': 0.4668428435921669} | train loss {'Reaction outcome loss': 0.339899765648248, 'Total loss': 0.339899765648248}
2023-01-05 13:48:54,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:54,988 INFO:     Epoch: 55
2023-01-05 13:48:57,099 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4609984755516052, 'Total loss': 0.4609984755516052} | train loss {'Reaction outcome loss': 0.3295867221477704, 'Total loss': 0.3295867221477704}
2023-01-05 13:48:57,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:57,100 INFO:     Epoch: 56
2023-01-05 13:48:59,205 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40988573705156645, 'Total loss': 0.40988573705156645} | train loss {'Reaction outcome loss': 0.3354386487914311, 'Total loss': 0.3354386487914311}
2023-01-05 13:48:59,205 INFO:     Found new best model at epoch 56
2023-01-05 13:48:59,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:48:59,207 INFO:     Epoch: 57
2023-01-05 13:49:01,329 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4396152635415395, 'Total loss': 0.4396152635415395} | train loss {'Reaction outcome loss': 0.3215197562052435, 'Total loss': 0.3215197562052435}
2023-01-05 13:49:01,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:01,329 INFO:     Epoch: 58
2023-01-05 13:49:03,438 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.448456734418869, 'Total loss': 0.448456734418869} | train loss {'Reaction outcome loss': 0.3247177348823556, 'Total loss': 0.3247177348823556}
2023-01-05 13:49:03,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:03,439 INFO:     Epoch: 59
2023-01-05 13:49:05,558 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47730201681454976, 'Total loss': 0.47730201681454976} | train loss {'Reaction outcome loss': 0.32291823156150706, 'Total loss': 0.32291823156150706}
2023-01-05 13:49:05,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:05,558 INFO:     Epoch: 60
2023-01-05 13:49:07,672 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42285784681638083, 'Total loss': 0.42285784681638083} | train loss {'Reaction outcome loss': 0.3130774653547413, 'Total loss': 0.3130774653547413}
2023-01-05 13:49:07,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:07,672 INFO:     Epoch: 61
2023-01-05 13:49:09,787 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4506288965543111, 'Total loss': 0.4506288965543111} | train loss {'Reaction outcome loss': 0.30976805264205287, 'Total loss': 0.30976805264205287}
2023-01-05 13:49:09,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:09,787 INFO:     Epoch: 62
2023-01-05 13:49:11,911 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4433963745832443, 'Total loss': 0.4433963745832443} | train loss {'Reaction outcome loss': 0.3123931063564269, 'Total loss': 0.3123931063564269}
2023-01-05 13:49:11,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:11,912 INFO:     Epoch: 63
2023-01-05 13:49:14,026 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45664354264736173, 'Total loss': 0.45664354264736173} | train loss {'Reaction outcome loss': 0.30970539229038435, 'Total loss': 0.30970539229038435}
2023-01-05 13:49:14,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:14,027 INFO:     Epoch: 64
2023-01-05 13:49:16,145 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4103946665922801, 'Total loss': 0.4103946665922801} | train loss {'Reaction outcome loss': 0.30994117744403443, 'Total loss': 0.30994117744403443}
2023-01-05 13:49:16,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:16,145 INFO:     Epoch: 65
2023-01-05 13:49:18,252 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42761431137720746, 'Total loss': 0.42761431137720746} | train loss {'Reaction outcome loss': 0.30462756570626476, 'Total loss': 0.30462756570626476}
2023-01-05 13:49:18,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:18,252 INFO:     Epoch: 66
2023-01-05 13:49:20,339 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40102730840444567, 'Total loss': 0.40102730840444567} | train loss {'Reaction outcome loss': 0.30279383604370413, 'Total loss': 0.30279383604370413}
2023-01-05 13:49:20,339 INFO:     Found new best model at epoch 66
2023-01-05 13:49:20,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:20,341 INFO:     Epoch: 67
2023-01-05 13:49:22,281 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43522440989812217, 'Total loss': 0.43522440989812217} | train loss {'Reaction outcome loss': 0.3016593575259268, 'Total loss': 0.3016593575259268}
2023-01-05 13:49:22,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:22,282 INFO:     Epoch: 68
2023-01-05 13:49:24,389 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4320614804824193, 'Total loss': 0.4320614804824193} | train loss {'Reaction outcome loss': 0.31036268109148674, 'Total loss': 0.31036268109148674}
2023-01-05 13:49:24,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:24,389 INFO:     Epoch: 69
2023-01-05 13:49:26,506 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43847154776255287, 'Total loss': 0.43847154776255287} | train loss {'Reaction outcome loss': 0.2946541912362471, 'Total loss': 0.2946541912362471}
2023-01-05 13:49:26,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:26,506 INFO:     Epoch: 70
2023-01-05 13:49:28,604 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4320358355840047, 'Total loss': 0.4320358355840047} | train loss {'Reaction outcome loss': 0.29634200594636984, 'Total loss': 0.29634200594636984}
2023-01-05 13:49:28,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:28,604 INFO:     Epoch: 71
2023-01-05 13:49:30,721 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44850080808003745, 'Total loss': 0.44850080808003745} | train loss {'Reaction outcome loss': 0.29616778326176463, 'Total loss': 0.29616778326176463}
2023-01-05 13:49:30,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:30,721 INFO:     Epoch: 72
2023-01-05 13:49:32,844 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4216844995816549, 'Total loss': 0.4216844995816549} | train loss {'Reaction outcome loss': 0.29453789456423385, 'Total loss': 0.29453789456423385}
2023-01-05 13:49:32,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:32,844 INFO:     Epoch: 73
2023-01-05 13:49:34,984 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4106921046972275, 'Total loss': 0.4106921046972275} | train loss {'Reaction outcome loss': 0.29088020679496585, 'Total loss': 0.29088020679496585}
2023-01-05 13:49:34,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:34,984 INFO:     Epoch: 74
2023-01-05 13:49:37,115 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44276839395364126, 'Total loss': 0.44276839395364126} | train loss {'Reaction outcome loss': 0.29250088908569716, 'Total loss': 0.29250088908569716}
2023-01-05 13:49:37,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:37,116 INFO:     Epoch: 75
2023-01-05 13:49:39,222 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43184595356384914, 'Total loss': 0.43184595356384914} | train loss {'Reaction outcome loss': 0.2921313339018778, 'Total loss': 0.2921313339018778}
2023-01-05 13:49:39,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:39,222 INFO:     Epoch: 76
2023-01-05 13:49:41,322 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41640260151276987, 'Total loss': 0.41640260151276987} | train loss {'Reaction outcome loss': 0.28800814990431833, 'Total loss': 0.28800814990431833}
2023-01-05 13:49:41,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:41,322 INFO:     Epoch: 77
2023-01-05 13:49:43,449 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4828278879324595, 'Total loss': 0.4828278879324595} | train loss {'Reaction outcome loss': 0.2858380784720674, 'Total loss': 0.2858380784720674}
2023-01-05 13:49:43,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:43,450 INFO:     Epoch: 78
2023-01-05 13:49:45,568 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4379212111234665, 'Total loss': 0.4379212111234665} | train loss {'Reaction outcome loss': 0.2842409611294121, 'Total loss': 0.2842409611294121}
2023-01-05 13:49:45,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:45,568 INFO:     Epoch: 79
2023-01-05 13:49:47,691 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3994705428679784, 'Total loss': 0.3994705428679784} | train loss {'Reaction outcome loss': 0.2797250088863757, 'Total loss': 0.2797250088863757}
2023-01-05 13:49:47,692 INFO:     Found new best model at epoch 79
2023-01-05 13:49:47,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:47,693 INFO:     Epoch: 80
2023-01-05 13:49:49,811 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43539782563845314, 'Total loss': 0.43539782563845314} | train loss {'Reaction outcome loss': 0.2778193540734686, 'Total loss': 0.2778193540734686}
2023-01-05 13:49:49,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:49,813 INFO:     Epoch: 81
2023-01-05 13:49:51,925 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42371111710866294, 'Total loss': 0.42371111710866294} | train loss {'Reaction outcome loss': 0.2738764747813508, 'Total loss': 0.2738764747813508}
2023-01-05 13:49:51,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:51,926 INFO:     Epoch: 82
2023-01-05 13:49:54,036 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44349744319915774, 'Total loss': 0.44349744319915774} | train loss {'Reaction outcome loss': 0.277651875133152, 'Total loss': 0.277651875133152}
2023-01-05 13:49:54,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:54,037 INFO:     Epoch: 83
2023-01-05 13:49:56,157 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4557270646095276, 'Total loss': 0.4557270646095276} | train loss {'Reaction outcome loss': 0.27965398184654916, 'Total loss': 0.27965398184654916}
2023-01-05 13:49:56,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:56,158 INFO:     Epoch: 84
2023-01-05 13:49:58,274 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4780577182769775, 'Total loss': 0.4780577182769775} | train loss {'Reaction outcome loss': 0.26713223406710684, 'Total loss': 0.26713223406710684}
2023-01-05 13:49:58,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:49:58,274 INFO:     Epoch: 85
2023-01-05 13:50:00,398 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4574888269106547, 'Total loss': 0.4574888269106547} | train loss {'Reaction outcome loss': 0.2750469552465602, 'Total loss': 0.2750469552465602}
2023-01-05 13:50:00,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:00,398 INFO:     Epoch: 86
2023-01-05 13:50:02,529 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4324887509147326, 'Total loss': 0.4324887509147326} | train loss {'Reaction outcome loss': 0.2717312267425405, 'Total loss': 0.2717312267425405}
2023-01-05 13:50:02,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:02,529 INFO:     Epoch: 87
2023-01-05 13:50:04,641 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4350467751423518, 'Total loss': 0.4350467751423518} | train loss {'Reaction outcome loss': 0.26524980763321393, 'Total loss': 0.26524980763321393}
2023-01-05 13:50:04,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:04,641 INFO:     Epoch: 88
2023-01-05 13:50:06,777 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48180688718954723, 'Total loss': 0.48180688718954723} | train loss {'Reaction outcome loss': 0.26818692495862206, 'Total loss': 0.26818692495862206}
2023-01-05 13:50:06,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:06,777 INFO:     Epoch: 89
2023-01-05 13:50:08,913 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4110129843155543, 'Total loss': 0.4110129843155543} | train loss {'Reaction outcome loss': 0.2603626127863105, 'Total loss': 0.2603626127863105}
2023-01-05 13:50:08,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:08,914 INFO:     Epoch: 90
2023-01-05 13:50:11,042 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4328267157077789, 'Total loss': 0.4328267157077789} | train loss {'Reaction outcome loss': 0.2665158672729036, 'Total loss': 0.2665158672729036}
2023-01-05 13:50:11,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:11,042 INFO:     Epoch: 91
2023-01-05 13:50:13,171 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4111480366128186, 'Total loss': 0.4111480366128186} | train loss {'Reaction outcome loss': 0.26524545839090485, 'Total loss': 0.26524545839090485}
2023-01-05 13:50:13,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:13,171 INFO:     Epoch: 92
2023-01-05 13:50:15,283 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46059847474098203, 'Total loss': 0.46059847474098203} | train loss {'Reaction outcome loss': 0.2696937630942344, 'Total loss': 0.2696937630942344}
2023-01-05 13:50:15,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:15,284 INFO:     Epoch: 93
2023-01-05 13:50:17,404 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39574968566497165, 'Total loss': 0.39574968566497165} | train loss {'Reaction outcome loss': 0.26338149453666837, 'Total loss': 0.26338149453666837}
2023-01-05 13:50:17,404 INFO:     Found new best model at epoch 93
2023-01-05 13:50:17,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:17,405 INFO:     Epoch: 94
2023-01-05 13:50:19,521 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4407572507858276, 'Total loss': 0.4407572507858276} | train loss {'Reaction outcome loss': 0.26231562493423566, 'Total loss': 0.26231562493423566}
2023-01-05 13:50:19,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:19,521 INFO:     Epoch: 95
2023-01-05 13:50:21,624 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42126466035842897, 'Total loss': 0.42126466035842897} | train loss {'Reaction outcome loss': 0.26284011636925486, 'Total loss': 0.26284011636925486}
2023-01-05 13:50:21,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:21,624 INFO:     Epoch: 96
2023-01-05 13:50:23,749 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42035366718967754, 'Total loss': 0.42035366718967754} | train loss {'Reaction outcome loss': 0.25833777619368864, 'Total loss': 0.25833777619368864}
2023-01-05 13:50:23,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:23,749 INFO:     Epoch: 97
2023-01-05 13:50:25,863 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4521907567977905, 'Total loss': 0.4521907567977905} | train loss {'Reaction outcome loss': 0.2608809034739222, 'Total loss': 0.2608809034739222}
2023-01-05 13:50:25,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:25,864 INFO:     Epoch: 98
2023-01-05 13:50:27,971 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4830740958452225, 'Total loss': 0.4830740958452225} | train loss {'Reaction outcome loss': 0.26163865399338826, 'Total loss': 0.26163865399338826}
2023-01-05 13:50:27,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:27,971 INFO:     Epoch: 99
2023-01-05 13:50:30,102 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42966839820146563, 'Total loss': 0.42966839820146563} | train loss {'Reaction outcome loss': 0.2589258711935181, 'Total loss': 0.2589258711935181}
2023-01-05 13:50:30,103 INFO:     Best model found after epoch 94 of 100.
2023-01-05 13:50:30,103 INFO:   Done with stage: TRAINING
2023-01-05 13:50:30,103 INFO:   Starting stage: EVALUATION
2023-01-05 13:50:30,247 INFO:   Done with stage: EVALUATION
2023-01-05 13:50:30,247 INFO:   Leaving out SEQ value Fold_3
2023-01-05 13:50:30,259 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 13:50:30,260 INFO:   Starting stage: FEATURE SCALING
2023-01-05 13:50:30,898 INFO:   Done with stage: FEATURE SCALING
2023-01-05 13:50:30,898 INFO:   Starting stage: SCALING TARGETS
2023-01-05 13:50:30,965 INFO:   Done with stage: SCALING TARGETS
2023-01-05 13:50:30,965 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:50:30,966 INFO:     No hyperparam tuning for this model
2023-01-05 13:50:30,966 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:50:30,966 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 13:50:30,966 INFO:     None feature selector for col prot
2023-01-05 13:50:30,967 INFO:     None feature selector for col prot
2023-01-05 13:50:30,967 INFO:     None feature selector for col prot
2023-01-05 13:50:30,967 INFO:     None feature selector for col chem
2023-01-05 13:50:30,967 INFO:     None feature selector for col chem
2023-01-05 13:50:30,967 INFO:     None feature selector for col chem
2023-01-05 13:50:30,967 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 13:50:30,967 INFO:   Starting stage: BUILD MODEL
2023-01-05 13:50:30,969 INFO:     Number of params in model 72901
2023-01-05 13:50:30,972 INFO:   Done with stage: BUILD MODEL
2023-01-05 13:50:30,972 INFO:   Starting stage: TRAINING
2023-01-05 13:50:31,031 INFO:     Val loss before train {'Reaction outcome loss': 1.098927585283915, 'Total loss': 1.098927585283915}
2023-01-05 13:50:31,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:31,032 INFO:     Epoch: 0
2023-01-05 13:50:33,132 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8806687235832215, 'Total loss': 0.8806687235832215} | train loss {'Reaction outcome loss': 0.940031967429451, 'Total loss': 0.940031967429451}
2023-01-05 13:50:33,133 INFO:     Found new best model at epoch 0
2023-01-05 13:50:33,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:33,134 INFO:     Epoch: 1
2023-01-05 13:50:35,236 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6590549111366272, 'Total loss': 0.6590549111366272} | train loss {'Reaction outcome loss': 0.7503806589505612, 'Total loss': 0.7503806589505612}
2023-01-05 13:50:35,236 INFO:     Found new best model at epoch 1
2023-01-05 13:50:35,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:35,238 INFO:     Epoch: 2
2023-01-05 13:50:37,351 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5775143524010976, 'Total loss': 0.5775143524010976} | train loss {'Reaction outcome loss': 0.589310966022722, 'Total loss': 0.589310966022722}
2023-01-05 13:50:37,351 INFO:     Found new best model at epoch 2
2023-01-05 13:50:37,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:37,352 INFO:     Epoch: 3
2023-01-05 13:50:39,456 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.557260525226593, 'Total loss': 0.557260525226593} | train loss {'Reaction outcome loss': 0.5262134774918958, 'Total loss': 0.5262134774918958}
2023-01-05 13:50:39,456 INFO:     Found new best model at epoch 3
2023-01-05 13:50:39,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:39,457 INFO:     Epoch: 4
2023-01-05 13:50:41,558 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5122383991877238, 'Total loss': 0.5122383991877238} | train loss {'Reaction outcome loss': 0.5000107728845471, 'Total loss': 0.5000107728845471}
2023-01-05 13:50:41,559 INFO:     Found new best model at epoch 4
2023-01-05 13:50:41,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:41,560 INFO:     Epoch: 5
2023-01-05 13:50:43,675 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5510683079560598, 'Total loss': 0.5510683079560598} | train loss {'Reaction outcome loss': 0.48684391196503307, 'Total loss': 0.48684391196503307}
2023-01-05 13:50:43,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:43,675 INFO:     Epoch: 6
2023-01-05 13:50:45,767 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5111635307470958, 'Total loss': 0.5111635307470958} | train loss {'Reaction outcome loss': 0.478506964969111, 'Total loss': 0.478506964969111}
2023-01-05 13:50:45,767 INFO:     Found new best model at epoch 6
2023-01-05 13:50:45,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:45,769 INFO:     Epoch: 7
2023-01-05 13:50:47,883 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5668807188669841, 'Total loss': 0.5668807188669841} | train loss {'Reaction outcome loss': 0.46147254480547084, 'Total loss': 0.46147254480547084}
2023-01-05 13:50:47,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:47,883 INFO:     Epoch: 8
2023-01-05 13:50:49,990 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4734739045302073, 'Total loss': 0.4734739045302073} | train loss {'Reaction outcome loss': 0.4578449368040204, 'Total loss': 0.4578449368040204}
2023-01-05 13:50:49,990 INFO:     Found new best model at epoch 8
2023-01-05 13:50:49,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:49,991 INFO:     Epoch: 9
2023-01-05 13:50:52,135 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4957906166712443, 'Total loss': 0.4957906166712443} | train loss {'Reaction outcome loss': 0.45873297357952203, 'Total loss': 0.45873297357952203}
2023-01-05 13:50:52,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:52,135 INFO:     Epoch: 10
2023-01-05 13:50:54,276 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49188616772492727, 'Total loss': 0.49188616772492727} | train loss {'Reaction outcome loss': 0.4462724969937251, 'Total loss': 0.4462724969937251}
2023-01-05 13:50:54,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:54,276 INFO:     Epoch: 11
2023-01-05 13:50:56,398 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49706430633862814, 'Total loss': 0.49706430633862814} | train loss {'Reaction outcome loss': 0.44920576775903664, 'Total loss': 0.44920576775903664}
2023-01-05 13:50:56,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:56,399 INFO:     Epoch: 12
2023-01-05 13:50:58,527 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5402084847291311, 'Total loss': 0.5402084847291311} | train loss {'Reaction outcome loss': 0.44299864763523633, 'Total loss': 0.44299864763523633}
2023-01-05 13:50:58,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:50:58,527 INFO:     Epoch: 13
2023-01-05 13:51:00,663 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4891037066777547, 'Total loss': 0.4891037066777547} | train loss {'Reaction outcome loss': 0.43779103992841184, 'Total loss': 0.43779103992841184}
2023-01-05 13:51:00,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:00,664 INFO:     Epoch: 14
2023-01-05 13:51:02,763 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47183710436026255, 'Total loss': 0.47183710436026255} | train loss {'Reaction outcome loss': 0.4340973907515352, 'Total loss': 0.4340973907515352}
2023-01-05 13:51:02,764 INFO:     Found new best model at epoch 14
2023-01-05 13:51:02,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:02,765 INFO:     Epoch: 15
2023-01-05 13:51:04,927 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47157824238141377, 'Total loss': 0.47157824238141377} | train loss {'Reaction outcome loss': 0.4290517721693594, 'Total loss': 0.4290517721693594}
2023-01-05 13:51:04,927 INFO:     Found new best model at epoch 15
2023-01-05 13:51:04,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:04,929 INFO:     Epoch: 16
2023-01-05 13:51:07,008 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4963789224624634, 'Total loss': 0.4963789224624634} | train loss {'Reaction outcome loss': 0.4251825534380399, 'Total loss': 0.4251825534380399}
2023-01-05 13:51:07,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:07,008 INFO:     Epoch: 17
2023-01-05 13:51:09,113 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4799952805042267, 'Total loss': 0.4799952805042267} | train loss {'Reaction outcome loss': 0.4193382298116719, 'Total loss': 0.4193382298116719}
2023-01-05 13:51:09,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:09,114 INFO:     Epoch: 18
2023-01-05 13:51:11,200 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4718466560045878, 'Total loss': 0.4718466560045878} | train loss {'Reaction outcome loss': 0.4223037121182942, 'Total loss': 0.4223037121182942}
2023-01-05 13:51:11,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:11,200 INFO:     Epoch: 19
2023-01-05 13:51:13,294 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46028987963994344, 'Total loss': 0.46028987963994344} | train loss {'Reaction outcome loss': 0.41102348349906587, 'Total loss': 0.41102348349906587}
2023-01-05 13:51:13,294 INFO:     Found new best model at epoch 19
2023-01-05 13:51:13,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:13,295 INFO:     Epoch: 20
2023-01-05 13:51:15,443 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46792034109433495, 'Total loss': 0.46792034109433495} | train loss {'Reaction outcome loss': 0.40883602638602695, 'Total loss': 0.40883602638602695}
2023-01-05 13:51:15,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:15,444 INFO:     Epoch: 21
2023-01-05 13:51:17,556 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4872787972291311, 'Total loss': 0.4872787972291311} | train loss {'Reaction outcome loss': 0.4076611388461057, 'Total loss': 0.4076611388461057}
2023-01-05 13:51:17,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:17,556 INFO:     Epoch: 22
2023-01-05 13:51:19,663 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49019967317581176, 'Total loss': 0.49019967317581176} | train loss {'Reaction outcome loss': 0.40519819534196083, 'Total loss': 0.40519819534196083}
2023-01-05 13:51:19,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:19,663 INFO:     Epoch: 23
2023-01-05 13:51:21,763 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4614071150620778, 'Total loss': 0.4614071150620778} | train loss {'Reaction outcome loss': 0.40567489789846617, 'Total loss': 0.40567489789846617}
2023-01-05 13:51:21,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:21,764 INFO:     Epoch: 24
2023-01-05 13:51:23,859 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4633831024169922, 'Total loss': 0.4633831024169922} | train loss {'Reaction outcome loss': 0.3956641007006687, 'Total loss': 0.3956641007006687}
2023-01-05 13:51:23,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:23,859 INFO:     Epoch: 25
2023-01-05 13:51:25,947 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4855212579170863, 'Total loss': 0.4855212579170863} | train loss {'Reaction outcome loss': 0.3931283167812414, 'Total loss': 0.3931283167812414}
2023-01-05 13:51:25,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:25,947 INFO:     Epoch: 26
2023-01-05 13:51:28,045 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4501631478468577, 'Total loss': 0.4501631478468577} | train loss {'Reaction outcome loss': 0.39479992268504677, 'Total loss': 0.39479992268504677}
2023-01-05 13:51:28,045 INFO:     Found new best model at epoch 26
2023-01-05 13:51:28,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:28,046 INFO:     Epoch: 27
2023-01-05 13:51:30,152 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4622910181681315, 'Total loss': 0.4622910181681315} | train loss {'Reaction outcome loss': 0.39624152732023715, 'Total loss': 0.39624152732023715}
2023-01-05 13:51:30,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:30,152 INFO:     Epoch: 28
2023-01-05 13:51:32,270 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4874337375164032, 'Total loss': 0.4874337375164032} | train loss {'Reaction outcome loss': 0.3853249207084432, 'Total loss': 0.3853249207084432}
2023-01-05 13:51:32,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:32,272 INFO:     Epoch: 29
2023-01-05 13:51:34,393 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4524808386961619, 'Total loss': 0.4524808386961619} | train loss {'Reaction outcome loss': 0.37616010801696076, 'Total loss': 0.37616010801696076}
2023-01-05 13:51:34,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:34,393 INFO:     Epoch: 30
2023-01-05 13:51:36,502 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46778136243422824, 'Total loss': 0.46778136243422824} | train loss {'Reaction outcome loss': 0.3781139527928534, 'Total loss': 0.3781139527928534}
2023-01-05 13:51:36,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:36,502 INFO:     Epoch: 31
2023-01-05 13:51:38,625 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4694604347149531, 'Total loss': 0.4694604347149531} | train loss {'Reaction outcome loss': 0.38114823400974274, 'Total loss': 0.38114823400974274}
2023-01-05 13:51:38,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:38,626 INFO:     Epoch: 32
2023-01-05 13:51:40,768 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47299017508824664, 'Total loss': 0.47299017508824664} | train loss {'Reaction outcome loss': 0.36988199851560943, 'Total loss': 0.36988199851560943}
2023-01-05 13:51:40,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:40,768 INFO:     Epoch: 33
2023-01-05 13:51:42,895 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44817018806934356, 'Total loss': 0.44817018806934356} | train loss {'Reaction outcome loss': 0.3733555684923689, 'Total loss': 0.3733555684923689}
2023-01-05 13:51:42,895 INFO:     Found new best model at epoch 33
2023-01-05 13:51:42,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:42,897 INFO:     Epoch: 34
2023-01-05 13:51:45,013 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4466992527246475, 'Total loss': 0.4466992527246475} | train loss {'Reaction outcome loss': 0.36685736048898415, 'Total loss': 0.36685736048898415}
2023-01-05 13:51:45,013 INFO:     Found new best model at epoch 34
2023-01-05 13:51:45,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:45,014 INFO:     Epoch: 35
2023-01-05 13:51:47,138 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46721465488274894, 'Total loss': 0.46721465488274894} | train loss {'Reaction outcome loss': 0.3672802697989967, 'Total loss': 0.3672802697989967}
2023-01-05 13:51:47,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:47,138 INFO:     Epoch: 36
2023-01-05 13:51:49,240 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4367936342954636, 'Total loss': 0.4367936342954636} | train loss {'Reaction outcome loss': 0.36334941203231774, 'Total loss': 0.36334941203231774}
2023-01-05 13:51:49,240 INFO:     Found new best model at epoch 36
2023-01-05 13:51:49,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:49,242 INFO:     Epoch: 37
2023-01-05 13:51:51,346 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.491417266925176, 'Total loss': 0.491417266925176} | train loss {'Reaction outcome loss': 0.35724518205220007, 'Total loss': 0.35724518205220007}
2023-01-05 13:51:51,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:51,347 INFO:     Epoch: 38
2023-01-05 13:51:53,434 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4373829424381256, 'Total loss': 0.4373829424381256} | train loss {'Reaction outcome loss': 0.35896736274272095, 'Total loss': 0.35896736274272095}
2023-01-05 13:51:53,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:53,434 INFO:     Epoch: 39
2023-01-05 13:51:55,549 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4705772399902344, 'Total loss': 0.4705772399902344} | train loss {'Reaction outcome loss': 0.3496985524183228, 'Total loss': 0.3496985524183228}
2023-01-05 13:51:55,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:55,549 INFO:     Epoch: 40
2023-01-05 13:51:57,671 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45139701863129933, 'Total loss': 0.45139701863129933} | train loss {'Reaction outcome loss': 0.3453935996216514, 'Total loss': 0.3453935996216514}
2023-01-05 13:51:57,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:57,671 INFO:     Epoch: 41
2023-01-05 13:51:59,780 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47687579492727916, 'Total loss': 0.47687579492727916} | train loss {'Reaction outcome loss': 0.3519329511041961, 'Total loss': 0.3519329511041961}
2023-01-05 13:51:59,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:51:59,780 INFO:     Epoch: 42
2023-01-05 13:52:01,884 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4311772629618645, 'Total loss': 0.4311772629618645} | train loss {'Reaction outcome loss': 0.3438035275637012, 'Total loss': 0.3438035275637012}
2023-01-05 13:52:01,885 INFO:     Found new best model at epoch 42
2023-01-05 13:52:01,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:01,887 INFO:     Epoch: 43
2023-01-05 13:52:03,990 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43894206086794535, 'Total loss': 0.43894206086794535} | train loss {'Reaction outcome loss': 0.3449021555183135, 'Total loss': 0.3449021555183135}
2023-01-05 13:52:03,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:03,990 INFO:     Epoch: 44
2023-01-05 13:52:06,096 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42642023861408235, 'Total loss': 0.42642023861408235} | train loss {'Reaction outcome loss': 0.35127086225119264, 'Total loss': 0.35127086225119264}
2023-01-05 13:52:06,096 INFO:     Found new best model at epoch 44
2023-01-05 13:52:06,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:06,097 INFO:     Epoch: 45
2023-01-05 13:52:08,221 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4906915366649628, 'Total loss': 0.4906915366649628} | train loss {'Reaction outcome loss': 0.3367258529878143, 'Total loss': 0.3367258529878143}
2023-01-05 13:52:08,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:08,222 INFO:     Epoch: 46
2023-01-05 13:52:10,340 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4556939919789632, 'Total loss': 0.4556939919789632} | train loss {'Reaction outcome loss': 0.32963326434867507, 'Total loss': 0.32963326434867507}
2023-01-05 13:52:10,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:10,341 INFO:     Epoch: 47
2023-01-05 13:52:12,447 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44890843828519184, 'Total loss': 0.44890843828519184} | train loss {'Reaction outcome loss': 0.33841704480322726, 'Total loss': 0.33841704480322726}
2023-01-05 13:52:12,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:12,447 INFO:     Epoch: 48
2023-01-05 13:52:14,586 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44348374009132385, 'Total loss': 0.44348374009132385} | train loss {'Reaction outcome loss': 0.32655974734069665, 'Total loss': 0.32655974734069665}
2023-01-05 13:52:14,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:14,586 INFO:     Epoch: 49
2023-01-05 13:52:16,713 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.445748175183932, 'Total loss': 0.445748175183932} | train loss {'Reaction outcome loss': 0.32285822463996244, 'Total loss': 0.32285822463996244}
2023-01-05 13:52:16,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:16,713 INFO:     Epoch: 50
2023-01-05 13:52:18,835 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48631587127844494, 'Total loss': 0.48631587127844494} | train loss {'Reaction outcome loss': 0.32777877416693685, 'Total loss': 0.32777877416693685}
2023-01-05 13:52:18,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:18,835 INFO:     Epoch: 51
2023-01-05 13:52:20,944 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47437288165092467, 'Total loss': 0.47437288165092467} | train loss {'Reaction outcome loss': 0.3260902309749316, 'Total loss': 0.3260902309749316}
2023-01-05 13:52:20,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:20,945 INFO:     Epoch: 52
2023-01-05 13:52:23,064 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46266199499368665, 'Total loss': 0.46266199499368665} | train loss {'Reaction outcome loss': 0.3185186480537002, 'Total loss': 0.3185186480537002}
2023-01-05 13:52:23,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:23,065 INFO:     Epoch: 53
2023-01-05 13:52:25,173 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5029194484154383, 'Total loss': 0.5029194484154383} | train loss {'Reaction outcome loss': 0.3231738956385862, 'Total loss': 0.3231738956385862}
2023-01-05 13:52:25,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:25,174 INFO:     Epoch: 54
2023-01-05 13:52:27,294 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.560553656021754, 'Total loss': 0.560553656021754} | train loss {'Reaction outcome loss': 0.31606790906111726, 'Total loss': 0.31606790906111726}
2023-01-05 13:52:27,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:27,294 INFO:     Epoch: 55
2023-01-05 13:52:29,419 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5007067720095316, 'Total loss': 0.5007067720095316} | train loss {'Reaction outcome loss': 0.3094625706433049, 'Total loss': 0.3094625706433049}
2023-01-05 13:52:29,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:29,419 INFO:     Epoch: 56
2023-01-05 13:52:31,547 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43753961821397147, 'Total loss': 0.43753961821397147} | train loss {'Reaction outcome loss': 0.31015210930298975, 'Total loss': 0.31015210930298975}
2023-01-05 13:52:31,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:31,548 INFO:     Epoch: 57
2023-01-05 13:52:33,672 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4204145699739456, 'Total loss': 0.4204145699739456} | train loss {'Reaction outcome loss': 0.3059122487766184, 'Total loss': 0.3059122487766184}
2023-01-05 13:52:33,672 INFO:     Found new best model at epoch 57
2023-01-05 13:52:33,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:33,673 INFO:     Epoch: 58
2023-01-05 13:52:35,787 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42673191328843435, 'Total loss': 0.42673191328843435} | train loss {'Reaction outcome loss': 0.3107105737804493, 'Total loss': 0.3107105737804493}
2023-01-05 13:52:35,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:35,787 INFO:     Epoch: 59
2023-01-05 13:52:37,898 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4752709110577901, 'Total loss': 0.4752709110577901} | train loss {'Reaction outcome loss': 0.3066472493576043, 'Total loss': 0.3066472493576043}
2023-01-05 13:52:37,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:37,900 INFO:     Epoch: 60
2023-01-05 13:52:40,009 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47956940631071726, 'Total loss': 0.47956940631071726} | train loss {'Reaction outcome loss': 0.304355088948876, 'Total loss': 0.304355088948876}
2023-01-05 13:52:40,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:40,010 INFO:     Epoch: 61
2023-01-05 13:52:42,130 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43095367749532065, 'Total loss': 0.43095367749532065} | train loss {'Reaction outcome loss': 0.30651846115951575, 'Total loss': 0.30651846115951575}
2023-01-05 13:52:42,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:42,130 INFO:     Epoch: 62
2023-01-05 13:52:44,212 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4298562953869502, 'Total loss': 0.4298562953869502} | train loss {'Reaction outcome loss': 0.30877319173443885, 'Total loss': 0.30877319173443885}
2023-01-05 13:52:44,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:44,213 INFO:     Epoch: 63
2023-01-05 13:52:46,332 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44420736928780874, 'Total loss': 0.44420736928780874} | train loss {'Reaction outcome loss': 0.29566446204598135, 'Total loss': 0.29566446204598135}
2023-01-05 13:52:46,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:46,333 INFO:     Epoch: 64
2023-01-05 13:52:48,455 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44820676843325297, 'Total loss': 0.44820676843325297} | train loss {'Reaction outcome loss': 0.2917642036637107, 'Total loss': 0.2917642036637107}
2023-01-05 13:52:48,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:48,456 INFO:     Epoch: 65
2023-01-05 13:52:50,567 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4502535849809647, 'Total loss': 0.4502535849809647} | train loss {'Reaction outcome loss': 0.29254846550496943, 'Total loss': 0.29254846550496943}
2023-01-05 13:52:50,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:50,567 INFO:     Epoch: 66
2023-01-05 13:52:52,713 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4819721062978109, 'Total loss': 0.4819721062978109} | train loss {'Reaction outcome loss': 0.2954674242780759, 'Total loss': 0.2954674242780759}
2023-01-05 13:52:52,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:52,713 INFO:     Epoch: 67
2023-01-05 13:52:54,839 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.446218004822731, 'Total loss': 0.446218004822731} | train loss {'Reaction outcome loss': 0.2940040752359908, 'Total loss': 0.2940040752359908}
2023-01-05 13:52:54,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:54,840 INFO:     Epoch: 68
2023-01-05 13:52:56,989 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4239482478549083, 'Total loss': 0.4239482478549083} | train loss {'Reaction outcome loss': 0.28256348251696034, 'Total loss': 0.28256348251696034}
2023-01-05 13:52:56,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:56,990 INFO:     Epoch: 69
2023-01-05 13:52:59,096 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4166276047627131, 'Total loss': 0.4166276047627131} | train loss {'Reaction outcome loss': 0.27988995899593, 'Total loss': 0.27988995899593}
2023-01-05 13:52:59,096 INFO:     Found new best model at epoch 69
2023-01-05 13:52:59,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:52:59,097 INFO:     Epoch: 70
2023-01-05 13:53:01,201 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4553101638952891, 'Total loss': 0.4553101638952891} | train loss {'Reaction outcome loss': 0.2807242884795308, 'Total loss': 0.2807242884795308}
2023-01-05 13:53:01,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:01,201 INFO:     Epoch: 71
2023-01-05 13:53:03,346 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4676407357056936, 'Total loss': 0.4676407357056936} | train loss {'Reaction outcome loss': 0.2831295024835583, 'Total loss': 0.2831295024835583}
2023-01-05 13:53:03,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:03,347 INFO:     Epoch: 72
2023-01-05 13:53:05,477 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4043390686313311, 'Total loss': 0.4043390686313311} | train loss {'Reaction outcome loss': 0.2866856879981119, 'Total loss': 0.2866856879981119}
2023-01-05 13:53:05,478 INFO:     Found new best model at epoch 72
2023-01-05 13:53:05,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:05,479 INFO:     Epoch: 73
2023-01-05 13:53:07,585 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49436392486095426, 'Total loss': 0.49436392486095426} | train loss {'Reaction outcome loss': 0.27807516449100367, 'Total loss': 0.27807516449100367}
2023-01-05 13:53:07,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:07,586 INFO:     Epoch: 74
2023-01-05 13:53:09,695 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4671704371770223, 'Total loss': 0.4671704371770223} | train loss {'Reaction outcome loss': 0.27830033504400714, 'Total loss': 0.27830033504400714}
2023-01-05 13:53:09,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:09,695 INFO:     Epoch: 75
2023-01-05 13:53:11,817 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44234114785989126, 'Total loss': 0.44234114785989126} | train loss {'Reaction outcome loss': 0.28035506945881217, 'Total loss': 0.28035506945881217}
2023-01-05 13:53:11,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:11,817 INFO:     Epoch: 76
2023-01-05 13:53:13,937 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4267058352629344, 'Total loss': 0.4267058352629344} | train loss {'Reaction outcome loss': 0.2721598786830684, 'Total loss': 0.2721598786830684}
2023-01-05 13:53:13,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:13,938 INFO:     Epoch: 77
2023-01-05 13:53:16,041 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4071837383011977, 'Total loss': 0.4071837383011977} | train loss {'Reaction outcome loss': 0.26535636024727, 'Total loss': 0.26535636024727}
2023-01-05 13:53:16,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:16,041 INFO:     Epoch: 78
2023-01-05 13:53:18,144 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4396701912085215, 'Total loss': 0.4396701912085215} | train loss {'Reaction outcome loss': 0.2687468639968966, 'Total loss': 0.2687468639968966}
2023-01-05 13:53:18,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:18,145 INFO:     Epoch: 79
2023-01-05 13:53:20,245 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.408587513367335, 'Total loss': 0.408587513367335} | train loss {'Reaction outcome loss': 0.26643227538837616, 'Total loss': 0.26643227538837616}
2023-01-05 13:53:20,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:20,246 INFO:     Epoch: 80
2023-01-05 13:53:22,231 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49026187757651013, 'Total loss': 0.49026187757651013} | train loss {'Reaction outcome loss': 0.2681340581222332, 'Total loss': 0.2681340581222332}
2023-01-05 13:53:22,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:22,231 INFO:     Epoch: 81
2023-01-05 13:53:24,250 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.442084073026975, 'Total loss': 0.442084073026975} | train loss {'Reaction outcome loss': 0.2632807527324219, 'Total loss': 0.2632807527324219}
2023-01-05 13:53:24,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:24,250 INFO:     Epoch: 82
2023-01-05 13:53:26,365 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4347016530732314, 'Total loss': 0.4347016530732314} | train loss {'Reaction outcome loss': 0.268270861275576, 'Total loss': 0.268270861275576}
2023-01-05 13:53:26,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:26,365 INFO:     Epoch: 83
2023-01-05 13:53:28,487 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45550636351108553, 'Total loss': 0.45550636351108553} | train loss {'Reaction outcome loss': 0.2652745373997387, 'Total loss': 0.2652745373997387}
2023-01-05 13:53:28,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:28,487 INFO:     Epoch: 84
2023-01-05 13:53:30,594 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3986734052499135, 'Total loss': 0.3986734052499135} | train loss {'Reaction outcome loss': 0.25865412135045607, 'Total loss': 0.25865412135045607}
2023-01-05 13:53:30,594 INFO:     Found new best model at epoch 84
2023-01-05 13:53:30,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:30,595 INFO:     Epoch: 85
2023-01-05 13:53:32,723 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4388710578282674, 'Total loss': 0.4388710578282674} | train loss {'Reaction outcome loss': 0.2662876627165756, 'Total loss': 0.2662876627165756}
2023-01-05 13:53:32,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:32,724 INFO:     Epoch: 86
2023-01-05 13:53:34,840 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39978737334410347, 'Total loss': 0.39978737334410347} | train loss {'Reaction outcome loss': 0.26080132453214555, 'Total loss': 0.26080132453214555}
2023-01-05 13:53:34,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:34,840 INFO:     Epoch: 87
2023-01-05 13:53:36,971 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4674767146507899, 'Total loss': 0.4674767146507899} | train loss {'Reaction outcome loss': 0.24893862385671217, 'Total loss': 0.24893862385671217}
2023-01-05 13:53:36,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:36,971 INFO:     Epoch: 88
2023-01-05 13:53:39,071 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4446078479290009, 'Total loss': 0.4446078479290009} | train loss {'Reaction outcome loss': 0.25534161558927415, 'Total loss': 0.25534161558927415}
2023-01-05 13:53:39,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:39,071 INFO:     Epoch: 89
2023-01-05 13:53:41,199 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4455624336997668, 'Total loss': 0.4455624336997668} | train loss {'Reaction outcome loss': 0.2662594005219884, 'Total loss': 0.2662594005219884}
2023-01-05 13:53:41,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:41,199 INFO:     Epoch: 90
2023-01-05 13:53:43,308 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4753457566102346, 'Total loss': 0.4753457566102346} | train loss {'Reaction outcome loss': 0.2612017985508392, 'Total loss': 0.2612017985508392}
2023-01-05 13:53:43,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:43,308 INFO:     Epoch: 91
2023-01-05 13:53:45,414 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45574949781099955, 'Total loss': 0.45574949781099955} | train loss {'Reaction outcome loss': 0.25659458945085717, 'Total loss': 0.25659458945085717}
2023-01-05 13:53:45,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:45,415 INFO:     Epoch: 92
2023-01-05 13:53:47,521 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4731183687845866, 'Total loss': 0.4731183687845866} | train loss {'Reaction outcome loss': 0.2551650506727425, 'Total loss': 0.2551650506727425}
2023-01-05 13:53:47,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:47,521 INFO:     Epoch: 93
2023-01-05 13:53:49,630 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45092063148816425, 'Total loss': 0.45092063148816425} | train loss {'Reaction outcome loss': 0.252271972944612, 'Total loss': 0.252271972944612}
2023-01-05 13:53:49,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:49,631 INFO:     Epoch: 94
2023-01-05 13:53:51,752 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4397993984321753, 'Total loss': 0.4397993984321753} | train loss {'Reaction outcome loss': 0.2533821101358413, 'Total loss': 0.2533821101358413}
2023-01-05 13:53:51,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:51,752 INFO:     Epoch: 95
2023-01-05 13:53:53,861 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4218996077775955, 'Total loss': 0.4218996077775955} | train loss {'Reaction outcome loss': 0.2524827395739791, 'Total loss': 0.2524827395739791}
2023-01-05 13:53:53,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:53,861 INFO:     Epoch: 96
2023-01-05 13:53:55,993 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4458221778273582, 'Total loss': 0.4458221778273582} | train loss {'Reaction outcome loss': 0.25291174160309765, 'Total loss': 0.25291174160309765}
2023-01-05 13:53:55,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:55,994 INFO:     Epoch: 97
2023-01-05 13:53:58,108 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4498608534534772, 'Total loss': 0.4498608534534772} | train loss {'Reaction outcome loss': 0.24408556119071476, 'Total loss': 0.24408556119071476}
2023-01-05 13:53:58,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:53:58,109 INFO:     Epoch: 98
2023-01-05 13:54:00,258 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4118713797380527, 'Total loss': 0.4118713797380527} | train loss {'Reaction outcome loss': 0.25265265033058415, 'Total loss': 0.25265265033058415}
2023-01-05 13:54:00,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:00,258 INFO:     Epoch: 99
2023-01-05 13:54:02,377 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43551335036754607, 'Total loss': 0.43551335036754607} | train loss {'Reaction outcome loss': 0.24290746749607306, 'Total loss': 0.24290746749607306}
2023-01-05 13:54:02,377 INFO:     Best model found after epoch 85 of 100.
2023-01-05 13:54:02,377 INFO:   Done with stage: TRAINING
2023-01-05 13:54:02,377 INFO:   Starting stage: EVALUATION
2023-01-05 13:54:02,520 INFO:   Done with stage: EVALUATION
2023-01-05 13:54:02,520 INFO:   Leaving out SEQ value Fold_4
2023-01-05 13:54:02,533 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 13:54:02,533 INFO:   Starting stage: FEATURE SCALING
2023-01-05 13:54:03,178 INFO:   Done with stage: FEATURE SCALING
2023-01-05 13:54:03,178 INFO:   Starting stage: SCALING TARGETS
2023-01-05 13:54:03,246 INFO:   Done with stage: SCALING TARGETS
2023-01-05 13:54:03,246 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:54:03,246 INFO:     No hyperparam tuning for this model
2023-01-05 13:54:03,246 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:54:03,246 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 13:54:03,247 INFO:     None feature selector for col prot
2023-01-05 13:54:03,247 INFO:     None feature selector for col prot
2023-01-05 13:54:03,247 INFO:     None feature selector for col prot
2023-01-05 13:54:03,247 INFO:     None feature selector for col chem
2023-01-05 13:54:03,248 INFO:     None feature selector for col chem
2023-01-05 13:54:03,248 INFO:     None feature selector for col chem
2023-01-05 13:54:03,248 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 13:54:03,248 INFO:   Starting stage: BUILD MODEL
2023-01-05 13:54:03,249 INFO:     Number of params in model 72901
2023-01-05 13:54:03,252 INFO:   Done with stage: BUILD MODEL
2023-01-05 13:54:03,252 INFO:   Starting stage: TRAINING
2023-01-05 13:54:03,312 INFO:     Val loss before train {'Reaction outcome loss': 0.9657350818316142, 'Total loss': 0.9657350818316142}
2023-01-05 13:54:03,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:03,313 INFO:     Epoch: 0
2023-01-05 13:54:05,463 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7921765247980753, 'Total loss': 0.7921765247980753} | train loss {'Reaction outcome loss': 0.9016671499804311, 'Total loss': 0.9016671499804311}
2023-01-05 13:54:05,463 INFO:     Found new best model at epoch 0
2023-01-05 13:54:05,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:05,464 INFO:     Epoch: 1
2023-01-05 13:54:07,580 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6336855093638102, 'Total loss': 0.6336855093638102} | train loss {'Reaction outcome loss': 0.7168282329820205, 'Total loss': 0.7168282329820205}
2023-01-05 13:54:07,580 INFO:     Found new best model at epoch 1
2023-01-05 13:54:07,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:07,581 INFO:     Epoch: 2
2023-01-05 13:54:09,716 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6560242831707, 'Total loss': 0.6560242831707} | train loss {'Reaction outcome loss': 0.5814905230941224, 'Total loss': 0.5814905230941224}
2023-01-05 13:54:09,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:09,717 INFO:     Epoch: 3
2023-01-05 13:54:11,847 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5792607545852662, 'Total loss': 0.5792607545852662} | train loss {'Reaction outcome loss': 0.523798223476911, 'Total loss': 0.523798223476911}
2023-01-05 13:54:11,847 INFO:     Found new best model at epoch 3
2023-01-05 13:54:11,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:11,849 INFO:     Epoch: 4
2023-01-05 13:54:13,968 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6059315035740535, 'Total loss': 0.6059315035740535} | train loss {'Reaction outcome loss': 0.5066958446784512, 'Total loss': 0.5066958446784512}
2023-01-05 13:54:13,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:13,968 INFO:     Epoch: 5
2023-01-05 13:54:16,122 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5947299242019654, 'Total loss': 0.5947299242019654} | train loss {'Reaction outcome loss': 0.4920769826495561, 'Total loss': 0.4920769826495561}
2023-01-05 13:54:16,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:16,122 INFO:     Epoch: 6
2023-01-05 13:54:18,196 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5731776913007101, 'Total loss': 0.5731776913007101} | train loss {'Reaction outcome loss': 0.4769158007685041, 'Total loss': 0.4769158007685041}
2023-01-05 13:54:18,196 INFO:     Found new best model at epoch 6
2023-01-05 13:54:18,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:18,198 INFO:     Epoch: 7
2023-01-05 13:54:19,958 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5813650806744893, 'Total loss': 0.5813650806744893} | train loss {'Reaction outcome loss': 0.47585908814832784, 'Total loss': 0.47585908814832784}
2023-01-05 13:54:19,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:19,958 INFO:     Epoch: 8
2023-01-05 13:54:21,719 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5723323285579681, 'Total loss': 0.5723323285579681} | train loss {'Reaction outcome loss': 0.46498806392639014, 'Total loss': 0.46498806392639014}
2023-01-05 13:54:21,719 INFO:     Found new best model at epoch 8
2023-01-05 13:54:21,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:21,721 INFO:     Epoch: 9
2023-01-05 13:54:23,813 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5675896783669789, 'Total loss': 0.5675896783669789} | train loss {'Reaction outcome loss': 0.45802265716264484, 'Total loss': 0.45802265716264484}
2023-01-05 13:54:23,813 INFO:     Found new best model at epoch 9
2023-01-05 13:54:23,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:23,814 INFO:     Epoch: 10
2023-01-05 13:54:25,974 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5615946084260941, 'Total loss': 0.5615946084260941} | train loss {'Reaction outcome loss': 0.4523187126416841, 'Total loss': 0.4523187126416841}
2023-01-05 13:54:25,975 INFO:     Found new best model at epoch 10
2023-01-05 13:54:25,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:25,977 INFO:     Epoch: 11
2023-01-05 13:54:28,132 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5816975891590118, 'Total loss': 0.5816975891590118} | train loss {'Reaction outcome loss': 0.4473881957431634, 'Total loss': 0.4473881957431634}
2023-01-05 13:54:28,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:28,132 INFO:     Epoch: 12
2023-01-05 13:54:30,288 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5709743241469065, 'Total loss': 0.5709743241469065} | train loss {'Reaction outcome loss': 0.4614680486636749, 'Total loss': 0.4614680486636749}
2023-01-05 13:54:30,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:30,288 INFO:     Epoch: 13
2023-01-05 13:54:32,432 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5698889513810476, 'Total loss': 0.5698889513810476} | train loss {'Reaction outcome loss': 0.46499088883865625, 'Total loss': 0.46499088883865625}
2023-01-05 13:54:32,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:32,433 INFO:     Epoch: 14
2023-01-05 13:54:34,583 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5537205874919892, 'Total loss': 0.5537205874919892} | train loss {'Reaction outcome loss': 0.44043382660796243, 'Total loss': 0.44043382660796243}
2023-01-05 13:54:34,583 INFO:     Found new best model at epoch 14
2023-01-05 13:54:34,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:34,584 INFO:     Epoch: 15
2023-01-05 13:54:36,731 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.537321937084198, 'Total loss': 0.537321937084198} | train loss {'Reaction outcome loss': 0.4374654594862807, 'Total loss': 0.4374654594862807}
2023-01-05 13:54:36,731 INFO:     Found new best model at epoch 15
2023-01-05 13:54:36,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:36,733 INFO:     Epoch: 16
2023-01-05 13:54:38,893 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5435824384291966, 'Total loss': 0.5435824384291966} | train loss {'Reaction outcome loss': 0.4285488653442134, 'Total loss': 0.4285488653442134}
2023-01-05 13:54:38,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:38,893 INFO:     Epoch: 17
2023-01-05 13:54:41,051 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5834558665752411, 'Total loss': 0.5834558665752411} | train loss {'Reaction outcome loss': 0.42366328668535774, 'Total loss': 0.42366328668535774}
2023-01-05 13:54:41,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:41,052 INFO:     Epoch: 18
2023-01-05 13:54:43,203 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5651316662629445, 'Total loss': 0.5651316662629445} | train loss {'Reaction outcome loss': 0.441343288814676, 'Total loss': 0.441343288814676}
2023-01-05 13:54:43,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:43,203 INFO:     Epoch: 19
2023-01-05 13:54:45,367 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5570465306440989, 'Total loss': 0.5570465306440989} | train loss {'Reaction outcome loss': 0.42283252622544987, 'Total loss': 0.42283252622544987}
2023-01-05 13:54:45,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:45,368 INFO:     Epoch: 20
2023-01-05 13:54:47,513 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5480950971444448, 'Total loss': 0.5480950971444448} | train loss {'Reaction outcome loss': 0.41386970000219636, 'Total loss': 0.41386970000219636}
2023-01-05 13:54:47,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:47,513 INFO:     Epoch: 21
2023-01-05 13:54:49,644 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5257587393124898, 'Total loss': 0.5257587393124898} | train loss {'Reaction outcome loss': 0.4106546690825886, 'Total loss': 0.4106546690825886}
2023-01-05 13:54:49,645 INFO:     Found new best model at epoch 21
2023-01-05 13:54:49,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:49,646 INFO:     Epoch: 22
2023-01-05 13:54:51,764 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5528691510359446, 'Total loss': 0.5528691510359446} | train loss {'Reaction outcome loss': 0.43191043911096844, 'Total loss': 0.43191043911096844}
2023-01-05 13:54:51,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:51,764 INFO:     Epoch: 23
2023-01-05 13:54:53,912 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5460675676663717, 'Total loss': 0.5460675676663717} | train loss {'Reaction outcome loss': 0.4094339912973236, 'Total loss': 0.4094339912973236}
2023-01-05 13:54:53,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:53,913 INFO:     Epoch: 24
2023-01-05 13:54:56,034 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5238794475793839, 'Total loss': 0.5238794475793839} | train loss {'Reaction outcome loss': 0.4051897910402909, 'Total loss': 0.4051897910402909}
2023-01-05 13:54:56,034 INFO:     Found new best model at epoch 24
2023-01-05 13:54:56,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:56,036 INFO:     Epoch: 25
2023-01-05 13:54:58,167 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5581532537937164, 'Total loss': 0.5581532537937164} | train loss {'Reaction outcome loss': 0.4035840219888917, 'Total loss': 0.4035840219888917}
2023-01-05 13:54:58,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:54:58,167 INFO:     Epoch: 26
2023-01-05 13:55:00,322 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.6097067534923554, 'Total loss': 0.6097067534923554} | train loss {'Reaction outcome loss': 0.40005348355549836, 'Total loss': 0.40005348355549836}
2023-01-05 13:55:00,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:00,322 INFO:     Epoch: 27
2023-01-05 13:55:02,472 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5254179398218791, 'Total loss': 0.5254179398218791} | train loss {'Reaction outcome loss': 0.40322791938872443, 'Total loss': 0.40322791938872443}
2023-01-05 13:55:02,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:02,473 INFO:     Epoch: 28
2023-01-05 13:55:04,620 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5269922753175099, 'Total loss': 0.5269922753175099} | train loss {'Reaction outcome loss': 0.39253250085681246, 'Total loss': 0.39253250085681246}
2023-01-05 13:55:04,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:04,621 INFO:     Epoch: 29
2023-01-05 13:55:06,740 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5627897948026657, 'Total loss': 0.5627897948026657} | train loss {'Reaction outcome loss': 0.3893204837416609, 'Total loss': 0.3893204837416609}
2023-01-05 13:55:06,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:06,741 INFO:     Epoch: 30
2023-01-05 13:55:08,870 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.541677196820577, 'Total loss': 0.541677196820577} | train loss {'Reaction outcome loss': 0.38375441779288044, 'Total loss': 0.38375441779288044}
2023-01-05 13:55:08,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:08,871 INFO:     Epoch: 31
2023-01-05 13:55:11,041 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5342757880687714, 'Total loss': 0.5342757880687714} | train loss {'Reaction outcome loss': 0.38286833824025485, 'Total loss': 0.38286833824025485}
2023-01-05 13:55:11,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:11,041 INFO:     Epoch: 32
2023-01-05 13:55:13,188 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.544757463534673, 'Total loss': 0.544757463534673} | train loss {'Reaction outcome loss': 0.37577112758889847, 'Total loss': 0.37577112758889847}
2023-01-05 13:55:13,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:13,188 INFO:     Epoch: 33
2023-01-05 13:55:15,338 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5296359121799469, 'Total loss': 0.5296359121799469} | train loss {'Reaction outcome loss': 0.3729265580237236, 'Total loss': 0.3729265580237236}
2023-01-05 13:55:15,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:15,339 INFO:     Epoch: 34
2023-01-05 13:55:17,515 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5234387417634329, 'Total loss': 0.5234387417634329} | train loss {'Reaction outcome loss': 0.37595397056724905, 'Total loss': 0.37595397056724905}
2023-01-05 13:55:17,516 INFO:     Found new best model at epoch 34
2023-01-05 13:55:17,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:17,517 INFO:     Epoch: 35
2023-01-05 13:55:19,661 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5473201811313629, 'Total loss': 0.5473201811313629} | train loss {'Reaction outcome loss': 0.3677077011772148, 'Total loss': 0.3677077011772148}
2023-01-05 13:55:19,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:19,661 INFO:     Epoch: 36
2023-01-05 13:55:21,814 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5139259735743205, 'Total loss': 0.5139259735743205} | train loss {'Reaction outcome loss': 0.3720424816909118, 'Total loss': 0.3720424816909118}
2023-01-05 13:55:21,814 INFO:     Found new best model at epoch 36
2023-01-05 13:55:21,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:21,816 INFO:     Epoch: 37
2023-01-05 13:55:23,947 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5302313943703969, 'Total loss': 0.5302313943703969} | train loss {'Reaction outcome loss': 0.3656233120589446, 'Total loss': 0.3656233120589446}
2023-01-05 13:55:23,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:23,948 INFO:     Epoch: 38
2023-01-05 13:55:26,094 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5315257082382838, 'Total loss': 0.5315257082382838} | train loss {'Reaction outcome loss': 0.3673055789883053, 'Total loss': 0.3673055789883053}
2023-01-05 13:55:26,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:26,094 INFO:     Epoch: 39
2023-01-05 13:55:28,250 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5146357834339141, 'Total loss': 0.5146357834339141} | train loss {'Reaction outcome loss': 0.3572610391209415, 'Total loss': 0.3572610391209415}
2023-01-05 13:55:28,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:28,250 INFO:     Epoch: 40
2023-01-05 13:55:30,416 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5509236752986908, 'Total loss': 0.5509236752986908} | train loss {'Reaction outcome loss': 0.3503186196387, 'Total loss': 0.3503186196387}
2023-01-05 13:55:30,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:30,417 INFO:     Epoch: 41
2023-01-05 13:55:32,584 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.558933428923289, 'Total loss': 0.558933428923289} | train loss {'Reaction outcome loss': 0.3517556369487716, 'Total loss': 0.3517556369487716}
2023-01-05 13:55:32,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:32,585 INFO:     Epoch: 42
2023-01-05 13:55:34,771 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5420337895552317, 'Total loss': 0.5420337895552317} | train loss {'Reaction outcome loss': 0.34696696216807416, 'Total loss': 0.34696696216807416}
2023-01-05 13:55:34,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:34,771 INFO:     Epoch: 43
2023-01-05 13:55:36,959 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5694694121678671, 'Total loss': 0.5694694121678671} | train loss {'Reaction outcome loss': 0.34643636953315116, 'Total loss': 0.34643636953315116}
2023-01-05 13:55:36,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:36,959 INFO:     Epoch: 44
2023-01-05 13:55:39,146 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5557723919550578, 'Total loss': 0.5557723919550578} | train loss {'Reaction outcome loss': 0.34631200057903194, 'Total loss': 0.34631200057903194}
2023-01-05 13:55:39,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:39,147 INFO:     Epoch: 45
2023-01-05 13:55:41,313 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5258879681428273, 'Total loss': 0.5258879681428273} | train loss {'Reaction outcome loss': 0.3437946043922093, 'Total loss': 0.3437946043922093}
2023-01-05 13:55:41,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:41,314 INFO:     Epoch: 46
2023-01-05 13:55:43,444 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5386645058790843, 'Total loss': 0.5386645058790843} | train loss {'Reaction outcome loss': 0.3422358978213447, 'Total loss': 0.3422358978213447}
2023-01-05 13:55:43,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:43,444 INFO:     Epoch: 47
2023-01-05 13:55:45,614 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.533336728811264, 'Total loss': 0.533336728811264} | train loss {'Reaction outcome loss': 0.3391844937712818, 'Total loss': 0.3391844937712818}
2023-01-05 13:55:45,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:45,614 INFO:     Epoch: 48
2023-01-05 13:55:47,765 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5601016680399576, 'Total loss': 0.5601016680399576} | train loss {'Reaction outcome loss': 0.3775561167711967, 'Total loss': 0.3775561167711967}
2023-01-05 13:55:47,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:47,766 INFO:     Epoch: 49
2023-01-05 13:55:49,927 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5103803167740504, 'Total loss': 0.5103803167740504} | train loss {'Reaction outcome loss': 0.33586631137607753, 'Total loss': 0.33586631137607753}
2023-01-05 13:55:49,927 INFO:     Found new best model at epoch 49
2023-01-05 13:55:49,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:49,929 INFO:     Epoch: 50
2023-01-05 13:55:52,100 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5683571239312489, 'Total loss': 0.5683571239312489} | train loss {'Reaction outcome loss': 0.3262631486210486, 'Total loss': 0.3262631486210486}
2023-01-05 13:55:52,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:52,101 INFO:     Epoch: 51
2023-01-05 13:55:54,279 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5098948587973913, 'Total loss': 0.5098948587973913} | train loss {'Reaction outcome loss': 0.34573774481111247, 'Total loss': 0.34573774481111247}
2023-01-05 13:55:54,279 INFO:     Found new best model at epoch 51
2023-01-05 13:55:54,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:54,280 INFO:     Epoch: 52
2023-01-05 13:55:56,471 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5158107668161392, 'Total loss': 0.5158107668161392} | train loss {'Reaction outcome loss': 0.3238764327513796, 'Total loss': 0.3238764327513796}
2023-01-05 13:55:56,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:56,472 INFO:     Epoch: 53
2023-01-05 13:55:58,655 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5172334084908168, 'Total loss': 0.5172334084908168} | train loss {'Reaction outcome loss': 0.3177550366357025, 'Total loss': 0.3177550366357025}
2023-01-05 13:55:58,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:55:58,656 INFO:     Epoch: 54
2023-01-05 13:56:00,870 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5569272220134736, 'Total loss': 0.5569272220134736} | train loss {'Reaction outcome loss': 0.3180017867446135, 'Total loss': 0.3180017867446135}
2023-01-05 13:56:00,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:00,871 INFO:     Epoch: 55
2023-01-05 13:56:03,044 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5468019406000774, 'Total loss': 0.5468019406000774} | train loss {'Reaction outcome loss': 0.31220077478244185, 'Total loss': 0.31220077478244185}
2023-01-05 13:56:03,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:03,044 INFO:     Epoch: 56
2023-01-05 13:56:05,171 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5210060755411784, 'Total loss': 0.5210060755411784} | train loss {'Reaction outcome loss': 0.31430297028408316, 'Total loss': 0.31430297028408316}
2023-01-05 13:56:05,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:05,171 INFO:     Epoch: 57
2023-01-05 13:56:07,277 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.550365020831426, 'Total loss': 0.550365020831426} | train loss {'Reaction outcome loss': 0.30834212482053164, 'Total loss': 0.30834212482053164}
2023-01-05 13:56:07,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:07,277 INFO:     Epoch: 58
2023-01-05 13:56:09,417 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5193819562594096, 'Total loss': 0.5193819562594096} | train loss {'Reaction outcome loss': 0.30592092789962355, 'Total loss': 0.30592092789962355}
2023-01-05 13:56:09,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:09,419 INFO:     Epoch: 59
2023-01-05 13:56:11,551 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.553025625149409, 'Total loss': 0.553025625149409} | train loss {'Reaction outcome loss': 0.3133820814579941, 'Total loss': 0.3133820814579941}
2023-01-05 13:56:11,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:11,552 INFO:     Epoch: 60
2023-01-05 13:56:13,687 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5440967182318369, 'Total loss': 0.5440967182318369} | train loss {'Reaction outcome loss': 0.3258827592002543, 'Total loss': 0.3258827592002543}
2023-01-05 13:56:13,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:13,687 INFO:     Epoch: 61
2023-01-05 13:56:15,844 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48635448813438414, 'Total loss': 0.48635448813438414} | train loss {'Reaction outcome loss': 0.2959897637622856, 'Total loss': 0.2959897637622856}
2023-01-05 13:56:15,845 INFO:     Found new best model at epoch 61
2023-01-05 13:56:15,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:15,847 INFO:     Epoch: 62
2023-01-05 13:56:17,985 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.525031050046285, 'Total loss': 0.525031050046285} | train loss {'Reaction outcome loss': 0.2967056459629152, 'Total loss': 0.2967056459629152}
2023-01-05 13:56:17,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:17,986 INFO:     Epoch: 63
2023-01-05 13:56:20,118 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5374312202135721, 'Total loss': 0.5374312202135721} | train loss {'Reaction outcome loss': 0.2926712600148307, 'Total loss': 0.2926712600148307}
2023-01-05 13:56:20,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:20,118 INFO:     Epoch: 64
2023-01-05 13:56:22,265 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.507287077109019, 'Total loss': 0.507287077109019} | train loss {'Reaction outcome loss': 0.29312960254901554, 'Total loss': 0.29312960254901554}
2023-01-05 13:56:22,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:22,265 INFO:     Epoch: 65
2023-01-05 13:56:24,396 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5088332196076711, 'Total loss': 0.5088332196076711} | train loss {'Reaction outcome loss': 0.29416484274037613, 'Total loss': 0.29416484274037613}
2023-01-05 13:56:24,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:24,397 INFO:     Epoch: 66
2023-01-05 13:56:26,540 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5335046817859014, 'Total loss': 0.5335046817859014} | train loss {'Reaction outcome loss': 0.29483679530507734, 'Total loss': 0.29483679530507734}
2023-01-05 13:56:26,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:26,541 INFO:     Epoch: 67
2023-01-05 13:56:28,675 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5076097011566162, 'Total loss': 0.5076097011566162} | train loss {'Reaction outcome loss': 0.2862104937287412, 'Total loss': 0.2862104937287412}
2023-01-05 13:56:28,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:28,676 INFO:     Epoch: 68
2023-01-05 13:56:30,450 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5478952666123708, 'Total loss': 0.5478952666123708} | train loss {'Reaction outcome loss': 0.3056109471759502, 'Total loss': 0.3056109471759502}
2023-01-05 13:56:30,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:30,450 INFO:     Epoch: 69
2023-01-05 13:56:32,225 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5161850353082021, 'Total loss': 0.5161850353082021} | train loss {'Reaction outcome loss': 0.31130586854735576, 'Total loss': 0.31130586854735576}
2023-01-05 13:56:32,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:32,226 INFO:     Epoch: 70
2023-01-05 13:56:34,257 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5222262452046077, 'Total loss': 0.5222262452046077} | train loss {'Reaction outcome loss': 0.29514344639576756, 'Total loss': 0.29514344639576756}
2023-01-05 13:56:34,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:34,257 INFO:     Epoch: 71
2023-01-05 13:56:36,415 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5769336442152659, 'Total loss': 0.5769336442152659} | train loss {'Reaction outcome loss': 0.2810152965851729, 'Total loss': 0.2810152965851729}
2023-01-05 13:56:36,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:36,416 INFO:     Epoch: 72
2023-01-05 13:56:38,674 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5331811229387919, 'Total loss': 0.5331811229387919} | train loss {'Reaction outcome loss': 0.28421945944833366, 'Total loss': 0.28421945944833366}
2023-01-05 13:56:38,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:38,676 INFO:     Epoch: 73
2023-01-05 13:56:40,921 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5536519169807435, 'Total loss': 0.5536519169807435} | train loss {'Reaction outcome loss': 0.2914373958280877, 'Total loss': 0.2914373958280877}
2023-01-05 13:56:40,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:40,921 INFO:     Epoch: 74
2023-01-05 13:56:43,236 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.569573599100113, 'Total loss': 0.569573599100113} | train loss {'Reaction outcome loss': 0.2850514821367814, 'Total loss': 0.2850514821367814}
2023-01-05 13:56:43,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:43,237 INFO:     Epoch: 75
2023-01-05 13:56:45,507 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5502066612243652, 'Total loss': 0.5502066612243652} | train loss {'Reaction outcome loss': 0.2799417040052662, 'Total loss': 0.2799417040052662}
2023-01-05 13:56:45,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:45,508 INFO:     Epoch: 76
2023-01-05 13:56:47,705 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48733249803384143, 'Total loss': 0.48733249803384143} | train loss {'Reaction outcome loss': 0.26924632806417387, 'Total loss': 0.26924632806417387}
2023-01-05 13:56:47,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:47,706 INFO:     Epoch: 77
2023-01-05 13:56:49,867 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5937888940175374, 'Total loss': 0.5937888940175374} | train loss {'Reaction outcome loss': 0.2823259492094318, 'Total loss': 0.2823259492094318}
2023-01-05 13:56:49,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:49,867 INFO:     Epoch: 78
2023-01-05 13:56:52,021 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5302578389644623, 'Total loss': 0.5302578389644623} | train loss {'Reaction outcome loss': 0.3319414227119431, 'Total loss': 0.3319414227119431}
2023-01-05 13:56:52,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:52,022 INFO:     Epoch: 79
2023-01-05 13:56:54,189 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5588411832849185, 'Total loss': 0.5588411832849185} | train loss {'Reaction outcome loss': 0.2860442949661418, 'Total loss': 0.2860442949661418}
2023-01-05 13:56:54,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:54,189 INFO:     Epoch: 80
2023-01-05 13:56:56,366 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5401555289824803, 'Total loss': 0.5401555289824803} | train loss {'Reaction outcome loss': 0.27888553350003087, 'Total loss': 0.27888553350003087}
2023-01-05 13:56:56,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:56,366 INFO:     Epoch: 81
2023-01-05 13:56:58,558 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5110523591438929, 'Total loss': 0.5110523591438929} | train loss {'Reaction outcome loss': 0.27809423251512827, 'Total loss': 0.27809423251512827}
2023-01-05 13:56:58,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:56:58,559 INFO:     Epoch: 82
2023-01-05 13:57:00,763 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5303354501724243, 'Total loss': 0.5303354501724243} | train loss {'Reaction outcome loss': 0.26401708505210886, 'Total loss': 0.26401708505210886}
2023-01-05 13:57:00,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:00,763 INFO:     Epoch: 83
2023-01-05 13:57:02,932 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5122374405463537, 'Total loss': 0.5122374405463537} | train loss {'Reaction outcome loss': 0.2693373193235501, 'Total loss': 0.2693373193235501}
2023-01-05 13:57:02,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:02,933 INFO:     Epoch: 84
2023-01-05 13:57:05,092 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5866758118073145, 'Total loss': 0.5866758118073145} | train loss {'Reaction outcome loss': 0.2680835421399578, 'Total loss': 0.2680835421399578}
2023-01-05 13:57:05,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:05,092 INFO:     Epoch: 85
2023-01-05 13:57:07,248 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5079409013191859, 'Total loss': 0.5079409013191859} | train loss {'Reaction outcome loss': 0.26762558387228, 'Total loss': 0.26762558387228}
2023-01-05 13:57:07,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:07,248 INFO:     Epoch: 86
2023-01-05 13:57:09,401 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4825257430473963, 'Total loss': 0.4825257430473963} | train loss {'Reaction outcome loss': 0.26711963219028234, 'Total loss': 0.26711963219028234}
2023-01-05 13:57:09,401 INFO:     Found new best model at epoch 86
2023-01-05 13:57:09,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:09,402 INFO:     Epoch: 87
2023-01-05 13:57:11,568 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5131699939568838, 'Total loss': 0.5131699939568838} | train loss {'Reaction outcome loss': 0.26030683215788525, 'Total loss': 0.26030683215788525}
2023-01-05 13:57:11,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:11,568 INFO:     Epoch: 88
2023-01-05 13:57:13,725 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5346432626247406, 'Total loss': 0.5346432626247406} | train loss {'Reaction outcome loss': 0.2685035275484341, 'Total loss': 0.2685035275484341}
2023-01-05 13:57:13,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:13,726 INFO:     Epoch: 89
2023-01-05 13:57:15,876 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5272799829641978, 'Total loss': 0.5272799829641978} | train loss {'Reaction outcome loss': 0.2620155069221189, 'Total loss': 0.2620155069221189}
2023-01-05 13:57:15,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:15,877 INFO:     Epoch: 90
2023-01-05 13:57:18,053 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5521503925323487, 'Total loss': 0.5521503925323487} | train loss {'Reaction outcome loss': 0.30997472681591043, 'Total loss': 0.30997472681591043}
2023-01-05 13:57:18,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:18,053 INFO:     Epoch: 91
2023-01-05 13:57:20,197 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5193347136179606, 'Total loss': 0.5193347136179606} | train loss {'Reaction outcome loss': 0.26747878600292385, 'Total loss': 0.26747878600292385}
2023-01-05 13:57:20,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:20,197 INFO:     Epoch: 92
2023-01-05 13:57:22,341 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5324268718560536, 'Total loss': 0.5324268718560536} | train loss {'Reaction outcome loss': 0.26429715203256277, 'Total loss': 0.26429715203256277}
2023-01-05 13:57:22,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:22,342 INFO:     Epoch: 93
2023-01-05 13:57:24,367 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5535503327846527, 'Total loss': 0.5535503327846527} | train loss {'Reaction outcome loss': 0.25963059788098664, 'Total loss': 0.25963059788098664}
2023-01-05 13:57:24,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:24,368 INFO:     Epoch: 94
2023-01-05 13:57:26,404 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5002008636792501, 'Total loss': 0.5002008636792501} | train loss {'Reaction outcome loss': 0.2601453738111625, 'Total loss': 0.2601453738111625}
2023-01-05 13:57:26,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:26,405 INFO:     Epoch: 95
2023-01-05 13:57:28,764 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5279583752155304, 'Total loss': 0.5279583752155304} | train loss {'Reaction outcome loss': 0.25959448713262606, 'Total loss': 0.25959448713262606}
2023-01-05 13:57:28,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:28,764 INFO:     Epoch: 96
2023-01-05 13:57:31,094 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5380233188470205, 'Total loss': 0.5380233188470205} | train loss {'Reaction outcome loss': 0.2601262445763285, 'Total loss': 0.2601262445763285}
2023-01-05 13:57:31,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:31,095 INFO:     Epoch: 97
2023-01-05 13:57:33,317 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4950052281220754, 'Total loss': 0.4950052281220754} | train loss {'Reaction outcome loss': 0.2814981518380776, 'Total loss': 0.2814981518380776}
2023-01-05 13:57:33,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:33,317 INFO:     Epoch: 98
2023-01-05 13:57:35,554 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5644934018452962, 'Total loss': 0.5644934018452962} | train loss {'Reaction outcome loss': 0.25734972897655517, 'Total loss': 0.25734972897655517}
2023-01-05 13:57:35,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:35,555 INFO:     Epoch: 99
2023-01-05 13:57:37,708 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5286884804566702, 'Total loss': 0.5286884804566702} | train loss {'Reaction outcome loss': 0.26552968758219125, 'Total loss': 0.26552968758219125}
2023-01-05 13:57:37,708 INFO:     Best model found after epoch 87 of 100.
2023-01-05 13:57:37,708 INFO:   Done with stage: TRAINING
2023-01-05 13:57:37,708 INFO:   Starting stage: EVALUATION
2023-01-05 13:57:37,841 INFO:   Done with stage: EVALUATION
2023-01-05 13:57:37,842 INFO:   Leaving out SEQ value Fold_5
2023-01-05 13:57:37,854 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 13:57:37,854 INFO:   Starting stage: FEATURE SCALING
2023-01-05 13:57:38,509 INFO:   Done with stage: FEATURE SCALING
2023-01-05 13:57:38,509 INFO:   Starting stage: SCALING TARGETS
2023-01-05 13:57:38,579 INFO:   Done with stage: SCALING TARGETS
2023-01-05 13:57:38,579 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:57:38,579 INFO:     No hyperparam tuning for this model
2023-01-05 13:57:38,579 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 13:57:38,579 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 13:57:38,580 INFO:     None feature selector for col prot
2023-01-05 13:57:38,580 INFO:     None feature selector for col prot
2023-01-05 13:57:38,580 INFO:     None feature selector for col prot
2023-01-05 13:57:38,581 INFO:     None feature selector for col chem
2023-01-05 13:57:38,581 INFO:     None feature selector for col chem
2023-01-05 13:57:38,581 INFO:     None feature selector for col chem
2023-01-05 13:57:38,581 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 13:57:38,581 INFO:   Starting stage: BUILD MODEL
2023-01-05 13:57:38,582 INFO:     Number of params in model 72901
2023-01-05 13:57:38,586 INFO:   Done with stage: BUILD MODEL
2023-01-05 13:57:38,586 INFO:   Starting stage: TRAINING
2023-01-05 13:57:38,645 INFO:     Val loss before train {'Reaction outcome loss': 1.0094074289004007, 'Total loss': 1.0094074289004007}
2023-01-05 13:57:38,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:38,645 INFO:     Epoch: 0
2023-01-05 13:57:40,827 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8050544023513794, 'Total loss': 0.8050544023513794} | train loss {'Reaction outcome loss': 0.9439581733439928, 'Total loss': 0.9439581733439928}
2023-01-05 13:57:40,827 INFO:     Found new best model at epoch 0
2023-01-05 13:57:40,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:40,828 INFO:     Epoch: 1
2023-01-05 13:57:43,024 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6206540882587432, 'Total loss': 0.6206540882587432} | train loss {'Reaction outcome loss': 0.7685084264941405, 'Total loss': 0.7685084264941405}
2023-01-05 13:57:43,024 INFO:     Found new best model at epoch 1
2023-01-05 13:57:43,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:43,025 INFO:     Epoch: 2
2023-01-05 13:57:45,155 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49787295460700987, 'Total loss': 0.49787295460700987} | train loss {'Reaction outcome loss': 0.5949556581891965, 'Total loss': 0.5949556581891965}
2023-01-05 13:57:45,156 INFO:     Found new best model at epoch 2
2023-01-05 13:57:45,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:45,158 INFO:     Epoch: 3
2023-01-05 13:57:47,284 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5114464322725932, 'Total loss': 0.5114464322725932} | train loss {'Reaction outcome loss': 0.5356221077858261, 'Total loss': 0.5356221077858261}
2023-01-05 13:57:47,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:47,284 INFO:     Epoch: 4
2023-01-05 13:57:49,427 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4817150831222534, 'Total loss': 0.4817150831222534} | train loss {'Reaction outcome loss': 0.514185953669358, 'Total loss': 0.514185953669358}
2023-01-05 13:57:49,427 INFO:     Found new best model at epoch 4
2023-01-05 13:57:49,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:49,429 INFO:     Epoch: 5
2023-01-05 13:57:51,577 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47803798417250315, 'Total loss': 0.47803798417250315} | train loss {'Reaction outcome loss': 0.5135824749975101, 'Total loss': 0.5135824749975101}
2023-01-05 13:57:51,578 INFO:     Found new best model at epoch 5
2023-01-05 13:57:51,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:51,579 INFO:     Epoch: 6
2023-01-05 13:57:53,723 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4772631287574768, 'Total loss': 0.4772631287574768} | train loss {'Reaction outcome loss': 0.492568529440441, 'Total loss': 0.492568529440441}
2023-01-05 13:57:53,724 INFO:     Found new best model at epoch 6
2023-01-05 13:57:53,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:53,725 INFO:     Epoch: 7
2023-01-05 13:57:55,857 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4617206265528997, 'Total loss': 0.4617206265528997} | train loss {'Reaction outcome loss': 0.4852566233687643, 'Total loss': 0.4852566233687643}
2023-01-05 13:57:55,857 INFO:     Found new best model at epoch 7
2023-01-05 13:57:55,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:55,858 INFO:     Epoch: 8
2023-01-05 13:57:58,032 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4611094216505686, 'Total loss': 0.4611094216505686} | train loss {'Reaction outcome loss': 0.47667059119271143, 'Total loss': 0.47667059119271143}
2023-01-05 13:57:58,033 INFO:     Found new best model at epoch 8
2023-01-05 13:57:58,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:57:58,034 INFO:     Epoch: 9
2023-01-05 13:58:00,149 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46660666664441425, 'Total loss': 0.46660666664441425} | train loss {'Reaction outcome loss': 0.4732492755531933, 'Total loss': 0.4732492755531933}
2023-01-05 13:58:00,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:00,149 INFO:     Epoch: 10
2023-01-05 13:58:02,270 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46617178519566854, 'Total loss': 0.46617178519566854} | train loss {'Reaction outcome loss': 0.4692868034227117, 'Total loss': 0.4692868034227117}
2023-01-05 13:58:02,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:02,271 INFO:     Epoch: 11
2023-01-05 13:58:04,434 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4723454385995865, 'Total loss': 0.4723454385995865} | train loss {'Reaction outcome loss': 0.4674215989222791, 'Total loss': 0.4674215989222791}
2023-01-05 13:58:04,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:04,435 INFO:     Epoch: 12
2023-01-05 13:58:06,591 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4595559726158778, 'Total loss': 0.4595559726158778} | train loss {'Reaction outcome loss': 0.4621985313327362, 'Total loss': 0.4621985313327362}
2023-01-05 13:58:06,591 INFO:     Found new best model at epoch 12
2023-01-05 13:58:06,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:06,592 INFO:     Epoch: 13
2023-01-05 13:58:08,728 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4573361357053121, 'Total loss': 0.4573361357053121} | train loss {'Reaction outcome loss': 0.45597182268418535, 'Total loss': 0.45597182268418535}
2023-01-05 13:58:08,728 INFO:     Found new best model at epoch 13
2023-01-05 13:58:08,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:08,730 INFO:     Epoch: 14
2023-01-05 13:58:10,890 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4456831673781077, 'Total loss': 0.4456831673781077} | train loss {'Reaction outcome loss': 0.4554739980485992, 'Total loss': 0.4554739980485992}
2023-01-05 13:58:10,890 INFO:     Found new best model at epoch 14
2023-01-05 13:58:10,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:10,891 INFO:     Epoch: 15
2023-01-05 13:58:13,032 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47064877847830455, 'Total loss': 0.47064877847830455} | train loss {'Reaction outcome loss': 0.45491618575001863, 'Total loss': 0.45491618575001863}
2023-01-05 13:58:13,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:13,032 INFO:     Epoch: 16
2023-01-05 13:58:15,200 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42686977684497834, 'Total loss': 0.42686977684497834} | train loss {'Reaction outcome loss': 0.44827921016553446, 'Total loss': 0.44827921016553446}
2023-01-05 13:58:15,200 INFO:     Found new best model at epoch 16
2023-01-05 13:58:15,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:15,201 INFO:     Epoch: 17
2023-01-05 13:58:17,358 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4424300382534663, 'Total loss': 0.4424300382534663} | train loss {'Reaction outcome loss': 0.44020278066180757, 'Total loss': 0.44020278066180757}
2023-01-05 13:58:17,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:17,359 INFO:     Epoch: 18
2023-01-05 13:58:19,513 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47872405449549355, 'Total loss': 0.47872405449549355} | train loss {'Reaction outcome loss': 0.43466534044431604, 'Total loss': 0.43466534044431604}
2023-01-05 13:58:19,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:19,514 INFO:     Epoch: 19
2023-01-05 13:58:21,668 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4447362244129181, 'Total loss': 0.4447362244129181} | train loss {'Reaction outcome loss': 0.4337172950010585, 'Total loss': 0.4337172950010585}
2023-01-05 13:58:21,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:21,669 INFO:     Epoch: 20
2023-01-05 13:58:23,814 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46290245056152346, 'Total loss': 0.46290245056152346} | train loss {'Reaction outcome loss': 0.43604115548371003, 'Total loss': 0.43604115548371003}
2023-01-05 13:58:23,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:23,814 INFO:     Epoch: 21
2023-01-05 13:58:25,980 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4241516133149465, 'Total loss': 0.4241516133149465} | train loss {'Reaction outcome loss': 0.4272530273115937, 'Total loss': 0.4272530273115937}
2023-01-05 13:58:25,980 INFO:     Found new best model at epoch 21
2023-01-05 13:58:25,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:25,982 INFO:     Epoch: 22
2023-01-05 13:58:28,204 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4298604965209961, 'Total loss': 0.4298604965209961} | train loss {'Reaction outcome loss': 0.42680054729925876, 'Total loss': 0.42680054729925876}
2023-01-05 13:58:28,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:28,204 INFO:     Epoch: 23
2023-01-05 13:58:30,390 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4399249235788981, 'Total loss': 0.4399249235788981} | train loss {'Reaction outcome loss': 0.4241899513000807, 'Total loss': 0.4241899513000807}
2023-01-05 13:58:30,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:30,391 INFO:     Epoch: 24
2023-01-05 13:58:32,605 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.495413397749265, 'Total loss': 0.495413397749265} | train loss {'Reaction outcome loss': 0.41781587698674033, 'Total loss': 0.41781587698674033}
2023-01-05 13:58:32,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:32,605 INFO:     Epoch: 25
2023-01-05 13:58:34,799 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4282646358013153, 'Total loss': 0.4282646358013153} | train loss {'Reaction outcome loss': 0.41696919074309047, 'Total loss': 0.41696919074309047}
2023-01-05 13:58:34,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:34,800 INFO:     Epoch: 26
2023-01-05 13:58:36,981 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42105355163415276, 'Total loss': 0.42105355163415276} | train loss {'Reaction outcome loss': 0.41515584925925225, 'Total loss': 0.41515584925925225}
2023-01-05 13:58:36,981 INFO:     Found new best model at epoch 26
2023-01-05 13:58:36,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:36,982 INFO:     Epoch: 27
2023-01-05 13:58:39,196 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42928467442591983, 'Total loss': 0.42928467442591983} | train loss {'Reaction outcome loss': 0.41246861542585184, 'Total loss': 0.41246861542585184}
2023-01-05 13:58:39,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:39,196 INFO:     Epoch: 28
2023-01-05 13:58:41,401 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42456906537214917, 'Total loss': 0.42456906537214917} | train loss {'Reaction outcome loss': 0.40100497605221724, 'Total loss': 0.40100497605221724}
2023-01-05 13:58:41,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:41,401 INFO:     Epoch: 29
2023-01-05 13:58:43,557 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.479067325592041, 'Total loss': 0.479067325592041} | train loss {'Reaction outcome loss': 0.4051577152610095, 'Total loss': 0.4051577152610095}
2023-01-05 13:58:43,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:43,557 INFO:     Epoch: 30
2023-01-05 13:58:45,729 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42227657238642374, 'Total loss': 0.42227657238642374} | train loss {'Reaction outcome loss': 0.4029568281578089, 'Total loss': 0.4029568281578089}
2023-01-05 13:58:45,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:45,730 INFO:     Epoch: 31
2023-01-05 13:58:47,886 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44170629580815635, 'Total loss': 0.44170629580815635} | train loss {'Reaction outcome loss': 0.39806897962546867, 'Total loss': 0.39806897962546867}
2023-01-05 13:58:47,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:47,887 INFO:     Epoch: 32
2023-01-05 13:58:50,083 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4189546763896942, 'Total loss': 0.4189546763896942} | train loss {'Reaction outcome loss': 0.39475393487394456, 'Total loss': 0.39475393487394456}
2023-01-05 13:58:50,083 INFO:     Found new best model at epoch 32
2023-01-05 13:58:50,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:50,084 INFO:     Epoch: 33
2023-01-05 13:58:52,237 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3959947238365809, 'Total loss': 0.3959947238365809} | train loss {'Reaction outcome loss': 0.40264158914594544, 'Total loss': 0.40264158914594544}
2023-01-05 13:58:52,238 INFO:     Found new best model at epoch 33
2023-01-05 13:58:52,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:52,239 INFO:     Epoch: 34
2023-01-05 13:58:54,392 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4422224978605906, 'Total loss': 0.4422224978605906} | train loss {'Reaction outcome loss': 0.41622163508208876, 'Total loss': 0.41622163508208876}
2023-01-05 13:58:54,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:54,392 INFO:     Epoch: 35
2023-01-05 13:58:56,529 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41758669378856816, 'Total loss': 0.41758669378856816} | train loss {'Reaction outcome loss': 0.393149450495991, 'Total loss': 0.393149450495991}
2023-01-05 13:58:56,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:56,531 INFO:     Epoch: 36
2023-01-05 13:58:58,676 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4399590914448102, 'Total loss': 0.4399590914448102} | train loss {'Reaction outcome loss': 0.3860913750046541, 'Total loss': 0.3860913750046541}
2023-01-05 13:58:58,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:58:58,677 INFO:     Epoch: 37
2023-01-05 13:59:00,807 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42952173252900444, 'Total loss': 0.42952173252900444} | train loss {'Reaction outcome loss': 0.3784759589344385, 'Total loss': 0.3784759589344385}
2023-01-05 13:59:00,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:00,808 INFO:     Epoch: 38
2023-01-05 13:59:02,955 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4202602098385493, 'Total loss': 0.4202602098385493} | train loss {'Reaction outcome loss': 0.37755061962578085, 'Total loss': 0.37755061962578085}
2023-01-05 13:59:02,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:02,956 INFO:     Epoch: 39
2023-01-05 13:59:05,104 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39576321343580884, 'Total loss': 0.39576321343580884} | train loss {'Reaction outcome loss': 0.38563216323761834, 'Total loss': 0.38563216323761834}
2023-01-05 13:59:05,104 INFO:     Found new best model at epoch 39
2023-01-05 13:59:05,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:05,105 INFO:     Epoch: 40
2023-01-05 13:59:07,241 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43860333661238354, 'Total loss': 0.43860333661238354} | train loss {'Reaction outcome loss': 0.43543815515611484, 'Total loss': 0.43543815515611484}
2023-01-05 13:59:07,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:07,241 INFO:     Epoch: 41
2023-01-05 13:59:09,379 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4446024010578791, 'Total loss': 0.4446024010578791} | train loss {'Reaction outcome loss': 0.3760938891462739, 'Total loss': 0.3760938891462739}
2023-01-05 13:59:09,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:09,379 INFO:     Epoch: 42
2023-01-05 13:59:11,514 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.399212787548701, 'Total loss': 0.399212787548701} | train loss {'Reaction outcome loss': 0.36293513728373183, 'Total loss': 0.36293513728373183}
2023-01-05 13:59:11,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:11,514 INFO:     Epoch: 43
2023-01-05 13:59:13,664 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41527074078718823, 'Total loss': 0.41527074078718823} | train loss {'Reaction outcome loss': 0.3627998040891185, 'Total loss': 0.3627998040891185}
2023-01-05 13:59:13,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:13,664 INFO:     Epoch: 44
2023-01-05 13:59:15,804 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.428200497229894, 'Total loss': 0.428200497229894} | train loss {'Reaction outcome loss': 0.3577305413276443, 'Total loss': 0.3577305413276443}
2023-01-05 13:59:15,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:15,805 INFO:     Epoch: 45
2023-01-05 13:59:17,949 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3870227664709091, 'Total loss': 0.3870227664709091} | train loss {'Reaction outcome loss': 0.354541776952354, 'Total loss': 0.354541776952354}
2023-01-05 13:59:17,949 INFO:     Found new best model at epoch 45
2023-01-05 13:59:17,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:17,950 INFO:     Epoch: 46
2023-01-05 13:59:20,081 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42887804508209226, 'Total loss': 0.42887804508209226} | train loss {'Reaction outcome loss': 0.3457245620885405, 'Total loss': 0.3457245620885405}
2023-01-05 13:59:20,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:20,081 INFO:     Epoch: 47
2023-01-05 13:59:22,247 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43264249463876087, 'Total loss': 0.43264249463876087} | train loss {'Reaction outcome loss': 0.3420664553118843, 'Total loss': 0.3420664553118843}
2023-01-05 13:59:22,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:22,247 INFO:     Epoch: 48
2023-01-05 13:59:24,411 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4634672373533249, 'Total loss': 0.4634672373533249} | train loss {'Reaction outcome loss': 0.3663750551910936, 'Total loss': 0.3663750551910936}
2023-01-05 13:59:24,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:24,412 INFO:     Epoch: 49
2023-01-05 13:59:26,573 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39438999195893604, 'Total loss': 0.39438999195893604} | train loss {'Reaction outcome loss': 0.33842605826100847, 'Total loss': 0.33842605826100847}
2023-01-05 13:59:26,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:26,573 INFO:     Epoch: 50
2023-01-05 13:59:28,709 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4000732143719991, 'Total loss': 0.4000732143719991} | train loss {'Reaction outcome loss': 0.3324660842787336, 'Total loss': 0.3324660842787336}
2023-01-05 13:59:28,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:28,710 INFO:     Epoch: 51
2023-01-05 13:59:30,831 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4101437310377757, 'Total loss': 0.4101437310377757} | train loss {'Reaction outcome loss': 0.3346678299738256, 'Total loss': 0.3346678299738256}
2023-01-05 13:59:30,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:30,832 INFO:     Epoch: 52
2023-01-05 13:59:32,969 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41972080171108245, 'Total loss': 0.41972080171108245} | train loss {'Reaction outcome loss': 0.3293680164299102, 'Total loss': 0.3293680164299102}
2023-01-05 13:59:32,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:32,970 INFO:     Epoch: 53
2023-01-05 13:59:35,103 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40893209824959437, 'Total loss': 0.40893209824959437} | train loss {'Reaction outcome loss': 0.3267130164793976, 'Total loss': 0.3267130164793976}
2023-01-05 13:59:35,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:35,103 INFO:     Epoch: 54
2023-01-05 13:59:37,235 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4076092624415954, 'Total loss': 0.4076092624415954} | train loss {'Reaction outcome loss': 0.3359229791963446, 'Total loss': 0.3359229791963446}
2023-01-05 13:59:37,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:37,236 INFO:     Epoch: 55
2023-01-05 13:59:39,371 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3854217201471329, 'Total loss': 0.3854217201471329} | train loss {'Reaction outcome loss': 0.38713168611739884, 'Total loss': 0.38713168611739884}
2023-01-05 13:59:39,372 INFO:     Found new best model at epoch 55
2023-01-05 13:59:39,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:39,373 INFO:     Epoch: 56
2023-01-05 13:59:41,504 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41038472255071007, 'Total loss': 0.41038472255071007} | train loss {'Reaction outcome loss': 0.33272737402644387, 'Total loss': 0.33272737402644387}
2023-01-05 13:59:41,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:41,505 INFO:     Epoch: 57
2023-01-05 13:59:43,653 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4063082496325175, 'Total loss': 0.4063082496325175} | train loss {'Reaction outcome loss': 0.32010866569328134, 'Total loss': 0.32010866569328134}
2023-01-05 13:59:43,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:43,654 INFO:     Epoch: 58
2023-01-05 13:59:45,803 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3629600465297699, 'Total loss': 0.3629600465297699} | train loss {'Reaction outcome loss': 0.322401004023445, 'Total loss': 0.322401004023445}
2023-01-05 13:59:45,803 INFO:     Found new best model at epoch 58
2023-01-05 13:59:45,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:45,805 INFO:     Epoch: 59
2023-01-05 13:59:47,945 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38924049685398737, 'Total loss': 0.38924049685398737} | train loss {'Reaction outcome loss': 0.30862541359417356, 'Total loss': 0.30862541359417356}
2023-01-05 13:59:47,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:47,946 INFO:     Epoch: 60
2023-01-05 13:59:50,101 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4164015606045723, 'Total loss': 0.4164015606045723} | train loss {'Reaction outcome loss': 0.3057144631794485, 'Total loss': 0.3057144631794485}
2023-01-05 13:59:50,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:50,101 INFO:     Epoch: 61
2023-01-05 13:59:52,217 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38900229533513386, 'Total loss': 0.38900229533513386} | train loss {'Reaction outcome loss': 0.30143673906939616, 'Total loss': 0.30143673906939616}
2023-01-05 13:59:52,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:52,217 INFO:     Epoch: 62
2023-01-05 13:59:54,364 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38512355436881385, 'Total loss': 0.38512355436881385} | train loss {'Reaction outcome loss': 0.30293956921989285, 'Total loss': 0.30293956921989285}
2023-01-05 13:59:54,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:54,364 INFO:     Epoch: 63
2023-01-05 13:59:56,531 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3838204503059387, 'Total loss': 0.3838204503059387} | train loss {'Reaction outcome loss': 0.29705600990522385, 'Total loss': 0.29705600990522385}
2023-01-05 13:59:56,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:56,531 INFO:     Epoch: 64
2023-01-05 13:59:58,723 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4174709737300873, 'Total loss': 0.4174709737300873} | train loss {'Reaction outcome loss': 0.29195046808192693, 'Total loss': 0.29195046808192693}
2023-01-05 13:59:58,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 13:59:58,723 INFO:     Epoch: 65
2023-01-05 14:00:00,898 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4490042934815089, 'Total loss': 0.4490042934815089} | train loss {'Reaction outcome loss': 0.31785162125268707, 'Total loss': 0.31785162125268707}
2023-01-05 14:00:00,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:00,898 INFO:     Epoch: 66
2023-01-05 14:00:03,034 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4844514946142832, 'Total loss': 0.4844514946142832} | train loss {'Reaction outcome loss': 0.3621889526375394, 'Total loss': 0.3621889526375394}
2023-01-05 14:00:03,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:03,035 INFO:     Epoch: 67
2023-01-05 14:00:05,173 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38145475685596464, 'Total loss': 0.38145475685596464} | train loss {'Reaction outcome loss': 0.3361167019634656, 'Total loss': 0.3361167019634656}
2023-01-05 14:00:05,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:05,174 INFO:     Epoch: 68
2023-01-05 14:00:07,323 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37231862246990205, 'Total loss': 0.37231862246990205} | train loss {'Reaction outcome loss': 0.2944773583729171, 'Total loss': 0.2944773583729171}
2023-01-05 14:00:07,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:07,323 INFO:     Epoch: 69
2023-01-05 14:00:09,482 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3955489243070284, 'Total loss': 0.3955489243070284} | train loss {'Reaction outcome loss': 0.2944430465260297, 'Total loss': 0.2944430465260297}
2023-01-05 14:00:09,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:09,483 INFO:     Epoch: 70
2023-01-05 14:00:11,644 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4612945238749186, 'Total loss': 0.4612945238749186} | train loss {'Reaction outcome loss': 0.29117388159468555, 'Total loss': 0.29117388159468555}
2023-01-05 14:00:11,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:11,644 INFO:     Epoch: 71
2023-01-05 14:00:13,808 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37840170562267306, 'Total loss': 0.37840170562267306} | train loss {'Reaction outcome loss': 0.32102933130480105, 'Total loss': 0.32102933130480105}
2023-01-05 14:00:13,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:13,808 INFO:     Epoch: 72
2023-01-05 14:00:15,967 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42551019887129465, 'Total loss': 0.42551019887129465} | train loss {'Reaction outcome loss': 0.28608694117840217, 'Total loss': 0.28608694117840217}
2023-01-05 14:00:15,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:15,967 INFO:     Epoch: 73
2023-01-05 14:00:18,122 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44396104117234547, 'Total loss': 0.44396104117234547} | train loss {'Reaction outcome loss': 0.2868268656502419, 'Total loss': 0.2868268656502419}
2023-01-05 14:00:18,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:18,122 INFO:     Epoch: 74
2023-01-05 14:00:20,267 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4078637659549713, 'Total loss': 0.4078637659549713} | train loss {'Reaction outcome loss': 0.3043402076793322, 'Total loss': 0.3043402076793322}
2023-01-05 14:00:20,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:20,267 INFO:     Epoch: 75
2023-01-05 14:00:22,419 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3856368836015463, 'Total loss': 0.3856368836015463} | train loss {'Reaction outcome loss': 0.2850404531775933, 'Total loss': 0.2850404531775933}
2023-01-05 14:00:22,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:22,419 INFO:     Epoch: 76
2023-01-05 14:00:24,550 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4195445607105891, 'Total loss': 0.4195445607105891} | train loss {'Reaction outcome loss': 0.2783675541480382, 'Total loss': 0.2783675541480382}
2023-01-05 14:00:24,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:24,550 INFO:     Epoch: 77
2023-01-05 14:00:26,708 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40794335802396137, 'Total loss': 0.40794335802396137} | train loss {'Reaction outcome loss': 0.27767625191937323, 'Total loss': 0.27767625191937323}
2023-01-05 14:00:26,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:26,708 INFO:     Epoch: 78
2023-01-05 14:00:28,854 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39175183450182277, 'Total loss': 0.39175183450182277} | train loss {'Reaction outcome loss': 0.27710495232874394, 'Total loss': 0.27710495232874394}
2023-01-05 14:00:28,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:28,855 INFO:     Epoch: 79
2023-01-05 14:00:30,996 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3604036549727122, 'Total loss': 0.3604036549727122} | train loss {'Reaction outcome loss': 0.2756628623296358, 'Total loss': 0.2756628623296358}
2023-01-05 14:00:30,996 INFO:     Found new best model at epoch 79
2023-01-05 14:00:30,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:30,998 INFO:     Epoch: 80
2023-01-05 14:00:33,151 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3901067723830541, 'Total loss': 0.3901067723830541} | train loss {'Reaction outcome loss': 0.276241066015285, 'Total loss': 0.276241066015285}
2023-01-05 14:00:33,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:33,151 INFO:     Epoch: 81
2023-01-05 14:00:35,316 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.36142864227294924, 'Total loss': 0.36142864227294924} | train loss {'Reaction outcome loss': 0.2705838644405694, 'Total loss': 0.2705838644405694}
2023-01-05 14:00:35,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:35,316 INFO:     Epoch: 82
2023-01-05 14:00:37,458 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40420444707075753, 'Total loss': 0.40420444707075753} | train loss {'Reaction outcome loss': 0.26842492079004593, 'Total loss': 0.26842492079004593}
2023-01-05 14:00:37,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:37,458 INFO:     Epoch: 83
2023-01-05 14:00:39,584 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41128124396006266, 'Total loss': 0.41128124396006266} | train loss {'Reaction outcome loss': 0.2689152995872723, 'Total loss': 0.2689152995872723}
2023-01-05 14:00:39,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:39,586 INFO:     Epoch: 84
2023-01-05 14:00:41,718 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.35705700715382893, 'Total loss': 0.35705700715382893} | train loss {'Reaction outcome loss': 0.2656524164502617, 'Total loss': 0.2656524164502617}
2023-01-05 14:00:41,718 INFO:     Found new best model at epoch 84
2023-01-05 14:00:41,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:41,719 INFO:     Epoch: 85
2023-01-05 14:00:43,829 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3658971925576528, 'Total loss': 0.3658971925576528} | train loss {'Reaction outcome loss': 0.2957358746991857, 'Total loss': 0.2957358746991857}
2023-01-05 14:00:43,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:43,830 INFO:     Epoch: 86
2023-01-05 14:00:45,972 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4004532516002655, 'Total loss': 0.4004532516002655} | train loss {'Reaction outcome loss': 0.31396831213958093, 'Total loss': 0.31396831213958093}
2023-01-05 14:00:45,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:45,973 INFO:     Epoch: 87
2023-01-05 14:00:48,109 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3841530253489812, 'Total loss': 0.3841530253489812} | train loss {'Reaction outcome loss': 0.262809220479803, 'Total loss': 0.262809220479803}
2023-01-05 14:00:48,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:48,109 INFO:     Epoch: 88
2023-01-05 14:00:50,260 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40826945900917055, 'Total loss': 0.40826945900917055} | train loss {'Reaction outcome loss': 0.2618178118697698, 'Total loss': 0.2618178118697698}
2023-01-05 14:00:50,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:50,260 INFO:     Epoch: 89
2023-01-05 14:00:52,410 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3979540874560674, 'Total loss': 0.3979540874560674} | train loss {'Reaction outcome loss': 0.257545962413449, 'Total loss': 0.257545962413449}
2023-01-05 14:00:52,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:52,410 INFO:     Epoch: 90
2023-01-05 14:00:54,553 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45944827497005464, 'Total loss': 0.45944827497005464} | train loss {'Reaction outcome loss': 0.261432515207781, 'Total loss': 0.261432515207781}
2023-01-05 14:00:54,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:54,553 INFO:     Epoch: 91
2023-01-05 14:00:56,703 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3971828669309616, 'Total loss': 0.3971828669309616} | train loss {'Reaction outcome loss': 0.26149548535223416, 'Total loss': 0.26149548535223416}
2023-01-05 14:00:56,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:56,703 INFO:     Epoch: 92
2023-01-05 14:00:58,832 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40161670943101246, 'Total loss': 0.40161670943101246} | train loss {'Reaction outcome loss': 0.26548017937159823, 'Total loss': 0.26548017937159823}
2023-01-05 14:00:58,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:00:58,832 INFO:     Epoch: 93
2023-01-05 14:01:00,969 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37781509856383005, 'Total loss': 0.37781509856383005} | train loss {'Reaction outcome loss': 0.2569321211818876, 'Total loss': 0.2569321211818876}
2023-01-05 14:01:00,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:00,969 INFO:     Epoch: 94
2023-01-05 14:01:03,111 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3736532273702323, 'Total loss': 0.3736532273702323} | train loss {'Reaction outcome loss': 0.2578046649535848, 'Total loss': 0.2578046649535848}
2023-01-05 14:01:03,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:03,112 INFO:     Epoch: 95
2023-01-05 14:01:05,249 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4211086850613356, 'Total loss': 0.4211086850613356} | train loss {'Reaction outcome loss': 0.24997840012519443, 'Total loss': 0.24997840012519443}
2023-01-05 14:01:05,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:05,250 INFO:     Epoch: 96
2023-01-05 14:01:07,350 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3940492744247119, 'Total loss': 0.3940492744247119} | train loss {'Reaction outcome loss': 0.2575714811075317, 'Total loss': 0.2575714811075317}
2023-01-05 14:01:07,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:07,350 INFO:     Epoch: 97
2023-01-05 14:01:09,484 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46753760874271394, 'Total loss': 0.46753760874271394} | train loss {'Reaction outcome loss': 0.2560282301210859, 'Total loss': 0.2560282301210859}
2023-01-05 14:01:09,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:09,484 INFO:     Epoch: 98
2023-01-05 14:01:11,598 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44673385520776115, 'Total loss': 0.44673385520776115} | train loss {'Reaction outcome loss': 0.25258341220720415, 'Total loss': 0.25258341220720415}
2023-01-05 14:01:11,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:11,598 INFO:     Epoch: 99
2023-01-05 14:01:13,743 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4156461477279663, 'Total loss': 0.4156461477279663} | train loss {'Reaction outcome loss': 0.2602951845949882, 'Total loss': 0.2602951845949882}
2023-01-05 14:01:13,743 INFO:     Best model found after epoch 85 of 100.
2023-01-05 14:01:13,743 INFO:   Done with stage: TRAINING
2023-01-05 14:01:13,743 INFO:   Starting stage: EVALUATION
2023-01-05 14:01:13,874 INFO:   Done with stage: EVALUATION
2023-01-05 14:01:13,874 INFO:   Leaving out SEQ value Fold_6
2023-01-05 14:01:13,886 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 14:01:13,887 INFO:   Starting stage: FEATURE SCALING
2023-01-05 14:01:14,526 INFO:   Done with stage: FEATURE SCALING
2023-01-05 14:01:14,526 INFO:   Starting stage: SCALING TARGETS
2023-01-05 14:01:14,593 INFO:   Done with stage: SCALING TARGETS
2023-01-05 14:01:14,593 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:01:14,593 INFO:     No hyperparam tuning for this model
2023-01-05 14:01:14,593 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:01:14,593 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 14:01:14,594 INFO:     None feature selector for col prot
2023-01-05 14:01:14,594 INFO:     None feature selector for col prot
2023-01-05 14:01:14,594 INFO:     None feature selector for col prot
2023-01-05 14:01:14,595 INFO:     None feature selector for col chem
2023-01-05 14:01:14,595 INFO:     None feature selector for col chem
2023-01-05 14:01:14,595 INFO:     None feature selector for col chem
2023-01-05 14:01:14,595 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 14:01:14,595 INFO:   Starting stage: BUILD MODEL
2023-01-05 14:01:14,596 INFO:     Number of params in model 72901
2023-01-05 14:01:14,599 INFO:   Done with stage: BUILD MODEL
2023-01-05 14:01:14,599 INFO:   Starting stage: TRAINING
2023-01-05 14:01:14,660 INFO:     Val loss before train {'Reaction outcome loss': 1.0111575285593668, 'Total loss': 1.0111575285593668}
2023-01-05 14:01:14,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:14,660 INFO:     Epoch: 0
2023-01-05 14:01:16,804 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8188383022944132, 'Total loss': 0.8188383022944132} | train loss {'Reaction outcome loss': 0.9025911977144785, 'Total loss': 0.9025911977144785}
2023-01-05 14:01:16,805 INFO:     Found new best model at epoch 0
2023-01-05 14:01:16,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:16,806 INFO:     Epoch: 1
2023-01-05 14:01:18,971 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6181066731611887, 'Total loss': 0.6181066731611887} | train loss {'Reaction outcome loss': 0.7085361090162601, 'Total loss': 0.7085361090162601}
2023-01-05 14:01:18,971 INFO:     Found new best model at epoch 1
2023-01-05 14:01:18,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:18,972 INFO:     Epoch: 2
2023-01-05 14:01:21,135 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5618778089682261, 'Total loss': 0.5618778089682261} | train loss {'Reaction outcome loss': 0.5813810115794412, 'Total loss': 0.5813810115794412}
2023-01-05 14:01:21,135 INFO:     Found new best model at epoch 2
2023-01-05 14:01:21,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:21,136 INFO:     Epoch: 3
2023-01-05 14:01:23,293 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5195417006810507, 'Total loss': 0.5195417006810507} | train loss {'Reaction outcome loss': 0.5394656833005727, 'Total loss': 0.5394656833005727}
2023-01-05 14:01:23,294 INFO:     Found new best model at epoch 3
2023-01-05 14:01:23,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:23,295 INFO:     Epoch: 4
2023-01-05 14:01:25,459 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5256691257158915, 'Total loss': 0.5256691257158915} | train loss {'Reaction outcome loss': 0.5199858266524029, 'Total loss': 0.5199858266524029}
2023-01-05 14:01:25,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:25,460 INFO:     Epoch: 5
2023-01-05 14:01:27,608 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5569679836432139, 'Total loss': 0.5569679836432139} | train loss {'Reaction outcome loss': 0.5005839747857531, 'Total loss': 0.5005839747857531}
2023-01-05 14:01:27,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:27,608 INFO:     Epoch: 6
2023-01-05 14:01:29,548 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4924590895573298, 'Total loss': 0.4924590895573298} | train loss {'Reaction outcome loss': 0.4938524981913584, 'Total loss': 0.4938524981913584}
2023-01-05 14:01:29,548 INFO:     Found new best model at epoch 6
2023-01-05 14:01:29,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:29,549 INFO:     Epoch: 7
2023-01-05 14:01:31,706 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49843979477882383, 'Total loss': 0.49843979477882383} | train loss {'Reaction outcome loss': 0.48382528282244713, 'Total loss': 0.48382528282244713}
2023-01-05 14:01:31,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:31,706 INFO:     Epoch: 8
2023-01-05 14:01:33,867 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5070443650086721, 'Total loss': 0.5070443650086721} | train loss {'Reaction outcome loss': 0.4790431747905614, 'Total loss': 0.4790431747905614}
2023-01-05 14:01:33,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:33,867 INFO:     Epoch: 9
2023-01-05 14:01:36,042 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4809613029162089, 'Total loss': 0.4809613029162089} | train loss {'Reaction outcome loss': 0.46873344023735514, 'Total loss': 0.46873344023735514}
2023-01-05 14:01:36,043 INFO:     Found new best model at epoch 9
2023-01-05 14:01:36,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:36,044 INFO:     Epoch: 10
2023-01-05 14:01:38,198 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5107467561960221, 'Total loss': 0.5107467561960221} | train loss {'Reaction outcome loss': 0.46614593262061316, 'Total loss': 0.46614593262061316}
2023-01-05 14:01:38,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:38,198 INFO:     Epoch: 11
2023-01-05 14:01:40,353 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4780421217282613, 'Total loss': 0.4780421217282613} | train loss {'Reaction outcome loss': 0.45652880608389956, 'Total loss': 0.45652880608389956}
2023-01-05 14:01:40,353 INFO:     Found new best model at epoch 11
2023-01-05 14:01:40,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:40,355 INFO:     Epoch: 12
2023-01-05 14:01:42,519 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4807249441742897, 'Total loss': 0.4807249441742897} | train loss {'Reaction outcome loss': 0.4555529960118476, 'Total loss': 0.4555529960118476}
2023-01-05 14:01:42,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:42,519 INFO:     Epoch: 13
2023-01-05 14:01:44,692 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49542100032170616, 'Total loss': 0.49542100032170616} | train loss {'Reaction outcome loss': 0.44921202390094955, 'Total loss': 0.44921202390094955}
2023-01-05 14:01:44,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:44,693 INFO:     Epoch: 14
2023-01-05 14:01:46,854 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48545751472314197, 'Total loss': 0.48545751472314197} | train loss {'Reaction outcome loss': 0.4432118787877396, 'Total loss': 0.4432118787877396}
2023-01-05 14:01:46,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:46,854 INFO:     Epoch: 15
2023-01-05 14:01:49,021 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46617034673690794, 'Total loss': 0.46617034673690794} | train loss {'Reaction outcome loss': 0.43815511664113416, 'Total loss': 0.43815511664113416}
2023-01-05 14:01:49,022 INFO:     Found new best model at epoch 15
2023-01-05 14:01:49,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:49,023 INFO:     Epoch: 16
2023-01-05 14:01:51,164 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4528067390124003, 'Total loss': 0.4528067390124003} | train loss {'Reaction outcome loss': 0.43626289411249575, 'Total loss': 0.43626289411249575}
2023-01-05 14:01:51,165 INFO:     Found new best model at epoch 16
2023-01-05 14:01:51,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:51,166 INFO:     Epoch: 17
2023-01-05 14:01:53,329 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46271921197573346, 'Total loss': 0.46271921197573346} | train loss {'Reaction outcome loss': 0.4274229616303306, 'Total loss': 0.4274229616303306}
2023-01-05 14:01:53,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:53,329 INFO:     Epoch: 18
2023-01-05 14:01:55,484 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47434072693188983, 'Total loss': 0.47434072693188983} | train loss {'Reaction outcome loss': 0.42383063942301574, 'Total loss': 0.42383063942301574}
2023-01-05 14:01:55,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:55,485 INFO:     Epoch: 19
2023-01-05 14:01:57,645 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49163790543874103, 'Total loss': 0.49163790543874103} | train loss {'Reaction outcome loss': 0.41938298063803237, 'Total loss': 0.41938298063803237}
2023-01-05 14:01:57,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:57,646 INFO:     Epoch: 20
2023-01-05 14:01:59,817 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4553757429122925, 'Total loss': 0.4553757429122925} | train loss {'Reaction outcome loss': 0.4165255383786742, 'Total loss': 0.4165255383786742}
2023-01-05 14:01:59,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:01:59,817 INFO:     Epoch: 21
2023-01-05 14:02:01,980 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4614160418510437, 'Total loss': 0.4614160418510437} | train loss {'Reaction outcome loss': 0.41273004741875274, 'Total loss': 0.41273004741875274}
2023-01-05 14:02:01,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:01,980 INFO:     Epoch: 22
2023-01-05 14:02:04,134 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4525085985660553, 'Total loss': 0.4525085985660553} | train loss {'Reaction outcome loss': 0.4123263093861432, 'Total loss': 0.4123263093861432}
2023-01-05 14:02:04,134 INFO:     Found new best model at epoch 22
2023-01-05 14:02:04,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:04,136 INFO:     Epoch: 23
2023-01-05 14:02:06,313 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44998086591561637, 'Total loss': 0.44998086591561637} | train loss {'Reaction outcome loss': 0.40571025331313, 'Total loss': 0.40571025331313}
2023-01-05 14:02:06,313 INFO:     Found new best model at epoch 23
2023-01-05 14:02:06,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:06,315 INFO:     Epoch: 24
2023-01-05 14:02:08,471 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4494696100552877, 'Total loss': 0.4494696100552877} | train loss {'Reaction outcome loss': 0.3994410338707349, 'Total loss': 0.3994410338707349}
2023-01-05 14:02:08,471 INFO:     Found new best model at epoch 24
2023-01-05 14:02:08,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:08,472 INFO:     Epoch: 25
2023-01-05 14:02:10,640 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44016746679941815, 'Total loss': 0.44016746679941815} | train loss {'Reaction outcome loss': 0.3957988625452837, 'Total loss': 0.3957988625452837}
2023-01-05 14:02:10,640 INFO:     Found new best model at epoch 25
2023-01-05 14:02:10,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:10,642 INFO:     Epoch: 26
2023-01-05 14:02:12,812 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4531701693932215, 'Total loss': 0.4531701693932215} | train loss {'Reaction outcome loss': 0.39405632839413757, 'Total loss': 0.39405632839413757}
2023-01-05 14:02:12,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:12,812 INFO:     Epoch: 27
2023-01-05 14:02:14,974 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42989272872606915, 'Total loss': 0.42989272872606915} | train loss {'Reaction outcome loss': 0.392614848562096, 'Total loss': 0.392614848562096}
2023-01-05 14:02:14,975 INFO:     Found new best model at epoch 27
2023-01-05 14:02:14,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:14,976 INFO:     Epoch: 28
2023-01-05 14:02:17,123 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46648186842600503, 'Total loss': 0.46648186842600503} | train loss {'Reaction outcome loss': 0.38783056592898246, 'Total loss': 0.38783056592898246}
2023-01-05 14:02:17,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:17,124 INFO:     Epoch: 29
2023-01-05 14:02:19,284 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45810030500094095, 'Total loss': 0.45810030500094095} | train loss {'Reaction outcome loss': 0.3817486329952302, 'Total loss': 0.3817486329952302}
2023-01-05 14:02:19,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:19,284 INFO:     Epoch: 30
2023-01-05 14:02:21,445 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44016523559888204, 'Total loss': 0.44016523559888204} | train loss {'Reaction outcome loss': 0.3768885774463953, 'Total loss': 0.3768885774463953}
2023-01-05 14:02:21,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:21,446 INFO:     Epoch: 31
2023-01-05 14:02:23,604 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41925315459569296, 'Total loss': 0.41925315459569296} | train loss {'Reaction outcome loss': 0.3741112542658076, 'Total loss': 0.3741112542658076}
2023-01-05 14:02:23,604 INFO:     Found new best model at epoch 31
2023-01-05 14:02:23,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:23,606 INFO:     Epoch: 32
2023-01-05 14:02:25,741 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.450442103544871, 'Total loss': 0.450442103544871} | train loss {'Reaction outcome loss': 0.3693721200262166, 'Total loss': 0.3693721200262166}
2023-01-05 14:02:25,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:25,741 INFO:     Epoch: 33
2023-01-05 14:02:27,923 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4401557366053263, 'Total loss': 0.4401557366053263} | train loss {'Reaction outcome loss': 0.3637679064047896, 'Total loss': 0.3637679064047896}
2023-01-05 14:02:27,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:27,924 INFO:     Epoch: 34
2023-01-05 14:02:30,096 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4608719180027644, 'Total loss': 0.4608719180027644} | train loss {'Reaction outcome loss': 0.3675262907567007, 'Total loss': 0.3675262907567007}
2023-01-05 14:02:30,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:30,096 INFO:     Epoch: 35
2023-01-05 14:02:32,249 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4461102902889252, 'Total loss': 0.4461102902889252} | train loss {'Reaction outcome loss': 0.3622991238529071, 'Total loss': 0.3622991238529071}
2023-01-05 14:02:32,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:32,250 INFO:     Epoch: 36
2023-01-05 14:02:34,388 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3998311921954155, 'Total loss': 0.3998311921954155} | train loss {'Reaction outcome loss': 0.36036320980167563, 'Total loss': 0.36036320980167563}
2023-01-05 14:02:34,389 INFO:     Found new best model at epoch 36
2023-01-05 14:02:34,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:34,390 INFO:     Epoch: 37
2023-01-05 14:02:36,519 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4298688381910324, 'Total loss': 0.4298688381910324} | train loss {'Reaction outcome loss': 0.36001525281353547, 'Total loss': 0.36001525281353547}
2023-01-05 14:02:36,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:36,519 INFO:     Epoch: 38
2023-01-05 14:02:38,689 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47171797752380373, 'Total loss': 0.47171797752380373} | train loss {'Reaction outcome loss': 0.3505795321121328, 'Total loss': 0.3505795321121328}
2023-01-05 14:02:38,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:38,689 INFO:     Epoch: 39
2023-01-05 14:02:40,856 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42842229108015695, 'Total loss': 0.42842229108015695} | train loss {'Reaction outcome loss': 0.3471443636295813, 'Total loss': 0.3471443636295813}
2023-01-05 14:02:40,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:40,857 INFO:     Epoch: 40
2023-01-05 14:02:42,990 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4411998808383942, 'Total loss': 0.4411998808383942} | train loss {'Reaction outcome loss': 0.3418865094653966, 'Total loss': 0.3418865094653966}
2023-01-05 14:02:42,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:42,990 INFO:     Epoch: 41
2023-01-05 14:02:45,137 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47683447202046714, 'Total loss': 0.47683447202046714} | train loss {'Reaction outcome loss': 0.3397694661513993, 'Total loss': 0.3397694661513993}
2023-01-05 14:02:45,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:45,138 INFO:     Epoch: 42
2023-01-05 14:02:47,318 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4172276844580968, 'Total loss': 0.4172276844580968} | train loss {'Reaction outcome loss': 0.3436837453220295, 'Total loss': 0.3436837453220295}
2023-01-05 14:02:47,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:47,319 INFO:     Epoch: 43
2023-01-05 14:02:49,491 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4250645786523819, 'Total loss': 0.4250645786523819} | train loss {'Reaction outcome loss': 0.33604975873167336, 'Total loss': 0.33604975873167336}
2023-01-05 14:02:49,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:49,491 INFO:     Epoch: 44
2023-01-05 14:02:51,653 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41328672170639036, 'Total loss': 0.41328672170639036} | train loss {'Reaction outcome loss': 0.33824804040606704, 'Total loss': 0.33824804040606704}
2023-01-05 14:02:51,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:51,653 INFO:     Epoch: 45
2023-01-05 14:02:53,834 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4438183526198069, 'Total loss': 0.4438183526198069} | train loss {'Reaction outcome loss': 0.3314516347049591, 'Total loss': 0.3314516347049591}
2023-01-05 14:02:53,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:53,834 INFO:     Epoch: 46
2023-01-05 14:02:56,022 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3984793504079183, 'Total loss': 0.3984793504079183} | train loss {'Reaction outcome loss': 0.32924523897173175, 'Total loss': 0.32924523897173175}
2023-01-05 14:02:56,022 INFO:     Found new best model at epoch 46
2023-01-05 14:02:56,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:56,024 INFO:     Epoch: 47
2023-01-05 14:02:58,186 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4048201104005178, 'Total loss': 0.4048201104005178} | train loss {'Reaction outcome loss': 0.3241300297235324, 'Total loss': 0.3241300297235324}
2023-01-05 14:02:58,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:02:58,188 INFO:     Epoch: 48
2023-01-05 14:03:00,344 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4551081309715907, 'Total loss': 0.4551081309715907} | train loss {'Reaction outcome loss': 0.3236781444925048, 'Total loss': 0.3236781444925048}
2023-01-05 14:03:00,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:00,344 INFO:     Epoch: 49
2023-01-05 14:03:02,505 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4277914841969808, 'Total loss': 0.4277914841969808} | train loss {'Reaction outcome loss': 0.322985936077278, 'Total loss': 0.322985936077278}
2023-01-05 14:03:02,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:02,506 INFO:     Epoch: 50
2023-01-05 14:03:04,633 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42362886170546216, 'Total loss': 0.42362886170546216} | train loss {'Reaction outcome loss': 0.318411747148321, 'Total loss': 0.318411747148321}
2023-01-05 14:03:04,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:04,633 INFO:     Epoch: 51
2023-01-05 14:03:06,782 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.414495450258255, 'Total loss': 0.414495450258255} | train loss {'Reaction outcome loss': 0.3192417370794267, 'Total loss': 0.3192417370794267}
2023-01-05 14:03:06,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:06,782 INFO:     Epoch: 52
2023-01-05 14:03:08,944 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4023664385080338, 'Total loss': 0.4023664385080338} | train loss {'Reaction outcome loss': 0.3162285352549398, 'Total loss': 0.3162285352549398}
2023-01-05 14:03:08,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:08,944 INFO:     Epoch: 53
2023-01-05 14:03:11,074 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40170797606309255, 'Total loss': 0.40170797606309255} | train loss {'Reaction outcome loss': 0.3085822677744102, 'Total loss': 0.3085822677744102}
2023-01-05 14:03:11,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:11,074 INFO:     Epoch: 54
2023-01-05 14:03:13,190 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38956601222356163, 'Total loss': 0.38956601222356163} | train loss {'Reaction outcome loss': 0.3077855613418865, 'Total loss': 0.3077855613418865}
2023-01-05 14:03:13,190 INFO:     Found new best model at epoch 54
2023-01-05 14:03:13,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:13,191 INFO:     Epoch: 55
2023-01-05 14:03:15,330 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4245246847470601, 'Total loss': 0.4245246847470601} | train loss {'Reaction outcome loss': 0.30688127348138966, 'Total loss': 0.30688127348138966}
2023-01-05 14:03:15,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:15,330 INFO:     Epoch: 56
2023-01-05 14:03:17,452 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4220994234085083, 'Total loss': 0.4220994234085083} | train loss {'Reaction outcome loss': 0.30296218404647246, 'Total loss': 0.30296218404647246}
2023-01-05 14:03:17,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:17,453 INFO:     Epoch: 57
2023-01-05 14:03:19,602 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4234158515930176, 'Total loss': 0.4234158515930176} | train loss {'Reaction outcome loss': 0.30623164197382946, 'Total loss': 0.30623164197382946}
2023-01-05 14:03:19,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:19,602 INFO:     Epoch: 58
2023-01-05 14:03:21,736 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4160922249158224, 'Total loss': 0.4160922249158224} | train loss {'Reaction outcome loss': 0.2920662809149883, 'Total loss': 0.2920662809149883}
2023-01-05 14:03:21,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:21,736 INFO:     Epoch: 59
2023-01-05 14:03:23,846 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45121603409449257, 'Total loss': 0.45121603409449257} | train loss {'Reaction outcome loss': 0.2953577687970568, 'Total loss': 0.2953577687970568}
2023-01-05 14:03:23,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:23,846 INFO:     Epoch: 60
2023-01-05 14:03:25,990 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4080082525809606, 'Total loss': 0.4080082525809606} | train loss {'Reaction outcome loss': 0.2951704770703178, 'Total loss': 0.2951704770703178}
2023-01-05 14:03:25,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:25,991 INFO:     Epoch: 61
2023-01-05 14:03:28,140 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4292266398668289, 'Total loss': 0.4292266398668289} | train loss {'Reaction outcome loss': 0.29522404359781357, 'Total loss': 0.29522404359781357}
2023-01-05 14:03:28,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:28,140 INFO:     Epoch: 62
2023-01-05 14:03:30,285 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42904349068800607, 'Total loss': 0.42904349068800607} | train loss {'Reaction outcome loss': 0.29099950622699966, 'Total loss': 0.29099950622699966}
2023-01-05 14:03:30,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:30,285 INFO:     Epoch: 63
2023-01-05 14:03:32,433 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4218565593163172, 'Total loss': 0.4218565593163172} | train loss {'Reaction outcome loss': 0.28756423437100453, 'Total loss': 0.28756423437100453}
2023-01-05 14:03:32,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:32,434 INFO:     Epoch: 64
2023-01-05 14:03:34,601 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3912723829348882, 'Total loss': 0.3912723829348882} | train loss {'Reaction outcome loss': 0.2853569956193762, 'Total loss': 0.2853569956193762}
2023-01-05 14:03:34,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:34,602 INFO:     Epoch: 65
2023-01-05 14:03:36,740 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4163109039266904, 'Total loss': 0.4163109039266904} | train loss {'Reaction outcome loss': 0.27753735525997536, 'Total loss': 0.27753735525997536}
2023-01-05 14:03:36,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:36,740 INFO:     Epoch: 66
2023-01-05 14:03:38,888 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42316340605417885, 'Total loss': 0.42316340605417885} | train loss {'Reaction outcome loss': 0.28322010909607265, 'Total loss': 0.28322010909607265}
2023-01-05 14:03:38,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:38,888 INFO:     Epoch: 67
2023-01-05 14:03:41,044 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41732659141222633, 'Total loss': 0.41732659141222633} | train loss {'Reaction outcome loss': 0.2814672759428136, 'Total loss': 0.2814672759428136}
2023-01-05 14:03:41,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:41,045 INFO:     Epoch: 68
2023-01-05 14:03:43,174 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.385964572429657, 'Total loss': 0.385964572429657} | train loss {'Reaction outcome loss': 0.2876473208250552, 'Total loss': 0.2876473208250552}
2023-01-05 14:03:43,175 INFO:     Found new best model at epoch 68
2023-01-05 14:03:43,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:43,176 INFO:     Epoch: 69
2023-01-05 14:03:45,307 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45986575782299044, 'Total loss': 0.45986575782299044} | train loss {'Reaction outcome loss': 0.2803243598110624, 'Total loss': 0.2803243598110624}
2023-01-05 14:03:45,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:45,307 INFO:     Epoch: 70
2023-01-05 14:03:47,431 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43287806312243143, 'Total loss': 0.43287806312243143} | train loss {'Reaction outcome loss': 0.27746957801080674, 'Total loss': 0.27746957801080674}
2023-01-05 14:03:47,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:47,431 INFO:     Epoch: 71
2023-01-05 14:03:49,597 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39289004877209666, 'Total loss': 0.39289004877209666} | train loss {'Reaction outcome loss': 0.27881322244336887, 'Total loss': 0.27881322244336887}
2023-01-05 14:03:49,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:49,598 INFO:     Epoch: 72
2023-01-05 14:03:51,734 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4036712110042572, 'Total loss': 0.4036712110042572} | train loss {'Reaction outcome loss': 0.27376249233523, 'Total loss': 0.27376249233523}
2023-01-05 14:03:51,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:51,734 INFO:     Epoch: 73
2023-01-05 14:03:53,888 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3955145239830017, 'Total loss': 0.3955145239830017} | train loss {'Reaction outcome loss': 0.2827479386641661, 'Total loss': 0.2827479386641661}
2023-01-05 14:03:53,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:53,889 INFO:     Epoch: 74
2023-01-05 14:03:56,031 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42988571027914685, 'Total loss': 0.42988571027914685} | train loss {'Reaction outcome loss': 0.2796742580158616, 'Total loss': 0.2796742580158616}
2023-01-05 14:03:56,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:56,032 INFO:     Epoch: 75
2023-01-05 14:03:58,174 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43451584776242574, 'Total loss': 0.43451584776242574} | train loss {'Reaction outcome loss': 0.27175252934386585, 'Total loss': 0.27175252934386585}
2023-01-05 14:03:58,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:03:58,174 INFO:     Epoch: 76
2023-01-05 14:04:00,328 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4040806993842125, 'Total loss': 0.4040806993842125} | train loss {'Reaction outcome loss': 0.26057408162685186, 'Total loss': 0.26057408162685186}
2023-01-05 14:04:00,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:00,328 INFO:     Epoch: 77
2023-01-05 14:04:02,482 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39490037262439726, 'Total loss': 0.39490037262439726} | train loss {'Reaction outcome loss': 0.2717501080934537, 'Total loss': 0.2717501080934537}
2023-01-05 14:04:02,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:02,483 INFO:     Epoch: 78
2023-01-05 14:04:04,606 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43001451045274736, 'Total loss': 0.43001451045274736} | train loss {'Reaction outcome loss': 0.26529967501113993, 'Total loss': 0.26529967501113993}
2023-01-05 14:04:04,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:04,607 INFO:     Epoch: 79
2023-01-05 14:04:06,764 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41559982150793073, 'Total loss': 0.41559982150793073} | train loss {'Reaction outcome loss': 0.26470664058835497, 'Total loss': 0.26470664058835497}
2023-01-05 14:04:06,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:06,764 INFO:     Epoch: 80
2023-01-05 14:04:08,921 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4380416552225749, 'Total loss': 0.4380416552225749} | train loss {'Reaction outcome loss': 0.26292943629009197, 'Total loss': 0.26292943629009197}
2023-01-05 14:04:08,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:08,921 INFO:     Epoch: 81
2023-01-05 14:04:11,062 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44081549197435377, 'Total loss': 0.44081549197435377} | train loss {'Reaction outcome loss': 0.26942123399395157, 'Total loss': 0.26942123399395157}
2023-01-05 14:04:11,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:11,063 INFO:     Epoch: 82
2023-01-05 14:04:13,234 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4208511511484782, 'Total loss': 0.4208511511484782} | train loss {'Reaction outcome loss': 0.26216527562763287, 'Total loss': 0.26216527562763287}
2023-01-05 14:04:13,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:13,234 INFO:     Epoch: 83
2023-01-05 14:04:15,393 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40434763381878536, 'Total loss': 0.40434763381878536} | train loss {'Reaction outcome loss': 0.2644664404160656, 'Total loss': 0.2644664404160656}
2023-01-05 14:04:15,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:15,393 INFO:     Epoch: 84
2023-01-05 14:04:17,603 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4012605339288712, 'Total loss': 0.4012605339288712} | train loss {'Reaction outcome loss': 0.25481699269923924, 'Total loss': 0.25481699269923924}
2023-01-05 14:04:17,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:17,603 INFO:     Epoch: 85
2023-01-05 14:04:19,784 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4195603181918462, 'Total loss': 0.4195603181918462} | train loss {'Reaction outcome loss': 0.26334205978560105, 'Total loss': 0.26334205978560105}
2023-01-05 14:04:19,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:19,785 INFO:     Epoch: 86
2023-01-05 14:04:21,914 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4093587875366211, 'Total loss': 0.4093587875366211} | train loss {'Reaction outcome loss': 0.2620719768886962, 'Total loss': 0.2620719768886962}
2023-01-05 14:04:21,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:21,915 INFO:     Epoch: 87
2023-01-05 14:04:24,057 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38077616492907207, 'Total loss': 0.38077616492907207} | train loss {'Reaction outcome loss': 0.2534439904810289, 'Total loss': 0.2534439904810289}
2023-01-05 14:04:24,057 INFO:     Found new best model at epoch 87
2023-01-05 14:04:24,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:24,059 INFO:     Epoch: 88
2023-01-05 14:04:26,205 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41491856848200165, 'Total loss': 0.41491856848200165} | train loss {'Reaction outcome loss': 0.25370647165157734, 'Total loss': 0.25370647165157734}
2023-01-05 14:04:26,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:26,206 INFO:     Epoch: 89
2023-01-05 14:04:28,325 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39473864436149597, 'Total loss': 0.39473864436149597} | train loss {'Reaction outcome loss': 0.26103120568857296, 'Total loss': 0.26103120568857296}
2023-01-05 14:04:28,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:28,325 INFO:     Epoch: 90
2023-01-05 14:04:30,481 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4112790048122406, 'Total loss': 0.4112790048122406} | train loss {'Reaction outcome loss': 0.2498487790353892, 'Total loss': 0.2498487790353892}
2023-01-05 14:04:30,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:30,482 INFO:     Epoch: 91
2023-01-05 14:04:32,712 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4080489069223404, 'Total loss': 0.4080489069223404} | train loss {'Reaction outcome loss': 0.25383703716583417, 'Total loss': 0.25383703716583417}
2023-01-05 14:04:32,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:32,712 INFO:     Epoch: 92
2023-01-05 14:04:34,871 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3894809444745382, 'Total loss': 0.3894809444745382} | train loss {'Reaction outcome loss': 0.25424059840853896, 'Total loss': 0.25424059840853896}
2023-01-05 14:04:34,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:34,872 INFO:     Epoch: 93
2023-01-05 14:04:37,024 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4649129579464594, 'Total loss': 0.4649129579464594} | train loss {'Reaction outcome loss': 0.24598470552141916, 'Total loss': 0.24598470552141916}
2023-01-05 14:04:37,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:37,025 INFO:     Epoch: 94
2023-01-05 14:04:39,228 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3921648696064949, 'Total loss': 0.3921648696064949} | train loss {'Reaction outcome loss': 0.254186883689802, 'Total loss': 0.254186883689802}
2023-01-05 14:04:39,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:39,228 INFO:     Epoch: 95
2023-01-05 14:04:41,391 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38885581195354463, 'Total loss': 0.38885581195354463} | train loss {'Reaction outcome loss': 0.24128619001821922, 'Total loss': 0.24128619001821922}
2023-01-05 14:04:41,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:41,392 INFO:     Epoch: 96
2023-01-05 14:04:43,541 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4188225527604421, 'Total loss': 0.4188225527604421} | train loss {'Reaction outcome loss': 0.2524250798492225, 'Total loss': 0.2524250798492225}
2023-01-05 14:04:43,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:43,541 INFO:     Epoch: 97
2023-01-05 14:04:45,690 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4209098269542058, 'Total loss': 0.4209098269542058} | train loss {'Reaction outcome loss': 0.24537345187382148, 'Total loss': 0.24537345187382148}
2023-01-05 14:04:45,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:45,690 INFO:     Epoch: 98
2023-01-05 14:04:47,869 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.38379481931527454, 'Total loss': 0.38379481931527454} | train loss {'Reaction outcome loss': 0.24378458655267846, 'Total loss': 0.24378458655267846}
2023-01-05 14:04:47,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:47,870 INFO:     Epoch: 99
2023-01-05 14:04:50,033 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3959270199139913, 'Total loss': 0.3959270199139913} | train loss {'Reaction outcome loss': 0.24887845062714622, 'Total loss': 0.24887845062714622}
2023-01-05 14:04:50,033 INFO:     Best model found after epoch 88 of 100.
2023-01-05 14:04:50,033 INFO:   Done with stage: TRAINING
2023-01-05 14:04:50,033 INFO:   Starting stage: EVALUATION
2023-01-05 14:04:50,159 INFO:   Done with stage: EVALUATION
2023-01-05 14:04:50,159 INFO:   Leaving out SEQ value Fold_7
2023-01-05 14:04:50,172 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 14:04:50,172 INFO:   Starting stage: FEATURE SCALING
2023-01-05 14:04:50,821 INFO:   Done with stage: FEATURE SCALING
2023-01-05 14:04:50,822 INFO:   Starting stage: SCALING TARGETS
2023-01-05 14:04:50,891 INFO:   Done with stage: SCALING TARGETS
2023-01-05 14:04:50,892 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:04:50,892 INFO:     No hyperparam tuning for this model
2023-01-05 14:04:50,892 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:04:50,892 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 14:04:50,892 INFO:     None feature selector for col prot
2023-01-05 14:04:50,893 INFO:     None feature selector for col prot
2023-01-05 14:04:50,893 INFO:     None feature selector for col prot
2023-01-05 14:04:50,893 INFO:     None feature selector for col chem
2023-01-05 14:04:50,893 INFO:     None feature selector for col chem
2023-01-05 14:04:50,893 INFO:     None feature selector for col chem
2023-01-05 14:04:50,893 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 14:04:50,894 INFO:   Starting stage: BUILD MODEL
2023-01-05 14:04:50,895 INFO:     Number of params in model 72901
2023-01-05 14:04:50,898 INFO:   Done with stage: BUILD MODEL
2023-01-05 14:04:50,898 INFO:   Starting stage: TRAINING
2023-01-05 14:04:50,958 INFO:     Val loss before train {'Reaction outcome loss': 1.0268742362658183, 'Total loss': 1.0268742362658183}
2023-01-05 14:04:50,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:50,958 INFO:     Epoch: 0
2023-01-05 14:04:53,126 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8825465301672618, 'Total loss': 0.8825465301672618} | train loss {'Reaction outcome loss': 0.9166431073032131, 'Total loss': 0.9166431073032131}
2023-01-05 14:04:53,126 INFO:     Found new best model at epoch 0
2023-01-05 14:04:53,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:53,127 INFO:     Epoch: 1
2023-01-05 14:04:55,295 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7718559106191, 'Total loss': 0.7718559106191} | train loss {'Reaction outcome loss': 0.7241755103161188, 'Total loss': 0.7241755103161188}
2023-01-05 14:04:55,295 INFO:     Found new best model at epoch 1
2023-01-05 14:04:55,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:55,297 INFO:     Epoch: 2
2023-01-05 14:04:57,444 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6429717242717743, 'Total loss': 0.6429717242717743} | train loss {'Reaction outcome loss': 0.5912948695653613, 'Total loss': 0.5912948695653613}
2023-01-05 14:04:57,444 INFO:     Found new best model at epoch 2
2023-01-05 14:04:57,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:57,446 INFO:     Epoch: 3
2023-01-05 14:04:59,609 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6154955406983693, 'Total loss': 0.6154955406983693} | train loss {'Reaction outcome loss': 0.532293278952583, 'Total loss': 0.532293278952583}
2023-01-05 14:04:59,609 INFO:     Found new best model at epoch 3
2023-01-05 14:04:59,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:04:59,611 INFO:     Epoch: 4
2023-01-05 14:05:01,779 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6253434836864471, 'Total loss': 0.6253434836864471} | train loss {'Reaction outcome loss': 0.5087963805301955, 'Total loss': 0.5087963805301955}
2023-01-05 14:05:01,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:01,780 INFO:     Epoch: 5
2023-01-05 14:05:03,936 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.6100290497144063, 'Total loss': 0.6100290497144063} | train loss {'Reaction outcome loss': 0.5016257899547742, 'Total loss': 0.5016257899547742}
2023-01-05 14:05:03,936 INFO:     Found new best model at epoch 5
2023-01-05 14:05:03,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:03,938 INFO:     Epoch: 6
2023-01-05 14:05:06,100 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.6040325820446014, 'Total loss': 0.6040325820446014} | train loss {'Reaction outcome loss': 0.49099387718021653, 'Total loss': 0.49099387718021653}
2023-01-05 14:05:06,100 INFO:     Found new best model at epoch 6
2023-01-05 14:05:06,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:06,102 INFO:     Epoch: 7
2023-01-05 14:05:08,253 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5903783957163493, 'Total loss': 0.5903783957163493} | train loss {'Reaction outcome loss': 0.47758390633422976, 'Total loss': 0.47758390633422976}
2023-01-05 14:05:08,253 INFO:     Found new best model at epoch 7
2023-01-05 14:05:08,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:08,255 INFO:     Epoch: 8
2023-01-05 14:05:10,403 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.6190999885400136, 'Total loss': 0.6190999885400136} | train loss {'Reaction outcome loss': 0.47063064908723107, 'Total loss': 0.47063064908723107}
2023-01-05 14:05:10,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:10,404 INFO:     Epoch: 9
2023-01-05 14:05:12,554 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.6074663241704304, 'Total loss': 0.6074663241704304} | train loss {'Reaction outcome loss': 0.46309360544388906, 'Total loss': 0.46309360544388906}
2023-01-05 14:05:12,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:12,554 INFO:     Epoch: 10
2023-01-05 14:05:14,726 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5769108533859253, 'Total loss': 0.5769108533859253} | train loss {'Reaction outcome loss': 0.4559929654378753, 'Total loss': 0.4559929654378753}
2023-01-05 14:05:14,726 INFO:     Found new best model at epoch 10
2023-01-05 14:05:14,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:14,727 INFO:     Epoch: 11
2023-01-05 14:05:16,884 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5969842453797658, 'Total loss': 0.5969842453797658} | train loss {'Reaction outcome loss': 0.45445019453226015, 'Total loss': 0.45445019453226015}
2023-01-05 14:05:16,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:16,885 INFO:     Epoch: 12
2023-01-05 14:05:19,049 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5816316902637482, 'Total loss': 0.5816316902637482} | train loss {'Reaction outcome loss': 0.4520925183911616, 'Total loss': 0.4520925183911616}
2023-01-05 14:05:19,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:19,049 INFO:     Epoch: 13
2023-01-05 14:05:21,209 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5973267475763957, 'Total loss': 0.5973267475763957} | train loss {'Reaction outcome loss': 0.4499234440955014, 'Total loss': 0.4499234440955014}
2023-01-05 14:05:21,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:21,210 INFO:     Epoch: 14
2023-01-05 14:05:23,368 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5862479011217753, 'Total loss': 0.5862479011217753} | train loss {'Reaction outcome loss': 0.43947998964184026, 'Total loss': 0.43947998964184026}
2023-01-05 14:05:23,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:23,369 INFO:     Epoch: 15
2023-01-05 14:05:25,533 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5569538275400797, 'Total loss': 0.5569538275400797} | train loss {'Reaction outcome loss': 0.4387055114180603, 'Total loss': 0.4387055114180603}
2023-01-05 14:05:25,533 INFO:     Found new best model at epoch 15
2023-01-05 14:05:25,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:25,534 INFO:     Epoch: 16
2023-01-05 14:05:27,701 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.58947327931722, 'Total loss': 0.58947327931722} | train loss {'Reaction outcome loss': 0.43167870181078083, 'Total loss': 0.43167870181078083}
2023-01-05 14:05:27,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:27,701 INFO:     Epoch: 17
2023-01-05 14:05:29,865 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5883849302927653, 'Total loss': 0.5883849302927653} | train loss {'Reaction outcome loss': 0.4320651907137585, 'Total loss': 0.4320651907137585}
2023-01-05 14:05:29,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:29,866 INFO:     Epoch: 18
2023-01-05 14:05:32,032 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5750603477160136, 'Total loss': 0.5750603477160136} | train loss {'Reaction outcome loss': 0.4237266080151396, 'Total loss': 0.4237266080151396}
2023-01-05 14:05:32,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:32,033 INFO:     Epoch: 19
2023-01-05 14:05:34,006 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5625394801298778, 'Total loss': 0.5625394801298778} | train loss {'Reaction outcome loss': 0.42255068675275315, 'Total loss': 0.42255068675275315}
2023-01-05 14:05:34,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:34,006 INFO:     Epoch: 20
2023-01-05 14:05:36,176 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5491275787353516, 'Total loss': 0.5491275787353516} | train loss {'Reaction outcome loss': 0.4161510188334255, 'Total loss': 0.4161510188334255}
2023-01-05 14:05:36,176 INFO:     Found new best model at epoch 20
2023-01-05 14:05:36,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:36,178 INFO:     Epoch: 21
2023-01-05 14:05:38,351 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5337919592857361, 'Total loss': 0.5337919592857361} | train loss {'Reaction outcome loss': 0.4126014246837327, 'Total loss': 0.4126014246837327}
2023-01-05 14:05:38,351 INFO:     Found new best model at epoch 21
2023-01-05 14:05:38,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:38,352 INFO:     Epoch: 22
2023-01-05 14:05:40,510 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5507948855559032, 'Total loss': 0.5507948855559032} | train loss {'Reaction outcome loss': 0.40407464766222645, 'Total loss': 0.40407464766222645}
2023-01-05 14:05:40,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:40,511 INFO:     Epoch: 23
2023-01-05 14:05:42,675 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5800739963849385, 'Total loss': 0.5800739963849385} | train loss {'Reaction outcome loss': 0.40417020090112615, 'Total loss': 0.40417020090112615}
2023-01-05 14:05:42,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:42,675 INFO:     Epoch: 24
2023-01-05 14:05:44,831 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5438685238361358, 'Total loss': 0.5438685238361358} | train loss {'Reaction outcome loss': 0.39610384894192, 'Total loss': 0.39610384894192}
2023-01-05 14:05:44,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:44,832 INFO:     Epoch: 25
2023-01-05 14:05:46,995 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5553962667783101, 'Total loss': 0.5553962667783101} | train loss {'Reaction outcome loss': 0.3950784647507788, 'Total loss': 0.3950784647507788}
2023-01-05 14:05:46,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:46,996 INFO:     Epoch: 26
2023-01-05 14:05:49,129 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5442449430624644, 'Total loss': 0.5442449430624644} | train loss {'Reaction outcome loss': 0.3924681065530123, 'Total loss': 0.3924681065530123}
2023-01-05 14:05:49,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:49,130 INFO:     Epoch: 27
2023-01-05 14:05:51,274 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5567687332630158, 'Total loss': 0.5567687332630158} | train loss {'Reaction outcome loss': 0.3852068460159784, 'Total loss': 0.3852068460159784}
2023-01-05 14:05:51,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:51,274 INFO:     Epoch: 28
2023-01-05 14:05:53,423 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5376078208287557, 'Total loss': 0.5376078208287557} | train loss {'Reaction outcome loss': 0.38618369795893076, 'Total loss': 0.38618369795893076}
2023-01-05 14:05:53,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:53,424 INFO:     Epoch: 29
2023-01-05 14:05:55,570 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5326391567786535, 'Total loss': 0.5326391567786535} | train loss {'Reaction outcome loss': 0.38277350799163756, 'Total loss': 0.38277350799163756}
2023-01-05 14:05:55,570 INFO:     Found new best model at epoch 29
2023-01-05 14:05:55,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:55,571 INFO:     Epoch: 30
2023-01-05 14:05:57,714 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5414432833592097, 'Total loss': 0.5414432833592097} | train loss {'Reaction outcome loss': 0.3835243105969059, 'Total loss': 0.3835243105969059}
2023-01-05 14:05:57,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:57,714 INFO:     Epoch: 31
2023-01-05 14:05:59,900 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.564394889275233, 'Total loss': 0.564394889275233} | train loss {'Reaction outcome loss': 0.3754572617125425, 'Total loss': 0.3754572617125425}
2023-01-05 14:05:59,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:05:59,900 INFO:     Epoch: 32
2023-01-05 14:06:02,036 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5064785997072856, 'Total loss': 0.5064785997072856} | train loss {'Reaction outcome loss': 0.3792296704779033, 'Total loss': 0.3792296704779033}
2023-01-05 14:06:02,036 INFO:     Found new best model at epoch 32
2023-01-05 14:06:02,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:02,037 INFO:     Epoch: 33
2023-01-05 14:06:04,197 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5254711012045542, 'Total loss': 0.5254711012045542} | train loss {'Reaction outcome loss': 0.373162240408603, 'Total loss': 0.373162240408603}
2023-01-05 14:06:04,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:04,198 INFO:     Epoch: 34
2023-01-05 14:06:06,338 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5377039472262065, 'Total loss': 0.5377039472262065} | train loss {'Reaction outcome loss': 0.362787782043111, 'Total loss': 0.362787782043111}
2023-01-05 14:06:06,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:06,339 INFO:     Epoch: 35
2023-01-05 14:06:08,482 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5270427773396175, 'Total loss': 0.5270427773396175} | train loss {'Reaction outcome loss': 0.3600946024920966, 'Total loss': 0.3600946024920966}
2023-01-05 14:06:08,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:08,482 INFO:     Epoch: 36
2023-01-05 14:06:10,637 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5221734344959259, 'Total loss': 0.5221734344959259} | train loss {'Reaction outcome loss': 0.3586269453275505, 'Total loss': 0.3586269453275505}
2023-01-05 14:06:10,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:10,637 INFO:     Epoch: 37
2023-01-05 14:06:12,792 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5120630239446958, 'Total loss': 0.5120630239446958} | train loss {'Reaction outcome loss': 0.3591735485389775, 'Total loss': 0.3591735485389775}
2023-01-05 14:06:12,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:12,792 INFO:     Epoch: 38
2023-01-05 14:06:14,927 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5308120369911193, 'Total loss': 0.5308120369911193} | train loss {'Reaction outcome loss': 0.3468286689868473, 'Total loss': 0.3468286689868473}
2023-01-05 14:06:14,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:14,927 INFO:     Epoch: 39
2023-01-05 14:06:17,085 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5340389907360077, 'Total loss': 0.5340389907360077} | train loss {'Reaction outcome loss': 0.3464875593512497, 'Total loss': 0.3464875593512497}
2023-01-05 14:06:17,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:17,085 INFO:     Epoch: 40
2023-01-05 14:06:19,225 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5236835241317749, 'Total loss': 0.5236835241317749} | train loss {'Reaction outcome loss': 0.3449322890342358, 'Total loss': 0.3449322890342358}
2023-01-05 14:06:19,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:19,225 INFO:     Epoch: 41
2023-01-05 14:06:21,368 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5281790554523468, 'Total loss': 0.5281790554523468} | train loss {'Reaction outcome loss': 0.34380182774488677, 'Total loss': 0.34380182774488677}
2023-01-05 14:06:21,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:21,368 INFO:     Epoch: 42
2023-01-05 14:06:23,510 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.49372076988220215, 'Total loss': 0.49372076988220215} | train loss {'Reaction outcome loss': 0.34695843996527176, 'Total loss': 0.34695843996527176}
2023-01-05 14:06:23,511 INFO:     Found new best model at epoch 42
2023-01-05 14:06:23,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:23,512 INFO:     Epoch: 43
2023-01-05 14:06:25,688 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5004806513587634, 'Total loss': 0.5004806513587634} | train loss {'Reaction outcome loss': 0.33535571815950344, 'Total loss': 0.33535571815950344}
2023-01-05 14:06:25,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:25,688 INFO:     Epoch: 44
2023-01-05 14:06:27,853 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5461378693580627, 'Total loss': 0.5461378693580627} | train loss {'Reaction outcome loss': 0.33010311825503513, 'Total loss': 0.33010311825503513}
2023-01-05 14:06:27,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:27,854 INFO:     Epoch: 45
2023-01-05 14:06:29,993 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5423651734987894, 'Total loss': 0.5423651734987894} | train loss {'Reaction outcome loss': 0.3445125229468414, 'Total loss': 0.3445125229468414}
2023-01-05 14:06:29,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:29,994 INFO:     Epoch: 46
2023-01-05 14:06:32,153 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5139586468537648, 'Total loss': 0.5139586468537648} | train loss {'Reaction outcome loss': 0.33604917890435954, 'Total loss': 0.33604917890435954}
2023-01-05 14:06:32,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:32,154 INFO:     Epoch: 47
2023-01-05 14:06:34,316 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5149101098378499, 'Total loss': 0.5149101098378499} | train loss {'Reaction outcome loss': 0.33503835632159823, 'Total loss': 0.33503835632159823}
2023-01-05 14:06:34,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:34,316 INFO:     Epoch: 48
2023-01-05 14:06:36,478 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5030080368121465, 'Total loss': 0.5030080368121465} | train loss {'Reaction outcome loss': 0.3311340271996247, 'Total loss': 0.3311340271996247}
2023-01-05 14:06:36,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:36,478 INFO:     Epoch: 49
2023-01-05 14:06:38,650 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5265300224224726, 'Total loss': 0.5265300224224726} | train loss {'Reaction outcome loss': 0.33029036124368005, 'Total loss': 0.33029036124368005}
2023-01-05 14:06:38,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:38,650 INFO:     Epoch: 50
2023-01-05 14:06:40,810 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49307539661725364, 'Total loss': 0.49307539661725364} | train loss {'Reaction outcome loss': 0.3188137449458618, 'Total loss': 0.3188137449458618}
2023-01-05 14:06:40,810 INFO:     Found new best model at epoch 50
2023-01-05 14:06:40,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:40,812 INFO:     Epoch: 51
2023-01-05 14:06:42,971 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5295313795407613, 'Total loss': 0.5295313795407613} | train loss {'Reaction outcome loss': 0.3169593644002284, 'Total loss': 0.3169593644002284}
2023-01-05 14:06:42,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:42,972 INFO:     Epoch: 52
2023-01-05 14:06:45,127 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.486512103676796, 'Total loss': 0.486512103676796} | train loss {'Reaction outcome loss': 0.3155818601754168, 'Total loss': 0.3155818601754168}
2023-01-05 14:06:45,127 INFO:     Found new best model at epoch 52
2023-01-05 14:06:45,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:45,128 INFO:     Epoch: 53
2023-01-05 14:06:47,291 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5135608484347661, 'Total loss': 0.5135608484347661} | train loss {'Reaction outcome loss': 0.32128800556655396, 'Total loss': 0.32128800556655396}
2023-01-05 14:06:47,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:47,291 INFO:     Epoch: 54
2023-01-05 14:06:49,460 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.547345240910848, 'Total loss': 0.547345240910848} | train loss {'Reaction outcome loss': 0.3176703517348758, 'Total loss': 0.3176703517348758}
2023-01-05 14:06:49,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:49,460 INFO:     Epoch: 55
2023-01-05 14:06:51,609 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49760162830352783, 'Total loss': 0.49760162830352783} | train loss {'Reaction outcome loss': 0.31396836600525285, 'Total loss': 0.31396836600525285}
2023-01-05 14:06:51,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:51,609 INFO:     Epoch: 56
2023-01-05 14:06:53,766 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5129344463348389, 'Total loss': 0.5129344463348389} | train loss {'Reaction outcome loss': 0.3076929298333743, 'Total loss': 0.3076929298333743}
2023-01-05 14:06:53,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:53,767 INFO:     Epoch: 57
2023-01-05 14:06:55,902 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5081648161013921, 'Total loss': 0.5081648161013921} | train loss {'Reaction outcome loss': 0.3070251096295536, 'Total loss': 0.3070251096295536}
2023-01-05 14:06:55,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:55,902 INFO:     Epoch: 58
2023-01-05 14:06:58,089 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5119463761647542, 'Total loss': 0.5119463761647542} | train loss {'Reaction outcome loss': 0.31126710304499533, 'Total loss': 0.31126710304499533}
2023-01-05 14:06:58,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:06:58,090 INFO:     Epoch: 59
2023-01-05 14:07:00,241 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5016430914402008, 'Total loss': 0.5016430914402008} | train loss {'Reaction outcome loss': 0.3045372066461222, 'Total loss': 0.3045372066461222}
2023-01-05 14:07:00,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:00,242 INFO:     Epoch: 60
2023-01-05 14:07:02,404 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5264778196811676, 'Total loss': 0.5264778196811676} | train loss {'Reaction outcome loss': 0.30419310175608644, 'Total loss': 0.30419310175608644}
2023-01-05 14:07:02,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:02,404 INFO:     Epoch: 61
2023-01-05 14:07:04,572 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5229723413785299, 'Total loss': 0.5229723413785299} | train loss {'Reaction outcome loss': 0.3035290543971724, 'Total loss': 0.3035290543971724}
2023-01-05 14:07:04,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:04,572 INFO:     Epoch: 62
2023-01-05 14:07:06,719 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5232207626104355, 'Total loss': 0.5232207626104355} | train loss {'Reaction outcome loss': 0.2996493781570493, 'Total loss': 0.2996493781570493}
2023-01-05 14:07:06,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:06,719 INFO:     Epoch: 63
2023-01-05 14:07:08,891 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5377019663651784, 'Total loss': 0.5377019663651784} | train loss {'Reaction outcome loss': 0.3006641619741271, 'Total loss': 0.3006641619741271}
2023-01-05 14:07:08,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:08,891 INFO:     Epoch: 64
2023-01-05 14:07:11,034 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5159530619780223, 'Total loss': 0.5159530619780223} | train loss {'Reaction outcome loss': 0.29843389505137174, 'Total loss': 0.29843389505137174}
2023-01-05 14:07:11,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:11,034 INFO:     Epoch: 65
2023-01-05 14:07:13,193 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4895125572880109, 'Total loss': 0.4895125572880109} | train loss {'Reaction outcome loss': 0.28997203107882924, 'Total loss': 0.28997203107882924}
2023-01-05 14:07:13,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:13,194 INFO:     Epoch: 66
2023-01-05 14:07:15,344 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.525203961133957, 'Total loss': 0.525203961133957} | train loss {'Reaction outcome loss': 0.2905218269447342, 'Total loss': 0.2905218269447342}
2023-01-05 14:07:15,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:15,344 INFO:     Epoch: 67
2023-01-05 14:07:17,498 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5126407543818156, 'Total loss': 0.5126407543818156} | train loss {'Reaction outcome loss': 0.2977740671014958, 'Total loss': 0.2977740671014958}
2023-01-05 14:07:17,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:17,498 INFO:     Epoch: 68
2023-01-05 14:07:19,667 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5159234543641408, 'Total loss': 0.5159234543641408} | train loss {'Reaction outcome loss': 0.2923401555429727, 'Total loss': 0.2923401555429727}
2023-01-05 14:07:19,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:19,668 INFO:     Epoch: 69
2023-01-05 14:07:21,836 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5184946656227112, 'Total loss': 0.5184946656227112} | train loss {'Reaction outcome loss': 0.294059278947782, 'Total loss': 0.294059278947782}
2023-01-05 14:07:21,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:21,837 INFO:     Epoch: 70
2023-01-05 14:07:23,977 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5398544251918793, 'Total loss': 0.5398544251918793} | train loss {'Reaction outcome loss': 0.287663284420214, 'Total loss': 0.287663284420214}
2023-01-05 14:07:23,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:23,977 INFO:     Epoch: 71
2023-01-05 14:07:26,135 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.551779552300771, 'Total loss': 0.551779552300771} | train loss {'Reaction outcome loss': 0.2935272107701009, 'Total loss': 0.2935272107701009}
2023-01-05 14:07:26,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:26,136 INFO:     Epoch: 72
2023-01-05 14:07:28,290 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5316688617070516, 'Total loss': 0.5316688617070516} | train loss {'Reaction outcome loss': 0.2854272873823393, 'Total loss': 0.2854272873823393}
2023-01-05 14:07:28,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:28,290 INFO:     Epoch: 73
2023-01-05 14:07:30,428 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4843785713116328, 'Total loss': 0.4843785713116328} | train loss {'Reaction outcome loss': 0.28538469654181803, 'Total loss': 0.28538469654181803}
2023-01-05 14:07:30,429 INFO:     Found new best model at epoch 73
2023-01-05 14:07:30,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:30,431 INFO:     Epoch: 74
2023-01-05 14:07:32,574 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5232099990049998, 'Total loss': 0.5232099990049998} | train loss {'Reaction outcome loss': 0.28500875844099033, 'Total loss': 0.28500875844099033}
2023-01-05 14:07:32,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:32,575 INFO:     Epoch: 75
2023-01-05 14:07:34,713 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5509964416424433, 'Total loss': 0.5509964416424433} | train loss {'Reaction outcome loss': 0.28022400367776407, 'Total loss': 0.28022400367776407}
2023-01-05 14:07:34,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:34,714 INFO:     Epoch: 76
2023-01-05 14:07:36,841 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4969899912675222, 'Total loss': 0.4969899912675222} | train loss {'Reaction outcome loss': 0.28015776512478663, 'Total loss': 0.28015776512478663}
2023-01-05 14:07:36,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:36,842 INFO:     Epoch: 77
2023-01-05 14:07:38,972 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5492718358834584, 'Total loss': 0.5492718358834584} | train loss {'Reaction outcome loss': 0.27901944959206704, 'Total loss': 0.27901944959206704}
2023-01-05 14:07:38,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:38,972 INFO:     Epoch: 78
2023-01-05 14:07:41,123 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49074431459108986, 'Total loss': 0.49074431459108986} | train loss {'Reaction outcome loss': 0.28319687897924484, 'Total loss': 0.28319687897924484}
2023-01-05 14:07:41,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:41,123 INFO:     Epoch: 79
2023-01-05 14:07:43,244 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.513354500134786, 'Total loss': 0.513354500134786} | train loss {'Reaction outcome loss': 0.27217079947168, 'Total loss': 0.27217079947168}
2023-01-05 14:07:43,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:43,244 INFO:     Epoch: 80
2023-01-05 14:07:45,384 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.521925276517868, 'Total loss': 0.521925276517868} | train loss {'Reaction outcome loss': 0.26728353356196133, 'Total loss': 0.26728353356196133}
2023-01-05 14:07:45,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:45,384 INFO:     Epoch: 81
2023-01-05 14:07:47,520 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5058626612027486, 'Total loss': 0.5058626612027486} | train loss {'Reaction outcome loss': 0.27074297050195695, 'Total loss': 0.27074297050195695}
2023-01-05 14:07:47,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:47,520 INFO:     Epoch: 82
2023-01-05 14:07:49,661 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5026502798000971, 'Total loss': 0.5026502798000971} | train loss {'Reaction outcome loss': 0.2692517347916261, 'Total loss': 0.2692517347916261}
2023-01-05 14:07:49,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:49,662 INFO:     Epoch: 83
2023-01-05 14:07:51,811 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49507144689559934, 'Total loss': 0.49507144689559934} | train loss {'Reaction outcome loss': 0.2708370939219902, 'Total loss': 0.2708370939219902}
2023-01-05 14:07:51,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:51,811 INFO:     Epoch: 84
2023-01-05 14:07:53,966 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5002495348453522, 'Total loss': 0.5002495348453522} | train loss {'Reaction outcome loss': 0.27053195917272826, 'Total loss': 0.27053195917272826}
2023-01-05 14:07:53,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:53,966 INFO:     Epoch: 85
2023-01-05 14:07:56,148 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47899846235911053, 'Total loss': 0.47899846235911053} | train loss {'Reaction outcome loss': 0.2672819868537063, 'Total loss': 0.2672819868537063}
2023-01-05 14:07:56,148 INFO:     Found new best model at epoch 85
2023-01-05 14:07:56,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:56,149 INFO:     Epoch: 86
2023-01-05 14:07:58,285 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49665672381718956, 'Total loss': 0.49665672381718956} | train loss {'Reaction outcome loss': 0.26739343349226763, 'Total loss': 0.26739343349226763}
2023-01-05 14:07:58,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:07:58,286 INFO:     Epoch: 87
2023-01-05 14:08:00,471 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5328879197438557, 'Total loss': 0.5328879197438557} | train loss {'Reaction outcome loss': 0.2673360448774448, 'Total loss': 0.2673360448774448}
2023-01-05 14:08:00,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:00,473 INFO:     Epoch: 88
2023-01-05 14:08:02,631 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5220278521378835, 'Total loss': 0.5220278521378835} | train loss {'Reaction outcome loss': 0.26576659283752047, 'Total loss': 0.26576659283752047}
2023-01-05 14:08:02,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:02,632 INFO:     Epoch: 89
2023-01-05 14:08:04,795 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4972361624240875, 'Total loss': 0.4972361624240875} | train loss {'Reaction outcome loss': 0.26475974039884037, 'Total loss': 0.26475974039884037}
2023-01-05 14:08:04,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:04,796 INFO:     Epoch: 90
2023-01-05 14:08:06,955 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4963859111070633, 'Total loss': 0.4963859111070633} | train loss {'Reaction outcome loss': 0.26242443849248576, 'Total loss': 0.26242443849248576}
2023-01-05 14:08:06,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:06,956 INFO:     Epoch: 91
2023-01-05 14:08:09,110 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.516493684053421, 'Total loss': 0.516493684053421} | train loss {'Reaction outcome loss': 0.2617196568593867, 'Total loss': 0.2617196568593867}
2023-01-05 14:08:09,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:09,110 INFO:     Epoch: 92
2023-01-05 14:08:11,266 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5192852437496185, 'Total loss': 0.5192852437496185} | train loss {'Reaction outcome loss': 0.26345157656240337, 'Total loss': 0.26345157656240337}
2023-01-05 14:08:11,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:11,267 INFO:     Epoch: 93
2023-01-05 14:08:13,410 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5242903749148051, 'Total loss': 0.5242903749148051} | train loss {'Reaction outcome loss': 0.26471170306958874, 'Total loss': 0.26471170306958874}
2023-01-05 14:08:13,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:13,410 INFO:     Epoch: 94
2023-01-05 14:08:15,575 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5403586665789286, 'Total loss': 0.5403586665789286} | train loss {'Reaction outcome loss': 0.2542553446877627, 'Total loss': 0.2542553446877627}
2023-01-05 14:08:15,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:15,576 INFO:     Epoch: 95
2023-01-05 14:08:17,725 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5109578430652618, 'Total loss': 0.5109578430652618} | train loss {'Reaction outcome loss': 0.26791231634115487, 'Total loss': 0.26791231634115487}
2023-01-05 14:08:17,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:17,726 INFO:     Epoch: 96
2023-01-05 14:08:19,882 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5132594682276249, 'Total loss': 0.5132594682276249} | train loss {'Reaction outcome loss': 0.25064485977044065, 'Total loss': 0.25064485977044065}
2023-01-05 14:08:19,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:19,883 INFO:     Epoch: 97
2023-01-05 14:08:22,048 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5744264721870422, 'Total loss': 0.5744264721870422} | train loss {'Reaction outcome loss': 0.26529671565128576, 'Total loss': 0.26529671565128576}
2023-01-05 14:08:22,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:22,048 INFO:     Epoch: 98
2023-01-05 14:08:24,197 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5020735005537669, 'Total loss': 0.5020735005537669} | train loss {'Reaction outcome loss': 0.25372591907904896, 'Total loss': 0.25372591907904896}
2023-01-05 14:08:24,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:24,198 INFO:     Epoch: 99
2023-01-05 14:08:26,361 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5573035717010498, 'Total loss': 0.5573035717010498} | train loss {'Reaction outcome loss': 0.26323318416891545, 'Total loss': 0.26323318416891545}
2023-01-05 14:08:26,361 INFO:     Best model found after epoch 86 of 100.
2023-01-05 14:08:26,361 INFO:   Done with stage: TRAINING
2023-01-05 14:08:26,361 INFO:   Starting stage: EVALUATION
2023-01-05 14:08:26,489 INFO:   Done with stage: EVALUATION
2023-01-05 14:08:26,489 INFO:   Leaving out SEQ value Fold_8
2023-01-05 14:08:26,502 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 14:08:26,502 INFO:   Starting stage: FEATURE SCALING
2023-01-05 14:08:27,156 INFO:   Done with stage: FEATURE SCALING
2023-01-05 14:08:27,156 INFO:   Starting stage: SCALING TARGETS
2023-01-05 14:08:27,226 INFO:   Done with stage: SCALING TARGETS
2023-01-05 14:08:27,226 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:08:27,227 INFO:     No hyperparam tuning for this model
2023-01-05 14:08:27,227 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:08:27,227 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 14:08:27,227 INFO:     None feature selector for col prot
2023-01-05 14:08:27,228 INFO:     None feature selector for col prot
2023-01-05 14:08:27,228 INFO:     None feature selector for col prot
2023-01-05 14:08:27,228 INFO:     None feature selector for col chem
2023-01-05 14:08:27,228 INFO:     None feature selector for col chem
2023-01-05 14:08:27,228 INFO:     None feature selector for col chem
2023-01-05 14:08:27,228 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 14:08:27,228 INFO:   Starting stage: BUILD MODEL
2023-01-05 14:08:27,231 INFO:     Number of params in model 72901
2023-01-05 14:08:27,234 INFO:   Done with stage: BUILD MODEL
2023-01-05 14:08:27,234 INFO:   Starting stage: TRAINING
2023-01-05 14:08:27,293 INFO:     Val loss before train {'Reaction outcome loss': 0.9438682834307353, 'Total loss': 0.9438682834307353}
2023-01-05 14:08:27,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:27,294 INFO:     Epoch: 0
2023-01-05 14:08:29,437 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7860751986503601, 'Total loss': 0.7860751986503601} | train loss {'Reaction outcome loss': 0.9015006778248842, 'Total loss': 0.9015006778248842}
2023-01-05 14:08:29,437 INFO:     Found new best model at epoch 0
2023-01-05 14:08:29,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:29,438 INFO:     Epoch: 1
2023-01-05 14:08:31,606 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5694697936375935, 'Total loss': 0.5694697936375935} | train loss {'Reaction outcome loss': 0.7095572481537575, 'Total loss': 0.7095572481537575}
2023-01-05 14:08:31,607 INFO:     Found new best model at epoch 1
2023-01-05 14:08:31,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:31,608 INFO:     Epoch: 2
2023-01-05 14:08:33,757 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5284202933311463, 'Total loss': 0.5284202933311463} | train loss {'Reaction outcome loss': 0.5868072839642781, 'Total loss': 0.5868072839642781}
2023-01-05 14:08:33,757 INFO:     Found new best model at epoch 2
2023-01-05 14:08:33,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:33,759 INFO:     Epoch: 3
2023-01-05 14:08:35,876 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5258231500784556, 'Total loss': 0.5258231500784556} | train loss {'Reaction outcome loss': 0.5184956614086885, 'Total loss': 0.5184956614086885}
2023-01-05 14:08:35,877 INFO:     Found new best model at epoch 3
2023-01-05 14:08:35,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:35,879 INFO:     Epoch: 4
2023-01-05 14:08:38,049 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5248452673355738, 'Total loss': 0.5248452673355738} | train loss {'Reaction outcome loss': 0.5059836034433566, 'Total loss': 0.5059836034433566}
2023-01-05 14:08:38,049 INFO:     Found new best model at epoch 4
2023-01-05 14:08:38,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:38,051 INFO:     Epoch: 5
2023-01-05 14:08:40,169 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4926364660263062, 'Total loss': 0.4926364660263062} | train loss {'Reaction outcome loss': 0.49809093417032907, 'Total loss': 0.49809093417032907}
2023-01-05 14:08:40,169 INFO:     Found new best model at epoch 5
2023-01-05 14:08:40,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:40,170 INFO:     Epoch: 6
2023-01-05 14:08:42,308 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5241225103537241, 'Total loss': 0.5241225103537241} | train loss {'Reaction outcome loss': 0.48535460589767393, 'Total loss': 0.48535460589767393}
2023-01-05 14:08:42,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:42,309 INFO:     Epoch: 7
2023-01-05 14:08:44,461 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4958516041437785, 'Total loss': 0.4958516041437785} | train loss {'Reaction outcome loss': 0.4713632069406626, 'Total loss': 0.4713632069406626}
2023-01-05 14:08:44,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:44,461 INFO:     Epoch: 8
2023-01-05 14:08:46,626 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4836924970149994, 'Total loss': 0.4836924970149994} | train loss {'Reaction outcome loss': 0.47202738935964694, 'Total loss': 0.47202738935964694}
2023-01-05 14:08:46,626 INFO:     Found new best model at epoch 8
2023-01-05 14:08:46,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:46,628 INFO:     Epoch: 9
2023-01-05 14:08:48,789 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5030341813961665, 'Total loss': 0.5030341813961665} | train loss {'Reaction outcome loss': 0.48586549194600515, 'Total loss': 0.48586549194600515}
2023-01-05 14:08:48,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:48,790 INFO:     Epoch: 10
2023-01-05 14:08:50,954 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5042527099450429, 'Total loss': 0.5042527099450429} | train loss {'Reaction outcome loss': 0.45756817442715925, 'Total loss': 0.45756817442715925}
2023-01-05 14:08:50,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:50,955 INFO:     Epoch: 11
2023-01-05 14:08:53,124 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4942470729351044, 'Total loss': 0.4942470729351044} | train loss {'Reaction outcome loss': 0.44978142502393736, 'Total loss': 0.44978142502393736}
2023-01-05 14:08:53,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:53,125 INFO:     Epoch: 12
2023-01-05 14:08:55,276 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46987113455931345, 'Total loss': 0.46987113455931345} | train loss {'Reaction outcome loss': 0.44725436333733937, 'Total loss': 0.44725436333733937}
2023-01-05 14:08:55,277 INFO:     Found new best model at epoch 12
2023-01-05 14:08:55,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:55,278 INFO:     Epoch: 13
2023-01-05 14:08:57,405 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4705443640549978, 'Total loss': 0.4705443640549978} | train loss {'Reaction outcome loss': 0.44187852813173895, 'Total loss': 0.44187852813173895}
2023-01-05 14:08:57,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:57,405 INFO:     Epoch: 14
2023-01-05 14:08:59,566 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4872509350379308, 'Total loss': 0.4872509350379308} | train loss {'Reaction outcome loss': 0.4379889018077781, 'Total loss': 0.4379889018077781}
2023-01-05 14:08:59,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:08:59,566 INFO:     Epoch: 15
2023-01-05 14:09:01,733 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4839100450277328, 'Total loss': 0.4839100450277328} | train loss {'Reaction outcome loss': 0.43592974779734295, 'Total loss': 0.43592974779734295}
2023-01-05 14:09:01,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:01,733 INFO:     Epoch: 16
2023-01-05 14:09:03,890 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4468634560704231, 'Total loss': 0.4468634560704231} | train loss {'Reaction outcome loss': 0.42827223781226337, 'Total loss': 0.42827223781226337}
2023-01-05 14:09:03,891 INFO:     Found new best model at epoch 16
2023-01-05 14:09:03,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:03,892 INFO:     Epoch: 17
2023-01-05 14:09:06,062 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4920201977094015, 'Total loss': 0.4920201977094015} | train loss {'Reaction outcome loss': 0.42635426129740867, 'Total loss': 0.42635426129740867}
2023-01-05 14:09:06,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:06,063 INFO:     Epoch: 18
2023-01-05 14:09:08,230 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4675620158513387, 'Total loss': 0.4675620158513387} | train loss {'Reaction outcome loss': 0.4206982905271234, 'Total loss': 0.4206982905271234}
2023-01-05 14:09:08,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:08,230 INFO:     Epoch: 19
2023-01-05 14:09:10,394 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47403892477353415, 'Total loss': 0.47403892477353415} | train loss {'Reaction outcome loss': 0.4186734276287177, 'Total loss': 0.4186734276287177}
2023-01-05 14:09:10,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:10,395 INFO:     Epoch: 20
2023-01-05 14:09:12,561 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43437788387139636, 'Total loss': 0.43437788387139636} | train loss {'Reaction outcome loss': 0.4185044080547242, 'Total loss': 0.4185044080547242}
2023-01-05 14:09:12,562 INFO:     Found new best model at epoch 20
2023-01-05 14:09:12,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:12,563 INFO:     Epoch: 21
2023-01-05 14:09:14,709 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47324161529541015, 'Total loss': 0.47324161529541015} | train loss {'Reaction outcome loss': 0.41117638281687413, 'Total loss': 0.41117638281687413}
2023-01-05 14:09:14,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:14,709 INFO:     Epoch: 22
2023-01-05 14:09:16,856 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44730520645777383, 'Total loss': 0.44730520645777383} | train loss {'Reaction outcome loss': 0.40635986377954536, 'Total loss': 0.40635986377954536}
2023-01-05 14:09:16,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:16,856 INFO:     Epoch: 23
2023-01-05 14:09:18,990 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44184282403439284, 'Total loss': 0.44184282403439284} | train loss {'Reaction outcome loss': 0.40195642676848947, 'Total loss': 0.40195642676848947}
2023-01-05 14:09:18,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:18,991 INFO:     Epoch: 24
2023-01-05 14:09:21,140 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4557418465614319, 'Total loss': 0.4557418465614319} | train loss {'Reaction outcome loss': 0.39220966653337913, 'Total loss': 0.39220966653337913}
2023-01-05 14:09:21,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:21,140 INFO:     Epoch: 25
2023-01-05 14:09:23,277 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4599589596192042, 'Total loss': 0.4599589596192042} | train loss {'Reaction outcome loss': 0.39291030541062355, 'Total loss': 0.39291030541062355}
2023-01-05 14:09:23,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:23,278 INFO:     Epoch: 26
2023-01-05 14:09:25,419 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48399868806203206, 'Total loss': 0.48399868806203206} | train loss {'Reaction outcome loss': 0.38887795488741517, 'Total loss': 0.38887795488741517}
2023-01-05 14:09:25,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:25,419 INFO:     Epoch: 27
2023-01-05 14:09:27,550 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46966162224610647, 'Total loss': 0.46966162224610647} | train loss {'Reaction outcome loss': 0.38804538759016566, 'Total loss': 0.38804538759016566}
2023-01-05 14:09:27,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:27,550 INFO:     Epoch: 28
2023-01-05 14:09:29,693 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4460557689269384, 'Total loss': 0.4460557689269384} | train loss {'Reaction outcome loss': 0.3839359466708603, 'Total loss': 0.3839359466708603}
2023-01-05 14:09:29,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:29,693 INFO:     Epoch: 29
2023-01-05 14:09:31,866 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45251825352509817, 'Total loss': 0.45251825352509817} | train loss {'Reaction outcome loss': 0.3787374292152126, 'Total loss': 0.3787374292152126}
2023-01-05 14:09:31,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:31,867 INFO:     Epoch: 30
2023-01-05 14:09:33,992 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4509083151817322, 'Total loss': 0.4509083151817322} | train loss {'Reaction outcome loss': 0.3784092938277762, 'Total loss': 0.3784092938277762}
2023-01-05 14:09:33,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:33,993 INFO:     Epoch: 31
2023-01-05 14:09:36,144 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4694066345691681, 'Total loss': 0.4694066345691681} | train loss {'Reaction outcome loss': 0.3729868824264723, 'Total loss': 0.3729868824264723}
2023-01-05 14:09:36,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:36,145 INFO:     Epoch: 32
2023-01-05 14:09:38,072 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4398704717556636, 'Total loss': 0.4398704717556636} | train loss {'Reaction outcome loss': 0.3723787538761246, 'Total loss': 0.3723787538761246}
2023-01-05 14:09:38,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:38,072 INFO:     Epoch: 33
2023-01-05 14:09:40,233 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4770131508509318, 'Total loss': 0.4770131508509318} | train loss {'Reaction outcome loss': 0.3675712177325782, 'Total loss': 0.3675712177325782}
2023-01-05 14:09:40,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:40,233 INFO:     Epoch: 34
2023-01-05 14:09:42,402 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4497510512669881, 'Total loss': 0.4497510512669881} | train loss {'Reaction outcome loss': 0.36304745271487604, 'Total loss': 0.36304745271487604}
2023-01-05 14:09:42,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:42,403 INFO:     Epoch: 35
2023-01-05 14:09:44,525 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43312469522158303, 'Total loss': 0.43312469522158303} | train loss {'Reaction outcome loss': 0.36194383843111066, 'Total loss': 0.36194383843111066}
2023-01-05 14:09:44,525 INFO:     Found new best model at epoch 35
2023-01-05 14:09:44,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:44,526 INFO:     Epoch: 36
2023-01-05 14:09:46,698 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4372716903686523, 'Total loss': 0.4372716903686523} | train loss {'Reaction outcome loss': 0.3622194869148307, 'Total loss': 0.3622194869148307}
2023-01-05 14:09:46,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:46,699 INFO:     Epoch: 37
2023-01-05 14:09:48,873 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44881295661131543, 'Total loss': 0.44881295661131543} | train loss {'Reaction outcome loss': 0.3556907790026752, 'Total loss': 0.3556907790026752}
2023-01-05 14:09:48,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:48,874 INFO:     Epoch: 38
2023-01-05 14:09:51,036 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4505989760160446, 'Total loss': 0.4505989760160446} | train loss {'Reaction outcome loss': 0.35222890980177274, 'Total loss': 0.35222890980177274}
2023-01-05 14:09:51,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:51,037 INFO:     Epoch: 39
2023-01-05 14:09:53,212 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4554943879445394, 'Total loss': 0.4554943879445394} | train loss {'Reaction outcome loss': 0.3496981690556783, 'Total loss': 0.3496981690556783}
2023-01-05 14:09:53,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:53,212 INFO:     Epoch: 40
2023-01-05 14:09:55,397 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4807691027720769, 'Total loss': 0.4807691027720769} | train loss {'Reaction outcome loss': 0.3493378416520579, 'Total loss': 0.3493378416520579}
2023-01-05 14:09:55,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:55,398 INFO:     Epoch: 41
2023-01-05 14:09:57,577 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4679938018321991, 'Total loss': 0.4679938018321991} | train loss {'Reaction outcome loss': 0.3483210154998799, 'Total loss': 0.3483210154998799}
2023-01-05 14:09:57,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:57,578 INFO:     Epoch: 42
2023-01-05 14:09:59,737 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4381448229153951, 'Total loss': 0.4381448229153951} | train loss {'Reaction outcome loss': 0.34341508507782564, 'Total loss': 0.34341508507782564}
2023-01-05 14:09:59,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:09:59,738 INFO:     Epoch: 43
2023-01-05 14:10:01,899 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4576082587242126, 'Total loss': 0.4576082587242126} | train loss {'Reaction outcome loss': 0.3460266353947151, 'Total loss': 0.3460266353947151}
2023-01-05 14:10:01,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:01,900 INFO:     Epoch: 44
2023-01-05 14:10:04,059 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4525585095087687, 'Total loss': 0.4525585095087687} | train loss {'Reaction outcome loss': 0.34100110862693883, 'Total loss': 0.34100110862693883}
2023-01-05 14:10:04,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:04,059 INFO:     Epoch: 45
2023-01-05 14:10:06,209 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44362955590089165, 'Total loss': 0.44362955590089165} | train loss {'Reaction outcome loss': 0.33923967834562063, 'Total loss': 0.33923967834562063}
2023-01-05 14:10:06,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:06,209 INFO:     Epoch: 46
2023-01-05 14:10:08,341 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4761206924915314, 'Total loss': 0.4761206924915314} | train loss {'Reaction outcome loss': 0.32871883473548014, 'Total loss': 0.32871883473548014}
2023-01-05 14:10:08,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:08,342 INFO:     Epoch: 47
2023-01-05 14:10:10,483 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42120567460854846, 'Total loss': 0.42120567460854846} | train loss {'Reaction outcome loss': 0.3290312134363837, 'Total loss': 0.3290312134363837}
2023-01-05 14:10:10,483 INFO:     Found new best model at epoch 47
2023-01-05 14:10:10,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:10,484 INFO:     Epoch: 48
2023-01-05 14:10:12,636 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42059604326883954, 'Total loss': 0.42059604326883954} | train loss {'Reaction outcome loss': 0.3269225811805961, 'Total loss': 0.3269225811805961}
2023-01-05 14:10:12,636 INFO:     Found new best model at epoch 48
2023-01-05 14:10:12,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:12,638 INFO:     Epoch: 49
2023-01-05 14:10:14,777 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40384014397859574, 'Total loss': 0.40384014397859574} | train loss {'Reaction outcome loss': 0.3230704035845322, 'Total loss': 0.3230704035845322}
2023-01-05 14:10:14,778 INFO:     Found new best model at epoch 49
2023-01-05 14:10:14,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:14,779 INFO:     Epoch: 50
2023-01-05 14:10:16,938 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40904462337493896, 'Total loss': 0.40904462337493896} | train loss {'Reaction outcome loss': 0.3252277536599465, 'Total loss': 0.3252277536599465}
2023-01-05 14:10:16,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:16,939 INFO:     Epoch: 51
2023-01-05 14:10:19,093 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43842386702696484, 'Total loss': 0.43842386702696484} | train loss {'Reaction outcome loss': 0.31749045492999384, 'Total loss': 0.31749045492999384}
2023-01-05 14:10:19,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:19,094 INFO:     Epoch: 52
2023-01-05 14:10:21,248 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4588445117076238, 'Total loss': 0.4588445117076238} | train loss {'Reaction outcome loss': 0.318735109642148, 'Total loss': 0.318735109642148}
2023-01-05 14:10:21,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:21,249 INFO:     Epoch: 53
2023-01-05 14:10:23,410 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46941550771395363, 'Total loss': 0.46941550771395363} | train loss {'Reaction outcome loss': 0.33406116935572977, 'Total loss': 0.33406116935572977}
2023-01-05 14:10:23,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:23,410 INFO:     Epoch: 54
2023-01-05 14:10:25,553 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.447007425626119, 'Total loss': 0.447007425626119} | train loss {'Reaction outcome loss': 0.3209349368631408, 'Total loss': 0.3209349368631408}
2023-01-05 14:10:25,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:25,554 INFO:     Epoch: 55
2023-01-05 14:10:27,709 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3967832401394844, 'Total loss': 0.3967832401394844} | train loss {'Reaction outcome loss': 0.31180753000781325, 'Total loss': 0.31180753000781325}
2023-01-05 14:10:27,709 INFO:     Found new best model at epoch 55
2023-01-05 14:10:27,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:27,710 INFO:     Epoch: 56
2023-01-05 14:10:29,863 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43725119829177855, 'Total loss': 0.43725119829177855} | train loss {'Reaction outcome loss': 0.30477328701754625, 'Total loss': 0.30477328701754625}
2023-01-05 14:10:29,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:29,863 INFO:     Epoch: 57
2023-01-05 14:10:32,000 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46085590720176695, 'Total loss': 0.46085590720176695} | train loss {'Reaction outcome loss': 0.30603994742083107, 'Total loss': 0.30603994742083107}
2023-01-05 14:10:32,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:32,000 INFO:     Epoch: 58
2023-01-05 14:10:34,213 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45593827664852143, 'Total loss': 0.45593827664852143} | train loss {'Reaction outcome loss': 0.3089722661133619, 'Total loss': 0.3089722661133619}
2023-01-05 14:10:34,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:34,214 INFO:     Epoch: 59
2023-01-05 14:10:36,401 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47783208191394805, 'Total loss': 0.47783208191394805} | train loss {'Reaction outcome loss': 0.3082029167562723, 'Total loss': 0.3082029167562723}
2023-01-05 14:10:36,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:36,401 INFO:     Epoch: 60
2023-01-05 14:10:38,577 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44836854139963783, 'Total loss': 0.44836854139963783} | train loss {'Reaction outcome loss': 0.3112492359680313, 'Total loss': 0.3112492359680313}
2023-01-05 14:10:38,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:38,577 INFO:     Epoch: 61
2023-01-05 14:10:40,748 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44929990768432615, 'Total loss': 0.44929990768432615} | train loss {'Reaction outcome loss': 0.3024548836764407, 'Total loss': 0.3024548836764407}
2023-01-05 14:10:40,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:40,748 INFO:     Epoch: 62
2023-01-05 14:10:42,906 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4383213549852371, 'Total loss': 0.4383213549852371} | train loss {'Reaction outcome loss': 0.29761776300396037, 'Total loss': 0.29761776300396037}
2023-01-05 14:10:42,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:42,906 INFO:     Epoch: 63
2023-01-05 14:10:45,056 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4164323796828588, 'Total loss': 0.4164323796828588} | train loss {'Reaction outcome loss': 0.2965568129957714, 'Total loss': 0.2965568129957714}
2023-01-05 14:10:45,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:45,057 INFO:     Epoch: 64
2023-01-05 14:10:47,214 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4306008363763491, 'Total loss': 0.4306008363763491} | train loss {'Reaction outcome loss': 0.2966746256781229, 'Total loss': 0.2966746256781229}
2023-01-05 14:10:47,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:47,214 INFO:     Epoch: 65
2023-01-05 14:10:49,367 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4544207294782003, 'Total loss': 0.4544207294782003} | train loss {'Reaction outcome loss': 0.29622538910136453, 'Total loss': 0.29622538910136453}
2023-01-05 14:10:49,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:49,368 INFO:     Epoch: 66
2023-01-05 14:10:51,530 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49746023416519164, 'Total loss': 0.49746023416519164} | train loss {'Reaction outcome loss': 0.2894030097581824, 'Total loss': 0.2894030097581824}
2023-01-05 14:10:51,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:51,530 INFO:     Epoch: 67
2023-01-05 14:10:53,686 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4559042652448018, 'Total loss': 0.4559042652448018} | train loss {'Reaction outcome loss': 0.297169807368714, 'Total loss': 0.297169807368714}
2023-01-05 14:10:53,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:53,686 INFO:     Epoch: 68
2023-01-05 14:10:55,835 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4360618362824122, 'Total loss': 0.4360618362824122} | train loss {'Reaction outcome loss': 0.2910742110975991, 'Total loss': 0.2910742110975991}
2023-01-05 14:10:55,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:55,836 INFO:     Epoch: 69
2023-01-05 14:10:57,984 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4339160511891047, 'Total loss': 0.4339160511891047} | train loss {'Reaction outcome loss': 0.2902060040477132, 'Total loss': 0.2902060040477132}
2023-01-05 14:10:57,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:10:57,984 INFO:     Epoch: 70
2023-01-05 14:11:00,140 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4353615641593933, 'Total loss': 0.4353615641593933} | train loss {'Reaction outcome loss': 0.283611137493964, 'Total loss': 0.283611137493964}
2023-01-05 14:11:00,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:00,140 INFO:     Epoch: 71
2023-01-05 14:11:02,283 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4168682446082433, 'Total loss': 0.4168682446082433} | train loss {'Reaction outcome loss': 0.2759762581061269, 'Total loss': 0.2759762581061269}
2023-01-05 14:11:02,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:02,283 INFO:     Epoch: 72
2023-01-05 14:11:04,431 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40782457490762075, 'Total loss': 0.40782457490762075} | train loss {'Reaction outcome loss': 0.2859528986714988, 'Total loss': 0.2859528986714988}
2023-01-05 14:11:04,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:04,432 INFO:     Epoch: 73
2023-01-05 14:11:06,579 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45013267993927003, 'Total loss': 0.45013267993927003} | train loss {'Reaction outcome loss': 0.2801627986052114, 'Total loss': 0.2801627986052114}
2023-01-05 14:11:06,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:06,579 INFO:     Epoch: 74
2023-01-05 14:11:08,735 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47827740708986916, 'Total loss': 0.47827740708986916} | train loss {'Reaction outcome loss': 0.2852956786400814, 'Total loss': 0.2852956786400814}
2023-01-05 14:11:08,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:08,736 INFO:     Epoch: 75
2023-01-05 14:11:10,888 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4338044772545497, 'Total loss': 0.4338044772545497} | train loss {'Reaction outcome loss': 0.279238622806008, 'Total loss': 0.279238622806008}
2023-01-05 14:11:10,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:10,889 INFO:     Epoch: 76
2023-01-05 14:11:13,048 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43004259864489236, 'Total loss': 0.43004259864489236} | train loss {'Reaction outcome loss': 0.27851674343000393, 'Total loss': 0.27851674343000393}
2023-01-05 14:11:13,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:13,049 INFO:     Epoch: 77
2023-01-05 14:11:15,188 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4379631151755651, 'Total loss': 0.4379631151755651} | train loss {'Reaction outcome loss': 0.27590979537184257, 'Total loss': 0.27590979537184257}
2023-01-05 14:11:15,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:15,188 INFO:     Epoch: 78
2023-01-05 14:11:17,341 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4320201396942139, 'Total loss': 0.4320201396942139} | train loss {'Reaction outcome loss': 0.27721895279879505, 'Total loss': 0.27721895279879505}
2023-01-05 14:11:17,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:17,341 INFO:     Epoch: 79
2023-01-05 14:11:19,494 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4757586161295573, 'Total loss': 0.4757586161295573} | train loss {'Reaction outcome loss': 0.2722587359390488, 'Total loss': 0.2722587359390488}
2023-01-05 14:11:19,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:19,494 INFO:     Epoch: 80
2023-01-05 14:11:21,647 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4550530428687731, 'Total loss': 0.4550530428687731} | train loss {'Reaction outcome loss': 0.26995956573533686, 'Total loss': 0.26995956573533686}
2023-01-05 14:11:21,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:21,647 INFO:     Epoch: 81
2023-01-05 14:11:23,804 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44052815064787865, 'Total loss': 0.44052815064787865} | train loss {'Reaction outcome loss': 0.270814786395193, 'Total loss': 0.270814786395193}
2023-01-05 14:11:23,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:23,804 INFO:     Epoch: 82
2023-01-05 14:11:25,961 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45464276770750683, 'Total loss': 0.45464276770750683} | train loss {'Reaction outcome loss': 0.35062563357760024, 'Total loss': 0.35062563357760024}
2023-01-05 14:11:25,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:25,962 INFO:     Epoch: 83
2023-01-05 14:11:28,119 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4433710664510727, 'Total loss': 0.4433710664510727} | train loss {'Reaction outcome loss': 0.2912422252036091, 'Total loss': 0.2912422252036091}
2023-01-05 14:11:28,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:28,120 INFO:     Epoch: 84
2023-01-05 14:11:30,284 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4740222414334615, 'Total loss': 0.4740222414334615} | train loss {'Reaction outcome loss': 0.27207864446762065, 'Total loss': 0.27207864446762065}
2023-01-05 14:11:30,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:30,284 INFO:     Epoch: 85
2023-01-05 14:11:32,455 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4315514514843623, 'Total loss': 0.4315514514843623} | train loss {'Reaction outcome loss': 0.26790213835888804, 'Total loss': 0.26790213835888804}
2023-01-05 14:11:32,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:32,456 INFO:     Epoch: 86
2023-01-05 14:11:34,630 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43043714463710786, 'Total loss': 0.43043714463710786} | train loss {'Reaction outcome loss': 0.26043525319107796, 'Total loss': 0.26043525319107796}
2023-01-05 14:11:34,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:34,630 INFO:     Epoch: 87
2023-01-05 14:11:36,797 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4230273087819417, 'Total loss': 0.4230273087819417} | train loss {'Reaction outcome loss': 0.2546177614747886, 'Total loss': 0.2546177614747886}
2023-01-05 14:11:36,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:36,798 INFO:     Epoch: 88
2023-01-05 14:11:38,975 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4106946582595507, 'Total loss': 0.4106946582595507} | train loss {'Reaction outcome loss': 0.258245749758435, 'Total loss': 0.258245749758435}
2023-01-05 14:11:38,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:38,975 INFO:     Epoch: 89
2023-01-05 14:11:41,135 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.438827524582545, 'Total loss': 0.438827524582545} | train loss {'Reaction outcome loss': 0.2578434398772357, 'Total loss': 0.2578434398772357}
2023-01-05 14:11:41,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:41,135 INFO:     Epoch: 90
2023-01-05 14:11:43,325 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4330968896547953, 'Total loss': 0.4330968896547953} | train loss {'Reaction outcome loss': 0.25977877785824577, 'Total loss': 0.25977877785824577}
2023-01-05 14:11:43,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:43,325 INFO:     Epoch: 91
2023-01-05 14:11:45,520 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4403822352488836, 'Total loss': 0.4403822352488836} | train loss {'Reaction outcome loss': 0.2569905159745257, 'Total loss': 0.2569905159745257}
2023-01-05 14:11:45,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:45,521 INFO:     Epoch: 92
2023-01-05 14:11:47,694 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44107191065947216, 'Total loss': 0.44107191065947216} | train loss {'Reaction outcome loss': 0.2646805078302745, 'Total loss': 0.2646805078302745}
2023-01-05 14:11:47,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:47,695 INFO:     Epoch: 93
2023-01-05 14:11:49,839 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4593579938014348, 'Total loss': 0.4593579938014348} | train loss {'Reaction outcome loss': 0.26200711724780285, 'Total loss': 0.26200711724780285}
2023-01-05 14:11:49,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:49,839 INFO:     Epoch: 94
2023-01-05 14:11:51,993 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4851327151060104, 'Total loss': 0.4851327151060104} | train loss {'Reaction outcome loss': 0.25788268288243155, 'Total loss': 0.25788268288243155}
2023-01-05 14:11:51,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:51,993 INFO:     Epoch: 95
2023-01-05 14:11:54,156 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45667739113171896, 'Total loss': 0.45667739113171896} | train loss {'Reaction outcome loss': 0.25748492691554536, 'Total loss': 0.25748492691554536}
2023-01-05 14:11:54,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:54,156 INFO:     Epoch: 96
2023-01-05 14:11:56,314 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4444010357062022, 'Total loss': 0.4444010357062022} | train loss {'Reaction outcome loss': 0.2533858323543994, 'Total loss': 0.2533858323543994}
2023-01-05 14:11:56,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:56,316 INFO:     Epoch: 97
2023-01-05 14:11:58,466 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4372917299469312, 'Total loss': 0.4372917299469312} | train loss {'Reaction outcome loss': 0.2558660298337909, 'Total loss': 0.2558660298337909}
2023-01-05 14:11:58,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:11:58,466 INFO:     Epoch: 98
2023-01-05 14:12:00,612 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4427989770968755, 'Total loss': 0.4427989770968755} | train loss {'Reaction outcome loss': 0.2518629854742397, 'Total loss': 0.2518629854742397}
2023-01-05 14:12:00,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:00,612 INFO:     Epoch: 99
2023-01-05 14:12:02,754 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47444240500529605, 'Total loss': 0.47444240500529605} | train loss {'Reaction outcome loss': 0.2511488967237697, 'Total loss': 0.2511488967237697}
2023-01-05 14:12:02,755 INFO:     Best model found after epoch 56 of 100.
2023-01-05 14:12:02,755 INFO:   Done with stage: TRAINING
2023-01-05 14:12:02,755 INFO:   Starting stage: EVALUATION
2023-01-05 14:12:02,886 INFO:   Done with stage: EVALUATION
2023-01-05 14:12:02,887 INFO:   Leaving out SEQ value Fold_9
2023-01-05 14:12:02,899 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 14:12:02,899 INFO:   Starting stage: FEATURE SCALING
2023-01-05 14:12:03,550 INFO:   Done with stage: FEATURE SCALING
2023-01-05 14:12:03,550 INFO:   Starting stage: SCALING TARGETS
2023-01-05 14:12:03,619 INFO:   Done with stage: SCALING TARGETS
2023-01-05 14:12:03,619 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:12:03,619 INFO:     No hyperparam tuning for this model
2023-01-05 14:12:03,619 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:12:03,619 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 14:12:03,620 INFO:     None feature selector for col prot
2023-01-05 14:12:03,620 INFO:     None feature selector for col prot
2023-01-05 14:12:03,620 INFO:     None feature selector for col prot
2023-01-05 14:12:03,621 INFO:     None feature selector for col chem
2023-01-05 14:12:03,621 INFO:     None feature selector for col chem
2023-01-05 14:12:03,621 INFO:     None feature selector for col chem
2023-01-05 14:12:03,621 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 14:12:03,621 INFO:   Starting stage: BUILD MODEL
2023-01-05 14:12:03,622 INFO:     Number of params in model 72901
2023-01-05 14:12:03,626 INFO:   Done with stage: BUILD MODEL
2023-01-05 14:12:03,626 INFO:   Starting stage: TRAINING
2023-01-05 14:12:03,685 INFO:     Val loss before train {'Reaction outcome loss': 0.9920095940430959, 'Total loss': 0.9920095940430959}
2023-01-05 14:12:03,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:03,685 INFO:     Epoch: 0
2023-01-05 14:12:05,845 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8113089243570963, 'Total loss': 0.8113089243570963} | train loss {'Reaction outcome loss': 0.929249108971461, 'Total loss': 0.929249108971461}
2023-01-05 14:12:05,845 INFO:     Found new best model at epoch 0
2023-01-05 14:12:05,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:05,846 INFO:     Epoch: 1
2023-01-05 14:12:08,013 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5925425966580709, 'Total loss': 0.5925425966580709} | train loss {'Reaction outcome loss': 0.7616840022467617, 'Total loss': 0.7616840022467617}
2023-01-05 14:12:08,013 INFO:     Found new best model at epoch 1
2023-01-05 14:12:08,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:08,015 INFO:     Epoch: 2
2023-01-05 14:12:10,169 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.522472228606542, 'Total loss': 0.522472228606542} | train loss {'Reaction outcome loss': 0.598685959637489, 'Total loss': 0.598685959637489}
2023-01-05 14:12:10,169 INFO:     Found new best model at epoch 2
2023-01-05 14:12:10,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:10,171 INFO:     Epoch: 3
2023-01-05 14:12:12,343 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49355790416399636, 'Total loss': 0.49355790416399636} | train loss {'Reaction outcome loss': 0.5474149067514994, 'Total loss': 0.5474149067514994}
2023-01-05 14:12:12,343 INFO:     Found new best model at epoch 3
2023-01-05 14:12:12,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:12,345 INFO:     Epoch: 4
2023-01-05 14:12:14,487 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46608322660128276, 'Total loss': 0.46608322660128276} | train loss {'Reaction outcome loss': 0.5277057017429151, 'Total loss': 0.5277057017429151}
2023-01-05 14:12:14,487 INFO:     Found new best model at epoch 4
2023-01-05 14:12:14,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:14,488 INFO:     Epoch: 5
2023-01-05 14:12:16,650 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45091761549313863, 'Total loss': 0.45091761549313863} | train loss {'Reaction outcome loss': 0.5468906010838522, 'Total loss': 0.5468906010838522}
2023-01-05 14:12:16,651 INFO:     Found new best model at epoch 5
2023-01-05 14:12:16,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:16,652 INFO:     Epoch: 6
2023-01-05 14:12:18,787 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4660796314477921, 'Total loss': 0.4660796314477921} | train loss {'Reaction outcome loss': 0.557179637843797, 'Total loss': 0.557179637843797}
2023-01-05 14:12:18,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:18,787 INFO:     Epoch: 7
2023-01-05 14:12:20,954 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4373124301433563, 'Total loss': 0.4373124301433563} | train loss {'Reaction outcome loss': 0.5012943762532972, 'Total loss': 0.5012943762532972}
2023-01-05 14:12:20,954 INFO:     Found new best model at epoch 7
2023-01-05 14:12:20,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:20,955 INFO:     Epoch: 8
2023-01-05 14:12:23,111 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4428398629029592, 'Total loss': 0.4428398629029592} | train loss {'Reaction outcome loss': 0.4914128163093836, 'Total loss': 0.4914128163093836}
2023-01-05 14:12:23,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:23,111 INFO:     Epoch: 9
2023-01-05 14:12:25,265 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4637624710798264, 'Total loss': 0.4637624710798264} | train loss {'Reaction outcome loss': 0.48758345233964856, 'Total loss': 0.48758345233964856}
2023-01-05 14:12:25,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:25,265 INFO:     Epoch: 10
2023-01-05 14:12:27,417 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4207022537787755, 'Total loss': 0.4207022537787755} | train loss {'Reaction outcome loss': 0.479488915183775, 'Total loss': 0.479488915183775}
2023-01-05 14:12:27,418 INFO:     Found new best model at epoch 10
2023-01-05 14:12:27,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:27,419 INFO:     Epoch: 11
2023-01-05 14:12:29,556 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4183664321899414, 'Total loss': 0.4183664321899414} | train loss {'Reaction outcome loss': 0.4777625951544352, 'Total loss': 0.4777625951544352}
2023-01-05 14:12:29,556 INFO:     Found new best model at epoch 11
2023-01-05 14:12:29,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:29,558 INFO:     Epoch: 12
2023-01-05 14:12:31,812 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43655031025409696, 'Total loss': 0.43655031025409696} | train loss {'Reaction outcome loss': 0.46871664851736883, 'Total loss': 0.46871664851736883}
2023-01-05 14:12:31,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:31,813 INFO:     Epoch: 13
2023-01-05 14:12:33,971 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4353214353322983, 'Total loss': 0.4353214353322983} | train loss {'Reaction outcome loss': 0.4682764971883549, 'Total loss': 0.4682764971883549}
2023-01-05 14:12:33,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:33,971 INFO:     Epoch: 14
2023-01-05 14:12:36,109 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46811474760373434, 'Total loss': 0.46811474760373434} | train loss {'Reaction outcome loss': 0.4655886843962514, 'Total loss': 0.4655886843962514}
2023-01-05 14:12:36,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:36,109 INFO:     Epoch: 15
2023-01-05 14:12:38,250 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4101020202040672, 'Total loss': 0.4101020202040672} | train loss {'Reaction outcome loss': 0.4611999523029595, 'Total loss': 0.4611999523029595}
2023-01-05 14:12:38,251 INFO:     Found new best model at epoch 15
2023-01-05 14:12:38,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:38,252 INFO:     Epoch: 16
2023-01-05 14:12:40,400 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4105866501728694, 'Total loss': 0.4105866501728694} | train loss {'Reaction outcome loss': 0.4526853515822238, 'Total loss': 0.4526853515822238}
2023-01-05 14:12:40,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:40,400 INFO:     Epoch: 17
2023-01-05 14:12:42,545 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4130706270535787, 'Total loss': 0.4130706270535787} | train loss {'Reaction outcome loss': 0.44942695701467816, 'Total loss': 0.44942695701467816}
2023-01-05 14:12:42,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:42,545 INFO:     Epoch: 18
2023-01-05 14:12:44,685 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42802024483680723, 'Total loss': 0.42802024483680723} | train loss {'Reaction outcome loss': 0.4524263543130803, 'Total loss': 0.4524263543130803}
2023-01-05 14:12:44,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:44,686 INFO:     Epoch: 19
2023-01-05 14:12:46,813 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4133782724539439, 'Total loss': 0.4133782724539439} | train loss {'Reaction outcome loss': 0.4400588590449289, 'Total loss': 0.4400588590449289}
2023-01-05 14:12:46,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:46,813 INFO:     Epoch: 20
2023-01-05 14:12:49,001 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3855548034111659, 'Total loss': 0.3855548034111659} | train loss {'Reaction outcome loss': 0.43688514137951034, 'Total loss': 0.43688514137951034}
2023-01-05 14:12:49,001 INFO:     Found new best model at epoch 20
2023-01-05 14:12:49,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:49,002 INFO:     Epoch: 21
2023-01-05 14:12:51,149 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40571984002987543, 'Total loss': 0.40571984002987543} | train loss {'Reaction outcome loss': 0.4349842478324612, 'Total loss': 0.4349842478324612}
2023-01-05 14:12:51,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:51,150 INFO:     Epoch: 22
2023-01-05 14:12:53,292 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4121138110756874, 'Total loss': 0.4121138110756874} | train loss {'Reaction outcome loss': 0.4274620245592761, 'Total loss': 0.4274620245592761}
2023-01-05 14:12:53,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:53,293 INFO:     Epoch: 23
2023-01-05 14:12:55,474 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42664211293061577, 'Total loss': 0.42664211293061577} | train loss {'Reaction outcome loss': 0.4254620609125055, 'Total loss': 0.4254620609125055}
2023-01-05 14:12:55,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:55,475 INFO:     Epoch: 24
2023-01-05 14:12:57,613 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40961843033631645, 'Total loss': 0.40961843033631645} | train loss {'Reaction outcome loss': 0.42679151527725323, 'Total loss': 0.42679151527725323}
2023-01-05 14:12:57,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:57,614 INFO:     Epoch: 25
2023-01-05 14:12:59,756 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40904613137245177, 'Total loss': 0.40904613137245177} | train loss {'Reaction outcome loss': 0.42903060147511785, 'Total loss': 0.42903060147511785}
2023-01-05 14:12:59,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:12:59,756 INFO:     Epoch: 26
2023-01-05 14:13:01,900 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4010779410600662, 'Total loss': 0.4010779410600662} | train loss {'Reaction outcome loss': 0.42790734007903136, 'Total loss': 0.42790734007903136}
2023-01-05 14:13:01,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:01,900 INFO:     Epoch: 27
2023-01-05 14:13:04,039 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40095007518927256, 'Total loss': 0.40095007518927256} | train loss {'Reaction outcome loss': 0.41249795192582667, 'Total loss': 0.41249795192582667}
2023-01-05 14:13:04,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:04,040 INFO:     Epoch: 28
2023-01-05 14:13:06,185 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4089842915534973, 'Total loss': 0.4089842915534973} | train loss {'Reaction outcome loss': 0.40537660236240947, 'Total loss': 0.40537660236240947}
2023-01-05 14:13:06,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:06,186 INFO:     Epoch: 29
2023-01-05 14:13:08,330 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39830376704533893, 'Total loss': 0.39830376704533893} | train loss {'Reaction outcome loss': 0.40820932844518754, 'Total loss': 0.40820932844518754}
2023-01-05 14:13:08,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:08,330 INFO:     Epoch: 30
2023-01-05 14:13:10,474 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3963875472545624, 'Total loss': 0.3963875472545624} | train loss {'Reaction outcome loss': 0.41743438218153367, 'Total loss': 0.41743438218153367}
2023-01-05 14:13:10,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:10,475 INFO:     Epoch: 31
2023-01-05 14:13:12,635 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4160754511753718, 'Total loss': 0.4160754511753718} | train loss {'Reaction outcome loss': 0.3990790862860023, 'Total loss': 0.3990790862860023}
2023-01-05 14:13:12,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:12,635 INFO:     Epoch: 32
2023-01-05 14:13:14,783 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38271596233050026, 'Total loss': 0.38271596233050026} | train loss {'Reaction outcome loss': 0.404506776241233, 'Total loss': 0.404506776241233}
2023-01-05 14:13:14,784 INFO:     Found new best model at epoch 32
2023-01-05 14:13:14,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:14,785 INFO:     Epoch: 33
2023-01-05 14:13:16,934 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4056847721338272, 'Total loss': 0.4056847721338272} | train loss {'Reaction outcome loss': 0.3916365396538479, 'Total loss': 0.3916365396538479}
2023-01-05 14:13:16,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:16,935 INFO:     Epoch: 34
2023-01-05 14:13:19,139 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.392774639527003, 'Total loss': 0.392774639527003} | train loss {'Reaction outcome loss': 0.38818712710686354, 'Total loss': 0.38818712710686354}
2023-01-05 14:13:19,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:19,140 INFO:     Epoch: 35
2023-01-05 14:13:21,296 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4026269197463989, 'Total loss': 0.4026269197463989} | train loss {'Reaction outcome loss': 0.38015214209377335, 'Total loss': 0.38015214209377335}
2023-01-05 14:13:21,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:21,296 INFO:     Epoch: 36
2023-01-05 14:13:23,441 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3768282214800517, 'Total loss': 0.3768282214800517} | train loss {'Reaction outcome loss': 0.37777712130392777, 'Total loss': 0.37777712130392777}
2023-01-05 14:13:23,442 INFO:     Found new best model at epoch 36
2023-01-05 14:13:23,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:23,443 INFO:     Epoch: 37
2023-01-05 14:13:25,589 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38076234559218086, 'Total loss': 0.38076234559218086} | train loss {'Reaction outcome loss': 0.3796400656156829, 'Total loss': 0.3796400656156829}
2023-01-05 14:13:25,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:25,589 INFO:     Epoch: 38
2023-01-05 14:13:27,753 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38421339889367423, 'Total loss': 0.38421339889367423} | train loss {'Reaction outcome loss': 0.3742195779214735, 'Total loss': 0.3742195779214735}
2023-01-05 14:13:27,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:27,754 INFO:     Epoch: 39
2023-01-05 14:13:29,898 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3864006370306015, 'Total loss': 0.3864006370306015} | train loss {'Reaction outcome loss': 0.3662804400690062, 'Total loss': 0.3662804400690062}
2023-01-05 14:13:29,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:29,898 INFO:     Epoch: 40
2023-01-05 14:13:32,057 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4189610024293264, 'Total loss': 0.4189610024293264} | train loss {'Reaction outcome loss': 0.37217634557273943, 'Total loss': 0.37217634557273943}
2023-01-05 14:13:32,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:32,057 INFO:     Epoch: 41
2023-01-05 14:13:34,193 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3842829038699468, 'Total loss': 0.3842829038699468} | train loss {'Reaction outcome loss': 0.40995907680927846, 'Total loss': 0.40995907680927846}
2023-01-05 14:13:34,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:34,194 INFO:     Epoch: 42
2023-01-05 14:13:36,165 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.393996791044871, 'Total loss': 0.393996791044871} | train loss {'Reaction outcome loss': 0.36628199854453997, 'Total loss': 0.36628199854453997}
2023-01-05 14:13:36,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:36,166 INFO:     Epoch: 43
2023-01-05 14:13:37,931 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3872710237900416, 'Total loss': 0.3872710237900416} | train loss {'Reaction outcome loss': 0.3656246907059171, 'Total loss': 0.3656246907059171}
2023-01-05 14:13:37,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:37,931 INFO:     Epoch: 44
2023-01-05 14:13:39,744 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3949675569931666, 'Total loss': 0.3949675569931666} | train loss {'Reaction outcome loss': 0.3499745256031283, 'Total loss': 0.3499745256031283}
2023-01-05 14:13:39,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:39,745 INFO:     Epoch: 45
2023-01-05 14:13:41,861 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43751879334449767, 'Total loss': 0.43751879334449767} | train loss {'Reaction outcome loss': 0.35911701419863146, 'Total loss': 0.35911701419863146}
2023-01-05 14:13:41,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:41,861 INFO:     Epoch: 46
2023-01-05 14:13:43,825 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38741466303666433, 'Total loss': 0.38741466303666433} | train loss {'Reaction outcome loss': 0.3694700550800864, 'Total loss': 0.3694700550800864}
2023-01-05 14:13:43,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:43,825 INFO:     Epoch: 47
2023-01-05 14:13:45,978 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39463975727558137, 'Total loss': 0.39463975727558137} | train loss {'Reaction outcome loss': 0.3501412769276784, 'Total loss': 0.3501412769276784}
2023-01-05 14:13:45,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:45,979 INFO:     Epoch: 48
2023-01-05 14:13:48,142 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3895311067501704, 'Total loss': 0.3895311067501704} | train loss {'Reaction outcome loss': 0.3457937149262801, 'Total loss': 0.3457937149262801}
2023-01-05 14:13:48,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:48,142 INFO:     Epoch: 49
2023-01-05 14:13:50,294 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3860941857099533, 'Total loss': 0.3860941857099533} | train loss {'Reaction outcome loss': 0.3440058532481392, 'Total loss': 0.3440058532481392}
2023-01-05 14:13:50,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:50,294 INFO:     Epoch: 50
2023-01-05 14:13:52,444 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.35998059809207916, 'Total loss': 0.35998059809207916} | train loss {'Reaction outcome loss': 0.3427865968663526, 'Total loss': 0.3427865968663526}
2023-01-05 14:13:52,444 INFO:     Found new best model at epoch 50
2023-01-05 14:13:52,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:52,446 INFO:     Epoch: 51
2023-01-05 14:13:54,588 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4124057908852895, 'Total loss': 0.4124057908852895} | train loss {'Reaction outcome loss': 0.343651303778524, 'Total loss': 0.343651303778524}
2023-01-05 14:13:54,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:54,588 INFO:     Epoch: 52
2023-01-05 14:13:56,741 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42248837848504384, 'Total loss': 0.42248837848504384} | train loss {'Reaction outcome loss': 0.34215104494216864, 'Total loss': 0.34215104494216864}
2023-01-05 14:13:56,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:56,741 INFO:     Epoch: 53
2023-01-05 14:13:58,932 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.399711175262928, 'Total loss': 0.399711175262928} | train loss {'Reaction outcome loss': 0.33501992223867, 'Total loss': 0.33501992223867}
2023-01-05 14:13:58,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:13:58,932 INFO:     Epoch: 54
2023-01-05 14:14:01,122 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3712457001209259, 'Total loss': 0.3712457001209259} | train loss {'Reaction outcome loss': 0.337302400028684, 'Total loss': 0.337302400028684}
2023-01-05 14:14:01,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:01,122 INFO:     Epoch: 55
2023-01-05 14:14:03,255 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3885385483503342, 'Total loss': 0.3885385483503342} | train loss {'Reaction outcome loss': 0.3831370214972159, 'Total loss': 0.3831370214972159}
2023-01-05 14:14:03,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:03,256 INFO:     Epoch: 56
2023-01-05 14:14:05,406 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3833205677568913, 'Total loss': 0.3833205677568913} | train loss {'Reaction outcome loss': 0.3466263700958233, 'Total loss': 0.3466263700958233}
2023-01-05 14:14:05,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:05,406 INFO:     Epoch: 57
2023-01-05 14:14:07,528 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39127403100331626, 'Total loss': 0.39127403100331626} | train loss {'Reaction outcome loss': 0.3283470723764512, 'Total loss': 0.3283470723764512}
2023-01-05 14:14:07,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:07,528 INFO:     Epoch: 58
2023-01-05 14:14:09,676 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4043845434983571, 'Total loss': 0.4043845434983571} | train loss {'Reaction outcome loss': 0.3172256511928593, 'Total loss': 0.3172256511928593}
2023-01-05 14:14:09,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:09,677 INFO:     Epoch: 59
2023-01-05 14:14:11,853 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38815045605103177, 'Total loss': 0.38815045605103177} | train loss {'Reaction outcome loss': 0.3175100984500613, 'Total loss': 0.3175100984500613}
2023-01-05 14:14:11,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:11,853 INFO:     Epoch: 60
2023-01-05 14:14:14,017 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40351335803667704, 'Total loss': 0.40351335803667704} | train loss {'Reaction outcome loss': 0.33040628581732995, 'Total loss': 0.33040628581732995}
2023-01-05 14:14:14,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:14,018 INFO:     Epoch: 61
2023-01-05 14:14:16,154 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4107640023032824, 'Total loss': 0.4107640023032824} | train loss {'Reaction outcome loss': 0.31876265279699006, 'Total loss': 0.31876265279699006}
2023-01-05 14:14:16,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:16,155 INFO:     Epoch: 62
2023-01-05 14:14:18,323 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37830870449542997, 'Total loss': 0.37830870449542997} | train loss {'Reaction outcome loss': 0.31193243958129996, 'Total loss': 0.31193243958129996}
2023-01-05 14:14:18,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:18,324 INFO:     Epoch: 63
2023-01-05 14:14:20,459 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3773909454544385, 'Total loss': 0.3773909454544385} | train loss {'Reaction outcome loss': 0.3158778578609876, 'Total loss': 0.3158778578609876}
2023-01-05 14:14:20,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:20,460 INFO:     Epoch: 64
2023-01-05 14:14:22,617 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43529079655806224, 'Total loss': 0.43529079655806224} | train loss {'Reaction outcome loss': 0.3069491418254061, 'Total loss': 0.3069491418254061}
2023-01-05 14:14:22,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:22,618 INFO:     Epoch: 65
2023-01-05 14:14:24,787 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39153587420781455, 'Total loss': 0.39153587420781455} | train loss {'Reaction outcome loss': 0.3070722488910837, 'Total loss': 0.3070722488910837}
2023-01-05 14:14:24,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:24,788 INFO:     Epoch: 66
2023-01-05 14:14:26,987 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3693606734275818, 'Total loss': 0.3693606734275818} | train loss {'Reaction outcome loss': 0.29952952320699283, 'Total loss': 0.29952952320699283}
2023-01-05 14:14:26,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:26,988 INFO:     Epoch: 67
2023-01-05 14:14:29,223 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37473588486512505, 'Total loss': 0.37473588486512505} | train loss {'Reaction outcome loss': 0.3080378031997425, 'Total loss': 0.3080378031997425}
2023-01-05 14:14:29,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:29,223 INFO:     Epoch: 68
2023-01-05 14:14:31,404 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42662752568721773, 'Total loss': 0.42662752568721773} | train loss {'Reaction outcome loss': 0.31128448172323947, 'Total loss': 0.31128448172323947}
2023-01-05 14:14:31,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:31,404 INFO:     Epoch: 69
2023-01-05 14:14:33,590 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3921729197104772, 'Total loss': 0.3921729197104772} | train loss {'Reaction outcome loss': 0.39039344624536065, 'Total loss': 0.39039344624536065}
2023-01-05 14:14:33,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:33,590 INFO:     Epoch: 70
2023-01-05 14:14:35,773 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3488283058007558, 'Total loss': 0.3488283058007558} | train loss {'Reaction outcome loss': 0.3116831835211707, 'Total loss': 0.3116831835211707}
2023-01-05 14:14:35,773 INFO:     Found new best model at epoch 70
2023-01-05 14:14:35,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:35,774 INFO:     Epoch: 71
2023-01-05 14:14:37,948 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38164255718390144, 'Total loss': 0.38164255718390144} | train loss {'Reaction outcome loss': 0.30595719653681136, 'Total loss': 0.30595719653681136}
2023-01-05 14:14:37,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:37,948 INFO:     Epoch: 72
2023-01-05 14:14:40,071 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4205561071634293, 'Total loss': 0.4205561071634293} | train loss {'Reaction outcome loss': 0.3005232861724453, 'Total loss': 0.3005232861724453}
2023-01-05 14:14:40,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:40,073 INFO:     Epoch: 73
2023-01-05 14:14:42,219 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3802842557430267, 'Total loss': 0.3802842557430267} | train loss {'Reaction outcome loss': 0.29011291206942574, 'Total loss': 0.29011291206942574}
2023-01-05 14:14:42,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:42,219 INFO:     Epoch: 74
2023-01-05 14:14:44,373 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38153234124183655, 'Total loss': 0.38153234124183655} | train loss {'Reaction outcome loss': 0.29709103933292563, 'Total loss': 0.29709103933292563}
2023-01-05 14:14:44,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:44,373 INFO:     Epoch: 75
2023-01-05 14:14:46,538 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3793591489394506, 'Total loss': 0.3793591489394506} | train loss {'Reaction outcome loss': 0.2861752494160707, 'Total loss': 0.2861752494160707}
2023-01-05 14:14:46,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:46,539 INFO:     Epoch: 76
2023-01-05 14:14:48,693 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40133873323599495, 'Total loss': 0.40133873323599495} | train loss {'Reaction outcome loss': 0.2945873746707482, 'Total loss': 0.2945873746707482}
2023-01-05 14:14:48,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:48,693 INFO:     Epoch: 77
2023-01-05 14:14:50,842 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.412283090253671, 'Total loss': 0.412283090253671} | train loss {'Reaction outcome loss': 0.28913611654475657, 'Total loss': 0.28913611654475657}
2023-01-05 14:14:50,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:50,842 INFO:     Epoch: 78
2023-01-05 14:14:52,993 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.37479079365730283, 'Total loss': 0.37479079365730283} | train loss {'Reaction outcome loss': 0.29238591467340785, 'Total loss': 0.29238591467340785}
2023-01-05 14:14:52,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:52,993 INFO:     Epoch: 79
2023-01-05 14:14:55,147 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4152332420150439, 'Total loss': 0.4152332420150439} | train loss {'Reaction outcome loss': 0.28240516585904424, 'Total loss': 0.28240516585904424}
2023-01-05 14:14:55,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:55,147 INFO:     Epoch: 80
2023-01-05 14:14:57,277 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4201595768332481, 'Total loss': 0.4201595768332481} | train loss {'Reaction outcome loss': 0.2851224760322467, 'Total loss': 0.2851224760322467}
2023-01-05 14:14:57,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:57,277 INFO:     Epoch: 81
2023-01-05 14:14:59,437 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.376117372016112, 'Total loss': 0.376117372016112} | train loss {'Reaction outcome loss': 0.2859336539381268, 'Total loss': 0.2859336539381268}
2023-01-05 14:14:59,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:14:59,438 INFO:     Epoch: 82
2023-01-05 14:15:01,580 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3875613366564115, 'Total loss': 0.3875613366564115} | train loss {'Reaction outcome loss': 0.28165429985940293, 'Total loss': 0.28165429985940293}
2023-01-05 14:15:01,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:01,580 INFO:     Epoch: 83
2023-01-05 14:15:03,699 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3669554630915324, 'Total loss': 0.3669554630915324} | train loss {'Reaction outcome loss': 0.2752151087725919, 'Total loss': 0.2752151087725919}
2023-01-05 14:15:03,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:03,699 INFO:     Epoch: 84
2023-01-05 14:15:05,857 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38038059944907826, 'Total loss': 0.38038059944907826} | train loss {'Reaction outcome loss': 0.281602094187068, 'Total loss': 0.281602094187068}
2023-01-05 14:15:05,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:05,857 INFO:     Epoch: 85
2023-01-05 14:15:08,000 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3927137076854706, 'Total loss': 0.3927137076854706} | train loss {'Reaction outcome loss': 0.27135742334244045, 'Total loss': 0.27135742334244045}
2023-01-05 14:15:08,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:08,000 INFO:     Epoch: 86
2023-01-05 14:15:10,136 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3901540825764338, 'Total loss': 0.3901540825764338} | train loss {'Reaction outcome loss': 0.2750307513026359, 'Total loss': 0.2750307513026359}
2023-01-05 14:15:10,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:10,137 INFO:     Epoch: 87
2023-01-05 14:15:12,292 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38725312252839406, 'Total loss': 0.38725312252839406} | train loss {'Reaction outcome loss': 0.27114879878628423, 'Total loss': 0.27114879878628423}
2023-01-05 14:15:12,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:12,292 INFO:     Epoch: 88
2023-01-05 14:15:14,418 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3754425020267566, 'Total loss': 0.3754425020267566} | train loss {'Reaction outcome loss': 0.27677267000894906, 'Total loss': 0.27677267000894906}
2023-01-05 14:15:14,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:14,418 INFO:     Epoch: 89
2023-01-05 14:15:16,582 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37810952166716255, 'Total loss': 0.37810952166716255} | train loss {'Reaction outcome loss': 0.26748843265628186, 'Total loss': 0.26748843265628186}
2023-01-05 14:15:16,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:16,583 INFO:     Epoch: 90
2023-01-05 14:15:18,724 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39051599403222403, 'Total loss': 0.39051599403222403} | train loss {'Reaction outcome loss': 0.2698187272276959, 'Total loss': 0.2698187272276959}
2023-01-05 14:15:18,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:18,724 INFO:     Epoch: 91
2023-01-05 14:15:20,885 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3827271198232969, 'Total loss': 0.3827271198232969} | train loss {'Reaction outcome loss': 0.2657957980974469, 'Total loss': 0.2657957980974469}
2023-01-05 14:15:20,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:20,885 INFO:     Epoch: 92
2023-01-05 14:15:23,035 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4059412787357966, 'Total loss': 0.4059412787357966} | train loss {'Reaction outcome loss': 0.26764755478074803, 'Total loss': 0.26764755478074803}
2023-01-05 14:15:23,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:23,036 INFO:     Epoch: 93
2023-01-05 14:15:25,170 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3775865892569224, 'Total loss': 0.3775865892569224} | train loss {'Reaction outcome loss': 0.2705466851754033, 'Total loss': 0.2705466851754033}
2023-01-05 14:15:25,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:25,170 INFO:     Epoch: 94
2023-01-05 14:15:27,358 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3988494982322057, 'Total loss': 0.3988494982322057} | train loss {'Reaction outcome loss': 0.27848855645456555, 'Total loss': 0.27848855645456555}
2023-01-05 14:15:27,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:27,358 INFO:     Epoch: 95
2023-01-05 14:15:29,586 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.383756456275781, 'Total loss': 0.383756456275781} | train loss {'Reaction outcome loss': 0.26387957798020134, 'Total loss': 0.26387957798020134}
2023-01-05 14:15:29,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:29,587 INFO:     Epoch: 96
2023-01-05 14:15:31,792 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39376808603604635, 'Total loss': 0.39376808603604635} | train loss {'Reaction outcome loss': 0.2834522701003521, 'Total loss': 0.2834522701003521}
2023-01-05 14:15:31,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:31,792 INFO:     Epoch: 97
2023-01-05 14:15:33,974 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3707867629826069, 'Total loss': 0.3707867629826069} | train loss {'Reaction outcome loss': 0.2648972980273159, 'Total loss': 0.2648972980273159}
2023-01-05 14:15:33,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:33,974 INFO:     Epoch: 98
2023-01-05 14:15:36,117 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39942883551120756, 'Total loss': 0.39942883551120756} | train loss {'Reaction outcome loss': 0.27834137576315116, 'Total loss': 0.27834137576315116}
2023-01-05 14:15:36,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:36,117 INFO:     Epoch: 99
2023-01-05 14:15:38,261 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3691003864941498, 'Total loss': 0.3691003864941498} | train loss {'Reaction outcome loss': 0.26033625484484696, 'Total loss': 0.26033625484484696}
2023-01-05 14:15:38,261 INFO:     Best model found after epoch 71 of 100.
2023-01-05 14:15:38,261 INFO:   Done with stage: TRAINING
2023-01-05 14:15:38,261 INFO:   Starting stage: EVALUATION
2023-01-05 14:15:38,394 INFO:   Done with stage: EVALUATION
2023-01-05 14:15:38,402 INFO:   Leaving out SEQ value Fold_0
2023-01-05 14:15:38,415 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 14:15:38,415 INFO:   Starting stage: FEATURE SCALING
2023-01-05 14:15:39,061 INFO:   Done with stage: FEATURE SCALING
2023-01-05 14:15:39,061 INFO:   Starting stage: SCALING TARGETS
2023-01-05 14:15:39,129 INFO:   Done with stage: SCALING TARGETS
2023-01-05 14:15:39,129 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:15:39,129 INFO:     No hyperparam tuning for this model
2023-01-05 14:15:39,129 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:15:39,129 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 14:15:39,130 INFO:     None feature selector for col prot
2023-01-05 14:15:39,130 INFO:     None feature selector for col prot
2023-01-05 14:15:39,130 INFO:     None feature selector for col prot
2023-01-05 14:15:39,131 INFO:     None feature selector for col chem
2023-01-05 14:15:39,131 INFO:     None feature selector for col chem
2023-01-05 14:15:39,131 INFO:     None feature selector for col chem
2023-01-05 14:15:39,131 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 14:15:39,131 INFO:   Starting stage: BUILD MODEL
2023-01-05 14:15:39,132 INFO:     Number of params in model 72901
2023-01-05 14:15:39,136 INFO:   Done with stage: BUILD MODEL
2023-01-05 14:15:39,136 INFO:   Starting stage: TRAINING
2023-01-05 14:15:39,195 INFO:     Val loss before train {'Reaction outcome loss': 0.9976757089296977, 'Total loss': 0.9976757089296977}
2023-01-05 14:15:39,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:39,195 INFO:     Epoch: 0
2023-01-05 14:15:41,328 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7984312494595845, 'Total loss': 0.7984312494595845} | train loss {'Reaction outcome loss': 0.9086015942322947, 'Total loss': 0.9086015942322947}
2023-01-05 14:15:41,328 INFO:     Found new best model at epoch 0
2023-01-05 14:15:41,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:41,330 INFO:     Epoch: 1
2023-01-05 14:15:43,461 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.622012068827947, 'Total loss': 0.622012068827947} | train loss {'Reaction outcome loss': 0.7182300983771791, 'Total loss': 0.7182300983771791}
2023-01-05 14:15:43,461 INFO:     Found new best model at epoch 1
2023-01-05 14:15:43,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:43,463 INFO:     Epoch: 2
2023-01-05 14:15:45,605 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5212352653344472, 'Total loss': 0.5212352653344472} | train loss {'Reaction outcome loss': 0.5722131384876523, 'Total loss': 0.5722131384876523}
2023-01-05 14:15:45,606 INFO:     Found new best model at epoch 2
2023-01-05 14:15:45,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:45,607 INFO:     Epoch: 3
2023-01-05 14:15:47,761 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5326585650444031, 'Total loss': 0.5326585650444031} | train loss {'Reaction outcome loss': 0.5362920495715454, 'Total loss': 0.5362920495715454}
2023-01-05 14:15:47,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:47,762 INFO:     Epoch: 4
2023-01-05 14:15:49,902 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5138192355632782, 'Total loss': 0.5138192355632782} | train loss {'Reaction outcome loss': 0.5139137952432146, 'Total loss': 0.5139137952432146}
2023-01-05 14:15:49,903 INFO:     Found new best model at epoch 4
2023-01-05 14:15:49,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:49,904 INFO:     Epoch: 5
2023-01-05 14:15:52,038 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5072558601697286, 'Total loss': 0.5072558601697286} | train loss {'Reaction outcome loss': 0.5024399378874006, 'Total loss': 0.5024399378874006}
2023-01-05 14:15:52,039 INFO:     Found new best model at epoch 5
2023-01-05 14:15:52,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:52,040 INFO:     Epoch: 6
2023-01-05 14:15:54,173 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48827036321163175, 'Total loss': 0.48827036321163175} | train loss {'Reaction outcome loss': 0.49576784387557177, 'Total loss': 0.49576784387557177}
2023-01-05 14:15:54,173 INFO:     Found new best model at epoch 6
2023-01-05 14:15:54,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:54,174 INFO:     Epoch: 7
2023-01-05 14:15:56,332 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4755173067251841, 'Total loss': 0.4755173067251841} | train loss {'Reaction outcome loss': 0.4872990440386925, 'Total loss': 0.4872990440386925}
2023-01-05 14:15:56,332 INFO:     Found new best model at epoch 7
2023-01-05 14:15:56,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:56,333 INFO:     Epoch: 8
2023-01-05 14:15:58,455 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47276836236317954, 'Total loss': 0.47276836236317954} | train loss {'Reaction outcome loss': 0.4751257313972842, 'Total loss': 0.4751257313972842}
2023-01-05 14:15:58,455 INFO:     Found new best model at epoch 8
2023-01-05 14:15:58,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:15:58,456 INFO:     Epoch: 9
2023-01-05 14:16:00,605 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49159587423006695, 'Total loss': 0.49159587423006695} | train loss {'Reaction outcome loss': 0.4691690568723818, 'Total loss': 0.4691690568723818}
2023-01-05 14:16:00,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:00,605 INFO:     Epoch: 10
2023-01-05 14:16:02,749 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4653597633043925, 'Total loss': 0.4653597633043925} | train loss {'Reaction outcome loss': 0.4673394146409348, 'Total loss': 0.4673394146409348}
2023-01-05 14:16:02,750 INFO:     Found new best model at epoch 10
2023-01-05 14:16:02,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:02,751 INFO:     Epoch: 11
2023-01-05 14:16:04,899 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45948984026908873, 'Total loss': 0.45948984026908873} | train loss {'Reaction outcome loss': 0.461334714652413, 'Total loss': 0.461334714652413}
2023-01-05 14:16:04,899 INFO:     Found new best model at epoch 11
2023-01-05 14:16:04,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:04,901 INFO:     Epoch: 12
2023-01-05 14:16:06,710 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4438654452562332, 'Total loss': 0.4438654452562332} | train loss {'Reaction outcome loss': 0.45539110730381777, 'Total loss': 0.45539110730381777}
2023-01-05 14:16:06,711 INFO:     Found new best model at epoch 12
2023-01-05 14:16:06,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:06,712 INFO:     Epoch: 13
2023-01-05 14:16:08,479 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.468957926829656, 'Total loss': 0.468957926829656} | train loss {'Reaction outcome loss': 0.44924288232178583, 'Total loss': 0.44924288232178583}
2023-01-05 14:16:08,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:08,480 INFO:     Epoch: 14
2023-01-05 14:16:10,473 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4710569302241007, 'Total loss': 0.4710569302241007} | train loss {'Reaction outcome loss': 0.44812264010636477, 'Total loss': 0.44812264010636477}
2023-01-05 14:16:10,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:10,474 INFO:     Epoch: 15
2023-01-05 14:16:12,623 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4492098947366079, 'Total loss': 0.4492098947366079} | train loss {'Reaction outcome loss': 0.44015511968275056, 'Total loss': 0.44015511968275056}
2023-01-05 14:16:12,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:12,623 INFO:     Epoch: 16
2023-01-05 14:16:14,759 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4435090427597364, 'Total loss': 0.4435090427597364} | train loss {'Reaction outcome loss': 0.44052955361395857, 'Total loss': 0.44052955361395857}
2023-01-05 14:16:14,759 INFO:     Found new best model at epoch 16
2023-01-05 14:16:14,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:14,760 INFO:     Epoch: 17
2023-01-05 14:16:16,908 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4383270184199015, 'Total loss': 0.4383270184199015} | train loss {'Reaction outcome loss': 0.4331127541669964, 'Total loss': 0.4331127541669964}
2023-01-05 14:16:16,908 INFO:     Found new best model at epoch 17
2023-01-05 14:16:16,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:16,909 INFO:     Epoch: 18
2023-01-05 14:16:19,054 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4544952869415283, 'Total loss': 0.4544952869415283} | train loss {'Reaction outcome loss': 0.42588480882836083, 'Total loss': 0.42588480882836083}
2023-01-05 14:16:19,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:19,055 INFO:     Epoch: 19
2023-01-05 14:16:21,182 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4302640895048777, 'Total loss': 0.4302640895048777} | train loss {'Reaction outcome loss': 0.41994796861914824, 'Total loss': 0.41994796861914824}
2023-01-05 14:16:21,183 INFO:     Found new best model at epoch 19
2023-01-05 14:16:21,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:21,184 INFO:     Epoch: 20
2023-01-05 14:16:23,320 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4518711050351461, 'Total loss': 0.4518711050351461} | train loss {'Reaction outcome loss': 0.41955315667021015, 'Total loss': 0.41955315667021015}
2023-01-05 14:16:23,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:23,320 INFO:     Epoch: 21
2023-01-05 14:16:25,469 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44308580954869586, 'Total loss': 0.44308580954869586} | train loss {'Reaction outcome loss': 0.4121958327064984, 'Total loss': 0.4121958327064984}
2023-01-05 14:16:25,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:25,469 INFO:     Epoch: 22
2023-01-05 14:16:27,615 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4293109357357025, 'Total loss': 0.4293109357357025} | train loss {'Reaction outcome loss': 0.4113178711085424, 'Total loss': 0.4113178711085424}
2023-01-05 14:16:27,616 INFO:     Found new best model at epoch 22
2023-01-05 14:16:27,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:27,617 INFO:     Epoch: 23
2023-01-05 14:16:29,738 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4304633766412735, 'Total loss': 0.4304633766412735} | train loss {'Reaction outcome loss': 0.4051591500803067, 'Total loss': 0.4051591500803067}
2023-01-05 14:16:29,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:29,739 INFO:     Epoch: 24
2023-01-05 14:16:31,859 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4314341962337494, 'Total loss': 0.4314341962337494} | train loss {'Reaction outcome loss': 0.403108667718233, 'Total loss': 0.403108667718233}
2023-01-05 14:16:31,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:31,860 INFO:     Epoch: 25
2023-01-05 14:16:33,986 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4109910547733307, 'Total loss': 0.4109910547733307} | train loss {'Reaction outcome loss': 0.40569256550639216, 'Total loss': 0.40569256550639216}
2023-01-05 14:16:33,986 INFO:     Found new best model at epoch 25
2023-01-05 14:16:33,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:33,988 INFO:     Epoch: 26
2023-01-05 14:16:36,138 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41449156403541565, 'Total loss': 0.41449156403541565} | train loss {'Reaction outcome loss': 0.39914730748664723, 'Total loss': 0.39914730748664723}
2023-01-05 14:16:36,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:36,138 INFO:     Epoch: 27
2023-01-05 14:16:38,281 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4179353793462118, 'Total loss': 0.4179353793462118} | train loss {'Reaction outcome loss': 0.3900847288161299, 'Total loss': 0.3900847288161299}
2023-01-05 14:16:38,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:38,281 INFO:     Epoch: 28
2023-01-05 14:16:40,426 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44435239136219024, 'Total loss': 0.44435239136219024} | train loss {'Reaction outcome loss': 0.38529347399943065, 'Total loss': 0.38529347399943065}
2023-01-05 14:16:40,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:40,427 INFO:     Epoch: 29
2023-01-05 14:16:42,576 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4139279325803121, 'Total loss': 0.4139279325803121} | train loss {'Reaction outcome loss': 0.38611407093975664, 'Total loss': 0.38611407093975664}
2023-01-05 14:16:42,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:42,576 INFO:     Epoch: 30
2023-01-05 14:16:44,712 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41313625474770865, 'Total loss': 0.41313625474770865} | train loss {'Reaction outcome loss': 0.38103844410311566, 'Total loss': 0.38103844410311566}
2023-01-05 14:16:44,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:44,713 INFO:     Epoch: 31
2023-01-05 14:16:46,864 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4245264490445455, 'Total loss': 0.4245264490445455} | train loss {'Reaction outcome loss': 0.3780333714926765, 'Total loss': 0.3780333714926765}
2023-01-05 14:16:46,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:46,865 INFO:     Epoch: 32
2023-01-05 14:16:49,006 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4154057055711746, 'Total loss': 0.4154057055711746} | train loss {'Reaction outcome loss': 0.3748701709954843, 'Total loss': 0.3748701709954843}
2023-01-05 14:16:49,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:49,007 INFO:     Epoch: 33
2023-01-05 14:16:51,141 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41313447455565133, 'Total loss': 0.41313447455565133} | train loss {'Reaction outcome loss': 0.3717210659091055, 'Total loss': 0.3717210659091055}
2023-01-05 14:16:51,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:51,142 INFO:     Epoch: 34
2023-01-05 14:16:53,275 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4164745012919108, 'Total loss': 0.4164745012919108} | train loss {'Reaction outcome loss': 0.36443106699598965, 'Total loss': 0.36443106699598965}
2023-01-05 14:16:53,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:53,276 INFO:     Epoch: 35
2023-01-05 14:16:55,414 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41852358082930247, 'Total loss': 0.41852358082930247} | train loss {'Reaction outcome loss': 0.3591932400272493, 'Total loss': 0.3591932400272493}
2023-01-05 14:16:55,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:55,414 INFO:     Epoch: 36
2023-01-05 14:16:57,568 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41758593420187634, 'Total loss': 0.41758593420187634} | train loss {'Reaction outcome loss': 0.3563436119660844, 'Total loss': 0.3563436119660844}
2023-01-05 14:16:57,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:57,570 INFO:     Epoch: 37
2023-01-05 14:16:59,713 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4075523018836975, 'Total loss': 0.4075523018836975} | train loss {'Reaction outcome loss': 0.35367920198035935, 'Total loss': 0.35367920198035935}
2023-01-05 14:16:59,713 INFO:     Found new best model at epoch 37
2023-01-05 14:16:59,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:16:59,715 INFO:     Epoch: 38
2023-01-05 14:17:01,872 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43997435172398885, 'Total loss': 0.43997435172398885} | train loss {'Reaction outcome loss': 0.3496307472351694, 'Total loss': 0.3496307472351694}
2023-01-05 14:17:01,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:01,872 INFO:     Epoch: 39
2023-01-05 14:17:04,031 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41611927648385366, 'Total loss': 0.41611927648385366} | train loss {'Reaction outcome loss': 0.3503263378991698, 'Total loss': 0.3503263378991698}
2023-01-05 14:17:04,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:04,032 INFO:     Epoch: 40
2023-01-05 14:17:06,184 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42495836516221364, 'Total loss': 0.42495836516221364} | train loss {'Reaction outcome loss': 0.35019097180805936, 'Total loss': 0.35019097180805936}
2023-01-05 14:17:06,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:06,184 INFO:     Epoch: 41
2023-01-05 14:17:08,334 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3966421594222387, 'Total loss': 0.3966421594222387} | train loss {'Reaction outcome loss': 0.3407113105466549, 'Total loss': 0.3407113105466549}
2023-01-05 14:17:08,334 INFO:     Found new best model at epoch 41
2023-01-05 14:17:08,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:08,335 INFO:     Epoch: 42
2023-01-05 14:17:10,496 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4307386020819346, 'Total loss': 0.4307386020819346} | train loss {'Reaction outcome loss': 0.33531091258908713, 'Total loss': 0.33531091258908713}
2023-01-05 14:17:10,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:10,497 INFO:     Epoch: 43
2023-01-05 14:17:12,646 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3838459675510724, 'Total loss': 0.3838459675510724} | train loss {'Reaction outcome loss': 0.3348623867806074, 'Total loss': 0.3348623867806074}
2023-01-05 14:17:12,646 INFO:     Found new best model at epoch 43
2023-01-05 14:17:12,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:12,648 INFO:     Epoch: 44
2023-01-05 14:17:14,792 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4107165942589442, 'Total loss': 0.4107165942589442} | train loss {'Reaction outcome loss': 0.3282101219384013, 'Total loss': 0.3282101219384013}
2023-01-05 14:17:14,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:14,793 INFO:     Epoch: 45
2023-01-05 14:17:16,948 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40822253823280336, 'Total loss': 0.40822253823280336} | train loss {'Reaction outcome loss': 0.33481243506998476, 'Total loss': 0.33481243506998476}
2023-01-05 14:17:16,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:16,949 INFO:     Epoch: 46
2023-01-05 14:17:19,101 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4032394210497538, 'Total loss': 0.4032394210497538} | train loss {'Reaction outcome loss': 0.3248045155846507, 'Total loss': 0.3248045155846507}
2023-01-05 14:17:19,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:19,101 INFO:     Epoch: 47
2023-01-05 14:17:21,252 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3860262503226598, 'Total loss': 0.3860262503226598} | train loss {'Reaction outcome loss': 0.3203504708779119, 'Total loss': 0.3203504708779119}
2023-01-05 14:17:21,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:21,252 INFO:     Epoch: 48
2023-01-05 14:17:23,409 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4622262239456177, 'Total loss': 0.4622262239456177} | train loss {'Reaction outcome loss': 0.31599890501884215, 'Total loss': 0.31599890501884215}
2023-01-05 14:17:23,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:23,409 INFO:     Epoch: 49
2023-01-05 14:17:25,589 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4234350194533666, 'Total loss': 0.4234350194533666} | train loss {'Reaction outcome loss': 0.3222265967922489, 'Total loss': 0.3222265967922489}
2023-01-05 14:17:25,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:25,590 INFO:     Epoch: 50
2023-01-05 14:17:27,748 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3994780351718267, 'Total loss': 0.3994780351718267} | train loss {'Reaction outcome loss': 0.3111656722850608, 'Total loss': 0.3111656722850608}
2023-01-05 14:17:27,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:27,748 INFO:     Epoch: 51
2023-01-05 14:17:29,900 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4260225256284078, 'Total loss': 0.4260225256284078} | train loss {'Reaction outcome loss': 0.31187959594556885, 'Total loss': 0.31187959594556885}
2023-01-05 14:17:29,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:29,901 INFO:     Epoch: 52
2023-01-05 14:17:32,032 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4047414243221283, 'Total loss': 0.4047414243221283} | train loss {'Reaction outcome loss': 0.3089257775241659, 'Total loss': 0.3089257775241659}
2023-01-05 14:17:32,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:32,032 INFO:     Epoch: 53
2023-01-05 14:17:34,178 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40458770195643107, 'Total loss': 0.40458770195643107} | train loss {'Reaction outcome loss': 0.2931107115544324, 'Total loss': 0.2931107115544324}
2023-01-05 14:17:34,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:34,179 INFO:     Epoch: 54
2023-01-05 14:17:36,320 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40093004604180654, 'Total loss': 0.40093004604180654} | train loss {'Reaction outcome loss': 0.2989343028026123, 'Total loss': 0.2989343028026123}
2023-01-05 14:17:36,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:36,320 INFO:     Epoch: 55
2023-01-05 14:17:38,459 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39605512072642646, 'Total loss': 0.39605512072642646} | train loss {'Reaction outcome loss': 0.3098136206857697, 'Total loss': 0.3098136206857697}
2023-01-05 14:17:38,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:38,459 INFO:     Epoch: 56
2023-01-05 14:17:40,587 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3935216228167216, 'Total loss': 0.3935216228167216} | train loss {'Reaction outcome loss': 0.29951226450230956, 'Total loss': 0.29951226450230956}
2023-01-05 14:17:40,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:40,588 INFO:     Epoch: 57
2023-01-05 14:17:42,710 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4031301409006119, 'Total loss': 0.4031301409006119} | train loss {'Reaction outcome loss': 0.29292504992471996, 'Total loss': 0.29292504992471996}
2023-01-05 14:17:42,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:42,710 INFO:     Epoch: 58
2023-01-05 14:17:44,821 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.416857048869133, 'Total loss': 0.416857048869133} | train loss {'Reaction outcome loss': 0.2958206932475097, 'Total loss': 0.2958206932475097}
2023-01-05 14:17:44,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:44,821 INFO:     Epoch: 59
2023-01-05 14:17:46,801 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38168334563573203, 'Total loss': 0.38168334563573203} | train loss {'Reaction outcome loss': 0.29016683566091706, 'Total loss': 0.29016683566091706}
2023-01-05 14:17:46,801 INFO:     Found new best model at epoch 59
2023-01-05 14:17:46,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:46,803 INFO:     Epoch: 60
2023-01-05 14:17:48,899 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44928378065427144, 'Total loss': 0.44928378065427144} | train loss {'Reaction outcome loss': 0.28958667353828893, 'Total loss': 0.28958667353828893}
2023-01-05 14:17:48,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:48,899 INFO:     Epoch: 61
2023-01-05 14:17:51,028 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3954552105317513, 'Total loss': 0.3954552105317513} | train loss {'Reaction outcome loss': 0.2914976998755749, 'Total loss': 0.2914976998755749}
2023-01-05 14:17:51,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:51,029 INFO:     Epoch: 62
2023-01-05 14:17:53,156 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41198286910851795, 'Total loss': 0.41198286910851795} | train loss {'Reaction outcome loss': 0.2856639891890061, 'Total loss': 0.2856639891890061}
2023-01-05 14:17:53,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:53,157 INFO:     Epoch: 63
2023-01-05 14:17:55,288 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3942748169104258, 'Total loss': 0.3942748169104258} | train loss {'Reaction outcome loss': 0.27888592900912257, 'Total loss': 0.27888592900912257}
2023-01-05 14:17:55,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:55,288 INFO:     Epoch: 64
2023-01-05 14:17:57,444 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41116204982002574, 'Total loss': 0.41116204982002574} | train loss {'Reaction outcome loss': 0.27846106635338636, 'Total loss': 0.27846106635338636}
2023-01-05 14:17:57,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:57,444 INFO:     Epoch: 65
2023-01-05 14:17:59,603 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40552890400091807, 'Total loss': 0.40552890400091807} | train loss {'Reaction outcome loss': 0.2799128106842837, 'Total loss': 0.2799128106842837}
2023-01-05 14:17:59,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:17:59,603 INFO:     Epoch: 66
2023-01-05 14:18:01,759 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42232142090797425, 'Total loss': 0.42232142090797425} | train loss {'Reaction outcome loss': 0.27804924220009875, 'Total loss': 0.27804924220009875}
2023-01-05 14:18:01,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:01,759 INFO:     Epoch: 67
2023-01-05 14:18:03,905 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3943503737449646, 'Total loss': 0.3943503737449646} | train loss {'Reaction outcome loss': 0.279526025328758, 'Total loss': 0.279526025328758}
2023-01-05 14:18:03,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:03,906 INFO:     Epoch: 68
2023-01-05 14:18:06,061 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41310907850662865, 'Total loss': 0.41310907850662865} | train loss {'Reaction outcome loss': 0.281480023086778, 'Total loss': 0.281480023086778}
2023-01-05 14:18:06,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:06,061 INFO:     Epoch: 69
2023-01-05 14:18:08,214 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4061183417836825, 'Total loss': 0.4061183417836825} | train loss {'Reaction outcome loss': 0.2820937456903014, 'Total loss': 0.2820937456903014}
2023-01-05 14:18:08,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:08,214 INFO:     Epoch: 70
2023-01-05 14:18:10,372 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4029452512661616, 'Total loss': 0.4029452512661616} | train loss {'Reaction outcome loss': 0.27209234100351803, 'Total loss': 0.27209234100351803}
2023-01-05 14:18:10,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:10,373 INFO:     Epoch: 71
2023-01-05 14:18:12,521 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3883784398436546, 'Total loss': 0.3883784398436546} | train loss {'Reaction outcome loss': 0.2778256968697057, 'Total loss': 0.2778256968697057}
2023-01-05 14:18:12,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:12,521 INFO:     Epoch: 72
2023-01-05 14:18:14,674 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41719321807225546, 'Total loss': 0.41719321807225546} | train loss {'Reaction outcome loss': 0.267505681400534, 'Total loss': 0.267505681400534}
2023-01-05 14:18:14,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:14,674 INFO:     Epoch: 73
2023-01-05 14:18:16,798 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43622313340504965, 'Total loss': 0.43622313340504965} | train loss {'Reaction outcome loss': 0.2700125740936203, 'Total loss': 0.2700125740936203}
2023-01-05 14:18:16,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:16,798 INFO:     Epoch: 74
2023-01-05 14:18:18,913 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40244309306144715, 'Total loss': 0.40244309306144715} | train loss {'Reaction outcome loss': 0.27819163030706834, 'Total loss': 0.27819163030706834}
2023-01-05 14:18:18,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:18,914 INFO:     Epoch: 75
2023-01-05 14:18:21,052 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.400250114997228, 'Total loss': 0.400250114997228} | train loss {'Reaction outcome loss': 0.26780655977390977, 'Total loss': 0.26780655977390977}
2023-01-05 14:18:21,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:21,052 INFO:     Epoch: 76
2023-01-05 14:18:23,152 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44293193022410077, 'Total loss': 0.44293193022410077} | train loss {'Reaction outcome loss': 0.2568577816709876, 'Total loss': 0.2568577816709876}
2023-01-05 14:18:23,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:23,153 INFO:     Epoch: 77
2023-01-05 14:18:25,265 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43182958116134007, 'Total loss': 0.43182958116134007} | train loss {'Reaction outcome loss': 0.264605486187676, 'Total loss': 0.264605486187676}
2023-01-05 14:18:25,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:25,265 INFO:     Epoch: 78
2023-01-05 14:18:27,394 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.388117782274882, 'Total loss': 0.388117782274882} | train loss {'Reaction outcome loss': 0.26604492436876914, 'Total loss': 0.26604492436876914}
2023-01-05 14:18:27,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:27,394 INFO:     Epoch: 79
2023-01-05 14:18:29,522 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46135508120059965, 'Total loss': 0.46135508120059965} | train loss {'Reaction outcome loss': 0.2592880111595575, 'Total loss': 0.2592880111595575}
2023-01-05 14:18:29,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:29,522 INFO:     Epoch: 80
2023-01-05 14:18:31,684 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40710448821385703, 'Total loss': 0.40710448821385703} | train loss {'Reaction outcome loss': 0.25829572700317543, 'Total loss': 0.25829572700317543}
2023-01-05 14:18:31,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:31,684 INFO:     Epoch: 81
2023-01-05 14:18:33,816 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4290750255187353, 'Total loss': 0.4290750255187353} | train loss {'Reaction outcome loss': 0.25691725373485663, 'Total loss': 0.25691725373485663}
2023-01-05 14:18:33,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:33,816 INFO:     Epoch: 82
2023-01-05 14:18:35,956 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42031545837720236, 'Total loss': 0.42031545837720236} | train loss {'Reaction outcome loss': 0.2548404524959352, 'Total loss': 0.2548404524959352}
2023-01-05 14:18:35,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:35,956 INFO:     Epoch: 83
2023-01-05 14:18:38,073 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.398736197501421, 'Total loss': 0.398736197501421} | train loss {'Reaction outcome loss': 0.24855742994084085, 'Total loss': 0.24855742994084085}
2023-01-05 14:18:38,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:38,073 INFO:     Epoch: 84
2023-01-05 14:18:40,195 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45174062649408975, 'Total loss': 0.45174062649408975} | train loss {'Reaction outcome loss': 0.25522096643401104, 'Total loss': 0.25522096643401104}
2023-01-05 14:18:40,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:40,196 INFO:     Epoch: 85
2023-01-05 14:18:42,321 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4053070391217867, 'Total loss': 0.4053070391217867} | train loss {'Reaction outcome loss': 0.2601930235247434, 'Total loss': 0.2601930235247434}
2023-01-05 14:18:42,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:42,321 INFO:     Epoch: 86
2023-01-05 14:18:44,460 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4533121605714162, 'Total loss': 0.4533121605714162} | train loss {'Reaction outcome loss': 0.26163129698838633, 'Total loss': 0.26163129698838633}
2023-01-05 14:18:44,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:44,460 INFO:     Epoch: 87
2023-01-05 14:18:46,609 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40088179806868235, 'Total loss': 0.40088179806868235} | train loss {'Reaction outcome loss': 0.2579921059392012, 'Total loss': 0.2579921059392012}
2023-01-05 14:18:46,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:46,610 INFO:     Epoch: 88
2023-01-05 14:18:48,740 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3882195472717285, 'Total loss': 0.3882195472717285} | train loss {'Reaction outcome loss': 0.25697730119972334, 'Total loss': 0.25697730119972334}
2023-01-05 14:18:48,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:48,740 INFO:     Epoch: 89
2023-01-05 14:18:50,864 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45033563872178395, 'Total loss': 0.45033563872178395} | train loss {'Reaction outcome loss': 0.254821641404644, 'Total loss': 0.254821641404644}
2023-01-05 14:18:50,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:50,865 INFO:     Epoch: 90
2023-01-05 14:18:53,000 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4152523994445801, 'Total loss': 0.4152523994445801} | train loss {'Reaction outcome loss': 0.25032484517806636, 'Total loss': 0.25032484517806636}
2023-01-05 14:18:53,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:53,000 INFO:     Epoch: 91
2023-01-05 14:18:55,108 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.36137983249500394, 'Total loss': 0.36137983249500394} | train loss {'Reaction outcome loss': 0.24953111679034892, 'Total loss': 0.24953111679034892}
2023-01-05 14:18:55,108 INFO:     Found new best model at epoch 91
2023-01-05 14:18:55,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:55,109 INFO:     Epoch: 92
2023-01-05 14:18:57,225 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3726726015408834, 'Total loss': 0.3726726015408834} | train loss {'Reaction outcome loss': 0.2500923818425976, 'Total loss': 0.2500923818425976}
2023-01-05 14:18:57,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:57,226 INFO:     Epoch: 93
2023-01-05 14:18:59,370 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44962879618008933, 'Total loss': 0.44962879618008933} | train loss {'Reaction outcome loss': 0.24931586827457386, 'Total loss': 0.24931586827457386}
2023-01-05 14:18:59,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:18:59,371 INFO:     Epoch: 94
2023-01-05 14:19:01,491 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39480322500069936, 'Total loss': 0.39480322500069936} | train loss {'Reaction outcome loss': 0.25003033380166895, 'Total loss': 0.25003033380166895}
2023-01-05 14:19:01,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:01,491 INFO:     Epoch: 95
2023-01-05 14:19:03,614 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4324013868967692, 'Total loss': 0.4324013868967692} | train loss {'Reaction outcome loss': 0.2470962759753159, 'Total loss': 0.2470962759753159}
2023-01-05 14:19:03,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:03,614 INFO:     Epoch: 96
2023-01-05 14:19:05,735 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4166039675474167, 'Total loss': 0.4166039675474167} | train loss {'Reaction outcome loss': 0.24931017722744142, 'Total loss': 0.24931017722744142}
2023-01-05 14:19:05,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:05,735 INFO:     Epoch: 97
2023-01-05 14:19:07,859 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40828529172576966, 'Total loss': 0.40828529172576966} | train loss {'Reaction outcome loss': 0.2442508340425735, 'Total loss': 0.2442508340425735}
2023-01-05 14:19:07,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:07,859 INFO:     Epoch: 98
2023-01-05 14:19:09,982 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4129594643910726, 'Total loss': 0.4129594643910726} | train loss {'Reaction outcome loss': 0.2458208433835067, 'Total loss': 0.2458208433835067}
2023-01-05 14:19:09,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:09,982 INFO:     Epoch: 99
2023-01-05 14:19:12,117 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45084211428960164, 'Total loss': 0.45084211428960164} | train loss {'Reaction outcome loss': 0.24208310009218262, 'Total loss': 0.24208310009218262}
2023-01-05 14:19:12,118 INFO:     Best model found after epoch 92 of 100.
2023-01-05 14:19:12,118 INFO:   Done with stage: TRAINING
2023-01-05 14:19:12,118 INFO:   Starting stage: EVALUATION
2023-01-05 14:19:12,257 INFO:   Done with stage: EVALUATION
2023-01-05 14:19:12,257 INFO:   Leaving out SEQ value Fold_1
2023-01-05 14:19:12,270 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 14:19:12,270 INFO:   Starting stage: FEATURE SCALING
2023-01-05 14:19:12,903 INFO:   Done with stage: FEATURE SCALING
2023-01-05 14:19:12,903 INFO:   Starting stage: SCALING TARGETS
2023-01-05 14:19:12,971 INFO:   Done with stage: SCALING TARGETS
2023-01-05 14:19:12,971 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:19:12,971 INFO:     No hyperparam tuning for this model
2023-01-05 14:19:12,971 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:19:12,971 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 14:19:12,972 INFO:     None feature selector for col prot
2023-01-05 14:19:12,972 INFO:     None feature selector for col prot
2023-01-05 14:19:12,972 INFO:     None feature selector for col prot
2023-01-05 14:19:12,973 INFO:     None feature selector for col chem
2023-01-05 14:19:12,973 INFO:     None feature selector for col chem
2023-01-05 14:19:12,973 INFO:     None feature selector for col chem
2023-01-05 14:19:12,973 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 14:19:12,973 INFO:   Starting stage: BUILD MODEL
2023-01-05 14:19:12,974 INFO:     Number of params in model 72901
2023-01-05 14:19:12,977 INFO:   Done with stage: BUILD MODEL
2023-01-05 14:19:12,977 INFO:   Starting stage: TRAINING
2023-01-05 14:19:13,036 INFO:     Val loss before train {'Reaction outcome loss': 0.9123382767041525, 'Total loss': 0.9123382767041525}
2023-01-05 14:19:13,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:13,037 INFO:     Epoch: 0
2023-01-05 14:19:15,163 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7461667418479919, 'Total loss': 0.7461667418479919} | train loss {'Reaction outcome loss': 0.9078072581317399, 'Total loss': 0.9078072581317399}
2023-01-05 14:19:15,164 INFO:     Found new best model at epoch 0
2023-01-05 14:19:15,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:15,166 INFO:     Epoch: 1
2023-01-05 14:19:17,279 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5263609697421392, 'Total loss': 0.5263609697421392} | train loss {'Reaction outcome loss': 0.7459527680943737, 'Total loss': 0.7459527680943737}
2023-01-05 14:19:17,279 INFO:     Found new best model at epoch 1
2023-01-05 14:19:17,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:17,280 INFO:     Epoch: 2
2023-01-05 14:19:19,387 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45639586448669434, 'Total loss': 0.45639586448669434} | train loss {'Reaction outcome loss': 0.5959194153001457, 'Total loss': 0.5959194153001457}
2023-01-05 14:19:19,388 INFO:     Found new best model at epoch 2
2023-01-05 14:19:19,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:19,389 INFO:     Epoch: 3
2023-01-05 14:19:21,494 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4540047427018484, 'Total loss': 0.4540047427018484} | train loss {'Reaction outcome loss': 0.5380561565195684, 'Total loss': 0.5380561565195684}
2023-01-05 14:19:21,495 INFO:     Found new best model at epoch 3
2023-01-05 14:19:21,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:21,497 INFO:     Epoch: 4
2023-01-05 14:19:23,601 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44515924354394276, 'Total loss': 0.44515924354394276} | train loss {'Reaction outcome loss': 0.5213677168656619, 'Total loss': 0.5213677168656619}
2023-01-05 14:19:23,601 INFO:     Found new best model at epoch 4
2023-01-05 14:19:23,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:23,603 INFO:     Epoch: 5
2023-01-05 14:19:25,701 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4311613569657008, 'Total loss': 0.4311613569657008} | train loss {'Reaction outcome loss': 0.5108098147552965, 'Total loss': 0.5108098147552965}
2023-01-05 14:19:25,701 INFO:     Found new best model at epoch 5
2023-01-05 14:19:25,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:25,703 INFO:     Epoch: 6
2023-01-05 14:19:27,816 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.464741258819898, 'Total loss': 0.464741258819898} | train loss {'Reaction outcome loss': 0.49928341254646524, 'Total loss': 0.49928341254646524}
2023-01-05 14:19:27,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:27,816 INFO:     Epoch: 7
2023-01-05 14:19:29,936 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4436540812253952, 'Total loss': 0.4436540812253952} | train loss {'Reaction outcome loss': 0.48915837961675485, 'Total loss': 0.48915837961675485}
2023-01-05 14:19:29,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:29,936 INFO:     Epoch: 8
2023-01-05 14:19:32,054 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4454714765151342, 'Total loss': 0.4454714765151342} | train loss {'Reaction outcome loss': 0.48714342560523594, 'Total loss': 0.48714342560523594}
2023-01-05 14:19:32,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:32,055 INFO:     Epoch: 9
2023-01-05 14:19:34,151 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4291969100634257, 'Total loss': 0.4291969100634257} | train loss {'Reaction outcome loss': 0.4842361425742125, 'Total loss': 0.4842361425742125}
2023-01-05 14:19:34,152 INFO:     Found new best model at epoch 9
2023-01-05 14:19:34,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:34,153 INFO:     Epoch: 10
2023-01-05 14:19:36,261 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4095588445663452, 'Total loss': 0.4095588445663452} | train loss {'Reaction outcome loss': 0.47344046981234256, 'Total loss': 0.47344046981234256}
2023-01-05 14:19:36,261 INFO:     Found new best model at epoch 10
2023-01-05 14:19:36,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:36,262 INFO:     Epoch: 11
2023-01-05 14:19:38,378 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42824730078379314, 'Total loss': 0.42824730078379314} | train loss {'Reaction outcome loss': 0.4715893221097988, 'Total loss': 0.4715893221097988}
2023-01-05 14:19:38,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:38,379 INFO:     Epoch: 12
2023-01-05 14:19:40,478 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4018311083316803, 'Total loss': 0.4018311083316803} | train loss {'Reaction outcome loss': 0.4643719394455899, 'Total loss': 0.4643719394455899}
2023-01-05 14:19:40,479 INFO:     Found new best model at epoch 12
2023-01-05 14:19:40,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:40,480 INFO:     Epoch: 13
2023-01-05 14:19:42,604 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41642336547374725, 'Total loss': 0.41642336547374725} | train loss {'Reaction outcome loss': 0.45947312566728055, 'Total loss': 0.45947312566728055}
2023-01-05 14:19:42,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:42,604 INFO:     Epoch: 14
2023-01-05 14:19:44,720 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41265232960383097, 'Total loss': 0.41265232960383097} | train loss {'Reaction outcome loss': 0.45789532701829416, 'Total loss': 0.45789532701829416}
2023-01-05 14:19:44,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:44,720 INFO:     Epoch: 15
2023-01-05 14:19:46,846 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40426977624495825, 'Total loss': 0.40426977624495825} | train loss {'Reaction outcome loss': 0.45065882389907874, 'Total loss': 0.45065882389907874}
2023-01-05 14:19:46,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:46,848 INFO:     Epoch: 16
2023-01-05 14:19:48,965 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4007268826166789, 'Total loss': 0.4007268826166789} | train loss {'Reaction outcome loss': 0.4522056235171063, 'Total loss': 0.4522056235171063}
2023-01-05 14:19:48,965 INFO:     Found new best model at epoch 16
2023-01-05 14:19:48,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:48,967 INFO:     Epoch: 17
2023-01-05 14:19:51,166 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4081224093834559, 'Total loss': 0.4081224093834559} | train loss {'Reaction outcome loss': 0.44241965275544387, 'Total loss': 0.44241965275544387}
2023-01-05 14:19:51,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:51,166 INFO:     Epoch: 18
2023-01-05 14:19:53,285 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40082207719484964, 'Total loss': 0.40082207719484964} | train loss {'Reaction outcome loss': 0.43893138916937857, 'Total loss': 0.43893138916937857}
2023-01-05 14:19:53,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:53,286 INFO:     Epoch: 19
2023-01-05 14:19:55,415 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4096459746360779, 'Total loss': 0.4096459746360779} | train loss {'Reaction outcome loss': 0.4370270826932275, 'Total loss': 0.4370270826932275}
2023-01-05 14:19:55,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:55,415 INFO:     Epoch: 20
2023-01-05 14:19:57,533 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4028245667616526, 'Total loss': 0.4028245667616526} | train loss {'Reaction outcome loss': 0.4377252865077812, 'Total loss': 0.4377252865077812}
2023-01-05 14:19:57,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:57,533 INFO:     Epoch: 21
2023-01-05 14:19:59,641 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42624959349632263, 'Total loss': 0.42624959349632263} | train loss {'Reaction outcome loss': 0.4308094588609842, 'Total loss': 0.4308094588609842}
2023-01-05 14:19:59,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:19:59,641 INFO:     Epoch: 22
2023-01-05 14:20:01,774 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40914685527483624, 'Total loss': 0.40914685527483624} | train loss {'Reaction outcome loss': 0.4274939075385258, 'Total loss': 0.4274939075385258}
2023-01-05 14:20:01,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:01,774 INFO:     Epoch: 23
2023-01-05 14:20:03,892 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42482199470202126, 'Total loss': 0.42482199470202126} | train loss {'Reaction outcome loss': 0.4217792875491656, 'Total loss': 0.4217792875491656}
2023-01-05 14:20:03,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:03,893 INFO:     Epoch: 24
2023-01-05 14:20:06,029 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.405748121937116, 'Total loss': 0.405748121937116} | train loss {'Reaction outcome loss': 0.4177087710235582, 'Total loss': 0.4177087710235582}
2023-01-05 14:20:06,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:06,030 INFO:     Epoch: 25
2023-01-05 14:20:08,151 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42988071342309314, 'Total loss': 0.42988071342309314} | train loss {'Reaction outcome loss': 0.41449911706831866, 'Total loss': 0.41449911706831866}
2023-01-05 14:20:08,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:08,151 INFO:     Epoch: 26
2023-01-05 14:20:10,269 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41065870424111683, 'Total loss': 0.41065870424111683} | train loss {'Reaction outcome loss': 0.41709828071105176, 'Total loss': 0.41709828071105176}
2023-01-05 14:20:10,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:10,270 INFO:     Epoch: 27
2023-01-05 14:20:12,383 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3830775486926238, 'Total loss': 0.3830775486926238} | train loss {'Reaction outcome loss': 0.4156853627317991, 'Total loss': 0.4156853627317991}
2023-01-05 14:20:12,383 INFO:     Found new best model at epoch 27
2023-01-05 14:20:12,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:12,384 INFO:     Epoch: 28
2023-01-05 14:20:14,514 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4017084012428919, 'Total loss': 0.4017084012428919} | train loss {'Reaction outcome loss': 0.4110586565711123, 'Total loss': 0.4110586565711123}
2023-01-05 14:20:14,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:14,515 INFO:     Epoch: 29
2023-01-05 14:20:16,644 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38505771358807883, 'Total loss': 0.38505771358807883} | train loss {'Reaction outcome loss': 0.4043286648261678, 'Total loss': 0.4043286648261678}
2023-01-05 14:20:16,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:16,644 INFO:     Epoch: 30
2023-01-05 14:20:18,768 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.37416386703650156, 'Total loss': 0.37416386703650156} | train loss {'Reaction outcome loss': 0.4003623834514356, 'Total loss': 0.4003623834514356}
2023-01-05 14:20:18,769 INFO:     Found new best model at epoch 30
2023-01-05 14:20:18,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:18,770 INFO:     Epoch: 31
2023-01-05 14:20:20,898 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39632760485013324, 'Total loss': 0.39632760485013324} | train loss {'Reaction outcome loss': 0.39494792587591177, 'Total loss': 0.39494792587591177}
2023-01-05 14:20:20,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:20,898 INFO:     Epoch: 32
2023-01-05 14:20:23,002 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.411946165561676, 'Total loss': 0.411946165561676} | train loss {'Reaction outcome loss': 0.3989225320326976, 'Total loss': 0.3989225320326976}
2023-01-05 14:20:23,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:23,004 INFO:     Epoch: 33
2023-01-05 14:20:25,140 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3759280222157637, 'Total loss': 0.3759280222157637} | train loss {'Reaction outcome loss': 0.3947459877956481, 'Total loss': 0.3947459877956481}
2023-01-05 14:20:25,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:25,140 INFO:     Epoch: 34
2023-01-05 14:20:27,243 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37940920193990074, 'Total loss': 0.37940920193990074} | train loss {'Reaction outcome loss': 0.3941420127020214, 'Total loss': 0.3941420127020214}
2023-01-05 14:20:27,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:27,243 INFO:     Epoch: 35
2023-01-05 14:20:29,373 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42749422589937847, 'Total loss': 0.42749422589937847} | train loss {'Reaction outcome loss': 0.38951478808463275, 'Total loss': 0.38951478808463275}
2023-01-05 14:20:29,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:29,374 INFO:     Epoch: 36
2023-01-05 14:20:31,493 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37753961185614265, 'Total loss': 0.37753961185614265} | train loss {'Reaction outcome loss': 0.38088447053664304, 'Total loss': 0.38088447053664304}
2023-01-05 14:20:31,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:31,493 INFO:     Epoch: 37
2023-01-05 14:20:33,605 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3811059241493543, 'Total loss': 0.3811059241493543} | train loss {'Reaction outcome loss': 0.37866668012880145, 'Total loss': 0.37866668012880145}
2023-01-05 14:20:33,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:33,605 INFO:     Epoch: 38
2023-01-05 14:20:35,736 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3771640052398046, 'Total loss': 0.3771640052398046} | train loss {'Reaction outcome loss': 0.37492127348105986, 'Total loss': 0.37492127348105986}
2023-01-05 14:20:35,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:35,736 INFO:     Epoch: 39
2023-01-05 14:20:37,852 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4352374086777369, 'Total loss': 0.4352374086777369} | train loss {'Reaction outcome loss': 0.37341171410275903, 'Total loss': 0.37341171410275903}
2023-01-05 14:20:37,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:37,852 INFO:     Epoch: 40
2023-01-05 14:20:40,002 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3817643235127131, 'Total loss': 0.3817643235127131} | train loss {'Reaction outcome loss': 0.3738513930594965, 'Total loss': 0.3738513930594965}
2023-01-05 14:20:40,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:40,002 INFO:     Epoch: 41
2023-01-05 14:20:42,130 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38988362103700636, 'Total loss': 0.38988362103700636} | train loss {'Reaction outcome loss': 0.36855248213087244, 'Total loss': 0.36855248213087244}
2023-01-05 14:20:42,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:42,131 INFO:     Epoch: 42
2023-01-05 14:20:44,269 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38029800256093343, 'Total loss': 0.38029800256093343} | train loss {'Reaction outcome loss': 0.3648317560089595, 'Total loss': 0.3648317560089595}
2023-01-05 14:20:44,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:44,269 INFO:     Epoch: 43
2023-01-05 14:20:46,380 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39511094937721886, 'Total loss': 0.39511094937721886} | train loss {'Reaction outcome loss': 0.3646232538989612, 'Total loss': 0.3646232538989612}
2023-01-05 14:20:46,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:46,380 INFO:     Epoch: 44
2023-01-05 14:20:48,486 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3622468570868174, 'Total loss': 0.3622468570868174} | train loss {'Reaction outcome loss': 0.36073494574307524, 'Total loss': 0.36073494574307524}
2023-01-05 14:20:48,487 INFO:     Found new best model at epoch 44
2023-01-05 14:20:48,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:48,488 INFO:     Epoch: 45
2023-01-05 14:20:50,600 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3793744258582592, 'Total loss': 0.3793744258582592} | train loss {'Reaction outcome loss': 0.35267284763601675, 'Total loss': 0.35267284763601675}
2023-01-05 14:20:50,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:50,600 INFO:     Epoch: 46
2023-01-05 14:20:52,730 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3937568108240763, 'Total loss': 0.3937568108240763} | train loss {'Reaction outcome loss': 0.3535752634998861, 'Total loss': 0.3535752634998861}
2023-01-05 14:20:52,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:52,731 INFO:     Epoch: 47
2023-01-05 14:20:54,861 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3635472819053878, 'Total loss': 0.3635472819053878} | train loss {'Reaction outcome loss': 0.3465452348206179, 'Total loss': 0.3465452348206179}
2023-01-05 14:20:54,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:54,861 INFO:     Epoch: 48
2023-01-05 14:20:56,979 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3650940174857775, 'Total loss': 0.3650940174857775} | train loss {'Reaction outcome loss': 0.3509448473597621, 'Total loss': 0.3509448473597621}
2023-01-05 14:20:56,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:56,979 INFO:     Epoch: 49
2023-01-05 14:20:59,116 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38678712050120034, 'Total loss': 0.38678712050120034} | train loss {'Reaction outcome loss': 0.3456194688712721, 'Total loss': 0.3456194688712721}
2023-01-05 14:20:59,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:20:59,117 INFO:     Epoch: 50
2023-01-05 14:21:01,258 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.36086660822232564, 'Total loss': 0.36086660822232564} | train loss {'Reaction outcome loss': 0.34001192988166007, 'Total loss': 0.34001192988166007}
2023-01-05 14:21:01,259 INFO:     Found new best model at epoch 50
2023-01-05 14:21:01,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:01,260 INFO:     Epoch: 51
2023-01-05 14:21:03,395 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42050488193829855, 'Total loss': 0.42050488193829855} | train loss {'Reaction outcome loss': 0.34265879582572767, 'Total loss': 0.34265879582572767}
2023-01-05 14:21:03,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:03,395 INFO:     Epoch: 52
2023-01-05 14:21:05,529 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3829834679762522, 'Total loss': 0.3829834679762522} | train loss {'Reaction outcome loss': 0.34089754898469526, 'Total loss': 0.34089754898469526}
2023-01-05 14:21:05,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:05,529 INFO:     Epoch: 53
2023-01-05 14:21:07,659 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39847067594528196, 'Total loss': 0.39847067594528196} | train loss {'Reaction outcome loss': 0.3311025332864169, 'Total loss': 0.3311025332864169}
2023-01-05 14:21:07,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:07,659 INFO:     Epoch: 54
2023-01-05 14:21:09,775 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3618570347627004, 'Total loss': 0.3618570347627004} | train loss {'Reaction outcome loss': 0.33773892670323996, 'Total loss': 0.33773892670323996}
2023-01-05 14:21:09,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:09,775 INFO:     Epoch: 55
2023-01-05 14:21:11,894 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38523199955622356, 'Total loss': 0.38523199955622356} | train loss {'Reaction outcome loss': 0.3326308171063552, 'Total loss': 0.3326308171063552}
2023-01-05 14:21:11,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:11,895 INFO:     Epoch: 56
2023-01-05 14:21:14,015 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37019485036532085, 'Total loss': 0.37019485036532085} | train loss {'Reaction outcome loss': 0.32865925457997197, 'Total loss': 0.32865925457997197}
2023-01-05 14:21:14,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:14,015 INFO:     Epoch: 57
2023-01-05 14:21:16,141 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3825795834263166, 'Total loss': 0.3825795834263166} | train loss {'Reaction outcome loss': 0.32470129550376653, 'Total loss': 0.32470129550376653}
2023-01-05 14:21:16,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:16,141 INFO:     Epoch: 58
2023-01-05 14:21:18,286 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.35884457528591157, 'Total loss': 0.35884457528591157} | train loss {'Reaction outcome loss': 0.32591128241843903, 'Total loss': 0.32591128241843903}
2023-01-05 14:21:18,286 INFO:     Found new best model at epoch 58
2023-01-05 14:21:18,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:18,288 INFO:     Epoch: 59
2023-01-05 14:21:20,412 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.371527960896492, 'Total loss': 0.371527960896492} | train loss {'Reaction outcome loss': 0.3201527691176741, 'Total loss': 0.3201527691176741}
2023-01-05 14:21:20,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:20,412 INFO:     Epoch: 60
2023-01-05 14:21:22,546 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3729102512200673, 'Total loss': 0.3729102512200673} | train loss {'Reaction outcome loss': 0.3235539100763999, 'Total loss': 0.3235539100763999}
2023-01-05 14:21:22,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:22,546 INFO:     Epoch: 61
2023-01-05 14:21:24,685 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3869798223177592, 'Total loss': 0.3869798223177592} | train loss {'Reaction outcome loss': 0.31003485437168743, 'Total loss': 0.31003485437168743}
2023-01-05 14:21:24,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:24,685 INFO:     Epoch: 62
2023-01-05 14:21:26,809 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.373414305349191, 'Total loss': 0.373414305349191} | train loss {'Reaction outcome loss': 0.31198255642702727, 'Total loss': 0.31198255642702727}
2023-01-05 14:21:26,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:26,809 INFO:     Epoch: 63
2023-01-05 14:21:28,934 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3880124698082606, 'Total loss': 0.3880124698082606} | train loss {'Reaction outcome loss': 0.31536925529494825, 'Total loss': 0.31536925529494825}
2023-01-05 14:21:28,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:28,936 INFO:     Epoch: 64
2023-01-05 14:21:31,059 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3841161330540975, 'Total loss': 0.3841161330540975} | train loss {'Reaction outcome loss': 0.30666707084691597, 'Total loss': 0.30666707084691597}
2023-01-05 14:21:31,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:31,059 INFO:     Epoch: 65
2023-01-05 14:21:33,187 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3492648219068845, 'Total loss': 0.3492648219068845} | train loss {'Reaction outcome loss': 0.31159555508103565, 'Total loss': 0.31159555508103565}
2023-01-05 14:21:33,187 INFO:     Found new best model at epoch 65
2023-01-05 14:21:33,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:33,188 INFO:     Epoch: 66
2023-01-05 14:21:35,287 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37764750719070433, 'Total loss': 0.37764750719070433} | train loss {'Reaction outcome loss': 0.30677219654941734, 'Total loss': 0.30677219654941734}
2023-01-05 14:21:35,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:35,288 INFO:     Epoch: 67
2023-01-05 14:21:37,402 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.35213733116785684, 'Total loss': 0.35213733116785684} | train loss {'Reaction outcome loss': 0.3098171068416847, 'Total loss': 0.3098171068416847}
2023-01-05 14:21:37,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:37,402 INFO:     Epoch: 68
2023-01-05 14:21:39,497 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4525746727983157, 'Total loss': 0.4525746727983157} | train loss {'Reaction outcome loss': 0.29887119912620863, 'Total loss': 0.29887119912620863}
2023-01-05 14:21:39,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:39,498 INFO:     Epoch: 69
2023-01-05 14:21:41,640 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3674445350964864, 'Total loss': 0.3674445350964864} | train loss {'Reaction outcome loss': 0.2995069235334712, 'Total loss': 0.2995069235334712}
2023-01-05 14:21:41,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:41,640 INFO:     Epoch: 70
2023-01-05 14:21:43,755 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38733930736780164, 'Total loss': 0.38733930736780164} | train loss {'Reaction outcome loss': 0.3055127142440705, 'Total loss': 0.3055127142440705}
2023-01-05 14:21:43,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:43,755 INFO:     Epoch: 71
2023-01-05 14:21:45,886 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38661619226137794, 'Total loss': 0.38661619226137794} | train loss {'Reaction outcome loss': 0.3017075397483595, 'Total loss': 0.3017075397483595}
2023-01-05 14:21:45,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:45,886 INFO:     Epoch: 72
2023-01-05 14:21:48,016 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.35878960490226747, 'Total loss': 0.35878960490226747} | train loss {'Reaction outcome loss': 0.29634981284484324, 'Total loss': 0.29634981284484324}
2023-01-05 14:21:48,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:48,017 INFO:     Epoch: 73
2023-01-05 14:21:50,146 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.34842963243524233, 'Total loss': 0.34842963243524233} | train loss {'Reaction outcome loss': 0.29902332605650794, 'Total loss': 0.29902332605650794}
2023-01-05 14:21:50,146 INFO:     Found new best model at epoch 73
2023-01-05 14:21:50,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:50,148 INFO:     Epoch: 74
2023-01-05 14:21:52,298 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37228998442490896, 'Total loss': 0.37228998442490896} | train loss {'Reaction outcome loss': 0.2968024758710748, 'Total loss': 0.2968024758710748}
2023-01-05 14:21:52,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:52,298 INFO:     Epoch: 75
2023-01-05 14:21:54,233 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40769848028818767, 'Total loss': 0.40769848028818767} | train loss {'Reaction outcome loss': 0.2878819889501556, 'Total loss': 0.2878819889501556}
2023-01-05 14:21:54,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:54,233 INFO:     Epoch: 76
2023-01-05 14:21:56,374 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3510686258474986, 'Total loss': 0.3510686258474986} | train loss {'Reaction outcome loss': 0.2974794153055865, 'Total loss': 0.2974794153055865}
2023-01-05 14:21:56,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:56,374 INFO:     Epoch: 77
2023-01-05 14:21:58,496 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37356514036655425, 'Total loss': 0.37356514036655425} | train loss {'Reaction outcome loss': 0.2839583225766599, 'Total loss': 0.2839583225766599}
2023-01-05 14:21:58,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:21:58,496 INFO:     Epoch: 78
2023-01-05 14:22:00,605 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.35749675234158834, 'Total loss': 0.35749675234158834} | train loss {'Reaction outcome loss': 0.2842142330721403, 'Total loss': 0.2842142330721403}
2023-01-05 14:22:00,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:00,605 INFO:     Epoch: 79
2023-01-05 14:22:02,720 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3750397692124049, 'Total loss': 0.3750397692124049} | train loss {'Reaction outcome loss': 0.27955583967404923, 'Total loss': 0.27955583967404923}
2023-01-05 14:22:02,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:02,720 INFO:     Epoch: 80
2023-01-05 14:22:04,864 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3780377040306727, 'Total loss': 0.3780377040306727} | train loss {'Reaction outcome loss': 0.2885835374766899, 'Total loss': 0.2885835374766899}
2023-01-05 14:22:04,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:04,866 INFO:     Epoch: 81
2023-01-05 14:22:06,993 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3233001589775085, 'Total loss': 0.3233001589775085} | train loss {'Reaction outcome loss': 0.28298144384318, 'Total loss': 0.28298144384318}
2023-01-05 14:22:06,993 INFO:     Found new best model at epoch 81
2023-01-05 14:22:06,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:06,994 INFO:     Epoch: 82
2023-01-05 14:22:09,128 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.32843276659647624, 'Total loss': 0.32843276659647624} | train loss {'Reaction outcome loss': 0.2786008167070347, 'Total loss': 0.2786008167070347}
2023-01-05 14:22:09,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:09,128 INFO:     Epoch: 83
2023-01-05 14:22:11,232 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3486716131369273, 'Total loss': 0.3486716131369273} | train loss {'Reaction outcome loss': 0.2879387856812486, 'Total loss': 0.2879387856812486}
2023-01-05 14:22:11,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:11,233 INFO:     Epoch: 84
2023-01-05 14:22:13,372 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.31074992020924885, 'Total loss': 0.31074992020924885} | train loss {'Reaction outcome loss': 0.27576260387406243, 'Total loss': 0.27576260387406243}
2023-01-05 14:22:13,372 INFO:     Found new best model at epoch 84
2023-01-05 14:22:13,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:13,373 INFO:     Epoch: 85
2023-01-05 14:22:15,497 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.35229735175768534, 'Total loss': 0.35229735175768534} | train loss {'Reaction outcome loss': 0.2800030323502782, 'Total loss': 0.2800030323502782}
2023-01-05 14:22:15,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:15,498 INFO:     Epoch: 86
2023-01-05 14:22:17,593 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.35800540645917256, 'Total loss': 0.35800540645917256} | train loss {'Reaction outcome loss': 0.27446404747637637, 'Total loss': 0.27446404747637637}
2023-01-05 14:22:17,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:17,594 INFO:     Epoch: 87
2023-01-05 14:22:19,726 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.33168407281239826, 'Total loss': 0.33168407281239826} | train loss {'Reaction outcome loss': 0.2713495317928411, 'Total loss': 0.2713495317928411}
2023-01-05 14:22:19,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:19,726 INFO:     Epoch: 88
2023-01-05 14:22:21,827 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3279509882132212, 'Total loss': 0.3279509882132212} | train loss {'Reaction outcome loss': 0.2791913516764894, 'Total loss': 0.2791913516764894}
2023-01-05 14:22:21,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:21,828 INFO:     Epoch: 89
2023-01-05 14:22:23,955 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37873393495877583, 'Total loss': 0.37873393495877583} | train loss {'Reaction outcome loss': 0.27100042963567644, 'Total loss': 0.27100042963567644}
2023-01-05 14:22:23,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:23,956 INFO:     Epoch: 90
2023-01-05 14:22:26,058 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3968921264012655, 'Total loss': 0.3968921264012655} | train loss {'Reaction outcome loss': 0.2722363979265694, 'Total loss': 0.2722363979265694}
2023-01-05 14:22:26,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:26,058 INFO:     Epoch: 91
2023-01-05 14:22:28,188 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3341675808032354, 'Total loss': 0.3341675808032354} | train loss {'Reaction outcome loss': 0.2727606984558123, 'Total loss': 0.2727606984558123}
2023-01-05 14:22:28,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:28,188 INFO:     Epoch: 92
2023-01-05 14:22:30,318 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.34842395583788555, 'Total loss': 0.34842395583788555} | train loss {'Reaction outcome loss': 0.26402392004353875, 'Total loss': 0.26402392004353875}
2023-01-05 14:22:30,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:30,318 INFO:     Epoch: 93
2023-01-05 14:22:32,431 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.33251827880740165, 'Total loss': 0.33251827880740165} | train loss {'Reaction outcome loss': 0.2652853277747284, 'Total loss': 0.2652853277747284}
2023-01-05 14:22:32,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:32,431 INFO:     Epoch: 94
2023-01-05 14:22:34,549 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.33002146358291307, 'Total loss': 0.33002146358291307} | train loss {'Reaction outcome loss': 0.27479188253373016, 'Total loss': 0.27479188253373016}
2023-01-05 14:22:34,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:34,550 INFO:     Epoch: 95
2023-01-05 14:22:36,671 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3693014234304428, 'Total loss': 0.3693014234304428} | train loss {'Reaction outcome loss': 0.26772353422892836, 'Total loss': 0.26772353422892836}
2023-01-05 14:22:36,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:36,671 INFO:     Epoch: 96
2023-01-05 14:22:38,793 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.35469517689198254, 'Total loss': 0.35469517689198254} | train loss {'Reaction outcome loss': 0.27229352857603695, 'Total loss': 0.27229352857603695}
2023-01-05 14:22:38,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:38,794 INFO:     Epoch: 97
2023-01-05 14:22:40,917 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.33942228158315024, 'Total loss': 0.33942228158315024} | train loss {'Reaction outcome loss': 0.26543812747130463, 'Total loss': 0.26543812747130463}
2023-01-05 14:22:40,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:40,918 INFO:     Epoch: 98
2023-01-05 14:22:43,036 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.34751620292663576, 'Total loss': 0.34751620292663576} | train loss {'Reaction outcome loss': 0.2662163694208358, 'Total loss': 0.2662163694208358}
2023-01-05 14:22:43,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:43,037 INFO:     Epoch: 99
2023-01-05 14:22:45,148 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3739127690593402, 'Total loss': 0.3739127690593402} | train loss {'Reaction outcome loss': 0.25902214414361635, 'Total loss': 0.25902214414361635}
2023-01-05 14:22:45,148 INFO:     Best model found after epoch 85 of 100.
2023-01-05 14:22:45,149 INFO:   Done with stage: TRAINING
2023-01-05 14:22:45,149 INFO:   Starting stage: EVALUATION
2023-01-05 14:22:45,296 INFO:   Done with stage: EVALUATION
2023-01-05 14:22:45,296 INFO:   Leaving out SEQ value Fold_2
2023-01-05 14:22:45,308 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-05 14:22:45,308 INFO:   Starting stage: FEATURE SCALING
2023-01-05 14:22:45,949 INFO:   Done with stage: FEATURE SCALING
2023-01-05 14:22:45,949 INFO:   Starting stage: SCALING TARGETS
2023-01-05 14:22:46,016 INFO:   Done with stage: SCALING TARGETS
2023-01-05 14:22:46,016 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:22:46,016 INFO:     No hyperparam tuning for this model
2023-01-05 14:22:46,016 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:22:46,016 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 14:22:46,017 INFO:     None feature selector for col prot
2023-01-05 14:22:46,017 INFO:     None feature selector for col prot
2023-01-05 14:22:46,017 INFO:     None feature selector for col prot
2023-01-05 14:22:46,018 INFO:     None feature selector for col chem
2023-01-05 14:22:46,018 INFO:     None feature selector for col chem
2023-01-05 14:22:46,018 INFO:     None feature selector for col chem
2023-01-05 14:22:46,018 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 14:22:46,018 INFO:   Starting stage: BUILD MODEL
2023-01-05 14:22:46,020 INFO:     Number of params in model 72901
2023-01-05 14:22:46,023 INFO:   Done with stage: BUILD MODEL
2023-01-05 14:22:46,023 INFO:   Starting stage: TRAINING
2023-01-05 14:22:46,082 INFO:     Val loss before train {'Reaction outcome loss': 1.0748441616694133, 'Total loss': 1.0748441616694133}
2023-01-05 14:22:46,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:46,082 INFO:     Epoch: 0
2023-01-05 14:22:48,180 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.813876207669576, 'Total loss': 0.813876207669576} | train loss {'Reaction outcome loss': 0.9140774469094083, 'Total loss': 0.9140774469094083}
2023-01-05 14:22:48,181 INFO:     Found new best model at epoch 0
2023-01-05 14:22:48,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:48,183 INFO:     Epoch: 1
2023-01-05 14:22:50,290 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6412044803301493, 'Total loss': 0.6412044803301493} | train loss {'Reaction outcome loss': 0.7417232516286998, 'Total loss': 0.7417232516286998}
2023-01-05 14:22:50,290 INFO:     Found new best model at epoch 1
2023-01-05 14:22:50,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:50,291 INFO:     Epoch: 2
2023-01-05 14:22:52,385 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5299440940221151, 'Total loss': 0.5299440940221151} | train loss {'Reaction outcome loss': 0.5886299409439643, 'Total loss': 0.5886299409439643}
2023-01-05 14:22:52,385 INFO:     Found new best model at epoch 2
2023-01-05 14:22:52,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:52,386 INFO:     Epoch: 3
2023-01-05 14:22:54,496 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49635576208432514, 'Total loss': 0.49635576208432514} | train loss {'Reaction outcome loss': 0.533648827364084, 'Total loss': 0.533648827364084}
2023-01-05 14:22:54,497 INFO:     Found new best model at epoch 3
2023-01-05 14:22:54,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:54,498 INFO:     Epoch: 4
2023-01-05 14:22:56,615 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5164914647738139, 'Total loss': 0.5164914647738139} | train loss {'Reaction outcome loss': 0.513221365004448, 'Total loss': 0.513221365004448}
2023-01-05 14:22:56,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:56,616 INFO:     Epoch: 5
2023-01-05 14:22:58,729 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4964686910311381, 'Total loss': 0.4964686910311381} | train loss {'Reaction outcome loss': 0.49862875632694287, 'Total loss': 0.49862875632694287}
2023-01-05 14:22:58,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:22:58,729 INFO:     Epoch: 6
2023-01-05 14:23:00,841 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47799483040968577, 'Total loss': 0.47799483040968577} | train loss {'Reaction outcome loss': 0.48992611778508255, 'Total loss': 0.48992611778508255}
2023-01-05 14:23:00,842 INFO:     Found new best model at epoch 6
2023-01-05 14:23:00,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:00,843 INFO:     Epoch: 7
2023-01-05 14:23:02,956 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47750636488199233, 'Total loss': 0.47750636488199233} | train loss {'Reaction outcome loss': 0.47821338719437484, 'Total loss': 0.47821338719437484}
2023-01-05 14:23:02,956 INFO:     Found new best model at epoch 7
2023-01-05 14:23:02,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:02,957 INFO:     Epoch: 8
2023-01-05 14:23:05,082 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47541126211484275, 'Total loss': 0.47541126211484275} | train loss {'Reaction outcome loss': 0.4745562785336012, 'Total loss': 0.4745562785336012}
2023-01-05 14:23:05,082 INFO:     Found new best model at epoch 8
2023-01-05 14:23:05,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:05,083 INFO:     Epoch: 9
2023-01-05 14:23:07,201 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5034728080034256, 'Total loss': 0.5034728080034256} | train loss {'Reaction outcome loss': 0.4661628154151114, 'Total loss': 0.4661628154151114}
2023-01-05 14:23:07,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:07,201 INFO:     Epoch: 10
2023-01-05 14:23:09,319 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4857399702072144, 'Total loss': 0.4857399702072144} | train loss {'Reaction outcome loss': 0.4642644580384902, 'Total loss': 0.4642644580384902}
2023-01-05 14:23:09,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:09,319 INFO:     Epoch: 11
2023-01-05 14:23:11,431 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45641364256540934, 'Total loss': 0.45641364256540934} | train loss {'Reaction outcome loss': 0.4590830537885757, 'Total loss': 0.4590830537885757}
2023-01-05 14:23:11,431 INFO:     Found new best model at epoch 11
2023-01-05 14:23:11,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:11,433 INFO:     Epoch: 12
2023-01-05 14:23:13,550 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5062937478224436, 'Total loss': 0.5062937478224436} | train loss {'Reaction outcome loss': 0.4507830075892135, 'Total loss': 0.4507830075892135}
2023-01-05 14:23:13,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:13,551 INFO:     Epoch: 13
2023-01-05 14:23:15,666 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4698932598034541, 'Total loss': 0.4698932598034541} | train loss {'Reaction outcome loss': 0.4496335588753003, 'Total loss': 0.4496335588753003}
2023-01-05 14:23:15,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:15,667 INFO:     Epoch: 14
2023-01-05 14:23:17,796 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4586048096418381, 'Total loss': 0.4586048096418381} | train loss {'Reaction outcome loss': 0.44424631804007886, 'Total loss': 0.44424631804007886}
2023-01-05 14:23:17,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:17,797 INFO:     Epoch: 15
2023-01-05 14:23:19,890 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4785710414250692, 'Total loss': 0.4785710414250692} | train loss {'Reaction outcome loss': 0.4409445259183975, 'Total loss': 0.4409445259183975}
2023-01-05 14:23:19,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:19,890 INFO:     Epoch: 16
2023-01-05 14:23:22,022 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4625053544839223, 'Total loss': 0.4625053544839223} | train loss {'Reaction outcome loss': 0.43637275706797946, 'Total loss': 0.43637275706797946}
2023-01-05 14:23:22,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:22,022 INFO:     Epoch: 17
2023-01-05 14:23:24,140 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44330652554829914, 'Total loss': 0.44330652554829914} | train loss {'Reaction outcome loss': 0.42768690853321245, 'Total loss': 0.42768690853321245}
2023-01-05 14:23:24,140 INFO:     Found new best model at epoch 17
2023-01-05 14:23:24,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:24,142 INFO:     Epoch: 18
2023-01-05 14:23:26,250 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4702389081319173, 'Total loss': 0.4702389081319173} | train loss {'Reaction outcome loss': 0.4305108423272622, 'Total loss': 0.4305108423272622}
2023-01-05 14:23:26,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:26,250 INFO:     Epoch: 19
2023-01-05 14:23:28,379 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4221909649670124, 'Total loss': 0.4221909649670124} | train loss {'Reaction outcome loss': 0.42652187562406724, 'Total loss': 0.42652187562406724}
2023-01-05 14:23:28,380 INFO:     Found new best model at epoch 19
2023-01-05 14:23:28,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:28,381 INFO:     Epoch: 20
2023-01-05 14:23:30,510 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4557337005933126, 'Total loss': 0.4557337005933126} | train loss {'Reaction outcome loss': 0.42139405086361614, 'Total loss': 0.42139405086361614}
2023-01-05 14:23:30,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:30,510 INFO:     Epoch: 21
2023-01-05 14:23:32,638 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44262624382972715, 'Total loss': 0.44262624382972715} | train loss {'Reaction outcome loss': 0.4222363453234694, 'Total loss': 0.4222363453234694}
2023-01-05 14:23:32,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:32,639 INFO:     Epoch: 22
2023-01-05 14:23:34,728 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4594879070917765, 'Total loss': 0.4594879070917765} | train loss {'Reaction outcome loss': 0.41479340610798876, 'Total loss': 0.41479340610798876}
2023-01-05 14:23:34,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:34,729 INFO:     Epoch: 23
2023-01-05 14:23:36,860 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4276151896764835, 'Total loss': 0.4276151896764835} | train loss {'Reaction outcome loss': 0.41162700648677303, 'Total loss': 0.41162700648677303}
2023-01-05 14:23:36,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:36,861 INFO:     Epoch: 24
2023-01-05 14:23:38,974 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42850111424922943, 'Total loss': 0.42850111424922943} | train loss {'Reaction outcome loss': 0.407502618498028, 'Total loss': 0.407502618498028}
2023-01-05 14:23:38,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:38,975 INFO:     Epoch: 25
2023-01-05 14:23:41,101 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4480215628941854, 'Total loss': 0.4480215628941854} | train loss {'Reaction outcome loss': 0.4064100925772832, 'Total loss': 0.4064100925772832}
2023-01-05 14:23:41,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:41,101 INFO:     Epoch: 26
2023-01-05 14:23:43,232 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.441186777750651, 'Total loss': 0.441186777750651} | train loss {'Reaction outcome loss': 0.3987634082726887, 'Total loss': 0.3987634082726887}
2023-01-05 14:23:43,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:43,232 INFO:     Epoch: 27
2023-01-05 14:23:45,329 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47628617882728574, 'Total loss': 0.47628617882728574} | train loss {'Reaction outcome loss': 0.393829847380134, 'Total loss': 0.393829847380134}
2023-01-05 14:23:45,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:45,329 INFO:     Epoch: 28
2023-01-05 14:23:47,436 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46884626348813374, 'Total loss': 0.46884626348813374} | train loss {'Reaction outcome loss': 0.3947509208013651, 'Total loss': 0.3947509208013651}
2023-01-05 14:23:47,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:47,437 INFO:     Epoch: 29
2023-01-05 14:23:49,539 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44088664948940276, 'Total loss': 0.44088664948940276} | train loss {'Reaction outcome loss': 0.39063232323340386, 'Total loss': 0.39063232323340386}
2023-01-05 14:23:49,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:49,539 INFO:     Epoch: 30
2023-01-05 14:23:51,651 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47272616227467856, 'Total loss': 0.47272616227467856} | train loss {'Reaction outcome loss': 0.3866726763793903, 'Total loss': 0.3866726763793903}
2023-01-05 14:23:51,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:51,652 INFO:     Epoch: 31
2023-01-05 14:23:53,780 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5042209585507711, 'Total loss': 0.5042209585507711} | train loss {'Reaction outcome loss': 0.38286331392192313, 'Total loss': 0.38286331392192313}
2023-01-05 14:23:53,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:53,781 INFO:     Epoch: 32
2023-01-05 14:23:55,910 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44366196990013124, 'Total loss': 0.44366196990013124} | train loss {'Reaction outcome loss': 0.38785858235126053, 'Total loss': 0.38785858235126053}
2023-01-05 14:23:55,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:55,910 INFO:     Epoch: 33
2023-01-05 14:23:58,009 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.441491562128067, 'Total loss': 0.441491562128067} | train loss {'Reaction outcome loss': 0.3785666594646074, 'Total loss': 0.3785666594646074}
2023-01-05 14:23:58,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:23:58,010 INFO:     Epoch: 34
2023-01-05 14:24:00,141 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46386066675186155, 'Total loss': 0.46386066675186155} | train loss {'Reaction outcome loss': 0.36547712467583343, 'Total loss': 0.36547712467583343}
2023-01-05 14:24:00,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:00,141 INFO:     Epoch: 35
2023-01-05 14:24:02,241 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4357893536488215, 'Total loss': 0.4357893536488215} | train loss {'Reaction outcome loss': 0.36712933793608993, 'Total loss': 0.36712933793608993}
2023-01-05 14:24:02,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:02,241 INFO:     Epoch: 36
2023-01-05 14:24:04,339 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42598137830694516, 'Total loss': 0.42598137830694516} | train loss {'Reaction outcome loss': 0.36145428477398145, 'Total loss': 0.36145428477398145}
2023-01-05 14:24:04,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:04,340 INFO:     Epoch: 37
2023-01-05 14:24:06,448 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4266273538271586, 'Total loss': 0.4266273538271586} | train loss {'Reaction outcome loss': 0.3601482259831305, 'Total loss': 0.3601482259831305}
2023-01-05 14:24:06,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:06,449 INFO:     Epoch: 38
2023-01-05 14:24:08,565 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46331384231646855, 'Total loss': 0.46331384231646855} | train loss {'Reaction outcome loss': 0.3554638663506156, 'Total loss': 0.3554638663506156}
2023-01-05 14:24:08,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:08,566 INFO:     Epoch: 39
2023-01-05 14:24:10,670 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46262996196746825, 'Total loss': 0.46262996196746825} | train loss {'Reaction outcome loss': 0.3585620123851783, 'Total loss': 0.3585620123851783}
2023-01-05 14:24:10,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:10,671 INFO:     Epoch: 40
2023-01-05 14:24:12,769 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43194546500841774, 'Total loss': 0.43194546500841774} | train loss {'Reaction outcome loss': 0.35508526025882947, 'Total loss': 0.35508526025882947}
2023-01-05 14:24:12,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:12,769 INFO:     Epoch: 41
2023-01-05 14:24:14,879 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42266844809055326, 'Total loss': 0.42266844809055326} | train loss {'Reaction outcome loss': 0.3466985672712326, 'Total loss': 0.3466985672712326}
2023-01-05 14:24:14,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:14,879 INFO:     Epoch: 42
2023-01-05 14:24:16,989 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4533751984437307, 'Total loss': 0.4533751984437307} | train loss {'Reaction outcome loss': 0.34316424376630256, 'Total loss': 0.34316424376630256}
2023-01-05 14:24:16,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:16,989 INFO:     Epoch: 43
2023-01-05 14:24:19,114 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4210211624701818, 'Total loss': 0.4210211624701818} | train loss {'Reaction outcome loss': 0.3389709444778432, 'Total loss': 0.3389709444778432}
2023-01-05 14:24:19,114 INFO:     Found new best model at epoch 43
2023-01-05 14:24:19,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:19,115 INFO:     Epoch: 44
2023-01-05 14:24:21,210 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4017856489866972, 'Total loss': 0.4017856489866972} | train loss {'Reaction outcome loss': 0.33671348854019634, 'Total loss': 0.33671348854019634}
2023-01-05 14:24:21,210 INFO:     Found new best model at epoch 44
2023-01-05 14:24:21,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:21,212 INFO:     Epoch: 45
2023-01-05 14:24:23,328 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4189376771450043, 'Total loss': 0.4189376771450043} | train loss {'Reaction outcome loss': 0.3323243861378779, 'Total loss': 0.3323243861378779}
2023-01-05 14:24:23,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:23,328 INFO:     Epoch: 46
2023-01-05 14:24:25,427 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45195942123730976, 'Total loss': 0.45195942123730976} | train loss {'Reaction outcome loss': 0.3250342489553554, 'Total loss': 0.3250342489553554}
2023-01-05 14:24:25,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:25,427 INFO:     Epoch: 47
2023-01-05 14:24:27,534 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4181065112352371, 'Total loss': 0.4181065112352371} | train loss {'Reaction outcome loss': 0.3287834846225612, 'Total loss': 0.3287834846225612}
2023-01-05 14:24:27,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:27,535 INFO:     Epoch: 48
2023-01-05 14:24:29,645 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4044871233403683, 'Total loss': 0.4044871233403683} | train loss {'Reaction outcome loss': 0.32243209983809845, 'Total loss': 0.32243209983809845}
2023-01-05 14:24:29,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:29,645 INFO:     Epoch: 49
2023-01-05 14:24:31,742 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4753309989968936, 'Total loss': 0.4753309989968936} | train loss {'Reaction outcome loss': 0.3282848343500572, 'Total loss': 0.3282848343500572}
2023-01-05 14:24:31,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:31,742 INFO:     Epoch: 50
2023-01-05 14:24:33,847 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4320093015829722, 'Total loss': 0.4320093015829722} | train loss {'Reaction outcome loss': 0.31891820428556183, 'Total loss': 0.31891820428556183}
2023-01-05 14:24:33,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:33,848 INFO:     Epoch: 51
2023-01-05 14:24:35,979 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41477524638175967, 'Total loss': 0.41477524638175967} | train loss {'Reaction outcome loss': 0.3190408007300208, 'Total loss': 0.3190408007300208}
2023-01-05 14:24:35,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:35,979 INFO:     Epoch: 52
2023-01-05 14:24:38,087 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45290106236934663, 'Total loss': 0.45290106236934663} | train loss {'Reaction outcome loss': 0.3111858637213047, 'Total loss': 0.3111858637213047}
2023-01-05 14:24:38,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:38,087 INFO:     Epoch: 53
2023-01-05 14:24:40,192 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46752500732739766, 'Total loss': 0.46752500732739766} | train loss {'Reaction outcome loss': 0.3084268695039063, 'Total loss': 0.3084268695039063}
2023-01-05 14:24:40,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:40,192 INFO:     Epoch: 54
2023-01-05 14:24:42,289 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41632556219895683, 'Total loss': 0.41632556219895683} | train loss {'Reaction outcome loss': 0.308642094556201, 'Total loss': 0.308642094556201}
2023-01-05 14:24:42,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:42,289 INFO:     Epoch: 55
2023-01-05 14:24:44,391 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4846255391836166, 'Total loss': 0.4846255391836166} | train loss {'Reaction outcome loss': 0.3108091420628048, 'Total loss': 0.3108091420628048}
2023-01-05 14:24:44,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:44,391 INFO:     Epoch: 56
2023-01-05 14:24:46,542 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4399870345989863, 'Total loss': 0.4399870345989863} | train loss {'Reaction outcome loss': 0.3008875434331568, 'Total loss': 0.3008875434331568}
2023-01-05 14:24:46,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:46,543 INFO:     Epoch: 57
2023-01-05 14:24:48,640 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4234739263852437, 'Total loss': 0.4234739263852437} | train loss {'Reaction outcome loss': 0.3020173572828629, 'Total loss': 0.3020173572828629}
2023-01-05 14:24:48,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:48,641 INFO:     Epoch: 58
2023-01-05 14:24:50,763 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4297207732995351, 'Total loss': 0.4297207732995351} | train loss {'Reaction outcome loss': 0.2943170988980365, 'Total loss': 0.2943170988980365}
2023-01-05 14:24:50,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:50,764 INFO:     Epoch: 59
2023-01-05 14:24:52,868 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41285598774751026, 'Total loss': 0.41285598774751026} | train loss {'Reaction outcome loss': 0.2954906375040867, 'Total loss': 0.2954906375040867}
2023-01-05 14:24:52,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:52,869 INFO:     Epoch: 60
2023-01-05 14:24:54,984 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45460328658421834, 'Total loss': 0.45460328658421834} | train loss {'Reaction outcome loss': 0.3027543210977778, 'Total loss': 0.3027543210977778}
2023-01-05 14:24:54,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:54,984 INFO:     Epoch: 61
2023-01-05 14:24:57,064 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45710885524749756, 'Total loss': 0.45710885524749756} | train loss {'Reaction outcome loss': 0.2917626609551511, 'Total loss': 0.2917626609551511}
2023-01-05 14:24:57,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:57,064 INFO:     Epoch: 62
2023-01-05 14:24:59,156 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44381191035111744, 'Total loss': 0.44381191035111744} | train loss {'Reaction outcome loss': 0.2871702700592165, 'Total loss': 0.2871702700592165}
2023-01-05 14:24:59,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:24:59,156 INFO:     Epoch: 63
2023-01-05 14:25:01,314 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45601903200149535, 'Total loss': 0.45601903200149535} | train loss {'Reaction outcome loss': 0.296591105358847, 'Total loss': 0.296591105358847}
2023-01-05 14:25:01,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:01,314 INFO:     Epoch: 64
2023-01-05 14:25:03,456 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43667468925317127, 'Total loss': 0.43667468925317127} | train loss {'Reaction outcome loss': 0.2860392621439981, 'Total loss': 0.2860392621439981}
2023-01-05 14:25:03,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:03,457 INFO:     Epoch: 65
2023-01-05 14:25:05,599 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4294188896814982, 'Total loss': 0.4294188896814982} | train loss {'Reaction outcome loss': 0.28624243050043874, 'Total loss': 0.28624243050043874}
2023-01-05 14:25:05,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:05,599 INFO:     Epoch: 66
2023-01-05 14:25:07,744 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4558240363995234, 'Total loss': 0.4558240363995234} | train loss {'Reaction outcome loss': 0.28163788559746916, 'Total loss': 0.28163788559746916}
2023-01-05 14:25:07,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:07,744 INFO:     Epoch: 67
2023-01-05 14:25:09,856 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4645592043797175, 'Total loss': 0.4645592043797175} | train loss {'Reaction outcome loss': 0.28253940657825927, 'Total loss': 0.28253940657825927}
2023-01-05 14:25:09,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:09,857 INFO:     Epoch: 68
2023-01-05 14:25:11,990 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4569177985191345, 'Total loss': 0.4569177985191345} | train loss {'Reaction outcome loss': 0.2841134475083589, 'Total loss': 0.2841134475083589}
2023-01-05 14:25:11,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:11,990 INFO:     Epoch: 69
2023-01-05 14:25:14,126 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4793893665075302, 'Total loss': 0.4793893665075302} | train loss {'Reaction outcome loss': 0.2767218290329859, 'Total loss': 0.2767218290329859}
2023-01-05 14:25:14,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:14,126 INFO:     Epoch: 70
2023-01-05 14:25:16,250 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4557920714219411, 'Total loss': 0.4557920714219411} | train loss {'Reaction outcome loss': 0.2738196865219032, 'Total loss': 0.2738196865219032}
2023-01-05 14:25:16,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:16,251 INFO:     Epoch: 71
2023-01-05 14:25:18,403 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44688729842503866, 'Total loss': 0.44688729842503866} | train loss {'Reaction outcome loss': 0.2776400871107499, 'Total loss': 0.2776400871107499}
2023-01-05 14:25:18,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:18,403 INFO:     Epoch: 72
2023-01-05 14:25:20,531 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.479614328344663, 'Total loss': 0.479614328344663} | train loss {'Reaction outcome loss': 0.28388126882487336, 'Total loss': 0.28388126882487336}
2023-01-05 14:25:20,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:20,532 INFO:     Epoch: 73
2023-01-05 14:25:22,639 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43256427844365436, 'Total loss': 0.43256427844365436} | train loss {'Reaction outcome loss': 0.2738604543943687, 'Total loss': 0.2738604543943687}
2023-01-05 14:25:22,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:22,640 INFO:     Epoch: 74
2023-01-05 14:25:24,754 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4803092936674754, 'Total loss': 0.4803092936674754} | train loss {'Reaction outcome loss': 0.26732429248930345, 'Total loss': 0.26732429248930345}
2023-01-05 14:25:24,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:24,754 INFO:     Epoch: 75
2023-01-05 14:25:26,860 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42432898183663686, 'Total loss': 0.42432898183663686} | train loss {'Reaction outcome loss': 0.27973798614998807, 'Total loss': 0.27973798614998807}
2023-01-05 14:25:26,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:26,860 INFO:     Epoch: 76
2023-01-05 14:25:28,952 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42657363737622894, 'Total loss': 0.42657363737622894} | train loss {'Reaction outcome loss': 0.2677151808494571, 'Total loss': 0.2677151808494571}
2023-01-05 14:25:28,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:28,952 INFO:     Epoch: 77
2023-01-05 14:25:31,069 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4466709911823273, 'Total loss': 0.4466709911823273} | train loss {'Reaction outcome loss': 0.26618376656047094, 'Total loss': 0.26618376656047094}
2023-01-05 14:25:31,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:31,069 INFO:     Epoch: 78
2023-01-05 14:25:33,176 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4853791822989782, 'Total loss': 0.4853791822989782} | train loss {'Reaction outcome loss': 0.2657857727658045, 'Total loss': 0.2657857727658045}
2023-01-05 14:25:33,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:33,177 INFO:     Epoch: 79
2023-01-05 14:25:35,282 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4200784504413605, 'Total loss': 0.4200784504413605} | train loss {'Reaction outcome loss': 0.2596611264488244, 'Total loss': 0.2596611264488244}
2023-01-05 14:25:35,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:35,282 INFO:     Epoch: 80
2023-01-05 14:25:37,405 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4270590454339981, 'Total loss': 0.4270590454339981} | train loss {'Reaction outcome loss': 0.26978448253276166, 'Total loss': 0.26978448253276166}
2023-01-05 14:25:37,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:37,405 INFO:     Epoch: 81
2023-01-05 14:25:39,521 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44866180221239726, 'Total loss': 0.44866180221239726} | train loss {'Reaction outcome loss': 0.2589827343079217, 'Total loss': 0.2589827343079217}
2023-01-05 14:25:39,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:39,522 INFO:     Epoch: 82
2023-01-05 14:25:41,645 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44063724676767985, 'Total loss': 0.44063724676767985} | train loss {'Reaction outcome loss': 0.25781627072234437, 'Total loss': 0.25781627072234437}
2023-01-05 14:25:41,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:41,646 INFO:     Epoch: 83
2023-01-05 14:25:43,745 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46558447976907097, 'Total loss': 0.46558447976907097} | train loss {'Reaction outcome loss': 0.25750841436790806, 'Total loss': 0.25750841436790806}
2023-01-05 14:25:43,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:43,746 INFO:     Epoch: 84
2023-01-05 14:25:45,883 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44592787822087604, 'Total loss': 0.44592787822087604} | train loss {'Reaction outcome loss': 0.24923877456531313, 'Total loss': 0.24923877456531313}
2023-01-05 14:25:45,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:45,884 INFO:     Epoch: 85
2023-01-05 14:25:48,048 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4283636669317881, 'Total loss': 0.4283636669317881} | train loss {'Reaction outcome loss': 0.25755599931542283, 'Total loss': 0.25755599931542283}
2023-01-05 14:25:48,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:48,048 INFO:     Epoch: 86
2023-01-05 14:25:50,204 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4631466249624888, 'Total loss': 0.4631466249624888} | train loss {'Reaction outcome loss': 0.24912933076687185, 'Total loss': 0.24912933076687185}
2023-01-05 14:25:50,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:50,204 INFO:     Epoch: 87
2023-01-05 14:25:52,364 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43867123623689014, 'Total loss': 0.43867123623689014} | train loss {'Reaction outcome loss': 0.25590714962115146, 'Total loss': 0.25590714962115146}
2023-01-05 14:25:52,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:52,364 INFO:     Epoch: 88
2023-01-05 14:25:54,516 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4709959159294764, 'Total loss': 0.4709959159294764} | train loss {'Reaction outcome loss': 0.2514250654919671, 'Total loss': 0.2514250654919671}
2023-01-05 14:25:54,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:54,516 INFO:     Epoch: 89
2023-01-05 14:25:56,640 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43021841074029604, 'Total loss': 0.43021841074029604} | train loss {'Reaction outcome loss': 0.2441839538033488, 'Total loss': 0.2441839538033488}
2023-01-05 14:25:56,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:56,641 INFO:     Epoch: 90
2023-01-05 14:25:58,592 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46675948103268944, 'Total loss': 0.46675948103268944} | train loss {'Reaction outcome loss': 0.24062504238583066, 'Total loss': 0.24062504238583066}
2023-01-05 14:25:58,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:25:58,593 INFO:     Epoch: 91
2023-01-05 14:26:00,722 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45267711381117504, 'Total loss': 0.45267711381117504} | train loss {'Reaction outcome loss': 0.25053286014255344, 'Total loss': 0.25053286014255344}
2023-01-05 14:26:00,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:00,722 INFO:     Epoch: 92
2023-01-05 14:26:02,824 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4596738487482071, 'Total loss': 0.4596738487482071} | train loss {'Reaction outcome loss': 0.24037897923610746, 'Total loss': 0.24037897923610746}
2023-01-05 14:26:02,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:02,824 INFO:     Epoch: 93
2023-01-05 14:26:04,927 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42378700462480384, 'Total loss': 0.42378700462480384} | train loss {'Reaction outcome loss': 0.24870571839482253, 'Total loss': 0.24870571839482253}
2023-01-05 14:26:04,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:04,928 INFO:     Epoch: 94
2023-01-05 14:26:07,025 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47473710079987846, 'Total loss': 0.47473710079987846} | train loss {'Reaction outcome loss': 0.2419925329526302, 'Total loss': 0.2419925329526302}
2023-01-05 14:26:07,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:07,026 INFO:     Epoch: 95
2023-01-05 14:26:09,143 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48804531842470167, 'Total loss': 0.48804531842470167} | train loss {'Reaction outcome loss': 0.243782043120243, 'Total loss': 0.243782043120243}
2023-01-05 14:26:09,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:09,144 INFO:     Epoch: 96
2023-01-05 14:26:11,266 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46171178221702575, 'Total loss': 0.46171178221702575} | train loss {'Reaction outcome loss': 0.24515826686721887, 'Total loss': 0.24515826686721887}
2023-01-05 14:26:11,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:11,266 INFO:     Epoch: 97
2023-01-05 14:26:13,399 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.440000452597936, 'Total loss': 0.440000452597936} | train loss {'Reaction outcome loss': 0.23908240430579414, 'Total loss': 0.23908240430579414}
2023-01-05 14:26:13,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:13,400 INFO:     Epoch: 98
2023-01-05 14:26:15,494 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4801527738571167, 'Total loss': 0.4801527738571167} | train loss {'Reaction outcome loss': 0.24123340126168244, 'Total loss': 0.24123340126168244}
2023-01-05 14:26:15,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:15,495 INFO:     Epoch: 99
2023-01-05 14:26:17,590 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42712068458398184, 'Total loss': 0.42712068458398184} | train loss {'Reaction outcome loss': 0.2355743397054747, 'Total loss': 0.2355743397054747}
2023-01-05 14:26:17,590 INFO:     Best model found after epoch 45 of 100.
2023-01-05 14:26:17,590 INFO:   Done with stage: TRAINING
2023-01-05 14:26:17,590 INFO:   Starting stage: EVALUATION
2023-01-05 14:26:17,738 INFO:   Done with stage: EVALUATION
2023-01-05 14:26:17,738 INFO:   Leaving out SEQ value Fold_3
2023-01-05 14:26:17,751 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 14:26:17,751 INFO:   Starting stage: FEATURE SCALING
2023-01-05 14:26:18,388 INFO:   Done with stage: FEATURE SCALING
2023-01-05 14:26:18,388 INFO:   Starting stage: SCALING TARGETS
2023-01-05 14:26:18,454 INFO:   Done with stage: SCALING TARGETS
2023-01-05 14:26:18,455 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:26:18,455 INFO:     No hyperparam tuning for this model
2023-01-05 14:26:18,455 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:26:18,455 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 14:26:18,455 INFO:     None feature selector for col prot
2023-01-05 14:26:18,456 INFO:     None feature selector for col prot
2023-01-05 14:26:18,456 INFO:     None feature selector for col prot
2023-01-05 14:26:18,456 INFO:     None feature selector for col chem
2023-01-05 14:26:18,456 INFO:     None feature selector for col chem
2023-01-05 14:26:18,456 INFO:     None feature selector for col chem
2023-01-05 14:26:18,456 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 14:26:18,456 INFO:   Starting stage: BUILD MODEL
2023-01-05 14:26:18,458 INFO:     Number of params in model 72901
2023-01-05 14:26:18,461 INFO:   Done with stage: BUILD MODEL
2023-01-05 14:26:18,461 INFO:   Starting stage: TRAINING
2023-01-05 14:26:18,520 INFO:     Val loss before train {'Reaction outcome loss': 1.0101688941319784, 'Total loss': 1.0101688941319784}
2023-01-05 14:26:18,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:18,520 INFO:     Epoch: 0
2023-01-05 14:26:20,634 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8771358768145243, 'Total loss': 0.8771358768145243} | train loss {'Reaction outcome loss': 0.9382118108498789, 'Total loss': 0.9382118108498789}
2023-01-05 14:26:20,634 INFO:     Found new best model at epoch 0
2023-01-05 14:26:20,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:20,635 INFO:     Epoch: 1
2023-01-05 14:26:22,758 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.676849095026652, 'Total loss': 0.676849095026652} | train loss {'Reaction outcome loss': 0.7832444206859074, 'Total loss': 0.7832444206859074}
2023-01-05 14:26:22,759 INFO:     Found new best model at epoch 1
2023-01-05 14:26:22,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:22,760 INFO:     Epoch: 2
2023-01-05 14:26:24,878 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5642958958943685, 'Total loss': 0.5642958958943685} | train loss {'Reaction outcome loss': 0.6138756603111316, 'Total loss': 0.6138756603111316}
2023-01-05 14:26:24,878 INFO:     Found new best model at epoch 2
2023-01-05 14:26:24,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:24,879 INFO:     Epoch: 3
2023-01-05 14:26:26,996 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5628964245319367, 'Total loss': 0.5628964245319367} | train loss {'Reaction outcome loss': 0.5362659556804782, 'Total loss': 0.5362659556804782}
2023-01-05 14:26:26,996 INFO:     Found new best model at epoch 3
2023-01-05 14:26:26,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:26,998 INFO:     Epoch: 4
2023-01-05 14:26:29,143 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5271851678689321, 'Total loss': 0.5271851678689321} | train loss {'Reaction outcome loss': 0.5157314746701804, 'Total loss': 0.5157314746701804}
2023-01-05 14:26:29,143 INFO:     Found new best model at epoch 4
2023-01-05 14:26:29,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:29,144 INFO:     Epoch: 5
2023-01-05 14:26:31,257 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5285830239454905, 'Total loss': 0.5285830239454905} | train loss {'Reaction outcome loss': 0.49774929418833586, 'Total loss': 0.49774929418833586}
2023-01-05 14:26:31,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:31,257 INFO:     Epoch: 6
2023-01-05 14:26:33,410 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4962616721789042, 'Total loss': 0.4962616721789042} | train loss {'Reaction outcome loss': 0.4923473771144874, 'Total loss': 0.4923473771144874}
2023-01-05 14:26:33,411 INFO:     Found new best model at epoch 6
2023-01-05 14:26:33,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:33,412 INFO:     Epoch: 7
2023-01-05 14:26:35,537 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4759620527426402, 'Total loss': 0.4759620527426402} | train loss {'Reaction outcome loss': 0.479517883954257, 'Total loss': 0.479517883954257}
2023-01-05 14:26:35,537 INFO:     Found new best model at epoch 7
2023-01-05 14:26:35,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:35,539 INFO:     Epoch: 8
2023-01-05 14:26:37,663 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49962196151415506, 'Total loss': 0.49962196151415506} | train loss {'Reaction outcome loss': 0.47723304105066033, 'Total loss': 0.47723304105066033}
2023-01-05 14:26:37,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:37,663 INFO:     Epoch: 9
2023-01-05 14:26:39,789 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46649855772654214, 'Total loss': 0.46649855772654214} | train loss {'Reaction outcome loss': 0.4684386299855083, 'Total loss': 0.4684386299855083}
2023-01-05 14:26:39,789 INFO:     Found new best model at epoch 9
2023-01-05 14:26:39,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:39,790 INFO:     Epoch: 10
2023-01-05 14:26:41,910 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5010872354110082, 'Total loss': 0.5010872354110082} | train loss {'Reaction outcome loss': 0.46818407665747797, 'Total loss': 0.46818407665747797}
2023-01-05 14:26:41,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:41,911 INFO:     Epoch: 11
2023-01-05 14:26:44,051 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49973011910915377, 'Total loss': 0.49973011910915377} | train loss {'Reaction outcome loss': 0.4609084808587158, 'Total loss': 0.4609084808587158}
2023-01-05 14:26:44,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:44,051 INFO:     Epoch: 12
2023-01-05 14:26:46,228 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5020029207070669, 'Total loss': 0.5020029207070669} | train loss {'Reaction outcome loss': 0.4598683965032118, 'Total loss': 0.4598683965032118}
2023-01-05 14:26:46,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:46,228 INFO:     Epoch: 13
2023-01-05 14:26:48,375 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49498087763786314, 'Total loss': 0.49498087763786314} | train loss {'Reaction outcome loss': 0.4536317602670106, 'Total loss': 0.4536317602670106}
2023-01-05 14:26:48,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:48,375 INFO:     Epoch: 14
2023-01-05 14:26:50,500 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46867109338442486, 'Total loss': 0.46867109338442486} | train loss {'Reaction outcome loss': 0.44763002506572835, 'Total loss': 0.44763002506572835}
2023-01-05 14:26:50,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:50,500 INFO:     Epoch: 15
2023-01-05 14:26:52,648 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5020278871059418, 'Total loss': 0.5020278871059418} | train loss {'Reaction outcome loss': 0.4481254994706081, 'Total loss': 0.4481254994706081}
2023-01-05 14:26:52,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:52,649 INFO:     Epoch: 16
2023-01-05 14:26:54,770 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4765003025531769, 'Total loss': 0.4765003025531769} | train loss {'Reaction outcome loss': 0.4446890444433602, 'Total loss': 0.4446890444433602}
2023-01-05 14:26:54,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:54,770 INFO:     Epoch: 17
2023-01-05 14:26:56,926 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49442606667677563, 'Total loss': 0.49442606667677563} | train loss {'Reaction outcome loss': 0.43783902117207535, 'Total loss': 0.43783902117207535}
2023-01-05 14:26:56,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:56,927 INFO:     Epoch: 18
2023-01-05 14:26:59,084 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4753836433092753, 'Total loss': 0.4753836433092753} | train loss {'Reaction outcome loss': 0.4369531819311372, 'Total loss': 0.4369531819311372}
2023-01-05 14:26:59,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:26:59,085 INFO:     Epoch: 19
2023-01-05 14:27:01,254 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4520355840524038, 'Total loss': 0.4520355840524038} | train loss {'Reaction outcome loss': 0.4344133786095755, 'Total loss': 0.4344133786095755}
2023-01-05 14:27:01,254 INFO:     Found new best model at epoch 19
2023-01-05 14:27:01,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:01,255 INFO:     Epoch: 20
2023-01-05 14:27:03,406 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.459892471631368, 'Total loss': 0.459892471631368} | train loss {'Reaction outcome loss': 0.42837117324127766, 'Total loss': 0.42837117324127766}
2023-01-05 14:27:03,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:03,406 INFO:     Epoch: 21
2023-01-05 14:27:05,542 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45334460536638893, 'Total loss': 0.45334460536638893} | train loss {'Reaction outcome loss': 0.42582333207565504, 'Total loss': 0.42582333207565504}
2023-01-05 14:27:05,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:05,543 INFO:     Epoch: 22
2023-01-05 14:27:07,702 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45828554729620613, 'Total loss': 0.45828554729620613} | train loss {'Reaction outcome loss': 0.42528147312955267, 'Total loss': 0.42528147312955267}
2023-01-05 14:27:07,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:07,702 INFO:     Epoch: 23
2023-01-05 14:27:09,867 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4518920948108037, 'Total loss': 0.4518920948108037} | train loss {'Reaction outcome loss': 0.41702276006014677, 'Total loss': 0.41702276006014677}
2023-01-05 14:27:09,867 INFO:     Found new best model at epoch 23
2023-01-05 14:27:09,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:09,868 INFO:     Epoch: 24
2023-01-05 14:27:12,019 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44719158113002777, 'Total loss': 0.44719158113002777} | train loss {'Reaction outcome loss': 0.4181500823937193, 'Total loss': 0.4181500823937193}
2023-01-05 14:27:12,019 INFO:     Found new best model at epoch 24
2023-01-05 14:27:12,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:12,021 INFO:     Epoch: 25
2023-01-05 14:27:14,168 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44507112304369606, 'Total loss': 0.44507112304369606} | train loss {'Reaction outcome loss': 0.4148090272924326, 'Total loss': 0.4148090272924326}
2023-01-05 14:27:14,168 INFO:     Found new best model at epoch 25
2023-01-05 14:27:14,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:14,169 INFO:     Epoch: 26
2023-01-05 14:27:16,313 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49130993684132895, 'Total loss': 0.49130993684132895} | train loss {'Reaction outcome loss': 0.4152553143781902, 'Total loss': 0.4152553143781902}
2023-01-05 14:27:16,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:16,313 INFO:     Epoch: 27
2023-01-05 14:27:18,442 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4577694555123647, 'Total loss': 0.4577694555123647} | train loss {'Reaction outcome loss': 0.4141839786439481, 'Total loss': 0.4141839786439481}
2023-01-05 14:27:18,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:18,443 INFO:     Epoch: 28
2023-01-05 14:27:20,596 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4618925929069519, 'Total loss': 0.4618925929069519} | train loss {'Reaction outcome loss': 0.4071473793065461, 'Total loss': 0.4071473793065461}
2023-01-05 14:27:20,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:20,596 INFO:     Epoch: 29
2023-01-05 14:27:22,760 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4499906003475189, 'Total loss': 0.4499906003475189} | train loss {'Reaction outcome loss': 0.4077535929960491, 'Total loss': 0.4077535929960491}
2023-01-05 14:27:22,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:22,761 INFO:     Epoch: 30
2023-01-05 14:27:24,918 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44913987467686334, 'Total loss': 0.44913987467686334} | train loss {'Reaction outcome loss': 0.39954258944757665, 'Total loss': 0.39954258944757665}
2023-01-05 14:27:24,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:24,919 INFO:     Epoch: 31
2023-01-05 14:27:27,066 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43460750579833984, 'Total loss': 0.43460750579833984} | train loss {'Reaction outcome loss': 0.3970036312502666, 'Total loss': 0.3970036312502666}
2023-01-05 14:27:27,066 INFO:     Found new best model at epoch 31
2023-01-05 14:27:27,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:27,067 INFO:     Epoch: 32
2023-01-05 14:27:29,215 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4649173686901728, 'Total loss': 0.4649173686901728} | train loss {'Reaction outcome loss': 0.3968501209560102, 'Total loss': 0.3968501209560102}
2023-01-05 14:27:29,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:29,216 INFO:     Epoch: 33
2023-01-05 14:27:31,389 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4725166171789169, 'Total loss': 0.4725166171789169} | train loss {'Reaction outcome loss': 0.39197005568085797, 'Total loss': 0.39197005568085797}
2023-01-05 14:27:31,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:31,389 INFO:     Epoch: 34
2023-01-05 14:27:33,521 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41683313498894375, 'Total loss': 0.41683313498894375} | train loss {'Reaction outcome loss': 0.38545578807918696, 'Total loss': 0.38545578807918696}
2023-01-05 14:27:33,521 INFO:     Found new best model at epoch 34
2023-01-05 14:27:33,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:33,522 INFO:     Epoch: 35
2023-01-05 14:27:35,656 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43171208997567495, 'Total loss': 0.43171208997567495} | train loss {'Reaction outcome loss': 0.3896256016608137, 'Total loss': 0.3896256016608137}
2023-01-05 14:27:35,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:35,657 INFO:     Epoch: 36
2023-01-05 14:27:37,787 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45741636455059054, 'Total loss': 0.45741636455059054} | train loss {'Reaction outcome loss': 0.38918463957842686, 'Total loss': 0.38918463957842686}
2023-01-05 14:27:37,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:37,787 INFO:     Epoch: 37
2023-01-05 14:27:39,907 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4239357093969981, 'Total loss': 0.4239357093969981} | train loss {'Reaction outcome loss': 0.37781141798970475, 'Total loss': 0.37781141798970475}
2023-01-05 14:27:39,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:39,907 INFO:     Epoch: 38
2023-01-05 14:27:42,035 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4397754063208898, 'Total loss': 0.4397754063208898} | train loss {'Reaction outcome loss': 0.3813639238041683, 'Total loss': 0.3813639238041683}
2023-01-05 14:27:42,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:42,036 INFO:     Epoch: 39
2023-01-05 14:27:44,188 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4433580696582794, 'Total loss': 0.4433580696582794} | train loss {'Reaction outcome loss': 0.3763590518684283, 'Total loss': 0.3763590518684283}
2023-01-05 14:27:44,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:44,188 INFO:     Epoch: 40
2023-01-05 14:27:46,343 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4474566847085953, 'Total loss': 0.4474566847085953} | train loss {'Reaction outcome loss': 0.37238503978961573, 'Total loss': 0.37238503978961573}
2023-01-05 14:27:46,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:46,343 INFO:     Epoch: 41
2023-01-05 14:27:48,496 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41753991941610974, 'Total loss': 0.41753991941610974} | train loss {'Reaction outcome loss': 0.36895300513201384, 'Total loss': 0.36895300513201384}
2023-01-05 14:27:48,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:48,496 INFO:     Epoch: 42
2023-01-05 14:27:50,647 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4451116899649302, 'Total loss': 0.4451116899649302} | train loss {'Reaction outcome loss': 0.3657774346860221, 'Total loss': 0.3657774346860221}
2023-01-05 14:27:50,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:50,648 INFO:     Epoch: 43
2023-01-05 14:27:52,784 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4584381322065989, 'Total loss': 0.4584381322065989} | train loss {'Reaction outcome loss': 0.3604396393209913, 'Total loss': 0.3604396393209913}
2023-01-05 14:27:52,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:52,785 INFO:     Epoch: 44
2023-01-05 14:27:54,926 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4283901770909627, 'Total loss': 0.4283901770909627} | train loss {'Reaction outcome loss': 0.35932950778816736, 'Total loss': 0.35932950778816736}
2023-01-05 14:27:54,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:54,926 INFO:     Epoch: 45
2023-01-05 14:27:57,059 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4600933055082957, 'Total loss': 0.4600933055082957} | train loss {'Reaction outcome loss': 0.35352813052761295, 'Total loss': 0.35352813052761295}
2023-01-05 14:27:57,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:57,059 INFO:     Epoch: 46
2023-01-05 14:27:59,205 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4243165522813797, 'Total loss': 0.4243165522813797} | train loss {'Reaction outcome loss': 0.35278120011526304, 'Total loss': 0.35278120011526304}
2023-01-05 14:27:59,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:27:59,206 INFO:     Epoch: 47
2023-01-05 14:28:01,388 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42787185112635295, 'Total loss': 0.42787185112635295} | train loss {'Reaction outcome loss': 0.35318609150330516, 'Total loss': 0.35318609150330516}
2023-01-05 14:28:01,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:01,388 INFO:     Epoch: 48
2023-01-05 14:28:03,513 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44871426026026406, 'Total loss': 0.44871426026026406} | train loss {'Reaction outcome loss': 0.3506899098899678, 'Total loss': 0.3506899098899678}
2023-01-05 14:28:03,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:03,514 INFO:     Epoch: 49
2023-01-05 14:28:05,655 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41674266358216605, 'Total loss': 0.41674266358216605} | train loss {'Reaction outcome loss': 0.3471677318813592, 'Total loss': 0.3471677318813592}
2023-01-05 14:28:05,656 INFO:     Found new best model at epoch 49
2023-01-05 14:28:05,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:05,657 INFO:     Epoch: 50
2023-01-05 14:28:07,806 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4007461885611216, 'Total loss': 0.4007461885611216} | train loss {'Reaction outcome loss': 0.34693316090172227, 'Total loss': 0.34693316090172227}
2023-01-05 14:28:07,806 INFO:     Found new best model at epoch 50
2023-01-05 14:28:07,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:07,807 INFO:     Epoch: 51
2023-01-05 14:28:09,919 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42841224471728007, 'Total loss': 0.42841224471728007} | train loss {'Reaction outcome loss': 0.3419884116436443, 'Total loss': 0.3419884116436443}
2023-01-05 14:28:09,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:09,919 INFO:     Epoch: 52
2023-01-05 14:28:12,077 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4266977568467458, 'Total loss': 0.4266977568467458} | train loss {'Reaction outcome loss': 0.34075735944466, 'Total loss': 0.34075735944466}
2023-01-05 14:28:12,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:12,078 INFO:     Epoch: 53
2023-01-05 14:28:14,247 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47446118493874867, 'Total loss': 0.47446118493874867} | train loss {'Reaction outcome loss': 0.3359283062010786, 'Total loss': 0.3359283062010786}
2023-01-05 14:28:14,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:14,247 INFO:     Epoch: 54
2023-01-05 14:28:16,357 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4022553359468778, 'Total loss': 0.4022553359468778} | train loss {'Reaction outcome loss': 0.33444758703130006, 'Total loss': 0.33444758703130006}
2023-01-05 14:28:16,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:16,357 INFO:     Epoch: 55
2023-01-05 14:28:18,498 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4304328819115957, 'Total loss': 0.4304328819115957} | train loss {'Reaction outcome loss': 0.3290554512101803, 'Total loss': 0.3290554512101803}
2023-01-05 14:28:18,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:18,498 INFO:     Epoch: 56
2023-01-05 14:28:20,650 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4124751110871633, 'Total loss': 0.4124751110871633} | train loss {'Reaction outcome loss': 0.3265221471334026, 'Total loss': 0.3265221471334026}
2023-01-05 14:28:20,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:20,651 INFO:     Epoch: 57
2023-01-05 14:28:22,793 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40890302459398903, 'Total loss': 0.40890302459398903} | train loss {'Reaction outcome loss': 0.32039359944743395, 'Total loss': 0.32039359944743395}
2023-01-05 14:28:22,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:22,793 INFO:     Epoch: 58
2023-01-05 14:28:24,965 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4456241856018702, 'Total loss': 0.4456241856018702} | train loss {'Reaction outcome loss': 0.3187384780251632, 'Total loss': 0.3187384780251632}
2023-01-05 14:28:24,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:24,965 INFO:     Epoch: 59
2023-01-05 14:28:27,070 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4222453405459722, 'Total loss': 0.4222453405459722} | train loss {'Reaction outcome loss': 0.3187448509771676, 'Total loss': 0.3187448509771676}
2023-01-05 14:28:27,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:27,070 INFO:     Epoch: 60
2023-01-05 14:28:29,189 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4438268045584361, 'Total loss': 0.4438268045584361} | train loss {'Reaction outcome loss': 0.30866069961203274, 'Total loss': 0.30866069961203274}
2023-01-05 14:28:29,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:29,190 INFO:     Epoch: 61
2023-01-05 14:28:31,345 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4109483351310094, 'Total loss': 0.4109483351310094} | train loss {'Reaction outcome loss': 0.3115147668392445, 'Total loss': 0.3115147668392445}
2023-01-05 14:28:31,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:31,346 INFO:     Epoch: 62
2023-01-05 14:28:33,511 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4082662910223007, 'Total loss': 0.4082662910223007} | train loss {'Reaction outcome loss': 0.31274881215263023, 'Total loss': 0.31274881215263023}
2023-01-05 14:28:33,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:33,512 INFO:     Epoch: 63
2023-01-05 14:28:35,637 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4425649637977282, 'Total loss': 0.4425649637977282} | train loss {'Reaction outcome loss': 0.30683006155882436, 'Total loss': 0.30683006155882436}
2023-01-05 14:28:35,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:35,638 INFO:     Epoch: 64
2023-01-05 14:28:37,763 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4245362142721812, 'Total loss': 0.4245362142721812} | train loss {'Reaction outcome loss': 0.31884436363721413, 'Total loss': 0.31884436363721413}
2023-01-05 14:28:37,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:37,763 INFO:     Epoch: 65
2023-01-05 14:28:39,880 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4309544563293457, 'Total loss': 0.4309544563293457} | train loss {'Reaction outcome loss': 0.30278098338494336, 'Total loss': 0.30278098338494336}
2023-01-05 14:28:39,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:39,881 INFO:     Epoch: 66
2023-01-05 14:28:42,005 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48724844654401145, 'Total loss': 0.48724844654401145} | train loss {'Reaction outcome loss': 0.30159341078931395, 'Total loss': 0.30159341078931395}
2023-01-05 14:28:42,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:42,006 INFO:     Epoch: 67
2023-01-05 14:28:44,147 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4121671030918757, 'Total loss': 0.4121671030918757} | train loss {'Reaction outcome loss': 0.3035505165747047, 'Total loss': 0.3035505165747047}
2023-01-05 14:28:44,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:44,148 INFO:     Epoch: 68
2023-01-05 14:28:46,270 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38937301337718966, 'Total loss': 0.38937301337718966} | train loss {'Reaction outcome loss': 0.29594352058930334, 'Total loss': 0.29594352058930334}
2023-01-05 14:28:46,270 INFO:     Found new best model at epoch 68
2023-01-05 14:28:46,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:46,271 INFO:     Epoch: 69
2023-01-05 14:28:48,416 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4022361606359482, 'Total loss': 0.4022361606359482} | train loss {'Reaction outcome loss': 0.2945103605624533, 'Total loss': 0.2945103605624533}
2023-01-05 14:28:48,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:48,417 INFO:     Epoch: 70
2023-01-05 14:28:50,531 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4364076534907023, 'Total loss': 0.4364076534907023} | train loss {'Reaction outcome loss': 0.2876188384953642, 'Total loss': 0.2876188384953642}
2023-01-05 14:28:50,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:50,531 INFO:     Epoch: 71
2023-01-05 14:28:52,684 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41833072528243065, 'Total loss': 0.41833072528243065} | train loss {'Reaction outcome loss': 0.29391137622024893, 'Total loss': 0.29391137622024893}
2023-01-05 14:28:52,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:52,684 INFO:     Epoch: 72
2023-01-05 14:28:54,824 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.426571653286616, 'Total loss': 0.426571653286616} | train loss {'Reaction outcome loss': 0.28656552525332374, 'Total loss': 0.28656552525332374}
2023-01-05 14:28:54,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:54,824 INFO:     Epoch: 73
2023-01-05 14:28:56,948 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40183526277542114, 'Total loss': 0.40183526277542114} | train loss {'Reaction outcome loss': 0.28797148975006637, 'Total loss': 0.28797148975006637}
2023-01-05 14:28:56,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:56,948 INFO:     Epoch: 74
2023-01-05 14:28:59,083 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3959794996927182, 'Total loss': 0.3959794996927182} | train loss {'Reaction outcome loss': 0.28741409769621645, 'Total loss': 0.28741409769621645}
2023-01-05 14:28:59,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:28:59,084 INFO:     Epoch: 75
2023-01-05 14:29:01,226 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3911676824092865, 'Total loss': 0.3911676824092865} | train loss {'Reaction outcome loss': 0.2790415760020923, 'Total loss': 0.2790415760020923}
2023-01-05 14:29:01,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:01,227 INFO:     Epoch: 76
2023-01-05 14:29:03,374 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4006348510583242, 'Total loss': 0.4006348510583242} | train loss {'Reaction outcome loss': 0.2797882755959991, 'Total loss': 0.2797882755959991}
2023-01-05 14:29:03,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:03,374 INFO:     Epoch: 77
2023-01-05 14:29:05,505 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4079443405071894, 'Total loss': 0.4079443405071894} | train loss {'Reaction outcome loss': 0.28344019622045713, 'Total loss': 0.28344019622045713}
2023-01-05 14:29:05,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:05,507 INFO:     Epoch: 78
2023-01-05 14:29:07,645 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4316423137982686, 'Total loss': 0.4316423137982686} | train loss {'Reaction outcome loss': 0.28097012864738485, 'Total loss': 0.28097012864738485}
2023-01-05 14:29:07,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:07,645 INFO:     Epoch: 79
2023-01-05 14:29:09,768 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4031339754660924, 'Total loss': 0.4031339754660924} | train loss {'Reaction outcome loss': 0.26649258504655676, 'Total loss': 0.26649258504655676}
2023-01-05 14:29:09,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:09,768 INFO:     Epoch: 80
2023-01-05 14:29:11,893 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45548038681348163, 'Total loss': 0.45548038681348163} | train loss {'Reaction outcome loss': 0.2776900394445788, 'Total loss': 0.2776900394445788}
2023-01-05 14:29:11,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:11,894 INFO:     Epoch: 81
2023-01-05 14:29:13,993 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39489700893561047, 'Total loss': 0.39489700893561047} | train loss {'Reaction outcome loss': 0.2672401117500815, 'Total loss': 0.2672401117500815}
2023-01-05 14:29:13,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:13,993 INFO:     Epoch: 82
2023-01-05 14:29:16,138 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41895931363105776, 'Total loss': 0.41895931363105776} | train loss {'Reaction outcome loss': 0.27139064956483616, 'Total loss': 0.27139064956483616}
2023-01-05 14:29:16,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:16,138 INFO:     Epoch: 83
2023-01-05 14:29:18,298 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3963823234041532, 'Total loss': 0.3963823234041532} | train loss {'Reaction outcome loss': 0.272417878786469, 'Total loss': 0.272417878786469}
2023-01-05 14:29:18,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:18,299 INFO:     Epoch: 84
2023-01-05 14:29:20,444 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44094619949658714, 'Total loss': 0.44094619949658714} | train loss {'Reaction outcome loss': 0.2678940895346612, 'Total loss': 0.2678940895346612}
2023-01-05 14:29:20,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:20,444 INFO:     Epoch: 85
2023-01-05 14:29:22,580 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3818971812725067, 'Total loss': 0.3818971812725067} | train loss {'Reaction outcome loss': 0.266159975371004, 'Total loss': 0.266159975371004}
2023-01-05 14:29:22,580 INFO:     Found new best model at epoch 85
2023-01-05 14:29:22,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:22,581 INFO:     Epoch: 86
2023-01-05 14:29:24,706 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.36308418413003285, 'Total loss': 0.36308418413003285} | train loss {'Reaction outcome loss': 0.26954525607182594, 'Total loss': 0.26954525607182594}
2023-01-05 14:29:24,707 INFO:     Found new best model at epoch 86
2023-01-05 14:29:24,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:24,708 INFO:     Epoch: 87
2023-01-05 14:29:26,822 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42019373973210655, 'Total loss': 0.42019373973210655} | train loss {'Reaction outcome loss': 0.26090122523452464, 'Total loss': 0.26090122523452464}
2023-01-05 14:29:26,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:26,822 INFO:     Epoch: 88
2023-01-05 14:29:28,980 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44715170164903006, 'Total loss': 0.44715170164903006} | train loss {'Reaction outcome loss': 0.2566200570087798, 'Total loss': 0.2566200570087798}
2023-01-05 14:29:28,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:28,980 INFO:     Epoch: 89
2023-01-05 14:29:31,096 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.34909311433633167, 'Total loss': 0.34909311433633167} | train loss {'Reaction outcome loss': 0.2660397556100557, 'Total loss': 0.2660397556100557}
2023-01-05 14:29:31,096 INFO:     Found new best model at epoch 89
2023-01-05 14:29:31,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:31,097 INFO:     Epoch: 90
2023-01-05 14:29:33,290 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40562111934026085, 'Total loss': 0.40562111934026085} | train loss {'Reaction outcome loss': 0.25841011227971883, 'Total loss': 0.25841011227971883}
2023-01-05 14:29:33,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:33,291 INFO:     Epoch: 91
2023-01-05 14:29:35,509 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4019215822219849, 'Total loss': 0.4019215822219849} | train loss {'Reaction outcome loss': 0.261957920503116, 'Total loss': 0.261957920503116}
2023-01-05 14:29:35,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:35,510 INFO:     Epoch: 92
2023-01-05 14:29:37,656 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4200979252656301, 'Total loss': 0.4200979252656301} | train loss {'Reaction outcome loss': 0.2600758144849517, 'Total loss': 0.2600758144849517}
2023-01-05 14:29:37,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:37,656 INFO:     Epoch: 93
2023-01-05 14:29:39,824 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4380571097135544, 'Total loss': 0.4380571097135544} | train loss {'Reaction outcome loss': 0.2597793086574678, 'Total loss': 0.2597793086574678}
2023-01-05 14:29:39,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:39,824 INFO:     Epoch: 94
2023-01-05 14:29:41,957 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44650070865948993, 'Total loss': 0.44650070865948993} | train loss {'Reaction outcome loss': 0.26042572947314185, 'Total loss': 0.26042572947314185}
2023-01-05 14:29:41,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:41,958 INFO:     Epoch: 95
2023-01-05 14:29:44,140 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.418467883579433, 'Total loss': 0.418467883579433} | train loss {'Reaction outcome loss': 0.2519598202779889, 'Total loss': 0.2519598202779889}
2023-01-05 14:29:44,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:44,141 INFO:     Epoch: 96
2023-01-05 14:29:46,313 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4186979472637177, 'Total loss': 0.4186979472637177} | train loss {'Reaction outcome loss': 0.2523845854439657, 'Total loss': 0.2523845854439657}
2023-01-05 14:29:46,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:46,313 INFO:     Epoch: 97
2023-01-05 14:29:48,440 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4111481159925461, 'Total loss': 0.4111481159925461} | train loss {'Reaction outcome loss': 0.24745200407847653, 'Total loss': 0.24745200407847653}
2023-01-05 14:29:48,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:48,440 INFO:     Epoch: 98
2023-01-05 14:29:50,610 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41243145962556205, 'Total loss': 0.41243145962556205} | train loss {'Reaction outcome loss': 0.2477318281443776, 'Total loss': 0.2477318281443776}
2023-01-05 14:29:50,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:50,611 INFO:     Epoch: 99
2023-01-05 14:29:52,786 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38561770468950274, 'Total loss': 0.38561770468950274} | train loss {'Reaction outcome loss': 0.25268279248508657, 'Total loss': 0.25268279248508657}
2023-01-05 14:29:52,786 INFO:     Best model found after epoch 90 of 100.
2023-01-05 14:29:52,787 INFO:   Done with stage: TRAINING
2023-01-05 14:29:52,787 INFO:   Starting stage: EVALUATION
2023-01-05 14:29:52,945 INFO:   Done with stage: EVALUATION
2023-01-05 14:29:52,946 INFO:   Leaving out SEQ value Fold_4
2023-01-05 14:29:52,960 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 14:29:52,960 INFO:   Starting stage: FEATURE SCALING
2023-01-05 14:29:53,665 INFO:   Done with stage: FEATURE SCALING
2023-01-05 14:29:53,665 INFO:   Starting stage: SCALING TARGETS
2023-01-05 14:29:53,743 INFO:   Done with stage: SCALING TARGETS
2023-01-05 14:29:53,743 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:29:53,743 INFO:     No hyperparam tuning for this model
2023-01-05 14:29:53,743 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:29:53,743 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 14:29:53,744 INFO:     None feature selector for col prot
2023-01-05 14:29:53,744 INFO:     None feature selector for col prot
2023-01-05 14:29:53,744 INFO:     None feature selector for col prot
2023-01-05 14:29:53,745 INFO:     None feature selector for col chem
2023-01-05 14:29:53,745 INFO:     None feature selector for col chem
2023-01-05 14:29:53,745 INFO:     None feature selector for col chem
2023-01-05 14:29:53,745 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 14:29:53,745 INFO:   Starting stage: BUILD MODEL
2023-01-05 14:29:53,747 INFO:     Number of params in model 72901
2023-01-05 14:29:53,750 INFO:   Done with stage: BUILD MODEL
2023-01-05 14:29:53,750 INFO:   Starting stage: TRAINING
2023-01-05 14:29:53,811 INFO:     Val loss before train {'Reaction outcome loss': 0.978316330909729, 'Total loss': 0.978316330909729}
2023-01-05 14:29:53,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:53,811 INFO:     Epoch: 0
2023-01-05 14:29:55,980 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8078838308652242, 'Total loss': 0.8078838308652242} | train loss {'Reaction outcome loss': 0.9310296717963924, 'Total loss': 0.9310296717963924}
2023-01-05 14:29:55,981 INFO:     Found new best model at epoch 0
2023-01-05 14:29:55,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:55,982 INFO:     Epoch: 1
2023-01-05 14:29:58,125 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6246051589647929, 'Total loss': 0.6246051589647929} | train loss {'Reaction outcome loss': 0.7126350644908657, 'Total loss': 0.7126350644908657}
2023-01-05 14:29:58,125 INFO:     Found new best model at epoch 1
2023-01-05 14:29:58,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:29:58,126 INFO:     Epoch: 2
2023-01-05 14:30:00,306 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.565866067012151, 'Total loss': 0.565866067012151} | train loss {'Reaction outcome loss': 0.5771562389303201, 'Total loss': 0.5771562389303201}
2023-01-05 14:30:00,306 INFO:     Found new best model at epoch 2
2023-01-05 14:30:00,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:00,308 INFO:     Epoch: 3
2023-01-05 14:30:02,450 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.691168220837911, 'Total loss': 0.691168220837911} | train loss {'Reaction outcome loss': 0.5328213661263566, 'Total loss': 0.5328213661263566}
2023-01-05 14:30:02,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:02,450 INFO:     Epoch: 4
2023-01-05 14:30:04,437 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5610141555468241, 'Total loss': 0.5610141555468241} | train loss {'Reaction outcome loss': 0.5147295429603288, 'Total loss': 0.5147295429603288}
2023-01-05 14:30:04,437 INFO:     Found new best model at epoch 4
2023-01-05 14:30:04,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:04,439 INFO:     Epoch: 5
2023-01-05 14:30:06,574 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5768490632375082, 'Total loss': 0.5768490632375082} | train loss {'Reaction outcome loss': 0.503878570797211, 'Total loss': 0.503878570797211}
2023-01-05 14:30:06,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:06,574 INFO:     Epoch: 6
2023-01-05 14:30:08,711 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5654022951920827, 'Total loss': 0.5654022951920827} | train loss {'Reaction outcome loss': 0.4919139707884634, 'Total loss': 0.4919139707884634}
2023-01-05 14:30:08,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:08,711 INFO:     Epoch: 7
2023-01-05 14:30:10,846 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5496849358081818, 'Total loss': 0.5496849358081818} | train loss {'Reaction outcome loss': 0.4851006799333793, 'Total loss': 0.4851006799333793}
2023-01-05 14:30:10,848 INFO:     Found new best model at epoch 7
2023-01-05 14:30:10,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:10,849 INFO:     Epoch: 8
2023-01-05 14:30:12,980 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5456292102734248, 'Total loss': 0.5456292102734248} | train loss {'Reaction outcome loss': 0.47663084323440646, 'Total loss': 0.47663084323440646}
2023-01-05 14:30:12,980 INFO:     Found new best model at epoch 8
2023-01-05 14:30:12,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:12,982 INFO:     Epoch: 9
2023-01-05 14:30:15,118 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5736875057220459, 'Total loss': 0.5736875057220459} | train loss {'Reaction outcome loss': 0.4696510098471108, 'Total loss': 0.4696510098471108}
2023-01-05 14:30:15,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:15,118 INFO:     Epoch: 10
2023-01-05 14:30:17,280 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5763399183750153, 'Total loss': 0.5763399183750153} | train loss {'Reaction outcome loss': 0.4690062467963687, 'Total loss': 0.4690062467963687}
2023-01-05 14:30:17,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:17,281 INFO:     Epoch: 11
2023-01-05 14:30:19,409 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5185809592405956, 'Total loss': 0.5185809592405956} | train loss {'Reaction outcome loss': 0.4576360827533777, 'Total loss': 0.4576360827533777}
2023-01-05 14:30:19,409 INFO:     Found new best model at epoch 11
2023-01-05 14:30:19,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:19,410 INFO:     Epoch: 12
2023-01-05 14:30:21,534 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5398391485214233, 'Total loss': 0.5398391485214233} | train loss {'Reaction outcome loss': 0.45521893613174935, 'Total loss': 0.45521893613174935}
2023-01-05 14:30:21,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:21,535 INFO:     Epoch: 13
2023-01-05 14:30:23,648 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5711833576361338, 'Total loss': 0.5711833576361338} | train loss {'Reaction outcome loss': 0.44724226917815985, 'Total loss': 0.44724226917815985}
2023-01-05 14:30:23,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:23,648 INFO:     Epoch: 14
2023-01-05 14:30:25,770 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5719082812468211, 'Total loss': 0.5719082812468211} | train loss {'Reaction outcome loss': 0.44474851878003524, 'Total loss': 0.44474851878003524}
2023-01-05 14:30:25,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:25,771 INFO:     Epoch: 15
2023-01-05 14:30:27,937 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5308191041151683, 'Total loss': 0.5308191041151683} | train loss {'Reaction outcome loss': 0.4387207182951352, 'Total loss': 0.4387207182951352}
2023-01-05 14:30:27,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:27,938 INFO:     Epoch: 16
2023-01-05 14:30:30,086 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5249120791753134, 'Total loss': 0.5249120791753134} | train loss {'Reaction outcome loss': 0.43803699731504014, 'Total loss': 0.43803699731504014}
2023-01-05 14:30:30,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:30,087 INFO:     Epoch: 17
2023-01-05 14:30:32,239 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5464249134063721, 'Total loss': 0.5464249134063721} | train loss {'Reaction outcome loss': 0.43405585394439283, 'Total loss': 0.43405585394439283}
2023-01-05 14:30:32,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:32,240 INFO:     Epoch: 18
2023-01-05 14:30:34,391 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5171385983626048, 'Total loss': 0.5171385983626048} | train loss {'Reaction outcome loss': 0.4289006778587073, 'Total loss': 0.4289006778587073}
2023-01-05 14:30:34,391 INFO:     Found new best model at epoch 18
2023-01-05 14:30:34,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:34,393 INFO:     Epoch: 19
2023-01-05 14:30:36,541 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5659313837687174, 'Total loss': 0.5659313837687174} | train loss {'Reaction outcome loss': 0.4240555411964547, 'Total loss': 0.4240555411964547}
2023-01-05 14:30:36,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:36,541 INFO:     Epoch: 20
2023-01-05 14:30:38,702 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5667432020107905, 'Total loss': 0.5667432020107905} | train loss {'Reaction outcome loss': 0.4183607430933615, 'Total loss': 0.4183607430933615}
2023-01-05 14:30:38,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:38,702 INFO:     Epoch: 21
2023-01-05 14:30:40,842 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5538311094045639, 'Total loss': 0.5538311094045639} | train loss {'Reaction outcome loss': 0.4097098034372829, 'Total loss': 0.4097098034372829}
2023-01-05 14:30:40,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:40,842 INFO:     Epoch: 22
2023-01-05 14:30:43,002 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5367543399333954, 'Total loss': 0.5367543399333954} | train loss {'Reaction outcome loss': 0.40538829626912243, 'Total loss': 0.40538829626912243}
2023-01-05 14:30:43,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:43,002 INFO:     Epoch: 23
2023-01-05 14:30:45,136 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5576363891363144, 'Total loss': 0.5576363891363144} | train loss {'Reaction outcome loss': 0.40642466197052585, 'Total loss': 0.40642466197052585}
2023-01-05 14:30:45,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:45,136 INFO:     Epoch: 24
2023-01-05 14:30:47,288 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5512941102186839, 'Total loss': 0.5512941102186839} | train loss {'Reaction outcome loss': 0.4063741876760545, 'Total loss': 0.4063741876760545}
2023-01-05 14:30:47,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:47,289 INFO:     Epoch: 25
2023-01-05 14:30:49,438 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5740974088509877, 'Total loss': 0.5740974088509877} | train loss {'Reaction outcome loss': 0.3945179792786763, 'Total loss': 0.3945179792786763}
2023-01-05 14:30:49,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:49,438 INFO:     Epoch: 26
2023-01-05 14:30:51,590 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5514075895150502, 'Total loss': 0.5514075895150502} | train loss {'Reaction outcome loss': 0.38975039377324416, 'Total loss': 0.38975039377324416}
2023-01-05 14:30:51,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:51,591 INFO:     Epoch: 27
2023-01-05 14:30:53,750 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5295058916012446, 'Total loss': 0.5295058916012446} | train loss {'Reaction outcome loss': 0.3876748825507474, 'Total loss': 0.3876748825507474}
2023-01-05 14:30:53,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:53,751 INFO:     Epoch: 28
2023-01-05 14:30:55,892 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5177919407685597, 'Total loss': 0.5177919407685597} | train loss {'Reaction outcome loss': 0.380517122413062, 'Total loss': 0.380517122413062}
2023-01-05 14:30:55,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:55,892 INFO:     Epoch: 29
2023-01-05 14:30:58,023 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.6092414220174154, 'Total loss': 0.6092414220174154} | train loss {'Reaction outcome loss': 0.3840514711417016, 'Total loss': 0.3840514711417016}
2023-01-05 14:30:58,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:30:58,024 INFO:     Epoch: 30
2023-01-05 14:31:00,164 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5194554487864177, 'Total loss': 0.5194554487864177} | train loss {'Reaction outcome loss': 0.3771193339775185, 'Total loss': 0.3771193339775185}
2023-01-05 14:31:00,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:00,165 INFO:     Epoch: 31
2023-01-05 14:31:02,304 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5626810053984325, 'Total loss': 0.5626810053984325} | train loss {'Reaction outcome loss': 0.37361572357398937, 'Total loss': 0.37361572357398937}
2023-01-05 14:31:02,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:02,304 INFO:     Epoch: 32
2023-01-05 14:31:04,463 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5287941575050354, 'Total loss': 0.5287941575050354} | train loss {'Reaction outcome loss': 0.3715900797329655, 'Total loss': 0.3715900797329655}
2023-01-05 14:31:04,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:04,463 INFO:     Epoch: 33
2023-01-05 14:31:06,616 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5430180877447128, 'Total loss': 0.5430180877447128} | train loss {'Reaction outcome loss': 0.3694784472619153, 'Total loss': 0.3694784472619153}
2023-01-05 14:31:06,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:06,617 INFO:     Epoch: 34
2023-01-05 14:31:08,761 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5490748445192973, 'Total loss': 0.5490748445192973} | train loss {'Reaction outcome loss': 0.35910355855142595, 'Total loss': 0.35910355855142595}
2023-01-05 14:31:08,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:08,761 INFO:     Epoch: 35
2023-01-05 14:31:10,884 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5151982486248017, 'Total loss': 0.5151982486248017} | train loss {'Reaction outcome loss': 0.3627679748763246, 'Total loss': 0.3627679748763246}
2023-01-05 14:31:10,885 INFO:     Found new best model at epoch 35
2023-01-05 14:31:10,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:10,886 INFO:     Epoch: 36
2023-01-05 14:31:13,042 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.541308053334554, 'Total loss': 0.541308053334554} | train loss {'Reaction outcome loss': 0.36047323704411405, 'Total loss': 0.36047323704411405}
2023-01-05 14:31:13,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:13,043 INFO:     Epoch: 37
2023-01-05 14:31:15,192 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5354003230730693, 'Total loss': 0.5354003230730693} | train loss {'Reaction outcome loss': 0.3568623822034481, 'Total loss': 0.3568623822034481}
2023-01-05 14:31:15,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:15,192 INFO:     Epoch: 38
2023-01-05 14:31:17,339 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5249543090661367, 'Total loss': 0.5249543090661367} | train loss {'Reaction outcome loss': 0.34991751985106656, 'Total loss': 0.34991751985106656}
2023-01-05 14:31:17,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:17,339 INFO:     Epoch: 39
2023-01-05 14:31:19,477 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.564913829167684, 'Total loss': 0.564913829167684} | train loss {'Reaction outcome loss': 0.3409390054670052, 'Total loss': 0.3409390054670052}
2023-01-05 14:31:19,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:19,477 INFO:     Epoch: 40
2023-01-05 14:31:21,635 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5053894837697347, 'Total loss': 0.5053894837697347} | train loss {'Reaction outcome loss': 0.3471807151938711, 'Total loss': 0.3471807151938711}
2023-01-05 14:31:21,635 INFO:     Found new best model at epoch 40
2023-01-05 14:31:21,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:21,637 INFO:     Epoch: 41
2023-01-05 14:31:23,764 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5362091133991878, 'Total loss': 0.5362091133991878} | train loss {'Reaction outcome loss': 0.338438784427914, 'Total loss': 0.338438784427914}
2023-01-05 14:31:23,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:23,766 INFO:     Epoch: 42
2023-01-05 14:31:25,927 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5545394003391266, 'Total loss': 0.5545394003391266} | train loss {'Reaction outcome loss': 0.33715618140861014, 'Total loss': 0.33715618140861014}
2023-01-05 14:31:25,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:25,927 INFO:     Epoch: 43
2023-01-05 14:31:28,081 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48916663229465485, 'Total loss': 0.48916663229465485} | train loss {'Reaction outcome loss': 0.3331405735887345, 'Total loss': 0.3331405735887345}
2023-01-05 14:31:28,081 INFO:     Found new best model at epoch 43
2023-01-05 14:31:28,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:28,082 INFO:     Epoch: 44
2023-01-05 14:31:30,224 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5060954074064891, 'Total loss': 0.5060954074064891} | train loss {'Reaction outcome loss': 0.33303867449936886, 'Total loss': 0.33303867449936886}
2023-01-05 14:31:30,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:30,225 INFO:     Epoch: 45
2023-01-05 14:31:32,375 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5412750601768493, 'Total loss': 0.5412750601768493} | train loss {'Reaction outcome loss': 0.330515514642323, 'Total loss': 0.330515514642323}
2023-01-05 14:31:32,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:32,375 INFO:     Epoch: 46
2023-01-05 14:31:34,524 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5252096215883891, 'Total loss': 0.5252096215883891} | train loss {'Reaction outcome loss': 0.32953624655946495, 'Total loss': 0.32953624655946495}
2023-01-05 14:31:34,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:34,524 INFO:     Epoch: 47
2023-01-05 14:31:36,675 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5368032425642013, 'Total loss': 0.5368032425642013} | train loss {'Reaction outcome loss': 0.3282740531953233, 'Total loss': 0.3282740531953233}
2023-01-05 14:31:36,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:36,675 INFO:     Epoch: 48
2023-01-05 14:31:38,816 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5665851324796677, 'Total loss': 0.5665851324796677} | train loss {'Reaction outcome loss': 0.3207098913483241, 'Total loss': 0.3207098913483241}
2023-01-05 14:31:38,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:38,816 INFO:     Epoch: 49
2023-01-05 14:31:40,954 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5035860915978749, 'Total loss': 0.5035860915978749} | train loss {'Reaction outcome loss': 0.31445016599653647, 'Total loss': 0.31445016599653647}
2023-01-05 14:31:40,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:40,954 INFO:     Epoch: 50
2023-01-05 14:31:43,085 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5470596835017204, 'Total loss': 0.5470596835017204} | train loss {'Reaction outcome loss': 0.3150183346915977, 'Total loss': 0.3150183346915977}
2023-01-05 14:31:43,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:43,086 INFO:     Epoch: 51
2023-01-05 14:31:45,234 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5411369502544403, 'Total loss': 0.5411369502544403} | train loss {'Reaction outcome loss': 0.31163692637766954, 'Total loss': 0.31163692637766954}
2023-01-05 14:31:45,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:45,234 INFO:     Epoch: 52
2023-01-05 14:31:47,372 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47668805718421936, 'Total loss': 0.47668805718421936} | train loss {'Reaction outcome loss': 0.3148221782936516, 'Total loss': 0.3148221782936516}
2023-01-05 14:31:47,372 INFO:     Found new best model at epoch 52
2023-01-05 14:31:47,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:47,374 INFO:     Epoch: 53
2023-01-05 14:31:49,498 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5516408840815227, 'Total loss': 0.5516408840815227} | train loss {'Reaction outcome loss': 0.3060081226193087, 'Total loss': 0.3060081226193087}
2023-01-05 14:31:49,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:49,498 INFO:     Epoch: 54
2023-01-05 14:31:51,634 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5283630798260371, 'Total loss': 0.5283630798260371} | train loss {'Reaction outcome loss': 0.30840362756368483, 'Total loss': 0.30840362756368483}
2023-01-05 14:31:51,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:51,634 INFO:     Epoch: 55
2023-01-05 14:31:53,775 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5006119638681412, 'Total loss': 0.5006119638681412} | train loss {'Reaction outcome loss': 0.2983355603923866, 'Total loss': 0.2983355603923866}
2023-01-05 14:31:53,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:53,776 INFO:     Epoch: 56
2023-01-05 14:31:55,914 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4941700279712677, 'Total loss': 0.4941700279712677} | train loss {'Reaction outcome loss': 0.30320477301409526, 'Total loss': 0.30320477301409526}
2023-01-05 14:31:55,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:55,914 INFO:     Epoch: 57
2023-01-05 14:31:58,062 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5329623599847158, 'Total loss': 0.5329623599847158} | train loss {'Reaction outcome loss': 0.30107124475257924, 'Total loss': 0.30107124475257924}
2023-01-05 14:31:58,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:31:58,062 INFO:     Epoch: 58
2023-01-05 14:32:00,218 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5421120723088583, 'Total loss': 0.5421120723088583} | train loss {'Reaction outcome loss': 0.30191086560810515, 'Total loss': 0.30191086560810515}
2023-01-05 14:32:00,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:00,219 INFO:     Epoch: 59
2023-01-05 14:32:02,479 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5277787784735362, 'Total loss': 0.5277787784735362} | train loss {'Reaction outcome loss': 0.30299233992177227, 'Total loss': 0.30299233992177227}
2023-01-05 14:32:02,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:02,479 INFO:     Epoch: 60
2023-01-05 14:32:04,701 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5110003829002381, 'Total loss': 0.5110003829002381} | train loss {'Reaction outcome loss': 0.2912426848193153, 'Total loss': 0.2912426848193153}
2023-01-05 14:32:04,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:04,701 INFO:     Epoch: 61
2023-01-05 14:32:06,834 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5127415736516316, 'Total loss': 0.5127415736516316} | train loss {'Reaction outcome loss': 0.29157414029113654, 'Total loss': 0.29157414029113654}
2023-01-05 14:32:06,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:06,834 INFO:     Epoch: 62
2023-01-05 14:32:08,993 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5349927534659703, 'Total loss': 0.5349927534659703} | train loss {'Reaction outcome loss': 0.2989258834829937, 'Total loss': 0.2989258834829937}
2023-01-05 14:32:08,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:08,993 INFO:     Epoch: 63
2023-01-05 14:32:11,137 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5298965732256572, 'Total loss': 0.5298965732256572} | train loss {'Reaction outcome loss': 0.2918513936901781, 'Total loss': 0.2918513936901781}
2023-01-05 14:32:11,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:11,138 INFO:     Epoch: 64
2023-01-05 14:32:13,285 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5593597114086151, 'Total loss': 0.5593597114086151} | train loss {'Reaction outcome loss': 0.2792136533864999, 'Total loss': 0.2792136533864999}
2023-01-05 14:32:13,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:13,285 INFO:     Epoch: 65
2023-01-05 14:32:15,417 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5415198057889938, 'Total loss': 0.5415198057889938} | train loss {'Reaction outcome loss': 0.28549835836306375, 'Total loss': 0.28549835836306375}
2023-01-05 14:32:15,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:15,417 INFO:     Epoch: 66
2023-01-05 14:32:17,540 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.525881615281105, 'Total loss': 0.525881615281105} | train loss {'Reaction outcome loss': 0.289201968265462, 'Total loss': 0.289201968265462}
2023-01-05 14:32:17,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:17,540 INFO:     Epoch: 67
2023-01-05 14:32:19,693 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5031570822000504, 'Total loss': 0.5031570822000504} | train loss {'Reaction outcome loss': 0.28947534777950296, 'Total loss': 0.28947534777950296}
2023-01-05 14:32:19,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:19,693 INFO:     Epoch: 68
2023-01-05 14:32:21,829 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5266707460085551, 'Total loss': 0.5266707460085551} | train loss {'Reaction outcome loss': 0.28911592019889976, 'Total loss': 0.28911592019889976}
2023-01-05 14:32:21,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:21,829 INFO:     Epoch: 69
2023-01-05 14:32:23,991 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5363143791755041, 'Total loss': 0.5363143791755041} | train loss {'Reaction outcome loss': 0.286046284039098, 'Total loss': 0.286046284039098}
2023-01-05 14:32:23,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:23,992 INFO:     Epoch: 70
2023-01-05 14:32:26,141 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5298670013745626, 'Total loss': 0.5298670013745626} | train loss {'Reaction outcome loss': 0.27836842432160885, 'Total loss': 0.27836842432160885}
2023-01-05 14:32:26,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:26,141 INFO:     Epoch: 71
2023-01-05 14:32:28,292 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49382054607073467, 'Total loss': 0.49382054607073467} | train loss {'Reaction outcome loss': 0.27240740769418353, 'Total loss': 0.27240740769418353}
2023-01-05 14:32:28,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:28,293 INFO:     Epoch: 72
2023-01-05 14:32:30,445 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5142928491036097, 'Total loss': 0.5142928491036097} | train loss {'Reaction outcome loss': 0.28190235156122095, 'Total loss': 0.28190235156122095}
2023-01-05 14:32:30,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:30,446 INFO:     Epoch: 73
2023-01-05 14:32:32,593 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49150340010722476, 'Total loss': 0.49150340010722476} | train loss {'Reaction outcome loss': 0.2741529895295305, 'Total loss': 0.2741529895295305}
2023-01-05 14:32:32,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:32,594 INFO:     Epoch: 74
2023-01-05 14:32:34,841 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5133514881134034, 'Total loss': 0.5133514881134034} | train loss {'Reaction outcome loss': 0.27268070491562035, 'Total loss': 0.27268070491562035}
2023-01-05 14:32:34,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:34,842 INFO:     Epoch: 75
2023-01-05 14:32:37,072 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5277267316977183, 'Total loss': 0.5277267316977183} | train loss {'Reaction outcome loss': 0.2691231404669879, 'Total loss': 0.2691231404669879}
2023-01-05 14:32:37,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:37,073 INFO:     Epoch: 76
2023-01-05 14:32:39,294 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5108052621285121, 'Total loss': 0.5108052621285121} | train loss {'Reaction outcome loss': 0.27372901502068725, 'Total loss': 0.27372901502068725}
2023-01-05 14:32:39,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:39,294 INFO:     Epoch: 77
2023-01-05 14:32:41,463 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5094577009479205, 'Total loss': 0.5094577009479205} | train loss {'Reaction outcome loss': 0.27317276196924145, 'Total loss': 0.27317276196924145}
2023-01-05 14:32:41,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:41,463 INFO:     Epoch: 78
2023-01-05 14:32:43,611 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5589898963769276, 'Total loss': 0.5589898963769276} | train loss {'Reaction outcome loss': 0.2766804567635705, 'Total loss': 0.2766804567635705}
2023-01-05 14:32:43,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:43,612 INFO:     Epoch: 79
2023-01-05 14:32:45,754 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46377794643243153, 'Total loss': 0.46377794643243153} | train loss {'Reaction outcome loss': 0.2751143314347801, 'Total loss': 0.2751143314347801}
2023-01-05 14:32:45,754 INFO:     Found new best model at epoch 79
2023-01-05 14:32:45,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:45,756 INFO:     Epoch: 80
2023-01-05 14:32:47,900 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5053027192751567, 'Total loss': 0.5053027192751567} | train loss {'Reaction outcome loss': 0.26384270653827957, 'Total loss': 0.26384270653827957}
2023-01-05 14:32:47,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:47,901 INFO:     Epoch: 81
2023-01-05 14:32:50,037 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5029845118522644, 'Total loss': 0.5029845118522644} | train loss {'Reaction outcome loss': 0.2606593678950833, 'Total loss': 0.2606593678950833}
2023-01-05 14:32:50,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:50,038 INFO:     Epoch: 82
2023-01-05 14:32:52,059 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4813305616378784, 'Total loss': 0.4813305616378784} | train loss {'Reaction outcome loss': 0.2593237208874916, 'Total loss': 0.2593237208874916}
2023-01-05 14:32:52,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:52,059 INFO:     Epoch: 83
2023-01-05 14:32:53,811 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4990719695885976, 'Total loss': 0.4990719695885976} | train loss {'Reaction outcome loss': 0.2571595452107247, 'Total loss': 0.2571595452107247}
2023-01-05 14:32:53,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:53,811 INFO:     Epoch: 84
2023-01-05 14:32:55,554 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49168811142444613, 'Total loss': 0.49168811142444613} | train loss {'Reaction outcome loss': 0.261750568161695, 'Total loss': 0.261750568161695}
2023-01-05 14:32:55,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:55,554 INFO:     Epoch: 85
2023-01-05 14:32:57,683 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5058599422375362, 'Total loss': 0.5058599422375362} | train loss {'Reaction outcome loss': 0.25373584807376354, 'Total loss': 0.25373584807376354}
2023-01-05 14:32:57,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:57,683 INFO:     Epoch: 86
2023-01-05 14:32:59,854 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.502019631365935, 'Total loss': 0.502019631365935} | train loss {'Reaction outcome loss': 0.2525491415378419, 'Total loss': 0.2525491415378419}
2023-01-05 14:32:59,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:32:59,855 INFO:     Epoch: 87
2023-01-05 14:33:02,003 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49485195279121397, 'Total loss': 0.49485195279121397} | train loss {'Reaction outcome loss': 0.2527531055726837, 'Total loss': 0.2527531055726837}
2023-01-05 14:33:02,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:02,004 INFO:     Epoch: 88
2023-01-05 14:33:04,148 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47558841506640115, 'Total loss': 0.47558841506640115} | train loss {'Reaction outcome loss': 0.2582804492846239, 'Total loss': 0.2582804492846239}
2023-01-05 14:33:04,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:04,148 INFO:     Epoch: 89
2023-01-05 14:33:06,289 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4581577623883883, 'Total loss': 0.4581577623883883} | train loss {'Reaction outcome loss': 0.25205243975999986, 'Total loss': 0.25205243975999986}
2023-01-05 14:33:06,290 INFO:     Found new best model at epoch 89
2023-01-05 14:33:06,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:06,291 INFO:     Epoch: 90
2023-01-05 14:33:08,408 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5339383582274119, 'Total loss': 0.5339383582274119} | train loss {'Reaction outcome loss': 0.25443540940511744, 'Total loss': 0.25443540940511744}
2023-01-05 14:33:08,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:08,409 INFO:     Epoch: 91
2023-01-05 14:33:10,555 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5073412537574769, 'Total loss': 0.5073412537574769} | train loss {'Reaction outcome loss': 0.2519115961092904, 'Total loss': 0.2519115961092904}
2023-01-05 14:33:10,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:10,556 INFO:     Epoch: 92
2023-01-05 14:33:12,697 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49896496534347534, 'Total loss': 0.49896496534347534} | train loss {'Reaction outcome loss': 0.25219109740498263, 'Total loss': 0.25219109740498263}
2023-01-05 14:33:12,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:12,698 INFO:     Epoch: 93
2023-01-05 14:33:14,829 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5131800492604573, 'Total loss': 0.5131800492604573} | train loss {'Reaction outcome loss': 0.25193924571148757, 'Total loss': 0.25193924571148757}
2023-01-05 14:33:14,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:14,829 INFO:     Epoch: 94
2023-01-05 14:33:16,992 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5058029373486836, 'Total loss': 0.5058029373486836} | train loss {'Reaction outcome loss': 0.2517606075785866, 'Total loss': 0.2517606075785866}
2023-01-05 14:33:16,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:16,993 INFO:     Epoch: 95
2023-01-05 14:33:19,133 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49609565958380697, 'Total loss': 0.49609565958380697} | train loss {'Reaction outcome loss': 0.24561265000017757, 'Total loss': 0.24561265000017757}
2023-01-05 14:33:19,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:19,134 INFO:     Epoch: 96
2023-01-05 14:33:21,291 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49344824254512787, 'Total loss': 0.49344824254512787} | train loss {'Reaction outcome loss': 0.2541935135768424, 'Total loss': 0.2541935135768424}
2023-01-05 14:33:21,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:21,291 INFO:     Epoch: 97
2023-01-05 14:33:23,441 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5457779238621394, 'Total loss': 0.5457779238621394} | train loss {'Reaction outcome loss': 0.25239524597618124, 'Total loss': 0.25239524597618124}
2023-01-05 14:33:23,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:23,442 INFO:     Epoch: 98
2023-01-05 14:33:25,604 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5247413873672485, 'Total loss': 0.5247413873672485} | train loss {'Reaction outcome loss': 0.24603556338630428, 'Total loss': 0.24603556338630428}
2023-01-05 14:33:25,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:25,604 INFO:     Epoch: 99
2023-01-05 14:33:27,754 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5538926343123118, 'Total loss': 0.5538926343123118} | train loss {'Reaction outcome loss': 0.24070220768102024, 'Total loss': 0.24070220768102024}
2023-01-05 14:33:27,754 INFO:     Best model found after epoch 90 of 100.
2023-01-05 14:33:27,755 INFO:   Done with stage: TRAINING
2023-01-05 14:33:27,755 INFO:   Starting stage: EVALUATION
2023-01-05 14:33:27,880 INFO:   Done with stage: EVALUATION
2023-01-05 14:33:27,880 INFO:   Leaving out SEQ value Fold_5
2023-01-05 14:33:27,892 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 14:33:27,892 INFO:   Starting stage: FEATURE SCALING
2023-01-05 14:33:28,540 INFO:   Done with stage: FEATURE SCALING
2023-01-05 14:33:28,540 INFO:   Starting stage: SCALING TARGETS
2023-01-05 14:33:28,609 INFO:   Done with stage: SCALING TARGETS
2023-01-05 14:33:28,609 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:33:28,609 INFO:     No hyperparam tuning for this model
2023-01-05 14:33:28,609 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:33:28,609 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 14:33:28,610 INFO:     None feature selector for col prot
2023-01-05 14:33:28,610 INFO:     None feature selector for col prot
2023-01-05 14:33:28,610 INFO:     None feature selector for col prot
2023-01-05 14:33:28,611 INFO:     None feature selector for col chem
2023-01-05 14:33:28,611 INFO:     None feature selector for col chem
2023-01-05 14:33:28,611 INFO:     None feature selector for col chem
2023-01-05 14:33:28,611 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 14:33:28,611 INFO:   Starting stage: BUILD MODEL
2023-01-05 14:33:28,612 INFO:     Number of params in model 72901
2023-01-05 14:33:28,615 INFO:   Done with stage: BUILD MODEL
2023-01-05 14:33:28,615 INFO:   Starting stage: TRAINING
2023-01-05 14:33:28,672 INFO:     Val loss before train {'Reaction outcome loss': 0.8913258711496989, 'Total loss': 0.8913258711496989}
2023-01-05 14:33:28,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:28,672 INFO:     Epoch: 0
2023-01-05 14:33:30,807 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7280370910962423, 'Total loss': 0.7280370910962423} | train loss {'Reaction outcome loss': 0.9266756132836806, 'Total loss': 0.9266756132836806}
2023-01-05 14:33:30,807 INFO:     Found new best model at epoch 0
2023-01-05 14:33:30,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:30,808 INFO:     Epoch: 1
2023-01-05 14:33:32,956 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5397476593653361, 'Total loss': 0.5397476593653361} | train loss {'Reaction outcome loss': 0.7079339756862352, 'Total loss': 0.7079339756862352}
2023-01-05 14:33:32,956 INFO:     Found new best model at epoch 1
2023-01-05 14:33:32,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:32,957 INFO:     Epoch: 2
2023-01-05 14:33:35,111 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5148784021536509, 'Total loss': 0.5148784021536509} | train loss {'Reaction outcome loss': 0.5665818261325575, 'Total loss': 0.5665818261325575}
2023-01-05 14:33:35,111 INFO:     Found new best model at epoch 2
2023-01-05 14:33:35,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:35,113 INFO:     Epoch: 3
2023-01-05 14:33:37,263 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4777447561422984, 'Total loss': 0.4777447561422984} | train loss {'Reaction outcome loss': 0.5224938576079448, 'Total loss': 0.5224938576079448}
2023-01-05 14:33:37,265 INFO:     Found new best model at epoch 3
2023-01-05 14:33:37,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:37,266 INFO:     Epoch: 4
2023-01-05 14:33:39,406 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46850683689117434, 'Total loss': 0.46850683689117434} | train loss {'Reaction outcome loss': 0.5054236870487675, 'Total loss': 0.5054236870487675}
2023-01-05 14:33:39,406 INFO:     Found new best model at epoch 4
2023-01-05 14:33:39,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:39,407 INFO:     Epoch: 5
2023-01-05 14:33:41,568 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5416966021060944, 'Total loss': 0.5416966021060944} | train loss {'Reaction outcome loss': 0.49897897695376126, 'Total loss': 0.49897897695376126}
2023-01-05 14:33:41,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:41,568 INFO:     Epoch: 6
2023-01-05 14:33:43,700 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49727954566478727, 'Total loss': 0.49727954566478727} | train loss {'Reaction outcome loss': 0.4873929205031171, 'Total loss': 0.4873929205031171}
2023-01-05 14:33:43,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:43,701 INFO:     Epoch: 7
2023-01-05 14:33:45,845 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47634875774383545, 'Total loss': 0.47634875774383545} | train loss {'Reaction outcome loss': 0.47554880789471016, 'Total loss': 0.47554880789471016}
2023-01-05 14:33:45,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:45,845 INFO:     Epoch: 8
2023-01-05 14:33:48,002 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47856099208196007, 'Total loss': 0.47856099208196007} | train loss {'Reaction outcome loss': 0.4769595405792932, 'Total loss': 0.4769595405792932}
2023-01-05 14:33:48,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:48,003 INFO:     Epoch: 9
2023-01-05 14:33:50,156 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49230685432751975, 'Total loss': 0.49230685432751975} | train loss {'Reaction outcome loss': 0.459650276047228, 'Total loss': 0.459650276047228}
2023-01-05 14:33:50,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:50,156 INFO:     Epoch: 10
2023-01-05 14:33:52,305 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45786194105943046, 'Total loss': 0.45786194105943046} | train loss {'Reaction outcome loss': 0.4592221417205428, 'Total loss': 0.4592221417205428}
2023-01-05 14:33:52,305 INFO:     Found new best model at epoch 10
2023-01-05 14:33:52,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:52,306 INFO:     Epoch: 11
2023-01-05 14:33:54,441 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46712672809759775, 'Total loss': 0.46712672809759775} | train loss {'Reaction outcome loss': 0.44885335502211365, 'Total loss': 0.44885335502211365}
2023-01-05 14:33:54,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:54,441 INFO:     Epoch: 12
2023-01-05 14:33:56,595 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4789024392763774, 'Total loss': 0.4789024392763774} | train loss {'Reaction outcome loss': 0.45252684027709683, 'Total loss': 0.45252684027709683}
2023-01-05 14:33:56,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:56,596 INFO:     Epoch: 13
2023-01-05 14:33:58,741 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44584489862124127, 'Total loss': 0.44584489862124127} | train loss {'Reaction outcome loss': 0.4435828513993683, 'Total loss': 0.4435828513993683}
2023-01-05 14:33:58,741 INFO:     Found new best model at epoch 13
2023-01-05 14:33:58,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:33:58,742 INFO:     Epoch: 14
2023-01-05 14:34:00,894 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4486324797074, 'Total loss': 0.4486324797074} | train loss {'Reaction outcome loss': 0.44046883954790955, 'Total loss': 0.44046883954790955}
2023-01-05 14:34:00,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:00,894 INFO:     Epoch: 15
2023-01-05 14:34:03,042 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43166239857673644, 'Total loss': 0.43166239857673644} | train loss {'Reaction outcome loss': 0.43430251501742684, 'Total loss': 0.43430251501742684}
2023-01-05 14:34:03,042 INFO:     Found new best model at epoch 15
2023-01-05 14:34:03,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:03,043 INFO:     Epoch: 16
2023-01-05 14:34:05,185 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4428669859965642, 'Total loss': 0.4428669859965642} | train loss {'Reaction outcome loss': 0.4290042265119966, 'Total loss': 0.4290042265119966}
2023-01-05 14:34:05,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:05,186 INFO:     Epoch: 17
2023-01-05 14:34:07,129 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45342880189418794, 'Total loss': 0.45342880189418794} | train loss {'Reaction outcome loss': 0.4250552369691835, 'Total loss': 0.4250552369691835}
2023-01-05 14:34:07,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:07,129 INFO:     Epoch: 18
2023-01-05 14:34:09,302 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4432181398073832, 'Total loss': 0.4432181398073832} | train loss {'Reaction outcome loss': 0.4163615538163736, 'Total loss': 0.4163615538163736}
2023-01-05 14:34:09,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:09,303 INFO:     Epoch: 19
2023-01-05 14:34:11,467 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4358585606018702, 'Total loss': 0.4358585606018702} | train loss {'Reaction outcome loss': 0.41699902686401397, 'Total loss': 0.41699902686401397}
2023-01-05 14:34:11,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:11,468 INFO:     Epoch: 20
2023-01-05 14:34:13,630 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4690724104642868, 'Total loss': 0.4690724104642868} | train loss {'Reaction outcome loss': 0.41579551962523686, 'Total loss': 0.41579551962523686}
2023-01-05 14:34:13,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:13,630 INFO:     Epoch: 21
2023-01-05 14:34:15,792 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4205021172761917, 'Total loss': 0.4205021172761917} | train loss {'Reaction outcome loss': 0.4092358022605469, 'Total loss': 0.4092358022605469}
2023-01-05 14:34:15,792 INFO:     Found new best model at epoch 21
2023-01-05 14:34:15,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:15,793 INFO:     Epoch: 22
2023-01-05 14:34:17,919 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4432188441356023, 'Total loss': 0.4432188441356023} | train loss {'Reaction outcome loss': 0.40795659787603233, 'Total loss': 0.40795659787603233}
2023-01-05 14:34:17,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:17,920 INFO:     Epoch: 23
2023-01-05 14:34:20,064 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4476527839899063, 'Total loss': 0.4476527839899063} | train loss {'Reaction outcome loss': 0.3990201089894298, 'Total loss': 0.3990201089894298}
2023-01-05 14:34:20,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:20,064 INFO:     Epoch: 24
2023-01-05 14:34:22,209 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4303072363138199, 'Total loss': 0.4303072363138199} | train loss {'Reaction outcome loss': 0.4011896885259057, 'Total loss': 0.4011896885259057}
2023-01-05 14:34:22,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:22,209 INFO:     Epoch: 25
2023-01-05 14:34:24,333 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4941884458065033, 'Total loss': 0.4941884458065033} | train loss {'Reaction outcome loss': 0.39181731479908155, 'Total loss': 0.39181731479908155}
2023-01-05 14:34:24,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:24,334 INFO:     Epoch: 26
2023-01-05 14:34:26,476 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4522879938284556, 'Total loss': 0.4522879938284556} | train loss {'Reaction outcome loss': 0.38723905174740814, 'Total loss': 0.38723905174740814}
2023-01-05 14:34:26,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:26,476 INFO:     Epoch: 27
2023-01-05 14:34:28,599 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46478155652681985, 'Total loss': 0.46478155652681985} | train loss {'Reaction outcome loss': 0.3843919377545372, 'Total loss': 0.3843919377545372}
2023-01-05 14:34:28,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:28,600 INFO:     Epoch: 28
2023-01-05 14:34:30,735 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43846237361431123, 'Total loss': 0.43846237361431123} | train loss {'Reaction outcome loss': 0.38338611982359355, 'Total loss': 0.38338611982359355}
2023-01-05 14:34:30,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:30,736 INFO:     Epoch: 29
2023-01-05 14:34:32,882 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43753253618876137, 'Total loss': 0.43753253618876137} | train loss {'Reaction outcome loss': 0.38057589972062233, 'Total loss': 0.38057589972062233}
2023-01-05 14:34:32,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:32,882 INFO:     Epoch: 30
2023-01-05 14:34:35,023 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42794037982821465, 'Total loss': 0.42794037982821465} | train loss {'Reaction outcome loss': 0.36992838153017127, 'Total loss': 0.36992838153017127}
2023-01-05 14:34:35,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:35,024 INFO:     Epoch: 31
2023-01-05 14:34:37,178 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4077053080002467, 'Total loss': 0.4077053080002467} | train loss {'Reaction outcome loss': 0.3744957442748417, 'Total loss': 0.3744957442748417}
2023-01-05 14:34:37,178 INFO:     Found new best model at epoch 31
2023-01-05 14:34:37,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:37,180 INFO:     Epoch: 32
2023-01-05 14:34:39,313 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4169732550779978, 'Total loss': 0.4169732550779978} | train loss {'Reaction outcome loss': 0.36965436383490097, 'Total loss': 0.36965436383490097}
2023-01-05 14:34:39,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:39,314 INFO:     Epoch: 33
2023-01-05 14:34:41,484 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4429813861846924, 'Total loss': 0.4429813861846924} | train loss {'Reaction outcome loss': 0.36453880336041483, 'Total loss': 0.36453880336041483}
2023-01-05 14:34:41,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:41,484 INFO:     Epoch: 34
2023-01-05 14:34:43,748 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4284258375565211, 'Total loss': 0.4284258375565211} | train loss {'Reaction outcome loss': 0.36230055011459206, 'Total loss': 0.36230055011459206}
2023-01-05 14:34:43,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:43,749 INFO:     Epoch: 35
2023-01-05 14:34:45,889 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43140929043292997, 'Total loss': 0.43140929043292997} | train loss {'Reaction outcome loss': 0.36042147148602277, 'Total loss': 0.36042147148602277}
2023-01-05 14:34:45,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:45,889 INFO:     Epoch: 36
2023-01-05 14:34:48,035 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4448752075433731, 'Total loss': 0.4448752075433731} | train loss {'Reaction outcome loss': 0.35704988956666595, 'Total loss': 0.35704988956666595}
2023-01-05 14:34:48,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:48,036 INFO:     Epoch: 37
2023-01-05 14:34:50,213 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42298027575016023, 'Total loss': 0.42298027575016023} | train loss {'Reaction outcome loss': 0.3487791805275941, 'Total loss': 0.3487791805275941}
2023-01-05 14:34:50,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:50,214 INFO:     Epoch: 38
2023-01-05 14:34:52,370 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44432272215684254, 'Total loss': 0.44432272215684254} | train loss {'Reaction outcome loss': 0.345723708398936, 'Total loss': 0.345723708398936}
2023-01-05 14:34:52,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:52,370 INFO:     Epoch: 39
2023-01-05 14:34:54,506 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.440562625726064, 'Total loss': 0.440562625726064} | train loss {'Reaction outcome loss': 0.3454284033190042, 'Total loss': 0.3454284033190042}
2023-01-05 14:34:54,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:54,507 INFO:     Epoch: 40
2023-01-05 14:34:56,634 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43157720963160195, 'Total loss': 0.43157720963160195} | train loss {'Reaction outcome loss': 0.34297003691162015, 'Total loss': 0.34297003691162015}
2023-01-05 14:34:56,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:56,635 INFO:     Epoch: 41
2023-01-05 14:34:58,806 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43691714803377785, 'Total loss': 0.43691714803377785} | train loss {'Reaction outcome loss': 0.3379521191873275, 'Total loss': 0.3379521191873275}
2023-01-05 14:34:58,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:34:58,806 INFO:     Epoch: 42
2023-01-05 14:35:00,944 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41033568779627483, 'Total loss': 0.41033568779627483} | train loss {'Reaction outcome loss': 0.33805372072417383, 'Total loss': 0.33805372072417383}
2023-01-05 14:35:00,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:00,944 INFO:     Epoch: 43
2023-01-05 14:35:03,087 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4280976434548696, 'Total loss': 0.4280976434548696} | train loss {'Reaction outcome loss': 0.33192085816326555, 'Total loss': 0.33192085816326555}
2023-01-05 14:35:03,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:03,087 INFO:     Epoch: 44
2023-01-05 14:35:05,239 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40985957384109495, 'Total loss': 0.40985957384109495} | train loss {'Reaction outcome loss': 0.32780263884941163, 'Total loss': 0.32780263884941163}
2023-01-05 14:35:05,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:05,239 INFO:     Epoch: 45
2023-01-05 14:35:07,365 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42965565125147503, 'Total loss': 0.42965565125147503} | train loss {'Reaction outcome loss': 0.3253595805071321, 'Total loss': 0.3253595805071321}
2023-01-05 14:35:07,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:07,366 INFO:     Epoch: 46
2023-01-05 14:35:09,503 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44940725664297737, 'Total loss': 0.44940725664297737} | train loss {'Reaction outcome loss': 0.32426971834596746, 'Total loss': 0.32426971834596746}
2023-01-05 14:35:09,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:09,504 INFO:     Epoch: 47
2023-01-05 14:35:11,651 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40841725865999856, 'Total loss': 0.40841725865999856} | train loss {'Reaction outcome loss': 0.3198312705497019, 'Total loss': 0.3198312705497019}
2023-01-05 14:35:11,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:11,652 INFO:     Epoch: 48
2023-01-05 14:35:13,774 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4013019522031148, 'Total loss': 0.4013019522031148} | train loss {'Reaction outcome loss': 0.31489602215453605, 'Total loss': 0.31489602215453605}
2023-01-05 14:35:13,774 INFO:     Found new best model at epoch 48
2023-01-05 14:35:13,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:13,775 INFO:     Epoch: 49
2023-01-05 14:35:15,895 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3901508351167043, 'Total loss': 0.3901508351167043} | train loss {'Reaction outcome loss': 0.3185837195130462, 'Total loss': 0.3185837195130462}
2023-01-05 14:35:15,895 INFO:     Found new best model at epoch 49
2023-01-05 14:35:15,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:15,896 INFO:     Epoch: 50
2023-01-05 14:35:18,043 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38108430008093513, 'Total loss': 0.38108430008093513} | train loss {'Reaction outcome loss': 0.3106261701037307, 'Total loss': 0.3106261701037307}
2023-01-05 14:35:18,044 INFO:     Found new best model at epoch 50
2023-01-05 14:35:18,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:18,045 INFO:     Epoch: 51
2023-01-05 14:35:20,181 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4196377664804459, 'Total loss': 0.4196377664804459} | train loss {'Reaction outcome loss': 0.3110576597200404, 'Total loss': 0.3110576597200404}
2023-01-05 14:35:20,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:20,182 INFO:     Epoch: 52
2023-01-05 14:35:22,313 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41489766736825306, 'Total loss': 0.41489766736825306} | train loss {'Reaction outcome loss': 0.3028909894318357, 'Total loss': 0.3028909894318357}
2023-01-05 14:35:22,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:22,313 INFO:     Epoch: 53
2023-01-05 14:35:24,452 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3927674581607183, 'Total loss': 0.3927674581607183} | train loss {'Reaction outcome loss': 0.30615232791415403, 'Total loss': 0.30615232791415403}
2023-01-05 14:35:24,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:24,453 INFO:     Epoch: 54
2023-01-05 14:35:26,584 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37412545680999754, 'Total loss': 0.37412545680999754} | train loss {'Reaction outcome loss': 0.30373844004064693, 'Total loss': 0.30373844004064693}
2023-01-05 14:35:26,584 INFO:     Found new best model at epoch 54
2023-01-05 14:35:26,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:26,586 INFO:     Epoch: 55
2023-01-05 14:35:28,735 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39024049242337544, 'Total loss': 0.39024049242337544} | train loss {'Reaction outcome loss': 0.3034569429307638, 'Total loss': 0.3034569429307638}
2023-01-05 14:35:28,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:28,736 INFO:     Epoch: 56
2023-01-05 14:35:30,883 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40080587764581044, 'Total loss': 0.40080587764581044} | train loss {'Reaction outcome loss': 0.2997441111596483, 'Total loss': 0.2997441111596483}
2023-01-05 14:35:30,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:30,884 INFO:     Epoch: 57
2023-01-05 14:35:33,021 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39329239130020144, 'Total loss': 0.39329239130020144} | train loss {'Reaction outcome loss': 0.29261014048373224, 'Total loss': 0.29261014048373224}
2023-01-05 14:35:33,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:33,021 INFO:     Epoch: 58
2023-01-05 14:35:35,173 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40727882186571757, 'Total loss': 0.40727882186571757} | train loss {'Reaction outcome loss': 0.2902675228805318, 'Total loss': 0.2902675228805318}
2023-01-05 14:35:35,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:35,174 INFO:     Epoch: 59
2023-01-05 14:35:37,312 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4130558600028356, 'Total loss': 0.4130558600028356} | train loss {'Reaction outcome loss': 0.2910282811829114, 'Total loss': 0.2910282811829114}
2023-01-05 14:35:37,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:37,312 INFO:     Epoch: 60
2023-01-05 14:35:39,443 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36129214068253834, 'Total loss': 0.36129214068253834} | train loss {'Reaction outcome loss': 0.2844551073568823, 'Total loss': 0.2844551073568823}
2023-01-05 14:35:39,443 INFO:     Found new best model at epoch 60
2023-01-05 14:35:39,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:39,444 INFO:     Epoch: 61
2023-01-05 14:35:41,232 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4309241364399592, 'Total loss': 0.4309241364399592} | train loss {'Reaction outcome loss': 0.29223815468728326, 'Total loss': 0.29223815468728326}
2023-01-05 14:35:41,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:41,232 INFO:     Epoch: 62
2023-01-05 14:35:43,012 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41515957911809287, 'Total loss': 0.41515957911809287} | train loss {'Reaction outcome loss': 0.2926758513298383, 'Total loss': 0.2926758513298383}
2023-01-05 14:35:43,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:43,013 INFO:     Epoch: 63
2023-01-05 14:35:45,011 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40686500271161397, 'Total loss': 0.40686500271161397} | train loss {'Reaction outcome loss': 0.2876903190939865, 'Total loss': 0.2876903190939865}
2023-01-05 14:35:45,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:45,011 INFO:     Epoch: 64
2023-01-05 14:35:47,174 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40331539511680603, 'Total loss': 0.40331539511680603} | train loss {'Reaction outcome loss': 0.2808352144374529, 'Total loss': 0.2808352144374529}
2023-01-05 14:35:47,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:47,175 INFO:     Epoch: 65
2023-01-05 14:35:49,305 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43256794214248656, 'Total loss': 0.43256794214248656} | train loss {'Reaction outcome loss': 0.28249427103286184, 'Total loss': 0.28249427103286184}
2023-01-05 14:35:49,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:49,305 INFO:     Epoch: 66
2023-01-05 14:35:51,425 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4845710188150406, 'Total loss': 0.4845710188150406} | train loss {'Reaction outcome loss': 0.285507840141385, 'Total loss': 0.285507840141385}
2023-01-05 14:35:51,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:51,426 INFO:     Epoch: 67
2023-01-05 14:35:53,550 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38022105395793915, 'Total loss': 0.38022105395793915} | train loss {'Reaction outcome loss': 0.27518387508682823, 'Total loss': 0.27518387508682823}
2023-01-05 14:35:53,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:53,551 INFO:     Epoch: 68
2023-01-05 14:35:55,688 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40491110483805337, 'Total loss': 0.40491110483805337} | train loss {'Reaction outcome loss': 0.2772231623664875, 'Total loss': 0.2772231623664875}
2023-01-05 14:35:55,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:55,688 INFO:     Epoch: 69
2023-01-05 14:35:57,824 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3912834992011388, 'Total loss': 0.3912834992011388} | train loss {'Reaction outcome loss': 0.27189494926307606, 'Total loss': 0.27189494926307606}
2023-01-05 14:35:57,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:57,824 INFO:     Epoch: 70
2023-01-05 14:35:59,994 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4301703910032908, 'Total loss': 0.4301703910032908} | train loss {'Reaction outcome loss': 0.2761645745351534, 'Total loss': 0.2761645745351534}
2023-01-05 14:35:59,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:35:59,995 INFO:     Epoch: 71
2023-01-05 14:36:02,136 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38281268924474715, 'Total loss': 0.38281268924474715} | train loss {'Reaction outcome loss': 0.2716330702783076, 'Total loss': 0.2716330702783076}
2023-01-05 14:36:02,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:02,136 INFO:     Epoch: 72
2023-01-05 14:36:04,295 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4060965319474538, 'Total loss': 0.4060965319474538} | train loss {'Reaction outcome loss': 0.26792592497455087, 'Total loss': 0.26792592497455087}
2023-01-05 14:36:04,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:04,295 INFO:     Epoch: 73
2023-01-05 14:36:06,426 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47321058114369713, 'Total loss': 0.47321058114369713} | train loss {'Reaction outcome loss': 0.268012544012457, 'Total loss': 0.268012544012457}
2023-01-05 14:36:06,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:06,426 INFO:     Epoch: 74
2023-01-05 14:36:08,552 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.395025576154391, 'Total loss': 0.395025576154391} | train loss {'Reaction outcome loss': 0.2683374799169358, 'Total loss': 0.2683374799169358}
2023-01-05 14:36:08,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:08,552 INFO:     Epoch: 75
2023-01-05 14:36:10,706 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39747796033819516, 'Total loss': 0.39747796033819516} | train loss {'Reaction outcome loss': 0.2641619469714939, 'Total loss': 0.2641619469714939}
2023-01-05 14:36:10,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:10,706 INFO:     Epoch: 76
2023-01-05 14:36:12,845 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38016230712334315, 'Total loss': 0.38016230712334315} | train loss {'Reaction outcome loss': 0.26333343626305944, 'Total loss': 0.26333343626305944}
2023-01-05 14:36:12,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:12,846 INFO:     Epoch: 77
2023-01-05 14:36:14,992 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40329315066337584, 'Total loss': 0.40329315066337584} | train loss {'Reaction outcome loss': 0.2634709857484924, 'Total loss': 0.2634709857484924}
2023-01-05 14:36:14,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:14,992 INFO:     Epoch: 78
2023-01-05 14:36:17,132 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40005592405796053, 'Total loss': 0.40005592405796053} | train loss {'Reaction outcome loss': 0.26243799946368385, 'Total loss': 0.26243799946368385}
2023-01-05 14:36:17,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:17,132 INFO:     Epoch: 79
2023-01-05 14:36:19,270 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3923906912406286, 'Total loss': 0.3923906912406286} | train loss {'Reaction outcome loss': 0.26328265040252186, 'Total loss': 0.26328265040252186}
2023-01-05 14:36:19,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:19,270 INFO:     Epoch: 80
2023-01-05 14:36:21,433 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3978917876879374, 'Total loss': 0.3978917876879374} | train loss {'Reaction outcome loss': 0.25590511484387657, 'Total loss': 0.25590511484387657}
2023-01-05 14:36:21,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:21,434 INFO:     Epoch: 81
2023-01-05 14:36:23,565 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.35899569988250735, 'Total loss': 0.35899569988250735} | train loss {'Reaction outcome loss': 0.25722532368362594, 'Total loss': 0.25722532368362594}
2023-01-05 14:36:23,565 INFO:     Found new best model at epoch 81
2023-01-05 14:36:23,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:23,567 INFO:     Epoch: 82
2023-01-05 14:36:25,716 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3950336883465449, 'Total loss': 0.3950336883465449} | train loss {'Reaction outcome loss': 0.26007255524504486, 'Total loss': 0.26007255524504486}
2023-01-05 14:36:25,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:25,717 INFO:     Epoch: 83
2023-01-05 14:36:27,860 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37002708911895754, 'Total loss': 0.37002708911895754} | train loss {'Reaction outcome loss': 0.2627010064650098, 'Total loss': 0.2627010064650098}
2023-01-05 14:36:27,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:27,860 INFO:     Epoch: 84
2023-01-05 14:36:30,020 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4344735160470009, 'Total loss': 0.4344735160470009} | train loss {'Reaction outcome loss': 0.2572406625597055, 'Total loss': 0.2572406625597055}
2023-01-05 14:36:30,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:30,021 INFO:     Epoch: 85
2023-01-05 14:36:32,187 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39000304043293, 'Total loss': 0.39000304043293} | train loss {'Reaction outcome loss': 0.24360135603790248, 'Total loss': 0.24360135603790248}
2023-01-05 14:36:32,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:32,187 INFO:     Epoch: 86
2023-01-05 14:36:34,329 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40189730475346247, 'Total loss': 0.40189730475346247} | train loss {'Reaction outcome loss': 0.25061842480452484, 'Total loss': 0.25061842480452484}
2023-01-05 14:36:34,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:34,330 INFO:     Epoch: 87
2023-01-05 14:36:36,493 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.36293518245220185, 'Total loss': 0.36293518245220185} | train loss {'Reaction outcome loss': 0.2518386926219567, 'Total loss': 0.2518386926219567}
2023-01-05 14:36:36,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:36,494 INFO:     Epoch: 88
2023-01-05 14:36:38,655 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3817191332578659, 'Total loss': 0.3817191332578659} | train loss {'Reaction outcome loss': 0.2554354600151093, 'Total loss': 0.2554354600151093}
2023-01-05 14:36:38,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:38,655 INFO:     Epoch: 89
2023-01-05 14:36:40,821 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40074149270852405, 'Total loss': 0.40074149270852405} | train loss {'Reaction outcome loss': 0.24527973162568434, 'Total loss': 0.24527973162568434}
2023-01-05 14:36:40,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:40,821 INFO:     Epoch: 90
2023-01-05 14:36:42,968 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.36710277398427327, 'Total loss': 0.36710277398427327} | train loss {'Reaction outcome loss': 0.24726306298740935, 'Total loss': 0.24726306298740935}
2023-01-05 14:36:42,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:42,968 INFO:     Epoch: 91
2023-01-05 14:36:45,127 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3726925904552142, 'Total loss': 0.3726925904552142} | train loss {'Reaction outcome loss': 0.24402857052720411, 'Total loss': 0.24402857052720411}
2023-01-05 14:36:45,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:45,127 INFO:     Epoch: 92
2023-01-05 14:36:47,275 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3699185738960902, 'Total loss': 0.3699185738960902} | train loss {'Reaction outcome loss': 0.254776590997992, 'Total loss': 0.254776590997992}
2023-01-05 14:36:47,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:47,275 INFO:     Epoch: 93
2023-01-05 14:36:49,426 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4052018567919731, 'Total loss': 0.4052018567919731} | train loss {'Reaction outcome loss': 0.24357942787305004, 'Total loss': 0.24357942787305004}
2023-01-05 14:36:49,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:49,427 INFO:     Epoch: 94
2023-01-05 14:36:51,572 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42080764671166737, 'Total loss': 0.42080764671166737} | train loss {'Reaction outcome loss': 0.245116800338783, 'Total loss': 0.245116800338783}
2023-01-05 14:36:51,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:51,572 INFO:     Epoch: 95
2023-01-05 14:36:53,716 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41306811074415845, 'Total loss': 0.41306811074415845} | train loss {'Reaction outcome loss': 0.24632403201386602, 'Total loss': 0.24632403201386602}
2023-01-05 14:36:53,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:53,716 INFO:     Epoch: 96
2023-01-05 14:36:55,850 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3721561759710312, 'Total loss': 0.3721561759710312} | train loss {'Reaction outcome loss': 0.24106210854160012, 'Total loss': 0.24106210854160012}
2023-01-05 14:36:55,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:55,850 INFO:     Epoch: 97
2023-01-05 14:36:58,001 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3740786200389266, 'Total loss': 0.3740786200389266} | train loss {'Reaction outcome loss': 0.241766830677644, 'Total loss': 0.241766830677644}
2023-01-05 14:36:58,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:36:58,001 INFO:     Epoch: 98
2023-01-05 14:37:00,140 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.38361237992842995, 'Total loss': 0.38361237992842995} | train loss {'Reaction outcome loss': 0.23545947134333398, 'Total loss': 0.23545947134333398}
2023-01-05 14:37:00,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:00,140 INFO:     Epoch: 99
2023-01-05 14:37:02,289 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.35048255771398545, 'Total loss': 0.35048255771398545} | train loss {'Reaction outcome loss': 0.23767850868780474, 'Total loss': 0.23767850868780474}
2023-01-05 14:37:02,289 INFO:     Found new best model at epoch 99
2023-01-05 14:37:02,290 INFO:     Best model found after epoch 100 of 100.
2023-01-05 14:37:02,291 INFO:   Done with stage: TRAINING
2023-01-05 14:37:02,291 INFO:   Starting stage: EVALUATION
2023-01-05 14:37:02,418 INFO:   Done with stage: EVALUATION
2023-01-05 14:37:02,418 INFO:   Leaving out SEQ value Fold_6
2023-01-05 14:37:02,430 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 14:37:02,430 INFO:   Starting stage: FEATURE SCALING
2023-01-05 14:37:03,083 INFO:   Done with stage: FEATURE SCALING
2023-01-05 14:37:03,083 INFO:   Starting stage: SCALING TARGETS
2023-01-05 14:37:03,152 INFO:   Done with stage: SCALING TARGETS
2023-01-05 14:37:03,153 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:37:03,153 INFO:     No hyperparam tuning for this model
2023-01-05 14:37:03,153 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:37:03,153 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 14:37:03,153 INFO:     None feature selector for col prot
2023-01-05 14:37:03,154 INFO:     None feature selector for col prot
2023-01-05 14:37:03,154 INFO:     None feature selector for col prot
2023-01-05 14:37:03,154 INFO:     None feature selector for col chem
2023-01-05 14:37:03,154 INFO:     None feature selector for col chem
2023-01-05 14:37:03,154 INFO:     None feature selector for col chem
2023-01-05 14:37:03,154 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 14:37:03,154 INFO:   Starting stage: BUILD MODEL
2023-01-05 14:37:03,156 INFO:     Number of params in model 72901
2023-01-05 14:37:03,159 INFO:   Done with stage: BUILD MODEL
2023-01-05 14:37:03,159 INFO:   Starting stage: TRAINING
2023-01-05 14:37:03,217 INFO:     Val loss before train {'Reaction outcome loss': 0.9438640991846721, 'Total loss': 0.9438640991846721}
2023-01-05 14:37:03,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:03,218 INFO:     Epoch: 0
2023-01-05 14:37:05,378 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7193995614846548, 'Total loss': 0.7193995614846548} | train loss {'Reaction outcome loss': 0.9350899063077645, 'Total loss': 0.9350899063077645}
2023-01-05 14:37:05,379 INFO:     Found new best model at epoch 0
2023-01-05 14:37:05,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:05,380 INFO:     Epoch: 1
2023-01-05 14:37:07,522 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6130366285641988, 'Total loss': 0.6130366285641988} | train loss {'Reaction outcome loss': 0.7671870136304022, 'Total loss': 0.7671870136304022}
2023-01-05 14:37:07,523 INFO:     Found new best model at epoch 1
2023-01-05 14:37:07,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:07,524 INFO:     Epoch: 2
2023-01-05 14:37:09,681 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5056993762652079, 'Total loss': 0.5056993762652079} | train loss {'Reaction outcome loss': 0.6035010967443997, 'Total loss': 0.6035010967443997}
2023-01-05 14:37:09,681 INFO:     Found new best model at epoch 2
2023-01-05 14:37:09,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:09,682 INFO:     Epoch: 3
2023-01-05 14:37:11,845 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5144107908010482, 'Total loss': 0.5144107908010482} | train loss {'Reaction outcome loss': 0.5400639183362038, 'Total loss': 0.5400639183362038}
2023-01-05 14:37:11,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:11,846 INFO:     Epoch: 4
2023-01-05 14:37:14,014 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49155047833919524, 'Total loss': 0.49155047833919524} | train loss {'Reaction outcome loss': 0.5180527802408817, 'Total loss': 0.5180527802408817}
2023-01-05 14:37:14,014 INFO:     Found new best model at epoch 4
2023-01-05 14:37:14,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:14,016 INFO:     Epoch: 5
2023-01-05 14:37:16,178 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4613134066263835, 'Total loss': 0.4613134066263835} | train loss {'Reaction outcome loss': 0.5021031661907258, 'Total loss': 0.5021031661907258}
2023-01-05 14:37:16,178 INFO:     Found new best model at epoch 5
2023-01-05 14:37:16,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:16,179 INFO:     Epoch: 6
2023-01-05 14:37:18,329 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4817160765329997, 'Total loss': 0.4817160765329997} | train loss {'Reaction outcome loss': 0.49180119896193275, 'Total loss': 0.49180119896193275}
2023-01-05 14:37:18,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:18,329 INFO:     Epoch: 7
2023-01-05 14:37:20,479 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4624730944633484, 'Total loss': 0.4624730944633484} | train loss {'Reaction outcome loss': 0.48029420979401694, 'Total loss': 0.48029420979401694}
2023-01-05 14:37:20,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:20,479 INFO:     Epoch: 8
2023-01-05 14:37:22,642 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47709196905295054, 'Total loss': 0.47709196905295054} | train loss {'Reaction outcome loss': 0.47744533285122054, 'Total loss': 0.47744533285122054}
2023-01-05 14:37:22,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:22,643 INFO:     Epoch: 9
2023-01-05 14:37:24,785 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45393238464991253, 'Total loss': 0.45393238464991253} | train loss {'Reaction outcome loss': 0.4734817512521675, 'Total loss': 0.4734817512521675}
2023-01-05 14:37:24,786 INFO:     Found new best model at epoch 9
2023-01-05 14:37:24,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:24,787 INFO:     Epoch: 10
2023-01-05 14:37:26,941 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.446744766831398, 'Total loss': 0.446744766831398} | train loss {'Reaction outcome loss': 0.46650241449851854, 'Total loss': 0.46650241449851854}
2023-01-05 14:37:26,941 INFO:     Found new best model at epoch 10
2023-01-05 14:37:26,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:26,942 INFO:     Epoch: 11
2023-01-05 14:37:29,101 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48142967025438943, 'Total loss': 0.48142967025438943} | train loss {'Reaction outcome loss': 0.4650074102065193, 'Total loss': 0.4650074102065193}
2023-01-05 14:37:29,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:29,101 INFO:     Epoch: 12
2023-01-05 14:37:31,241 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45547790030638374, 'Total loss': 0.45547790030638374} | train loss {'Reaction outcome loss': 0.4564129525950239, 'Total loss': 0.4564129525950239}
2023-01-05 14:37:31,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:31,241 INFO:     Epoch: 13
2023-01-05 14:37:33,385 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44105725884437563, 'Total loss': 0.44105725884437563} | train loss {'Reaction outcome loss': 0.45093937540958073, 'Total loss': 0.45093937540958073}
2023-01-05 14:37:33,385 INFO:     Found new best model at epoch 13
2023-01-05 14:37:33,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:33,386 INFO:     Epoch: 14
2023-01-05 14:37:35,533 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43892858624458314, 'Total loss': 0.43892858624458314} | train loss {'Reaction outcome loss': 0.4478577277505441, 'Total loss': 0.4478577277505441}
2023-01-05 14:37:35,534 INFO:     Found new best model at epoch 14
2023-01-05 14:37:35,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:35,535 INFO:     Epoch: 15
2023-01-05 14:37:37,693 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4304198463757833, 'Total loss': 0.4304198463757833} | train loss {'Reaction outcome loss': 0.44508016795350325, 'Total loss': 0.44508016795350325}
2023-01-05 14:37:37,694 INFO:     Found new best model at epoch 15
2023-01-05 14:37:37,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:37,695 INFO:     Epoch: 16
2023-01-05 14:37:39,858 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43735286394755046, 'Total loss': 0.43735286394755046} | train loss {'Reaction outcome loss': 0.44229789839432126, 'Total loss': 0.44229789839432126}
2023-01-05 14:37:39,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:39,858 INFO:     Epoch: 17
2023-01-05 14:37:41,995 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42991926670074465, 'Total loss': 0.42991926670074465} | train loss {'Reaction outcome loss': 0.4372075350975302, 'Total loss': 0.4372075350975302}
2023-01-05 14:37:41,995 INFO:     Found new best model at epoch 17
2023-01-05 14:37:41,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:41,997 INFO:     Epoch: 18
2023-01-05 14:37:44,171 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4360033889611562, 'Total loss': 0.4360033889611562} | train loss {'Reaction outcome loss': 0.43045277350215705, 'Total loss': 0.43045277350215705}
2023-01-05 14:37:44,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:44,172 INFO:     Epoch: 19
2023-01-05 14:37:46,324 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4299789726734161, 'Total loss': 0.4299789726734161} | train loss {'Reaction outcome loss': 0.42765337180359697, 'Total loss': 0.42765337180359697}
2023-01-05 14:37:46,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:46,324 INFO:     Epoch: 20
2023-01-05 14:37:48,477 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4171820804476738, 'Total loss': 0.4171820804476738} | train loss {'Reaction outcome loss': 0.4238087087062722, 'Total loss': 0.4238087087062722}
2023-01-05 14:37:48,477 INFO:     Found new best model at epoch 20
2023-01-05 14:37:48,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:48,478 INFO:     Epoch: 21
2023-01-05 14:37:50,625 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4318768799304962, 'Total loss': 0.4318768799304962} | train loss {'Reaction outcome loss': 0.4212508749095757, 'Total loss': 0.4212508749095757}
2023-01-05 14:37:50,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:50,625 INFO:     Epoch: 22
2023-01-05 14:37:52,774 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3996880362431208, 'Total loss': 0.3996880362431208} | train loss {'Reaction outcome loss': 0.42273180262061233, 'Total loss': 0.42273180262061233}
2023-01-05 14:37:52,774 INFO:     Found new best model at epoch 22
2023-01-05 14:37:52,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:52,775 INFO:     Epoch: 23
2023-01-05 14:37:54,918 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42725043892860415, 'Total loss': 0.42725043892860415} | train loss {'Reaction outcome loss': 0.4097839442185977, 'Total loss': 0.4097839442185977}
2023-01-05 14:37:54,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:54,918 INFO:     Epoch: 24
2023-01-05 14:37:57,069 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44470891455809275, 'Total loss': 0.44470891455809275} | train loss {'Reaction outcome loss': 0.409826533028365, 'Total loss': 0.409826533028365}
2023-01-05 14:37:57,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:57,070 INFO:     Epoch: 25
2023-01-05 14:37:59,228 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4071302185455958, 'Total loss': 0.4071302185455958} | train loss {'Reaction outcome loss': 0.40936398732102736, 'Total loss': 0.40936398732102736}
2023-01-05 14:37:59,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:37:59,229 INFO:     Epoch: 26
2023-01-05 14:38:01,391 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41866426716248195, 'Total loss': 0.41866426716248195} | train loss {'Reaction outcome loss': 0.4018368694379872, 'Total loss': 0.4018368694379872}
2023-01-05 14:38:01,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:01,392 INFO:     Epoch: 27
2023-01-05 14:38:03,537 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4030144115289052, 'Total loss': 0.4030144115289052} | train loss {'Reaction outcome loss': 0.395861684442212, 'Total loss': 0.395861684442212}
2023-01-05 14:38:03,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:03,537 INFO:     Epoch: 28
2023-01-05 14:38:05,642 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43633023699124657, 'Total loss': 0.43633023699124657} | train loss {'Reaction outcome loss': 0.3951500076464367, 'Total loss': 0.3951500076464367}
2023-01-05 14:38:05,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:05,642 INFO:     Epoch: 29
2023-01-05 14:38:07,777 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41878389318784076, 'Total loss': 0.41878389318784076} | train loss {'Reaction outcome loss': 0.39030877783195206, 'Total loss': 0.39030877783195206}
2023-01-05 14:38:07,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:07,778 INFO:     Epoch: 30
2023-01-05 14:38:09,752 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4042551428079605, 'Total loss': 0.4042551428079605} | train loss {'Reaction outcome loss': 0.38732519431127105, 'Total loss': 0.38732519431127105}
2023-01-05 14:38:09,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:09,753 INFO:     Epoch: 31
2023-01-05 14:38:11,911 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4425532112518946, 'Total loss': 0.4425532112518946} | train loss {'Reaction outcome loss': 0.38621648121288965, 'Total loss': 0.38621648121288965}
2023-01-05 14:38:11,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:11,911 INFO:     Epoch: 32
2023-01-05 14:38:14,062 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3899839222431183, 'Total loss': 0.3899839222431183} | train loss {'Reaction outcome loss': 0.3800257865057095, 'Total loss': 0.3800257865057095}
2023-01-05 14:38:14,063 INFO:     Found new best model at epoch 32
2023-01-05 14:38:14,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:14,064 INFO:     Epoch: 33
2023-01-05 14:38:16,213 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4038014883796374, 'Total loss': 0.4038014883796374} | train loss {'Reaction outcome loss': 0.37675657139465696, 'Total loss': 0.37675657139465696}
2023-01-05 14:38:16,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:16,214 INFO:     Epoch: 34
2023-01-05 14:38:18,361 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3846705287694931, 'Total loss': 0.3846705287694931} | train loss {'Reaction outcome loss': 0.37387479058994716, 'Total loss': 0.37387479058994716}
2023-01-05 14:38:18,362 INFO:     Found new best model at epoch 34
2023-01-05 14:38:18,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:18,363 INFO:     Epoch: 35
2023-01-05 14:38:20,521 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3876606851816177, 'Total loss': 0.3876606851816177} | train loss {'Reaction outcome loss': 0.37031062509501456, 'Total loss': 0.37031062509501456}
2023-01-05 14:38:20,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:20,521 INFO:     Epoch: 36
2023-01-05 14:38:22,677 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3744108060995738, 'Total loss': 0.3744108060995738} | train loss {'Reaction outcome loss': 0.3730234085491418, 'Total loss': 0.3730234085491418}
2023-01-05 14:38:22,677 INFO:     Found new best model at epoch 36
2023-01-05 14:38:22,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:22,679 INFO:     Epoch: 37
2023-01-05 14:38:24,813 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3769400676091512, 'Total loss': 0.3769400676091512} | train loss {'Reaction outcome loss': 0.3700343632418326, 'Total loss': 0.3700343632418326}
2023-01-05 14:38:24,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:24,813 INFO:     Epoch: 38
2023-01-05 14:38:26,975 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.35855336536963783, 'Total loss': 0.35855336536963783} | train loss {'Reaction outcome loss': 0.3579928582594713, 'Total loss': 0.3579928582594713}
2023-01-05 14:38:26,976 INFO:     Found new best model at epoch 38
2023-01-05 14:38:26,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:26,977 INFO:     Epoch: 39
2023-01-05 14:38:29,092 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4160049562652906, 'Total loss': 0.4160049562652906} | train loss {'Reaction outcome loss': 0.36179388268759965, 'Total loss': 0.36179388268759965}
2023-01-05 14:38:29,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:29,092 INFO:     Epoch: 40
2023-01-05 14:38:31,236 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3920315444469452, 'Total loss': 0.3920315444469452} | train loss {'Reaction outcome loss': 0.35494171201322056, 'Total loss': 0.35494171201322056}
2023-01-05 14:38:31,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:31,236 INFO:     Epoch: 41
2023-01-05 14:38:33,375 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3969950407743454, 'Total loss': 0.3969950407743454} | train loss {'Reaction outcome loss': 0.3531099837340603, 'Total loss': 0.3531099837340603}
2023-01-05 14:38:33,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:33,375 INFO:     Epoch: 42
2023-01-05 14:38:35,509 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.37514170904954275, 'Total loss': 0.37514170904954275} | train loss {'Reaction outcome loss': 0.34843703945728843, 'Total loss': 0.34843703945728843}
2023-01-05 14:38:35,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:35,509 INFO:     Epoch: 43
2023-01-05 14:38:37,667 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3582891116539637, 'Total loss': 0.3582891116539637} | train loss {'Reaction outcome loss': 0.3522454004075768, 'Total loss': 0.3522454004075768}
2023-01-05 14:38:37,667 INFO:     Found new best model at epoch 43
2023-01-05 14:38:37,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:37,668 INFO:     Epoch: 44
2023-01-05 14:38:39,803 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4003665417432785, 'Total loss': 0.4003665417432785} | train loss {'Reaction outcome loss': 0.33821642739086377, 'Total loss': 0.33821642739086377}
2023-01-05 14:38:39,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:39,803 INFO:     Epoch: 45
2023-01-05 14:38:41,923 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3831948647896449, 'Total loss': 0.3831948647896449} | train loss {'Reaction outcome loss': 0.33529039426615953, 'Total loss': 0.33529039426615953}
2023-01-05 14:38:41,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:41,923 INFO:     Epoch: 46
2023-01-05 14:38:44,064 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3830057630936305, 'Total loss': 0.3830057630936305} | train loss {'Reaction outcome loss': 0.336408524871518, 'Total loss': 0.336408524871518}
2023-01-05 14:38:44,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:44,065 INFO:     Epoch: 47
2023-01-05 14:38:46,214 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.36782243152459465, 'Total loss': 0.36782243152459465} | train loss {'Reaction outcome loss': 0.3282874893356747, 'Total loss': 0.3282874893356747}
2023-01-05 14:38:46,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:46,214 INFO:     Epoch: 48
2023-01-05 14:38:48,368 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3664790297547976, 'Total loss': 0.3664790297547976} | train loss {'Reaction outcome loss': 0.32883866014301993, 'Total loss': 0.32883866014301993}
2023-01-05 14:38:48,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:48,368 INFO:     Epoch: 49
2023-01-05 14:38:50,528 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3892756241063277, 'Total loss': 0.3892756241063277} | train loss {'Reaction outcome loss': 0.3242174544529687, 'Total loss': 0.3242174544529687}
2023-01-05 14:38:50,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:50,529 INFO:     Epoch: 50
2023-01-05 14:38:52,669 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39761504580577217, 'Total loss': 0.39761504580577217} | train loss {'Reaction outcome loss': 0.326823209624213, 'Total loss': 0.326823209624213}
2023-01-05 14:38:52,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:52,669 INFO:     Epoch: 51
2023-01-05 14:38:54,818 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.382593464354674, 'Total loss': 0.382593464354674} | train loss {'Reaction outcome loss': 0.31955334756671305, 'Total loss': 0.31955334756671305}
2023-01-05 14:38:54,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:54,818 INFO:     Epoch: 52
2023-01-05 14:38:56,958 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3679480105638504, 'Total loss': 0.3679480105638504} | train loss {'Reaction outcome loss': 0.30837577643269665, 'Total loss': 0.30837577643269665}
2023-01-05 14:38:56,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:56,958 INFO:     Epoch: 53
2023-01-05 14:38:59,132 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3763479953010877, 'Total loss': 0.3763479953010877} | train loss {'Reaction outcome loss': 0.3133335808016333, 'Total loss': 0.3133335808016333}
2023-01-05 14:38:59,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:38:59,132 INFO:     Epoch: 54
2023-01-05 14:39:01,291 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39138800501823423, 'Total loss': 0.39138800501823423} | train loss {'Reaction outcome loss': 0.3106832277527355, 'Total loss': 0.3106832277527355}
2023-01-05 14:39:01,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:01,291 INFO:     Epoch: 55
2023-01-05 14:39:03,478 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.35167319774627687, 'Total loss': 0.35167319774627687} | train loss {'Reaction outcome loss': 0.3151825848119569, 'Total loss': 0.3151825848119569}
2023-01-05 14:39:03,479 INFO:     Found new best model at epoch 55
2023-01-05 14:39:03,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:03,480 INFO:     Epoch: 56
2023-01-05 14:39:05,651 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.35500285526116687, 'Total loss': 0.35500285526116687} | train loss {'Reaction outcome loss': 0.3113574941343349, 'Total loss': 0.3113574941343349}
2023-01-05 14:39:05,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:05,651 INFO:     Epoch: 57
2023-01-05 14:39:07,794 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3847153897086779, 'Total loss': 0.3847153897086779} | train loss {'Reaction outcome loss': 0.30663759738798607, 'Total loss': 0.30663759738798607}
2023-01-05 14:39:07,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:07,794 INFO:     Epoch: 58
2023-01-05 14:39:09,912 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3765737106402715, 'Total loss': 0.3765737106402715} | train loss {'Reaction outcome loss': 0.3098540913569153, 'Total loss': 0.3098540913569153}
2023-01-05 14:39:09,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:09,912 INFO:     Epoch: 59
2023-01-05 14:39:12,062 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3500559131304423, 'Total loss': 0.3500559131304423} | train loss {'Reaction outcome loss': 0.30239875381980563, 'Total loss': 0.30239875381980563}
2023-01-05 14:39:12,063 INFO:     Found new best model at epoch 59
2023-01-05 14:39:12,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:12,064 INFO:     Epoch: 60
2023-01-05 14:39:14,218 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40774589478969575, 'Total loss': 0.40774589478969575} | train loss {'Reaction outcome loss': 0.2977447164133998, 'Total loss': 0.2977447164133998}
2023-01-05 14:39:14,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:14,219 INFO:     Epoch: 61
2023-01-05 14:39:16,375 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.36992576668659843, 'Total loss': 0.36992576668659843} | train loss {'Reaction outcome loss': 0.3030243392845461, 'Total loss': 0.3030243392845461}
2023-01-05 14:39:16,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:16,375 INFO:     Epoch: 62
2023-01-05 14:39:18,523 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3984752674897512, 'Total loss': 0.3984752674897512} | train loss {'Reaction outcome loss': 0.293529720445725, 'Total loss': 0.293529720445725}
2023-01-05 14:39:18,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:18,523 INFO:     Epoch: 63
2023-01-05 14:39:20,694 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3875672628482183, 'Total loss': 0.3875672628482183} | train loss {'Reaction outcome loss': 0.2935476132705539, 'Total loss': 0.2935476132705539}
2023-01-05 14:39:20,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:20,695 INFO:     Epoch: 64
2023-01-05 14:39:22,856 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.382427904009819, 'Total loss': 0.382427904009819} | train loss {'Reaction outcome loss': 0.2948260038606957, 'Total loss': 0.2948260038606957}
2023-01-05 14:39:22,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:22,856 INFO:     Epoch: 65
2023-01-05 14:39:24,997 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3634680166840553, 'Total loss': 0.3634680166840553} | train loss {'Reaction outcome loss': 0.2860326339837016, 'Total loss': 0.2860326339837016}
2023-01-05 14:39:24,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:24,997 INFO:     Epoch: 66
2023-01-05 14:39:27,127 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.35152410517136257, 'Total loss': 0.35152410517136257} | train loss {'Reaction outcome loss': 0.28153761348515643, 'Total loss': 0.28153761348515643}
2023-01-05 14:39:27,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:27,127 INFO:     Epoch: 67
2023-01-05 14:39:29,271 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36108878056208293, 'Total loss': 0.36108878056208293} | train loss {'Reaction outcome loss': 0.29097385522959895, 'Total loss': 0.29097385522959895}
2023-01-05 14:39:29,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:29,272 INFO:     Epoch: 68
2023-01-05 14:39:31,424 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3946716149648031, 'Total loss': 0.3946716149648031} | train loss {'Reaction outcome loss': 0.27859761187006526, 'Total loss': 0.27859761187006526}
2023-01-05 14:39:31,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:31,424 INFO:     Epoch: 69
2023-01-05 14:39:33,585 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.37315515577793124, 'Total loss': 0.37315515577793124} | train loss {'Reaction outcome loss': 0.2756100323871585, 'Total loss': 0.2756100323871585}
2023-01-05 14:39:33,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:33,586 INFO:     Epoch: 70
2023-01-05 14:39:35,747 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3656279146671295, 'Total loss': 0.3656279146671295} | train loss {'Reaction outcome loss': 0.2759116495276939, 'Total loss': 0.2759116495276939}
2023-01-05 14:39:35,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:35,748 INFO:     Epoch: 71
2023-01-05 14:39:37,907 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37984460095564526, 'Total loss': 0.37984460095564526} | train loss {'Reaction outcome loss': 0.27690529918789003, 'Total loss': 0.27690529918789003}
2023-01-05 14:39:37,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:37,907 INFO:     Epoch: 72
2023-01-05 14:39:40,040 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.36094052096207935, 'Total loss': 0.36094052096207935} | train loss {'Reaction outcome loss': 0.274998776345692, 'Total loss': 0.274998776345692}
2023-01-05 14:39:40,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:40,040 INFO:     Epoch: 73
2023-01-05 14:39:42,201 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3848712424437205, 'Total loss': 0.3848712424437205} | train loss {'Reaction outcome loss': 0.2785110573422177, 'Total loss': 0.2785110573422177}
2023-01-05 14:39:42,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:42,201 INFO:     Epoch: 74
2023-01-05 14:39:44,347 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39017081558704375, 'Total loss': 0.39017081558704375} | train loss {'Reaction outcome loss': 0.27365434522125265, 'Total loss': 0.27365434522125265}
2023-01-05 14:39:44,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:44,347 INFO:     Epoch: 75
2023-01-05 14:39:46,481 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37778231700261433, 'Total loss': 0.37778231700261433} | train loss {'Reaction outcome loss': 0.27197796512489286, 'Total loss': 0.27197796512489286}
2023-01-05 14:39:46,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:46,481 INFO:     Epoch: 76
2023-01-05 14:39:48,629 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3738475094238917, 'Total loss': 0.3738475094238917} | train loss {'Reaction outcome loss': 0.2670694045076947, 'Total loss': 0.2670694045076947}
2023-01-05 14:39:48,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:48,629 INFO:     Epoch: 77
2023-01-05 14:39:50,791 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3982636292775472, 'Total loss': 0.3982636292775472} | train loss {'Reaction outcome loss': 0.26716721970386237, 'Total loss': 0.26716721970386237}
2023-01-05 14:39:50,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:50,792 INFO:     Epoch: 78
2023-01-05 14:39:53,001 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.37835964461167654, 'Total loss': 0.37835964461167654} | train loss {'Reaction outcome loss': 0.2654739795286303, 'Total loss': 0.2654739795286303}
2023-01-05 14:39:53,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:53,002 INFO:     Epoch: 79
2023-01-05 14:39:55,194 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42480760216712954, 'Total loss': 0.42480760216712954} | train loss {'Reaction outcome loss': 0.266865683013459, 'Total loss': 0.266865683013459}
2023-01-05 14:39:55,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:55,194 INFO:     Epoch: 80
2023-01-05 14:39:57,337 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3749078373114268, 'Total loss': 0.3749078373114268} | train loss {'Reaction outcome loss': 0.2751504617881043, 'Total loss': 0.2751504617881043}
2023-01-05 14:39:57,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:57,338 INFO:     Epoch: 81
2023-01-05 14:39:59,475 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3910882920026779, 'Total loss': 0.3910882920026779} | train loss {'Reaction outcome loss': 0.25466102777243954, 'Total loss': 0.25466102777243954}
2023-01-05 14:39:59,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:39:59,476 INFO:     Epoch: 82
2023-01-05 14:40:01,621 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4374050815900167, 'Total loss': 0.4374050815900167} | train loss {'Reaction outcome loss': 0.2641769091359975, 'Total loss': 0.2641769091359975}
2023-01-05 14:40:01,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:01,622 INFO:     Epoch: 83
2023-01-05 14:40:03,755 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3684619635343552, 'Total loss': 0.3684619635343552} | train loss {'Reaction outcome loss': 0.26224028606922617, 'Total loss': 0.26224028606922617}
2023-01-05 14:40:03,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:03,755 INFO:     Epoch: 84
2023-01-05 14:40:05,889 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3610850632190704, 'Total loss': 0.3610850632190704} | train loss {'Reaction outcome loss': 0.25888842618637564, 'Total loss': 0.25888842618637564}
2023-01-05 14:40:05,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:05,889 INFO:     Epoch: 85
2023-01-05 14:40:08,015 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37324392000834145, 'Total loss': 0.37324392000834145} | train loss {'Reaction outcome loss': 0.2620463172370561, 'Total loss': 0.2620463172370561}
2023-01-05 14:40:08,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:08,015 INFO:     Epoch: 86
2023-01-05 14:40:10,160 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.35392296810944873, 'Total loss': 0.35392296810944873} | train loss {'Reaction outcome loss': 0.25976871725992173, 'Total loss': 0.25976871725992173}
2023-01-05 14:40:10,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:10,161 INFO:     Epoch: 87
2023-01-05 14:40:12,294 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3550321996212006, 'Total loss': 0.3550321996212006} | train loss {'Reaction outcome loss': 0.25640083483625403, 'Total loss': 0.25640083483625403}
2023-01-05 14:40:12,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:12,294 INFO:     Epoch: 88
2023-01-05 14:40:14,426 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3646625181039174, 'Total loss': 0.3646625181039174} | train loss {'Reaction outcome loss': 0.2538147512083665, 'Total loss': 0.2538147512083665}
2023-01-05 14:40:14,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:14,427 INFO:     Epoch: 89
2023-01-05 14:40:16,576 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.35472945670286815, 'Total loss': 0.35472945670286815} | train loss {'Reaction outcome loss': 0.25439655595200156, 'Total loss': 0.25439655595200156}
2023-01-05 14:40:16,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:16,577 INFO:     Epoch: 90
2023-01-05 14:40:18,733 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3861407627662023, 'Total loss': 0.3861407627662023} | train loss {'Reaction outcome loss': 0.24785172798761607, 'Total loss': 0.24785172798761607}
2023-01-05 14:40:18,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:18,733 INFO:     Epoch: 91
2023-01-05 14:40:20,876 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3689123829205831, 'Total loss': 0.3689123829205831} | train loss {'Reaction outcome loss': 0.2455246701621407, 'Total loss': 0.2455246701621407}
2023-01-05 14:40:20,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:20,878 INFO:     Epoch: 92
2023-01-05 14:40:23,006 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37987554967403414, 'Total loss': 0.37987554967403414} | train loss {'Reaction outcome loss': 0.24091482638559616, 'Total loss': 0.24091482638559616}
2023-01-05 14:40:23,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:23,006 INFO:     Epoch: 93
2023-01-05 14:40:25,138 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36444612095753354, 'Total loss': 0.36444612095753354} | train loss {'Reaction outcome loss': 0.24792613618963463, 'Total loss': 0.24792613618963463}
2023-01-05 14:40:25,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:25,138 INFO:     Epoch: 94
2023-01-05 14:40:27,276 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3978999445835749, 'Total loss': 0.3978999445835749} | train loss {'Reaction outcome loss': 0.2391026366892059, 'Total loss': 0.2391026366892059}
2023-01-05 14:40:27,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:27,277 INFO:     Epoch: 95
2023-01-05 14:40:29,431 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3914778729279836, 'Total loss': 0.3914778729279836} | train loss {'Reaction outcome loss': 0.24451268553088287, 'Total loss': 0.24451268553088287}
2023-01-05 14:40:29,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:29,431 INFO:     Epoch: 96
2023-01-05 14:40:31,578 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37306686739126843, 'Total loss': 0.37306686739126843} | train loss {'Reaction outcome loss': 0.2443244897185519, 'Total loss': 0.2443244897185519}
2023-01-05 14:40:31,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:31,578 INFO:     Epoch: 97
2023-01-05 14:40:33,734 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3927466318011284, 'Total loss': 0.3927466318011284} | train loss {'Reaction outcome loss': 0.23850531204324552, 'Total loss': 0.23850531204324552}
2023-01-05 14:40:33,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:33,734 INFO:     Epoch: 98
2023-01-05 14:40:35,893 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39541497429211936, 'Total loss': 0.39541497429211936} | train loss {'Reaction outcome loss': 0.23451314151744335, 'Total loss': 0.23451314151744335}
2023-01-05 14:40:35,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:35,894 INFO:     Epoch: 99
2023-01-05 14:40:38,028 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37959263324737547, 'Total loss': 0.37959263324737547} | train loss {'Reaction outcome loss': 0.23832772642925434, 'Total loss': 0.23832772642925434}
2023-01-05 14:40:38,029 INFO:     Best model found after epoch 60 of 100.
2023-01-05 14:40:38,029 INFO:   Done with stage: TRAINING
2023-01-05 14:40:38,029 INFO:   Starting stage: EVALUATION
2023-01-05 14:40:38,157 INFO:   Done with stage: EVALUATION
2023-01-05 14:40:38,157 INFO:   Leaving out SEQ value Fold_7
2023-01-05 14:40:38,170 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 14:40:38,170 INFO:   Starting stage: FEATURE SCALING
2023-01-05 14:40:38,829 INFO:   Done with stage: FEATURE SCALING
2023-01-05 14:40:38,829 INFO:   Starting stage: SCALING TARGETS
2023-01-05 14:40:38,898 INFO:   Done with stage: SCALING TARGETS
2023-01-05 14:40:38,899 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:40:38,899 INFO:     No hyperparam tuning for this model
2023-01-05 14:40:38,899 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:40:38,899 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 14:40:38,899 INFO:     None feature selector for col prot
2023-01-05 14:40:38,900 INFO:     None feature selector for col prot
2023-01-05 14:40:38,900 INFO:     None feature selector for col prot
2023-01-05 14:40:38,900 INFO:     None feature selector for col chem
2023-01-05 14:40:38,900 INFO:     None feature selector for col chem
2023-01-05 14:40:38,900 INFO:     None feature selector for col chem
2023-01-05 14:40:38,900 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 14:40:38,901 INFO:   Starting stage: BUILD MODEL
2023-01-05 14:40:38,903 INFO:     Number of params in model 72901
2023-01-05 14:40:38,906 INFO:   Done with stage: BUILD MODEL
2023-01-05 14:40:38,906 INFO:   Starting stage: TRAINING
2023-01-05 14:40:38,964 INFO:     Val loss before train {'Reaction outcome loss': 0.9634326060612997, 'Total loss': 0.9634326060612997}
2023-01-05 14:40:38,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:38,964 INFO:     Epoch: 0
2023-01-05 14:40:41,126 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7596450507640838, 'Total loss': 0.7596450507640838} | train loss {'Reaction outcome loss': 0.9180175413508708, 'Total loss': 0.9180175413508708}
2023-01-05 14:40:41,127 INFO:     Found new best model at epoch 0
2023-01-05 14:40:41,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:41,128 INFO:     Epoch: 1
2023-01-05 14:40:43,312 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.605679448445638, 'Total loss': 0.605679448445638} | train loss {'Reaction outcome loss': 0.7308878817928397, 'Total loss': 0.7308878817928397}
2023-01-05 14:40:43,312 INFO:     Found new best model at epoch 1
2023-01-05 14:40:43,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:43,313 INFO:     Epoch: 2
2023-01-05 14:40:45,467 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5249547918637594, 'Total loss': 0.5249547918637594} | train loss {'Reaction outcome loss': 0.5893450622524166, 'Total loss': 0.5893450622524166}
2023-01-05 14:40:45,467 INFO:     Found new best model at epoch 2
2023-01-05 14:40:45,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:45,468 INFO:     Epoch: 3
2023-01-05 14:40:47,604 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.498159251610438, 'Total loss': 0.498159251610438} | train loss {'Reaction outcome loss': 0.536433593514594, 'Total loss': 0.536433593514594}
2023-01-05 14:40:47,604 INFO:     Found new best model at epoch 3
2023-01-05 14:40:47,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:47,606 INFO:     Epoch: 4
2023-01-05 14:40:49,746 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5094372431437174, 'Total loss': 0.5094372431437174} | train loss {'Reaction outcome loss': 0.5128533797143598, 'Total loss': 0.5128533797143598}
2023-01-05 14:40:49,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:49,747 INFO:     Epoch: 5
2023-01-05 14:40:51,898 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4913991014162699, 'Total loss': 0.4913991014162699} | train loss {'Reaction outcome loss': 0.5059879492659001, 'Total loss': 0.5059879492659001}
2023-01-05 14:40:51,898 INFO:     Found new best model at epoch 5
2023-01-05 14:40:51,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:51,899 INFO:     Epoch: 6
2023-01-05 14:40:54,041 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4983378986517588, 'Total loss': 0.4983378986517588} | train loss {'Reaction outcome loss': 0.4942425682011064, 'Total loss': 0.4942425682011064}
2023-01-05 14:40:54,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:54,041 INFO:     Epoch: 7
2023-01-05 14:40:56,185 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47883030970891316, 'Total loss': 0.47883030970891316} | train loss {'Reaction outcome loss': 0.48369850753554366, 'Total loss': 0.48369850753554366}
2023-01-05 14:40:56,187 INFO:     Found new best model at epoch 7
2023-01-05 14:40:56,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:56,188 INFO:     Epoch: 8
2023-01-05 14:40:58,307 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4734897553920746, 'Total loss': 0.4734897553920746} | train loss {'Reaction outcome loss': 0.4772510433347647, 'Total loss': 0.4772510433347647}
2023-01-05 14:40:58,307 INFO:     Found new best model at epoch 8
2023-01-05 14:40:58,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:40:58,308 INFO:     Epoch: 9
2023-01-05 14:41:00,447 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46669570604960126, 'Total loss': 0.46669570604960126} | train loss {'Reaction outcome loss': 0.4688113109622191, 'Total loss': 0.4688113109622191}
2023-01-05 14:41:00,447 INFO:     Found new best model at epoch 9
2023-01-05 14:41:00,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:00,448 INFO:     Epoch: 10
2023-01-05 14:41:02,569 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4629736711581548, 'Total loss': 0.4629736711581548} | train loss {'Reaction outcome loss': 0.46843530810589395, 'Total loss': 0.46843530810589395}
2023-01-05 14:41:02,570 INFO:     Found new best model at epoch 10
2023-01-05 14:41:02,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:02,571 INFO:     Epoch: 11
2023-01-05 14:41:04,695 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.468744562069575, 'Total loss': 0.468744562069575} | train loss {'Reaction outcome loss': 0.462428403675341, 'Total loss': 0.462428403675341}
2023-01-05 14:41:04,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:04,695 INFO:     Epoch: 12
2023-01-05 14:41:06,807 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45037590463956195, 'Total loss': 0.45037590463956195} | train loss {'Reaction outcome loss': 0.44961171804352357, 'Total loss': 0.44961171804352357}
2023-01-05 14:41:06,807 INFO:     Found new best model at epoch 12
2023-01-05 14:41:06,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:06,808 INFO:     Epoch: 13
2023-01-05 14:41:08,959 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46513982812563576, 'Total loss': 0.46513982812563576} | train loss {'Reaction outcome loss': 0.45169348067970483, 'Total loss': 0.45169348067970483}
2023-01-05 14:41:08,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:08,959 INFO:     Epoch: 14
2023-01-05 14:41:11,101 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4538576066493988, 'Total loss': 0.4538576066493988} | train loss {'Reaction outcome loss': 0.44471339596307663, 'Total loss': 0.44471339596307663}
2023-01-05 14:41:11,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:11,102 INFO:     Epoch: 15
2023-01-05 14:41:13,231 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4557475666205088, 'Total loss': 0.4557475666205088} | train loss {'Reaction outcome loss': 0.4418468231651327, 'Total loss': 0.4418468231651327}
2023-01-05 14:41:13,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:13,232 INFO:     Epoch: 16
2023-01-05 14:41:15,364 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44596443374951683, 'Total loss': 0.44596443374951683} | train loss {'Reaction outcome loss': 0.4330449152724407, 'Total loss': 0.4330449152724407}
2023-01-05 14:41:15,365 INFO:     Found new best model at epoch 16
2023-01-05 14:41:15,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:15,366 INFO:     Epoch: 17
2023-01-05 14:41:17,483 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4814803719520569, 'Total loss': 0.4814803719520569} | train loss {'Reaction outcome loss': 0.4295533218484923, 'Total loss': 0.4295533218484923}
2023-01-05 14:41:17,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:17,484 INFO:     Epoch: 18
2023-01-05 14:41:19,646 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45844510197639465, 'Total loss': 0.45844510197639465} | train loss {'Reaction outcome loss': 0.4238491605980732, 'Total loss': 0.4238491605980732}
2023-01-05 14:41:19,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:19,646 INFO:     Epoch: 19
2023-01-05 14:41:21,785 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43722227613131204, 'Total loss': 0.43722227613131204} | train loss {'Reaction outcome loss': 0.4193585394252939, 'Total loss': 0.4193585394252939}
2023-01-05 14:41:21,785 INFO:     Found new best model at epoch 19
2023-01-05 14:41:21,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:21,786 INFO:     Epoch: 20
2023-01-05 14:41:23,920 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4277163763840993, 'Total loss': 0.4277163763840993} | train loss {'Reaction outcome loss': 0.4177090011617767, 'Total loss': 0.4177090011617767}
2023-01-05 14:41:23,920 INFO:     Found new best model at epoch 20
2023-01-05 14:41:23,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:23,922 INFO:     Epoch: 21
2023-01-05 14:41:26,070 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43705432713031767, 'Total loss': 0.43705432713031767} | train loss {'Reaction outcome loss': 0.41546645658326065, 'Total loss': 0.41546645658326065}
2023-01-05 14:41:26,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:26,070 INFO:     Epoch: 22
2023-01-05 14:41:28,264 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4611217627922694, 'Total loss': 0.4611217627922694} | train loss {'Reaction outcome loss': 0.4089545647643964, 'Total loss': 0.4089545647643964}
2023-01-05 14:41:28,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:28,264 INFO:     Epoch: 23
2023-01-05 14:41:30,418 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45328969856103263, 'Total loss': 0.45328969856103263} | train loss {'Reaction outcome loss': 0.41119063532632183, 'Total loss': 0.41119063532632183}
2023-01-05 14:41:30,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:30,418 INFO:     Epoch: 24
2023-01-05 14:41:32,574 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46129168967405954, 'Total loss': 0.46129168967405954} | train loss {'Reaction outcome loss': 0.40664580316427384, 'Total loss': 0.40664580316427384}
2023-01-05 14:41:32,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:32,575 INFO:     Epoch: 25
2023-01-05 14:41:34,721 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4576518893241882, 'Total loss': 0.4576518893241882} | train loss {'Reaction outcome loss': 0.397744713035086, 'Total loss': 0.397744713035086}
2023-01-05 14:41:34,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:34,721 INFO:     Epoch: 26
2023-01-05 14:41:36,861 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4302242825428645, 'Total loss': 0.4302242825428645} | train loss {'Reaction outcome loss': 0.3980734088737181, 'Total loss': 0.3980734088737181}
2023-01-05 14:41:36,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:36,861 INFO:     Epoch: 27
2023-01-05 14:41:39,020 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.444696964820226, 'Total loss': 0.444696964820226} | train loss {'Reaction outcome loss': 0.3946761471162204, 'Total loss': 0.3946761471162204}
2023-01-05 14:41:39,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:39,021 INFO:     Epoch: 28
2023-01-05 14:41:41,173 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4346049199501673, 'Total loss': 0.4346049199501673} | train loss {'Reaction outcome loss': 0.38548127564497375, 'Total loss': 0.38548127564497375}
2023-01-05 14:41:41,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:41,173 INFO:     Epoch: 29
2023-01-05 14:41:43,315 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.427898042400678, 'Total loss': 0.427898042400678} | train loss {'Reaction outcome loss': 0.38645555791764485, 'Total loss': 0.38645555791764485}
2023-01-05 14:41:43,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:43,316 INFO:     Epoch: 30
2023-01-05 14:41:45,496 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43434072931607565, 'Total loss': 0.43434072931607565} | train loss {'Reaction outcome loss': 0.384370209050738, 'Total loss': 0.384370209050738}
2023-01-05 14:41:45,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:45,497 INFO:     Epoch: 31
2023-01-05 14:41:47,638 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4383755167325338, 'Total loss': 0.4383755167325338} | train loss {'Reaction outcome loss': 0.3748225109241499, 'Total loss': 0.3748225109241499}
2023-01-05 14:41:47,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:47,638 INFO:     Epoch: 32
2023-01-05 14:41:49,795 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4560226082801819, 'Total loss': 0.4560226082801819} | train loss {'Reaction outcome loss': 0.37277495484489825, 'Total loss': 0.37277495484489825}
2023-01-05 14:41:49,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:49,796 INFO:     Epoch: 33
2023-01-05 14:41:51,945 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42601341952880223, 'Total loss': 0.42601341952880223} | train loss {'Reaction outcome loss': 0.37366376951713426, 'Total loss': 0.37366376951713426}
2023-01-05 14:41:51,946 INFO:     Found new best model at epoch 33
2023-01-05 14:41:51,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:51,947 INFO:     Epoch: 34
2023-01-05 14:41:54,092 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42280800342559816, 'Total loss': 0.42280800342559816} | train loss {'Reaction outcome loss': 0.3726374595980782, 'Total loss': 0.3726374595980782}
2023-01-05 14:41:54,092 INFO:     Found new best model at epoch 34
2023-01-05 14:41:54,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:54,094 INFO:     Epoch: 35
2023-01-05 14:41:56,248 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4491911431153615, 'Total loss': 0.4491911431153615} | train loss {'Reaction outcome loss': 0.3667009408831166, 'Total loss': 0.3667009408831166}
2023-01-05 14:41:56,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:56,248 INFO:     Epoch: 36
2023-01-05 14:41:58,394 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4330837458372116, 'Total loss': 0.4330837458372116} | train loss {'Reaction outcome loss': 0.3619890975554067, 'Total loss': 0.3619890975554067}
2023-01-05 14:41:58,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:41:58,394 INFO:     Epoch: 37
2023-01-05 14:42:00,544 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43468067745367683, 'Total loss': 0.43468067745367683} | train loss {'Reaction outcome loss': 0.3631391359042605, 'Total loss': 0.3631391359042605}
2023-01-05 14:42:00,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:00,544 INFO:     Epoch: 38
2023-01-05 14:42:02,710 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47294021050135293, 'Total loss': 0.47294021050135293} | train loss {'Reaction outcome loss': 0.3593338339014604, 'Total loss': 0.3593338339014604}
2023-01-05 14:42:02,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:02,710 INFO:     Epoch: 39
2023-01-05 14:42:04,888 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44998454054196674, 'Total loss': 0.44998454054196674} | train loss {'Reaction outcome loss': 0.35234121199603113, 'Total loss': 0.35234121199603113}
2023-01-05 14:42:04,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:04,888 INFO:     Epoch: 40
2023-01-05 14:42:07,040 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4833329143623511, 'Total loss': 0.4833329143623511} | train loss {'Reaction outcome loss': 0.3519645321724217, 'Total loss': 0.3519645321724217}
2023-01-05 14:42:07,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:07,040 INFO:     Epoch: 41
2023-01-05 14:42:09,183 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4373568813006083, 'Total loss': 0.4373568813006083} | train loss {'Reaction outcome loss': 0.3527704228778178, 'Total loss': 0.3527704228778178}
2023-01-05 14:42:09,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:09,185 INFO:     Epoch: 42
2023-01-05 14:42:11,221 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45520712931950885, 'Total loss': 0.45520712931950885} | train loss {'Reaction outcome loss': 0.3404894070397215, 'Total loss': 0.3404894070397215}
2023-01-05 14:42:11,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:11,221 INFO:     Epoch: 43
2023-01-05 14:42:13,262 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45278388063112895, 'Total loss': 0.45278388063112895} | train loss {'Reaction outcome loss': 0.3376736544502986, 'Total loss': 0.3376736544502986}
2023-01-05 14:42:13,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:13,262 INFO:     Epoch: 44
2023-01-05 14:42:15,419 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4379989951848984, 'Total loss': 0.4379989951848984} | train loss {'Reaction outcome loss': 0.3410696998937896, 'Total loss': 0.3410696998937896}
2023-01-05 14:42:15,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:15,420 INFO:     Epoch: 45
2023-01-05 14:42:17,589 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4514499415953954, 'Total loss': 0.4514499415953954} | train loss {'Reaction outcome loss': 0.3336520155737116, 'Total loss': 0.3336520155737116}
2023-01-05 14:42:17,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:17,589 INFO:     Epoch: 46
2023-01-05 14:42:19,729 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4502272655566533, 'Total loss': 0.4502272655566533} | train loss {'Reaction outcome loss': 0.3303274468044727, 'Total loss': 0.3303274468044727}
2023-01-05 14:42:19,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:19,730 INFO:     Epoch: 47
2023-01-05 14:42:21,889 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4104777256647746, 'Total loss': 0.4104777256647746} | train loss {'Reaction outcome loss': 0.3324832127089965, 'Total loss': 0.3324832127089965}
2023-01-05 14:42:21,889 INFO:     Found new best model at epoch 47
2023-01-05 14:42:21,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:21,891 INFO:     Epoch: 48
2023-01-05 14:42:24,043 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40605636934439343, 'Total loss': 0.40605636934439343} | train loss {'Reaction outcome loss': 0.3284597001996712, 'Total loss': 0.3284597001996712}
2023-01-05 14:42:24,043 INFO:     Found new best model at epoch 48
2023-01-05 14:42:24,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:24,045 INFO:     Epoch: 49
2023-01-05 14:42:26,229 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4016507605711619, 'Total loss': 0.4016507605711619} | train loss {'Reaction outcome loss': 0.3228639781152298, 'Total loss': 0.3228639781152298}
2023-01-05 14:42:26,229 INFO:     Found new best model at epoch 49
2023-01-05 14:42:26,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:26,231 INFO:     Epoch: 50
2023-01-05 14:42:28,377 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4089290579160055, 'Total loss': 0.4089290579160055} | train loss {'Reaction outcome loss': 0.31948610151771606, 'Total loss': 0.31948610151771606}
2023-01-05 14:42:28,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:28,378 INFO:     Epoch: 51
2023-01-05 14:42:30,521 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.38843210935592654, 'Total loss': 0.38843210935592654} | train loss {'Reaction outcome loss': 0.317523836733148, 'Total loss': 0.317523836733148}
2023-01-05 14:42:30,521 INFO:     Found new best model at epoch 51
2023-01-05 14:42:30,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:30,522 INFO:     Epoch: 52
2023-01-05 14:42:32,659 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41965596477190653, 'Total loss': 0.41965596477190653} | train loss {'Reaction outcome loss': 0.3145436203974679, 'Total loss': 0.3145436203974679}
2023-01-05 14:42:32,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:32,660 INFO:     Epoch: 53
2023-01-05 14:42:34,792 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42730558216571807, 'Total loss': 0.42730558216571807} | train loss {'Reaction outcome loss': 0.31078746538299945, 'Total loss': 0.31078746538299945}
2023-01-05 14:42:34,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:34,793 INFO:     Epoch: 54
2023-01-05 14:42:36,948 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39612797697385155, 'Total loss': 0.39612797697385155} | train loss {'Reaction outcome loss': 0.30741623723845835, 'Total loss': 0.30741623723845835}
2023-01-05 14:42:36,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:36,948 INFO:     Epoch: 55
2023-01-05 14:42:39,097 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4724086165428162, 'Total loss': 0.4724086165428162} | train loss {'Reaction outcome loss': 0.3091856761287481, 'Total loss': 0.3091856761287481}
2023-01-05 14:42:39,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:39,098 INFO:     Epoch: 56
2023-01-05 14:42:41,276 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4641659915447235, 'Total loss': 0.4641659915447235} | train loss {'Reaction outcome loss': 0.3115205654491156, 'Total loss': 0.3115205654491156}
2023-01-05 14:42:41,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:41,276 INFO:     Epoch: 57
2023-01-05 14:42:43,428 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41259447236855823, 'Total loss': 0.41259447236855823} | train loss {'Reaction outcome loss': 0.30496464116962807, 'Total loss': 0.30496464116962807}
2023-01-05 14:42:43,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:43,428 INFO:     Epoch: 58
2023-01-05 14:42:45,599 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4566062291463216, 'Total loss': 0.4566062291463216} | train loss {'Reaction outcome loss': 0.3052781004095551, 'Total loss': 0.3052781004095551}
2023-01-05 14:42:45,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:45,600 INFO:     Epoch: 59
2023-01-05 14:42:47,782 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45695256590843203, 'Total loss': 0.45695256590843203} | train loss {'Reaction outcome loss': 0.29784765791161394, 'Total loss': 0.29784765791161394}
2023-01-05 14:42:47,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:47,783 INFO:     Epoch: 60
2023-01-05 14:42:49,949 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4521656781435013, 'Total loss': 0.4521656781435013} | train loss {'Reaction outcome loss': 0.2967861111575085, 'Total loss': 0.2967861111575085}
2023-01-05 14:42:49,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:49,950 INFO:     Epoch: 61
2023-01-05 14:42:52,111 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44022605021794636, 'Total loss': 0.44022605021794636} | train loss {'Reaction outcome loss': 0.30337761089689896, 'Total loss': 0.30337761089689896}
2023-01-05 14:42:52,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:52,112 INFO:     Epoch: 62
2023-01-05 14:42:54,260 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4190518061319987, 'Total loss': 0.4190518061319987} | train loss {'Reaction outcome loss': 0.2991067375584307, 'Total loss': 0.2991067375584307}
2023-01-05 14:42:54,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:54,260 INFO:     Epoch: 63
2023-01-05 14:42:56,407 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4403783053159714, 'Total loss': 0.4403783053159714} | train loss {'Reaction outcome loss': 0.28944347164045603, 'Total loss': 0.28944347164045603}
2023-01-05 14:42:56,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:56,408 INFO:     Epoch: 64
2023-01-05 14:42:58,545 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41296297013759614, 'Total loss': 0.41296297013759614} | train loss {'Reaction outcome loss': 0.29574179900843744, 'Total loss': 0.29574179900843744}
2023-01-05 14:42:58,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:42:58,546 INFO:     Epoch: 65
2023-01-05 14:43:00,706 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42305891811847685, 'Total loss': 0.42305891811847685} | train loss {'Reaction outcome loss': 0.2940583832104714, 'Total loss': 0.2940583832104714}
2023-01-05 14:43:00,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:00,707 INFO:     Epoch: 66
2023-01-05 14:43:02,873 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41754655838012694, 'Total loss': 0.41754655838012694} | train loss {'Reaction outcome loss': 0.28592631465583934, 'Total loss': 0.28592631465583934}
2023-01-05 14:43:02,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:02,874 INFO:     Epoch: 67
2023-01-05 14:43:05,036 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43666807015736897, 'Total loss': 0.43666807015736897} | train loss {'Reaction outcome loss': 0.28995299562542876, 'Total loss': 0.28995299562542876}
2023-01-05 14:43:05,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:05,036 INFO:     Epoch: 68
2023-01-05 14:43:07,187 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47848356068134307, 'Total loss': 0.47848356068134307} | train loss {'Reaction outcome loss': 0.29034063626174894, 'Total loss': 0.29034063626174894}
2023-01-05 14:43:07,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:07,187 INFO:     Epoch: 69
2023-01-05 14:43:09,338 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4418238977591197, 'Total loss': 0.4418238977591197} | train loss {'Reaction outcome loss': 0.280741665888887, 'Total loss': 0.280741665888887}
2023-01-05 14:43:09,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:09,338 INFO:     Epoch: 70
2023-01-05 14:43:11,483 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46011546850204466, 'Total loss': 0.46011546850204466} | train loss {'Reaction outcome loss': 0.28719649405053915, 'Total loss': 0.28719649405053915}
2023-01-05 14:43:11,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:11,483 INFO:     Epoch: 71
2023-01-05 14:43:13,639 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4039613276720047, 'Total loss': 0.4039613276720047} | train loss {'Reaction outcome loss': 0.279504606251467, 'Total loss': 0.279504606251467}
2023-01-05 14:43:13,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:13,640 INFO:     Epoch: 72
2023-01-05 14:43:15,808 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4864688535531362, 'Total loss': 0.4864688535531362} | train loss {'Reaction outcome loss': 0.28001143923197414, 'Total loss': 0.28001143923197414}
2023-01-05 14:43:15,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:15,809 INFO:     Epoch: 73
2023-01-05 14:43:17,958 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.436944505572319, 'Total loss': 0.436944505572319} | train loss {'Reaction outcome loss': 0.27876014131985416, 'Total loss': 0.27876014131985416}
2023-01-05 14:43:17,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:17,958 INFO:     Epoch: 74
2023-01-05 14:43:20,130 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43586590786774954, 'Total loss': 0.43586590786774954} | train loss {'Reaction outcome loss': 0.27137049273436464, 'Total loss': 0.27137049273436464}
2023-01-05 14:43:20,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:20,130 INFO:     Epoch: 75
2023-01-05 14:43:22,304 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4664943565924962, 'Total loss': 0.4664943565924962} | train loss {'Reaction outcome loss': 0.27906790469850445, 'Total loss': 0.27906790469850445}
2023-01-05 14:43:22,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:22,305 INFO:     Epoch: 76
2023-01-05 14:43:24,466 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43625611265500386, 'Total loss': 0.43625611265500386} | train loss {'Reaction outcome loss': 0.27603114622944314, 'Total loss': 0.27603114622944314}
2023-01-05 14:43:24,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:24,466 INFO:     Epoch: 77
2023-01-05 14:43:26,630 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41306564112504324, 'Total loss': 0.41306564112504324} | train loss {'Reaction outcome loss': 0.26916992894309955, 'Total loss': 0.26916992894309955}
2023-01-05 14:43:26,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:26,630 INFO:     Epoch: 78
2023-01-05 14:43:28,774 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4080500682195028, 'Total loss': 0.4080500682195028} | train loss {'Reaction outcome loss': 0.27529374600828554, 'Total loss': 0.27529374600828554}
2023-01-05 14:43:28,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:28,774 INFO:     Epoch: 79
2023-01-05 14:43:30,930 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41217105885346733, 'Total loss': 0.41217105885346733} | train loss {'Reaction outcome loss': 0.27071924771212497, 'Total loss': 0.27071924771212497}
2023-01-05 14:43:30,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:30,931 INFO:     Epoch: 80
2023-01-05 14:43:33,097 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.39258154630661013, 'Total loss': 0.39258154630661013} | train loss {'Reaction outcome loss': 0.262376985247062, 'Total loss': 0.262376985247062}
2023-01-05 14:43:33,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:33,097 INFO:     Epoch: 81
2023-01-05 14:43:35,238 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.487060875693957, 'Total loss': 0.487060875693957} | train loss {'Reaction outcome loss': 0.2652449376934917, 'Total loss': 0.2652449376934917}
2023-01-05 14:43:35,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:35,239 INFO:     Epoch: 82
2023-01-05 14:43:37,405 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44165497124195097, 'Total loss': 0.44165497124195097} | train loss {'Reaction outcome loss': 0.2671784299429143, 'Total loss': 0.2671784299429143}
2023-01-05 14:43:37,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:37,406 INFO:     Epoch: 83
2023-01-05 14:43:39,582 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43108404825131097, 'Total loss': 0.43108404825131097} | train loss {'Reaction outcome loss': 0.26256033600667755, 'Total loss': 0.26256033600667755}
2023-01-05 14:43:39,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:39,582 INFO:     Epoch: 84
2023-01-05 14:43:41,763 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44595560828844705, 'Total loss': 0.44595560828844705} | train loss {'Reaction outcome loss': 0.26202631209193583, 'Total loss': 0.26202631209193583}
2023-01-05 14:43:41,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:41,764 INFO:     Epoch: 85
2023-01-05 14:43:43,953 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4082076112429301, 'Total loss': 0.4082076112429301} | train loss {'Reaction outcome loss': 0.259750147629193, 'Total loss': 0.259750147629193}
2023-01-05 14:43:43,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:43,954 INFO:     Epoch: 86
2023-01-05 14:43:46,141 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46032538811365764, 'Total loss': 0.46032538811365764} | train loss {'Reaction outcome loss': 0.25840676633056103, 'Total loss': 0.25840676633056103}
2023-01-05 14:43:46,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:46,141 INFO:     Epoch: 87
2023-01-05 14:43:48,339 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4372583051522573, 'Total loss': 0.4372583051522573} | train loss {'Reaction outcome loss': 0.26181798093424374, 'Total loss': 0.26181798093424374}
2023-01-05 14:43:48,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:48,339 INFO:     Epoch: 88
2023-01-05 14:43:50,518 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4414590577284495, 'Total loss': 0.4414590577284495} | train loss {'Reaction outcome loss': 0.26071152117923707, 'Total loss': 0.26071152117923707}
2023-01-05 14:43:50,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:50,519 INFO:     Epoch: 89
2023-01-05 14:43:52,675 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3982514635970195, 'Total loss': 0.3982514635970195} | train loss {'Reaction outcome loss': 0.2602004411526105, 'Total loss': 0.2602004411526105}
2023-01-05 14:43:52,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:52,675 INFO:     Epoch: 90
2023-01-05 14:43:54,830 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4720020910104116, 'Total loss': 0.4720020910104116} | train loss {'Reaction outcome loss': 0.26504612099446545, 'Total loss': 0.26504612099446545}
2023-01-05 14:43:54,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:54,830 INFO:     Epoch: 91
2023-01-05 14:43:56,958 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40981347262859347, 'Total loss': 0.40981347262859347} | train loss {'Reaction outcome loss': 0.2632222009506682, 'Total loss': 0.2632222009506682}
2023-01-05 14:43:56,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:56,959 INFO:     Epoch: 92
2023-01-05 14:43:59,103 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4229779064655304, 'Total loss': 0.4229779064655304} | train loss {'Reaction outcome loss': 0.2556294427868584, 'Total loss': 0.2556294427868584}
2023-01-05 14:43:59,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:43:59,104 INFO:     Epoch: 93
2023-01-05 14:44:01,262 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4273044566313426, 'Total loss': 0.4273044566313426} | train loss {'Reaction outcome loss': 0.25406592985151155, 'Total loss': 0.25406592985151155}
2023-01-05 14:44:01,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:01,262 INFO:     Epoch: 94
2023-01-05 14:44:03,384 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42231657803058625, 'Total loss': 0.42231657803058625} | train loss {'Reaction outcome loss': 0.2516132630878515, 'Total loss': 0.2516132630878515}
2023-01-05 14:44:03,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:03,384 INFO:     Epoch: 95
2023-01-05 14:44:05,517 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42099449038505554, 'Total loss': 0.42099449038505554} | train loss {'Reaction outcome loss': 0.25089134649787137, 'Total loss': 0.25089134649787137}
2023-01-05 14:44:05,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:05,517 INFO:     Epoch: 96
2023-01-05 14:44:07,672 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4259102374315262, 'Total loss': 0.4259102374315262} | train loss {'Reaction outcome loss': 0.24562548345042265, 'Total loss': 0.24562548345042265}
2023-01-05 14:44:07,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:07,672 INFO:     Epoch: 97
2023-01-05 14:44:09,820 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4023864299058914, 'Total loss': 0.4023864299058914} | train loss {'Reaction outcome loss': 0.25259398842492686, 'Total loss': 0.25259398842492686}
2023-01-05 14:44:09,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:09,821 INFO:     Epoch: 98
2023-01-05 14:44:11,992 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44568370779355365, 'Total loss': 0.44568370779355365} | train loss {'Reaction outcome loss': 0.25065058921984923, 'Total loss': 0.25065058921984923}
2023-01-05 14:44:11,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:11,992 INFO:     Epoch: 99
2023-01-05 14:44:14,164 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45679595371087395, 'Total loss': 0.45679595371087395} | train loss {'Reaction outcome loss': 0.2474934954048279, 'Total loss': 0.2474934954048279}
2023-01-05 14:44:14,164 INFO:     Best model found after epoch 52 of 100.
2023-01-05 14:44:14,164 INFO:   Done with stage: TRAINING
2023-01-05 14:44:14,164 INFO:   Starting stage: EVALUATION
2023-01-05 14:44:14,290 INFO:   Done with stage: EVALUATION
2023-01-05 14:44:14,290 INFO:   Leaving out SEQ value Fold_8
2023-01-05 14:44:14,302 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 14:44:14,302 INFO:   Starting stage: FEATURE SCALING
2023-01-05 14:44:14,953 INFO:   Done with stage: FEATURE SCALING
2023-01-05 14:44:14,953 INFO:   Starting stage: SCALING TARGETS
2023-01-05 14:44:15,021 INFO:   Done with stage: SCALING TARGETS
2023-01-05 14:44:15,021 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:44:15,021 INFO:     No hyperparam tuning for this model
2023-01-05 14:44:15,021 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:44:15,021 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 14:44:15,022 INFO:     None feature selector for col prot
2023-01-05 14:44:15,022 INFO:     None feature selector for col prot
2023-01-05 14:44:15,022 INFO:     None feature selector for col prot
2023-01-05 14:44:15,022 INFO:     None feature selector for col chem
2023-01-05 14:44:15,022 INFO:     None feature selector for col chem
2023-01-05 14:44:15,023 INFO:     None feature selector for col chem
2023-01-05 14:44:15,023 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 14:44:15,023 INFO:   Starting stage: BUILD MODEL
2023-01-05 14:44:15,024 INFO:     Number of params in model 72901
2023-01-05 14:44:15,027 INFO:   Done with stage: BUILD MODEL
2023-01-05 14:44:15,027 INFO:   Starting stage: TRAINING
2023-01-05 14:44:15,087 INFO:     Val loss before train {'Reaction outcome loss': 1.0632414976755777, 'Total loss': 1.0632414976755777}
2023-01-05 14:44:15,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:15,087 INFO:     Epoch: 0
2023-01-05 14:44:17,182 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8862485806147258, 'Total loss': 0.8862485806147258} | train loss {'Reaction outcome loss': 0.9195750303512072, 'Total loss': 0.9195750303512072}
2023-01-05 14:44:17,182 INFO:     Found new best model at epoch 0
2023-01-05 14:44:17,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:17,183 INFO:     Epoch: 1
2023-01-05 14:44:19,295 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6870201468467713, 'Total loss': 0.6870201468467713} | train loss {'Reaction outcome loss': 0.7587276551410229, 'Total loss': 0.7587276551410229}
2023-01-05 14:44:19,295 INFO:     Found new best model at epoch 1
2023-01-05 14:44:19,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:19,296 INFO:     Epoch: 2
2023-01-05 14:44:21,405 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5993396004041036, 'Total loss': 0.5993396004041036} | train loss {'Reaction outcome loss': 0.6152285187348833, 'Total loss': 0.6152285187348833}
2023-01-05 14:44:21,406 INFO:     Found new best model at epoch 2
2023-01-05 14:44:21,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:21,407 INFO:     Epoch: 3
2023-01-05 14:44:23,523 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5454455614089966, 'Total loss': 0.5454455614089966} | train loss {'Reaction outcome loss': 0.5464475109194317, 'Total loss': 0.5464475109194317}
2023-01-05 14:44:23,524 INFO:     Found new best model at epoch 3
2023-01-05 14:44:23,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:23,525 INFO:     Epoch: 4
2023-01-05 14:44:25,635 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5133704463640849, 'Total loss': 0.5133704463640849} | train loss {'Reaction outcome loss': 0.5203167287102581, 'Total loss': 0.5203167287102581}
2023-01-05 14:44:25,636 INFO:     Found new best model at epoch 4
2023-01-05 14:44:25,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:25,637 INFO:     Epoch: 5
2023-01-05 14:44:27,764 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5550383627414703, 'Total loss': 0.5550383627414703} | train loss {'Reaction outcome loss': 0.5065055697830054, 'Total loss': 0.5065055697830054}
2023-01-05 14:44:27,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:27,764 INFO:     Epoch: 6
2023-01-05 14:44:29,901 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5406658192475636, 'Total loss': 0.5406658192475636} | train loss {'Reaction outcome loss': 0.5025222231871891, 'Total loss': 0.5025222231871891}
2023-01-05 14:44:29,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:29,901 INFO:     Epoch: 7
2023-01-05 14:44:32,010 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4938867231210073, 'Total loss': 0.4938867231210073} | train loss {'Reaction outcome loss': 0.4899283210971277, 'Total loss': 0.4899283210971277}
2023-01-05 14:44:32,011 INFO:     Found new best model at epoch 7
2023-01-05 14:44:32,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:32,012 INFO:     Epoch: 8
2023-01-05 14:44:34,140 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5719899713993073, 'Total loss': 0.5719899713993073} | train loss {'Reaction outcome loss': 0.48255320263169976, 'Total loss': 0.48255320263169976}
2023-01-05 14:44:34,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:34,140 INFO:     Epoch: 9
2023-01-05 14:44:36,265 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5052557806173961, 'Total loss': 0.5052557806173961} | train loss {'Reaction outcome loss': 0.4804886596372528, 'Total loss': 0.4804886596372528}
2023-01-05 14:44:36,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:36,265 INFO:     Epoch: 10
2023-01-05 14:44:38,373 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.520853849252065, 'Total loss': 0.520853849252065} | train loss {'Reaction outcome loss': 0.47172052345245424, 'Total loss': 0.47172052345245424}
2023-01-05 14:44:38,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:38,374 INFO:     Epoch: 11
2023-01-05 14:44:40,512 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5156080961227417, 'Total loss': 0.5156080961227417} | train loss {'Reaction outcome loss': 0.46659955613478254, 'Total loss': 0.46659955613478254}
2023-01-05 14:44:40,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:40,512 INFO:     Epoch: 12
2023-01-05 14:44:42,643 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48229206005732217, 'Total loss': 0.48229206005732217} | train loss {'Reaction outcome loss': 0.46182696654522504, 'Total loss': 0.46182696654522504}
2023-01-05 14:44:42,643 INFO:     Found new best model at epoch 12
2023-01-05 14:44:42,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:42,645 INFO:     Epoch: 13
2023-01-05 14:44:44,772 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5237801492214202, 'Total loss': 0.5237801492214202} | train loss {'Reaction outcome loss': 0.4581036535057708, 'Total loss': 0.4581036535057708}
2023-01-05 14:44:44,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:44,773 INFO:     Epoch: 14
2023-01-05 14:44:46,928 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45882092316945394, 'Total loss': 0.45882092316945394} | train loss {'Reaction outcome loss': 0.45834724466404775, 'Total loss': 0.45834724466404775}
2023-01-05 14:44:46,928 INFO:     Found new best model at epoch 14
2023-01-05 14:44:46,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:46,930 INFO:     Epoch: 15
2023-01-05 14:44:49,080 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47700885037581126, 'Total loss': 0.47700885037581126} | train loss {'Reaction outcome loss': 0.45099171609991656, 'Total loss': 0.45099171609991656}
2023-01-05 14:44:49,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:49,080 INFO:     Epoch: 16
2023-01-05 14:44:51,195 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49514470199743904, 'Total loss': 0.49514470199743904} | train loss {'Reaction outcome loss': 0.44709212670143506, 'Total loss': 0.44709212670143506}
2023-01-05 14:44:51,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:51,196 INFO:     Epoch: 17
2023-01-05 14:44:53,329 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.464047746360302, 'Total loss': 0.464047746360302} | train loss {'Reaction outcome loss': 0.44046586678519734, 'Total loss': 0.44046586678519734}
2023-01-05 14:44:53,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:53,329 INFO:     Epoch: 18
2023-01-05 14:44:55,443 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4437122275431951, 'Total loss': 0.4437122275431951} | train loss {'Reaction outcome loss': 0.44050978194840634, 'Total loss': 0.44050978194840634}
2023-01-05 14:44:55,443 INFO:     Found new best model at epoch 18
2023-01-05 14:44:55,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:55,444 INFO:     Epoch: 19
2023-01-05 14:44:57,569 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44674104154109956, 'Total loss': 0.44674104154109956} | train loss {'Reaction outcome loss': 0.43177763514057566, 'Total loss': 0.43177763514057566}
2023-01-05 14:44:57,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:57,569 INFO:     Epoch: 20
2023-01-05 14:44:59,718 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.452844874560833, 'Total loss': 0.452844874560833} | train loss {'Reaction outcome loss': 0.43269430552303356, 'Total loss': 0.43269430552303356}
2023-01-05 14:44:59,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:44:59,719 INFO:     Epoch: 21
2023-01-05 14:45:01,840 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5010641237099965, 'Total loss': 0.5010641237099965} | train loss {'Reaction outcome loss': 0.42685892302406964, 'Total loss': 0.42685892302406964}
2023-01-05 14:45:01,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:01,842 INFO:     Epoch: 22
2023-01-05 14:45:03,955 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4705603808164597, 'Total loss': 0.4705603808164597} | train loss {'Reaction outcome loss': 0.42427672744884976, 'Total loss': 0.42427672744884976}
2023-01-05 14:45:03,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:03,956 INFO:     Epoch: 23
2023-01-05 14:45:06,064 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5061832070350647, 'Total loss': 0.5061832070350647} | train loss {'Reaction outcome loss': 0.41897457253432624, 'Total loss': 0.41897457253432624}
2023-01-05 14:45:06,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:06,064 INFO:     Epoch: 24
2023-01-05 14:45:08,176 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5038310110569, 'Total loss': 0.5038310110569} | train loss {'Reaction outcome loss': 0.4147908350411993, 'Total loss': 0.4147908350411993}
2023-01-05 14:45:08,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:08,177 INFO:     Epoch: 25
2023-01-05 14:45:10,301 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44623219470183056, 'Total loss': 0.44623219470183056} | train loss {'Reaction outcome loss': 0.4113287746797513, 'Total loss': 0.4113287746797513}
2023-01-05 14:45:10,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:10,301 INFO:     Epoch: 26
2023-01-05 14:45:12,424 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46795000433921813, 'Total loss': 0.46795000433921813} | train loss {'Reaction outcome loss': 0.4066903603120442, 'Total loss': 0.4066903603120442}
2023-01-05 14:45:12,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:12,425 INFO:     Epoch: 27
2023-01-05 14:45:14,540 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4715874433517456, 'Total loss': 0.4715874433517456} | train loss {'Reaction outcome loss': 0.4092339536134344, 'Total loss': 0.4092339536134344}
2023-01-05 14:45:14,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:14,540 INFO:     Epoch: 28
2023-01-05 14:45:16,660 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47202952901522316, 'Total loss': 0.47202952901522316} | train loss {'Reaction outcome loss': 0.40760068195688465, 'Total loss': 0.40760068195688465}
2023-01-05 14:45:16,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:16,661 INFO:     Epoch: 29
2023-01-05 14:45:18,776 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48437915245691937, 'Total loss': 0.48437915245691937} | train loss {'Reaction outcome loss': 0.4025624919764317, 'Total loss': 0.4025624919764317}
2023-01-05 14:45:18,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:18,776 INFO:     Epoch: 30
2023-01-05 14:45:20,911 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4296383261680603, 'Total loss': 0.4296383261680603} | train loss {'Reaction outcome loss': 0.3977951393836606, 'Total loss': 0.3977951393836606}
2023-01-05 14:45:20,912 INFO:     Found new best model at epoch 30
2023-01-05 14:45:20,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:20,913 INFO:     Epoch: 31
2023-01-05 14:45:23,058 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4585953772068024, 'Total loss': 0.4585953772068024} | train loss {'Reaction outcome loss': 0.38962898699797854, 'Total loss': 0.38962898699797854}
2023-01-05 14:45:23,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:23,058 INFO:     Epoch: 32
2023-01-05 14:45:25,177 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4644807835419973, 'Total loss': 0.4644807835419973} | train loss {'Reaction outcome loss': 0.3866159156454306, 'Total loss': 0.3866159156454306}
2023-01-05 14:45:25,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:25,177 INFO:     Epoch: 33
2023-01-05 14:45:27,306 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45589360892772673, 'Total loss': 0.45589360892772673} | train loss {'Reaction outcome loss': 0.3862015553580148, 'Total loss': 0.3862015553580148}
2023-01-05 14:45:27,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:27,306 INFO:     Epoch: 34
2023-01-05 14:45:29,455 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46983792781829836, 'Total loss': 0.46983792781829836} | train loss {'Reaction outcome loss': 0.38423789473400066, 'Total loss': 0.38423789473400066}
2023-01-05 14:45:29,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:29,456 INFO:     Epoch: 35
2023-01-05 14:45:31,583 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4484907319148382, 'Total loss': 0.4484907319148382} | train loss {'Reaction outcome loss': 0.37998999456745863, 'Total loss': 0.37998999456745863}
2023-01-05 14:45:31,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:31,583 INFO:     Epoch: 36
2023-01-05 14:45:33,712 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4676240066687266, 'Total loss': 0.4676240066687266} | train loss {'Reaction outcome loss': 0.38452996838375597, 'Total loss': 0.38452996838375597}
2023-01-05 14:45:33,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:33,712 INFO:     Epoch: 37
2023-01-05 14:45:35,847 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42538589735825855, 'Total loss': 0.42538589735825855} | train loss {'Reaction outcome loss': 0.37164463217023513, 'Total loss': 0.37164463217023513}
2023-01-05 14:45:35,847 INFO:     Found new best model at epoch 37
2023-01-05 14:45:35,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:35,848 INFO:     Epoch: 38
2023-01-05 14:45:38,007 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4155459890762965, 'Total loss': 0.4155459890762965} | train loss {'Reaction outcome loss': 0.36997268134116257, 'Total loss': 0.36997268134116257}
2023-01-05 14:45:38,008 INFO:     Found new best model at epoch 38
2023-01-05 14:45:38,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:38,009 INFO:     Epoch: 39
2023-01-05 14:45:40,123 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4663428048292796, 'Total loss': 0.4663428048292796} | train loss {'Reaction outcome loss': 0.37404323450840304, 'Total loss': 0.37404323450840304}
2023-01-05 14:45:40,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:40,124 INFO:     Epoch: 40
2023-01-05 14:45:42,236 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4856180508931478, 'Total loss': 0.4856180508931478} | train loss {'Reaction outcome loss': 0.3666454906826907, 'Total loss': 0.3666454906826907}
2023-01-05 14:45:42,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:42,237 INFO:     Epoch: 41
2023-01-05 14:45:44,375 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4623202482859294, 'Total loss': 0.4623202482859294} | train loss {'Reaction outcome loss': 0.36004938666511627, 'Total loss': 0.36004938666511627}
2023-01-05 14:45:44,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:44,376 INFO:     Epoch: 42
2023-01-05 14:45:46,514 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4644924014806747, 'Total loss': 0.4644924014806747} | train loss {'Reaction outcome loss': 0.3537810309416186, 'Total loss': 0.3537810309416186}
2023-01-05 14:45:46,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:46,515 INFO:     Epoch: 43
2023-01-05 14:45:48,643 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4419396777947744, 'Total loss': 0.4419396777947744} | train loss {'Reaction outcome loss': 0.3544144183941131, 'Total loss': 0.3544144183941131}
2023-01-05 14:45:48,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:48,643 INFO:     Epoch: 44
2023-01-05 14:45:50,786 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48236538767814635, 'Total loss': 0.48236538767814635} | train loss {'Reaction outcome loss': 0.3542080075092559, 'Total loss': 0.3542080075092559}
2023-01-05 14:45:50,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:50,786 INFO:     Epoch: 45
2023-01-05 14:45:52,933 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48966239094734193, 'Total loss': 0.48966239094734193} | train loss {'Reaction outcome loss': 0.3493192195076577, 'Total loss': 0.3493192195076577}
2023-01-05 14:45:52,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:52,934 INFO:     Epoch: 46
2023-01-05 14:45:55,024 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4568726321061452, 'Total loss': 0.4568726321061452} | train loss {'Reaction outcome loss': 0.34809085419469504, 'Total loss': 0.34809085419469504}
2023-01-05 14:45:55,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:55,024 INFO:     Epoch: 47
2023-01-05 14:45:57,128 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4448294925192992, 'Total loss': 0.4448294925192992} | train loss {'Reaction outcome loss': 0.34833242900560807, 'Total loss': 0.34833242900560807}
2023-01-05 14:45:57,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:57,129 INFO:     Epoch: 48
2023-01-05 14:45:59,242 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46571225523948667, 'Total loss': 0.46571225523948667} | train loss {'Reaction outcome loss': 0.3408253397384699, 'Total loss': 0.3408253397384699}
2023-01-05 14:45:59,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:45:59,242 INFO:     Epoch: 49
2023-01-05 14:46:01,356 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43847479422887164, 'Total loss': 0.43847479422887164} | train loss {'Reaction outcome loss': 0.33794308374941784, 'Total loss': 0.33794308374941784}
2023-01-05 14:46:01,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:01,356 INFO:     Epoch: 50
2023-01-05 14:46:03,494 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.462788858016332, 'Total loss': 0.462788858016332} | train loss {'Reaction outcome loss': 0.3378770941474142, 'Total loss': 0.3378770941474142}
2023-01-05 14:46:03,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:03,494 INFO:     Epoch: 51
2023-01-05 14:46:05,620 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4860830177863439, 'Total loss': 0.4860830177863439} | train loss {'Reaction outcome loss': 0.33697464242305636, 'Total loss': 0.33697464242305636}
2023-01-05 14:46:05,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:05,620 INFO:     Epoch: 52
2023-01-05 14:46:07,744 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4899648507436117, 'Total loss': 0.4899648507436117} | train loss {'Reaction outcome loss': 0.3361610763155631, 'Total loss': 0.3361610763155631}
2023-01-05 14:46:07,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:07,744 INFO:     Epoch: 53
2023-01-05 14:46:09,856 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4953773021697998, 'Total loss': 0.4953773021697998} | train loss {'Reaction outcome loss': 0.33424101814790796, 'Total loss': 0.33424101814790796}
2023-01-05 14:46:09,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:09,857 INFO:     Epoch: 54
2023-01-05 14:46:11,955 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4761150767405828, 'Total loss': 0.4761150767405828} | train loss {'Reaction outcome loss': 0.3287592045826851, 'Total loss': 0.3287592045826851}
2023-01-05 14:46:11,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:11,955 INFO:     Epoch: 55
2023-01-05 14:46:14,079 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4672131578127543, 'Total loss': 0.4672131578127543} | train loss {'Reaction outcome loss': 0.32667802536628976, 'Total loss': 0.32667802536628976}
2023-01-05 14:46:14,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:14,080 INFO:     Epoch: 56
2023-01-05 14:46:16,025 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4611685653527578, 'Total loss': 0.4611685653527578} | train loss {'Reaction outcome loss': 0.3231055547694003, 'Total loss': 0.3231055547694003}
2023-01-05 14:46:16,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:16,026 INFO:     Epoch: 57
2023-01-05 14:46:18,152 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.468851770957311, 'Total loss': 0.468851770957311} | train loss {'Reaction outcome loss': 0.31741267887290814, 'Total loss': 0.31741267887290814}
2023-01-05 14:46:18,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:18,153 INFO:     Epoch: 58
2023-01-05 14:46:20,269 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43746545414129895, 'Total loss': 0.43746545414129895} | train loss {'Reaction outcome loss': 0.3204745250026675, 'Total loss': 0.3204745250026675}
2023-01-05 14:46:20,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:20,270 INFO:     Epoch: 59
2023-01-05 14:46:22,367 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4547001401583354, 'Total loss': 0.4547001401583354} | train loss {'Reaction outcome loss': 0.3171998266076302, 'Total loss': 0.3171998266076302}
2023-01-05 14:46:22,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:22,367 INFO:     Epoch: 60
2023-01-05 14:46:24,520 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48914231061935426, 'Total loss': 0.48914231061935426} | train loss {'Reaction outcome loss': 0.3198771461586121, 'Total loss': 0.3198771461586121}
2023-01-05 14:46:24,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:24,521 INFO:     Epoch: 61
2023-01-05 14:46:26,671 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43627058068911234, 'Total loss': 0.43627058068911234} | train loss {'Reaction outcome loss': 0.3131234362503908, 'Total loss': 0.3131234362503908}
2023-01-05 14:46:26,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:26,671 INFO:     Epoch: 62
2023-01-05 14:46:28,784 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45863714814186096, 'Total loss': 0.45863714814186096} | train loss {'Reaction outcome loss': 0.31202685724209694, 'Total loss': 0.31202685724209694}
2023-01-05 14:46:28,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:28,785 INFO:     Epoch: 63
2023-01-05 14:46:30,899 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4284856388966242, 'Total loss': 0.4284856388966242} | train loss {'Reaction outcome loss': 0.305610124715162, 'Total loss': 0.305610124715162}
2023-01-05 14:46:30,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:30,899 INFO:     Epoch: 64
2023-01-05 14:46:33,021 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49758618474006655, 'Total loss': 0.49758618474006655} | train loss {'Reaction outcome loss': 0.30981189061472886, 'Total loss': 0.30981189061472886}
2023-01-05 14:46:33,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:33,022 INFO:     Epoch: 65
2023-01-05 14:46:35,130 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4294012089570363, 'Total loss': 0.4294012089570363} | train loss {'Reaction outcome loss': 0.3062146610451223, 'Total loss': 0.3062146610451223}
2023-01-05 14:46:35,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:35,130 INFO:     Epoch: 66
2023-01-05 14:46:37,244 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44548851251602173, 'Total loss': 0.44548851251602173} | train loss {'Reaction outcome loss': 0.3094452326831809, 'Total loss': 0.3094452326831809}
2023-01-05 14:46:37,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:37,245 INFO:     Epoch: 67
2023-01-05 14:46:39,355 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45514644384384156, 'Total loss': 0.45514644384384156} | train loss {'Reaction outcome loss': 0.30294624142294385, 'Total loss': 0.30294624142294385}
2023-01-05 14:46:39,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:39,355 INFO:     Epoch: 68
2023-01-05 14:46:41,476 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4183158869544665, 'Total loss': 0.4183158869544665} | train loss {'Reaction outcome loss': 0.2991607287341226, 'Total loss': 0.2991607287341226}
2023-01-05 14:46:41,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:41,476 INFO:     Epoch: 69
2023-01-05 14:46:43,621 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44221601684888207, 'Total loss': 0.44221601684888207} | train loss {'Reaction outcome loss': 0.29146355964297793, 'Total loss': 0.29146355964297793}
2023-01-05 14:46:43,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:43,621 INFO:     Epoch: 70
2023-01-05 14:46:45,778 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45078496138254803, 'Total loss': 0.45078496138254803} | train loss {'Reaction outcome loss': 0.29745625474755344, 'Total loss': 0.29745625474755344}
2023-01-05 14:46:45,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:45,778 INFO:     Epoch: 71
2023-01-05 14:46:47,907 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4573566277821859, 'Total loss': 0.4573566277821859} | train loss {'Reaction outcome loss': 0.2987321992914607, 'Total loss': 0.2987321992914607}
2023-01-05 14:46:47,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:47,908 INFO:     Epoch: 72
2023-01-05 14:46:50,050 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49491969545682274, 'Total loss': 0.49491969545682274} | train loss {'Reaction outcome loss': 0.2958565506621869, 'Total loss': 0.2958565506621869}
2023-01-05 14:46:50,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:50,051 INFO:     Epoch: 73
2023-01-05 14:46:52,178 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46935197214285534, 'Total loss': 0.46935197214285534} | train loss {'Reaction outcome loss': 0.2990382098776363, 'Total loss': 0.2990382098776363}
2023-01-05 14:46:52,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:52,178 INFO:     Epoch: 74
2023-01-05 14:46:54,319 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42776176730791726, 'Total loss': 0.42776176730791726} | train loss {'Reaction outcome loss': 0.2943022379202999, 'Total loss': 0.2943022379202999}
2023-01-05 14:46:54,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:54,319 INFO:     Epoch: 75
2023-01-05 14:46:56,458 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46939818461736044, 'Total loss': 0.46939818461736044} | train loss {'Reaction outcome loss': 0.28558193557780154, 'Total loss': 0.28558193557780154}
2023-01-05 14:46:56,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:56,459 INFO:     Epoch: 76
2023-01-05 14:46:58,604 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45929970145225524, 'Total loss': 0.45929970145225524} | train loss {'Reaction outcome loss': 0.2871131923348799, 'Total loss': 0.2871131923348799}
2023-01-05 14:46:58,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:46:58,604 INFO:     Epoch: 77
2023-01-05 14:47:00,748 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4434378445148468, 'Total loss': 0.4434378445148468} | train loss {'Reaction outcome loss': 0.2916787111737432, 'Total loss': 0.2916787111737432}
2023-01-05 14:47:00,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:00,748 INFO:     Epoch: 78
2023-01-05 14:47:02,899 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4778562724590302, 'Total loss': 0.4778562724590302} | train loss {'Reaction outcome loss': 0.2947961478528098, 'Total loss': 0.2947961478528098}
2023-01-05 14:47:02,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:02,899 INFO:     Epoch: 79
2023-01-05 14:47:05,051 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44581268057227136, 'Total loss': 0.44581268057227136} | train loss {'Reaction outcome loss': 0.28291901485165105, 'Total loss': 0.28291901485165105}
2023-01-05 14:47:05,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:05,051 INFO:     Epoch: 80
2023-01-05 14:47:07,197 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4340368062257767, 'Total loss': 0.4340368062257767} | train loss {'Reaction outcome loss': 0.2758757263204477, 'Total loss': 0.2758757263204477}
2023-01-05 14:47:07,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:07,197 INFO:     Epoch: 81
2023-01-05 14:47:09,329 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44458779791990916, 'Total loss': 0.44458779791990916} | train loss {'Reaction outcome loss': 0.27615619434492433, 'Total loss': 0.27615619434492433}
2023-01-05 14:47:09,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:09,330 INFO:     Epoch: 82
2023-01-05 14:47:11,481 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4565086394548416, 'Total loss': 0.4565086394548416} | train loss {'Reaction outcome loss': 0.28235290898350035, 'Total loss': 0.28235290898350035}
2023-01-05 14:47:11,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:11,481 INFO:     Epoch: 83
2023-01-05 14:47:13,634 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4409345100323359, 'Total loss': 0.4409345100323359} | train loss {'Reaction outcome loss': 0.278434562761962, 'Total loss': 0.278434562761962}
2023-01-05 14:47:13,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:13,634 INFO:     Epoch: 84
2023-01-05 14:47:15,788 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43632583518822987, 'Total loss': 0.43632583518822987} | train loss {'Reaction outcome loss': 0.28106135774376617, 'Total loss': 0.28106135774376617}
2023-01-05 14:47:15,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:15,789 INFO:     Epoch: 85
2023-01-05 14:47:17,946 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47663746202985446, 'Total loss': 0.47663746202985446} | train loss {'Reaction outcome loss': 0.26934133338857524, 'Total loss': 0.26934133338857524}
2023-01-05 14:47:17,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:17,947 INFO:     Epoch: 86
2023-01-05 14:47:20,107 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4495663364728292, 'Total loss': 0.4495663364728292} | train loss {'Reaction outcome loss': 0.27771186597482134, 'Total loss': 0.27771186597482134}
2023-01-05 14:47:20,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:20,107 INFO:     Epoch: 87
2023-01-05 14:47:22,237 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41714179813861846, 'Total loss': 0.41714179813861846} | train loss {'Reaction outcome loss': 0.26906990068182896, 'Total loss': 0.26906990068182896}
2023-01-05 14:47:22,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:22,237 INFO:     Epoch: 88
2023-01-05 14:47:24,397 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47342730561892193, 'Total loss': 0.47342730561892193} | train loss {'Reaction outcome loss': 0.2707187938945789, 'Total loss': 0.2707187938945789}
2023-01-05 14:47:24,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:24,397 INFO:     Epoch: 89
2023-01-05 14:47:26,546 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46613674362500507, 'Total loss': 0.46613674362500507} | train loss {'Reaction outcome loss': 0.2798063531076114, 'Total loss': 0.2798063531076114}
2023-01-05 14:47:26,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:26,547 INFO:     Epoch: 90
2023-01-05 14:47:28,673 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45347807208697, 'Total loss': 0.45347807208697} | train loss {'Reaction outcome loss': 0.2692914417006728, 'Total loss': 0.2692914417006728}
2023-01-05 14:47:28,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:28,673 INFO:     Epoch: 91
2023-01-05 14:47:30,800 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.462617552280426, 'Total loss': 0.462617552280426} | train loss {'Reaction outcome loss': 0.2649698244224228, 'Total loss': 0.2649698244224228}
2023-01-05 14:47:30,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:30,800 INFO:     Epoch: 92
2023-01-05 14:47:32,928 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5026431222756703, 'Total loss': 0.5026431222756703} | train loss {'Reaction outcome loss': 0.27193686667911326, 'Total loss': 0.27193686667911326}
2023-01-05 14:47:32,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:32,929 INFO:     Epoch: 93
2023-01-05 14:47:35,060 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4258242110411326, 'Total loss': 0.4258242110411326} | train loss {'Reaction outcome loss': 0.2603187697062636, 'Total loss': 0.2603187697062636}
2023-01-05 14:47:35,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:35,060 INFO:     Epoch: 94
2023-01-05 14:47:37,174 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47768160700798035, 'Total loss': 0.47768160700798035} | train loss {'Reaction outcome loss': 0.26207324353991635, 'Total loss': 0.26207324353991635}
2023-01-05 14:47:37,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:37,174 INFO:     Epoch: 95
2023-01-05 14:47:39,317 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4395351101954778, 'Total loss': 0.4395351101954778} | train loss {'Reaction outcome loss': 0.26330109612921077, 'Total loss': 0.26330109612921077}
2023-01-05 14:47:39,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:39,318 INFO:     Epoch: 96
2023-01-05 14:47:41,496 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48629846374193825, 'Total loss': 0.48629846374193825} | train loss {'Reaction outcome loss': 0.25368923235711827, 'Total loss': 0.25368923235711827}
2023-01-05 14:47:41,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:41,497 INFO:     Epoch: 97
2023-01-05 14:47:43,652 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46848734418551125, 'Total loss': 0.46848734418551125} | train loss {'Reaction outcome loss': 0.26545238894593975, 'Total loss': 0.26545238894593975}
2023-01-05 14:47:43,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:43,652 INFO:     Epoch: 98
2023-01-05 14:47:45,778 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42295294602711997, 'Total loss': 0.42295294602711997} | train loss {'Reaction outcome loss': 0.25419099520157723, 'Total loss': 0.25419099520157723}
2023-01-05 14:47:45,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:45,779 INFO:     Epoch: 99
2023-01-05 14:47:47,941 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43642459909121195, 'Total loss': 0.43642459909121195} | train loss {'Reaction outcome loss': 0.2591232371101849, 'Total loss': 0.2591232371101849}
2023-01-05 14:47:47,941 INFO:     Best model found after epoch 39 of 100.
2023-01-05 14:47:47,942 INFO:   Done with stage: TRAINING
2023-01-05 14:47:47,942 INFO:   Starting stage: EVALUATION
2023-01-05 14:47:48,080 INFO:   Done with stage: EVALUATION
2023-01-05 14:47:48,080 INFO:   Leaving out SEQ value Fold_9
2023-01-05 14:47:48,093 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 14:47:48,093 INFO:   Starting stage: FEATURE SCALING
2023-01-05 14:47:48,734 INFO:   Done with stage: FEATURE SCALING
2023-01-05 14:47:48,734 INFO:   Starting stage: SCALING TARGETS
2023-01-05 14:47:48,803 INFO:   Done with stage: SCALING TARGETS
2023-01-05 14:47:48,803 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:47:48,803 INFO:     No hyperparam tuning for this model
2023-01-05 14:47:48,803 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:47:48,803 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 14:47:48,804 INFO:     None feature selector for col prot
2023-01-05 14:47:48,804 INFO:     None feature selector for col prot
2023-01-05 14:47:48,804 INFO:     None feature selector for col prot
2023-01-05 14:47:48,804 INFO:     None feature selector for col chem
2023-01-05 14:47:48,804 INFO:     None feature selector for col chem
2023-01-05 14:47:48,805 INFO:     None feature selector for col chem
2023-01-05 14:47:48,805 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 14:47:48,805 INFO:   Starting stage: BUILD MODEL
2023-01-05 14:47:48,806 INFO:     Number of params in model 72901
2023-01-05 14:47:48,809 INFO:   Done with stage: BUILD MODEL
2023-01-05 14:47:48,809 INFO:   Starting stage: TRAINING
2023-01-05 14:47:48,868 INFO:     Val loss before train {'Reaction outcome loss': 1.015080420176188, 'Total loss': 1.015080420176188}
2023-01-05 14:47:48,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:48,868 INFO:     Epoch: 0
2023-01-05 14:47:50,966 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8378675619761149, 'Total loss': 0.8378675619761149} | train loss {'Reaction outcome loss': 0.920723598315448, 'Total loss': 0.920723598315448}
2023-01-05 14:47:50,966 INFO:     Found new best model at epoch 0
2023-01-05 14:47:50,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:50,968 INFO:     Epoch: 1
2023-01-05 14:47:53,135 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6743775924046834, 'Total loss': 0.6743775924046834} | train loss {'Reaction outcome loss': 0.7637007306667342, 'Total loss': 0.7637007306667342}
2023-01-05 14:47:53,135 INFO:     Found new best model at epoch 1
2023-01-05 14:47:53,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:53,136 INFO:     Epoch: 2
2023-01-05 14:47:55,295 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.558885371685028, 'Total loss': 0.558885371685028} | train loss {'Reaction outcome loss': 0.5958773134600209, 'Total loss': 0.5958773134600209}
2023-01-05 14:47:55,295 INFO:     Found new best model at epoch 2
2023-01-05 14:47:55,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:55,297 INFO:     Epoch: 3
2023-01-05 14:47:57,438 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5687524318695069, 'Total loss': 0.5687524318695069} | train loss {'Reaction outcome loss': 0.5290562604567495, 'Total loss': 0.5290562604567495}
2023-01-05 14:47:57,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:57,440 INFO:     Epoch: 4
2023-01-05 14:47:59,600 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5014131079117458, 'Total loss': 0.5014131079117458} | train loss {'Reaction outcome loss': 0.5111755834845151, 'Total loss': 0.5111755834845151}
2023-01-05 14:47:59,600 INFO:     Found new best model at epoch 4
2023-01-05 14:47:59,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:47:59,601 INFO:     Epoch: 5
2023-01-05 14:48:01,753 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.527678120136261, 'Total loss': 0.527678120136261} | train loss {'Reaction outcome loss': 0.4903138910076055, 'Total loss': 0.4903138910076055}
2023-01-05 14:48:01,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:01,753 INFO:     Epoch: 6
2023-01-05 14:48:03,890 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.546613876024882, 'Total loss': 0.546613876024882} | train loss {'Reaction outcome loss': 0.4822339896238118, 'Total loss': 0.4822339896238118}
2023-01-05 14:48:03,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:03,891 INFO:     Epoch: 7
2023-01-05 14:48:06,047 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5102493127187093, 'Total loss': 0.5102493127187093} | train loss {'Reaction outcome loss': 0.47491327042086556, 'Total loss': 0.47491327042086556}
2023-01-05 14:48:06,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:06,047 INFO:     Epoch: 8
2023-01-05 14:48:08,179 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5196775356928508, 'Total loss': 0.5196775356928508} | train loss {'Reaction outcome loss': 0.4680302143220299, 'Total loss': 0.4680302143220299}
2023-01-05 14:48:08,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:08,180 INFO:     Epoch: 9
2023-01-05 14:48:10,325 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4986408034960429, 'Total loss': 0.4986408034960429} | train loss {'Reaction outcome loss': 0.4594225115191269, 'Total loss': 0.4594225115191269}
2023-01-05 14:48:10,325 INFO:     Found new best model at epoch 9
2023-01-05 14:48:10,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:10,327 INFO:     Epoch: 10
2023-01-05 14:48:12,472 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4858733654022217, 'Total loss': 0.4858733654022217} | train loss {'Reaction outcome loss': 0.4566616417732144, 'Total loss': 0.4566616417732144}
2023-01-05 14:48:12,472 INFO:     Found new best model at epoch 10
2023-01-05 14:48:12,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:12,474 INFO:     Epoch: 11
2023-01-05 14:48:14,604 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47783130208651226, 'Total loss': 0.47783130208651226} | train loss {'Reaction outcome loss': 0.4487877140577505, 'Total loss': 0.4487877140577505}
2023-01-05 14:48:14,604 INFO:     Found new best model at epoch 11
2023-01-05 14:48:14,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:14,605 INFO:     Epoch: 12
2023-01-05 14:48:16,753 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47746259172757466, 'Total loss': 0.47746259172757466} | train loss {'Reaction outcome loss': 0.45123647102087305, 'Total loss': 0.45123647102087305}
2023-01-05 14:48:16,754 INFO:     Found new best model at epoch 12
2023-01-05 14:48:16,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:16,755 INFO:     Epoch: 13
2023-01-05 14:48:18,900 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.472413303454717, 'Total loss': 0.472413303454717} | train loss {'Reaction outcome loss': 0.44310973644546786, 'Total loss': 0.44310973644546786}
2023-01-05 14:48:18,900 INFO:     Found new best model at epoch 13
2023-01-05 14:48:18,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:18,901 INFO:     Epoch: 14
2023-01-05 14:48:21,064 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4780783752600352, 'Total loss': 0.4780783752600352} | train loss {'Reaction outcome loss': 0.44136885774956236, 'Total loss': 0.44136885774956236}
2023-01-05 14:48:21,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:21,064 INFO:     Epoch: 15
2023-01-05 14:48:23,208 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4861763596534729, 'Total loss': 0.4861763596534729} | train loss {'Reaction outcome loss': 0.4411383195361797, 'Total loss': 0.4411383195361797}
2023-01-05 14:48:23,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:23,209 INFO:     Epoch: 16
2023-01-05 14:48:25,399 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4702444652716319, 'Total loss': 0.4702444652716319} | train loss {'Reaction outcome loss': 0.4499816398905671, 'Total loss': 0.4499816398905671}
2023-01-05 14:48:25,399 INFO:     Found new best model at epoch 16
2023-01-05 14:48:25,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:25,401 INFO:     Epoch: 17
2023-01-05 14:48:27,566 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49101433853308357, 'Total loss': 0.49101433853308357} | train loss {'Reaction outcome loss': 0.45755813991569955, 'Total loss': 0.45755813991569955}
2023-01-05 14:48:27,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:27,567 INFO:     Epoch: 18
2023-01-05 14:48:29,740 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48666664163271584, 'Total loss': 0.48666664163271584} | train loss {'Reaction outcome loss': 0.4278912592031386, 'Total loss': 0.4278912592031386}
2023-01-05 14:48:29,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:29,740 INFO:     Epoch: 19
2023-01-05 14:48:31,921 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5018241355816523, 'Total loss': 0.5018241355816523} | train loss {'Reaction outcome loss': 0.4225485475990749, 'Total loss': 0.4225485475990749}
2023-01-05 14:48:31,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:31,923 INFO:     Epoch: 20
2023-01-05 14:48:34,128 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4855340967575709, 'Total loss': 0.4855340967575709} | train loss {'Reaction outcome loss': 0.42160041332649795, 'Total loss': 0.42160041332649795}
2023-01-05 14:48:34,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:34,128 INFO:     Epoch: 21
2023-01-05 14:48:36,320 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.514989439646403, 'Total loss': 0.514989439646403} | train loss {'Reaction outcome loss': 0.4153586685205337, 'Total loss': 0.4153586685205337}
2023-01-05 14:48:36,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:36,320 INFO:     Epoch: 22
2023-01-05 14:48:38,503 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47678617437680565, 'Total loss': 0.47678617437680565} | train loss {'Reaction outcome loss': 0.4322215579180182, 'Total loss': 0.4322215579180182}
2023-01-05 14:48:38,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:38,504 INFO:     Epoch: 23
2023-01-05 14:48:40,690 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44359658161799115, 'Total loss': 0.44359658161799115} | train loss {'Reaction outcome loss': 0.404113527637083, 'Total loss': 0.404113527637083}
2023-01-05 14:48:40,690 INFO:     Found new best model at epoch 23
2023-01-05 14:48:40,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:40,692 INFO:     Epoch: 24
2023-01-05 14:48:42,840 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5048007269700369, 'Total loss': 0.5048007269700369} | train loss {'Reaction outcome loss': 0.3994365075731353, 'Total loss': 0.3994365075731353}
2023-01-05 14:48:42,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:42,840 INFO:     Epoch: 25
2023-01-05 14:48:44,985 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4563975214958191, 'Total loss': 0.4563975214958191} | train loss {'Reaction outcome loss': 0.4199366060935933, 'Total loss': 0.4199366060935933}
2023-01-05 14:48:44,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:44,985 INFO:     Epoch: 26
2023-01-05 14:48:47,131 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4754839340845744, 'Total loss': 0.4754839340845744} | train loss {'Reaction outcome loss': 0.4096508839478095, 'Total loss': 0.4096508839478095}
2023-01-05 14:48:47,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:47,131 INFO:     Epoch: 27
2023-01-05 14:48:49,301 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45981949468453726, 'Total loss': 0.45981949468453726} | train loss {'Reaction outcome loss': 0.3927214649570026, 'Total loss': 0.3927214649570026}
2023-01-05 14:48:49,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:49,302 INFO:     Epoch: 28
2023-01-05 14:48:51,459 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4598221252361933, 'Total loss': 0.4598221252361933} | train loss {'Reaction outcome loss': 0.38519042177949153, 'Total loss': 0.38519042177949153}
2023-01-05 14:48:51,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:51,460 INFO:     Epoch: 29
2023-01-05 14:48:53,602 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44219480752944945, 'Total loss': 0.44219480752944945} | train loss {'Reaction outcome loss': 0.38715701403123315, 'Total loss': 0.38715701403123315}
2023-01-05 14:48:53,602 INFO:     Found new best model at epoch 29
2023-01-05 14:48:53,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:53,603 INFO:     Epoch: 30
2023-01-05 14:48:55,761 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4729876299699148, 'Total loss': 0.4729876299699148} | train loss {'Reaction outcome loss': 0.3766131391580068, 'Total loss': 0.3766131391580068}
2023-01-05 14:48:55,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:55,762 INFO:     Epoch: 31
2023-01-05 14:48:57,898 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47060174147288003, 'Total loss': 0.47060174147288003} | train loss {'Reaction outcome loss': 0.3754622346714841, 'Total loss': 0.3754622346714841}
2023-01-05 14:48:57,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:48:57,898 INFO:     Epoch: 32
2023-01-05 14:49:00,049 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4642938137054443, 'Total loss': 0.4642938137054443} | train loss {'Reaction outcome loss': 0.3775120283058588, 'Total loss': 0.3775120283058588}
2023-01-05 14:49:00,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:00,049 INFO:     Epoch: 33
2023-01-05 14:49:02,193 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48487560749053954, 'Total loss': 0.48487560749053954} | train loss {'Reaction outcome loss': 0.3916462938810793, 'Total loss': 0.3916462938810793}
2023-01-05 14:49:02,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:02,193 INFO:     Epoch: 34
2023-01-05 14:49:04,333 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44396509130795797, 'Total loss': 0.44396509130795797} | train loss {'Reaction outcome loss': 0.3655141154508717, 'Total loss': 0.3655141154508717}
2023-01-05 14:49:04,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:04,333 INFO:     Epoch: 35
2023-01-05 14:49:06,474 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45900697112083433, 'Total loss': 0.45900697112083433} | train loss {'Reaction outcome loss': 0.36237233326736523, 'Total loss': 0.36237233326736523}
2023-01-05 14:49:06,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:06,474 INFO:     Epoch: 36
2023-01-05 14:49:08,630 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4579525242249171, 'Total loss': 0.4579525242249171} | train loss {'Reaction outcome loss': 0.3545808076379362, 'Total loss': 0.3545808076379362}
2023-01-05 14:49:08,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:08,631 INFO:     Epoch: 37
2023-01-05 14:49:10,752 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4348466694355011, 'Total loss': 0.4348466694355011} | train loss {'Reaction outcome loss': 0.3533860239260083, 'Total loss': 0.3533860239260083}
2023-01-05 14:49:10,752 INFO:     Found new best model at epoch 37
2023-01-05 14:49:10,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:10,753 INFO:     Epoch: 38
2023-01-05 14:49:12,903 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.502649121483167, 'Total loss': 0.502649121483167} | train loss {'Reaction outcome loss': 0.3526086542905946, 'Total loss': 0.3526086542905946}
2023-01-05 14:49:12,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:12,903 INFO:     Epoch: 39
2023-01-05 14:49:15,042 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4442790220181147, 'Total loss': 0.4442790220181147} | train loss {'Reaction outcome loss': 0.34953496682093194, 'Total loss': 0.34953496682093194}
2023-01-05 14:49:15,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:15,043 INFO:     Epoch: 40
2023-01-05 14:49:17,183 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4166841169198354, 'Total loss': 0.4166841169198354} | train loss {'Reaction outcome loss': 0.350933821628923, 'Total loss': 0.350933821628923}
2023-01-05 14:49:17,184 INFO:     Found new best model at epoch 40
2023-01-05 14:49:17,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:17,185 INFO:     Epoch: 41
2023-01-05 14:49:19,320 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42009046326080957, 'Total loss': 0.42009046326080957} | train loss {'Reaction outcome loss': 0.3802902878775532, 'Total loss': 0.3802902878775532}
2023-01-05 14:49:19,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:19,320 INFO:     Epoch: 42
2023-01-05 14:49:21,435 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43522888123989106, 'Total loss': 0.43522888123989106} | train loss {'Reaction outcome loss': 0.35435958358752745, 'Total loss': 0.35435958358752745}
2023-01-05 14:49:21,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:21,436 INFO:     Epoch: 43
2023-01-05 14:49:23,579 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4526693090796471, 'Total loss': 0.4526693090796471} | train loss {'Reaction outcome loss': 0.3506654086590245, 'Total loss': 0.3506654086590245}
2023-01-05 14:49:23,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:23,579 INFO:     Epoch: 44
2023-01-05 14:49:25,710 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40926994880040485, 'Total loss': 0.40926994880040485} | train loss {'Reaction outcome loss': 0.3632396542478987, 'Total loss': 0.3632396542478987}
2023-01-05 14:49:25,710 INFO:     Found new best model at epoch 44
2023-01-05 14:49:25,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:25,711 INFO:     Epoch: 45
2023-01-05 14:49:27,825 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4113378137350082, 'Total loss': 0.4113378137350082} | train loss {'Reaction outcome loss': 0.3395589584074712, 'Total loss': 0.3395589584074712}
2023-01-05 14:49:27,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:27,826 INFO:     Epoch: 46
2023-01-05 14:49:29,971 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3926925897598267, 'Total loss': 0.3926925897598267} | train loss {'Reaction outcome loss': 0.3297413385581171, 'Total loss': 0.3297413385581171}
2023-01-05 14:49:29,972 INFO:     Found new best model at epoch 46
2023-01-05 14:49:29,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:29,973 INFO:     Epoch: 47
2023-01-05 14:49:32,119 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4197783648967743, 'Total loss': 0.4197783648967743} | train loss {'Reaction outcome loss': 0.3249362616378399, 'Total loss': 0.3249362616378399}
2023-01-05 14:49:32,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:32,119 INFO:     Epoch: 48
2023-01-05 14:49:34,277 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44107062816619874, 'Total loss': 0.44107062816619874} | train loss {'Reaction outcome loss': 0.3300067994851565, 'Total loss': 0.3300067994851565}
2023-01-05 14:49:34,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:34,278 INFO:     Epoch: 49
2023-01-05 14:49:36,441 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4316720505555471, 'Total loss': 0.4316720505555471} | train loss {'Reaction outcome loss': 0.3219730841127508, 'Total loss': 0.3219730841127508}
2023-01-05 14:49:36,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:36,442 INFO:     Epoch: 50
2023-01-05 14:49:38,588 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41040607790152234, 'Total loss': 0.41040607790152234} | train loss {'Reaction outcome loss': 0.32454227984619693, 'Total loss': 0.32454227984619693}
2023-01-05 14:49:38,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:38,589 INFO:     Epoch: 51
2023-01-05 14:49:40,739 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4062598009904226, 'Total loss': 0.4062598009904226} | train loss {'Reaction outcome loss': 0.31498622029061074, 'Total loss': 0.31498622029061074}
2023-01-05 14:49:40,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:40,740 INFO:     Epoch: 52
2023-01-05 14:49:42,882 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44790162245432535, 'Total loss': 0.44790162245432535} | train loss {'Reaction outcome loss': 0.3123726031753113, 'Total loss': 0.3123726031753113}
2023-01-05 14:49:42,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:42,883 INFO:     Epoch: 53
2023-01-05 14:49:45,028 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39333127240339916, 'Total loss': 0.39333127240339916} | train loss {'Reaction outcome loss': 0.3092280452576655, 'Total loss': 0.3092280452576655}
2023-01-05 14:49:45,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:45,029 INFO:     Epoch: 54
2023-01-05 14:49:47,183 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4143384099006653, 'Total loss': 0.4143384099006653} | train loss {'Reaction outcome loss': 0.3112435430639248, 'Total loss': 0.3112435430639248}
2023-01-05 14:49:47,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:47,184 INFO:     Epoch: 55
2023-01-05 14:49:49,317 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4115945835908254, 'Total loss': 0.4115945835908254} | train loss {'Reaction outcome loss': 0.31991873113303515, 'Total loss': 0.31991873113303515}
2023-01-05 14:49:49,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:49,317 INFO:     Epoch: 56
2023-01-05 14:49:51,445 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41145629187424976, 'Total loss': 0.41145629187424976} | train loss {'Reaction outcome loss': 0.3088773406620601, 'Total loss': 0.3088773406620601}
2023-01-05 14:49:51,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:51,446 INFO:     Epoch: 57
2023-01-05 14:49:53,592 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38746864994366964, 'Total loss': 0.38746864994366964} | train loss {'Reaction outcome loss': 0.30057829297173, 'Total loss': 0.30057829297173}
2023-01-05 14:49:53,592 INFO:     Found new best model at epoch 57
2023-01-05 14:49:53,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:53,593 INFO:     Epoch: 58
2023-01-05 14:49:55,751 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43278112411499026, 'Total loss': 0.43278112411499026} | train loss {'Reaction outcome loss': 0.28926085847416433, 'Total loss': 0.28926085847416433}
2023-01-05 14:49:55,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:55,751 INFO:     Epoch: 59
2023-01-05 14:49:57,898 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41258763472239174, 'Total loss': 0.41258763472239174} | train loss {'Reaction outcome loss': 0.30742113529771997, 'Total loss': 0.30742113529771997}
2023-01-05 14:49:57,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:49:57,899 INFO:     Epoch: 60
2023-01-05 14:50:00,027 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42166396578152976, 'Total loss': 0.42166396578152976} | train loss {'Reaction outcome loss': 0.302539585225716, 'Total loss': 0.302539585225716}
2023-01-05 14:50:00,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:00,027 INFO:     Epoch: 61
2023-01-05 14:50:02,161 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3844276785850525, 'Total loss': 0.3844276785850525} | train loss {'Reaction outcome loss': 0.2928361294241082, 'Total loss': 0.2928361294241082}
2023-01-05 14:50:02,161 INFO:     Found new best model at epoch 61
2023-01-05 14:50:02,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:02,163 INFO:     Epoch: 62
2023-01-05 14:50:04,316 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42718185583750407, 'Total loss': 0.42718185583750407} | train loss {'Reaction outcome loss': 0.29248427176355396, 'Total loss': 0.29248427176355396}
2023-01-05 14:50:04,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:04,316 INFO:     Epoch: 63
2023-01-05 14:50:06,493 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42281646927197775, 'Total loss': 0.42281646927197775} | train loss {'Reaction outcome loss': 0.3004876590887274, 'Total loss': 0.3004876590887274}
2023-01-05 14:50:06,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:06,493 INFO:     Epoch: 64
2023-01-05 14:50:08,636 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4014842371145884, 'Total loss': 0.4014842371145884} | train loss {'Reaction outcome loss': 0.3159881851104834, 'Total loss': 0.3159881851104834}
2023-01-05 14:50:08,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:08,636 INFO:     Epoch: 65
2023-01-05 14:50:10,800 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41154943108558656, 'Total loss': 0.41154943108558656} | train loss {'Reaction outcome loss': 0.3059223283595149, 'Total loss': 0.3059223283595149}
2023-01-05 14:50:10,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:10,801 INFO:     Epoch: 66
2023-01-05 14:50:12,930 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3938802187641462, 'Total loss': 0.3938802187641462} | train loss {'Reaction outcome loss': 0.2901596361939944, 'Total loss': 0.2901596361939944}
2023-01-05 14:50:12,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:12,930 INFO:     Epoch: 67
2023-01-05 14:50:15,108 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38844264497359593, 'Total loss': 0.38844264497359593} | train loss {'Reaction outcome loss': 0.2863169596984981, 'Total loss': 0.2863169596984981}
2023-01-05 14:50:15,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:15,109 INFO:     Epoch: 68
2023-01-05 14:50:17,315 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.480849156777064, 'Total loss': 0.480849156777064} | train loss {'Reaction outcome loss': 0.28659876230834186, 'Total loss': 0.28659876230834186}
2023-01-05 14:50:17,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:17,315 INFO:     Epoch: 69
2023-01-05 14:50:19,379 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4896484871705373, 'Total loss': 0.4896484871705373} | train loss {'Reaction outcome loss': 0.29186570103185816, 'Total loss': 0.29186570103185816}
2023-01-05 14:50:19,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:19,379 INFO:     Epoch: 70
2023-01-05 14:50:21,402 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44121249914169314, 'Total loss': 0.44121249914169314} | train loss {'Reaction outcome loss': 0.2797261115378044, 'Total loss': 0.2797261115378044}
2023-01-05 14:50:21,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:21,403 INFO:     Epoch: 71
2023-01-05 14:50:23,584 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.432101845741272, 'Total loss': 0.432101845741272} | train loss {'Reaction outcome loss': 0.27721147824848996, 'Total loss': 0.27721147824848996}
2023-01-05 14:50:23,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:23,584 INFO:     Epoch: 72
2023-01-05 14:50:25,716 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4082024052739143, 'Total loss': 0.4082024052739143} | train loss {'Reaction outcome loss': 0.28199844701094146, 'Total loss': 0.28199844701094146}
2023-01-05 14:50:25,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:25,716 INFO:     Epoch: 73
2023-01-05 14:50:27,853 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3719674997031689, 'Total loss': 0.3719674997031689} | train loss {'Reaction outcome loss': 0.27747376537139434, 'Total loss': 0.27747376537139434}
2023-01-05 14:50:27,853 INFO:     Found new best model at epoch 73
2023-01-05 14:50:27,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:27,855 INFO:     Epoch: 74
2023-01-05 14:50:30,000 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39029069741566974, 'Total loss': 0.39029069741566974} | train loss {'Reaction outcome loss': 0.2794311550847403, 'Total loss': 0.2794311550847403}
2023-01-05 14:50:30,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:30,001 INFO:     Epoch: 75
2023-01-05 14:50:32,137 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.424598823984464, 'Total loss': 0.424598823984464} | train loss {'Reaction outcome loss': 0.2725022272139356, 'Total loss': 0.2725022272139356}
2023-01-05 14:50:32,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:32,137 INFO:     Epoch: 76
2023-01-05 14:50:34,287 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4488554189602534, 'Total loss': 0.4488554189602534} | train loss {'Reaction outcome loss': 0.3383046802221055, 'Total loss': 0.3383046802221055}
2023-01-05 14:50:34,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:34,288 INFO:     Epoch: 77
2023-01-05 14:50:36,428 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43549001614252725, 'Total loss': 0.43549001614252725} | train loss {'Reaction outcome loss': 0.2839424047752813, 'Total loss': 0.2839424047752813}
2023-01-05 14:50:36,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:36,428 INFO:     Epoch: 78
2023-01-05 14:50:38,580 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40574870904286703, 'Total loss': 0.40574870904286703} | train loss {'Reaction outcome loss': 0.2756652276228229, 'Total loss': 0.2756652276228229}
2023-01-05 14:50:38,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:38,580 INFO:     Epoch: 79
2023-01-05 14:50:40,725 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41047193507353463, 'Total loss': 0.41047193507353463} | train loss {'Reaction outcome loss': 0.27409304272167495, 'Total loss': 0.27409304272167495}
2023-01-05 14:50:40,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:40,725 INFO:     Epoch: 80
2023-01-05 14:50:42,885 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40633793771266935, 'Total loss': 0.40633793771266935} | train loss {'Reaction outcome loss': 0.27555010763087234, 'Total loss': 0.27555010763087234}
2023-01-05 14:50:42,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:42,885 INFO:     Epoch: 81
2023-01-05 14:50:45,028 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4282572646935781, 'Total loss': 0.4282572646935781} | train loss {'Reaction outcome loss': 0.2683915633816218, 'Total loss': 0.2683915633816218}
2023-01-05 14:50:45,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:45,030 INFO:     Epoch: 82
2023-01-05 14:50:47,176 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4080089608828227, 'Total loss': 0.4080089608828227} | train loss {'Reaction outcome loss': 0.2672826341628367, 'Total loss': 0.2672826341628367}
2023-01-05 14:50:47,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:47,177 INFO:     Epoch: 83
2023-01-05 14:50:49,293 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40594588220119476, 'Total loss': 0.40594588220119476} | train loss {'Reaction outcome loss': 0.2602805770407228, 'Total loss': 0.2602805770407228}
2023-01-05 14:50:49,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:49,293 INFO:     Epoch: 84
2023-01-05 14:50:51,438 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43581373393535616, 'Total loss': 0.43581373393535616} | train loss {'Reaction outcome loss': 0.29275026338303217, 'Total loss': 0.29275026338303217}
2023-01-05 14:50:51,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:51,439 INFO:     Epoch: 85
2023-01-05 14:50:53,597 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4518533597389857, 'Total loss': 0.4518533597389857} | train loss {'Reaction outcome loss': 0.26305953186997416, 'Total loss': 0.26305953186997416}
2023-01-05 14:50:53,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:53,597 INFO:     Epoch: 86
2023-01-05 14:50:55,739 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4227455536524455, 'Total loss': 0.4227455536524455} | train loss {'Reaction outcome loss': 0.26894333618996746, 'Total loss': 0.26894333618996746}
2023-01-05 14:50:55,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:55,739 INFO:     Epoch: 87
2023-01-05 14:50:57,869 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46631817569335304, 'Total loss': 0.46631817569335304} | train loss {'Reaction outcome loss': 0.2608461727074388, 'Total loss': 0.2608461727074388}
2023-01-05 14:50:57,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:50:57,869 INFO:     Epoch: 88
2023-01-05 14:51:00,021 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4250663553675016, 'Total loss': 0.4250663553675016} | train loss {'Reaction outcome loss': 0.2682313584457692, 'Total loss': 0.2682313584457692}
2023-01-05 14:51:00,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:00,021 INFO:     Epoch: 89
2023-01-05 14:51:02,172 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4385558267434438, 'Total loss': 0.4385558267434438} | train loss {'Reaction outcome loss': 0.2665998572778915, 'Total loss': 0.2665998572778915}
2023-01-05 14:51:02,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:02,173 INFO:     Epoch: 90
2023-01-05 14:51:04,318 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4093748092651367, 'Total loss': 0.4093748092651367} | train loss {'Reaction outcome loss': 0.26173937817266973, 'Total loss': 0.26173937817266973}
2023-01-05 14:51:04,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:04,319 INFO:     Epoch: 91
2023-01-05 14:51:06,479 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4218084514141083, 'Total loss': 0.4218084514141083} | train loss {'Reaction outcome loss': 0.25218565729143017, 'Total loss': 0.25218565729143017}
2023-01-05 14:51:06,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:06,479 INFO:     Epoch: 92
2023-01-05 14:51:08,637 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37977339575688046, 'Total loss': 0.37977339575688046} | train loss {'Reaction outcome loss': 0.25990529714719107, 'Total loss': 0.25990529714719107}
2023-01-05 14:51:08,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:08,637 INFO:     Epoch: 93
2023-01-05 14:51:10,788 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3948523799578349, 'Total loss': 0.3948523799578349} | train loss {'Reaction outcome loss': 0.27171314449979167, 'Total loss': 0.27171314449979167}
2023-01-05 14:51:10,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:10,789 INFO:     Epoch: 94
2023-01-05 14:51:12,914 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44314177334308624, 'Total loss': 0.44314177334308624} | train loss {'Reaction outcome loss': 0.2534472515901038, 'Total loss': 0.2534472515901038}
2023-01-05 14:51:12,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:12,914 INFO:     Epoch: 95
2023-01-05 14:51:15,051 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4539789378643036, 'Total loss': 0.4539789378643036} | train loss {'Reaction outcome loss': 0.26248019228017033, 'Total loss': 0.26248019228017033}
2023-01-05 14:51:15,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:15,051 INFO:     Epoch: 96
2023-01-05 14:51:17,193 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4235332493980726, 'Total loss': 0.4235332493980726} | train loss {'Reaction outcome loss': 0.2510675659308143, 'Total loss': 0.2510675659308143}
2023-01-05 14:51:17,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:17,193 INFO:     Epoch: 97
2023-01-05 14:51:19,316 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4336302767197291, 'Total loss': 0.4336302767197291} | train loss {'Reaction outcome loss': 0.2515275177302892, 'Total loss': 0.2515275177302892}
2023-01-05 14:51:19,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:19,316 INFO:     Epoch: 98
2023-01-05 14:51:21,439 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3756970261534055, 'Total loss': 0.3756970261534055} | train loss {'Reaction outcome loss': 0.2593651666074816, 'Total loss': 0.2593651666074816}
2023-01-05 14:51:21,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:21,440 INFO:     Epoch: 99
2023-01-05 14:51:23,551 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4108057638009389, 'Total loss': 0.4108057638009389} | train loss {'Reaction outcome loss': 0.2509692782988313, 'Total loss': 0.2509692782988313}
2023-01-05 14:51:23,551 INFO:     Best model found after epoch 74 of 100.
2023-01-05 14:51:23,551 INFO:   Done with stage: TRAINING
2023-01-05 14:51:23,551 INFO:   Starting stage: EVALUATION
2023-01-05 14:51:23,683 INFO:   Done with stage: EVALUATION
2023-01-05 14:51:23,691 INFO:   Leaving out SEQ value Fold_0
2023-01-05 14:51:23,704 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-05 14:51:23,704 INFO:   Starting stage: FEATURE SCALING
2023-01-05 14:51:24,345 INFO:   Done with stage: FEATURE SCALING
2023-01-05 14:51:24,345 INFO:   Starting stage: SCALING TARGETS
2023-01-05 14:51:24,413 INFO:   Done with stage: SCALING TARGETS
2023-01-05 14:51:24,413 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:51:24,413 INFO:     No hyperparam tuning for this model
2023-01-05 14:51:24,413 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:51:24,413 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 14:51:24,414 INFO:     None feature selector for col prot
2023-01-05 14:51:24,414 INFO:     None feature selector for col prot
2023-01-05 14:51:24,414 INFO:     None feature selector for col prot
2023-01-05 14:51:24,414 INFO:     None feature selector for col chem
2023-01-05 14:51:24,414 INFO:     None feature selector for col chem
2023-01-05 14:51:24,414 INFO:     None feature selector for col chem
2023-01-05 14:51:24,415 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 14:51:24,415 INFO:   Starting stage: BUILD MODEL
2023-01-05 14:51:24,416 INFO:     Number of params in model 72901
2023-01-05 14:51:24,419 INFO:   Done with stage: BUILD MODEL
2023-01-05 14:51:24,419 INFO:   Starting stage: TRAINING
2023-01-05 14:51:24,479 INFO:     Val loss before train {'Reaction outcome loss': 0.896330730120341, 'Total loss': 0.896330730120341}
2023-01-05 14:51:24,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:24,479 INFO:     Epoch: 0
2023-01-05 14:51:26,596 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7344651927550634, 'Total loss': 0.7344651927550634} | train loss {'Reaction outcome loss': 0.9012537175218998, 'Total loss': 0.9012537175218998}
2023-01-05 14:51:26,596 INFO:     Found new best model at epoch 0
2023-01-05 14:51:26,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:26,598 INFO:     Epoch: 1
2023-01-05 14:51:28,701 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5214413970708847, 'Total loss': 0.5214413970708847} | train loss {'Reaction outcome loss': 0.7227252512840328, 'Total loss': 0.7227252512840328}
2023-01-05 14:51:28,702 INFO:     Found new best model at epoch 1
2023-01-05 14:51:28,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:28,704 INFO:     Epoch: 2
2023-01-05 14:51:30,820 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5139755109945933, 'Total loss': 0.5139755109945933} | train loss {'Reaction outcome loss': 0.5666924180579801, 'Total loss': 0.5666924180579801}
2023-01-05 14:51:30,820 INFO:     Found new best model at epoch 2
2023-01-05 14:51:30,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:30,821 INFO:     Epoch: 3
2023-01-05 14:51:32,912 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4978702306747437, 'Total loss': 0.4978702306747437} | train loss {'Reaction outcome loss': 0.5220320512887736, 'Total loss': 0.5220320512887736}
2023-01-05 14:51:32,912 INFO:     Found new best model at epoch 3
2023-01-05 14:51:32,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:32,914 INFO:     Epoch: 4
2023-01-05 14:51:35,013 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4479494829972585, 'Total loss': 0.4479494829972585} | train loss {'Reaction outcome loss': 0.4994705275965793, 'Total loss': 0.4994705275965793}
2023-01-05 14:51:35,013 INFO:     Found new best model at epoch 4
2023-01-05 14:51:35,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:35,014 INFO:     Epoch: 5
2023-01-05 14:51:37,098 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4680475334326426, 'Total loss': 0.4680475334326426} | train loss {'Reaction outcome loss': 0.4849871382172257, 'Total loss': 0.4849871382172257}
2023-01-05 14:51:37,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:37,098 INFO:     Epoch: 6
2023-01-05 14:51:39,186 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44484824140866597, 'Total loss': 0.44484824140866597} | train loss {'Reaction outcome loss': 0.4825281397442976, 'Total loss': 0.4825281397442976}
2023-01-05 14:51:39,186 INFO:     Found new best model at epoch 6
2023-01-05 14:51:39,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:39,187 INFO:     Epoch: 7
2023-01-05 14:51:41,283 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4513935347398122, 'Total loss': 0.4513935347398122} | train loss {'Reaction outcome loss': 0.46953717385490884, 'Total loss': 0.46953717385490884}
2023-01-05 14:51:41,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:41,284 INFO:     Epoch: 8
2023-01-05 14:51:43,373 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4447404419382413, 'Total loss': 0.4447404419382413} | train loss {'Reaction outcome loss': 0.4591599539802083, 'Total loss': 0.4591599539802083}
2023-01-05 14:51:43,373 INFO:     Found new best model at epoch 8
2023-01-05 14:51:43,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:43,374 INFO:     Epoch: 9
2023-01-05 14:51:45,482 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45183851768573124, 'Total loss': 0.45183851768573124} | train loss {'Reaction outcome loss': 0.45743072076917135, 'Total loss': 0.45743072076917135}
2023-01-05 14:51:45,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:45,482 INFO:     Epoch: 10
2023-01-05 14:51:47,556 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44843829472859703, 'Total loss': 0.44843829472859703} | train loss {'Reaction outcome loss': 0.44852002377439687, 'Total loss': 0.44852002377439687}
2023-01-05 14:51:47,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:47,557 INFO:     Epoch: 11
2023-01-05 14:51:49,660 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42700755695501963, 'Total loss': 0.42700755695501963} | train loss {'Reaction outcome loss': 0.4442266275851929, 'Total loss': 0.4442266275851929}
2023-01-05 14:51:49,660 INFO:     Found new best model at epoch 11
2023-01-05 14:51:49,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:49,662 INFO:     Epoch: 12
2023-01-05 14:51:51,770 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.500928544998169, 'Total loss': 0.500928544998169} | train loss {'Reaction outcome loss': 0.4394506090131633, 'Total loss': 0.4394506090131633}
2023-01-05 14:51:51,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:51,771 INFO:     Epoch: 13
2023-01-05 14:51:53,883 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45703358252843224, 'Total loss': 0.45703358252843224} | train loss {'Reaction outcome loss': 0.43569877182865496, 'Total loss': 0.43569877182865496}
2023-01-05 14:51:53,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:53,884 INFO:     Epoch: 14
2023-01-05 14:51:56,068 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46043720046679176, 'Total loss': 0.46043720046679176} | train loss {'Reaction outcome loss': 0.42608529219328256, 'Total loss': 0.42608529219328256}
2023-01-05 14:51:56,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:56,068 INFO:     Epoch: 15
2023-01-05 14:51:58,197 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4210304836432139, 'Total loss': 0.4210304836432139} | train loss {'Reaction outcome loss': 0.42840875619231994, 'Total loss': 0.42840875619231994}
2023-01-05 14:51:58,198 INFO:     Found new best model at epoch 15
2023-01-05 14:51:58,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:51:58,199 INFO:     Epoch: 16
2023-01-05 14:52:00,295 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4211132787168026, 'Total loss': 0.4211132787168026} | train loss {'Reaction outcome loss': 0.42426977240621383, 'Total loss': 0.42426977240621383}
2023-01-05 14:52:00,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:00,296 INFO:     Epoch: 17
2023-01-05 14:52:02,395 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44050573110580443, 'Total loss': 0.44050573110580443} | train loss {'Reaction outcome loss': 0.42043280321073706, 'Total loss': 0.42043280321073706}
2023-01-05 14:52:02,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:02,396 INFO:     Epoch: 18
2023-01-05 14:52:04,497 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4354802668094635, 'Total loss': 0.4354802668094635} | train loss {'Reaction outcome loss': 0.41347519481534006, 'Total loss': 0.41347519481534006}
2023-01-05 14:52:04,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:04,497 INFO:     Epoch: 19
2023-01-05 14:52:06,596 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40273352563381193, 'Total loss': 0.40273352563381193} | train loss {'Reaction outcome loss': 0.4123466746173662, 'Total loss': 0.4123466746173662}
2023-01-05 14:52:06,596 INFO:     Found new best model at epoch 19
2023-01-05 14:52:06,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:06,597 INFO:     Epoch: 20
2023-01-05 14:52:08,694 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4416434367497762, 'Total loss': 0.4416434367497762} | train loss {'Reaction outcome loss': 0.4074157308718375, 'Total loss': 0.4074157308718375}
2023-01-05 14:52:08,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:08,694 INFO:     Epoch: 21
2023-01-05 14:52:10,579 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46794851620992023, 'Total loss': 0.46794851620992023} | train loss {'Reaction outcome loss': 0.4040887996114488, 'Total loss': 0.4040887996114488}
2023-01-05 14:52:10,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:10,579 INFO:     Epoch: 22
2023-01-05 14:52:12,311 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4827793210744858, 'Total loss': 0.4827793210744858} | train loss {'Reaction outcome loss': 0.3970929826317678, 'Total loss': 0.3970929826317678}
2023-01-05 14:52:12,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:12,311 INFO:     Epoch: 23
2023-01-05 14:52:14,121 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43450673719247185, 'Total loss': 0.43450673719247185} | train loss {'Reaction outcome loss': 0.4031881308698566, 'Total loss': 0.4031881308698566}
2023-01-05 14:52:14,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:14,121 INFO:     Epoch: 24
2023-01-05 14:52:16,216 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39869586726029715, 'Total loss': 0.39869586726029715} | train loss {'Reaction outcome loss': 0.3909374057036924, 'Total loss': 0.3909374057036924}
2023-01-05 14:52:16,217 INFO:     Found new best model at epoch 24
2023-01-05 14:52:16,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:16,218 INFO:     Epoch: 25
2023-01-05 14:52:18,334 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41034946143627166, 'Total loss': 0.41034946143627166} | train loss {'Reaction outcome loss': 0.38967505608757486, 'Total loss': 0.38967505608757486}
2023-01-05 14:52:18,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:18,334 INFO:     Epoch: 26
2023-01-05 14:52:20,418 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4288386325041453, 'Total loss': 0.4288386325041453} | train loss {'Reaction outcome loss': 0.38518834281781505, 'Total loss': 0.38518834281781505}
2023-01-05 14:52:20,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:20,418 INFO:     Epoch: 27
2023-01-05 14:52:22,476 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42777735193570454, 'Total loss': 0.42777735193570454} | train loss {'Reaction outcome loss': 0.3826752047147258, 'Total loss': 0.3826752047147258}
2023-01-05 14:52:22,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:22,476 INFO:     Epoch: 28
2023-01-05 14:52:24,589 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43863567312558494, 'Total loss': 0.43863567312558494} | train loss {'Reaction outcome loss': 0.3809334999740784, 'Total loss': 0.3809334999740784}
2023-01-05 14:52:24,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:24,589 INFO:     Epoch: 29
2023-01-05 14:52:26,684 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41636108557383217, 'Total loss': 0.41636108557383217} | train loss {'Reaction outcome loss': 0.3742149089535224, 'Total loss': 0.3742149089535224}
2023-01-05 14:52:26,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:26,685 INFO:     Epoch: 30
2023-01-05 14:52:28,799 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41662455002466836, 'Total loss': 0.41662455002466836} | train loss {'Reaction outcome loss': 0.3689510342544735, 'Total loss': 0.3689510342544735}
2023-01-05 14:52:28,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:28,800 INFO:     Epoch: 31
2023-01-05 14:52:30,941 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4618917773167292, 'Total loss': 0.4618917773167292} | train loss {'Reaction outcome loss': 0.3681669323756686, 'Total loss': 0.3681669323756686}
2023-01-05 14:52:30,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:30,941 INFO:     Epoch: 32
2023-01-05 14:52:33,083 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4215336966017882, 'Total loss': 0.4215336966017882} | train loss {'Reaction outcome loss': 0.3616721224575905, 'Total loss': 0.3616721224575905}
2023-01-05 14:52:33,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:33,084 INFO:     Epoch: 33
2023-01-05 14:52:35,214 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4250515734155973, 'Total loss': 0.4250515734155973} | train loss {'Reaction outcome loss': 0.3619605434501743, 'Total loss': 0.3619605434501743}
2023-01-05 14:52:35,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:35,215 INFO:     Epoch: 34
2023-01-05 14:52:37,376 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43810540934403736, 'Total loss': 0.43810540934403736} | train loss {'Reaction outcome loss': 0.36162565651305045, 'Total loss': 0.36162565651305045}
2023-01-05 14:52:37,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:37,376 INFO:     Epoch: 35
2023-01-05 14:52:39,533 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4345641901095708, 'Total loss': 0.4345641901095708} | train loss {'Reaction outcome loss': 0.3484049979528598, 'Total loss': 0.3484049979528598}
2023-01-05 14:52:39,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:39,534 INFO:     Epoch: 36
2023-01-05 14:52:41,702 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4211642930905024, 'Total loss': 0.4211642930905024} | train loss {'Reaction outcome loss': 0.3555134969223909, 'Total loss': 0.3555134969223909}
2023-01-05 14:52:41,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:41,703 INFO:     Epoch: 37
2023-01-05 14:52:43,844 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44093658328056334, 'Total loss': 0.44093658328056334} | train loss {'Reaction outcome loss': 0.3490575142342226, 'Total loss': 0.3490575142342226}
2023-01-05 14:52:43,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:43,844 INFO:     Epoch: 38
2023-01-05 14:52:45,955 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41225842038790383, 'Total loss': 0.41225842038790383} | train loss {'Reaction outcome loss': 0.3387251677768257, 'Total loss': 0.3387251677768257}
2023-01-05 14:52:45,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:45,955 INFO:     Epoch: 39
2023-01-05 14:52:48,099 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38996243178844453, 'Total loss': 0.38996243178844453} | train loss {'Reaction outcome loss': 0.34514440161715576, 'Total loss': 0.34514440161715576}
2023-01-05 14:52:48,099 INFO:     Found new best model at epoch 39
2023-01-05 14:52:48,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:48,101 INFO:     Epoch: 40
2023-01-05 14:52:50,215 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40393711626529694, 'Total loss': 0.40393711626529694} | train loss {'Reaction outcome loss': 0.34180606992372287, 'Total loss': 0.34180606992372287}
2023-01-05 14:52:50,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:50,215 INFO:     Epoch: 41
2023-01-05 14:52:52,339 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41634920984506607, 'Total loss': 0.41634920984506607} | train loss {'Reaction outcome loss': 0.33575926575383575, 'Total loss': 0.33575926575383575}
2023-01-05 14:52:52,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:52,339 INFO:     Epoch: 42
2023-01-05 14:52:54,470 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4285401165485382, 'Total loss': 0.4285401165485382} | train loss {'Reaction outcome loss': 0.3348898674839097, 'Total loss': 0.3348898674839097}
2023-01-05 14:52:54,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:54,471 INFO:     Epoch: 43
2023-01-05 14:52:56,548 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3805095851421356, 'Total loss': 0.3805095851421356} | train loss {'Reaction outcome loss': 0.3326348344695744, 'Total loss': 0.3326348344695744}
2023-01-05 14:52:56,548 INFO:     Found new best model at epoch 43
2023-01-05 14:52:56,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:56,549 INFO:     Epoch: 44
2023-01-05 14:52:58,667 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3967494269212087, 'Total loss': 0.3967494269212087} | train loss {'Reaction outcome loss': 0.3297383875562036, 'Total loss': 0.3297383875562036}
2023-01-05 14:52:58,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:52:58,668 INFO:     Epoch: 45
2023-01-05 14:53:00,752 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3713776270548503, 'Total loss': 0.3713776270548503} | train loss {'Reaction outcome loss': 0.31975911587916617, 'Total loss': 0.31975911587916617}
2023-01-05 14:53:00,752 INFO:     Found new best model at epoch 45
2023-01-05 14:53:00,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:00,753 INFO:     Epoch: 46
2023-01-05 14:53:02,843 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4314954717954, 'Total loss': 0.4314954717954} | train loss {'Reaction outcome loss': 0.31849682669248086, 'Total loss': 0.31849682669248086}
2023-01-05 14:53:02,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:02,844 INFO:     Epoch: 47
2023-01-05 14:53:04,958 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42436458071072897, 'Total loss': 0.42436458071072897} | train loss {'Reaction outcome loss': 0.31509840230000413, 'Total loss': 0.31509840230000413}
2023-01-05 14:53:04,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:04,958 INFO:     Epoch: 48
2023-01-05 14:53:07,085 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38957469860712685, 'Total loss': 0.38957469860712685} | train loss {'Reaction outcome loss': 0.3159676487815336, 'Total loss': 0.3159676487815336}
2023-01-05 14:53:07,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:07,086 INFO:     Epoch: 49
2023-01-05 14:53:09,178 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40235696534315746, 'Total loss': 0.40235696534315746} | train loss {'Reaction outcome loss': 0.3099129485220707, 'Total loss': 0.3099129485220707}
2023-01-05 14:53:09,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:09,179 INFO:     Epoch: 50
2023-01-05 14:53:11,298 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38675485402345655, 'Total loss': 0.38675485402345655} | train loss {'Reaction outcome loss': 0.30954605745103525, 'Total loss': 0.30954605745103525}
2023-01-05 14:53:11,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:11,298 INFO:     Epoch: 51
2023-01-05 14:53:13,404 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4788894568880399, 'Total loss': 0.4788894568880399} | train loss {'Reaction outcome loss': 0.31160419666624156, 'Total loss': 0.31160419666624156}
2023-01-05 14:53:13,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:13,405 INFO:     Epoch: 52
2023-01-05 14:53:15,528 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3836558597783248, 'Total loss': 0.3836558597783248} | train loss {'Reaction outcome loss': 0.3027438476296808, 'Total loss': 0.3027438476296808}
2023-01-05 14:53:15,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:15,528 INFO:     Epoch: 53
2023-01-05 14:53:17,630 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4062104463577271, 'Total loss': 0.4062104463577271} | train loss {'Reaction outcome loss': 0.30688006642559795, 'Total loss': 0.30688006642559795}
2023-01-05 14:53:17,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:17,630 INFO:     Epoch: 54
2023-01-05 14:53:19,724 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4054739743471146, 'Total loss': 0.4054739743471146} | train loss {'Reaction outcome loss': 0.29510166542776395, 'Total loss': 0.29510166542776395}
2023-01-05 14:53:19,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:19,725 INFO:     Epoch: 55
2023-01-05 14:53:21,845 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37322798917690914, 'Total loss': 0.37322798917690914} | train loss {'Reaction outcome loss': 0.2880765901143041, 'Total loss': 0.2880765901143041}
2023-01-05 14:53:21,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:21,846 INFO:     Epoch: 56
2023-01-05 14:53:23,963 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3814719747751951, 'Total loss': 0.3814719747751951} | train loss {'Reaction outcome loss': 0.29289285305241375, 'Total loss': 0.29289285305241375}
2023-01-05 14:53:23,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:23,963 INFO:     Epoch: 57
2023-01-05 14:53:26,081 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41380372941493987, 'Total loss': 0.41380372941493987} | train loss {'Reaction outcome loss': 0.2948352729152489, 'Total loss': 0.2948352729152489}
2023-01-05 14:53:26,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:26,081 INFO:     Epoch: 58
2023-01-05 14:53:28,287 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4061553860704104, 'Total loss': 0.4061553860704104} | train loss {'Reaction outcome loss': 0.28562377453730114, 'Total loss': 0.28562377453730114}
2023-01-05 14:53:28,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:28,287 INFO:     Epoch: 59
2023-01-05 14:53:30,426 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.36662742296854656, 'Total loss': 0.36662742296854656} | train loss {'Reaction outcome loss': 0.28002881064901053, 'Total loss': 0.28002881064901053}
2023-01-05 14:53:30,426 INFO:     Found new best model at epoch 59
2023-01-05 14:53:30,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:30,427 INFO:     Epoch: 60
2023-01-05 14:53:32,543 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3922032296657562, 'Total loss': 0.3922032296657562} | train loss {'Reaction outcome loss': 0.28190006224981534, 'Total loss': 0.28190006224981534}
2023-01-05 14:53:32,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:32,544 INFO:     Epoch: 61
2023-01-05 14:53:34,648 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38939123377203944, 'Total loss': 0.38939123377203944} | train loss {'Reaction outcome loss': 0.2825727182890656, 'Total loss': 0.2825727182890656}
2023-01-05 14:53:34,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:34,649 INFO:     Epoch: 62
2023-01-05 14:53:36,713 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4019695977369944, 'Total loss': 0.4019695977369944} | train loss {'Reaction outcome loss': 0.2820989652588359, 'Total loss': 0.2820989652588359}
2023-01-05 14:53:36,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:36,714 INFO:     Epoch: 63
2023-01-05 14:53:38,836 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4016559501489004, 'Total loss': 0.4016559501489004} | train loss {'Reaction outcome loss': 0.2800569973913506, 'Total loss': 0.2800569973913506}
2023-01-05 14:53:38,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:38,838 INFO:     Epoch: 64
2023-01-05 14:53:40,937 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4082225610812505, 'Total loss': 0.4082225610812505} | train loss {'Reaction outcome loss': 0.2735462173737063, 'Total loss': 0.2735462173737063}
2023-01-05 14:53:40,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:40,938 INFO:     Epoch: 65
2023-01-05 14:53:43,037 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40705061753590904, 'Total loss': 0.40705061753590904} | train loss {'Reaction outcome loss': 0.27656253222444843, 'Total loss': 0.27656253222444843}
2023-01-05 14:53:43,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:43,037 INFO:     Epoch: 66
2023-01-05 14:53:45,151 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3823690291494131, 'Total loss': 0.3823690291494131} | train loss {'Reaction outcome loss': 0.26665787501913596, 'Total loss': 0.26665787501913596}
2023-01-05 14:53:45,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:45,152 INFO:     Epoch: 67
2023-01-05 14:53:47,254 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41302851190169654, 'Total loss': 0.41302851190169654} | train loss {'Reaction outcome loss': 0.26767472382566143, 'Total loss': 0.26767472382566143}
2023-01-05 14:53:47,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:47,254 INFO:     Epoch: 68
2023-01-05 14:53:49,348 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43441213965415953, 'Total loss': 0.43441213965415953} | train loss {'Reaction outcome loss': 0.2706668536106599, 'Total loss': 0.2706668536106599}
2023-01-05 14:53:49,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:49,349 INFO:     Epoch: 69
2023-01-05 14:53:51,456 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42812624176343284, 'Total loss': 0.42812624176343284} | train loss {'Reaction outcome loss': 0.2635510620966939, 'Total loss': 0.2635510620966939}
2023-01-05 14:53:51,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:51,456 INFO:     Epoch: 70
2023-01-05 14:53:53,541 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39062863326010605, 'Total loss': 0.39062863326010605} | train loss {'Reaction outcome loss': 0.26340889121746003, 'Total loss': 0.26340889121746003}
2023-01-05 14:53:53,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:53,542 INFO:     Epoch: 71
2023-01-05 14:53:55,642 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3927846272786458, 'Total loss': 0.3927846272786458} | train loss {'Reaction outcome loss': 0.2681067885342999, 'Total loss': 0.2681067885342999}
2023-01-05 14:53:55,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:55,643 INFO:     Epoch: 72
2023-01-05 14:53:57,762 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42270054419835407, 'Total loss': 0.42270054419835407} | train loss {'Reaction outcome loss': 0.25686342548235314, 'Total loss': 0.25686342548235314}
2023-01-05 14:53:57,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:57,763 INFO:     Epoch: 73
2023-01-05 14:53:59,879 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4208055396874746, 'Total loss': 0.4208055396874746} | train loss {'Reaction outcome loss': 0.2562317799130709, 'Total loss': 0.2562317799130709}
2023-01-05 14:53:59,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:53:59,879 INFO:     Epoch: 74
2023-01-05 14:54:01,989 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4195905576149623, 'Total loss': 0.4195905576149623} | train loss {'Reaction outcome loss': 0.2582839440942718, 'Total loss': 0.2582839440942718}
2023-01-05 14:54:01,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:01,990 INFO:     Epoch: 75
2023-01-05 14:54:04,073 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44599941894412043, 'Total loss': 0.44599941894412043} | train loss {'Reaction outcome loss': 0.2562495525788887, 'Total loss': 0.2562495525788887}
2023-01-05 14:54:04,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:04,074 INFO:     Epoch: 76
2023-01-05 14:54:06,164 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37513639628887174, 'Total loss': 0.37513639628887174} | train loss {'Reaction outcome loss': 0.24387807432713324, 'Total loss': 0.24387807432713324}
2023-01-05 14:54:06,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:06,165 INFO:     Epoch: 77
2023-01-05 14:54:08,266 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4379277274012566, 'Total loss': 0.4379277274012566} | train loss {'Reaction outcome loss': 0.2493943099990982, 'Total loss': 0.2493943099990982}
2023-01-05 14:54:08,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:08,266 INFO:     Epoch: 78
2023-01-05 14:54:10,356 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4073792981604735, 'Total loss': 0.4073792981604735} | train loss {'Reaction outcome loss': 0.2538778471358368, 'Total loss': 0.2538778471358368}
2023-01-05 14:54:10,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:10,356 INFO:     Epoch: 79
2023-01-05 14:54:12,469 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4372408792376518, 'Total loss': 0.4372408792376518} | train loss {'Reaction outcome loss': 0.25619413429438187, 'Total loss': 0.25619413429438187}
2023-01-05 14:54:12,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:12,469 INFO:     Epoch: 80
2023-01-05 14:54:14,636 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3965022643407186, 'Total loss': 0.3965022643407186} | train loss {'Reaction outcome loss': 0.24799510873716696, 'Total loss': 0.24799510873716696}
2023-01-05 14:54:14,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:14,638 INFO:     Epoch: 81
2023-01-05 14:54:16,789 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4345348685979843, 'Total loss': 0.4345348685979843} | train loss {'Reaction outcome loss': 0.25041135027145495, 'Total loss': 0.25041135027145495}
2023-01-05 14:54:16,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:16,789 INFO:     Epoch: 82
2023-01-05 14:54:18,941 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39089655329783757, 'Total loss': 0.39089655329783757} | train loss {'Reaction outcome loss': 0.23985406103444276, 'Total loss': 0.23985406103444276}
2023-01-05 14:54:18,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:18,941 INFO:     Epoch: 83
2023-01-05 14:54:21,033 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4094725467264652, 'Total loss': 0.4094725467264652} | train loss {'Reaction outcome loss': 0.2415459092527738, 'Total loss': 0.2415459092527738}
2023-01-05 14:54:21,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:21,034 INFO:     Epoch: 84
2023-01-05 14:54:23,001 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37277209212382634, 'Total loss': 0.37277209212382634} | train loss {'Reaction outcome loss': 0.2382485434254872, 'Total loss': 0.2382485434254872}
2023-01-05 14:54:23,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:23,001 INFO:     Epoch: 85
2023-01-05 14:54:25,166 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4235701908667882, 'Total loss': 0.4235701908667882} | train loss {'Reaction outcome loss': 0.23796022374086714, 'Total loss': 0.23796022374086714}
2023-01-05 14:54:25,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:25,166 INFO:     Epoch: 86
2023-01-05 14:54:27,334 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43236889044443766, 'Total loss': 0.43236889044443766} | train loss {'Reaction outcome loss': 0.23595716658553514, 'Total loss': 0.23595716658553514}
2023-01-05 14:54:27,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:27,334 INFO:     Epoch: 87
2023-01-05 14:54:29,464 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4114817649126053, 'Total loss': 0.4114817649126053} | train loss {'Reaction outcome loss': 0.23443448815384804, 'Total loss': 0.23443448815384804}
2023-01-05 14:54:29,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:29,465 INFO:     Epoch: 88
2023-01-05 14:54:31,621 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3974401940902074, 'Total loss': 0.3974401940902074} | train loss {'Reaction outcome loss': 0.2448368303381539, 'Total loss': 0.2448368303381539}
2023-01-05 14:54:31,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:31,622 INFO:     Epoch: 89
2023-01-05 14:54:33,753 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4001284450292587, 'Total loss': 0.4001284450292587} | train loss {'Reaction outcome loss': 0.231047988350321, 'Total loss': 0.231047988350321}
2023-01-05 14:54:33,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:33,754 INFO:     Epoch: 90
2023-01-05 14:54:35,905 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4090102973083655, 'Total loss': 0.4090102973083655} | train loss {'Reaction outcome loss': 0.23422627931811274, 'Total loss': 0.23422627931811274}
2023-01-05 14:54:35,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:35,906 INFO:     Epoch: 91
2023-01-05 14:54:38,042 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38488331337769827, 'Total loss': 0.38488331337769827} | train loss {'Reaction outcome loss': 0.23743374606532583, 'Total loss': 0.23743374606532583}
2023-01-05 14:54:38,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:38,042 INFO:     Epoch: 92
2023-01-05 14:54:40,176 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3546230578174194, 'Total loss': 0.3546230578174194} | train loss {'Reaction outcome loss': 0.2350312274884144, 'Total loss': 0.2350312274884144}
2023-01-05 14:54:40,177 INFO:     Found new best model at epoch 92
2023-01-05 14:54:40,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:40,178 INFO:     Epoch: 93
2023-01-05 14:54:42,283 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4293317993481954, 'Total loss': 0.4293317993481954} | train loss {'Reaction outcome loss': 0.23337733722377801, 'Total loss': 0.23337733722377801}
2023-01-05 14:54:42,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:42,283 INFO:     Epoch: 94
2023-01-05 14:54:44,387 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4092455307642619, 'Total loss': 0.4092455307642619} | train loss {'Reaction outcome loss': 0.23148317430924445, 'Total loss': 0.23148317430924445}
2023-01-05 14:54:44,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:44,388 INFO:     Epoch: 95
2023-01-05 14:54:46,501 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41454232136408486, 'Total loss': 0.41454232136408486} | train loss {'Reaction outcome loss': 0.22771481672006338, 'Total loss': 0.22771481672006338}
2023-01-05 14:54:46,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:46,501 INFO:     Epoch: 96
2023-01-05 14:54:48,609 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39547369480133054, 'Total loss': 0.39547369480133054} | train loss {'Reaction outcome loss': 0.2271129463376594, 'Total loss': 0.2271129463376594}
2023-01-05 14:54:48,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:48,609 INFO:     Epoch: 97
2023-01-05 14:54:50,725 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43915107746918997, 'Total loss': 0.43915107746918997} | train loss {'Reaction outcome loss': 0.23184321521063134, 'Total loss': 0.23184321521063134}
2023-01-05 14:54:50,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:50,727 INFO:     Epoch: 98
2023-01-05 14:54:52,845 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4035697301228841, 'Total loss': 0.4035697301228841} | train loss {'Reaction outcome loss': 0.2359146983998508, 'Total loss': 0.2359146983998508}
2023-01-05 14:54:52,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:52,846 INFO:     Epoch: 99
2023-01-05 14:54:54,959 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37137504418691, 'Total loss': 0.37137504418691} | train loss {'Reaction outcome loss': 0.23031974666342964, 'Total loss': 0.23031974666342964}
2023-01-05 14:54:54,959 INFO:     Best model found after epoch 93 of 100.
2023-01-05 14:54:54,959 INFO:   Done with stage: TRAINING
2023-01-05 14:54:54,959 INFO:   Starting stage: EVALUATION
2023-01-05 14:54:55,110 INFO:   Done with stage: EVALUATION
2023-01-05 14:54:55,110 INFO:   Leaving out SEQ value Fold_1
2023-01-05 14:54:55,123 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 14:54:55,123 INFO:   Starting stage: FEATURE SCALING
2023-01-05 14:54:55,768 INFO:   Done with stage: FEATURE SCALING
2023-01-05 14:54:55,768 INFO:   Starting stage: SCALING TARGETS
2023-01-05 14:54:55,836 INFO:   Done with stage: SCALING TARGETS
2023-01-05 14:54:55,836 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:54:55,836 INFO:     No hyperparam tuning for this model
2023-01-05 14:54:55,836 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:54:55,836 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 14:54:55,837 INFO:     None feature selector for col prot
2023-01-05 14:54:55,837 INFO:     None feature selector for col prot
2023-01-05 14:54:55,837 INFO:     None feature selector for col prot
2023-01-05 14:54:55,838 INFO:     None feature selector for col chem
2023-01-05 14:54:55,838 INFO:     None feature selector for col chem
2023-01-05 14:54:55,838 INFO:     None feature selector for col chem
2023-01-05 14:54:55,838 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 14:54:55,838 INFO:   Starting stage: BUILD MODEL
2023-01-05 14:54:55,839 INFO:     Number of params in model 72901
2023-01-05 14:54:55,842 INFO:   Done with stage: BUILD MODEL
2023-01-05 14:54:55,843 INFO:   Starting stage: TRAINING
2023-01-05 14:54:55,900 INFO:     Val loss before train {'Reaction outcome loss': 0.9078616460164388, 'Total loss': 0.9078616460164388}
2023-01-05 14:54:55,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:55,900 INFO:     Epoch: 0
2023-01-05 14:54:58,046 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7779481291770936, 'Total loss': 0.7779481291770936} | train loss {'Reaction outcome loss': 0.9535677836541712, 'Total loss': 0.9535677836541712}
2023-01-05 14:54:58,046 INFO:     Found new best model at epoch 0
2023-01-05 14:54:58,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:54:58,048 INFO:     Epoch: 1
2023-01-05 14:55:00,195 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5592420995235443, 'Total loss': 0.5592420995235443} | train loss {'Reaction outcome loss': 0.7813796376007317, 'Total loss': 0.7813796376007317}
2023-01-05 14:55:00,196 INFO:     Found new best model at epoch 1
2023-01-05 14:55:00,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:00,197 INFO:     Epoch: 2
2023-01-05 14:55:02,345 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45491493145624795, 'Total loss': 0.45491493145624795} | train loss {'Reaction outcome loss': 0.6023974916251906, 'Total loss': 0.6023974916251906}
2023-01-05 14:55:02,345 INFO:     Found new best model at epoch 2
2023-01-05 14:55:02,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:02,346 INFO:     Epoch: 3
2023-01-05 14:55:04,477 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.41329320669174197, 'Total loss': 0.41329320669174197} | train loss {'Reaction outcome loss': 0.5465683338850954, 'Total loss': 0.5465683338850954}
2023-01-05 14:55:04,478 INFO:     Found new best model at epoch 3
2023-01-05 14:55:04,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:04,479 INFO:     Epoch: 4
2023-01-05 14:55:06,608 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4230712890625, 'Total loss': 0.4230712890625} | train loss {'Reaction outcome loss': 0.5270481967795504, 'Total loss': 0.5270481967795504}
2023-01-05 14:55:06,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:06,608 INFO:     Epoch: 5
2023-01-05 14:55:08,745 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3992378165324529, 'Total loss': 0.3992378165324529} | train loss {'Reaction outcome loss': 0.515025311088475, 'Total loss': 0.515025311088475}
2023-01-05 14:55:08,745 INFO:     Found new best model at epoch 5
2023-01-05 14:55:08,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:08,746 INFO:     Epoch: 6
2023-01-05 14:55:10,896 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.36069848636786145, 'Total loss': 0.36069848636786145} | train loss {'Reaction outcome loss': 0.5004613394611073, 'Total loss': 0.5004613394611073}
2023-01-05 14:55:10,896 INFO:     Found new best model at epoch 6
2023-01-05 14:55:10,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:10,898 INFO:     Epoch: 7
2023-01-05 14:55:13,050 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3954202075799306, 'Total loss': 0.3954202075799306} | train loss {'Reaction outcome loss': 0.5011039702017812, 'Total loss': 0.5011039702017812}
2023-01-05 14:55:13,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:13,050 INFO:     Epoch: 8
2023-01-05 14:55:15,202 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.37976455663641295, 'Total loss': 0.37976455663641295} | train loss {'Reaction outcome loss': 0.48704517621846094, 'Total loss': 0.48704517621846094}
2023-01-05 14:55:15,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:15,202 INFO:     Epoch: 9
2023-01-05 14:55:17,173 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.34397548958659174, 'Total loss': 0.34397548958659174} | train loss {'Reaction outcome loss': 0.4830108230566456, 'Total loss': 0.4830108230566456}
2023-01-05 14:55:17,174 INFO:     Found new best model at epoch 9
2023-01-05 14:55:17,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:17,175 INFO:     Epoch: 10
2023-01-05 14:55:18,929 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3699508339166641, 'Total loss': 0.3699508339166641} | train loss {'Reaction outcome loss': 0.47710932900000663, 'Total loss': 0.47710932900000663}
2023-01-05 14:55:18,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:18,929 INFO:     Epoch: 11
2023-01-05 14:55:20,782 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.34253281553586323, 'Total loss': 0.34253281553586323} | train loss {'Reaction outcome loss': 0.46982817550318956, 'Total loss': 0.46982817550318956}
2023-01-05 14:55:20,782 INFO:     Found new best model at epoch 11
2023-01-05 14:55:20,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:20,783 INFO:     Epoch: 12
2023-01-05 14:55:22,931 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3629134232799212, 'Total loss': 0.3629134232799212} | train loss {'Reaction outcome loss': 0.46734238921725835, 'Total loss': 0.46734238921725835}
2023-01-05 14:55:22,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:22,932 INFO:     Epoch: 13
2023-01-05 14:55:25,079 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3654985805352529, 'Total loss': 0.3654985805352529} | train loss {'Reaction outcome loss': 0.46157144771440184, 'Total loss': 0.46157144771440184}
2023-01-05 14:55:25,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:25,079 INFO:     Epoch: 14
2023-01-05 14:55:27,245 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.35556293924649557, 'Total loss': 0.35556293924649557} | train loss {'Reaction outcome loss': 0.4564171324137354, 'Total loss': 0.4564171324137354}
2023-01-05 14:55:27,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:27,246 INFO:     Epoch: 15
2023-01-05 14:55:29,384 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.343081459403038, 'Total loss': 0.343081459403038} | train loss {'Reaction outcome loss': 0.45117973906062814, 'Total loss': 0.45117973906062814}
2023-01-05 14:55:29,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:29,384 INFO:     Epoch: 16
2023-01-05 14:55:31,534 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.36789658466974895, 'Total loss': 0.36789658466974895} | train loss {'Reaction outcome loss': 0.4449283395533579, 'Total loss': 0.4449283395533579}
2023-01-05 14:55:31,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:31,535 INFO:     Epoch: 17
2023-01-05 14:55:33,695 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3494177838166555, 'Total loss': 0.3494177838166555} | train loss {'Reaction outcome loss': 0.44164395536275675, 'Total loss': 0.44164395536275675}
2023-01-05 14:55:33,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:33,696 INFO:     Epoch: 18
2023-01-05 14:55:35,865 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.34781763752301537, 'Total loss': 0.34781763752301537} | train loss {'Reaction outcome loss': 0.4373286003178924, 'Total loss': 0.4373286003178924}
2023-01-05 14:55:35,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:35,865 INFO:     Epoch: 19
2023-01-05 14:55:38,005 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3345844636360804, 'Total loss': 0.3345844636360804} | train loss {'Reaction outcome loss': 0.43378795381553853, 'Total loss': 0.43378795381553853}
2023-01-05 14:55:38,005 INFO:     Found new best model at epoch 19
2023-01-05 14:55:38,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:38,007 INFO:     Epoch: 20
2023-01-05 14:55:40,161 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3453027864297231, 'Total loss': 0.3453027864297231} | train loss {'Reaction outcome loss': 0.4331987438193203, 'Total loss': 0.4331987438193203}
2023-01-05 14:55:40,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:40,162 INFO:     Epoch: 21
2023-01-05 14:55:42,306 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.36152884165445964, 'Total loss': 0.36152884165445964} | train loss {'Reaction outcome loss': 0.4287198640569283, 'Total loss': 0.4287198640569283}
2023-01-05 14:55:42,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:42,307 INFO:     Epoch: 22
2023-01-05 14:55:44,448 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3686021685600281, 'Total loss': 0.3686021685600281} | train loss {'Reaction outcome loss': 0.4235042972068717, 'Total loss': 0.4235042972068717}
2023-01-05 14:55:44,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:44,449 INFO:     Epoch: 23
2023-01-05 14:55:46,602 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3357531547546387, 'Total loss': 0.3357531547546387} | train loss {'Reaction outcome loss': 0.41592470537463244, 'Total loss': 0.41592470537463244}
2023-01-05 14:55:46,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:46,603 INFO:     Epoch: 24
2023-01-05 14:55:48,749 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3299421856800715, 'Total loss': 0.3299421856800715} | train loss {'Reaction outcome loss': 0.4162667864104257, 'Total loss': 0.4162667864104257}
2023-01-05 14:55:48,749 INFO:     Found new best model at epoch 24
2023-01-05 14:55:48,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:48,751 INFO:     Epoch: 25
2023-01-05 14:55:50,892 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3706339697043101, 'Total loss': 0.3706339697043101} | train loss {'Reaction outcome loss': 0.407237476648858, 'Total loss': 0.407237476648858}
2023-01-05 14:55:50,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:50,892 INFO:     Epoch: 26
2023-01-05 14:55:53,029 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3353649934132894, 'Total loss': 0.3353649934132894} | train loss {'Reaction outcome loss': 0.40826446492306506, 'Total loss': 0.40826446492306506}
2023-01-05 14:55:53,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:53,029 INFO:     Epoch: 27
2023-01-05 14:55:55,163 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3319172700246175, 'Total loss': 0.3319172700246175} | train loss {'Reaction outcome loss': 0.4009396571149356, 'Total loss': 0.4009396571149356}
2023-01-05 14:55:55,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:55,163 INFO:     Epoch: 28
2023-01-05 14:55:57,281 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.30775291671355565, 'Total loss': 0.30775291671355565} | train loss {'Reaction outcome loss': 0.39847543522933104, 'Total loss': 0.39847543522933104}
2023-01-05 14:55:57,282 INFO:     Found new best model at epoch 28
2023-01-05 14:55:57,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:57,284 INFO:     Epoch: 29
2023-01-05 14:55:59,424 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3331427127122879, 'Total loss': 0.3331427127122879} | train loss {'Reaction outcome loss': 0.3932296978241771, 'Total loss': 0.3932296978241771}
2023-01-05 14:55:59,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:55:59,424 INFO:     Epoch: 30
2023-01-05 14:56:01,562 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.36887853443622587, 'Total loss': 0.36887853443622587} | train loss {'Reaction outcome loss': 0.39857535855504717, 'Total loss': 0.39857535855504717}
2023-01-05 14:56:01,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:01,562 INFO:     Epoch: 31
2023-01-05 14:56:03,713 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3511175920565923, 'Total loss': 0.3511175920565923} | train loss {'Reaction outcome loss': 0.39133906870210255, 'Total loss': 0.39133906870210255}
2023-01-05 14:56:03,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:03,714 INFO:     Epoch: 32
2023-01-05 14:56:05,856 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3644254138072332, 'Total loss': 0.3644254138072332} | train loss {'Reaction outcome loss': 0.3854871809373807, 'Total loss': 0.3854871809373807}
2023-01-05 14:56:05,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:05,856 INFO:     Epoch: 33
2023-01-05 14:56:07,977 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3142304062843323, 'Total loss': 0.3142304062843323} | train loss {'Reaction outcome loss': 0.37822622716100546, 'Total loss': 0.37822622716100546}
2023-01-05 14:56:07,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:07,977 INFO:     Epoch: 34
2023-01-05 14:56:10,181 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3385217974583308, 'Total loss': 0.3385217974583308} | train loss {'Reaction outcome loss': 0.38380127810757525, 'Total loss': 0.38380127810757525}
2023-01-05 14:56:10,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:10,181 INFO:     Epoch: 35
2023-01-05 14:56:12,330 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38137957950433093, 'Total loss': 0.38137957950433093} | train loss {'Reaction outcome loss': 0.3788997634266415, 'Total loss': 0.3788997634266415}
2023-01-05 14:56:12,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:12,330 INFO:     Epoch: 36
2023-01-05 14:56:14,476 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.33497723589340844, 'Total loss': 0.33497723589340844} | train loss {'Reaction outcome loss': 0.37833826824424477, 'Total loss': 0.37833826824424477}
2023-01-05 14:56:14,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:14,476 INFO:     Epoch: 37
2023-01-05 14:56:16,599 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.35996461908022565, 'Total loss': 0.35996461908022565} | train loss {'Reaction outcome loss': 0.3698646407982294, 'Total loss': 0.3698646407982294}
2023-01-05 14:56:16,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:16,600 INFO:     Epoch: 38
2023-01-05 14:56:18,729 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.35833892424901326, 'Total loss': 0.35833892424901326} | train loss {'Reaction outcome loss': 0.3678819689437421, 'Total loss': 0.3678819689437421}
2023-01-05 14:56:18,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:18,730 INFO:     Epoch: 39
2023-01-05 14:56:20,860 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3179542242238919, 'Total loss': 0.3179542242238919} | train loss {'Reaction outcome loss': 0.366391110648639, 'Total loss': 0.366391110648639}
2023-01-05 14:56:20,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:20,860 INFO:     Epoch: 40
2023-01-05 14:56:22,997 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.31164089739322665, 'Total loss': 0.31164089739322665} | train loss {'Reaction outcome loss': 0.3585590703589638, 'Total loss': 0.3585590703589638}
2023-01-05 14:56:22,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:22,997 INFO:     Epoch: 41
2023-01-05 14:56:25,136 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3190641929705938, 'Total loss': 0.3190641929705938} | train loss {'Reaction outcome loss': 0.3567932121537245, 'Total loss': 0.3567932121537245}
2023-01-05 14:56:25,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:25,136 INFO:     Epoch: 42
2023-01-05 14:56:27,350 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.35539746284484863, 'Total loss': 0.35539746284484863} | train loss {'Reaction outcome loss': 0.3521052793103413, 'Total loss': 0.3521052793103413}
2023-01-05 14:56:27,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:27,351 INFO:     Epoch: 43
2023-01-05 14:56:29,569 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3509593884150187, 'Total loss': 0.3509593884150187} | train loss {'Reaction outcome loss': 0.359272781351622, 'Total loss': 0.359272781351622}
2023-01-05 14:56:29,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:29,569 INFO:     Epoch: 44
2023-01-05 14:56:31,764 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.36241364280382793, 'Total loss': 0.36241364280382793} | train loss {'Reaction outcome loss': 0.3515157636499753, 'Total loss': 0.3515157636499753}
2023-01-05 14:56:31,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:31,764 INFO:     Epoch: 45
2023-01-05 14:56:33,939 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3067261775334676, 'Total loss': 0.3067261775334676} | train loss {'Reaction outcome loss': 0.3449958912402826, 'Total loss': 0.3449958912402826}
2023-01-05 14:56:33,940 INFO:     Found new best model at epoch 45
2023-01-05 14:56:33,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:33,942 INFO:     Epoch: 46
2023-01-05 14:56:36,071 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3430016020933787, 'Total loss': 0.3430016020933787} | train loss {'Reaction outcome loss': 0.3431057729044535, 'Total loss': 0.3431057729044535}
2023-01-05 14:56:36,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:36,071 INFO:     Epoch: 47
2023-01-05 14:56:38,212 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.34456118047237394, 'Total loss': 0.34456118047237394} | train loss {'Reaction outcome loss': 0.3411992854255177, 'Total loss': 0.3411992854255177}
2023-01-05 14:56:38,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:38,213 INFO:     Epoch: 48
2023-01-05 14:56:40,342 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3436807463566462, 'Total loss': 0.3436807463566462} | train loss {'Reaction outcome loss': 0.33515246874605215, 'Total loss': 0.33515246874605215}
2023-01-05 14:56:40,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:40,343 INFO:     Epoch: 49
2023-01-05 14:56:42,476 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3040588731567065, 'Total loss': 0.3040588731567065} | train loss {'Reaction outcome loss': 0.33803391407658584, 'Total loss': 0.33803391407658584}
2023-01-05 14:56:42,476 INFO:     Found new best model at epoch 49
2023-01-05 14:56:42,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:42,477 INFO:     Epoch: 50
2023-01-05 14:56:44,630 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.34580451746781665, 'Total loss': 0.34580451746781665} | train loss {'Reaction outcome loss': 0.33331779905860004, 'Total loss': 0.33331779905860004}
2023-01-05 14:56:44,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:44,631 INFO:     Epoch: 51
2023-01-05 14:56:46,813 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3193020502726237, 'Total loss': 0.3193020502726237} | train loss {'Reaction outcome loss': 0.33462713269285693, 'Total loss': 0.33462713269285693}
2023-01-05 14:56:46,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:46,814 INFO:     Epoch: 52
2023-01-05 14:56:48,966 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3320603628953298, 'Total loss': 0.3320603628953298} | train loss {'Reaction outcome loss': 0.33146452660380055, 'Total loss': 0.33146452660380055}
2023-01-05 14:56:48,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:48,966 INFO:     Epoch: 53
2023-01-05 14:56:51,093 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3334194948275884, 'Total loss': 0.3334194948275884} | train loss {'Reaction outcome loss': 0.3274014264236402, 'Total loss': 0.3274014264236402}
2023-01-05 14:56:51,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:51,093 INFO:     Epoch: 54
2023-01-05 14:56:53,230 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.34525427023569744, 'Total loss': 0.34525427023569744} | train loss {'Reaction outcome loss': 0.32431476152617567, 'Total loss': 0.32431476152617567}
2023-01-05 14:56:53,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:53,231 INFO:     Epoch: 55
2023-01-05 14:56:55,370 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3182338813940684, 'Total loss': 0.3182338813940684} | train loss {'Reaction outcome loss': 0.3200877604761372, 'Total loss': 0.3200877604761372}
2023-01-05 14:56:55,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:55,370 INFO:     Epoch: 56
2023-01-05 14:56:57,523 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.31482808689276376, 'Total loss': 0.31482808689276376} | train loss {'Reaction outcome loss': 0.31456908916741827, 'Total loss': 0.31456908916741827}
2023-01-05 14:56:57,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:57,524 INFO:     Epoch: 57
2023-01-05 14:56:59,674 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.31156777242819467, 'Total loss': 0.31156777242819467} | train loss {'Reaction outcome loss': 0.3124833002577733, 'Total loss': 0.3124833002577733}
2023-01-05 14:56:59,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:56:59,674 INFO:     Epoch: 58
2023-01-05 14:57:01,807 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.32508612275123594, 'Total loss': 0.32508612275123594} | train loss {'Reaction outcome loss': 0.3210253708309283, 'Total loss': 0.3210253708309283}
2023-01-05 14:57:01,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:01,807 INFO:     Epoch: 59
2023-01-05 14:57:03,955 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3820799574255943, 'Total loss': 0.3820799574255943} | train loss {'Reaction outcome loss': 0.31735551082631097, 'Total loss': 0.31735551082631097}
2023-01-05 14:57:03,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:03,956 INFO:     Epoch: 60
2023-01-05 14:57:06,088 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3009260391195615, 'Total loss': 0.3009260391195615} | train loss {'Reaction outcome loss': 0.31273623811502527, 'Total loss': 0.31273623811502527}
2023-01-05 14:57:06,089 INFO:     Found new best model at epoch 60
2023-01-05 14:57:06,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:06,090 INFO:     Epoch: 61
2023-01-05 14:57:08,235 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.36300965150197345, 'Total loss': 0.36300965150197345} | train loss {'Reaction outcome loss': 0.3071296783096164, 'Total loss': 0.3071296783096164}
2023-01-05 14:57:08,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:08,236 INFO:     Epoch: 62
2023-01-05 14:57:10,389 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3394731005032857, 'Total loss': 0.3394731005032857} | train loss {'Reaction outcome loss': 0.3138421796615759, 'Total loss': 0.3138421796615759}
2023-01-05 14:57:10,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:10,390 INFO:     Epoch: 63
2023-01-05 14:57:12,560 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.32858298867940905, 'Total loss': 0.32858298867940905} | train loss {'Reaction outcome loss': 0.3061014029476112, 'Total loss': 0.3061014029476112}
2023-01-05 14:57:12,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:12,560 INFO:     Epoch: 64
2023-01-05 14:57:14,734 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3214456001917521, 'Total loss': 0.3214456001917521} | train loss {'Reaction outcome loss': 0.29750329189437585, 'Total loss': 0.29750329189437585}
2023-01-05 14:57:14,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:14,734 INFO:     Epoch: 65
2023-01-05 14:57:16,907 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.36384199261665345, 'Total loss': 0.36384199261665345} | train loss {'Reaction outcome loss': 0.3055693744307887, 'Total loss': 0.3055693744307887}
2023-01-05 14:57:16,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:16,907 INFO:     Epoch: 66
2023-01-05 14:57:19,070 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.2992411136627197, 'Total loss': 0.2992411136627197} | train loss {'Reaction outcome loss': 0.3011735458008564, 'Total loss': 0.3011735458008564}
2023-01-05 14:57:19,071 INFO:     Found new best model at epoch 66
2023-01-05 14:57:19,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:19,072 INFO:     Epoch: 67
2023-01-05 14:57:21,259 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.34498650034268696, 'Total loss': 0.34498650034268696} | train loss {'Reaction outcome loss': 0.2962361462686184, 'Total loss': 0.2962361462686184}
2023-01-05 14:57:21,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:21,260 INFO:     Epoch: 68
2023-01-05 14:57:23,427 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.30901709794998167, 'Total loss': 0.30901709794998167} | train loss {'Reaction outcome loss': 0.29846282509991723, 'Total loss': 0.29846282509991723}
2023-01-05 14:57:23,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:23,428 INFO:     Epoch: 69
2023-01-05 14:57:25,605 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.34008017828067144, 'Total loss': 0.34008017828067144} | train loss {'Reaction outcome loss': 0.29087992470684276, 'Total loss': 0.29087992470684276}
2023-01-05 14:57:25,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:25,605 INFO:     Epoch: 70
2023-01-05 14:57:27,784 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3426680684089661, 'Total loss': 0.3426680684089661} | train loss {'Reaction outcome loss': 0.2924629184315457, 'Total loss': 0.2924629184315457}
2023-01-05 14:57:27,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:27,784 INFO:     Epoch: 71
2023-01-05 14:57:29,969 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3946557323137919, 'Total loss': 0.3946557323137919} | train loss {'Reaction outcome loss': 0.29309800022492444, 'Total loss': 0.29309800022492444}
2023-01-05 14:57:29,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:29,970 INFO:     Epoch: 72
2023-01-05 14:57:32,137 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3425333966811498, 'Total loss': 0.3425333966811498} | train loss {'Reaction outcome loss': 0.2896084814420799, 'Total loss': 0.2896084814420799}
2023-01-05 14:57:32,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:32,137 INFO:     Epoch: 73
2023-01-05 14:57:34,306 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3072219093640645, 'Total loss': 0.3072219093640645} | train loss {'Reaction outcome loss': 0.2906141737408012, 'Total loss': 0.2906141737408012}
2023-01-05 14:57:34,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:34,306 INFO:     Epoch: 74
2023-01-05 14:57:36,437 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.35186592986186344, 'Total loss': 0.35186592986186344} | train loss {'Reaction outcome loss': 0.29167344692387503, 'Total loss': 0.29167344692387503}
2023-01-05 14:57:36,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:36,437 INFO:     Epoch: 75
2023-01-05 14:57:38,565 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.2973600854476293, 'Total loss': 0.2973600854476293} | train loss {'Reaction outcome loss': 0.2809363166686066, 'Total loss': 0.2809363166686066}
2023-01-05 14:57:38,566 INFO:     Found new best model at epoch 75
2023-01-05 14:57:38,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:38,567 INFO:     Epoch: 76
2023-01-05 14:57:40,700 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3184064288934072, 'Total loss': 0.3184064288934072} | train loss {'Reaction outcome loss': 0.2862570790478783, 'Total loss': 0.2862570790478783}
2023-01-05 14:57:40,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:40,701 INFO:     Epoch: 77
2023-01-05 14:57:42,831 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.33723092277844746, 'Total loss': 0.33723092277844746} | train loss {'Reaction outcome loss': 0.2830464968960868, 'Total loss': 0.2830464968960868}
2023-01-05 14:57:42,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:42,831 INFO:     Epoch: 78
2023-01-05 14:57:44,951 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3457725261648496, 'Total loss': 0.3457725261648496} | train loss {'Reaction outcome loss': 0.2819734679358284, 'Total loss': 0.2819734679358284}
2023-01-05 14:57:44,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:44,952 INFO:     Epoch: 79
2023-01-05 14:57:47,083 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3356703619162242, 'Total loss': 0.3356703619162242} | train loss {'Reaction outcome loss': 0.2804681175000911, 'Total loss': 0.2804681175000911}
2023-01-05 14:57:47,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:47,084 INFO:     Epoch: 80
2023-01-05 14:57:49,214 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.31967825815081596, 'Total loss': 0.31967825815081596} | train loss {'Reaction outcome loss': 0.2700893339585431, 'Total loss': 0.2700893339585431}
2023-01-05 14:57:49,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:49,214 INFO:     Epoch: 81
2023-01-05 14:57:51,356 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.31740833024183907, 'Total loss': 0.31740833024183907} | train loss {'Reaction outcome loss': 0.27500314158081574, 'Total loss': 0.27500314158081574}
2023-01-05 14:57:51,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:51,357 INFO:     Epoch: 82
2023-01-05 14:57:53,494 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.2949914206750691, 'Total loss': 0.2949914206750691} | train loss {'Reaction outcome loss': 0.2763270591691571, 'Total loss': 0.2763270591691571}
2023-01-05 14:57:53,494 INFO:     Found new best model at epoch 82
2023-01-05 14:57:53,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:53,495 INFO:     Epoch: 83
2023-01-05 14:57:55,604 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3173895448446274, 'Total loss': 0.3173895448446274} | train loss {'Reaction outcome loss': 0.2764291931079687, 'Total loss': 0.2764291931079687}
2023-01-05 14:57:55,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:55,604 INFO:     Epoch: 84
2023-01-05 14:57:57,742 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3271170139312744, 'Total loss': 0.3271170139312744} | train loss {'Reaction outcome loss': 0.2745000393993228, 'Total loss': 0.2745000393993228}
2023-01-05 14:57:57,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:57,742 INFO:     Epoch: 85
2023-01-05 14:57:59,874 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.32044290949900944, 'Total loss': 0.32044290949900944} | train loss {'Reaction outcome loss': 0.2693910564493089, 'Total loss': 0.2693910564493089}
2023-01-05 14:57:59,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:57:59,875 INFO:     Epoch: 86
2023-01-05 14:58:01,996 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.32548317487041156, 'Total loss': 0.32548317487041156} | train loss {'Reaction outcome loss': 0.2679170941777636, 'Total loss': 0.2679170941777636}
2023-01-05 14:58:01,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:01,996 INFO:     Epoch: 87
2023-01-05 14:58:04,113 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3280084078510602, 'Total loss': 0.3280084078510602} | train loss {'Reaction outcome loss': 0.2634089816375262, 'Total loss': 0.2634089816375262}
2023-01-05 14:58:04,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:04,113 INFO:     Epoch: 88
2023-01-05 14:58:06,237 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3303179850180944, 'Total loss': 0.3303179850180944} | train loss {'Reaction outcome loss': 0.26251296465876545, 'Total loss': 0.26251296465876545}
2023-01-05 14:58:06,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:06,237 INFO:     Epoch: 89
2023-01-05 14:58:08,379 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.33596422473589577, 'Total loss': 0.33596422473589577} | train loss {'Reaction outcome loss': 0.25707882411614824, 'Total loss': 0.25707882411614824}
2023-01-05 14:58:08,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:08,379 INFO:     Epoch: 90
2023-01-05 14:58:10,527 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.31909512480099994, 'Total loss': 0.31909512480099994} | train loss {'Reaction outcome loss': 0.2521046994757043, 'Total loss': 0.2521046994757043}
2023-01-05 14:58:10,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:10,529 INFO:     Epoch: 91
2023-01-05 14:58:12,641 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.34868235389391583, 'Total loss': 0.34868235389391583} | train loss {'Reaction outcome loss': 0.26392106435866686, 'Total loss': 0.26392106435866686}
2023-01-05 14:58:12,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:12,641 INFO:     Epoch: 92
2023-01-05 14:58:14,778 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.2994302729765574, 'Total loss': 0.2994302729765574} | train loss {'Reaction outcome loss': 0.2510171125432218, 'Total loss': 0.2510171125432218}
2023-01-05 14:58:14,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:14,778 INFO:     Epoch: 93
2023-01-05 14:58:16,899 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3424018343289693, 'Total loss': 0.3424018343289693} | train loss {'Reaction outcome loss': 0.25907378407181614, 'Total loss': 0.25907378407181614}
2023-01-05 14:58:16,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:16,900 INFO:     Epoch: 94
2023-01-05 14:58:19,021 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3313545892635981, 'Total loss': 0.3313545892635981} | train loss {'Reaction outcome loss': 0.2585556934907162, 'Total loss': 0.2585556934907162}
2023-01-05 14:58:19,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:19,022 INFO:     Epoch: 95
2023-01-05 14:58:21,151 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3596965193748474, 'Total loss': 0.3596965193748474} | train loss {'Reaction outcome loss': 0.2508669190965321, 'Total loss': 0.2508669190965321}
2023-01-05 14:58:21,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:21,151 INFO:     Epoch: 96
2023-01-05 14:58:23,267 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3227731227874756, 'Total loss': 0.3227731227874756} | train loss {'Reaction outcome loss': 0.25670625685449067, 'Total loss': 0.25670625685449067}
2023-01-05 14:58:23,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:23,268 INFO:     Epoch: 97
2023-01-05 14:58:25,373 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3747350255648295, 'Total loss': 0.3747350255648295} | train loss {'Reaction outcome loss': 0.25366869532115704, 'Total loss': 0.25366869532115704}
2023-01-05 14:58:25,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:25,373 INFO:     Epoch: 98
2023-01-05 14:58:27,338 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3100194469094276, 'Total loss': 0.3100194469094276} | train loss {'Reaction outcome loss': 0.24904886115152036, 'Total loss': 0.24904886115152036}
2023-01-05 14:58:27,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:27,338 INFO:     Epoch: 99
2023-01-05 14:58:29,449 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3373099982738495, 'Total loss': 0.3373099982738495} | train loss {'Reaction outcome loss': 0.24738987631089712, 'Total loss': 0.24738987631089712}
2023-01-05 14:58:29,450 INFO:     Best model found after epoch 83 of 100.
2023-01-05 14:58:29,450 INFO:   Done with stage: TRAINING
2023-01-05 14:58:29,450 INFO:   Starting stage: EVALUATION
2023-01-05 14:58:29,589 INFO:   Done with stage: EVALUATION
2023-01-05 14:58:29,590 INFO:   Leaving out SEQ value Fold_2
2023-01-05 14:58:29,602 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 14:58:29,603 INFO:   Starting stage: FEATURE SCALING
2023-01-05 14:58:30,259 INFO:   Done with stage: FEATURE SCALING
2023-01-05 14:58:30,259 INFO:   Starting stage: SCALING TARGETS
2023-01-05 14:58:30,327 INFO:   Done with stage: SCALING TARGETS
2023-01-05 14:58:30,327 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:58:30,327 INFO:     No hyperparam tuning for this model
2023-01-05 14:58:30,327 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 14:58:30,327 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 14:58:30,328 INFO:     None feature selector for col prot
2023-01-05 14:58:30,328 INFO:     None feature selector for col prot
2023-01-05 14:58:30,328 INFO:     None feature selector for col prot
2023-01-05 14:58:30,329 INFO:     None feature selector for col chem
2023-01-05 14:58:30,329 INFO:     None feature selector for col chem
2023-01-05 14:58:30,329 INFO:     None feature selector for col chem
2023-01-05 14:58:30,329 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 14:58:30,329 INFO:   Starting stage: BUILD MODEL
2023-01-05 14:58:30,330 INFO:     Number of params in model 72901
2023-01-05 14:58:30,333 INFO:   Done with stage: BUILD MODEL
2023-01-05 14:58:30,334 INFO:   Starting stage: TRAINING
2023-01-05 14:58:30,393 INFO:     Val loss before train {'Reaction outcome loss': 1.0613144199053446, 'Total loss': 1.0613144199053446}
2023-01-05 14:58:30,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:30,393 INFO:     Epoch: 0
2023-01-05 14:58:32,526 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.852302618821462, 'Total loss': 0.852302618821462} | train loss {'Reaction outcome loss': 0.9256162749252458, 'Total loss': 0.9256162749252458}
2023-01-05 14:58:32,526 INFO:     Found new best model at epoch 0
2023-01-05 14:58:32,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:32,527 INFO:     Epoch: 1
2023-01-05 14:58:34,657 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6604622185230256, 'Total loss': 0.6604622185230256} | train loss {'Reaction outcome loss': 0.7646386767176581, 'Total loss': 0.7646386767176581}
2023-01-05 14:58:34,657 INFO:     Found new best model at epoch 1
2023-01-05 14:58:34,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:34,659 INFO:     Epoch: 2
2023-01-05 14:58:36,794 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5518307030200958, 'Total loss': 0.5518307030200958} | train loss {'Reaction outcome loss': 0.6092109324113615, 'Total loss': 0.6092109324113615}
2023-01-05 14:58:36,794 INFO:     Found new best model at epoch 2
2023-01-05 14:58:36,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:36,795 INFO:     Epoch: 3
2023-01-05 14:58:38,942 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5533212860425313, 'Total loss': 0.5533212860425313} | train loss {'Reaction outcome loss': 0.5377732989863548, 'Total loss': 0.5377732989863548}
2023-01-05 14:58:38,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:38,942 INFO:     Epoch: 4
2023-01-05 14:58:41,084 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5510508477687835, 'Total loss': 0.5510508477687835} | train loss {'Reaction outcome loss': 0.5157869115060169, 'Total loss': 0.5157869115060169}
2023-01-05 14:58:41,084 INFO:     Found new best model at epoch 4
2023-01-05 14:58:41,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:41,085 INFO:     Epoch: 5
2023-01-05 14:58:43,224 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5336705386638642, 'Total loss': 0.5336705386638642} | train loss {'Reaction outcome loss': 0.4959689362541489, 'Total loss': 0.4959689362541489}
2023-01-05 14:58:43,224 INFO:     Found new best model at epoch 5
2023-01-05 14:58:43,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:43,225 INFO:     Epoch: 6
2023-01-05 14:58:45,360 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.524269159634908, 'Total loss': 0.524269159634908} | train loss {'Reaction outcome loss': 0.5065558509280285, 'Total loss': 0.5065558509280285}
2023-01-05 14:58:45,360 INFO:     Found new best model at epoch 6
2023-01-05 14:58:45,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:45,362 INFO:     Epoch: 7
2023-01-05 14:58:47,518 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4959919214248657, 'Total loss': 0.4959919214248657} | train loss {'Reaction outcome loss': 0.48163428811012243, 'Total loss': 0.48163428811012243}
2023-01-05 14:58:47,519 INFO:     Found new best model at epoch 7
2023-01-05 14:58:47,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:47,520 INFO:     Epoch: 8
2023-01-05 14:58:49,665 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49456206361452737, 'Total loss': 0.49456206361452737} | train loss {'Reaction outcome loss': 0.47328165688794915, 'Total loss': 0.47328165688794915}
2023-01-05 14:58:49,665 INFO:     Found new best model at epoch 8
2023-01-05 14:58:49,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:49,666 INFO:     Epoch: 9
2023-01-05 14:58:51,813 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48349749445915224, 'Total loss': 0.48349749445915224} | train loss {'Reaction outcome loss': 0.47252621404502704, 'Total loss': 0.47252621404502704}
2023-01-05 14:58:51,813 INFO:     Found new best model at epoch 9
2023-01-05 14:58:51,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:51,814 INFO:     Epoch: 10
2023-01-05 14:58:53,950 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4601642926534017, 'Total loss': 0.4601642926534017} | train loss {'Reaction outcome loss': 0.4649419029229793, 'Total loss': 0.4649419029229793}
2023-01-05 14:58:53,951 INFO:     Found new best model at epoch 10
2023-01-05 14:58:53,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:53,953 INFO:     Epoch: 11
2023-01-05 14:58:56,103 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4788371086120605, 'Total loss': 0.4788371086120605} | train loss {'Reaction outcome loss': 0.46513962011511856, 'Total loss': 0.46513962011511856}
2023-01-05 14:58:56,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:56,103 INFO:     Epoch: 12
2023-01-05 14:58:58,243 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4707036395867666, 'Total loss': 0.4707036395867666} | train loss {'Reaction outcome loss': 0.45337977404773666, 'Total loss': 0.45337977404773666}
2023-01-05 14:58:58,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:58:58,243 INFO:     Epoch: 13
2023-01-05 14:59:00,375 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4735625227292379, 'Total loss': 0.4735625227292379} | train loss {'Reaction outcome loss': 0.4566292101584807, 'Total loss': 0.4566292101584807}
2023-01-05 14:59:00,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:00,375 INFO:     Epoch: 14
2023-01-05 14:59:02,492 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45312467217445374, 'Total loss': 0.45312467217445374} | train loss {'Reaction outcome loss': 0.44975077843064093, 'Total loss': 0.44975077843064093}
2023-01-05 14:59:02,493 INFO:     Found new best model at epoch 14
2023-01-05 14:59:02,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:02,494 INFO:     Epoch: 15
2023-01-05 14:59:04,614 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46677042841911315, 'Total loss': 0.46677042841911315} | train loss {'Reaction outcome loss': 0.44742668499036325, 'Total loss': 0.44742668499036325}
2023-01-05 14:59:04,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:04,615 INFO:     Epoch: 16
2023-01-05 14:59:06,765 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45829033851623535, 'Total loss': 0.45829033851623535} | train loss {'Reaction outcome loss': 0.4420728423241256, 'Total loss': 0.4420728423241256}
2023-01-05 14:59:06,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:06,766 INFO:     Epoch: 17
2023-01-05 14:59:08,914 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4759620447953542, 'Total loss': 0.4759620447953542} | train loss {'Reaction outcome loss': 0.4344387174165551, 'Total loss': 0.4344387174165551}
2023-01-05 14:59:08,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:08,915 INFO:     Epoch: 18
2023-01-05 14:59:11,064 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4541323403517405, 'Total loss': 0.4541323403517405} | train loss {'Reaction outcome loss': 0.4293586736733931, 'Total loss': 0.4293586736733931}
2023-01-05 14:59:11,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:11,064 INFO:     Epoch: 19
2023-01-05 14:59:13,218 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4548644423484802, 'Total loss': 0.4548644423484802} | train loss {'Reaction outcome loss': 0.42364601412639563, 'Total loss': 0.42364601412639563}
2023-01-05 14:59:13,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:13,218 INFO:     Epoch: 20
2023-01-05 14:59:15,354 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4328445941209793, 'Total loss': 0.4328445941209793} | train loss {'Reaction outcome loss': 0.42347838296689955, 'Total loss': 0.42347838296689955}
2023-01-05 14:59:15,354 INFO:     Found new best model at epoch 20
2023-01-05 14:59:15,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:15,355 INFO:     Epoch: 21
2023-01-05 14:59:17,486 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4584962824980418, 'Total loss': 0.4584962824980418} | train loss {'Reaction outcome loss': 0.418734166747553, 'Total loss': 0.418734166747553}
2023-01-05 14:59:17,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:17,487 INFO:     Epoch: 22
2023-01-05 14:59:19,626 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42116617610057194, 'Total loss': 0.42116617610057194} | train loss {'Reaction outcome loss': 0.4117842042940775, 'Total loss': 0.4117842042940775}
2023-01-05 14:59:19,626 INFO:     Found new best model at epoch 22
2023-01-05 14:59:19,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:19,627 INFO:     Epoch: 23
2023-01-05 14:59:21,776 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4593049923578898, 'Total loss': 0.4593049923578898} | train loss {'Reaction outcome loss': 0.4072804961596494, 'Total loss': 0.4072804961596494}
2023-01-05 14:59:21,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:21,776 INFO:     Epoch: 24
2023-01-05 14:59:23,932 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4549407328168551, 'Total loss': 0.4549407328168551} | train loss {'Reaction outcome loss': 0.40617953902382514, 'Total loss': 0.40617953902382514}
2023-01-05 14:59:23,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:23,933 INFO:     Epoch: 25
2023-01-05 14:59:26,078 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4663005391756693, 'Total loss': 0.4663005391756693} | train loss {'Reaction outcome loss': 0.41826483731468517, 'Total loss': 0.41826483731468517}
2023-01-05 14:59:26,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:26,078 INFO:     Epoch: 26
2023-01-05 14:59:28,219 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44061906188726424, 'Total loss': 0.44061906188726424} | train loss {'Reaction outcome loss': 0.4401658427888069, 'Total loss': 0.4401658427888069}
2023-01-05 14:59:28,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:28,219 INFO:     Epoch: 27
2023-01-05 14:59:30,353 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4351328621308009, 'Total loss': 0.4351328621308009} | train loss {'Reaction outcome loss': 0.4125146034375707, 'Total loss': 0.4125146034375707}
2023-01-05 14:59:30,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:30,354 INFO:     Epoch: 28
2023-01-05 14:59:32,489 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40556401014328003, 'Total loss': 0.40556401014328003} | train loss {'Reaction outcome loss': 0.4105144194394782, 'Total loss': 0.4105144194394782}
2023-01-05 14:59:32,489 INFO:     Found new best model at epoch 28
2023-01-05 14:59:32,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:32,490 INFO:     Epoch: 29
2023-01-05 14:59:34,665 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41283155182997383, 'Total loss': 0.41283155182997383} | train loss {'Reaction outcome loss': 0.4225561697897227, 'Total loss': 0.4225561697897227}
2023-01-05 14:59:34,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:34,665 INFO:     Epoch: 30
2023-01-05 14:59:36,832 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4401535987854004, 'Total loss': 0.4401535987854004} | train loss {'Reaction outcome loss': 0.38207936186707864, 'Total loss': 0.38207936186707864}
2023-01-05 14:59:36,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:36,833 INFO:     Epoch: 31
2023-01-05 14:59:38,960 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43355557521184285, 'Total loss': 0.43355557521184285} | train loss {'Reaction outcome loss': 0.37769388441212365, 'Total loss': 0.37769388441212365}
2023-01-05 14:59:38,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:38,960 INFO:     Epoch: 32
2023-01-05 14:59:41,147 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4417137622833252, 'Total loss': 0.4417137622833252} | train loss {'Reaction outcome loss': 0.3712694371470075, 'Total loss': 0.3712694371470075}
2023-01-05 14:59:41,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:41,147 INFO:     Epoch: 33
2023-01-05 14:59:43,335 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43898511628309883, 'Total loss': 0.43898511628309883} | train loss {'Reaction outcome loss': 0.37350335121690464, 'Total loss': 0.37350335121690464}
2023-01-05 14:59:43,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:43,335 INFO:     Epoch: 34
2023-01-05 14:59:45,516 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42465449968973795, 'Total loss': 0.42465449968973795} | train loss {'Reaction outcome loss': 0.36943389479057404, 'Total loss': 0.36943389479057404}
2023-01-05 14:59:45,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:45,517 INFO:     Epoch: 35
2023-01-05 14:59:47,713 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4032464404900869, 'Total loss': 0.4032464404900869} | train loss {'Reaction outcome loss': 0.36152402946617507, 'Total loss': 0.36152402946617507}
2023-01-05 14:59:47,713 INFO:     Found new best model at epoch 35
2023-01-05 14:59:47,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:47,715 INFO:     Epoch: 36
2023-01-05 14:59:49,919 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4525936444600423, 'Total loss': 0.4525936444600423} | train loss {'Reaction outcome loss': 0.35623300437262095, 'Total loss': 0.35623300437262095}
2023-01-05 14:59:49,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:49,919 INFO:     Epoch: 37
2023-01-05 14:59:52,068 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4418500651915868, 'Total loss': 0.4418500651915868} | train loss {'Reaction outcome loss': 0.35804662273696286, 'Total loss': 0.35804662273696286}
2023-01-05 14:59:52,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:52,068 INFO:     Epoch: 38
2023-01-05 14:59:54,215 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4079634586970011, 'Total loss': 0.4079634586970011} | train loss {'Reaction outcome loss': 0.35679464646534104, 'Total loss': 0.35679464646534104}
2023-01-05 14:59:54,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:54,216 INFO:     Epoch: 39
2023-01-05 14:59:56,355 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39673731923103334, 'Total loss': 0.39673731923103334} | train loss {'Reaction outcome loss': 0.350579576818205, 'Total loss': 0.350579576818205}
2023-01-05 14:59:56,355 INFO:     Found new best model at epoch 39
2023-01-05 14:59:56,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:56,356 INFO:     Epoch: 40
2023-01-05 14:59:58,504 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4243818352619807, 'Total loss': 0.4243818352619807} | train loss {'Reaction outcome loss': 0.349767305618287, 'Total loss': 0.349767305618287}
2023-01-05 14:59:58,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 14:59:58,505 INFO:     Epoch: 41
2023-01-05 15:00:00,722 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42056287328402203, 'Total loss': 0.42056287328402203} | train loss {'Reaction outcome loss': 0.3500663136464014, 'Total loss': 0.3500663136464014}
2023-01-05 15:00:00,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:00,723 INFO:     Epoch: 42
2023-01-05 15:00:02,871 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4542258530855179, 'Total loss': 0.4542258530855179} | train loss {'Reaction outcome loss': 0.3524854901530173, 'Total loss': 0.3524854901530173}
2023-01-05 15:00:02,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:02,871 INFO:     Epoch: 43
2023-01-05 15:00:05,042 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40614610314369204, 'Total loss': 0.40614610314369204} | train loss {'Reaction outcome loss': 0.44149910570185835, 'Total loss': 0.44149910570185835}
2023-01-05 15:00:05,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:05,042 INFO:     Epoch: 44
2023-01-05 15:00:07,195 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44166328608989713, 'Total loss': 0.44166328608989713} | train loss {'Reaction outcome loss': 0.35750029537914507, 'Total loss': 0.35750029537914507}
2023-01-05 15:00:07,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:07,195 INFO:     Epoch: 45
2023-01-05 15:00:09,342 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42935551355282464, 'Total loss': 0.42935551355282464} | train loss {'Reaction outcome loss': 0.34433147772421985, 'Total loss': 0.34433147772421985}
2023-01-05 15:00:09,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:09,343 INFO:     Epoch: 46
2023-01-05 15:00:11,512 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4208313743273417, 'Total loss': 0.4208313743273417} | train loss {'Reaction outcome loss': 0.3350759610766545, 'Total loss': 0.3350759610766545}
2023-01-05 15:00:11,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:11,512 INFO:     Epoch: 47
2023-01-05 15:00:13,677 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.411598294476668, 'Total loss': 0.411598294476668} | train loss {'Reaction outcome loss': 0.3340989817482072, 'Total loss': 0.3340989817482072}
2023-01-05 15:00:13,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:13,678 INFO:     Epoch: 48
2023-01-05 15:00:15,832 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42486352622509005, 'Total loss': 0.42486352622509005} | train loss {'Reaction outcome loss': 0.3330421790173455, 'Total loss': 0.3330421790173455}
2023-01-05 15:00:15,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:15,833 INFO:     Epoch: 49
2023-01-05 15:00:17,987 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4389627784490585, 'Total loss': 0.4389627784490585} | train loss {'Reaction outcome loss': 0.32414969757529977, 'Total loss': 0.32414969757529977}
2023-01-05 15:00:17,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:17,987 INFO:     Epoch: 50
2023-01-05 15:00:20,143 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4482635885477066, 'Total loss': 0.4482635885477066} | train loss {'Reaction outcome loss': 0.32310734463744273, 'Total loss': 0.32310734463744273}
2023-01-05 15:00:20,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:20,144 INFO:     Epoch: 51
2023-01-05 15:00:22,321 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39045169949531555, 'Total loss': 0.39045169949531555} | train loss {'Reaction outcome loss': 0.31544601449712756, 'Total loss': 0.31544601449712756}
2023-01-05 15:00:22,321 INFO:     Found new best model at epoch 51
2023-01-05 15:00:22,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:22,323 INFO:     Epoch: 52
2023-01-05 15:00:24,469 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38076287508010864, 'Total loss': 0.38076287508010864} | train loss {'Reaction outcome loss': 0.3161435713266036, 'Total loss': 0.3161435713266036}
2023-01-05 15:00:24,469 INFO:     Found new best model at epoch 52
2023-01-05 15:00:24,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:24,471 INFO:     Epoch: 53
2023-01-05 15:00:26,624 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4100439210732778, 'Total loss': 0.4100439210732778} | train loss {'Reaction outcome loss': 0.31579558243854833, 'Total loss': 0.31579558243854833}
2023-01-05 15:00:26,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:26,624 INFO:     Epoch: 54
2023-01-05 15:00:28,769 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46388484835624694, 'Total loss': 0.46388484835624694} | train loss {'Reaction outcome loss': 0.30682214559055865, 'Total loss': 0.30682214559055865}
2023-01-05 15:00:28,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:28,770 INFO:     Epoch: 55
2023-01-05 15:00:30,952 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41133771439393363, 'Total loss': 0.41133771439393363} | train loss {'Reaction outcome loss': 0.3092724302945683, 'Total loss': 0.3092724302945683}
2023-01-05 15:00:30,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:30,952 INFO:     Epoch: 56
2023-01-05 15:00:33,095 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41328906963268913, 'Total loss': 0.41328906963268913} | train loss {'Reaction outcome loss': 0.3070046532008311, 'Total loss': 0.3070046532008311}
2023-01-05 15:00:33,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:33,096 INFO:     Epoch: 57
2023-01-05 15:00:35,242 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39497327506542207, 'Total loss': 0.39497327506542207} | train loss {'Reaction outcome loss': 0.3068926569202618, 'Total loss': 0.3068926569202618}
2023-01-05 15:00:35,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:35,243 INFO:     Epoch: 58
2023-01-05 15:00:37,379 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4088077574968338, 'Total loss': 0.4088077574968338} | train loss {'Reaction outcome loss': 0.3031217477550524, 'Total loss': 0.3031217477550524}
2023-01-05 15:00:37,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:37,380 INFO:     Epoch: 59
2023-01-05 15:00:39,530 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4441740185022354, 'Total loss': 0.4441740185022354} | train loss {'Reaction outcome loss': 0.29736780576817895, 'Total loss': 0.29736780576817895}
2023-01-05 15:00:39,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:39,530 INFO:     Epoch: 60
2023-01-05 15:00:41,675 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4158673663934072, 'Total loss': 0.4158673663934072} | train loss {'Reaction outcome loss': 0.3021468856062764, 'Total loss': 0.3021468856062764}
2023-01-05 15:00:41,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:41,676 INFO:     Epoch: 61
2023-01-05 15:00:43,829 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4301227231820424, 'Total loss': 0.4301227231820424} | train loss {'Reaction outcome loss': 0.29339142914938315, 'Total loss': 0.29339142914938315}
2023-01-05 15:00:43,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:43,829 INFO:     Epoch: 62
2023-01-05 15:00:45,991 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40604971051216127, 'Total loss': 0.40604971051216127} | train loss {'Reaction outcome loss': 0.2901621964976083, 'Total loss': 0.2901621964976083}
2023-01-05 15:00:45,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:45,991 INFO:     Epoch: 63
2023-01-05 15:00:48,135 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40382632513840994, 'Total loss': 0.40382632513840994} | train loss {'Reaction outcome loss': 0.28395842370156205, 'Total loss': 0.28395842370156205}
2023-01-05 15:00:48,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:48,136 INFO:     Epoch: 64
2023-01-05 15:00:50,274 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4453840807080269, 'Total loss': 0.4453840807080269} | train loss {'Reaction outcome loss': 0.29303690459093323, 'Total loss': 0.29303690459093323}
2023-01-05 15:00:50,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:50,274 INFO:     Epoch: 65
2023-01-05 15:00:52,439 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38270963231722516, 'Total loss': 0.38270963231722516} | train loss {'Reaction outcome loss': 0.34156952500073373, 'Total loss': 0.34156952500073373}
2023-01-05 15:00:52,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:52,439 INFO:     Epoch: 66
2023-01-05 15:00:54,579 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4181004563967387, 'Total loss': 0.4181004563967387} | train loss {'Reaction outcome loss': 0.2940210752270144, 'Total loss': 0.2940210752270144}
2023-01-05 15:00:54,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:54,579 INFO:     Epoch: 67
2023-01-05 15:00:56,728 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4341410915056864, 'Total loss': 0.4341410915056864} | train loss {'Reaction outcome loss': 0.28688728719229717, 'Total loss': 0.28688728719229717}
2023-01-05 15:00:56,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:56,728 INFO:     Epoch: 68
2023-01-05 15:00:58,885 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3966274678707123, 'Total loss': 0.3966274678707123} | train loss {'Reaction outcome loss': 0.2893621673036883, 'Total loss': 0.2893621673036883}
2023-01-05 15:00:58,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:00:58,885 INFO:     Epoch: 69
2023-01-05 15:01:01,032 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43839771846930187, 'Total loss': 0.43839771846930187} | train loss {'Reaction outcome loss': 0.29409924612475047, 'Total loss': 0.29409924612475047}
2023-01-05 15:01:01,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:01,032 INFO:     Epoch: 70
2023-01-05 15:01:03,183 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4376045693953832, 'Total loss': 0.4376045693953832} | train loss {'Reaction outcome loss': 0.2956834618646784, 'Total loss': 0.2956834618646784}
2023-01-05 15:01:03,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:03,183 INFO:     Epoch: 71
2023-01-05 15:01:05,320 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4138000895579656, 'Total loss': 0.4138000895579656} | train loss {'Reaction outcome loss': 0.2874850050961176, 'Total loss': 0.2874850050961176}
2023-01-05 15:01:05,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:05,321 INFO:     Epoch: 72
2023-01-05 15:01:07,445 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4653960347175598, 'Total loss': 0.4653960347175598} | train loss {'Reaction outcome loss': 0.2828018294639665, 'Total loss': 0.2828018294639665}
2023-01-05 15:01:07,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:07,446 INFO:     Epoch: 73
2023-01-05 15:01:09,580 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4465977311134338, 'Total loss': 0.4465977311134338} | train loss {'Reaction outcome loss': 0.2813643507956379, 'Total loss': 0.2813643507956379}
2023-01-05 15:01:09,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:09,581 INFO:     Epoch: 74
2023-01-05 15:01:11,717 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4080063437422117, 'Total loss': 0.4080063437422117} | train loss {'Reaction outcome loss': 0.3004419339881481, 'Total loss': 0.3004419339881481}
2023-01-05 15:01:11,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:11,718 INFO:     Epoch: 75
2023-01-05 15:01:13,860 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4475653201341629, 'Total loss': 0.4475653201341629} | train loss {'Reaction outcome loss': 0.2846192073454891, 'Total loss': 0.2846192073454891}
2023-01-05 15:01:13,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:13,860 INFO:     Epoch: 76
2023-01-05 15:01:15,993 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4030563165744146, 'Total loss': 0.4030563165744146} | train loss {'Reaction outcome loss': 0.28824356966651976, 'Total loss': 0.28824356966651976}
2023-01-05 15:01:15,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:15,995 INFO:     Epoch: 77
2023-01-05 15:01:18,144 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4185799593726794, 'Total loss': 0.4185799593726794} | train loss {'Reaction outcome loss': 0.28909244750072993, 'Total loss': 0.28909244750072993}
2023-01-05 15:01:18,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:18,145 INFO:     Epoch: 78
2023-01-05 15:01:20,316 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4018101950486501, 'Total loss': 0.4018101950486501} | train loss {'Reaction outcome loss': 0.30490195669193304, 'Total loss': 0.30490195669193304}
2023-01-05 15:01:20,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:20,316 INFO:     Epoch: 79
2023-01-05 15:01:22,475 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4472761943936348, 'Total loss': 0.4472761943936348} | train loss {'Reaction outcome loss': 0.28152186540967744, 'Total loss': 0.28152186540967744}
2023-01-05 15:01:22,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:22,476 INFO:     Epoch: 80
2023-01-05 15:01:24,602 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42214608589808145, 'Total loss': 0.42214608589808145} | train loss {'Reaction outcome loss': 0.2938129775617542, 'Total loss': 0.2938129775617542}
2023-01-05 15:01:24,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:24,603 INFO:     Epoch: 81
2023-01-05 15:01:26,734 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41123883724212645, 'Total loss': 0.41123883724212645} | train loss {'Reaction outcome loss': 0.2726278673481849, 'Total loss': 0.2726278673481849}
2023-01-05 15:01:26,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:26,735 INFO:     Epoch: 82
2023-01-05 15:01:28,883 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4021131793657939, 'Total loss': 0.4021131793657939} | train loss {'Reaction outcome loss': 0.275300037217043, 'Total loss': 0.275300037217043}
2023-01-05 15:01:28,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:28,883 INFO:     Epoch: 83
2023-01-05 15:01:31,032 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4004295110702515, 'Total loss': 0.4004295110702515} | train loss {'Reaction outcome loss': 0.2682049857795009, 'Total loss': 0.2682049857795009}
2023-01-05 15:01:31,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:31,032 INFO:     Epoch: 84
2023-01-05 15:01:33,178 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43559737702210743, 'Total loss': 0.43559737702210743} | train loss {'Reaction outcome loss': 0.2626919910845058, 'Total loss': 0.2626919910845058}
2023-01-05 15:01:33,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:33,180 INFO:     Epoch: 85
2023-01-05 15:01:35,313 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41418811306357384, 'Total loss': 0.41418811306357384} | train loss {'Reaction outcome loss': 0.2598666859085442, 'Total loss': 0.2598666859085442}
2023-01-05 15:01:35,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:35,314 INFO:     Epoch: 86
2023-01-05 15:01:37,450 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38838036755720773, 'Total loss': 0.38838036755720773} | train loss {'Reaction outcome loss': 0.2608745166512233, 'Total loss': 0.2608745166512233}
2023-01-05 15:01:37,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:37,450 INFO:     Epoch: 87
2023-01-05 15:01:39,589 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43393155733744304, 'Total loss': 0.43393155733744304} | train loss {'Reaction outcome loss': 0.26399822376223037, 'Total loss': 0.26399822376223037}
2023-01-05 15:01:39,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:39,591 INFO:     Epoch: 88
2023-01-05 15:01:41,731 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42716909646987916, 'Total loss': 0.42716909646987916} | train loss {'Reaction outcome loss': 0.259459555444328, 'Total loss': 0.259459555444328}
2023-01-05 15:01:41,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:41,731 INFO:     Epoch: 89
2023-01-05 15:01:43,889 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4073957808315754, 'Total loss': 0.4073957808315754} | train loss {'Reaction outcome loss': 0.26240686664781265, 'Total loss': 0.26240686664781265}
2023-01-05 15:01:43,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:43,890 INFO:     Epoch: 90
2023-01-05 15:01:46,041 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4161248097817103, 'Total loss': 0.4161248097817103} | train loss {'Reaction outcome loss': 0.26326241468389827, 'Total loss': 0.26326241468389827}
2023-01-05 15:01:46,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:46,042 INFO:     Epoch: 91
2023-01-05 15:01:48,178 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39572628115614256, 'Total loss': 0.39572628115614256} | train loss {'Reaction outcome loss': 0.2556564680594222, 'Total loss': 0.2556564680594222}
2023-01-05 15:01:48,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:48,178 INFO:     Epoch: 92
2023-01-05 15:01:50,335 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39886536200841266, 'Total loss': 0.39886536200841266} | train loss {'Reaction outcome loss': 0.2630165119939542, 'Total loss': 0.2630165119939542}
2023-01-05 15:01:50,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:50,336 INFO:     Epoch: 93
2023-01-05 15:01:52,496 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3969257682561874, 'Total loss': 0.3969257682561874} | train loss {'Reaction outcome loss': 0.27924525361859065, 'Total loss': 0.27924525361859065}
2023-01-05 15:01:52,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:52,496 INFO:     Epoch: 94
2023-01-05 15:01:54,643 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4082215528935194, 'Total loss': 0.4082215528935194} | train loss {'Reaction outcome loss': 0.300017007798369, 'Total loss': 0.300017007798369}
2023-01-05 15:01:54,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:54,644 INFO:     Epoch: 95
2023-01-05 15:01:56,799 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4259797225395838, 'Total loss': 0.4259797225395838} | train loss {'Reaction outcome loss': 0.27113018383312487, 'Total loss': 0.27113018383312487}
2023-01-05 15:01:56,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:56,800 INFO:     Epoch: 96
2023-01-05 15:01:58,954 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4233593761920929, 'Total loss': 0.4233593761920929} | train loss {'Reaction outcome loss': 0.25997256746423125, 'Total loss': 0.25997256746423125}
2023-01-05 15:01:58,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:01:58,954 INFO:     Epoch: 97
2023-01-05 15:02:01,091 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3992171972990036, 'Total loss': 0.3992171972990036} | train loss {'Reaction outcome loss': 0.26255650352771004, 'Total loss': 0.26255650352771004}
2023-01-05 15:02:01,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:01,091 INFO:     Epoch: 98
2023-01-05 15:02:03,222 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4279465854167938, 'Total loss': 0.4279465854167938} | train loss {'Reaction outcome loss': 0.24977445585798283, 'Total loss': 0.24977445585798283}
2023-01-05 15:02:03,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:03,224 INFO:     Epoch: 99
2023-01-05 15:02:05,377 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4428838868935903, 'Total loss': 0.4428838868935903} | train loss {'Reaction outcome loss': 0.25348442515942093, 'Total loss': 0.25348442515942093}
2023-01-05 15:02:05,378 INFO:     Best model found after epoch 53 of 100.
2023-01-05 15:02:05,378 INFO:   Done with stage: TRAINING
2023-01-05 15:02:05,378 INFO:   Starting stage: EVALUATION
2023-01-05 15:02:05,510 INFO:   Done with stage: EVALUATION
2023-01-05 15:02:05,510 INFO:   Leaving out SEQ value Fold_3
2023-01-05 15:02:05,523 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 15:02:05,523 INFO:   Starting stage: FEATURE SCALING
2023-01-05 15:02:06,165 INFO:   Done with stage: FEATURE SCALING
2023-01-05 15:02:06,165 INFO:   Starting stage: SCALING TARGETS
2023-01-05 15:02:06,234 INFO:   Done with stage: SCALING TARGETS
2023-01-05 15:02:06,234 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:02:06,234 INFO:     No hyperparam tuning for this model
2023-01-05 15:02:06,234 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:02:06,234 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 15:02:06,235 INFO:     None feature selector for col prot
2023-01-05 15:02:06,235 INFO:     None feature selector for col prot
2023-01-05 15:02:06,235 INFO:     None feature selector for col prot
2023-01-05 15:02:06,235 INFO:     None feature selector for col chem
2023-01-05 15:02:06,236 INFO:     None feature selector for col chem
2023-01-05 15:02:06,236 INFO:     None feature selector for col chem
2023-01-05 15:02:06,236 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 15:02:06,236 INFO:   Starting stage: BUILD MODEL
2023-01-05 15:02:06,237 INFO:     Number of params in model 72901
2023-01-05 15:02:06,240 INFO:   Done with stage: BUILD MODEL
2023-01-05 15:02:06,240 INFO:   Starting stage: TRAINING
2023-01-05 15:02:06,300 INFO:     Val loss before train {'Reaction outcome loss': 1.0964397152264913, 'Total loss': 1.0964397152264913}
2023-01-05 15:02:06,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:06,301 INFO:     Epoch: 0
2023-01-05 15:02:08,431 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8848468224207561, 'Total loss': 0.8848468224207561} | train loss {'Reaction outcome loss': 0.9106077704160218, 'Total loss': 0.9106077704160218}
2023-01-05 15:02:08,432 INFO:     Found new best model at epoch 0
2023-01-05 15:02:08,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:08,434 INFO:     Epoch: 1
2023-01-05 15:02:10,603 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6186781307061513, 'Total loss': 0.6186781307061513} | train loss {'Reaction outcome loss': 0.7275880358141401, 'Total loss': 0.7275880358141401}
2023-01-05 15:02:10,603 INFO:     Found new best model at epoch 1
2023-01-05 15:02:10,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:10,604 INFO:     Epoch: 2
2023-01-05 15:02:12,760 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5887830416361491, 'Total loss': 0.5887830416361491} | train loss {'Reaction outcome loss': 0.5796723994628891, 'Total loss': 0.5796723994628891}
2023-01-05 15:02:12,760 INFO:     Found new best model at epoch 2
2023-01-05 15:02:12,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:12,761 INFO:     Epoch: 3
2023-01-05 15:02:14,915 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5640789220730463, 'Total loss': 0.5640789220730463} | train loss {'Reaction outcome loss': 0.5306698621075222, 'Total loss': 0.5306698621075222}
2023-01-05 15:02:14,916 INFO:     Found new best model at epoch 3
2023-01-05 15:02:14,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:14,918 INFO:     Epoch: 4
2023-01-05 15:02:17,075 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5159849047660827, 'Total loss': 0.5159849047660827} | train loss {'Reaction outcome loss': 0.5192077681422234, 'Total loss': 0.5192077681422234}
2023-01-05 15:02:17,075 INFO:     Found new best model at epoch 4
2023-01-05 15:02:17,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:17,077 INFO:     Epoch: 5
2023-01-05 15:02:19,252 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5439882357915242, 'Total loss': 0.5439882357915242} | train loss {'Reaction outcome loss': 0.5093506892630155, 'Total loss': 0.5093506892630155}
2023-01-05 15:02:19,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:19,254 INFO:     Epoch: 6
2023-01-05 15:02:21,415 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5020793457825978, 'Total loss': 0.5020793457825978} | train loss {'Reaction outcome loss': 0.4954076106216129, 'Total loss': 0.4954076106216129}
2023-01-05 15:02:21,415 INFO:     Found new best model at epoch 6
2023-01-05 15:02:21,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:21,417 INFO:     Epoch: 7
2023-01-05 15:02:23,568 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5305185457070668, 'Total loss': 0.5305185457070668} | train loss {'Reaction outcome loss': 0.4876527021760526, 'Total loss': 0.4876527021760526}
2023-01-05 15:02:23,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:23,568 INFO:     Epoch: 8
2023-01-05 15:02:25,719 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5138980130354563, 'Total loss': 0.5138980130354563} | train loss {'Reaction outcome loss': 0.4860870052344989, 'Total loss': 0.4860870052344989}
2023-01-05 15:02:25,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:25,720 INFO:     Epoch: 9
2023-01-05 15:02:27,888 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5462937851746877, 'Total loss': 0.5462937851746877} | train loss {'Reaction outcome loss': 0.5010134488128234, 'Total loss': 0.5010134488128234}
2023-01-05 15:02:27,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:27,888 INFO:     Epoch: 10
2023-01-05 15:02:29,979 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5325322965780894, 'Total loss': 0.5325322965780894} | train loss {'Reaction outcome loss': 0.490376984997504, 'Total loss': 0.490376984997504}
2023-01-05 15:02:29,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:29,979 INFO:     Epoch: 11
2023-01-05 15:02:32,026 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5203917821248373, 'Total loss': 0.5203917821248373} | train loss {'Reaction outcome loss': 0.48481049981352914, 'Total loss': 0.48481049981352914}
2023-01-05 15:02:32,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:32,027 INFO:     Epoch: 12
2023-01-05 15:02:34,162 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49723195234934486, 'Total loss': 0.49723195234934486} | train loss {'Reaction outcome loss': 0.45680575148688385, 'Total loss': 0.45680575148688385}
2023-01-05 15:02:34,162 INFO:     Found new best model at epoch 12
2023-01-05 15:02:34,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:34,164 INFO:     Epoch: 13
2023-01-05 15:02:36,324 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5018592933813731, 'Total loss': 0.5018592933813731} | train loss {'Reaction outcome loss': 0.45504058052724955, 'Total loss': 0.45504058052724955}
2023-01-05 15:02:36,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:36,325 INFO:     Epoch: 14
2023-01-05 15:02:38,512 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5029827018578847, 'Total loss': 0.5029827018578847} | train loss {'Reaction outcome loss': 0.451736149492849, 'Total loss': 0.451736149492849}
2023-01-05 15:02:38,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:38,512 INFO:     Epoch: 15
2023-01-05 15:02:40,657 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47832356492678324, 'Total loss': 0.47832356492678324} | train loss {'Reaction outcome loss': 0.4460455508652966, 'Total loss': 0.4460455508652966}
2023-01-05 15:02:40,657 INFO:     Found new best model at epoch 15
2023-01-05 15:02:40,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:40,659 INFO:     Epoch: 16
2023-01-05 15:02:42,806 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4925529857476552, 'Total loss': 0.4925529857476552} | train loss {'Reaction outcome loss': 0.4401749737157513, 'Total loss': 0.4401749737157513}
2023-01-05 15:02:42,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:42,808 INFO:     Epoch: 17
2023-01-05 15:02:44,946 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4866616229216258, 'Total loss': 0.4866616229216258} | train loss {'Reaction outcome loss': 0.43770230090181494, 'Total loss': 0.43770230090181494}
2023-01-05 15:02:44,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:44,946 INFO:     Epoch: 18
2023-01-05 15:02:47,103 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49342426856358845, 'Total loss': 0.49342426856358845} | train loss {'Reaction outcome loss': 0.4356483123332694, 'Total loss': 0.4356483123332694}
2023-01-05 15:02:47,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:47,104 INFO:     Epoch: 19
2023-01-05 15:02:49,244 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4973142459988594, 'Total loss': 0.4973142459988594} | train loss {'Reaction outcome loss': 0.42960639155901753, 'Total loss': 0.42960639155901753}
2023-01-05 15:02:49,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:49,244 INFO:     Epoch: 20
2023-01-05 15:02:51,388 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4931938827037811, 'Total loss': 0.4931938827037811} | train loss {'Reaction outcome loss': 0.4305680640559792, 'Total loss': 0.4305680640559792}
2023-01-05 15:02:51,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:51,388 INFO:     Epoch: 21
2023-01-05 15:02:53,549 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4723156770070394, 'Total loss': 0.4723156770070394} | train loss {'Reaction outcome loss': 0.42344202771462314, 'Total loss': 0.42344202771462314}
2023-01-05 15:02:53,550 INFO:     Found new best model at epoch 21
2023-01-05 15:02:53,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:53,551 INFO:     Epoch: 22
2023-01-05 15:02:55,708 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4820303350687027, 'Total loss': 0.4820303350687027} | train loss {'Reaction outcome loss': 0.42055619015582785, 'Total loss': 0.42055619015582785}
2023-01-05 15:02:55,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:55,708 INFO:     Epoch: 23
2023-01-05 15:02:57,859 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.49553038080533346, 'Total loss': 0.49553038080533346} | train loss {'Reaction outcome loss': 0.4162035334348479, 'Total loss': 0.4162035334348479}
2023-01-05 15:02:57,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:02:57,859 INFO:     Epoch: 24
2023-01-05 15:03:00,123 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5035313894351323, 'Total loss': 0.5035313894351323} | train loss {'Reaction outcome loss': 0.41418324997716083, 'Total loss': 0.41418324997716083}
2023-01-05 15:03:00,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:00,124 INFO:     Epoch: 25
2023-01-05 15:03:02,313 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.504504410425822, 'Total loss': 0.504504410425822} | train loss {'Reaction outcome loss': 0.41175423200795613, 'Total loss': 0.41175423200795613}
2023-01-05 15:03:02,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:02,313 INFO:     Epoch: 26
2023-01-05 15:03:04,485 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4879090925057729, 'Total loss': 0.4879090925057729} | train loss {'Reaction outcome loss': 0.4022714752607736, 'Total loss': 0.4022714752607736}
2023-01-05 15:03:04,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:04,485 INFO:     Epoch: 27
2023-01-05 15:03:06,620 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49921936392784116, 'Total loss': 0.49921936392784116} | train loss {'Reaction outcome loss': 0.4018851843700205, 'Total loss': 0.4018851843700205}
2023-01-05 15:03:06,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:06,621 INFO:     Epoch: 28
2023-01-05 15:03:08,784 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47463486591974896, 'Total loss': 0.47463486591974896} | train loss {'Reaction outcome loss': 0.39428925146078825, 'Total loss': 0.39428925146078825}
2023-01-05 15:03:08,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:08,785 INFO:     Epoch: 29
2023-01-05 15:03:10,916 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46342041393121086, 'Total loss': 0.46342041393121086} | train loss {'Reaction outcome loss': 0.3943850642637066, 'Total loss': 0.3943850642637066}
2023-01-05 15:03:10,916 INFO:     Found new best model at epoch 29
2023-01-05 15:03:10,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:10,918 INFO:     Epoch: 30
2023-01-05 15:03:13,076 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48289682269096373, 'Total loss': 0.48289682269096373} | train loss {'Reaction outcome loss': 0.39050999055873853, 'Total loss': 0.39050999055873853}
2023-01-05 15:03:13,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:13,077 INFO:     Epoch: 31
2023-01-05 15:03:15,227 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4842787245909373, 'Total loss': 0.4842787245909373} | train loss {'Reaction outcome loss': 0.3831933290272465, 'Total loss': 0.3831933290272465}
2023-01-05 15:03:15,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:15,227 INFO:     Epoch: 32
2023-01-05 15:03:17,399 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4929390033086141, 'Total loss': 0.4929390033086141} | train loss {'Reaction outcome loss': 0.38290416490475554, 'Total loss': 0.38290416490475554}
2023-01-05 15:03:17,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:17,400 INFO:     Epoch: 33
2023-01-05 15:03:19,541 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46529953281084696, 'Total loss': 0.46529953281084696} | train loss {'Reaction outcome loss': 0.3791302534181328, 'Total loss': 0.3791302534181328}
2023-01-05 15:03:19,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:19,542 INFO:     Epoch: 34
2023-01-05 15:03:21,669 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4912736197312673, 'Total loss': 0.4912736197312673} | train loss {'Reaction outcome loss': 0.37539250934639934, 'Total loss': 0.37539250934639934}
2023-01-05 15:03:21,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:21,669 INFO:     Epoch: 35
2023-01-05 15:03:23,832 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5123771707216899, 'Total loss': 0.5123771707216899} | train loss {'Reaction outcome loss': 0.37036910552895913, 'Total loss': 0.37036910552895913}
2023-01-05 15:03:23,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:23,833 INFO:     Epoch: 36
2023-01-05 15:03:25,992 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49338639875253043, 'Total loss': 0.49338639875253043} | train loss {'Reaction outcome loss': 0.3630381181188252, 'Total loss': 0.3630381181188252}
2023-01-05 15:03:25,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:25,992 INFO:     Epoch: 37
2023-01-05 15:03:28,151 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47594142258167266, 'Total loss': 0.47594142258167266} | train loss {'Reaction outcome loss': 0.3586726458102087, 'Total loss': 0.3586726458102087}
2023-01-05 15:03:28,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:28,151 INFO:     Epoch: 38
2023-01-05 15:03:30,283 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49615972141424813, 'Total loss': 0.49615972141424813} | train loss {'Reaction outcome loss': 0.35309064668684226, 'Total loss': 0.35309064668684226}
2023-01-05 15:03:30,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:30,285 INFO:     Epoch: 39
2023-01-05 15:03:32,456 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4708580116430918, 'Total loss': 0.4708580116430918} | train loss {'Reaction outcome loss': 0.3512181560717262, 'Total loss': 0.3512181560717262}
2023-01-05 15:03:32,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:32,457 INFO:     Epoch: 40
2023-01-05 15:03:34,599 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44765109022458394, 'Total loss': 0.44765109022458394} | train loss {'Reaction outcome loss': 0.3494760532107582, 'Total loss': 0.3494760532107582}
2023-01-05 15:03:34,599 INFO:     Found new best model at epoch 40
2023-01-05 15:03:34,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:34,600 INFO:     Epoch: 41
2023-01-05 15:03:36,735 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4919650435447693, 'Total loss': 0.4919650435447693} | train loss {'Reaction outcome loss': 0.3396672073049822, 'Total loss': 0.3396672073049822}
2023-01-05 15:03:36,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:36,737 INFO:     Epoch: 42
2023-01-05 15:03:38,889 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47991151611010235, 'Total loss': 0.47991151611010235} | train loss {'Reaction outcome loss': 0.3430434757796373, 'Total loss': 0.3430434757796373}
2023-01-05 15:03:38,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:38,889 INFO:     Epoch: 43
2023-01-05 15:03:41,080 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45023820772767065, 'Total loss': 0.45023820772767065} | train loss {'Reaction outcome loss': 0.3344078395326716, 'Total loss': 0.3344078395326716}
2023-01-05 15:03:41,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:41,080 INFO:     Epoch: 44
2023-01-05 15:03:43,234 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48680055340131123, 'Total loss': 0.48680055340131123} | train loss {'Reaction outcome loss': 0.3299647495454258, 'Total loss': 0.3299647495454258}
2023-01-05 15:03:43,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:43,236 INFO:     Epoch: 45
2023-01-05 15:03:45,390 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4900393754243851, 'Total loss': 0.4900393754243851} | train loss {'Reaction outcome loss': 0.33119138457097, 'Total loss': 0.33119138457097}
2023-01-05 15:03:45,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:45,391 INFO:     Epoch: 46
2023-01-05 15:03:47,537 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5069712003072103, 'Total loss': 0.5069712003072103} | train loss {'Reaction outcome loss': 0.3309311110465585, 'Total loss': 0.3309311110465585}
2023-01-05 15:03:47,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:47,539 INFO:     Epoch: 47
2023-01-05 15:03:49,690 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4938161532084147, 'Total loss': 0.4938161532084147} | train loss {'Reaction outcome loss': 0.32452041076739196, 'Total loss': 0.32452041076739196}
2023-01-05 15:03:49,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:49,690 INFO:     Epoch: 48
2023-01-05 15:03:51,844 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5219982812801996, 'Total loss': 0.5219982812801996} | train loss {'Reaction outcome loss': 0.320843321718343, 'Total loss': 0.320843321718343}
2023-01-05 15:03:51,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:51,844 INFO:     Epoch: 49
2023-01-05 15:03:54,006 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4616339991490046, 'Total loss': 0.4616339991490046} | train loss {'Reaction outcome loss': 0.31333553963813227, 'Total loss': 0.31333553963813227}
2023-01-05 15:03:54,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:54,008 INFO:     Epoch: 50
2023-01-05 15:03:56,166 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.500212182601293, 'Total loss': 0.500212182601293} | train loss {'Reaction outcome loss': 0.3142884608106755, 'Total loss': 0.3142884608106755}
2023-01-05 15:03:56,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:56,166 INFO:     Epoch: 51
2023-01-05 15:03:58,305 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4544889271259308, 'Total loss': 0.4544889271259308} | train loss {'Reaction outcome loss': 0.3131452437652194, 'Total loss': 0.3131452437652194}
2023-01-05 15:03:58,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:03:58,305 INFO:     Epoch: 52
2023-01-05 15:04:00,474 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4966901123523712, 'Total loss': 0.4966901123523712} | train loss {'Reaction outcome loss': 0.30711224041410984, 'Total loss': 0.30711224041410984}
2023-01-05 15:04:00,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:00,476 INFO:     Epoch: 53
2023-01-05 15:04:02,623 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4423681805531184, 'Total loss': 0.4423681805531184} | train loss {'Reaction outcome loss': 0.30828871104021993, 'Total loss': 0.30828871104021993}
2023-01-05 15:04:02,623 INFO:     Found new best model at epoch 53
2023-01-05 15:04:02,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:02,624 INFO:     Epoch: 54
2023-01-05 15:04:04,787 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4973581701517105, 'Total loss': 0.4973581701517105} | train loss {'Reaction outcome loss': 0.298642975980065, 'Total loss': 0.298642975980065}
2023-01-05 15:04:04,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:04,788 INFO:     Epoch: 55
2023-01-05 15:04:06,947 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4740659773349762, 'Total loss': 0.4740659773349762} | train loss {'Reaction outcome loss': 0.29251460923874023, 'Total loss': 0.29251460923874023}
2023-01-05 15:04:06,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:06,947 INFO:     Epoch: 56
2023-01-05 15:04:09,084 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49501285552978513, 'Total loss': 0.49501285552978513} | train loss {'Reaction outcome loss': 0.3029471812314232, 'Total loss': 0.3029471812314232}
2023-01-05 15:04:09,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:09,084 INFO:     Epoch: 57
2023-01-05 15:04:11,265 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46337253352006275, 'Total loss': 0.46337253352006275} | train loss {'Reaction outcome loss': 0.29953180636801047, 'Total loss': 0.29953180636801047}
2023-01-05 15:04:11,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:11,266 INFO:     Epoch: 58
2023-01-05 15:04:13,431 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5154449641704559, 'Total loss': 0.5154449641704559} | train loss {'Reaction outcome loss': 0.2885832464578899, 'Total loss': 0.2885832464578899}
2023-01-05 15:04:13,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:13,431 INFO:     Epoch: 59
2023-01-05 15:04:15,622 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49182049036026, 'Total loss': 0.49182049036026} | train loss {'Reaction outcome loss': 0.29411997643309523, 'Total loss': 0.29411997643309523}
2023-01-05 15:04:15,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:15,623 INFO:     Epoch: 60
2023-01-05 15:04:17,767 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4946948652466138, 'Total loss': 0.4946948652466138} | train loss {'Reaction outcome loss': 0.28935419884847774, 'Total loss': 0.28935419884847774}
2023-01-05 15:04:17,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:17,768 INFO:     Epoch: 61
2023-01-05 15:04:19,907 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.463661169509093, 'Total loss': 0.463661169509093} | train loss {'Reaction outcome loss': 0.2763731294930043, 'Total loss': 0.2763731294930043}
2023-01-05 15:04:19,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:19,907 INFO:     Epoch: 62
2023-01-05 15:04:22,031 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4567060858011246, 'Total loss': 0.4567060858011246} | train loss {'Reaction outcome loss': 0.27415708632653824, 'Total loss': 0.27415708632653824}
2023-01-05 15:04:22,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:22,033 INFO:     Epoch: 63
2023-01-05 15:04:24,192 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4722190827131271, 'Total loss': 0.4722190827131271} | train loss {'Reaction outcome loss': 0.28799711146669893, 'Total loss': 0.28799711146669893}
2023-01-05 15:04:24,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:24,192 INFO:     Epoch: 64
2023-01-05 15:04:26,345 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4683639543751876, 'Total loss': 0.4683639543751876} | train loss {'Reaction outcome loss': 0.2815317957108651, 'Total loss': 0.2815317957108651}
2023-01-05 15:04:26,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:26,346 INFO:     Epoch: 65
2023-01-05 15:04:28,519 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.49157478908697766, 'Total loss': 0.49157478908697766} | train loss {'Reaction outcome loss': 0.2686391843995754, 'Total loss': 0.2686391843995754}
2023-01-05 15:04:28,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:28,520 INFO:     Epoch: 66
2023-01-05 15:04:30,668 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4821025341749191, 'Total loss': 0.4821025341749191} | train loss {'Reaction outcome loss': 0.27841553156115656, 'Total loss': 0.27841553156115656}
2023-01-05 15:04:30,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:30,668 INFO:     Epoch: 67
2023-01-05 15:04:32,809 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4591071536143621, 'Total loss': 0.4591071536143621} | train loss {'Reaction outcome loss': 0.26977940814812545, 'Total loss': 0.26977940814812545}
2023-01-05 15:04:32,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:32,809 INFO:     Epoch: 68
2023-01-05 15:04:34,975 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4692838023106257, 'Total loss': 0.4692838023106257} | train loss {'Reaction outcome loss': 0.27410980197263585, 'Total loss': 0.27410980197263585}
2023-01-05 15:04:34,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:34,976 INFO:     Epoch: 69
2023-01-05 15:04:37,129 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49757096072038015, 'Total loss': 0.49757096072038015} | train loss {'Reaction outcome loss': 0.2717560464145103, 'Total loss': 0.2717560464145103}
2023-01-05 15:04:37,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:37,129 INFO:     Epoch: 70
2023-01-05 15:04:39,291 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48531090319156645, 'Total loss': 0.48531090319156645} | train loss {'Reaction outcome loss': 0.2680649504730262, 'Total loss': 0.2680649504730262}
2023-01-05 15:04:39,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:39,291 INFO:     Epoch: 71
2023-01-05 15:04:41,469 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4483574330806732, 'Total loss': 0.4483574330806732} | train loss {'Reaction outcome loss': 0.2580248704137942, 'Total loss': 0.2580248704137942}
2023-01-05 15:04:41,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:41,470 INFO:     Epoch: 72
2023-01-05 15:04:43,622 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5041587173938751, 'Total loss': 0.5041587173938751} | train loss {'Reaction outcome loss': 0.2702804175745426, 'Total loss': 0.2702804175745426}
2023-01-05 15:04:43,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:43,623 INFO:     Epoch: 73
2023-01-05 15:04:45,765 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47195278803507484, 'Total loss': 0.47195278803507484} | train loss {'Reaction outcome loss': 0.26284050822500105, 'Total loss': 0.26284050822500105}
2023-01-05 15:04:45,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:45,765 INFO:     Epoch: 74
2023-01-05 15:04:47,948 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5006092965602875, 'Total loss': 0.5006092965602875} | train loss {'Reaction outcome loss': 0.2628528915950522, 'Total loss': 0.2628528915950522}
2023-01-05 15:04:47,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:47,949 INFO:     Epoch: 75
2023-01-05 15:04:50,172 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4911906143029531, 'Total loss': 0.4911906143029531} | train loss {'Reaction outcome loss': 0.25956134717768914, 'Total loss': 0.25956134717768914}
2023-01-05 15:04:50,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:50,172 INFO:     Epoch: 76
2023-01-05 15:04:52,313 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5164167006810506, 'Total loss': 0.5164167006810506} | train loss {'Reaction outcome loss': 0.25369077352671954, 'Total loss': 0.25369077352671954}
2023-01-05 15:04:52,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:52,313 INFO:     Epoch: 77
2023-01-05 15:04:54,460 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44826703270276386, 'Total loss': 0.44826703270276386} | train loss {'Reaction outcome loss': 0.26120333574995724, 'Total loss': 0.26120333574995724}
2023-01-05 15:04:54,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:54,461 INFO:     Epoch: 78
2023-01-05 15:04:56,606 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4953045388062795, 'Total loss': 0.4953045388062795} | train loss {'Reaction outcome loss': 0.2595885187873374, 'Total loss': 0.2595885187873374}
2023-01-05 15:04:56,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:56,607 INFO:     Epoch: 79
2023-01-05 15:04:58,757 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4643211990594864, 'Total loss': 0.4643211990594864} | train loss {'Reaction outcome loss': 0.26928196788324293, 'Total loss': 0.26928196788324293}
2023-01-05 15:04:58,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:04:58,759 INFO:     Epoch: 80
2023-01-05 15:05:00,921 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45361312131086984, 'Total loss': 0.45361312131086984} | train loss {'Reaction outcome loss': 0.2550473627296911, 'Total loss': 0.2550473627296911}
2023-01-05 15:05:00,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:00,921 INFO:     Epoch: 81
2023-01-05 15:05:03,089 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4479907671610514, 'Total loss': 0.4479907671610514} | train loss {'Reaction outcome loss': 0.24985139300975867, 'Total loss': 0.24985139300975867}
2023-01-05 15:05:03,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:03,089 INFO:     Epoch: 82
2023-01-05 15:05:05,236 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.528970988591512, 'Total loss': 0.528970988591512} | train loss {'Reaction outcome loss': 0.2521182331357799, 'Total loss': 0.2521182331357799}
2023-01-05 15:05:05,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:05,237 INFO:     Epoch: 83
2023-01-05 15:05:07,363 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4929411848386129, 'Total loss': 0.4929411848386129} | train loss {'Reaction outcome loss': 0.2475003453201034, 'Total loss': 0.2475003453201034}
2023-01-05 15:05:07,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:07,363 INFO:     Epoch: 84
2023-01-05 15:05:09,520 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4914262374242147, 'Total loss': 0.4914262374242147} | train loss {'Reaction outcome loss': 0.2533592376697714, 'Total loss': 0.2533592376697714}
2023-01-05 15:05:09,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:09,521 INFO:     Epoch: 85
2023-01-05 15:05:11,688 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4768449366092682, 'Total loss': 0.4768449366092682} | train loss {'Reaction outcome loss': 0.24743135387588933, 'Total loss': 0.24743135387588933}
2023-01-05 15:05:11,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:11,688 INFO:     Epoch: 86
2023-01-05 15:05:13,847 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49641840855280556, 'Total loss': 0.49641840855280556} | train loss {'Reaction outcome loss': 0.2458546420532292, 'Total loss': 0.2458546420532292}
2023-01-05 15:05:13,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:13,848 INFO:     Epoch: 87
2023-01-05 15:05:16,015 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48610103329022725, 'Total loss': 0.48610103329022725} | train loss {'Reaction outcome loss': 0.2477941377590574, 'Total loss': 0.2477941377590574}
2023-01-05 15:05:16,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:16,016 INFO:     Epoch: 88
2023-01-05 15:05:18,190 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47379063566525775, 'Total loss': 0.47379063566525775} | train loss {'Reaction outcome loss': 0.24213678802703542, 'Total loss': 0.24213678802703542}
2023-01-05 15:05:18,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:18,190 INFO:     Epoch: 89
2023-01-05 15:05:20,324 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4601851065953573, 'Total loss': 0.4601851065953573} | train loss {'Reaction outcome loss': 0.2434467934050928, 'Total loss': 0.2434467934050928}
2023-01-05 15:05:20,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:20,324 INFO:     Epoch: 90
2023-01-05 15:05:22,489 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4562334517637889, 'Total loss': 0.4562334517637889} | train loss {'Reaction outcome loss': 0.24670357909053564, 'Total loss': 0.24670357909053564}
2023-01-05 15:05:22,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:22,491 INFO:     Epoch: 91
2023-01-05 15:05:24,653 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4911814828713735, 'Total loss': 0.4911814828713735} | train loss {'Reaction outcome loss': 0.2507448094678483, 'Total loss': 0.2507448094678483}
2023-01-05 15:05:24,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:24,653 INFO:     Epoch: 92
2023-01-05 15:05:26,821 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4892144799232483, 'Total loss': 0.4892144799232483} | train loss {'Reaction outcome loss': 0.24267784168140666, 'Total loss': 0.24267784168140666}
2023-01-05 15:05:26,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:26,821 INFO:     Epoch: 93
2023-01-05 15:05:28,998 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49654967586199444, 'Total loss': 0.49654967586199444} | train loss {'Reaction outcome loss': 0.24087621435941453, 'Total loss': 0.24087621435941453}
2023-01-05 15:05:28,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:28,999 INFO:     Epoch: 94
2023-01-05 15:05:31,143 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5033905987938245, 'Total loss': 0.5033905987938245} | train loss {'Reaction outcome loss': 0.23872268172419644, 'Total loss': 0.23872268172419644}
2023-01-05 15:05:31,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:31,144 INFO:     Epoch: 95
2023-01-05 15:05:33,301 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4681513175368309, 'Total loss': 0.4681513175368309} | train loss {'Reaction outcome loss': 0.2449989895997704, 'Total loss': 0.2449989895997704}
2023-01-05 15:05:33,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:33,302 INFO:     Epoch: 96
2023-01-05 15:05:35,467 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4974112947781881, 'Total loss': 0.4974112947781881} | train loss {'Reaction outcome loss': 0.26165109476668463, 'Total loss': 0.26165109476668463}
2023-01-05 15:05:35,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:35,468 INFO:     Epoch: 97
2023-01-05 15:05:37,617 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49046446979045866, 'Total loss': 0.49046446979045866} | train loss {'Reaction outcome loss': 0.29073018768302566, 'Total loss': 0.29073018768302566}
2023-01-05 15:05:37,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:37,618 INFO:     Epoch: 98
2023-01-05 15:05:39,777 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48877805868784585, 'Total loss': 0.48877805868784585} | train loss {'Reaction outcome loss': 0.24857899012462492, 'Total loss': 0.24857899012462492}
2023-01-05 15:05:39,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:39,778 INFO:     Epoch: 99
2023-01-05 15:05:41,940 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49160807927449546, 'Total loss': 0.49160807927449546} | train loss {'Reaction outcome loss': 0.24062856079831693, 'Total loss': 0.24062856079831693}
2023-01-05 15:05:41,940 INFO:     Best model found after epoch 54 of 100.
2023-01-05 15:05:41,940 INFO:   Done with stage: TRAINING
2023-01-05 15:05:41,940 INFO:   Starting stage: EVALUATION
2023-01-05 15:05:42,072 INFO:   Done with stage: EVALUATION
2023-01-05 15:05:42,072 INFO:   Leaving out SEQ value Fold_4
2023-01-05 15:05:42,085 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 15:05:42,085 INFO:   Starting stage: FEATURE SCALING
2023-01-05 15:05:42,750 INFO:   Done with stage: FEATURE SCALING
2023-01-05 15:05:42,750 INFO:   Starting stage: SCALING TARGETS
2023-01-05 15:05:42,819 INFO:   Done with stage: SCALING TARGETS
2023-01-05 15:05:42,820 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:05:42,820 INFO:     No hyperparam tuning for this model
2023-01-05 15:05:42,820 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:05:42,820 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 15:05:42,820 INFO:     None feature selector for col prot
2023-01-05 15:05:42,821 INFO:     None feature selector for col prot
2023-01-05 15:05:42,821 INFO:     None feature selector for col prot
2023-01-05 15:05:42,821 INFO:     None feature selector for col chem
2023-01-05 15:05:42,821 INFO:     None feature selector for col chem
2023-01-05 15:05:42,821 INFO:     None feature selector for col chem
2023-01-05 15:05:42,821 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 15:05:42,821 INFO:   Starting stage: BUILD MODEL
2023-01-05 15:05:42,823 INFO:     Number of params in model 72901
2023-01-05 15:05:42,826 INFO:   Done with stage: BUILD MODEL
2023-01-05 15:05:42,826 INFO:   Starting stage: TRAINING
2023-01-05 15:05:42,885 INFO:     Val loss before train {'Reaction outcome loss': 1.020867935816447, 'Total loss': 1.020867935816447}
2023-01-05 15:05:42,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:42,886 INFO:     Epoch: 0
2023-01-05 15:05:45,047 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7964137514432271, 'Total loss': 0.7964137514432271} | train loss {'Reaction outcome loss': 0.9197466449832228, 'Total loss': 0.9197466449832228}
2023-01-05 15:05:45,048 INFO:     Found new best model at epoch 0
2023-01-05 15:05:45,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:45,049 INFO:     Epoch: 1
2023-01-05 15:05:47,182 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6190885066986084, 'Total loss': 0.6190885066986084} | train loss {'Reaction outcome loss': 0.7303926563865442, 'Total loss': 0.7303926563865442}
2023-01-05 15:05:47,182 INFO:     Found new best model at epoch 1
2023-01-05 15:05:47,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:47,183 INFO:     Epoch: 2
2023-01-05 15:05:49,330 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5623913705348969, 'Total loss': 0.5623913705348969} | train loss {'Reaction outcome loss': 0.5812841529019903, 'Total loss': 0.5812841529019903}
2023-01-05 15:05:49,330 INFO:     Found new best model at epoch 2
2023-01-05 15:05:49,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:49,331 INFO:     Epoch: 3
2023-01-05 15:05:51,491 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5411165595054627, 'Total loss': 0.5411165595054627} | train loss {'Reaction outcome loss': 0.532660339982501, 'Total loss': 0.532660339982501}
2023-01-05 15:05:51,492 INFO:     Found new best model at epoch 3
2023-01-05 15:05:51,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:51,493 INFO:     Epoch: 4
2023-01-05 15:05:53,664 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.584490696589152, 'Total loss': 0.584490696589152} | train loss {'Reaction outcome loss': 0.5067645505016891, 'Total loss': 0.5067645505016891}
2023-01-05 15:05:53,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:53,664 INFO:     Epoch: 5
2023-01-05 15:05:55,861 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5222775002320608, 'Total loss': 0.5222775002320608} | train loss {'Reaction outcome loss': 0.5015050038318771, 'Total loss': 0.5015050038318771}
2023-01-05 15:05:55,862 INFO:     Found new best model at epoch 5
2023-01-05 15:05:55,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:55,864 INFO:     Epoch: 6
2023-01-05 15:05:58,030 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5395426591237386, 'Total loss': 0.5395426591237386} | train loss {'Reaction outcome loss': 0.49753777435325114, 'Total loss': 0.49753777435325114}
2023-01-05 15:05:58,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:05:58,030 INFO:     Epoch: 7
2023-01-05 15:06:00,217 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5455025295416515, 'Total loss': 0.5455025295416515} | train loss {'Reaction outcome loss': 0.4793780699426086, 'Total loss': 0.4793780699426086}
2023-01-05 15:06:00,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:00,217 INFO:     Epoch: 8
2023-01-05 15:06:02,383 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5272042393684387, 'Total loss': 0.5272042393684387} | train loss {'Reaction outcome loss': 0.4783080412807878, 'Total loss': 0.4783080412807878}
2023-01-05 15:06:02,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:02,384 INFO:     Epoch: 9
2023-01-05 15:06:04,521 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5186080356438955, 'Total loss': 0.5186080356438955} | train loss {'Reaction outcome loss': 0.4733614349731039, 'Total loss': 0.4733614349731039}
2023-01-05 15:06:04,521 INFO:     Found new best model at epoch 9
2023-01-05 15:06:04,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:04,522 INFO:     Epoch: 10
2023-01-05 15:06:06,661 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5034605969985326, 'Total loss': 0.5034605969985326} | train loss {'Reaction outcome loss': 0.4699422487928549, 'Total loss': 0.4699422487928549}
2023-01-05 15:06:06,661 INFO:     Found new best model at epoch 10
2023-01-05 15:06:06,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:06,662 INFO:     Epoch: 11
2023-01-05 15:06:08,803 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5098997135957082, 'Total loss': 0.5098997135957082} | train loss {'Reaction outcome loss': 0.4563902975312209, 'Total loss': 0.4563902975312209}
2023-01-05 15:06:08,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:08,804 INFO:     Epoch: 12
2023-01-05 15:06:10,960 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5127896477778753, 'Total loss': 0.5127896477778753} | train loss {'Reaction outcome loss': 0.45845168828964233, 'Total loss': 0.45845168828964233}
2023-01-05 15:06:10,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:10,960 INFO:     Epoch: 13
2023-01-05 15:06:13,130 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5123739222685496, 'Total loss': 0.5123739222685496} | train loss {'Reaction outcome loss': 0.45117568515160456, 'Total loss': 0.45117568515160456}
2023-01-05 15:06:13,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:13,130 INFO:     Epoch: 14
2023-01-05 15:06:15,285 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.496234530210495, 'Total loss': 0.496234530210495} | train loss {'Reaction outcome loss': 0.4450508474711907, 'Total loss': 0.4450508474711907}
2023-01-05 15:06:15,286 INFO:     Found new best model at epoch 14
2023-01-05 15:06:15,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:15,288 INFO:     Epoch: 15
2023-01-05 15:06:17,439 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5003437121709188, 'Total loss': 0.5003437121709188} | train loss {'Reaction outcome loss': 0.44092501121630306, 'Total loss': 0.44092501121630306}
2023-01-05 15:06:17,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:17,440 INFO:     Epoch: 16
2023-01-05 15:06:19,582 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5147765556971232, 'Total loss': 0.5147765556971232} | train loss {'Reaction outcome loss': 0.44231679556817355, 'Total loss': 0.44231679556817355}
2023-01-05 15:06:19,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:19,583 INFO:     Epoch: 17
2023-01-05 15:06:21,726 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5094560652971267, 'Total loss': 0.5094560652971267} | train loss {'Reaction outcome loss': 0.43047816317111576, 'Total loss': 0.43047816317111576}
2023-01-05 15:06:21,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:21,726 INFO:     Epoch: 18
2023-01-05 15:06:23,872 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4908474385738373, 'Total loss': 0.4908474385738373} | train loss {'Reaction outcome loss': 0.43198975942195106, 'Total loss': 0.43198975942195106}
2023-01-05 15:06:23,872 INFO:     Found new best model at epoch 18
2023-01-05 15:06:23,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:23,873 INFO:     Epoch: 19
2023-01-05 15:06:26,028 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4824479460716248, 'Total loss': 0.4824479460716248} | train loss {'Reaction outcome loss': 0.42551753852879526, 'Total loss': 0.42551753852879526}
2023-01-05 15:06:26,029 INFO:     Found new best model at epoch 19
2023-01-05 15:06:26,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:26,031 INFO:     Epoch: 20
2023-01-05 15:06:28,179 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4911977340777715, 'Total loss': 0.4911977340777715} | train loss {'Reaction outcome loss': 0.4266354770597998, 'Total loss': 0.4266354770597998}
2023-01-05 15:06:28,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:28,179 INFO:     Epoch: 21
2023-01-05 15:06:30,323 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49537868003050484, 'Total loss': 0.49537868003050484} | train loss {'Reaction outcome loss': 0.42196297416940926, 'Total loss': 0.42196297416940926}
2023-01-05 15:06:30,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:30,323 INFO:     Epoch: 22
2023-01-05 15:06:32,465 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48723262747128804, 'Total loss': 0.48723262747128804} | train loss {'Reaction outcome loss': 0.4126145958846657, 'Total loss': 0.4126145958846657}
2023-01-05 15:06:32,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:32,467 INFO:     Epoch: 23
2023-01-05 15:06:34,632 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5097982247670492, 'Total loss': 0.5097982247670492} | train loss {'Reaction outcome loss': 0.41158242321939675, 'Total loss': 0.41158242321939675}
2023-01-05 15:06:34,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:34,632 INFO:     Epoch: 24
2023-01-05 15:06:36,598 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4711505631605784, 'Total loss': 0.4711505631605784} | train loss {'Reaction outcome loss': 0.4089243016088052, 'Total loss': 0.4089243016088052}
2023-01-05 15:06:36,600 INFO:     Found new best model at epoch 24
2023-01-05 15:06:36,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:36,601 INFO:     Epoch: 25
2023-01-05 15:06:38,757 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5034937962889672, 'Total loss': 0.5034937962889672} | train loss {'Reaction outcome loss': 0.40708503084062236, 'Total loss': 0.40708503084062236}
2023-01-05 15:06:38,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:38,757 INFO:     Epoch: 26
2023-01-05 15:06:40,884 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48342816829681395, 'Total loss': 0.48342816829681395} | train loss {'Reaction outcome loss': 0.39711284363097665, 'Total loss': 0.39711284363097665}
2023-01-05 15:06:40,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:40,885 INFO:     Epoch: 27
2023-01-05 15:06:43,053 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4831676721572876, 'Total loss': 0.4831676721572876} | train loss {'Reaction outcome loss': 0.3952747980394949, 'Total loss': 0.3952747980394949}
2023-01-05 15:06:43,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:43,055 INFO:     Epoch: 28
2023-01-05 15:06:45,199 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4896469712257385, 'Total loss': 0.4896469712257385} | train loss {'Reaction outcome loss': 0.39667374713326187, 'Total loss': 0.39667374713326187}
2023-01-05 15:06:45,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:45,200 INFO:     Epoch: 29
2023-01-05 15:06:47,423 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4667209247748057, 'Total loss': 0.4667209247748057} | train loss {'Reaction outcome loss': 0.38965859670286146, 'Total loss': 0.38965859670286146}
2023-01-05 15:06:47,423 INFO:     Found new best model at epoch 29
2023-01-05 15:06:47,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:47,426 INFO:     Epoch: 30
2023-01-05 15:06:49,643 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.49127411941687266, 'Total loss': 0.49127411941687266} | train loss {'Reaction outcome loss': 0.3857449694714822, 'Total loss': 0.3857449694714822}
2023-01-05 15:06:49,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:49,645 INFO:     Epoch: 31
2023-01-05 15:06:51,827 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49571016629536946, 'Total loss': 0.49571016629536946} | train loss {'Reaction outcome loss': 0.3794982315642954, 'Total loss': 0.3794982315642954}
2023-01-05 15:06:51,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:51,827 INFO:     Epoch: 32
2023-01-05 15:06:54,032 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45935714840888975, 'Total loss': 0.45935714840888975} | train loss {'Reaction outcome loss': 0.38280891134850814, 'Total loss': 0.38280891134850814}
2023-01-05 15:06:54,033 INFO:     Found new best model at epoch 32
2023-01-05 15:06:54,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:54,034 INFO:     Epoch: 33
2023-01-05 15:06:56,277 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48609411319096885, 'Total loss': 0.48609411319096885} | train loss {'Reaction outcome loss': 0.37732480014489445, 'Total loss': 0.37732480014489445}
2023-01-05 15:06:56,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:56,278 INFO:     Epoch: 34
2023-01-05 15:06:58,478 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4599536180496216, 'Total loss': 0.4599536180496216} | train loss {'Reaction outcome loss': 0.3770452057034961, 'Total loss': 0.3770452057034961}
2023-01-05 15:06:58,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:06:58,479 INFO:     Epoch: 35
2023-01-05 15:07:00,706 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4406993746757507, 'Total loss': 0.4406993746757507} | train loss {'Reaction outcome loss': 0.37033182059814784, 'Total loss': 0.37033182059814784}
2023-01-05 15:07:00,706 INFO:     Found new best model at epoch 35
2023-01-05 15:07:00,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:00,708 INFO:     Epoch: 36
2023-01-05 15:07:02,893 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4859691301981608, 'Total loss': 0.4859691301981608} | train loss {'Reaction outcome loss': 0.37226070237719194, 'Total loss': 0.37226070237719194}
2023-01-05 15:07:02,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:02,894 INFO:     Epoch: 37
2023-01-05 15:07:05,092 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4452911615371704, 'Total loss': 0.4452911615371704} | train loss {'Reaction outcome loss': 0.36954757253831044, 'Total loss': 0.36954757253831044}
2023-01-05 15:07:05,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:05,092 INFO:     Epoch: 38
2023-01-05 15:07:07,288 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48644891381263733, 'Total loss': 0.48644891381263733} | train loss {'Reaction outcome loss': 0.3590146254761555, 'Total loss': 0.3590146254761555}
2023-01-05 15:07:07,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:07,288 INFO:     Epoch: 39
2023-01-05 15:07:09,516 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4708790421485901, 'Total loss': 0.4708790421485901} | train loss {'Reaction outcome loss': 0.35645170950932625, 'Total loss': 0.35645170950932625}
2023-01-05 15:07:09,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:09,516 INFO:     Epoch: 40
2023-01-05 15:07:11,744 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4521527906258901, 'Total loss': 0.4521527906258901} | train loss {'Reaction outcome loss': 0.35656662575819864, 'Total loss': 0.35656662575819864}
2023-01-05 15:07:11,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:11,744 INFO:     Epoch: 41
2023-01-05 15:07:13,913 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45851295987764995, 'Total loss': 0.45851295987764995} | train loss {'Reaction outcome loss': 0.3513272664499627, 'Total loss': 0.3513272664499627}
2023-01-05 15:07:13,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:13,914 INFO:     Epoch: 42
2023-01-05 15:07:16,062 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45516656736532846, 'Total loss': 0.45516656736532846} | train loss {'Reaction outcome loss': 0.3511315002660889, 'Total loss': 0.3511315002660889}
2023-01-05 15:07:16,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:16,063 INFO:     Epoch: 43
2023-01-05 15:07:18,208 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48279330333073933, 'Total loss': 0.48279330333073933} | train loss {'Reaction outcome loss': 0.3447411574611595, 'Total loss': 0.3447411574611595}
2023-01-05 15:07:18,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:18,209 INFO:     Epoch: 44
2023-01-05 15:07:20,372 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44373364423712097, 'Total loss': 0.44373364423712097} | train loss {'Reaction outcome loss': 0.3480262095612955, 'Total loss': 0.3480262095612955}
2023-01-05 15:07:20,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:20,372 INFO:     Epoch: 45
2023-01-05 15:07:22,527 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4658532897631327, 'Total loss': 0.4658532897631327} | train loss {'Reaction outcome loss': 0.348461492558679, 'Total loss': 0.348461492558679}
2023-01-05 15:07:22,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:22,527 INFO:     Epoch: 46
2023-01-05 15:07:24,683 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4532728532950083, 'Total loss': 0.4532728532950083} | train loss {'Reaction outcome loss': 0.3384958910032945, 'Total loss': 0.3384958910032945}
2023-01-05 15:07:24,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:24,683 INFO:     Epoch: 47
2023-01-05 15:07:26,828 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4463969796895981, 'Total loss': 0.4463969796895981} | train loss {'Reaction outcome loss': 0.33991142186178197, 'Total loss': 0.33991142186178197}
2023-01-05 15:07:26,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:26,828 INFO:     Epoch: 48
2023-01-05 15:07:29,000 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4721133728822072, 'Total loss': 0.4721133728822072} | train loss {'Reaction outcome loss': 0.3349434860615524, 'Total loss': 0.3349434860615524}
2023-01-05 15:07:29,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:29,000 INFO:     Epoch: 49
2023-01-05 15:07:31,165 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47017015020052594, 'Total loss': 0.47017015020052594} | train loss {'Reaction outcome loss': 0.33710351439751013, 'Total loss': 0.33710351439751013}
2023-01-05 15:07:31,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:31,166 INFO:     Epoch: 50
2023-01-05 15:07:33,330 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4520262042681376, 'Total loss': 0.4520262042681376} | train loss {'Reaction outcome loss': 0.32792712352658865, 'Total loss': 0.32792712352658865}
2023-01-05 15:07:33,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:33,331 INFO:     Epoch: 51
2023-01-05 15:07:35,492 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4222719500462214, 'Total loss': 0.4222719500462214} | train loss {'Reaction outcome loss': 0.3286366491756715, 'Total loss': 0.3286366491756715}
2023-01-05 15:07:35,492 INFO:     Found new best model at epoch 51
2023-01-05 15:07:35,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:35,493 INFO:     Epoch: 52
2023-01-05 15:07:37,712 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42860285540421805, 'Total loss': 0.42860285540421805} | train loss {'Reaction outcome loss': 0.3278376496521359, 'Total loss': 0.3278376496521359}
2023-01-05 15:07:37,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:37,712 INFO:     Epoch: 53
2023-01-05 15:07:39,885 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4455648084481557, 'Total loss': 0.4455648084481557} | train loss {'Reaction outcome loss': 0.31883366444965133, 'Total loss': 0.31883366444965133}
2023-01-05 15:07:39,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:39,886 INFO:     Epoch: 54
2023-01-05 15:07:42,045 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44159438808759055, 'Total loss': 0.44159438808759055} | train loss {'Reaction outcome loss': 0.32235091016880013, 'Total loss': 0.32235091016880013}
2023-01-05 15:07:42,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:42,045 INFO:     Epoch: 55
2023-01-05 15:07:44,217 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44150737921396893, 'Total loss': 0.44150737921396893} | train loss {'Reaction outcome loss': 0.31646483586529534, 'Total loss': 0.31646483586529534}
2023-01-05 15:07:44,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:44,218 INFO:     Epoch: 56
2023-01-05 15:07:46,365 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.445238995552063, 'Total loss': 0.445238995552063} | train loss {'Reaction outcome loss': 0.318611193138985, 'Total loss': 0.318611193138985}
2023-01-05 15:07:46,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:46,365 INFO:     Epoch: 57
2023-01-05 15:07:48,518 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4978313644727071, 'Total loss': 0.4978313644727071} | train loss {'Reaction outcome loss': 0.31447440947974203, 'Total loss': 0.31447440947974203}
2023-01-05 15:07:48,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:48,518 INFO:     Epoch: 58
2023-01-05 15:07:50,665 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.449894971648852, 'Total loss': 0.449894971648852} | train loss {'Reaction outcome loss': 0.30874084794241596, 'Total loss': 0.30874084794241596}
2023-01-05 15:07:50,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:50,665 INFO:     Epoch: 59
2023-01-05 15:07:52,852 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4387959912419319, 'Total loss': 0.4387959912419319} | train loss {'Reaction outcome loss': 0.3049923437193628, 'Total loss': 0.3049923437193628}
2023-01-05 15:07:52,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:52,853 INFO:     Epoch: 60
2023-01-05 15:07:55,018 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4220363527536392, 'Total loss': 0.4220363527536392} | train loss {'Reaction outcome loss': 0.30351140393139225, 'Total loss': 0.30351140393139225}
2023-01-05 15:07:55,018 INFO:     Found new best model at epoch 60
2023-01-05 15:07:55,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:55,019 INFO:     Epoch: 61
2023-01-05 15:07:57,194 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4354962607224782, 'Total loss': 0.4354962607224782} | train loss {'Reaction outcome loss': 0.2991725609567191, 'Total loss': 0.2991725609567191}
2023-01-05 15:07:57,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:57,194 INFO:     Epoch: 62
2023-01-05 15:07:59,352 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41938982754945753, 'Total loss': 0.41938982754945753} | train loss {'Reaction outcome loss': 0.30243462620686323, 'Total loss': 0.30243462620686323}
2023-01-05 15:07:59,352 INFO:     Found new best model at epoch 62
2023-01-05 15:07:59,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:07:59,354 INFO:     Epoch: 63
2023-01-05 15:08:01,506 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4352158357699712, 'Total loss': 0.4352158357699712} | train loss {'Reaction outcome loss': 0.2981114493353487, 'Total loss': 0.2981114493353487}
2023-01-05 15:08:01,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:01,506 INFO:     Epoch: 64
2023-01-05 15:08:03,654 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45708754857381184, 'Total loss': 0.45708754857381184} | train loss {'Reaction outcome loss': 0.3012013281577869, 'Total loss': 0.3012013281577869}
2023-01-05 15:08:03,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:03,656 INFO:     Epoch: 65
2023-01-05 15:08:05,822 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4326953520377477, 'Total loss': 0.4326953520377477} | train loss {'Reaction outcome loss': 0.2984466630467869, 'Total loss': 0.2984466630467869}
2023-01-05 15:08:05,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:05,822 INFO:     Epoch: 66
2023-01-05 15:08:07,971 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44452375173568726, 'Total loss': 0.44452375173568726} | train loss {'Reaction outcome loss': 0.2963303005127808, 'Total loss': 0.2963303005127808}
2023-01-05 15:08:07,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:07,971 INFO:     Epoch: 67
2023-01-05 15:08:10,131 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4477578580379486, 'Total loss': 0.4477578580379486} | train loss {'Reaction outcome loss': 0.29157563145625465, 'Total loss': 0.29157563145625465}
2023-01-05 15:08:10,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:10,132 INFO:     Epoch: 68
2023-01-05 15:08:12,282 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4763777489463488, 'Total loss': 0.4763777489463488} | train loss {'Reaction outcome loss': 0.29918810463634854, 'Total loss': 0.29918810463634854}
2023-01-05 15:08:12,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:12,283 INFO:     Epoch: 69
2023-01-05 15:08:14,469 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4558297177155813, 'Total loss': 0.4558297177155813} | train loss {'Reaction outcome loss': 0.2922987877744307, 'Total loss': 0.2922987877744307}
2023-01-05 15:08:14,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:14,470 INFO:     Epoch: 70
2023-01-05 15:08:16,612 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44783265789349874, 'Total loss': 0.44783265789349874} | train loss {'Reaction outcome loss': 0.29247065322197946, 'Total loss': 0.29247065322197946}
2023-01-05 15:08:16,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:16,612 INFO:     Epoch: 71
2023-01-05 15:08:18,777 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43620925893386203, 'Total loss': 0.43620925893386203} | train loss {'Reaction outcome loss': 0.2825603474516569, 'Total loss': 0.2825603474516569}
2023-01-05 15:08:18,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:18,777 INFO:     Epoch: 72
2023-01-05 15:08:20,928 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4553827991088231, 'Total loss': 0.4553827991088231} | train loss {'Reaction outcome loss': 0.28098645363850283, 'Total loss': 0.28098645363850283}
2023-01-05 15:08:20,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:20,928 INFO:     Epoch: 73
2023-01-05 15:08:23,072 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4678024878104528, 'Total loss': 0.4678024878104528} | train loss {'Reaction outcome loss': 0.27945193343052793, 'Total loss': 0.27945193343052793}
2023-01-05 15:08:23,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:23,073 INFO:     Epoch: 74
2023-01-05 15:08:25,222 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4273860367635886, 'Total loss': 0.4273860367635886} | train loss {'Reaction outcome loss': 0.2851561179135788, 'Total loss': 0.2851561179135788}
2023-01-05 15:08:25,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:25,222 INFO:     Epoch: 75
2023-01-05 15:08:27,339 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4654866635799408, 'Total loss': 0.4654866635799408} | train loss {'Reaction outcome loss': 0.2726496912686941, 'Total loss': 0.2726496912686941}
2023-01-05 15:08:27,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:27,340 INFO:     Epoch: 76
2023-01-05 15:08:29,486 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47827042440573375, 'Total loss': 0.47827042440573375} | train loss {'Reaction outcome loss': 0.271884422924114, 'Total loss': 0.271884422924114}
2023-01-05 15:08:29,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:29,486 INFO:     Epoch: 77
2023-01-05 15:08:31,635 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47011546095212303, 'Total loss': 0.47011546095212303} | train loss {'Reaction outcome loss': 0.2718768939308634, 'Total loss': 0.2718768939308634}
2023-01-05 15:08:31,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:31,635 INFO:     Epoch: 78
2023-01-05 15:08:33,782 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4701703995466232, 'Total loss': 0.4701703995466232} | train loss {'Reaction outcome loss': 0.2710362128133378, 'Total loss': 0.2710362128133378}
2023-01-05 15:08:33,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:33,783 INFO:     Epoch: 79
2023-01-05 15:08:35,919 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4236297669510047, 'Total loss': 0.4236297669510047} | train loss {'Reaction outcome loss': 0.27037200780874554, 'Total loss': 0.27037200780874554}
2023-01-05 15:08:35,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:35,920 INFO:     Epoch: 80
2023-01-05 15:08:38,052 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4600907176733017, 'Total loss': 0.4600907176733017} | train loss {'Reaction outcome loss': 0.27171044641372744, 'Total loss': 0.27171044641372744}
2023-01-05 15:08:38,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:38,052 INFO:     Epoch: 81
2023-01-05 15:08:40,198 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4407978057861328, 'Total loss': 0.4407978057861328} | train loss {'Reaction outcome loss': 0.2720305416262322, 'Total loss': 0.2720305416262322}
2023-01-05 15:08:40,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:40,199 INFO:     Epoch: 82
2023-01-05 15:08:42,351 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48310720920562744, 'Total loss': 0.48310720920562744} | train loss {'Reaction outcome loss': 0.2637609821283645, 'Total loss': 0.2637609821283645}
2023-01-05 15:08:42,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:42,351 INFO:     Epoch: 83
2023-01-05 15:08:44,504 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39528491397698723, 'Total loss': 0.39528491397698723} | train loss {'Reaction outcome loss': 0.26081438097322784, 'Total loss': 0.26081438097322784}
2023-01-05 15:08:44,505 INFO:     Found new best model at epoch 83
2023-01-05 15:08:44,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:44,506 INFO:     Epoch: 84
2023-01-05 15:08:46,668 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.447555469473203, 'Total loss': 0.447555469473203} | train loss {'Reaction outcome loss': 0.26936876463169224, 'Total loss': 0.26936876463169224}
2023-01-05 15:08:46,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:46,668 INFO:     Epoch: 85
2023-01-05 15:08:48,801 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4468023916085561, 'Total loss': 0.4468023916085561} | train loss {'Reaction outcome loss': 0.2624928456552945, 'Total loss': 0.2624928456552945}
2023-01-05 15:08:48,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:48,801 INFO:     Epoch: 86
2023-01-05 15:08:50,945 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4397001663843791, 'Total loss': 0.4397001663843791} | train loss {'Reaction outcome loss': 0.2634517550468445, 'Total loss': 0.2634517550468445}
2023-01-05 15:08:50,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:50,945 INFO:     Epoch: 87
2023-01-05 15:08:53,117 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4479911983013153, 'Total loss': 0.4479911983013153} | train loss {'Reaction outcome loss': 0.2589519892883107, 'Total loss': 0.2589519892883107}
2023-01-05 15:08:53,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:53,118 INFO:     Epoch: 88
2023-01-05 15:08:55,261 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43502601484457654, 'Total loss': 0.43502601484457654} | train loss {'Reaction outcome loss': 0.26550856684519497, 'Total loss': 0.26550856684519497}
2023-01-05 15:08:55,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:55,261 INFO:     Epoch: 89
2023-01-05 15:08:57,423 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4645064036051432, 'Total loss': 0.4645064036051432} | train loss {'Reaction outcome loss': 0.2566989251825999, 'Total loss': 0.2566989251825999}
2023-01-05 15:08:57,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:57,424 INFO:     Epoch: 90
2023-01-05 15:08:59,589 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44910804331302645, 'Total loss': 0.44910804331302645} | train loss {'Reaction outcome loss': 0.25551334631356953, 'Total loss': 0.25551334631356953}
2023-01-05 15:08:59,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:08:59,589 INFO:     Epoch: 91
2023-01-05 15:09:01,745 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48389882147312163, 'Total loss': 0.48389882147312163} | train loss {'Reaction outcome loss': 0.2542984666242281, 'Total loss': 0.2542984666242281}
2023-01-05 15:09:01,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:01,745 INFO:     Epoch: 92
2023-01-05 15:09:03,887 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4500545253356298, 'Total loss': 0.4500545253356298} | train loss {'Reaction outcome loss': 0.25604229269125617, 'Total loss': 0.25604229269125617}
2023-01-05 15:09:03,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:03,888 INFO:     Epoch: 93
2023-01-05 15:09:06,052 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4551931967337926, 'Total loss': 0.4551931967337926} | train loss {'Reaction outcome loss': 0.25813790286356575, 'Total loss': 0.25813790286356575}
2023-01-05 15:09:06,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:06,052 INFO:     Epoch: 94
2023-01-05 15:09:08,209 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43308808108170826, 'Total loss': 0.43308808108170826} | train loss {'Reaction outcome loss': 0.2576298810010406, 'Total loss': 0.2576298810010406}
2023-01-05 15:09:08,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:08,209 INFO:     Epoch: 95
2023-01-05 15:09:10,376 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4420991390943527, 'Total loss': 0.4420991390943527} | train loss {'Reaction outcome loss': 0.24831481265838826, 'Total loss': 0.24831481265838826}
2023-01-05 15:09:10,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:10,377 INFO:     Epoch: 96
2023-01-05 15:09:12,532 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4445259263118108, 'Total loss': 0.4445259263118108} | train loss {'Reaction outcome loss': 0.25005323125809326, 'Total loss': 0.25005323125809326}
2023-01-05 15:09:12,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:12,533 INFO:     Epoch: 97
2023-01-05 15:09:14,734 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44206103185812634, 'Total loss': 0.44206103185812634} | train loss {'Reaction outcome loss': 0.2540682565407417, 'Total loss': 0.2540682565407417}
2023-01-05 15:09:14,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:14,735 INFO:     Epoch: 98
2023-01-05 15:09:16,939 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45028969446818035, 'Total loss': 0.45028969446818035} | train loss {'Reaction outcome loss': 0.24722293746869486, 'Total loss': 0.24722293746869486}
2023-01-05 15:09:16,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:16,940 INFO:     Epoch: 99
2023-01-05 15:09:19,107 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43195919742186867, 'Total loss': 0.43195919742186867} | train loss {'Reaction outcome loss': 0.2526371192039135, 'Total loss': 0.2526371192039135}
2023-01-05 15:09:19,107 INFO:     Best model found after epoch 84 of 100.
2023-01-05 15:09:19,107 INFO:   Done with stage: TRAINING
2023-01-05 15:09:19,107 INFO:   Starting stage: EVALUATION
2023-01-05 15:09:19,235 INFO:   Done with stage: EVALUATION
2023-01-05 15:09:19,235 INFO:   Leaving out SEQ value Fold_5
2023-01-05 15:09:19,248 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 15:09:19,248 INFO:   Starting stage: FEATURE SCALING
2023-01-05 15:09:19,917 INFO:   Done with stage: FEATURE SCALING
2023-01-05 15:09:19,917 INFO:   Starting stage: SCALING TARGETS
2023-01-05 15:09:19,986 INFO:   Done with stage: SCALING TARGETS
2023-01-05 15:09:19,987 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:09:19,987 INFO:     No hyperparam tuning for this model
2023-01-05 15:09:19,987 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:09:19,987 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 15:09:19,988 INFO:     None feature selector for col prot
2023-01-05 15:09:19,988 INFO:     None feature selector for col prot
2023-01-05 15:09:19,988 INFO:     None feature selector for col prot
2023-01-05 15:09:19,988 INFO:     None feature selector for col chem
2023-01-05 15:09:19,988 INFO:     None feature selector for col chem
2023-01-05 15:09:19,988 INFO:     None feature selector for col chem
2023-01-05 15:09:19,989 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 15:09:19,989 INFO:   Starting stage: BUILD MODEL
2023-01-05 15:09:19,990 INFO:     Number of params in model 72901
2023-01-05 15:09:19,993 INFO:   Done with stage: BUILD MODEL
2023-01-05 15:09:19,993 INFO:   Starting stage: TRAINING
2023-01-05 15:09:20,051 INFO:     Val loss before train {'Reaction outcome loss': 0.8846520026524861, 'Total loss': 0.8846520026524861}
2023-01-05 15:09:20,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:20,051 INFO:     Epoch: 0
2023-01-05 15:09:22,163 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.757140173514684, 'Total loss': 0.757140173514684} | train loss {'Reaction outcome loss': 0.9399750991894381, 'Total loss': 0.9399750991894381}
2023-01-05 15:09:22,163 INFO:     Found new best model at epoch 0
2023-01-05 15:09:22,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:22,164 INFO:     Epoch: 1
2023-01-05 15:09:24,308 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.600040872891744, 'Total loss': 0.600040872891744} | train loss {'Reaction outcome loss': 0.7639191649908567, 'Total loss': 0.7639191649908567}
2023-01-05 15:09:24,309 INFO:     Found new best model at epoch 1
2023-01-05 15:09:24,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:24,310 INFO:     Epoch: 2
2023-01-05 15:09:26,459 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5043081899483999, 'Total loss': 0.5043081899483999} | train loss {'Reaction outcome loss': 0.6183542777804563, 'Total loss': 0.6183542777804563}
2023-01-05 15:09:26,459 INFO:     Found new best model at epoch 2
2023-01-05 15:09:26,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:26,461 INFO:     Epoch: 3
2023-01-05 15:09:28,611 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49198937813440957, 'Total loss': 0.49198937813440957} | train loss {'Reaction outcome loss': 0.5366572975350993, 'Total loss': 0.5366572975350993}
2023-01-05 15:09:28,611 INFO:     Found new best model at epoch 3
2023-01-05 15:09:28,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:28,612 INFO:     Epoch: 4
2023-01-05 15:09:30,763 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4761405289173126, 'Total loss': 0.4761405289173126} | train loss {'Reaction outcome loss': 0.5155921185756251, 'Total loss': 0.5155921185756251}
2023-01-05 15:09:30,764 INFO:     Found new best model at epoch 4
2023-01-05 15:09:30,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:30,765 INFO:     Epoch: 5
2023-01-05 15:09:32,901 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4428913749754429, 'Total loss': 0.4428913749754429} | train loss {'Reaction outcome loss': 0.4975687728202256, 'Total loss': 0.4975687728202256}
2023-01-05 15:09:32,901 INFO:     Found new best model at epoch 5
2023-01-05 15:09:32,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:32,902 INFO:     Epoch: 6
2023-01-05 15:09:35,044 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47596543033917743, 'Total loss': 0.47596543033917743} | train loss {'Reaction outcome loss': 0.48612585462575414, 'Total loss': 0.48612585462575414}
2023-01-05 15:09:35,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:35,044 INFO:     Epoch: 7
2023-01-05 15:09:37,189 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48050018946329753, 'Total loss': 0.48050018946329753} | train loss {'Reaction outcome loss': 0.47710168769542316, 'Total loss': 0.47710168769542316}
2023-01-05 15:09:37,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:37,190 INFO:     Epoch: 8
2023-01-05 15:09:39,322 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47031618158022565, 'Total loss': 0.47031618158022565} | train loss {'Reaction outcome loss': 0.4709070447805154, 'Total loss': 0.4709070447805154}
2023-01-05 15:09:39,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:39,322 INFO:     Epoch: 9
2023-01-05 15:09:41,475 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4373148769140244, 'Total loss': 0.4373148769140244} | train loss {'Reaction outcome loss': 0.46560217075756866, 'Total loss': 0.46560217075756866}
2023-01-05 15:09:41,477 INFO:     Found new best model at epoch 9
2023-01-05 15:09:41,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:41,478 INFO:     Epoch: 10
2023-01-05 15:09:43,628 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4414950927098592, 'Total loss': 0.4414950927098592} | train loss {'Reaction outcome loss': 0.4564726829637576, 'Total loss': 0.4564726829637576}
2023-01-05 15:09:43,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:43,628 INFO:     Epoch: 11
2023-01-05 15:09:45,830 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45639663736025493, 'Total loss': 0.45639663736025493} | train loss {'Reaction outcome loss': 0.4506950169584177, 'Total loss': 0.4506950169584177}
2023-01-05 15:09:45,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:45,830 INFO:     Epoch: 12
2023-01-05 15:09:47,959 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46594988902409873, 'Total loss': 0.46594988902409873} | train loss {'Reaction outcome loss': 0.44422053567466946, 'Total loss': 0.44422053567466946}
2023-01-05 15:09:47,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:47,960 INFO:     Epoch: 13
2023-01-05 15:09:50,112 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4473212679227193, 'Total loss': 0.4473212679227193} | train loss {'Reaction outcome loss': 0.44288282139893, 'Total loss': 0.44288282139893}
2023-01-05 15:09:50,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:50,112 INFO:     Epoch: 14
2023-01-05 15:09:52,294 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4234028389056524, 'Total loss': 0.4234028389056524} | train loss {'Reaction outcome loss': 0.43249861773674503, 'Total loss': 0.43249861773674503}
2023-01-05 15:09:52,294 INFO:     Found new best model at epoch 14
2023-01-05 15:09:52,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:52,295 INFO:     Epoch: 15
2023-01-05 15:09:54,450 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4638013814886411, 'Total loss': 0.4638013814886411} | train loss {'Reaction outcome loss': 0.4317784153305701, 'Total loss': 0.4317784153305701}
2023-01-05 15:09:54,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:54,451 INFO:     Epoch: 16
2023-01-05 15:09:56,602 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41856165329615275, 'Total loss': 0.41856165329615275} | train loss {'Reaction outcome loss': 0.42695288335646153, 'Total loss': 0.42695288335646153}
2023-01-05 15:09:56,602 INFO:     Found new best model at epoch 16
2023-01-05 15:09:56,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:56,603 INFO:     Epoch: 17
2023-01-05 15:09:58,742 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3944860935211182, 'Total loss': 0.3944860935211182} | train loss {'Reaction outcome loss': 0.41974201472136224, 'Total loss': 0.41974201472136224}
2023-01-05 15:09:58,742 INFO:     Found new best model at epoch 17
2023-01-05 15:09:58,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:09:58,743 INFO:     Epoch: 18
2023-01-05 15:10:00,885 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.425182036558787, 'Total loss': 0.425182036558787} | train loss {'Reaction outcome loss': 0.418010554201629, 'Total loss': 0.418010554201629}
2023-01-05 15:10:00,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:00,886 INFO:     Epoch: 19
2023-01-05 15:10:03,105 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43181943893432617, 'Total loss': 0.43181943893432617} | train loss {'Reaction outcome loss': 0.4104655415744242, 'Total loss': 0.4104655415744242}
2023-01-05 15:10:03,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:03,105 INFO:     Epoch: 20
2023-01-05 15:10:05,339 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43588306605815885, 'Total loss': 0.43588306605815885} | train loss {'Reaction outcome loss': 0.4077648032375061, 'Total loss': 0.4077648032375061}
2023-01-05 15:10:05,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:05,340 INFO:     Epoch: 21
2023-01-05 15:10:07,480 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4042424241701762, 'Total loss': 0.4042424241701762} | train loss {'Reaction outcome loss': 0.4042658583145507, 'Total loss': 0.4042658583145507}
2023-01-05 15:10:07,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:07,480 INFO:     Epoch: 22
2023-01-05 15:10:09,599 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4217495103677114, 'Total loss': 0.4217495103677114} | train loss {'Reaction outcome loss': 0.39988306202810175, 'Total loss': 0.39988306202810175}
2023-01-05 15:10:09,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:09,600 INFO:     Epoch: 23
2023-01-05 15:10:11,733 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4228666633367538, 'Total loss': 0.4228666633367538} | train loss {'Reaction outcome loss': 0.39342530240325163, 'Total loss': 0.39342530240325163}
2023-01-05 15:10:11,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:11,733 INFO:     Epoch: 24
2023-01-05 15:10:13,884 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41455865601698555, 'Total loss': 0.41455865601698555} | train loss {'Reaction outcome loss': 0.3897242228208232, 'Total loss': 0.3897242228208232}
2023-01-05 15:10:13,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:13,884 INFO:     Epoch: 25
2023-01-05 15:10:16,030 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3973400374253591, 'Total loss': 0.3973400374253591} | train loss {'Reaction outcome loss': 0.3901718436692753, 'Total loss': 0.3901718436692753}
2023-01-05 15:10:16,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:16,032 INFO:     Epoch: 26
2023-01-05 15:10:18,187 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40233604510625204, 'Total loss': 0.40233604510625204} | train loss {'Reaction outcome loss': 0.38716018072118724, 'Total loss': 0.38716018072118724}
2023-01-05 15:10:18,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:18,187 INFO:     Epoch: 27
2023-01-05 15:10:20,313 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.37513295660416285, 'Total loss': 0.37513295660416285} | train loss {'Reaction outcome loss': 0.3769614338929201, 'Total loss': 0.3769614338929201}
2023-01-05 15:10:20,313 INFO:     Found new best model at epoch 27
2023-01-05 15:10:20,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:20,315 INFO:     Epoch: 28
2023-01-05 15:10:22,452 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4516918003559113, 'Total loss': 0.4516918003559113} | train loss {'Reaction outcome loss': 0.38118976415780775, 'Total loss': 0.38118976415780775}
2023-01-05 15:10:22,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:22,453 INFO:     Epoch: 29
2023-01-05 15:10:24,587 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.413564761976401, 'Total loss': 0.413564761976401} | train loss {'Reaction outcome loss': 0.37362371983319304, 'Total loss': 0.37362371983319304}
2023-01-05 15:10:24,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:24,587 INFO:     Epoch: 30
2023-01-05 15:10:26,767 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4187985181808472, 'Total loss': 0.4187985181808472} | train loss {'Reaction outcome loss': 0.376733637040984, 'Total loss': 0.376733637040984}
2023-01-05 15:10:26,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:26,767 INFO:     Epoch: 31
2023-01-05 15:10:28,903 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4452351291974386, 'Total loss': 0.4452351291974386} | train loss {'Reaction outcome loss': 0.36583148764215245, 'Total loss': 0.36583148764215245}
2023-01-05 15:10:28,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:28,903 INFO:     Epoch: 32
2023-01-05 15:10:31,031 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4003460625807444, 'Total loss': 0.4003460625807444} | train loss {'Reaction outcome loss': 0.36371075103644035, 'Total loss': 0.36371075103644035}
2023-01-05 15:10:31,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:31,031 INFO:     Epoch: 33
2023-01-05 15:10:33,156 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4301172658801079, 'Total loss': 0.4301172658801079} | train loss {'Reaction outcome loss': 0.3620539586175315, 'Total loss': 0.3620539586175315}
2023-01-05 15:10:33,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:33,157 INFO:     Epoch: 34
2023-01-05 15:10:35,278 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43517992794513705, 'Total loss': 0.43517992794513705} | train loss {'Reaction outcome loss': 0.3568788752993093, 'Total loss': 0.3568788752993093}
2023-01-05 15:10:35,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:35,279 INFO:     Epoch: 35
2023-01-05 15:10:37,419 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42592214395602546, 'Total loss': 0.42592214395602546} | train loss {'Reaction outcome loss': 0.3605133900350898, 'Total loss': 0.3605133900350898}
2023-01-05 15:10:37,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:37,419 INFO:     Epoch: 36
2023-01-05 15:10:39,560 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37775603830814364, 'Total loss': 0.37775603830814364} | train loss {'Reaction outcome loss': 0.3472767020065854, 'Total loss': 0.3472767020065854}
2023-01-05 15:10:39,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:39,560 INFO:     Epoch: 37
2023-01-05 15:10:41,502 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4089375783999761, 'Total loss': 0.4089375783999761} | train loss {'Reaction outcome loss': 0.34666079093776914, 'Total loss': 0.34666079093776914}
2023-01-05 15:10:41,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:41,503 INFO:     Epoch: 38
2023-01-05 15:10:43,637 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41284624934196473, 'Total loss': 0.41284624934196473} | train loss {'Reaction outcome loss': 0.3417706717974948, 'Total loss': 0.3417706717974948}
2023-01-05 15:10:43,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:43,637 INFO:     Epoch: 39
2023-01-05 15:10:45,819 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3997301787137985, 'Total loss': 0.3997301787137985} | train loss {'Reaction outcome loss': 0.3440227670336727, 'Total loss': 0.3440227670336727}
2023-01-05 15:10:45,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:45,819 INFO:     Epoch: 40
2023-01-05 15:10:47,948 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38513997892538704, 'Total loss': 0.38513997892538704} | train loss {'Reaction outcome loss': 0.3390599738833678, 'Total loss': 0.3390599738833678}
2023-01-05 15:10:47,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:47,948 INFO:     Epoch: 41
2023-01-05 15:10:50,080 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4052712510029475, 'Total loss': 0.4052712510029475} | train loss {'Reaction outcome loss': 0.3375389233068393, 'Total loss': 0.3375389233068393}
2023-01-05 15:10:50,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:50,080 INFO:     Epoch: 42
2023-01-05 15:10:52,204 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4224663108587265, 'Total loss': 0.4224663108587265} | train loss {'Reaction outcome loss': 0.3325889115595687, 'Total loss': 0.3325889115595687}
2023-01-05 15:10:52,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:52,205 INFO:     Epoch: 43
2023-01-05 15:10:54,354 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.37568406760692596, 'Total loss': 0.37568406760692596} | train loss {'Reaction outcome loss': 0.33015106126231, 'Total loss': 0.33015106126231}
2023-01-05 15:10:54,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:54,354 INFO:     Epoch: 44
2023-01-05 15:10:56,494 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41487529277801516, 'Total loss': 0.41487529277801516} | train loss {'Reaction outcome loss': 0.3254202699193554, 'Total loss': 0.3254202699193554}
2023-01-05 15:10:56,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:56,494 INFO:     Epoch: 45
2023-01-05 15:10:58,612 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4084522560238838, 'Total loss': 0.4084522560238838} | train loss {'Reaction outcome loss': 0.3177233824003352, 'Total loss': 0.3177233824003352}
2023-01-05 15:10:58,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:10:58,613 INFO:     Epoch: 46
2023-01-05 15:11:00,735 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44541795055071515, 'Total loss': 0.44541795055071515} | train loss {'Reaction outcome loss': 0.3262031986548083, 'Total loss': 0.3262031986548083}
2023-01-05 15:11:00,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:00,735 INFO:     Epoch: 47
2023-01-05 15:11:02,842 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42118136286735536, 'Total loss': 0.42118136286735536} | train loss {'Reaction outcome loss': 0.3123833850352433, 'Total loss': 0.3123833850352433}
2023-01-05 15:11:02,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:02,842 INFO:     Epoch: 48
2023-01-05 15:11:04,972 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3855931140482426, 'Total loss': 0.3855931140482426} | train loss {'Reaction outcome loss': 0.3124601735876207, 'Total loss': 0.3124601735876207}
2023-01-05 15:11:04,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:04,972 INFO:     Epoch: 49
2023-01-05 15:11:07,089 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40331005603075026, 'Total loss': 0.40331005603075026} | train loss {'Reaction outcome loss': 0.32085542723427724, 'Total loss': 0.32085542723427724}
2023-01-05 15:11:07,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:07,089 INFO:     Epoch: 50
2023-01-05 15:11:09,230 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4131916125615438, 'Total loss': 0.4131916125615438} | train loss {'Reaction outcome loss': 0.3194351534420339, 'Total loss': 0.3194351534420339}
2023-01-05 15:11:09,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:09,230 INFO:     Epoch: 51
2023-01-05 15:11:11,361 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42674185186624525, 'Total loss': 0.42674185186624525} | train loss {'Reaction outcome loss': 0.3044662327933921, 'Total loss': 0.3044662327933921}
2023-01-05 15:11:11,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:11,362 INFO:     Epoch: 52
2023-01-05 15:11:13,500 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41894348462422687, 'Total loss': 0.41894348462422687} | train loss {'Reaction outcome loss': 0.30262158195195843, 'Total loss': 0.30262158195195843}
2023-01-05 15:11:13,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:13,501 INFO:     Epoch: 53
2023-01-05 15:11:15,630 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43688185662031176, 'Total loss': 0.43688185662031176} | train loss {'Reaction outcome loss': 0.3051574840380328, 'Total loss': 0.3051574840380328}
2023-01-05 15:11:15,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:15,630 INFO:     Epoch: 54
2023-01-05 15:11:17,778 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40282510916392006, 'Total loss': 0.40282510916392006} | train loss {'Reaction outcome loss': 0.2979517957046084, 'Total loss': 0.2979517957046084}
2023-01-05 15:11:17,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:17,778 INFO:     Epoch: 55
2023-01-05 15:11:19,950 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3833938017487526, 'Total loss': 0.3833938017487526} | train loss {'Reaction outcome loss': 0.3008276567909948, 'Total loss': 0.3008276567909948}
2023-01-05 15:11:19,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:19,950 INFO:     Epoch: 56
2023-01-05 15:11:22,126 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4034519533316294, 'Total loss': 0.4034519533316294} | train loss {'Reaction outcome loss': 0.29794348080227845, 'Total loss': 0.29794348080227845}
2023-01-05 15:11:22,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:22,127 INFO:     Epoch: 57
2023-01-05 15:11:24,293 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3548255319396655, 'Total loss': 0.3548255319396655} | train loss {'Reaction outcome loss': 0.2924483523493374, 'Total loss': 0.2924483523493374}
2023-01-05 15:11:24,293 INFO:     Found new best model at epoch 57
2023-01-05 15:11:24,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:24,294 INFO:     Epoch: 58
2023-01-05 15:11:26,449 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3962741365035375, 'Total loss': 0.3962741365035375} | train loss {'Reaction outcome loss': 0.29072612748365767, 'Total loss': 0.29072612748365767}
2023-01-05 15:11:26,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:26,449 INFO:     Epoch: 59
2023-01-05 15:11:28,586 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4089452068010966, 'Total loss': 0.4089452068010966} | train loss {'Reaction outcome loss': 0.28797547338380863, 'Total loss': 0.28797547338380863}
2023-01-05 15:11:28,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:28,588 INFO:     Epoch: 60
2023-01-05 15:11:30,454 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4064937094847361, 'Total loss': 0.4064937094847361} | train loss {'Reaction outcome loss': 0.2889482794995726, 'Total loss': 0.2889482794995726}
2023-01-05 15:11:30,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:30,454 INFO:     Epoch: 61
2023-01-05 15:11:32,201 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39190935492515566, 'Total loss': 0.39190935492515566} | train loss {'Reaction outcome loss': 0.2803634468493235, 'Total loss': 0.2803634468493235}
2023-01-05 15:11:32,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:32,201 INFO:     Epoch: 62
2023-01-05 15:11:34,093 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41757522424062093, 'Total loss': 0.41757522424062093} | train loss {'Reaction outcome loss': 0.27618828217369795, 'Total loss': 0.27618828217369795}
2023-01-05 15:11:34,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:34,093 INFO:     Epoch: 63
2023-01-05 15:11:36,325 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.386275452375412, 'Total loss': 0.386275452375412} | train loss {'Reaction outcome loss': 0.2823817365442532, 'Total loss': 0.2823817365442532}
2023-01-05 15:11:36,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:36,326 INFO:     Epoch: 64
2023-01-05 15:11:38,483 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41586844126383465, 'Total loss': 0.41586844126383465} | train loss {'Reaction outcome loss': 0.27248314044091604, 'Total loss': 0.27248314044091604}
2023-01-05 15:11:38,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:38,484 INFO:     Epoch: 65
2023-01-05 15:11:40,622 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4317094663778941, 'Total loss': 0.4317094663778941} | train loss {'Reaction outcome loss': 0.27574094214619405, 'Total loss': 0.27574094214619405}
2023-01-05 15:11:40,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:40,622 INFO:     Epoch: 66
2023-01-05 15:11:42,764 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3956162969271342, 'Total loss': 0.3956162969271342} | train loss {'Reaction outcome loss': 0.2746324708182229, 'Total loss': 0.2746324708182229}
2023-01-05 15:11:42,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:42,765 INFO:     Epoch: 67
2023-01-05 15:11:44,897 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39687627206246057, 'Total loss': 0.39687627206246057} | train loss {'Reaction outcome loss': 0.2779378562784978, 'Total loss': 0.2779378562784978}
2023-01-05 15:11:44,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:44,898 INFO:     Epoch: 68
2023-01-05 15:11:47,044 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44326155781745913, 'Total loss': 0.44326155781745913} | train loss {'Reaction outcome loss': 0.26889938511375855, 'Total loss': 0.26889938511375855}
2023-01-05 15:11:47,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:47,044 INFO:     Epoch: 69
2023-01-05 15:11:49,236 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45084933439890545, 'Total loss': 0.45084933439890545} | train loss {'Reaction outcome loss': 0.2681405369437089, 'Total loss': 0.2681405369437089}
2023-01-05 15:11:49,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:49,237 INFO:     Epoch: 70
2023-01-05 15:11:51,424 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40747580329577127, 'Total loss': 0.40747580329577127} | train loss {'Reaction outcome loss': 0.26855950767215153, 'Total loss': 0.26855950767215153}
2023-01-05 15:11:51,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:51,424 INFO:     Epoch: 71
2023-01-05 15:11:53,611 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38807229523857434, 'Total loss': 0.38807229523857434} | train loss {'Reaction outcome loss': 0.2715059917175422, 'Total loss': 0.2715059917175422}
2023-01-05 15:11:53,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:53,612 INFO:     Epoch: 72
2023-01-05 15:11:55,796 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39352625906467437, 'Total loss': 0.39352625906467437} | train loss {'Reaction outcome loss': 0.2595532844183001, 'Total loss': 0.2595532844183001}
2023-01-05 15:11:55,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:55,796 INFO:     Epoch: 73
2023-01-05 15:11:57,929 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4161343981822332, 'Total loss': 0.4161343981822332} | train loss {'Reaction outcome loss': 0.2580582578972417, 'Total loss': 0.2580582578972417}
2023-01-05 15:11:57,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:11:57,930 INFO:     Epoch: 74
2023-01-05 15:12:00,092 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4107663710912069, 'Total loss': 0.4107663710912069} | train loss {'Reaction outcome loss': 0.26994552561183915, 'Total loss': 0.26994552561183915}
2023-01-05 15:12:00,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:00,092 INFO:     Epoch: 75
2023-01-05 15:12:02,232 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39394324521223706, 'Total loss': 0.39394324521223706} | train loss {'Reaction outcome loss': 0.26215852646116355, 'Total loss': 0.26215852646116355}
2023-01-05 15:12:02,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:02,232 INFO:     Epoch: 76
2023-01-05 15:12:04,363 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4423458884159724, 'Total loss': 0.4423458884159724} | train loss {'Reaction outcome loss': 0.26430055441973854, 'Total loss': 0.26430055441973854}
2023-01-05 15:12:04,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:04,364 INFO:     Epoch: 77
2023-01-05 15:12:06,516 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39324771662553154, 'Total loss': 0.39324771662553154} | train loss {'Reaction outcome loss': 0.2541882035655588, 'Total loss': 0.2541882035655588}
2023-01-05 15:12:06,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:06,517 INFO:     Epoch: 78
2023-01-05 15:12:08,630 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4715547243754069, 'Total loss': 0.4715547243754069} | train loss {'Reaction outcome loss': 0.2562521378149408, 'Total loss': 0.2562521378149408}
2023-01-05 15:12:08,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:08,631 INFO:     Epoch: 79
2023-01-05 15:12:10,775 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39138921797275544, 'Total loss': 0.39138921797275544} | train loss {'Reaction outcome loss': 0.25538353851051443, 'Total loss': 0.25538353851051443}
2023-01-05 15:12:10,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:10,775 INFO:     Epoch: 80
2023-01-05 15:12:12,904 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41198027034600576, 'Total loss': 0.41198027034600576} | train loss {'Reaction outcome loss': 0.25425944116347243, 'Total loss': 0.25425944116347243}
2023-01-05 15:12:12,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:12,904 INFO:     Epoch: 81
2023-01-05 15:12:15,041 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4283538599809011, 'Total loss': 0.4283538599809011} | train loss {'Reaction outcome loss': 0.2564644352634893, 'Total loss': 0.2564644352634893}
2023-01-05 15:12:15,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:15,042 INFO:     Epoch: 82
2023-01-05 15:12:17,165 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4112499882777532, 'Total loss': 0.4112499882777532} | train loss {'Reaction outcome loss': 0.24853596790102275, 'Total loss': 0.24853596790102275}
2023-01-05 15:12:17,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:17,166 INFO:     Epoch: 83
2023-01-05 15:12:19,338 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43321593503157296, 'Total loss': 0.43321593503157296} | train loss {'Reaction outcome loss': 0.2532827191421912, 'Total loss': 0.2532827191421912}
2023-01-05 15:12:19,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:19,338 INFO:     Epoch: 84
2023-01-05 15:12:21,460 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41859252254168194, 'Total loss': 0.41859252254168194} | train loss {'Reaction outcome loss': 0.2498315672396961, 'Total loss': 0.2498315672396961}
2023-01-05 15:12:21,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:21,460 INFO:     Epoch: 85
2023-01-05 15:12:23,597 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4275176008542379, 'Total loss': 0.4275176008542379} | train loss {'Reaction outcome loss': 0.24549914397516825, 'Total loss': 0.24549914397516825}
2023-01-05 15:12:23,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:23,597 INFO:     Epoch: 86
2023-01-05 15:12:25,761 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4222378740708033, 'Total loss': 0.4222378740708033} | train loss {'Reaction outcome loss': 0.24711582511935357, 'Total loss': 0.24711582511935357}
2023-01-05 15:12:25,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:25,761 INFO:     Epoch: 87
2023-01-05 15:12:27,915 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48990206718444823, 'Total loss': 0.48990206718444823} | train loss {'Reaction outcome loss': 0.2457651990418234, 'Total loss': 0.2457651990418234}
2023-01-05 15:12:27,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:27,915 INFO:     Epoch: 88
2023-01-05 15:12:30,062 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4615352352460225, 'Total loss': 0.4615352352460225} | train loss {'Reaction outcome loss': 0.24855550414590288, 'Total loss': 0.24855550414590288}
2023-01-05 15:12:30,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:30,062 INFO:     Epoch: 89
2023-01-05 15:12:32,193 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43311382134755455, 'Total loss': 0.43311382134755455} | train loss {'Reaction outcome loss': 0.24293552458721357, 'Total loss': 0.24293552458721357}
2023-01-05 15:12:32,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:32,193 INFO:     Epoch: 90
2023-01-05 15:12:34,343 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4292965799570084, 'Total loss': 0.4292965799570084} | train loss {'Reaction outcome loss': 0.24532677637698658, 'Total loss': 0.24532677637698658}
2023-01-05 15:12:34,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:34,344 INFO:     Epoch: 91
2023-01-05 15:12:36,519 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4509557828307152, 'Total loss': 0.4509557828307152} | train loss {'Reaction outcome loss': 0.2407457723764934, 'Total loss': 0.2407457723764934}
2023-01-05 15:12:36,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:36,520 INFO:     Epoch: 92
2023-01-05 15:12:38,671 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39776762227217355, 'Total loss': 0.39776762227217355} | train loss {'Reaction outcome loss': 0.23993505491963485, 'Total loss': 0.23993505491963485}
2023-01-05 15:12:38,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:38,671 INFO:     Epoch: 93
2023-01-05 15:12:40,807 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4199653521180153, 'Total loss': 0.4199653521180153} | train loss {'Reaction outcome loss': 0.2461884994073397, 'Total loss': 0.2461884994073397}
2023-01-05 15:12:40,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:40,808 INFO:     Epoch: 94
2023-01-05 15:12:42,932 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39764554301897687, 'Total loss': 0.39764554301897687} | train loss {'Reaction outcome loss': 0.23950198865121733, 'Total loss': 0.23950198865121733}
2023-01-05 15:12:42,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:42,933 INFO:     Epoch: 95
2023-01-05 15:12:45,038 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45750414207577705, 'Total loss': 0.45750414207577705} | train loss {'Reaction outcome loss': 0.2327961377785915, 'Total loss': 0.2327961377785915}
2023-01-05 15:12:45,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:45,039 INFO:     Epoch: 96
2023-01-05 15:12:47,183 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42157022456328075, 'Total loss': 0.42157022456328075} | train loss {'Reaction outcome loss': 0.23728976495917478, 'Total loss': 0.23728976495917478}
2023-01-05 15:12:47,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:47,183 INFO:     Epoch: 97
2023-01-05 15:12:49,319 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3991763412952423, 'Total loss': 0.3991763412952423} | train loss {'Reaction outcome loss': 0.2386145224849129, 'Total loss': 0.2386145224849129}
2023-01-05 15:12:49,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:49,319 INFO:     Epoch: 98
2023-01-05 15:12:51,452 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3932164122660955, 'Total loss': 0.3932164122660955} | train loss {'Reaction outcome loss': 0.2349816490658117, 'Total loss': 0.2349816490658117}
2023-01-05 15:12:51,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:51,452 INFO:     Epoch: 99
2023-01-05 15:12:53,588 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4143865672250589, 'Total loss': 0.4143865672250589} | train loss {'Reaction outcome loss': 0.22932573343987447, 'Total loss': 0.22932573343987447}
2023-01-05 15:12:53,588 INFO:     Best model found after epoch 58 of 100.
2023-01-05 15:12:53,589 INFO:   Done with stage: TRAINING
2023-01-05 15:12:53,589 INFO:   Starting stage: EVALUATION
2023-01-05 15:12:53,728 INFO:   Done with stage: EVALUATION
2023-01-05 15:12:53,728 INFO:   Leaving out SEQ value Fold_6
2023-01-05 15:12:53,741 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 15:12:53,741 INFO:   Starting stage: FEATURE SCALING
2023-01-05 15:12:54,384 INFO:   Done with stage: FEATURE SCALING
2023-01-05 15:12:54,384 INFO:   Starting stage: SCALING TARGETS
2023-01-05 15:12:54,451 INFO:   Done with stage: SCALING TARGETS
2023-01-05 15:12:54,451 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:12:54,451 INFO:     No hyperparam tuning for this model
2023-01-05 15:12:54,451 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:12:54,451 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 15:12:54,452 INFO:     None feature selector for col prot
2023-01-05 15:12:54,452 INFO:     None feature selector for col prot
2023-01-05 15:12:54,452 INFO:     None feature selector for col prot
2023-01-05 15:12:54,453 INFO:     None feature selector for col chem
2023-01-05 15:12:54,453 INFO:     None feature selector for col chem
2023-01-05 15:12:54,453 INFO:     None feature selector for col chem
2023-01-05 15:12:54,453 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 15:12:54,453 INFO:   Starting stage: BUILD MODEL
2023-01-05 15:12:54,454 INFO:     Number of params in model 72901
2023-01-05 15:12:54,458 INFO:   Done with stage: BUILD MODEL
2023-01-05 15:12:54,458 INFO:   Starting stage: TRAINING
2023-01-05 15:12:54,515 INFO:     Val loss before train {'Reaction outcome loss': 1.107687787214915, 'Total loss': 1.107687787214915}
2023-01-05 15:12:54,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:54,516 INFO:     Epoch: 0
2023-01-05 15:12:56,648 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8666275978088379, 'Total loss': 0.8666275978088379} | train loss {'Reaction outcome loss': 0.9123413325884403, 'Total loss': 0.9123413325884403}
2023-01-05 15:12:56,648 INFO:     Found new best model at epoch 0
2023-01-05 15:12:56,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:56,649 INFO:     Epoch: 1
2023-01-05 15:12:58,760 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6917687217394511, 'Total loss': 0.6917687217394511} | train loss {'Reaction outcome loss': 0.7211745980676714, 'Total loss': 0.7211745980676714}
2023-01-05 15:12:58,760 INFO:     Found new best model at epoch 1
2023-01-05 15:12:58,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:12:58,761 INFO:     Epoch: 2
2023-01-05 15:13:00,882 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6318977574507395, 'Total loss': 0.6318977574507395} | train loss {'Reaction outcome loss': 0.5772678333065121, 'Total loss': 0.5772678333065121}
2023-01-05 15:13:00,882 INFO:     Found new best model at epoch 2
2023-01-05 15:13:00,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:00,884 INFO:     Epoch: 3
2023-01-05 15:13:03,044 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5770954688390096, 'Total loss': 0.5770954688390096} | train loss {'Reaction outcome loss': 0.5296817183931232, 'Total loss': 0.5296817183931232}
2023-01-05 15:13:03,044 INFO:     Found new best model at epoch 3
2023-01-05 15:13:03,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:03,045 INFO:     Epoch: 4
2023-01-05 15:13:05,200 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5568114837010701, 'Total loss': 0.5568114837010701} | train loss {'Reaction outcome loss': 0.5182917065126992, 'Total loss': 0.5182917065126992}
2023-01-05 15:13:05,201 INFO:     Found new best model at epoch 4
2023-01-05 15:13:05,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:05,202 INFO:     Epoch: 5
2023-01-05 15:13:07,303 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5331406603256862, 'Total loss': 0.5331406603256862} | train loss {'Reaction outcome loss': 0.5036924205201886, 'Total loss': 0.5036924205201886}
2023-01-05 15:13:07,303 INFO:     Found new best model at epoch 5
2023-01-05 15:13:07,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:07,304 INFO:     Epoch: 6
2023-01-05 15:13:09,422 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.6141420046488444, 'Total loss': 0.6141420046488444} | train loss {'Reaction outcome loss': 0.48520276896082437, 'Total loss': 0.48520276896082437}
2023-01-05 15:13:09,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:09,423 INFO:     Epoch: 7
2023-01-05 15:13:11,548 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5266258031129837, 'Total loss': 0.5266258031129837} | train loss {'Reaction outcome loss': 0.481338327566346, 'Total loss': 0.481338327566346}
2023-01-05 15:13:11,548 INFO:     Found new best model at epoch 7
2023-01-05 15:13:11,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:11,549 INFO:     Epoch: 8
2023-01-05 15:13:13,665 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5316470791896184, 'Total loss': 0.5316470791896184} | train loss {'Reaction outcome loss': 0.4755741673020216, 'Total loss': 0.4755741673020216}
2023-01-05 15:13:13,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:13,665 INFO:     Epoch: 9
2023-01-05 15:13:15,792 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5225952853759129, 'Total loss': 0.5225952853759129} | train loss {'Reaction outcome loss': 0.4701070968375538, 'Total loss': 0.4701070968375538}
2023-01-05 15:13:15,793 INFO:     Found new best model at epoch 9
2023-01-05 15:13:15,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:15,794 INFO:     Epoch: 10
2023-01-05 15:13:17,929 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5785084088643392, 'Total loss': 0.5785084088643392} | train loss {'Reaction outcome loss': 0.4645592422384919, 'Total loss': 0.4645592422384919}
2023-01-05 15:13:17,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:17,929 INFO:     Epoch: 11
2023-01-05 15:13:20,065 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5409527103106181, 'Total loss': 0.5409527103106181} | train loss {'Reaction outcome loss': 0.46345481740467714, 'Total loss': 0.46345481740467714}
2023-01-05 15:13:20,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:20,066 INFO:     Epoch: 12
2023-01-05 15:13:22,201 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5334509571393331, 'Total loss': 0.5334509571393331} | train loss {'Reaction outcome loss': 0.4602965570836168, 'Total loss': 0.4602965570836168}
2023-01-05 15:13:22,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:22,201 INFO:     Epoch: 13
2023-01-05 15:13:24,297 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.523175444205602, 'Total loss': 0.523175444205602} | train loss {'Reaction outcome loss': 0.44968075995698514, 'Total loss': 0.44968075995698514}
2023-01-05 15:13:24,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:24,297 INFO:     Epoch: 14
2023-01-05 15:13:26,398 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5270858883857727, 'Total loss': 0.5270858883857727} | train loss {'Reaction outcome loss': 0.44010131713344064, 'Total loss': 0.44010131713344064}
2023-01-05 15:13:26,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:26,398 INFO:     Epoch: 15
2023-01-05 15:13:28,512 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48290171722571057, 'Total loss': 0.48290171722571057} | train loss {'Reaction outcome loss': 0.43462143800197506, 'Total loss': 0.43462143800197506}
2023-01-05 15:13:28,513 INFO:     Found new best model at epoch 15
2023-01-05 15:13:28,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:28,514 INFO:     Epoch: 16
2023-01-05 15:13:30,638 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5297279278437297, 'Total loss': 0.5297279278437297} | train loss {'Reaction outcome loss': 0.4334568807056972, 'Total loss': 0.4334568807056972}
2023-01-05 15:13:30,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:30,638 INFO:     Epoch: 17
2023-01-05 15:13:32,761 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5136909822622935, 'Total loss': 0.5136909822622935} | train loss {'Reaction outcome loss': 0.43286000519663426, 'Total loss': 0.43286000519663426}
2023-01-05 15:13:32,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:32,761 INFO:     Epoch: 18
2023-01-05 15:13:34,893 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5123335917790731, 'Total loss': 0.5123335917790731} | train loss {'Reaction outcome loss': 0.42770950146865494, 'Total loss': 0.42770950146865494}
2023-01-05 15:13:34,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:34,893 INFO:     Epoch: 19
2023-01-05 15:13:37,011 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5140130201975505, 'Total loss': 0.5140130201975505} | train loss {'Reaction outcome loss': 0.42201751385962133, 'Total loss': 0.42201751385962133}
2023-01-05 15:13:37,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:37,011 INFO:     Epoch: 20
2023-01-05 15:13:39,157 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5430346290270488, 'Total loss': 0.5430346290270488} | train loss {'Reaction outcome loss': 0.41804429454790365, 'Total loss': 0.41804429454790365}
2023-01-05 15:13:39,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:39,158 INFO:     Epoch: 21
2023-01-05 15:13:41,281 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5039249857266744, 'Total loss': 0.5039249857266744} | train loss {'Reaction outcome loss': 0.41473595997243573, 'Total loss': 0.41473595997243573}
2023-01-05 15:13:41,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:41,281 INFO:     Epoch: 22
2023-01-05 15:13:43,395 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5004712224006653, 'Total loss': 0.5004712224006653} | train loss {'Reaction outcome loss': 0.40641139715145796, 'Total loss': 0.40641139715145796}
2023-01-05 15:13:43,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:43,396 INFO:     Epoch: 23
2023-01-05 15:13:45,536 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5104461173216502, 'Total loss': 0.5104461173216502} | train loss {'Reaction outcome loss': 0.4071539273082992, 'Total loss': 0.4071539273082992}
2023-01-05 15:13:45,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:45,537 INFO:     Epoch: 24
2023-01-05 15:13:47,667 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.500450732310613, 'Total loss': 0.500450732310613} | train loss {'Reaction outcome loss': 0.40424016197194984, 'Total loss': 0.40424016197194984}
2023-01-05 15:13:47,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:47,667 INFO:     Epoch: 25
2023-01-05 15:13:49,804 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49665477176507317, 'Total loss': 0.49665477176507317} | train loss {'Reaction outcome loss': 0.4010435284384878, 'Total loss': 0.4010435284384878}
2023-01-05 15:13:49,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:49,805 INFO:     Epoch: 26
2023-01-05 15:13:51,914 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5180869857470195, 'Total loss': 0.5180869857470195} | train loss {'Reaction outcome loss': 0.39010670404512804, 'Total loss': 0.39010670404512804}
2023-01-05 15:13:51,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:51,915 INFO:     Epoch: 27
2023-01-05 15:13:54,027 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4886371069898208, 'Total loss': 0.4886371069898208} | train loss {'Reaction outcome loss': 0.39178148408730823, 'Total loss': 0.39178148408730823}
2023-01-05 15:13:54,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:54,027 INFO:     Epoch: 28
2023-01-05 15:13:56,151 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5217439969380696, 'Total loss': 0.5217439969380696} | train loss {'Reaction outcome loss': 0.3898999129896199, 'Total loss': 0.3898999129896199}
2023-01-05 15:13:56,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:56,151 INFO:     Epoch: 29
2023-01-05 15:13:58,281 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49279789328575135, 'Total loss': 0.49279789328575135} | train loss {'Reaction outcome loss': 0.3887006137178931, 'Total loss': 0.3887006137178931}
2023-01-05 15:13:58,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:13:58,281 INFO:     Epoch: 30
2023-01-05 15:14:00,406 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5287709176540375, 'Total loss': 0.5287709176540375} | train loss {'Reaction outcome loss': 0.3791862998580758, 'Total loss': 0.3791862998580758}
2023-01-05 15:14:00,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:00,406 INFO:     Epoch: 31
2023-01-05 15:14:02,531 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49992679357528685, 'Total loss': 0.49992679357528685} | train loss {'Reaction outcome loss': 0.3841383220293583, 'Total loss': 0.3841383220293583}
2023-01-05 15:14:02,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:02,532 INFO:     Epoch: 32
2023-01-05 15:14:04,656 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5289495269457499, 'Total loss': 0.5289495269457499} | train loss {'Reaction outcome loss': 0.3819421634296358, 'Total loss': 0.3819421634296358}
2023-01-05 15:14:04,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:04,657 INFO:     Epoch: 33
2023-01-05 15:14:06,779 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49408891797065735, 'Total loss': 0.49408891797065735} | train loss {'Reaction outcome loss': 0.36554521322250366, 'Total loss': 0.36554521322250366}
2023-01-05 15:14:06,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:06,779 INFO:     Epoch: 34
2023-01-05 15:14:08,893 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5088826974232992, 'Total loss': 0.5088826974232992} | train loss {'Reaction outcome loss': 0.3744819591661076, 'Total loss': 0.3744819591661076}
2023-01-05 15:14:08,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:08,893 INFO:     Epoch: 35
2023-01-05 15:14:11,003 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5435936053593954, 'Total loss': 0.5435936053593954} | train loss {'Reaction outcome loss': 0.3591710773770844, 'Total loss': 0.3591710773770844}
2023-01-05 15:14:11,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:11,003 INFO:     Epoch: 36
2023-01-05 15:14:13,146 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5309903254111608, 'Total loss': 0.5309903254111608} | train loss {'Reaction outcome loss': 0.3644649251585915, 'Total loss': 0.3644649251585915}
2023-01-05 15:14:13,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:13,146 INFO:     Epoch: 37
2023-01-05 15:14:15,288 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4867509673039118, 'Total loss': 0.4867509673039118} | train loss {'Reaction outcome loss': 0.3546246526278419, 'Total loss': 0.3546246526278419}
2023-01-05 15:14:15,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:15,288 INFO:     Epoch: 38
2023-01-05 15:14:17,404 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5066984991232554, 'Total loss': 0.5066984991232554} | train loss {'Reaction outcome loss': 0.3581580545739595, 'Total loss': 0.3581580545739595}
2023-01-05 15:14:17,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:17,404 INFO:     Epoch: 39
2023-01-05 15:14:19,608 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46081643402576444, 'Total loss': 0.46081643402576444} | train loss {'Reaction outcome loss': 0.35556200506922964, 'Total loss': 0.35556200506922964}
2023-01-05 15:14:19,608 INFO:     Found new best model at epoch 39
2023-01-05 15:14:19,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:19,610 INFO:     Epoch: 40
2023-01-05 15:14:21,780 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5263661762078603, 'Total loss': 0.5263661762078603} | train loss {'Reaction outcome loss': 0.3398860643034453, 'Total loss': 0.3398860643034453}
2023-01-05 15:14:21,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:21,782 INFO:     Epoch: 41
2023-01-05 15:14:23,900 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5046828846136729, 'Total loss': 0.5046828846136729} | train loss {'Reaction outcome loss': 0.34241455212071703, 'Total loss': 0.34241455212071703}
2023-01-05 15:14:23,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:23,900 INFO:     Epoch: 42
2023-01-05 15:14:26,009 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.49675595307101805, 'Total loss': 0.49675595307101805} | train loss {'Reaction outcome loss': 0.34771761662521206, 'Total loss': 0.34771761662521206}
2023-01-05 15:14:26,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:26,010 INFO:     Epoch: 43
2023-01-05 15:14:28,129 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5012411773204803, 'Total loss': 0.5012411773204803} | train loss {'Reaction outcome loss': 0.3363802754234918, 'Total loss': 0.3363802754234918}
2023-01-05 15:14:28,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:28,130 INFO:     Epoch: 44
2023-01-05 15:14:30,236 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4892421305179596, 'Total loss': 0.4892421305179596} | train loss {'Reaction outcome loss': 0.33300580469816377, 'Total loss': 0.33300580469816377}
2023-01-05 15:14:30,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:30,236 INFO:     Epoch: 45
2023-01-05 15:14:32,371 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4992529054482778, 'Total loss': 0.4992529054482778} | train loss {'Reaction outcome loss': 0.33278957821920024, 'Total loss': 0.33278957821920024}
2023-01-05 15:14:32,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:32,372 INFO:     Epoch: 46
2023-01-05 15:14:34,487 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49687933226426445, 'Total loss': 0.49687933226426445} | train loss {'Reaction outcome loss': 0.3256148883438372, 'Total loss': 0.3256148883438372}
2023-01-05 15:14:34,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:34,488 INFO:     Epoch: 47
2023-01-05 15:14:36,622 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5001559942960739, 'Total loss': 0.5001559942960739} | train loss {'Reaction outcome loss': 0.32067342001549054, 'Total loss': 0.32067342001549054}
2023-01-05 15:14:36,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:36,622 INFO:     Epoch: 48
2023-01-05 15:14:38,753 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4605487108230591, 'Total loss': 0.4605487108230591} | train loss {'Reaction outcome loss': 0.32107089411453665, 'Total loss': 0.32107089411453665}
2023-01-05 15:14:38,753 INFO:     Found new best model at epoch 48
2023-01-05 15:14:38,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:38,754 INFO:     Epoch: 49
2023-01-05 15:14:40,887 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48914759457111356, 'Total loss': 0.48914759457111356} | train loss {'Reaction outcome loss': 0.31991808991128706, 'Total loss': 0.31991808991128706}
2023-01-05 15:14:40,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:40,888 INFO:     Epoch: 50
2023-01-05 15:14:43,028 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4866704058522979, 'Total loss': 0.4866704058522979} | train loss {'Reaction outcome loss': 0.31418565375518887, 'Total loss': 0.31418565375518887}
2023-01-05 15:14:43,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:43,028 INFO:     Epoch: 51
2023-01-05 15:14:45,109 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4967218468586604, 'Total loss': 0.4967218468586604} | train loss {'Reaction outcome loss': 0.31420965952587215, 'Total loss': 0.31420965952587215}
2023-01-05 15:14:45,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:45,109 INFO:     Epoch: 52
2023-01-05 15:14:47,101 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4961316148440043, 'Total loss': 0.4961316148440043} | train loss {'Reaction outcome loss': 0.3116936951657355, 'Total loss': 0.3116936951657355}
2023-01-05 15:14:47,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:47,102 INFO:     Epoch: 53
2023-01-05 15:14:49,231 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5085076183080673, 'Total loss': 0.5085076183080673} | train loss {'Reaction outcome loss': 0.30614484802925546, 'Total loss': 0.30614484802925546}
2023-01-05 15:14:49,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:49,231 INFO:     Epoch: 54
2023-01-05 15:14:51,348 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4854031056165695, 'Total loss': 0.4854031056165695} | train loss {'Reaction outcome loss': 0.3152638129794445, 'Total loss': 0.3152638129794445}
2023-01-05 15:14:51,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:51,349 INFO:     Epoch: 55
2023-01-05 15:14:53,405 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5366491874059042, 'Total loss': 0.5366491874059042} | train loss {'Reaction outcome loss': 0.31490910461261157, 'Total loss': 0.31490910461261157}
2023-01-05 15:14:53,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:53,406 INFO:     Epoch: 56
2023-01-05 15:14:55,176 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4918766478697459, 'Total loss': 0.4918766478697459} | train loss {'Reaction outcome loss': 0.30167181263149, 'Total loss': 0.30167181263149}
2023-01-05 15:14:55,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:55,176 INFO:     Epoch: 57
2023-01-05 15:14:56,940 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.538167272011439, 'Total loss': 0.538167272011439} | train loss {'Reaction outcome loss': 0.2997353300486347, 'Total loss': 0.2997353300486347}
2023-01-05 15:14:56,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:56,941 INFO:     Epoch: 58
2023-01-05 15:14:58,989 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4916833281517029, 'Total loss': 0.4916833281517029} | train loss {'Reaction outcome loss': 0.29698249327203075, 'Total loss': 0.29698249327203075}
2023-01-05 15:14:58,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:14:58,989 INFO:     Epoch: 59
2023-01-05 15:15:01,116 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5122490614652634, 'Total loss': 0.5122490614652634} | train loss {'Reaction outcome loss': 0.2935265095379108, 'Total loss': 0.2935265095379108}
2023-01-05 15:15:01,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:01,116 INFO:     Epoch: 60
2023-01-05 15:15:03,232 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5155592585603396, 'Total loss': 0.5155592585603396} | train loss {'Reaction outcome loss': 0.2962127570267562, 'Total loss': 0.2962127570267562}
2023-01-05 15:15:03,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:03,233 INFO:     Epoch: 61
2023-01-05 15:15:05,354 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5182132959365845, 'Total loss': 0.5182132959365845} | train loss {'Reaction outcome loss': 0.28877491936524274, 'Total loss': 0.28877491936524274}
2023-01-05 15:15:05,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:05,354 INFO:     Epoch: 62
2023-01-05 15:15:07,487 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5719142297903697, 'Total loss': 0.5719142297903697} | train loss {'Reaction outcome loss': 0.2948365443873973, 'Total loss': 0.2948365443873973}
2023-01-05 15:15:07,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:07,487 INFO:     Epoch: 63
2023-01-05 15:15:09,595 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49842505156993866, 'Total loss': 0.49842505156993866} | train loss {'Reaction outcome loss': 0.2909223787732177, 'Total loss': 0.2909223787732177}
2023-01-05 15:15:09,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:09,595 INFO:     Epoch: 64
2023-01-05 15:15:11,724 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.504225864013036, 'Total loss': 0.504225864013036} | train loss {'Reaction outcome loss': 0.28530238591980583, 'Total loss': 0.28530238591980583}
2023-01-05 15:15:11,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:11,724 INFO:     Epoch: 65
2023-01-05 15:15:13,851 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5217690428098043, 'Total loss': 0.5217690428098043} | train loss {'Reaction outcome loss': 0.28416069666428606, 'Total loss': 0.28416069666428606}
2023-01-05 15:15:13,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:13,851 INFO:     Epoch: 66
2023-01-05 15:15:15,982 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5693012913068135, 'Total loss': 0.5693012913068135} | train loss {'Reaction outcome loss': 0.28378628437567655, 'Total loss': 0.28378628437567655}
2023-01-05 15:15:15,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:15,983 INFO:     Epoch: 67
2023-01-05 15:15:18,109 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4998508850733439, 'Total loss': 0.4998508850733439} | train loss {'Reaction outcome loss': 0.27893803092640834, 'Total loss': 0.27893803092640834}
2023-01-05 15:15:18,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:18,110 INFO:     Epoch: 68
2023-01-05 15:15:20,260 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5026260495185852, 'Total loss': 0.5026260495185852} | train loss {'Reaction outcome loss': 0.28997989787614387, 'Total loss': 0.28997989787614387}
2023-01-05 15:15:20,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:20,260 INFO:     Epoch: 69
2023-01-05 15:15:22,387 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4984140952428182, 'Total loss': 0.4984140952428182} | train loss {'Reaction outcome loss': 0.27312399485854655, 'Total loss': 0.27312399485854655}
2023-01-05 15:15:22,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:22,388 INFO:     Epoch: 70
2023-01-05 15:15:24,485 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5119946812589963, 'Total loss': 0.5119946812589963} | train loss {'Reaction outcome loss': 0.2799631091987803, 'Total loss': 0.2799631091987803}
2023-01-05 15:15:24,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:24,485 INFO:     Epoch: 71
2023-01-05 15:15:26,602 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5239147086938222, 'Total loss': 0.5239147086938222} | train loss {'Reaction outcome loss': 0.2749333330890635, 'Total loss': 0.2749333330890635}
2023-01-05 15:15:26,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:26,603 INFO:     Epoch: 72
2023-01-05 15:15:28,718 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5179106583197911, 'Total loss': 0.5179106583197911} | train loss {'Reaction outcome loss': 0.27324952306942296, 'Total loss': 0.27324952306942296}
2023-01-05 15:15:28,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:28,718 INFO:     Epoch: 73
2023-01-05 15:15:30,841 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5518000205357869, 'Total loss': 0.5518000205357869} | train loss {'Reaction outcome loss': 0.2710690784639928, 'Total loss': 0.2710690784639928}
2023-01-05 15:15:30,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:30,841 INFO:     Epoch: 74
2023-01-05 15:15:32,947 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5119764113798737, 'Total loss': 0.5119764113798737} | train loss {'Reaction outcome loss': 0.2726983345785748, 'Total loss': 0.2726983345785748}
2023-01-05 15:15:32,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:32,948 INFO:     Epoch: 75
2023-01-05 15:15:35,102 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5180973390738169, 'Total loss': 0.5180973390738169} | train loss {'Reaction outcome loss': 0.2664386982255148, 'Total loss': 0.2664386982255148}
2023-01-05 15:15:35,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:35,102 INFO:     Epoch: 76
2023-01-05 15:15:37,254 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5303943614164989, 'Total loss': 0.5303943614164989} | train loss {'Reaction outcome loss': 0.26950533785635516, 'Total loss': 0.26950533785635516}
2023-01-05 15:15:37,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:37,254 INFO:     Epoch: 77
2023-01-05 15:15:39,414 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5949100414911906, 'Total loss': 0.5949100414911906} | train loss {'Reaction outcome loss': 0.2639978266672501, 'Total loss': 0.2639978266672501}
2023-01-05 15:15:39,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:39,415 INFO:     Epoch: 78
2023-01-05 15:15:41,544 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.528210586309433, 'Total loss': 0.528210586309433} | train loss {'Reaction outcome loss': 0.264703715261031, 'Total loss': 0.264703715261031}
2023-01-05 15:15:41,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:41,544 INFO:     Epoch: 79
2023-01-05 15:15:43,650 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5195700208346049, 'Total loss': 0.5195700208346049} | train loss {'Reaction outcome loss': 0.2619863227146231, 'Total loss': 0.2619863227146231}
2023-01-05 15:15:43,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:43,650 INFO:     Epoch: 80
2023-01-05 15:15:45,790 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.543883885939916, 'Total loss': 0.543883885939916} | train loss {'Reaction outcome loss': 0.26276971395008075, 'Total loss': 0.26276971395008075}
2023-01-05 15:15:45,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:45,791 INFO:     Epoch: 81
2023-01-05 15:15:47,951 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5175186256567638, 'Total loss': 0.5175186256567638} | train loss {'Reaction outcome loss': 0.2646787497300259, 'Total loss': 0.2646787497300259}
2023-01-05 15:15:47,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:47,951 INFO:     Epoch: 82
2023-01-05 15:15:50,067 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5228058596452078, 'Total loss': 0.5228058596452078} | train loss {'Reaction outcome loss': 0.2529718529385252, 'Total loss': 0.2529718529385252}
2023-01-05 15:15:50,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:50,067 INFO:     Epoch: 83
2023-01-05 15:15:52,181 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4963749945163727, 'Total loss': 0.4963749945163727} | train loss {'Reaction outcome loss': 0.2583163267908952, 'Total loss': 0.2583163267908952}
2023-01-05 15:15:52,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:52,182 INFO:     Epoch: 84
2023-01-05 15:15:54,309 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5115860810503363, 'Total loss': 0.5115860810503363} | train loss {'Reaction outcome loss': 0.2541873202942339, 'Total loss': 0.2541873202942339}
2023-01-05 15:15:54,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:54,309 INFO:     Epoch: 85
2023-01-05 15:15:56,413 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.52608369688193, 'Total loss': 0.52608369688193} | train loss {'Reaction outcome loss': 0.25414479156144154, 'Total loss': 0.25414479156144154}
2023-01-05 15:15:56,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:56,414 INFO:     Epoch: 86
2023-01-05 15:15:58,519 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5139594579736392, 'Total loss': 0.5139594579736392} | train loss {'Reaction outcome loss': 0.24754869768007115, 'Total loss': 0.24754869768007115}
2023-01-05 15:15:58,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:15:58,519 INFO:     Epoch: 87
2023-01-05 15:16:00,638 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4961582240959009, 'Total loss': 0.4961582240959009} | train loss {'Reaction outcome loss': 0.2585926937423783, 'Total loss': 0.2585926937423783}
2023-01-05 15:16:00,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:00,638 INFO:     Epoch: 88
2023-01-05 15:16:02,755 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5611841370662053, 'Total loss': 0.5611841370662053} | train loss {'Reaction outcome loss': 0.2597366323005476, 'Total loss': 0.2597366323005476}
2023-01-05 15:16:02,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:02,755 INFO:     Epoch: 89
2023-01-05 15:16:04,877 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.501622615257899, 'Total loss': 0.501622615257899} | train loss {'Reaction outcome loss': 0.25647777052862303, 'Total loss': 0.25647777052862303}
2023-01-05 15:16:04,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:04,878 INFO:     Epoch: 90
2023-01-05 15:16:06,993 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4812695223838091, 'Total loss': 0.4812695223838091} | train loss {'Reaction outcome loss': 0.24512910830955476, 'Total loss': 0.24512910830955476}
2023-01-05 15:16:06,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:06,994 INFO:     Epoch: 91
2023-01-05 15:16:09,092 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5366405506928762, 'Total loss': 0.5366405506928762} | train loss {'Reaction outcome loss': 0.24371529994157207, 'Total loss': 0.24371529994157207}
2023-01-05 15:16:09,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:09,092 INFO:     Epoch: 92
2023-01-05 15:16:11,217 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5092012087504069, 'Total loss': 0.5092012087504069} | train loss {'Reaction outcome loss': 0.24516346101604758, 'Total loss': 0.24516346101604758}
2023-01-05 15:16:11,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:11,217 INFO:     Epoch: 93
2023-01-05 15:16:13,365 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5203920165697734, 'Total loss': 0.5203920165697734} | train loss {'Reaction outcome loss': 0.24518320987157988, 'Total loss': 0.24518320987157988}
2023-01-05 15:16:13,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:13,365 INFO:     Epoch: 94
2023-01-05 15:16:15,497 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5089144468307495, 'Total loss': 0.5089144468307495} | train loss {'Reaction outcome loss': 0.2420442319737795, 'Total loss': 0.2420442319737795}
2023-01-05 15:16:15,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:15,498 INFO:     Epoch: 95
2023-01-05 15:16:17,626 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.533919553955396, 'Total loss': 0.533919553955396} | train loss {'Reaction outcome loss': 0.24301802802953745, 'Total loss': 0.24301802802953745}
2023-01-05 15:16:17,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:17,626 INFO:     Epoch: 96
2023-01-05 15:16:19,757 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4869767000277837, 'Total loss': 0.4869767000277837} | train loss {'Reaction outcome loss': 0.24118297452946286, 'Total loss': 0.24118297452946286}
2023-01-05 15:16:19,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:19,757 INFO:     Epoch: 97
2023-01-05 15:16:21,875 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5323486944039663, 'Total loss': 0.5323486944039663} | train loss {'Reaction outcome loss': 0.24054520751175645, 'Total loss': 0.24054520751175645}
2023-01-05 15:16:21,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:21,875 INFO:     Epoch: 98
2023-01-05 15:16:24,014 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46852536996205646, 'Total loss': 0.46852536996205646} | train loss {'Reaction outcome loss': 0.242835015304141, 'Total loss': 0.242835015304141}
2023-01-05 15:16:24,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:24,014 INFO:     Epoch: 99
2023-01-05 15:16:26,148 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5192001700401306, 'Total loss': 0.5192001700401306} | train loss {'Reaction outcome loss': 0.245507858018135, 'Total loss': 0.245507858018135}
2023-01-05 15:16:26,148 INFO:     Best model found after epoch 49 of 100.
2023-01-05 15:16:26,149 INFO:   Done with stage: TRAINING
2023-01-05 15:16:26,149 INFO:   Starting stage: EVALUATION
2023-01-05 15:16:26,294 INFO:   Done with stage: EVALUATION
2023-01-05 15:16:26,294 INFO:   Leaving out SEQ value Fold_7
2023-01-05 15:16:26,307 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 15:16:26,307 INFO:   Starting stage: FEATURE SCALING
2023-01-05 15:16:26,961 INFO:   Done with stage: FEATURE SCALING
2023-01-05 15:16:26,961 INFO:   Starting stage: SCALING TARGETS
2023-01-05 15:16:27,031 INFO:   Done with stage: SCALING TARGETS
2023-01-05 15:16:27,031 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:16:27,031 INFO:     No hyperparam tuning for this model
2023-01-05 15:16:27,031 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:16:27,031 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 15:16:27,032 INFO:     None feature selector for col prot
2023-01-05 15:16:27,032 INFO:     None feature selector for col prot
2023-01-05 15:16:27,032 INFO:     None feature selector for col prot
2023-01-05 15:16:27,033 INFO:     None feature selector for col chem
2023-01-05 15:16:27,033 INFO:     None feature selector for col chem
2023-01-05 15:16:27,033 INFO:     None feature selector for col chem
2023-01-05 15:16:27,033 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 15:16:27,033 INFO:   Starting stage: BUILD MODEL
2023-01-05 15:16:27,034 INFO:     Number of params in model 72901
2023-01-05 15:16:27,037 INFO:   Done with stage: BUILD MODEL
2023-01-05 15:16:27,037 INFO:   Starting stage: TRAINING
2023-01-05 15:16:27,099 INFO:     Val loss before train {'Reaction outcome loss': 0.9947389046351115, 'Total loss': 0.9947389046351115}
2023-01-05 15:16:27,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:27,099 INFO:     Epoch: 0
2023-01-05 15:16:29,245 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8353916645050049, 'Total loss': 0.8353916645050049} | train loss {'Reaction outcome loss': 0.9336602884724683, 'Total loss': 0.9336602884724683}
2023-01-05 15:16:29,245 INFO:     Found new best model at epoch 0
2023-01-05 15:16:29,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:29,247 INFO:     Epoch: 1
2023-01-05 15:16:31,418 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6397859374682109, 'Total loss': 0.6397859374682109} | train loss {'Reaction outcome loss': 0.7400736975540754, 'Total loss': 0.7400736975540754}
2023-01-05 15:16:31,418 INFO:     Found new best model at epoch 1
2023-01-05 15:16:31,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:31,420 INFO:     Epoch: 2
2023-01-05 15:16:33,574 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5482565422852834, 'Total loss': 0.5482565422852834} | train loss {'Reaction outcome loss': 0.5853178474231747, 'Total loss': 0.5853178474231747}
2023-01-05 15:16:33,574 INFO:     Found new best model at epoch 2
2023-01-05 15:16:33,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:33,575 INFO:     Epoch: 3
2023-01-05 15:16:35,773 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5208410580952962, 'Total loss': 0.5208410580952962} | train loss {'Reaction outcome loss': 0.5246180388740254, 'Total loss': 0.5246180388740254}
2023-01-05 15:16:35,773 INFO:     Found new best model at epoch 3
2023-01-05 15:16:35,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:35,774 INFO:     Epoch: 4
2023-01-05 15:16:37,992 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.504065990447998, 'Total loss': 0.504065990447998} | train loss {'Reaction outcome loss': 0.5133982227059478, 'Total loss': 0.5133982227059478}
2023-01-05 15:16:37,992 INFO:     Found new best model at epoch 4
2023-01-05 15:16:37,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:37,993 INFO:     Epoch: 5
2023-01-05 15:16:40,176 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5372892022132874, 'Total loss': 0.5372892022132874} | train loss {'Reaction outcome loss': 0.49823854965853775, 'Total loss': 0.49823854965853775}
2023-01-05 15:16:40,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:40,176 INFO:     Epoch: 6
2023-01-05 15:16:42,361 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4961348344882329, 'Total loss': 0.4961348344882329} | train loss {'Reaction outcome loss': 0.4883076598605524, 'Total loss': 0.4883076598605524}
2023-01-05 15:16:42,362 INFO:     Found new best model at epoch 6
2023-01-05 15:16:42,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:42,363 INFO:     Epoch: 7
2023-01-05 15:16:44,495 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4723856488863627, 'Total loss': 0.4723856488863627} | train loss {'Reaction outcome loss': 0.48631985232718156, 'Total loss': 0.48631985232718156}
2023-01-05 15:16:44,495 INFO:     Found new best model at epoch 7
2023-01-05 15:16:44,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:44,496 INFO:     Epoch: 8
2023-01-05 15:16:46,692 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4501219968001048, 'Total loss': 0.4501219968001048} | train loss {'Reaction outcome loss': 0.47583250106994857, 'Total loss': 0.47583250106994857}
2023-01-05 15:16:46,692 INFO:     Found new best model at epoch 8
2023-01-05 15:16:46,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:46,693 INFO:     Epoch: 9
2023-01-05 15:16:48,891 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5054947276910146, 'Total loss': 0.5054947276910146} | train loss {'Reaction outcome loss': 0.47204327814630653, 'Total loss': 0.47204327814630653}
2023-01-05 15:16:48,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:48,892 INFO:     Epoch: 10
2023-01-05 15:16:51,080 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4650721440712611, 'Total loss': 0.4650721440712611} | train loss {'Reaction outcome loss': 0.4654836887056647, 'Total loss': 0.4654836887056647}
2023-01-05 15:16:51,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:51,080 INFO:     Epoch: 11
2023-01-05 15:16:53,254 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47216433584690093, 'Total loss': 0.47216433584690093} | train loss {'Reaction outcome loss': 0.4619470621704625, 'Total loss': 0.4619470621704625}
2023-01-05 15:16:53,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:53,254 INFO:     Epoch: 12
2023-01-05 15:16:55,414 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5083181907733282, 'Total loss': 0.5083181907733282} | train loss {'Reaction outcome loss': 0.45563869167536175, 'Total loss': 0.45563869167536175}
2023-01-05 15:16:55,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:55,414 INFO:     Epoch: 13
2023-01-05 15:16:57,581 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4575629264116287, 'Total loss': 0.4575629264116287} | train loss {'Reaction outcome loss': 0.45095549061195084, 'Total loss': 0.45095549061195084}
2023-01-05 15:16:57,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:57,581 INFO:     Epoch: 14
2023-01-05 15:16:59,749 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4650646646817525, 'Total loss': 0.4650646646817525} | train loss {'Reaction outcome loss': 0.44654564395385526, 'Total loss': 0.44654564395385526}
2023-01-05 15:16:59,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:16:59,749 INFO:     Epoch: 15
2023-01-05 15:17:01,910 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48087220191955565, 'Total loss': 0.48087220191955565} | train loss {'Reaction outcome loss': 0.4405023706841555, 'Total loss': 0.4405023706841555}
2023-01-05 15:17:01,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:01,911 INFO:     Epoch: 16
2023-01-05 15:17:04,055 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43107407887776694, 'Total loss': 0.43107407887776694} | train loss {'Reaction outcome loss': 0.44258342263715794, 'Total loss': 0.44258342263715794}
2023-01-05 15:17:04,055 INFO:     Found new best model at epoch 16
2023-01-05 15:17:04,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:04,056 INFO:     Epoch: 17
2023-01-05 15:17:06,218 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46204357743263247, 'Total loss': 0.46204357743263247} | train loss {'Reaction outcome loss': 0.4339034235111643, 'Total loss': 0.4339034235111643}
2023-01-05 15:17:06,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:06,218 INFO:     Epoch: 18
2023-01-05 15:17:08,378 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4906254808108012, 'Total loss': 0.4906254808108012} | train loss {'Reaction outcome loss': 0.4275224732524221, 'Total loss': 0.4275224732524221}
2023-01-05 15:17:08,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:08,379 INFO:     Epoch: 19
2023-01-05 15:17:10,577 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4551469475030899, 'Total loss': 0.4551469475030899} | train loss {'Reaction outcome loss': 0.4300252037788556, 'Total loss': 0.4300252037788556}
2023-01-05 15:17:10,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:10,578 INFO:     Epoch: 20
2023-01-05 15:17:12,729 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43986778358618417, 'Total loss': 0.43986778358618417} | train loss {'Reaction outcome loss': 0.4227708939610836, 'Total loss': 0.4227708939610836}
2023-01-05 15:17:12,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:12,731 INFO:     Epoch: 21
2023-01-05 15:17:14,889 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4465681364138921, 'Total loss': 0.4465681364138921} | train loss {'Reaction outcome loss': 0.41581084786339356, 'Total loss': 0.41581084786339356}
2023-01-05 15:17:14,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:14,889 INFO:     Epoch: 22
2023-01-05 15:17:17,049 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4451228857040405, 'Total loss': 0.4451228857040405} | train loss {'Reaction outcome loss': 0.40978212183886054, 'Total loss': 0.40978212183886054}
2023-01-05 15:17:17,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:17,049 INFO:     Epoch: 23
2023-01-05 15:17:19,197 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42517462372779846, 'Total loss': 0.42517462372779846} | train loss {'Reaction outcome loss': 0.41054983030910525, 'Total loss': 0.41054983030910525}
2023-01-05 15:17:19,198 INFO:     Found new best model at epoch 23
2023-01-05 15:17:19,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:19,199 INFO:     Epoch: 24
2023-01-05 15:17:21,348 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4819010655085246, 'Total loss': 0.4819010655085246} | train loss {'Reaction outcome loss': 0.40698347501591225, 'Total loss': 0.40698347501591225}
2023-01-05 15:17:21,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:21,348 INFO:     Epoch: 25
2023-01-05 15:17:23,489 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42905313869317374, 'Total loss': 0.42905313869317374} | train loss {'Reaction outcome loss': 0.4093259153652277, 'Total loss': 0.4093259153652277}
2023-01-05 15:17:23,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:23,489 INFO:     Epoch: 26
2023-01-05 15:17:25,630 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4408920109272003, 'Total loss': 0.4408920109272003} | train loss {'Reaction outcome loss': 0.3998521764355876, 'Total loss': 0.3998521764355876}
2023-01-05 15:17:25,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:25,630 INFO:     Epoch: 27
2023-01-05 15:17:27,817 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4249211460351944, 'Total loss': 0.4249211460351944} | train loss {'Reaction outcome loss': 0.3995015601819173, 'Total loss': 0.3995015601819173}
2023-01-05 15:17:27,817 INFO:     Found new best model at epoch 27
2023-01-05 15:17:27,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:27,818 INFO:     Epoch: 28
2023-01-05 15:17:30,008 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4283020387093226, 'Total loss': 0.4283020387093226} | train loss {'Reaction outcome loss': 0.3942533412188399, 'Total loss': 0.3942533412188399}
2023-01-05 15:17:30,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:30,008 INFO:     Epoch: 29
2023-01-05 15:17:32,148 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4298234224319458, 'Total loss': 0.4298234224319458} | train loss {'Reaction outcome loss': 0.39182049036026, 'Total loss': 0.39182049036026}
2023-01-05 15:17:32,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:32,149 INFO:     Epoch: 30
2023-01-05 15:17:34,309 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4600167055924734, 'Total loss': 0.4600167055924734} | train loss {'Reaction outcome loss': 0.3890130755757167, 'Total loss': 0.3890130755757167}
2023-01-05 15:17:34,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:34,309 INFO:     Epoch: 31
2023-01-05 15:17:36,469 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4085112164417903, 'Total loss': 0.4085112164417903} | train loss {'Reaction outcome loss': 0.3859201847484826, 'Total loss': 0.3859201847484826}
2023-01-05 15:17:36,469 INFO:     Found new best model at epoch 31
2023-01-05 15:17:36,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:36,471 INFO:     Epoch: 32
2023-01-05 15:17:38,613 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4509544998407364, 'Total loss': 0.4509544998407364} | train loss {'Reaction outcome loss': 0.37946641657649394, 'Total loss': 0.37946641657649394}
2023-01-05 15:17:38,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:38,613 INFO:     Epoch: 33
2023-01-05 15:17:40,767 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4465351502100627, 'Total loss': 0.4465351502100627} | train loss {'Reaction outcome loss': 0.37678973142743544, 'Total loss': 0.37678973142743544}
2023-01-05 15:17:40,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:40,767 INFO:     Epoch: 34
2023-01-05 15:17:42,913 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42735083897908527, 'Total loss': 0.42735083897908527} | train loss {'Reaction outcome loss': 0.37707782609368057, 'Total loss': 0.37707782609368057}
2023-01-05 15:17:42,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:42,914 INFO:     Epoch: 35
2023-01-05 15:17:45,065 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41919779777526855, 'Total loss': 0.41919779777526855} | train loss {'Reaction outcome loss': 0.36965858968586696, 'Total loss': 0.36965858968586696}
2023-01-05 15:17:45,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:45,065 INFO:     Epoch: 36
2023-01-05 15:17:47,224 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39649546444416045, 'Total loss': 0.39649546444416045} | train loss {'Reaction outcome loss': 0.3631710535191026, 'Total loss': 0.3631710535191026}
2023-01-05 15:17:47,224 INFO:     Found new best model at epoch 36
2023-01-05 15:17:47,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:47,225 INFO:     Epoch: 37
2023-01-05 15:17:49,380 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4393933773040771, 'Total loss': 0.4393933773040771} | train loss {'Reaction outcome loss': 0.3638054431829642, 'Total loss': 0.3638054431829642}
2023-01-05 15:17:49,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:49,381 INFO:     Epoch: 38
2023-01-05 15:17:51,532 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3946733236312866, 'Total loss': 0.3946733236312866} | train loss {'Reaction outcome loss': 0.36138206591244637, 'Total loss': 0.36138206591244637}
2023-01-05 15:17:51,532 INFO:     Found new best model at epoch 38
2023-01-05 15:17:51,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:51,533 INFO:     Epoch: 39
2023-01-05 15:17:53,658 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41599540611108143, 'Total loss': 0.41599540611108143} | train loss {'Reaction outcome loss': 0.3613188960303684, 'Total loss': 0.3613188960303684}
2023-01-05 15:17:53,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:53,658 INFO:     Epoch: 40
2023-01-05 15:17:55,791 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4440964718659719, 'Total loss': 0.4440964718659719} | train loss {'Reaction outcome loss': 0.3558588846442071, 'Total loss': 0.3558588846442071}
2023-01-05 15:17:55,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:55,791 INFO:     Epoch: 41
2023-01-05 15:17:57,983 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40077266097068787, 'Total loss': 0.40077266097068787} | train loss {'Reaction outcome loss': 0.35187652498645045, 'Total loss': 0.35187652498645045}
2023-01-05 15:17:57,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:17:57,984 INFO:     Epoch: 42
2023-01-05 15:18:00,138 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39412144720554354, 'Total loss': 0.39412144720554354} | train loss {'Reaction outcome loss': 0.350004202030626, 'Total loss': 0.350004202030626}
2023-01-05 15:18:00,138 INFO:     Found new best model at epoch 42
2023-01-05 15:18:00,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:00,139 INFO:     Epoch: 43
2023-01-05 15:18:02,299 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4661874671777089, 'Total loss': 0.4661874671777089} | train loss {'Reaction outcome loss': 0.3525169867524601, 'Total loss': 0.3525169867524601}
2023-01-05 15:18:02,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:02,300 INFO:     Epoch: 44
2023-01-05 15:18:04,468 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43836725254853565, 'Total loss': 0.43836725254853565} | train loss {'Reaction outcome loss': 0.3452514867678231, 'Total loss': 0.3452514867678231}
2023-01-05 15:18:04,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:04,468 INFO:     Epoch: 45
2023-01-05 15:18:06,611 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3977235188086828, 'Total loss': 0.3977235188086828} | train loss {'Reaction outcome loss': 0.34132016184218633, 'Total loss': 0.34132016184218633}
2023-01-05 15:18:06,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:06,612 INFO:     Epoch: 46
2023-01-05 15:18:08,773 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41177041629950206, 'Total loss': 0.41177041629950206} | train loss {'Reaction outcome loss': 0.3354730627193563, 'Total loss': 0.3354730627193563}
2023-01-05 15:18:08,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:08,773 INFO:     Epoch: 47
2023-01-05 15:18:10,906 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40816501478354134, 'Total loss': 0.40816501478354134} | train loss {'Reaction outcome loss': 0.334567907269681, 'Total loss': 0.334567907269681}
2023-01-05 15:18:10,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:10,906 INFO:     Epoch: 48
2023-01-05 15:18:13,074 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41268206561605136, 'Total loss': 0.41268206561605136} | train loss {'Reaction outcome loss': 0.333693089293121, 'Total loss': 0.333693089293121}
2023-01-05 15:18:13,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:13,074 INFO:     Epoch: 49
2023-01-05 15:18:15,240 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3690735429525375, 'Total loss': 0.3690735429525375} | train loss {'Reaction outcome loss': 0.3285532961414609, 'Total loss': 0.3285532961414609}
2023-01-05 15:18:15,241 INFO:     Found new best model at epoch 49
2023-01-05 15:18:15,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:15,242 INFO:     Epoch: 50
2023-01-05 15:18:17,384 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43165019154548645, 'Total loss': 0.43165019154548645} | train loss {'Reaction outcome loss': 0.3285386841542454, 'Total loss': 0.3285386841542454}
2023-01-05 15:18:17,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:17,385 INFO:     Epoch: 51
2023-01-05 15:18:19,549 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3992695142825445, 'Total loss': 0.3992695142825445} | train loss {'Reaction outcome loss': 0.33211819654068364, 'Total loss': 0.33211819654068364}
2023-01-05 15:18:19,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:19,550 INFO:     Epoch: 52
2023-01-05 15:18:21,701 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36652401884396874, 'Total loss': 0.36652401884396874} | train loss {'Reaction outcome loss': 0.33025027834390047, 'Total loss': 0.33025027834390047}
2023-01-05 15:18:21,701 INFO:     Found new best model at epoch 52
2023-01-05 15:18:21,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:21,702 INFO:     Epoch: 53
2023-01-05 15:18:23,853 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40895335574944813, 'Total loss': 0.40895335574944813} | train loss {'Reaction outcome loss': 0.3209541769637743, 'Total loss': 0.3209541769637743}
2023-01-05 15:18:23,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:23,854 INFO:     Epoch: 54
2023-01-05 15:18:26,012 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4419353445370992, 'Total loss': 0.4419353445370992} | train loss {'Reaction outcome loss': 0.3186983155752347, 'Total loss': 0.3186983155752347}
2023-01-05 15:18:26,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:26,012 INFO:     Epoch: 55
2023-01-05 15:18:28,171 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40889943738778434, 'Total loss': 0.40889943738778434} | train loss {'Reaction outcome loss': 0.31540328948775354, 'Total loss': 0.31540328948775354}
2023-01-05 15:18:28,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:28,172 INFO:     Epoch: 56
2023-01-05 15:18:30,312 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3865556299686432, 'Total loss': 0.3865556299686432} | train loss {'Reaction outcome loss': 0.31194770558054696, 'Total loss': 0.31194770558054696}
2023-01-05 15:18:30,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:30,312 INFO:     Epoch: 57
2023-01-05 15:18:32,466 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3619834472735723, 'Total loss': 0.3619834472735723} | train loss {'Reaction outcome loss': 0.3159980937327504, 'Total loss': 0.3159980937327504}
2023-01-05 15:18:32,467 INFO:     Found new best model at epoch 57
2023-01-05 15:18:32,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:32,468 INFO:     Epoch: 58
2023-01-05 15:18:34,631 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3986676762501399, 'Total loss': 0.3986676762501399} | train loss {'Reaction outcome loss': 0.3175342673644262, 'Total loss': 0.3175342673644262}
2023-01-05 15:18:34,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:34,631 INFO:     Epoch: 59
2023-01-05 15:18:36,803 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40524426102638245, 'Total loss': 0.40524426102638245} | train loss {'Reaction outcome loss': 0.3095930359168281, 'Total loss': 0.3095930359168281}
2023-01-05 15:18:36,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:36,803 INFO:     Epoch: 60
2023-01-05 15:18:38,961 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.389945109685262, 'Total loss': 0.389945109685262} | train loss {'Reaction outcome loss': 0.3137944347094005, 'Total loss': 0.3137944347094005}
2023-01-05 15:18:38,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:38,962 INFO:     Epoch: 61
2023-01-05 15:18:41,120 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4024069497982661, 'Total loss': 0.4024069497982661} | train loss {'Reaction outcome loss': 0.3050758105295875, 'Total loss': 0.3050758105295875}
2023-01-05 15:18:41,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:41,120 INFO:     Epoch: 62
2023-01-05 15:18:43,289 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41806467100977895, 'Total loss': 0.41806467100977895} | train loss {'Reaction outcome loss': 0.3068606127524204, 'Total loss': 0.3068606127524204}
2023-01-05 15:18:43,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:43,290 INFO:     Epoch: 63
2023-01-05 15:18:45,452 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40880351066589354, 'Total loss': 0.40880351066589354} | train loss {'Reaction outcome loss': 0.30113292802864894, 'Total loss': 0.30113292802864894}
2023-01-05 15:18:45,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:45,452 INFO:     Epoch: 64
2023-01-05 15:18:47,605 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3555367633700371, 'Total loss': 0.3555367633700371} | train loss {'Reaction outcome loss': 0.31154086493251554, 'Total loss': 0.31154086493251554}
2023-01-05 15:18:47,605 INFO:     Found new best model at epoch 64
2023-01-05 15:18:47,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:47,606 INFO:     Epoch: 65
2023-01-05 15:18:49,718 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41265293061733244, 'Total loss': 0.41265293061733244} | train loss {'Reaction outcome loss': 0.30076623168716793, 'Total loss': 0.30076623168716793}
2023-01-05 15:18:49,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:49,719 INFO:     Epoch: 66
2023-01-05 15:18:51,714 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43657037715117136, 'Total loss': 0.43657037715117136} | train loss {'Reaction outcome loss': 0.3008609133291761, 'Total loss': 0.3008609133291761}
2023-01-05 15:18:51,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:51,714 INFO:     Epoch: 67
2023-01-05 15:18:53,876 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40932934284210204, 'Total loss': 0.40932934284210204} | train loss {'Reaction outcome loss': 0.29655867227309446, 'Total loss': 0.29655867227309446}
2023-01-05 15:18:53,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:53,877 INFO:     Epoch: 68
2023-01-05 15:18:56,030 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38809388180573784, 'Total loss': 0.38809388180573784} | train loss {'Reaction outcome loss': 0.2931067073979963, 'Total loss': 0.2931067073979963}
2023-01-05 15:18:56,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:56,030 INFO:     Epoch: 69
2023-01-05 15:18:58,182 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4183092157046, 'Total loss': 0.4183092157046} | train loss {'Reaction outcome loss': 0.2939942726791443, 'Total loss': 0.2939942726791443}
2023-01-05 15:18:58,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:18:58,182 INFO:     Epoch: 70
2023-01-05 15:19:00,328 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4260836203893026, 'Total loss': 0.4260836203893026} | train loss {'Reaction outcome loss': 0.29334733047478895, 'Total loss': 0.29334733047478895}
2023-01-05 15:19:00,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:00,328 INFO:     Epoch: 71
2023-01-05 15:19:02,491 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4110511302947998, 'Total loss': 0.4110511302947998} | train loss {'Reaction outcome loss': 0.28977531152995917, 'Total loss': 0.28977531152995917}
2023-01-05 15:19:02,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:02,491 INFO:     Epoch: 72
2023-01-05 15:19:04,633 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3866704617937406, 'Total loss': 0.3866704617937406} | train loss {'Reaction outcome loss': 0.28989429746347645, 'Total loss': 0.28989429746347645}
2023-01-05 15:19:04,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:04,633 INFO:     Epoch: 73
2023-01-05 15:19:06,792 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38705820540587105, 'Total loss': 0.38705820540587105} | train loss {'Reaction outcome loss': 0.2881670981201777, 'Total loss': 0.2881670981201777}
2023-01-05 15:19:06,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:06,792 INFO:     Epoch: 74
2023-01-05 15:19:08,963 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45043765803178154, 'Total loss': 0.45043765803178154} | train loss {'Reaction outcome loss': 0.2837483624151037, 'Total loss': 0.2837483624151037}
2023-01-05 15:19:08,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:08,964 INFO:     Epoch: 75
2023-01-05 15:19:11,140 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.35974193265040716, 'Total loss': 0.35974193265040716} | train loss {'Reaction outcome loss': 0.28853997107366575, 'Total loss': 0.28853997107366575}
2023-01-05 15:19:11,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:11,140 INFO:     Epoch: 76
2023-01-05 15:19:13,302 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4296114921569824, 'Total loss': 0.4296114921569824} | train loss {'Reaction outcome loss': 0.283870827083876, 'Total loss': 0.283870827083876}
2023-01-05 15:19:13,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:13,302 INFO:     Epoch: 77
2023-01-05 15:19:15,451 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40839868585268657, 'Total loss': 0.40839868585268657} | train loss {'Reaction outcome loss': 0.2849407027801667, 'Total loss': 0.2849407027801667}
2023-01-05 15:19:15,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:15,452 INFO:     Epoch: 78
2023-01-05 15:19:17,634 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38698170681794486, 'Total loss': 0.38698170681794486} | train loss {'Reaction outcome loss': 0.2844954433343256, 'Total loss': 0.2844954433343256}
2023-01-05 15:19:17,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:17,634 INFO:     Epoch: 79
2023-01-05 15:19:19,804 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4511838515599569, 'Total loss': 0.4511838515599569} | train loss {'Reaction outcome loss': 0.2754468628834086, 'Total loss': 0.2754468628834086}
2023-01-05 15:19:19,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:19,804 INFO:     Epoch: 80
2023-01-05 15:19:21,960 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4003905216852824, 'Total loss': 0.4003905216852824} | train loss {'Reaction outcome loss': 0.28085361263086006, 'Total loss': 0.28085361263086006}
2023-01-05 15:19:21,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:21,961 INFO:     Epoch: 81
2023-01-05 15:19:24,081 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.36127574096123377, 'Total loss': 0.36127574096123377} | train loss {'Reaction outcome loss': 0.27081130632612893, 'Total loss': 0.27081130632612893}
2023-01-05 15:19:24,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:24,081 INFO:     Epoch: 82
2023-01-05 15:19:26,230 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37750424245993297, 'Total loss': 0.37750424245993297} | train loss {'Reaction outcome loss': 0.26876863425039427, 'Total loss': 0.26876863425039427}
2023-01-05 15:19:26,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:26,231 INFO:     Epoch: 83
2023-01-05 15:19:28,383 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3805544252196948, 'Total loss': 0.3805544252196948} | train loss {'Reaction outcome loss': 0.2694680153153541, 'Total loss': 0.2694680153153541}
2023-01-05 15:19:28,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:28,383 INFO:     Epoch: 84
2023-01-05 15:19:30,546 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3823764890432358, 'Total loss': 0.3823764890432358} | train loss {'Reaction outcome loss': 0.26838235803862986, 'Total loss': 0.26838235803862986}
2023-01-05 15:19:30,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:30,546 INFO:     Epoch: 85
2023-01-05 15:19:32,713 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.36576503117879233, 'Total loss': 0.36576503117879233} | train loss {'Reaction outcome loss': 0.27195544077574346, 'Total loss': 0.27195544077574346}
2023-01-05 15:19:32,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:32,714 INFO:     Epoch: 86
2023-01-05 15:19:34,885 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38923529982566835, 'Total loss': 0.38923529982566835} | train loss {'Reaction outcome loss': 0.2614032416890244, 'Total loss': 0.2614032416890244}
2023-01-05 15:19:34,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:34,886 INFO:     Epoch: 87
2023-01-05 15:19:37,046 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3586415077249209, 'Total loss': 0.3586415077249209} | train loss {'Reaction outcome loss': 0.27411871696637424, 'Total loss': 0.27411871696637424}
2023-01-05 15:19:37,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:37,046 INFO:     Epoch: 88
2023-01-05 15:19:39,204 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3779716691623131, 'Total loss': 0.3779716691623131} | train loss {'Reaction outcome loss': 0.2666504817480215, 'Total loss': 0.2666504817480215}
2023-01-05 15:19:39,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:39,204 INFO:     Epoch: 89
2023-01-05 15:19:41,373 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4082940806945165, 'Total loss': 0.4082940806945165} | train loss {'Reaction outcome loss': 0.2619592343534373, 'Total loss': 0.2619592343534373}
2023-01-05 15:19:41,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:41,373 INFO:     Epoch: 90
2023-01-05 15:19:43,529 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4462129851182302, 'Total loss': 0.4462129851182302} | train loss {'Reaction outcome loss': 0.2661962882524847, 'Total loss': 0.2661962882524847}
2023-01-05 15:19:43,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:43,529 INFO:     Epoch: 91
2023-01-05 15:19:45,705 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3763227800528208, 'Total loss': 0.3763227800528208} | train loss {'Reaction outcome loss': 0.26214910917898593, 'Total loss': 0.26214910917898593}
2023-01-05 15:19:45,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:45,706 INFO:     Epoch: 92
2023-01-05 15:19:47,861 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37735756983359653, 'Total loss': 0.37735756983359653} | train loss {'Reaction outcome loss': 0.25516074902583114, 'Total loss': 0.25516074902583114}
2023-01-05 15:19:47,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:47,861 INFO:     Epoch: 93
2023-01-05 15:19:50,000 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38207140068213147, 'Total loss': 0.38207140068213147} | train loss {'Reaction outcome loss': 0.2581412556147479, 'Total loss': 0.2581412556147479}
2023-01-05 15:19:50,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:50,001 INFO:     Epoch: 94
2023-01-05 15:19:52,157 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40458720127741493, 'Total loss': 0.40458720127741493} | train loss {'Reaction outcome loss': 0.26002415697954406, 'Total loss': 0.26002415697954406}
2023-01-05 15:19:52,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:52,157 INFO:     Epoch: 95
2023-01-05 15:19:54,322 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38322217104335626, 'Total loss': 0.38322217104335626} | train loss {'Reaction outcome loss': 0.2533218457232421, 'Total loss': 0.2533218457232421}
2023-01-05 15:19:54,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:54,322 INFO:     Epoch: 96
2023-01-05 15:19:56,478 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37905966937541963, 'Total loss': 0.37905966937541963} | train loss {'Reaction outcome loss': 0.2633238839731965, 'Total loss': 0.2633238839731965}
2023-01-05 15:19:56,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:56,479 INFO:     Epoch: 97
2023-01-05 15:19:58,650 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3562474956115087, 'Total loss': 0.3562474956115087} | train loss {'Reaction outcome loss': 0.25621337949933776, 'Total loss': 0.25621337949933776}
2023-01-05 15:19:58,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:19:58,650 INFO:     Epoch: 98
2023-01-05 15:20:00,799 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4147716929515203, 'Total loss': 0.4147716929515203} | train loss {'Reaction outcome loss': 0.24594820345943585, 'Total loss': 0.24594820345943585}
2023-01-05 15:20:00,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:00,799 INFO:     Epoch: 99
2023-01-05 15:20:02,961 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39176958600680034, 'Total loss': 0.39176958600680034} | train loss {'Reaction outcome loss': 0.25385589540569575, 'Total loss': 0.25385589540569575}
2023-01-05 15:20:02,962 INFO:     Best model found after epoch 65 of 100.
2023-01-05 15:20:02,962 INFO:   Done with stage: TRAINING
2023-01-05 15:20:02,962 INFO:   Starting stage: EVALUATION
2023-01-05 15:20:03,089 INFO:   Done with stage: EVALUATION
2023-01-05 15:20:03,089 INFO:   Leaving out SEQ value Fold_8
2023-01-05 15:20:03,102 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 15:20:03,102 INFO:   Starting stage: FEATURE SCALING
2023-01-05 15:20:03,751 INFO:   Done with stage: FEATURE SCALING
2023-01-05 15:20:03,751 INFO:   Starting stage: SCALING TARGETS
2023-01-05 15:20:03,820 INFO:   Done with stage: SCALING TARGETS
2023-01-05 15:20:03,820 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:20:03,820 INFO:     No hyperparam tuning for this model
2023-01-05 15:20:03,820 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:20:03,820 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 15:20:03,821 INFO:     None feature selector for col prot
2023-01-05 15:20:03,821 INFO:     None feature selector for col prot
2023-01-05 15:20:03,821 INFO:     None feature selector for col prot
2023-01-05 15:20:03,822 INFO:     None feature selector for col chem
2023-01-05 15:20:03,822 INFO:     None feature selector for col chem
2023-01-05 15:20:03,822 INFO:     None feature selector for col chem
2023-01-05 15:20:03,822 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 15:20:03,822 INFO:   Starting stage: BUILD MODEL
2023-01-05 15:20:03,823 INFO:     Number of params in model 72901
2023-01-05 15:20:03,826 INFO:   Done with stage: BUILD MODEL
2023-01-05 15:20:03,827 INFO:   Starting stage: TRAINING
2023-01-05 15:20:03,883 INFO:     Val loss before train {'Reaction outcome loss': 1.1042806148529052, 'Total loss': 1.1042806148529052}
2023-01-05 15:20:03,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:03,883 INFO:     Epoch: 0
2023-01-05 15:20:06,029 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8835182507832845, 'Total loss': 0.8835182507832845} | train loss {'Reaction outcome loss': 0.9026217198917184, 'Total loss': 0.9026217198917184}
2023-01-05 15:20:06,029 INFO:     Found new best model at epoch 0
2023-01-05 15:20:06,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:06,030 INFO:     Epoch: 1
2023-01-05 15:20:08,167 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6491551160812378, 'Total loss': 0.6491551160812378} | train loss {'Reaction outcome loss': 0.7311836836051425, 'Total loss': 0.7311836836051425}
2023-01-05 15:20:08,168 INFO:     Found new best model at epoch 1
2023-01-05 15:20:08,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:08,169 INFO:     Epoch: 2
2023-01-05 15:20:10,319 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5484553813934326, 'Total loss': 0.5484553813934326} | train loss {'Reaction outcome loss': 0.5992293968472792, 'Total loss': 0.5992293968472792}
2023-01-05 15:20:10,319 INFO:     Found new best model at epoch 2
2023-01-05 15:20:10,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:10,320 INFO:     Epoch: 3
2023-01-05 15:20:12,461 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5235718826452891, 'Total loss': 0.5235718826452891} | train loss {'Reaction outcome loss': 0.5531649252752423, 'Total loss': 0.5531649252752423}
2023-01-05 15:20:12,461 INFO:     Found new best model at epoch 3
2023-01-05 15:20:12,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:12,462 INFO:     Epoch: 4
2023-01-05 15:20:14,604 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5064600904782613, 'Total loss': 0.5064600904782613} | train loss {'Reaction outcome loss': 0.5129042305592177, 'Total loss': 0.5129042305592177}
2023-01-05 15:20:14,605 INFO:     Found new best model at epoch 4
2023-01-05 15:20:14,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:14,606 INFO:     Epoch: 5
2023-01-05 15:20:16,758 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5185627559820811, 'Total loss': 0.5185627559820811} | train loss {'Reaction outcome loss': 0.5020521226460519, 'Total loss': 0.5020521226460519}
2023-01-05 15:20:16,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:16,759 INFO:     Epoch: 6
2023-01-05 15:20:18,942 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.510942272345225, 'Total loss': 0.510942272345225} | train loss {'Reaction outcome loss': 0.4900205696096131, 'Total loss': 0.4900205696096131}
2023-01-05 15:20:18,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:18,942 INFO:     Epoch: 7
2023-01-05 15:20:21,150 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.500782502690951, 'Total loss': 0.500782502690951} | train loss {'Reaction outcome loss': 0.48544360448579316, 'Total loss': 0.48544360448579316}
2023-01-05 15:20:21,151 INFO:     Found new best model at epoch 7
2023-01-05 15:20:21,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:21,152 INFO:     Epoch: 8
2023-01-05 15:20:23,349 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4961748421192169, 'Total loss': 0.4961748421192169} | train loss {'Reaction outcome loss': 0.47687236408608547, 'Total loss': 0.47687236408608547}
2023-01-05 15:20:23,349 INFO:     Found new best model at epoch 8
2023-01-05 15:20:23,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:23,351 INFO:     Epoch: 9
2023-01-05 15:20:25,492 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.517960645755132, 'Total loss': 0.517960645755132} | train loss {'Reaction outcome loss': 0.4675534429179211, 'Total loss': 0.4675534429179211}
2023-01-05 15:20:25,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:25,493 INFO:     Epoch: 10
2023-01-05 15:20:27,653 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49148985743522644, 'Total loss': 0.49148985743522644} | train loss {'Reaction outcome loss': 0.46101399223898887, 'Total loss': 0.46101399223898887}
2023-01-05 15:20:27,654 INFO:     Found new best model at epoch 10
2023-01-05 15:20:27,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:27,655 INFO:     Epoch: 11
2023-01-05 15:20:29,810 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4672063857316971, 'Total loss': 0.4672063857316971} | train loss {'Reaction outcome loss': 0.45705653983168304, 'Total loss': 0.45705653983168304}
2023-01-05 15:20:29,810 INFO:     Found new best model at epoch 11
2023-01-05 15:20:29,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:29,811 INFO:     Epoch: 12
2023-01-05 15:20:31,966 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4741831700007121, 'Total loss': 0.4741831700007121} | train loss {'Reaction outcome loss': 0.4558875818739329, 'Total loss': 0.4558875818739329}
2023-01-05 15:20:31,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:31,966 INFO:     Epoch: 13
2023-01-05 15:20:34,108 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49196179310480753, 'Total loss': 0.49196179310480753} | train loss {'Reaction outcome loss': 0.457440257774315, 'Total loss': 0.457440257774315}
2023-01-05 15:20:34,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:34,109 INFO:     Epoch: 14
2023-01-05 15:20:36,248 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4694676101207733, 'Total loss': 0.4694676101207733} | train loss {'Reaction outcome loss': 0.45273897742879565, 'Total loss': 0.45273897742879565}
2023-01-05 15:20:36,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:36,248 INFO:     Epoch: 15
2023-01-05 15:20:38,390 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45740323265393573, 'Total loss': 0.45740323265393573} | train loss {'Reaction outcome loss': 0.45334197489031847, 'Total loss': 0.45334197489031847}
2023-01-05 15:20:38,390 INFO:     Found new best model at epoch 15
2023-01-05 15:20:38,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:38,391 INFO:     Epoch: 16
2023-01-05 15:20:40,531 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5001258850097656, 'Total loss': 0.5001258850097656} | train loss {'Reaction outcome loss': 0.46098887830959173, 'Total loss': 0.46098887830959173}
2023-01-05 15:20:40,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:40,532 INFO:     Epoch: 17
2023-01-05 15:20:42,676 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45582669774691265, 'Total loss': 0.45582669774691265} | train loss {'Reaction outcome loss': 0.4333066855611253, 'Total loss': 0.4333066855611253}
2023-01-05 15:20:42,676 INFO:     Found new best model at epoch 17
2023-01-05 15:20:42,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:42,678 INFO:     Epoch: 18
2023-01-05 15:20:44,818 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4780680467685064, 'Total loss': 0.4780680467685064} | train loss {'Reaction outcome loss': 0.42529762583865743, 'Total loss': 0.42529762583865743}
2023-01-05 15:20:44,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:44,819 INFO:     Epoch: 19
2023-01-05 15:20:46,946 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49029428164164224, 'Total loss': 0.49029428164164224} | train loss {'Reaction outcome loss': 0.42189077808575676, 'Total loss': 0.42189077808575676}
2023-01-05 15:20:46,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:46,947 INFO:     Epoch: 20
2023-01-05 15:20:49,107 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4650284389654795, 'Total loss': 0.4650284389654795} | train loss {'Reaction outcome loss': 0.4127492005717468, 'Total loss': 0.4127492005717468}
2023-01-05 15:20:49,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:49,108 INFO:     Epoch: 21
2023-01-05 15:20:51,258 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44886000057061515, 'Total loss': 0.44886000057061515} | train loss {'Reaction outcome loss': 0.41182413988097827, 'Total loss': 0.41182413988097827}
2023-01-05 15:20:51,259 INFO:     Found new best model at epoch 21
2023-01-05 15:20:51,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:51,260 INFO:     Epoch: 22
2023-01-05 15:20:53,437 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46428526043891905, 'Total loss': 0.46428526043891905} | train loss {'Reaction outcome loss': 0.4109737323732048, 'Total loss': 0.4109737323732048}
2023-01-05 15:20:53,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:53,438 INFO:     Epoch: 23
2023-01-05 15:20:55,614 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4349405159552892, 'Total loss': 0.4349405159552892} | train loss {'Reaction outcome loss': 0.4194580429652031, 'Total loss': 0.4194580429652031}
2023-01-05 15:20:55,614 INFO:     Found new best model at epoch 23
2023-01-05 15:20:55,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:55,615 INFO:     Epoch: 24
2023-01-05 15:20:57,780 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45754748980204263, 'Total loss': 0.45754748980204263} | train loss {'Reaction outcome loss': 0.41221008505132317, 'Total loss': 0.41221008505132317}
2023-01-05 15:20:57,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:57,781 INFO:     Epoch: 25
2023-01-05 15:20:59,967 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4633354643980662, 'Total loss': 0.4633354643980662} | train loss {'Reaction outcome loss': 0.40544478400893835, 'Total loss': 0.40544478400893835}
2023-01-05 15:20:59,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:20:59,967 INFO:     Epoch: 26
2023-01-05 15:21:02,142 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4616016397873561, 'Total loss': 0.4616016397873561} | train loss {'Reaction outcome loss': 0.425974700901492, 'Total loss': 0.425974700901492}
2023-01-05 15:21:02,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:02,142 INFO:     Epoch: 27
2023-01-05 15:21:04,317 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4559237152338028, 'Total loss': 0.4559237152338028} | train loss {'Reaction outcome loss': 0.39251348769501393, 'Total loss': 0.39251348769501393}
2023-01-05 15:21:04,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:04,318 INFO:     Epoch: 28
2023-01-05 15:21:06,484 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.486573056379954, 'Total loss': 0.486573056379954} | train loss {'Reaction outcome loss': 0.3896381646877803, 'Total loss': 0.3896381646877803}
2023-01-05 15:21:06,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:06,484 INFO:     Epoch: 29
2023-01-05 15:21:08,653 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4563156604766846, 'Total loss': 0.4563156604766846} | train loss {'Reaction outcome loss': 0.3883832642889541, 'Total loss': 0.3883832642889541}
2023-01-05 15:21:08,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:08,653 INFO:     Epoch: 30
2023-01-05 15:21:10,808 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4491222788890203, 'Total loss': 0.4491222788890203} | train loss {'Reaction outcome loss': 0.4066089329923894, 'Total loss': 0.4066089329923894}
2023-01-05 15:21:10,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:10,808 INFO:     Epoch: 31
2023-01-05 15:21:12,942 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4455757260322571, 'Total loss': 0.4455757260322571} | train loss {'Reaction outcome loss': 0.3800152223557234, 'Total loss': 0.3800152223557234}
2023-01-05 15:21:12,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:12,942 INFO:     Epoch: 32
2023-01-05 15:21:15,084 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46672843098640443, 'Total loss': 0.46672843098640443} | train loss {'Reaction outcome loss': 0.37733434071170463, 'Total loss': 0.37733434071170463}
2023-01-05 15:21:15,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:15,084 INFO:     Epoch: 33
2023-01-05 15:21:17,226 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4439767897129059, 'Total loss': 0.4439767897129059} | train loss {'Reaction outcome loss': 0.3875464285197465, 'Total loss': 0.3875464285197465}
2023-01-05 15:21:17,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:17,227 INFO:     Epoch: 34
2023-01-05 15:21:19,413 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45675763686498005, 'Total loss': 0.45675763686498005} | train loss {'Reaction outcome loss': 0.38324934511911124, 'Total loss': 0.38324934511911124}
2023-01-05 15:21:19,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:19,414 INFO:     Epoch: 35
2023-01-05 15:21:21,546 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42754870653152466, 'Total loss': 0.42754870653152466} | train loss {'Reaction outcome loss': 0.3714176412820276, 'Total loss': 0.3714176412820276}
2023-01-05 15:21:21,546 INFO:     Found new best model at epoch 35
2023-01-05 15:21:21,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:21,548 INFO:     Epoch: 36
2023-01-05 15:21:23,717 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47475976347923277, 'Total loss': 0.47475976347923277} | train loss {'Reaction outcome loss': 0.3577268518099605, 'Total loss': 0.3577268518099605}
2023-01-05 15:21:23,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:23,717 INFO:     Epoch: 37
2023-01-05 15:21:25,867 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4411274820566177, 'Total loss': 0.4411274820566177} | train loss {'Reaction outcome loss': 0.3613950264407322, 'Total loss': 0.3613950264407322}
2023-01-05 15:21:25,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:25,868 INFO:     Epoch: 38
2023-01-05 15:21:27,989 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4280207504828771, 'Total loss': 0.4280207504828771} | train loss {'Reaction outcome loss': 0.36451075766303076, 'Total loss': 0.36451075766303076}
2023-01-05 15:21:27,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:27,990 INFO:     Epoch: 39
2023-01-05 15:21:30,128 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4323126971721649, 'Total loss': 0.4323126971721649} | train loss {'Reaction outcome loss': 0.3523246762739238, 'Total loss': 0.3523246762739238}
2023-01-05 15:21:30,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:30,128 INFO:     Epoch: 40
2023-01-05 15:21:32,269 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4277455727259318, 'Total loss': 0.4277455727259318} | train loss {'Reaction outcome loss': 0.34504114043143025, 'Total loss': 0.34504114043143025}
2023-01-05 15:21:32,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:32,269 INFO:     Epoch: 41
2023-01-05 15:21:34,400 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45748493274052937, 'Total loss': 0.45748493274052937} | train loss {'Reaction outcome loss': 0.3520632125167311, 'Total loss': 0.3520632125167311}
2023-01-05 15:21:34,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:34,401 INFO:     Epoch: 42
2023-01-05 15:21:36,535 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4382440596818924, 'Total loss': 0.4382440596818924} | train loss {'Reaction outcome loss': 0.34759758051781764, 'Total loss': 0.34759758051781764}
2023-01-05 15:21:36,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:36,536 INFO:     Epoch: 43
2023-01-05 15:21:38,673 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4109654953082403, 'Total loss': 0.4109654953082403} | train loss {'Reaction outcome loss': 0.33965472366295557, 'Total loss': 0.33965472366295557}
2023-01-05 15:21:38,673 INFO:     Found new best model at epoch 43
2023-01-05 15:21:38,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:38,675 INFO:     Epoch: 44
2023-01-05 15:21:40,817 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46497390468915306, 'Total loss': 0.46497390468915306} | train loss {'Reaction outcome loss': 0.33558582796958153, 'Total loss': 0.33558582796958153}
2023-01-05 15:21:40,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:40,818 INFO:     Epoch: 45
2023-01-05 15:21:42,963 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41969598333040875, 'Total loss': 0.41969598333040875} | train loss {'Reaction outcome loss': 0.33642514326619793, 'Total loss': 0.33642514326619793}
2023-01-05 15:21:42,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:42,963 INFO:     Epoch: 46
2023-01-05 15:21:45,123 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4392286310593287, 'Total loss': 0.4392286310593287} | train loss {'Reaction outcome loss': 0.3336543579504866, 'Total loss': 0.3336543579504866}
2023-01-05 15:21:45,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:45,123 INFO:     Epoch: 47
2023-01-05 15:21:47,247 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41252040266990664, 'Total loss': 0.41252040266990664} | train loss {'Reaction outcome loss': 0.3312216349438751, 'Total loss': 0.3312216349438751}
2023-01-05 15:21:47,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:47,247 INFO:     Epoch: 48
2023-01-05 15:21:49,376 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43102513750394184, 'Total loss': 0.43102513750394184} | train loss {'Reaction outcome loss': 0.3270462229982882, 'Total loss': 0.3270462229982882}
2023-01-05 15:21:49,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:49,376 INFO:     Epoch: 49
2023-01-05 15:21:51,540 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39894459446271263, 'Total loss': 0.39894459446271263} | train loss {'Reaction outcome loss': 0.3301665156656215, 'Total loss': 0.3301665156656215}
2023-01-05 15:21:51,540 INFO:     Found new best model at epoch 49
2023-01-05 15:21:51,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:51,541 INFO:     Epoch: 50
2023-01-05 15:21:53,693 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42389929890632627, 'Total loss': 0.42389929890632627} | train loss {'Reaction outcome loss': 0.31665783999968605, 'Total loss': 0.31665783999968605}
2023-01-05 15:21:53,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:53,694 INFO:     Epoch: 51
2023-01-05 15:21:55,833 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45421383877595267, 'Total loss': 0.45421383877595267} | train loss {'Reaction outcome loss': 0.3171220291810839, 'Total loss': 0.3171220291810839}
2023-01-05 15:21:55,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:55,833 INFO:     Epoch: 52
2023-01-05 15:21:57,958 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48489980697631835, 'Total loss': 0.48489980697631835} | train loss {'Reaction outcome loss': 0.3179446138782149, 'Total loss': 0.3179446138782149}
2023-01-05 15:21:57,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:21:57,959 INFO:     Epoch: 53
2023-01-05 15:22:00,099 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4030438303947449, 'Total loss': 0.4030438303947449} | train loss {'Reaction outcome loss': 0.31520722081388713, 'Total loss': 0.31520722081388713}
2023-01-05 15:22:00,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:00,100 INFO:     Epoch: 54
2023-01-05 15:22:02,237 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4054883619149526, 'Total loss': 0.4054883619149526} | train loss {'Reaction outcome loss': 0.30800879522771074, 'Total loss': 0.30800879522771074}
2023-01-05 15:22:02,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:02,238 INFO:     Epoch: 55
2023-01-05 15:22:04,366 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44661107162634534, 'Total loss': 0.44661107162634534} | train loss {'Reaction outcome loss': 0.30850080182647394, 'Total loss': 0.30850080182647394}
2023-01-05 15:22:04,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:04,367 INFO:     Epoch: 56
2023-01-05 15:22:06,517 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4243331710497538, 'Total loss': 0.4243331710497538} | train loss {'Reaction outcome loss': 0.3070182472688232, 'Total loss': 0.3070182472688232}
2023-01-05 15:22:06,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:06,518 INFO:     Epoch: 57
2023-01-05 15:22:08,675 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39631407260894774, 'Total loss': 0.39631407260894774} | train loss {'Reaction outcome loss': 0.30580766831247974, 'Total loss': 0.30580766831247974}
2023-01-05 15:22:08,676 INFO:     Found new best model at epoch 57
2023-01-05 15:22:08,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:08,678 INFO:     Epoch: 58
2023-01-05 15:22:10,831 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42039875090122225, 'Total loss': 0.42039875090122225} | train loss {'Reaction outcome loss': 0.3023182404888929, 'Total loss': 0.3023182404888929}
2023-01-05 15:22:10,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:10,831 INFO:     Epoch: 59
2023-01-05 15:22:12,976 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4438225964705149, 'Total loss': 0.4438225964705149} | train loss {'Reaction outcome loss': 0.3252819087373201, 'Total loss': 0.3252819087373201}
2023-01-05 15:22:12,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:12,976 INFO:     Epoch: 60
2023-01-05 15:22:15,130 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4060249800483386, 'Total loss': 0.4060249800483386} | train loss {'Reaction outcome loss': 0.30143204960378184, 'Total loss': 0.30143204960378184}
2023-01-05 15:22:15,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:15,131 INFO:     Epoch: 61
2023-01-05 15:22:17,298 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40597351317604385, 'Total loss': 0.40597351317604385} | train loss {'Reaction outcome loss': 0.3134753775391247, 'Total loss': 0.3134753775391247}
2023-01-05 15:22:17,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:17,298 INFO:     Epoch: 62
2023-01-05 15:22:19,426 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4236172844966253, 'Total loss': 0.4236172844966253} | train loss {'Reaction outcome loss': 0.304488276583615, 'Total loss': 0.304488276583615}
2023-01-05 15:22:19,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:19,426 INFO:     Epoch: 63
2023-01-05 15:22:21,577 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4088169385989507, 'Total loss': 0.4088169385989507} | train loss {'Reaction outcome loss': 0.29125541630808427, 'Total loss': 0.29125541630808427}
2023-01-05 15:22:21,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:21,577 INFO:     Epoch: 64
2023-01-05 15:22:23,726 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44574886163075766, 'Total loss': 0.44574886163075766} | train loss {'Reaction outcome loss': 0.28787611647967953, 'Total loss': 0.28787611647967953}
2023-01-05 15:22:23,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:23,726 INFO:     Epoch: 65
2023-01-05 15:22:25,894 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4034415990114212, 'Total loss': 0.4034415990114212} | train loss {'Reaction outcome loss': 0.2876022801296439, 'Total loss': 0.2876022801296439}
2023-01-05 15:22:25,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:25,894 INFO:     Epoch: 66
2023-01-05 15:22:28,049 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4418733179569244, 'Total loss': 0.4418733179569244} | train loss {'Reaction outcome loss': 0.28062766243642684, 'Total loss': 0.28062766243642684}
2023-01-05 15:22:28,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:28,050 INFO:     Epoch: 67
2023-01-05 15:22:30,225 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4475924029946327, 'Total loss': 0.4475924029946327} | train loss {'Reaction outcome loss': 0.2927956908312373, 'Total loss': 0.2927956908312373}
2023-01-05 15:22:30,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:30,225 INFO:     Epoch: 68
2023-01-05 15:22:32,367 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38398539771636325, 'Total loss': 0.38398539771636325} | train loss {'Reaction outcome loss': 0.2884420814175889, 'Total loss': 0.2884420814175889}
2023-01-05 15:22:32,367 INFO:     Found new best model at epoch 68
2023-01-05 15:22:32,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:32,368 INFO:     Epoch: 69
2023-01-05 15:22:34,535 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4076327840487162, 'Total loss': 0.4076327840487162} | train loss {'Reaction outcome loss': 0.27418773084916237, 'Total loss': 0.27418773084916237}
2023-01-05 15:22:34,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:34,535 INFO:     Epoch: 70
2023-01-05 15:22:36,685 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4376167188088099, 'Total loss': 0.4376167188088099} | train loss {'Reaction outcome loss': 0.27520180947149, 'Total loss': 0.27520180947149}
2023-01-05 15:22:36,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:36,685 INFO:     Epoch: 71
2023-01-05 15:22:38,848 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38427150348822275, 'Total loss': 0.38427150348822275} | train loss {'Reaction outcome loss': 0.2881561433677089, 'Total loss': 0.2881561433677089}
2023-01-05 15:22:38,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:38,848 INFO:     Epoch: 72
2023-01-05 15:22:41,007 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39340607325236004, 'Total loss': 0.39340607325236004} | train loss {'Reaction outcome loss': 0.288266277218877, 'Total loss': 0.288266277218877}
2023-01-05 15:22:41,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:41,007 INFO:     Epoch: 73
2023-01-05 15:22:43,160 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3747941811879476, 'Total loss': 0.3747941811879476} | train loss {'Reaction outcome loss': 0.27897605191970215, 'Total loss': 0.27897605191970215}
2023-01-05 15:22:43,160 INFO:     Found new best model at epoch 73
2023-01-05 15:22:43,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:43,162 INFO:     Epoch: 74
2023-01-05 15:22:45,334 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3773813103636106, 'Total loss': 0.3773813103636106} | train loss {'Reaction outcome loss': 0.27591469237223215, 'Total loss': 0.27591469237223215}
2023-01-05 15:22:45,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:45,335 INFO:     Epoch: 75
2023-01-05 15:22:47,472 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42613252699375154, 'Total loss': 0.42613252699375154} | train loss {'Reaction outcome loss': 0.27787062679451174, 'Total loss': 0.27787062679451174}
2023-01-05 15:22:47,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:47,472 INFO:     Epoch: 76
2023-01-05 15:22:49,630 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39098018457492195, 'Total loss': 0.39098018457492195} | train loss {'Reaction outcome loss': 0.2703877869431196, 'Total loss': 0.2703877869431196}
2023-01-05 15:22:49,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:49,631 INFO:     Epoch: 77
2023-01-05 15:22:51,782 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49579595029354095, 'Total loss': 0.49579595029354095} | train loss {'Reaction outcome loss': 0.2784810334821974, 'Total loss': 0.2784810334821974}
2023-01-05 15:22:51,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:51,783 INFO:     Epoch: 78
2023-01-05 15:22:53,919 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5876547555128734, 'Total loss': 0.5876547555128734} | train loss {'Reaction outcome loss': 0.4237447508806498, 'Total loss': 0.4237447508806498}
2023-01-05 15:22:53,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:53,919 INFO:     Epoch: 79
2023-01-05 15:22:55,864 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.576456481218338, 'Total loss': 0.576456481218338} | train loss {'Reaction outcome loss': 0.3987293845258545, 'Total loss': 0.3987293845258545}
2023-01-05 15:22:55,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:55,865 INFO:     Epoch: 80
2023-01-05 15:22:58,018 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5407598078250885, 'Total loss': 0.5407598078250885} | train loss {'Reaction outcome loss': 0.4035925769879006, 'Total loss': 0.4035925769879006}
2023-01-05 15:22:58,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:22:58,019 INFO:     Epoch: 81
2023-01-05 15:23:00,173 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5454882760842641, 'Total loss': 0.5454882760842641} | train loss {'Reaction outcome loss': 0.39711018706479395, 'Total loss': 0.39711018706479395}
2023-01-05 15:23:00,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:00,173 INFO:     Epoch: 82
2023-01-05 15:23:02,328 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.520191165804863, 'Total loss': 0.520191165804863} | train loss {'Reaction outcome loss': 0.39058968136964395, 'Total loss': 0.39058968136964395}
2023-01-05 15:23:02,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:02,328 INFO:     Epoch: 83
2023-01-05 15:23:04,477 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5567463179429372, 'Total loss': 0.5567463179429372} | train loss {'Reaction outcome loss': 0.38650763996944687, 'Total loss': 0.38650763996944687}
2023-01-05 15:23:04,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:04,478 INFO:     Epoch: 84
2023-01-05 15:23:06,627 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5209715972344081, 'Total loss': 0.5209715972344081} | train loss {'Reaction outcome loss': 0.3835370728659167, 'Total loss': 0.3835370728659167}
2023-01-05 15:23:06,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:06,627 INFO:     Epoch: 85
2023-01-05 15:23:08,846 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5333278278509775, 'Total loss': 0.5333278278509775} | train loss {'Reaction outcome loss': 0.3785958190775895, 'Total loss': 0.3785958190775895}
2023-01-05 15:23:08,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:08,847 INFO:     Epoch: 86
2023-01-05 15:23:11,059 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5193494737148285, 'Total loss': 0.5193494737148285} | train loss {'Reaction outcome loss': 0.38633685980006494, 'Total loss': 0.38633685980006494}
2023-01-05 15:23:11,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:11,059 INFO:     Epoch: 87
2023-01-05 15:23:13,221 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5646330316861471, 'Total loss': 0.5646330316861471} | train loss {'Reaction outcome loss': 0.3792353966922931, 'Total loss': 0.3792353966922931}
2023-01-05 15:23:13,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:13,221 INFO:     Epoch: 88
2023-01-05 15:23:15,377 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49877725044886273, 'Total loss': 0.49877725044886273} | train loss {'Reaction outcome loss': 0.38042875085080013, 'Total loss': 0.38042875085080013}
2023-01-05 15:23:15,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:15,377 INFO:     Epoch: 89
2023-01-05 15:23:17,540 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5066351572672526, 'Total loss': 0.5066351572672526} | train loss {'Reaction outcome loss': 0.37835513025930245, 'Total loss': 0.37835513025930245}
2023-01-05 15:23:17,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:17,541 INFO:     Epoch: 90
2023-01-05 15:23:19,703 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.535929548740387, 'Total loss': 0.535929548740387} | train loss {'Reaction outcome loss': 0.37648525655432435, 'Total loss': 0.37648525655432435}
2023-01-05 15:23:19,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:19,703 INFO:     Epoch: 91
2023-01-05 15:23:21,852 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4933133125305176, 'Total loss': 0.4933133125305176} | train loss {'Reaction outcome loss': 0.3678832180356013, 'Total loss': 0.3678832180356013}
2023-01-05 15:23:21,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:21,853 INFO:     Epoch: 92
2023-01-05 15:23:24,020 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5191819091637929, 'Total loss': 0.5191819091637929} | train loss {'Reaction outcome loss': 0.3693313918741204, 'Total loss': 0.3693313918741204}
2023-01-05 15:23:24,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:24,020 INFO:     Epoch: 93
2023-01-05 15:23:26,177 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5084073583285014, 'Total loss': 0.5084073583285014} | train loss {'Reaction outcome loss': 0.36532206641024223, 'Total loss': 0.36532206641024223}
2023-01-05 15:23:26,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:26,178 INFO:     Epoch: 94
2023-01-05 15:23:28,329 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5504955331484477, 'Total loss': 0.5504955331484477} | train loss {'Reaction outcome loss': 0.35459690620663803, 'Total loss': 0.35459690620663803}
2023-01-05 15:23:28,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:28,330 INFO:     Epoch: 95
2023-01-05 15:23:30,466 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49279963672161103, 'Total loss': 0.49279963672161103} | train loss {'Reaction outcome loss': 0.3519355451040294, 'Total loss': 0.3519355451040294}
2023-01-05 15:23:30,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:30,466 INFO:     Epoch: 96
2023-01-05 15:23:32,628 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47822112540404, 'Total loss': 0.47822112540404} | train loss {'Reaction outcome loss': 0.3372225302142476, 'Total loss': 0.3372225302142476}
2023-01-05 15:23:32,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:32,628 INFO:     Epoch: 97
2023-01-05 15:23:34,781 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46999785403410593, 'Total loss': 0.46999785403410593} | train loss {'Reaction outcome loss': 0.33672783578483667, 'Total loss': 0.33672783578483667}
2023-01-05 15:23:34,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:34,781 INFO:     Epoch: 98
2023-01-05 15:23:36,934 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4707190036773682, 'Total loss': 0.4707190036773682} | train loss {'Reaction outcome loss': 0.3323911443838607, 'Total loss': 0.3323911443838607}
2023-01-05 15:23:36,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:36,934 INFO:     Epoch: 99
2023-01-05 15:23:39,100 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43538824915885926, 'Total loss': 0.43538824915885926} | train loss {'Reaction outcome loss': 0.3225930099273472, 'Total loss': 0.3225930099273472}
2023-01-05 15:23:39,100 INFO:     Best model found after epoch 74 of 100.
2023-01-05 15:23:39,100 INFO:   Done with stage: TRAINING
2023-01-05 15:23:39,101 INFO:   Starting stage: EVALUATION
2023-01-05 15:23:39,235 INFO:   Done with stage: EVALUATION
2023-01-05 15:23:39,235 INFO:   Leaving out SEQ value Fold_9
2023-01-05 15:23:39,248 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 15:23:39,248 INFO:   Starting stage: FEATURE SCALING
2023-01-05 15:23:39,901 INFO:   Done with stage: FEATURE SCALING
2023-01-05 15:23:39,901 INFO:   Starting stage: SCALING TARGETS
2023-01-05 15:23:39,971 INFO:   Done with stage: SCALING TARGETS
2023-01-05 15:23:39,971 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:23:39,971 INFO:     No hyperparam tuning for this model
2023-01-05 15:23:39,971 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:23:39,971 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 15:23:39,972 INFO:     None feature selector for col prot
2023-01-05 15:23:39,972 INFO:     None feature selector for col prot
2023-01-05 15:23:39,972 INFO:     None feature selector for col prot
2023-01-05 15:23:39,973 INFO:     None feature selector for col chem
2023-01-05 15:23:39,973 INFO:     None feature selector for col chem
2023-01-05 15:23:39,973 INFO:     None feature selector for col chem
2023-01-05 15:23:39,973 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 15:23:39,973 INFO:   Starting stage: BUILD MODEL
2023-01-05 15:23:39,974 INFO:     Number of params in model 72901
2023-01-05 15:23:39,978 INFO:   Done with stage: BUILD MODEL
2023-01-05 15:23:39,978 INFO:   Starting stage: TRAINING
2023-01-05 15:23:40,037 INFO:     Val loss before train {'Reaction outcome loss': 0.9866567254066467, 'Total loss': 0.9866567254066467}
2023-01-05 15:23:40,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:40,037 INFO:     Epoch: 0
2023-01-05 15:23:42,212 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.850581419467926, 'Total loss': 0.850581419467926} | train loss {'Reaction outcome loss': 0.9274217297023815, 'Total loss': 0.9274217297023815}
2023-01-05 15:23:42,213 INFO:     Found new best model at epoch 0
2023-01-05 15:23:42,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:42,214 INFO:     Epoch: 1
2023-01-05 15:23:44,374 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7011458357175191, 'Total loss': 0.7011458357175191} | train loss {'Reaction outcome loss': 0.773753586981701, 'Total loss': 0.773753586981701}
2023-01-05 15:23:44,375 INFO:     Found new best model at epoch 1
2023-01-05 15:23:44,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:44,376 INFO:     Epoch: 2
2023-01-05 15:23:46,538 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.560575419664383, 'Total loss': 0.560575419664383} | train loss {'Reaction outcome loss': 0.6226748849941075, 'Total loss': 0.6226748849941075}
2023-01-05 15:23:46,538 INFO:     Found new best model at epoch 2
2023-01-05 15:23:46,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:46,540 INFO:     Epoch: 3
2023-01-05 15:23:48,697 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5279540181159973, 'Total loss': 0.5279540181159973} | train loss {'Reaction outcome loss': 0.5450121098154288, 'Total loss': 0.5450121098154288}
2023-01-05 15:23:48,697 INFO:     Found new best model at epoch 3
2023-01-05 15:23:48,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:48,698 INFO:     Epoch: 4
2023-01-05 15:23:50,864 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5070582250754039, 'Total loss': 0.5070582250754039} | train loss {'Reaction outcome loss': 0.522176828948169, 'Total loss': 0.522176828948169}
2023-01-05 15:23:50,865 INFO:     Found new best model at epoch 4
2023-01-05 15:23:50,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:50,866 INFO:     Epoch: 5
2023-01-05 15:23:53,056 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5074418505032857, 'Total loss': 0.5074418505032857} | train loss {'Reaction outcome loss': 0.5070468815655484, 'Total loss': 0.5070468815655484}
2023-01-05 15:23:53,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:53,056 INFO:     Epoch: 6
2023-01-05 15:23:55,287 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48657178282737734, 'Total loss': 0.48657178282737734} | train loss {'Reaction outcome loss': 0.5012919711292005, 'Total loss': 0.5012919711292005}
2023-01-05 15:23:55,287 INFO:     Found new best model at epoch 6
2023-01-05 15:23:55,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:55,288 INFO:     Epoch: 7
2023-01-05 15:23:57,468 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4818368017673492, 'Total loss': 0.4818368017673492} | train loss {'Reaction outcome loss': 0.4922216882666956, 'Total loss': 0.4922216882666956}
2023-01-05 15:23:57,469 INFO:     Found new best model at epoch 7
2023-01-05 15:23:57,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:57,471 INFO:     Epoch: 8
2023-01-05 15:23:59,639 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4834089934825897, 'Total loss': 0.4834089934825897} | train loss {'Reaction outcome loss': 0.48700707193316106, 'Total loss': 0.48700707193316106}
2023-01-05 15:23:59,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:23:59,639 INFO:     Epoch: 9
2023-01-05 15:24:01,805 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5019563098748525, 'Total loss': 0.5019563098748525} | train loss {'Reaction outcome loss': 0.48551657228370865, 'Total loss': 0.48551657228370865}
2023-01-05 15:24:01,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:01,805 INFO:     Epoch: 10
2023-01-05 15:24:03,938 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49062543312708534, 'Total loss': 0.49062543312708534} | train loss {'Reaction outcome loss': 0.4732647215416285, 'Total loss': 0.4732647215416285}
2023-01-05 15:24:03,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:03,939 INFO:     Epoch: 11
2023-01-05 15:24:06,123 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4839805622895559, 'Total loss': 0.4839805622895559} | train loss {'Reaction outcome loss': 0.46839389958106226, 'Total loss': 0.46839389958106226}
2023-01-05 15:24:06,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:06,123 INFO:     Epoch: 12
2023-01-05 15:24:08,293 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47868411938349403, 'Total loss': 0.47868411938349403} | train loss {'Reaction outcome loss': 0.4625289561193342, 'Total loss': 0.4625289561193342}
2023-01-05 15:24:08,293 INFO:     Found new best model at epoch 12
2023-01-05 15:24:08,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:08,295 INFO:     Epoch: 13
2023-01-05 15:24:10,477 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45347060561180114, 'Total loss': 0.45347060561180114} | train loss {'Reaction outcome loss': 0.4585715220024009, 'Total loss': 0.4585715220024009}
2023-01-05 15:24:10,478 INFO:     Found new best model at epoch 13
2023-01-05 15:24:10,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:10,479 INFO:     Epoch: 14
2023-01-05 15:24:12,655 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4813205063343048, 'Total loss': 0.4813205063343048} | train loss {'Reaction outcome loss': 0.45850664882883696, 'Total loss': 0.45850664882883696}
2023-01-05 15:24:12,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:12,656 INFO:     Epoch: 15
2023-01-05 15:24:14,809 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47364617784818014, 'Total loss': 0.47364617784818014} | train loss {'Reaction outcome loss': 0.45161612954542096, 'Total loss': 0.45161612954542096}
2023-01-05 15:24:14,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:14,810 INFO:     Epoch: 16
2023-01-05 15:24:16,993 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4803555399179459, 'Total loss': 0.4803555399179459} | train loss {'Reaction outcome loss': 0.4497008241363381, 'Total loss': 0.4497008241363381}
2023-01-05 15:24:16,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:16,993 INFO:     Epoch: 17
2023-01-05 15:24:19,167 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4493564963340759, 'Total loss': 0.4493564963340759} | train loss {'Reaction outcome loss': 0.44307216049746917, 'Total loss': 0.44307216049746917}
2023-01-05 15:24:19,167 INFO:     Found new best model at epoch 17
2023-01-05 15:24:19,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:19,168 INFO:     Epoch: 18
2023-01-05 15:24:21,327 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4688461144765218, 'Total loss': 0.4688461144765218} | train loss {'Reaction outcome loss': 0.44201316428959153, 'Total loss': 0.44201316428959153}
2023-01-05 15:24:21,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:21,328 INFO:     Epoch: 19
2023-01-05 15:24:23,489 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4639610489209493, 'Total loss': 0.4639610489209493} | train loss {'Reaction outcome loss': 0.4356070138271965, 'Total loss': 0.4356070138271965}
2023-01-05 15:24:23,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:23,489 INFO:     Epoch: 20
2023-01-05 15:24:25,658 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4546583245197932, 'Total loss': 0.4546583245197932} | train loss {'Reaction outcome loss': 0.4293469783954242, 'Total loss': 0.4293469783954242}
2023-01-05 15:24:25,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:25,658 INFO:     Epoch: 21
2023-01-05 15:24:27,797 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4320808539787928, 'Total loss': 0.4320808539787928} | train loss {'Reaction outcome loss': 0.4276577527718854, 'Total loss': 0.4276577527718854}
2023-01-05 15:24:27,798 INFO:     Found new best model at epoch 21
2023-01-05 15:24:27,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:27,800 INFO:     Epoch: 22
2023-01-05 15:24:29,951 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4474221020936966, 'Total loss': 0.4474221020936966} | train loss {'Reaction outcome loss': 0.42948730306074506, 'Total loss': 0.42948730306074506}
2023-01-05 15:24:29,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:29,952 INFO:     Epoch: 23
2023-01-05 15:24:32,091 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4548073311646779, 'Total loss': 0.4548073311646779} | train loss {'Reaction outcome loss': 0.4173413080428912, 'Total loss': 0.4173413080428912}
2023-01-05 15:24:32,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:32,091 INFO:     Epoch: 24
2023-01-05 15:24:34,254 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45120603442192075, 'Total loss': 0.45120603442192075} | train loss {'Reaction outcome loss': 0.4144082487382613, 'Total loss': 0.4144082487382613}
2023-01-05 15:24:34,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:34,255 INFO:     Epoch: 25
2023-01-05 15:24:36,446 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4193505575259527, 'Total loss': 0.4193505575259527} | train loss {'Reaction outcome loss': 0.4188299653816309, 'Total loss': 0.4188299653816309}
2023-01-05 15:24:36,446 INFO:     Found new best model at epoch 25
2023-01-05 15:24:36,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:36,448 INFO:     Epoch: 26
2023-01-05 15:24:38,641 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4786256531874339, 'Total loss': 0.4786256531874339} | train loss {'Reaction outcome loss': 0.4098800341144796, 'Total loss': 0.4098800341144796}
2023-01-05 15:24:38,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:38,641 INFO:     Epoch: 27
2023-01-05 15:24:40,857 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43319021463394164, 'Total loss': 0.43319021463394164} | train loss {'Reaction outcome loss': 0.40290120991773987, 'Total loss': 0.40290120991773987}
2023-01-05 15:24:40,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:40,857 INFO:     Epoch: 28
2023-01-05 15:24:43,012 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4263597389062246, 'Total loss': 0.4263597389062246} | train loss {'Reaction outcome loss': 0.4007200011815405, 'Total loss': 0.4007200011815405}
2023-01-05 15:24:43,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:43,013 INFO:     Epoch: 29
2023-01-05 15:24:45,145 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44881338874499005, 'Total loss': 0.44881338874499005} | train loss {'Reaction outcome loss': 0.3992439302672978, 'Total loss': 0.3992439302672978}
2023-01-05 15:24:45,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:45,145 INFO:     Epoch: 30
2023-01-05 15:24:47,279 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4249517341454824, 'Total loss': 0.4249517341454824} | train loss {'Reaction outcome loss': 0.39689638500609553, 'Total loss': 0.39689638500609553}
2023-01-05 15:24:47,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:47,280 INFO:     Epoch: 31
2023-01-05 15:24:49,423 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44806074698766074, 'Total loss': 0.44806074698766074} | train loss {'Reaction outcome loss': 0.3922091478259985, 'Total loss': 0.3922091478259985}
2023-01-05 15:24:49,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:49,424 INFO:     Epoch: 32
2023-01-05 15:24:51,565 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4903842568397522, 'Total loss': 0.4903842568397522} | train loss {'Reaction outcome loss': 0.3923445199263225, 'Total loss': 0.3923445199263225}
2023-01-05 15:24:51,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:51,565 INFO:     Epoch: 33
2023-01-05 15:24:53,723 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4603061238924662, 'Total loss': 0.4603061238924662} | train loss {'Reaction outcome loss': 0.37840230442206996, 'Total loss': 0.37840230442206996}
2023-01-05 15:24:53,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:53,723 INFO:     Epoch: 34
2023-01-05 15:24:55,859 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43194639682769775, 'Total loss': 0.43194639682769775} | train loss {'Reaction outcome loss': 0.3824236114452247, 'Total loss': 0.3824236114452247}
2023-01-05 15:24:55,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:55,859 INFO:     Epoch: 35
2023-01-05 15:24:58,028 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4465605795383453, 'Total loss': 0.4465605795383453} | train loss {'Reaction outcome loss': 0.3783811574485758, 'Total loss': 0.3783811574485758}
2023-01-05 15:24:58,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:24:58,030 INFO:     Epoch: 36
2023-01-05 15:25:00,234 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43093340198198954, 'Total loss': 0.43093340198198954} | train loss {'Reaction outcome loss': 0.3722838825455426, 'Total loss': 0.3722838825455426}
2023-01-05 15:25:00,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:00,234 INFO:     Epoch: 37
2023-01-05 15:25:02,412 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3987549881140391, 'Total loss': 0.3987549881140391} | train loss {'Reaction outcome loss': 0.36864254725861634, 'Total loss': 0.36864254725861634}
2023-01-05 15:25:02,412 INFO:     Found new best model at epoch 37
2023-01-05 15:25:02,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:02,414 INFO:     Epoch: 38
2023-01-05 15:25:04,604 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4370747794707616, 'Total loss': 0.4370747794707616} | train loss {'Reaction outcome loss': 0.3670935512180793, 'Total loss': 0.3670935512180793}
2023-01-05 15:25:04,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:04,605 INFO:     Epoch: 39
2023-01-05 15:25:06,778 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42414069871107735, 'Total loss': 0.42414069871107735} | train loss {'Reaction outcome loss': 0.36292039301744006, 'Total loss': 0.36292039301744006}
2023-01-05 15:25:06,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:06,778 INFO:     Epoch: 40
2023-01-05 15:25:08,933 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4608436807990074, 'Total loss': 0.4608436807990074} | train loss {'Reaction outcome loss': 0.361384944620438, 'Total loss': 0.361384944620438}
2023-01-05 15:25:08,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:08,933 INFO:     Epoch: 41
2023-01-05 15:25:11,132 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4115245074033737, 'Total loss': 0.4115245074033737} | train loss {'Reaction outcome loss': 0.35352644934873717, 'Total loss': 0.35352644934873717}
2023-01-05 15:25:11,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:11,133 INFO:     Epoch: 42
2023-01-05 15:25:13,304 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3998924215634664, 'Total loss': 0.3998924215634664} | train loss {'Reaction outcome loss': 0.35849606194651085, 'Total loss': 0.35849606194651085}
2023-01-05 15:25:13,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:13,304 INFO:     Epoch: 43
2023-01-05 15:25:15,492 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4175740341345469, 'Total loss': 0.4175740341345469} | train loss {'Reaction outcome loss': 0.3496853868991459, 'Total loss': 0.3496853868991459}
2023-01-05 15:25:15,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:15,493 INFO:     Epoch: 44
2023-01-05 15:25:17,675 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4311596304178238, 'Total loss': 0.4311596304178238} | train loss {'Reaction outcome loss': 0.3502008180110463, 'Total loss': 0.3502008180110463}
2023-01-05 15:25:17,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:17,676 INFO:     Epoch: 45
2023-01-05 15:25:19,855 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44477828641732536, 'Total loss': 0.44477828641732536} | train loss {'Reaction outcome loss': 0.3509926384025748, 'Total loss': 0.3509926384025748}
2023-01-05 15:25:19,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:19,855 INFO:     Epoch: 46
2023-01-05 15:25:22,024 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4376174733042717, 'Total loss': 0.4376174733042717} | train loss {'Reaction outcome loss': 0.34207702362203857, 'Total loss': 0.34207702362203857}
2023-01-05 15:25:22,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:22,024 INFO:     Epoch: 47
2023-01-05 15:25:24,187 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3974437768260638, 'Total loss': 0.3974437768260638} | train loss {'Reaction outcome loss': 0.3366330324769666, 'Total loss': 0.3366330324769666}
2023-01-05 15:25:24,187 INFO:     Found new best model at epoch 47
2023-01-05 15:25:24,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:24,189 INFO:     Epoch: 48
2023-01-05 15:25:26,349 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.408673753341039, 'Total loss': 0.408673753341039} | train loss {'Reaction outcome loss': 0.33995398545523414, 'Total loss': 0.33995398545523414}
2023-01-05 15:25:26,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:26,349 INFO:     Epoch: 49
2023-01-05 15:25:28,524 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39157341917355853, 'Total loss': 0.39157341917355853} | train loss {'Reaction outcome loss': 0.32818610933928716, 'Total loss': 0.32818610933928716}
2023-01-05 15:25:28,524 INFO:     Found new best model at epoch 49
2023-01-05 15:25:28,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:28,526 INFO:     Epoch: 50
2023-01-05 15:25:30,689 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4312146613995234, 'Total loss': 0.4312146613995234} | train loss {'Reaction outcome loss': 0.3304281817876905, 'Total loss': 0.3304281817876905}
2023-01-05 15:25:30,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:30,689 INFO:     Epoch: 51
2023-01-05 15:25:32,846 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3998918722073237, 'Total loss': 0.3998918722073237} | train loss {'Reaction outcome loss': 0.33147336386601417, 'Total loss': 0.33147336386601417}
2023-01-05 15:25:32,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:32,846 INFO:     Epoch: 52
2023-01-05 15:25:35,006 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40899042586485546, 'Total loss': 0.40899042586485546} | train loss {'Reaction outcome loss': 0.32149671195646484, 'Total loss': 0.32149671195646484}
2023-01-05 15:25:35,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:35,007 INFO:     Epoch: 53
2023-01-05 15:25:37,168 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40586356073617935, 'Total loss': 0.40586356073617935} | train loss {'Reaction outcome loss': 0.3233132010547693, 'Total loss': 0.3233132010547693}
2023-01-05 15:25:37,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:37,168 INFO:     Epoch: 54
2023-01-05 15:25:39,329 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39625170032183327, 'Total loss': 0.39625170032183327} | train loss {'Reaction outcome loss': 0.32052203663204554, 'Total loss': 0.32052203663204554}
2023-01-05 15:25:39,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:39,329 INFO:     Epoch: 55
2023-01-05 15:25:41,496 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3920066813627879, 'Total loss': 0.3920066813627879} | train loss {'Reaction outcome loss': 0.31471128274252913, 'Total loss': 0.31471128274252913}
2023-01-05 15:25:41,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:41,497 INFO:     Epoch: 56
2023-01-05 15:25:43,631 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4511319955190023, 'Total loss': 0.4511319955190023} | train loss {'Reaction outcome loss': 0.3148995462791584, 'Total loss': 0.3148995462791584}
2023-01-05 15:25:43,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:43,631 INFO:     Epoch: 57
2023-01-05 15:25:45,774 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40894423897067705, 'Total loss': 0.40894423897067705} | train loss {'Reaction outcome loss': 0.31840133930586734, 'Total loss': 0.31840133930586734}
2023-01-05 15:25:45,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:45,774 INFO:     Epoch: 58
2023-01-05 15:25:47,919 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41904732088247937, 'Total loss': 0.41904732088247937} | train loss {'Reaction outcome loss': 0.311181531714726, 'Total loss': 0.311181531714726}
2023-01-05 15:25:47,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:47,919 INFO:     Epoch: 59
2023-01-05 15:25:50,057 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39296988646189374, 'Total loss': 0.39296988646189374} | train loss {'Reaction outcome loss': 0.3093693359126253, 'Total loss': 0.3093693359126253}
2023-01-05 15:25:50,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:50,057 INFO:     Epoch: 60
2023-01-05 15:25:52,202 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39826372464497883, 'Total loss': 0.39826372464497883} | train loss {'Reaction outcome loss': 0.29765473679044296, 'Total loss': 0.29765473679044296}
2023-01-05 15:25:52,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:52,202 INFO:     Epoch: 61
2023-01-05 15:25:54,337 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40779665609200794, 'Total loss': 0.40779665609200794} | train loss {'Reaction outcome loss': 0.30091312187404406, 'Total loss': 0.30091312187404406}
2023-01-05 15:25:54,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:54,338 INFO:     Epoch: 62
2023-01-05 15:25:56,520 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4054919103781382, 'Total loss': 0.4054919103781382} | train loss {'Reaction outcome loss': 0.3059019818431311, 'Total loss': 0.3059019818431311}
2023-01-05 15:25:56,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:56,521 INFO:     Epoch: 63
2023-01-05 15:25:58,653 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41052848696708677, 'Total loss': 0.41052848696708677} | train loss {'Reaction outcome loss': 0.299983582321541, 'Total loss': 0.299983582321541}
2023-01-05 15:25:58,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:25:58,653 INFO:     Epoch: 64
2023-01-05 15:26:00,779 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43051231106122334, 'Total loss': 0.43051231106122334} | train loss {'Reaction outcome loss': 0.28834921475298136, 'Total loss': 0.28834921475298136}
2023-01-05 15:26:00,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:00,779 INFO:     Epoch: 65
2023-01-05 15:26:02,921 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3698148747285207, 'Total loss': 0.3698148747285207} | train loss {'Reaction outcome loss': 0.2965591430045422, 'Total loss': 0.2965591430045422}
2023-01-05 15:26:02,921 INFO:     Found new best model at epoch 65
2023-01-05 15:26:02,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:02,923 INFO:     Epoch: 66
2023-01-05 15:26:05,066 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3969042509794235, 'Total loss': 0.3969042509794235} | train loss {'Reaction outcome loss': 0.2913808898213538, 'Total loss': 0.2913808898213538}
2023-01-05 15:26:05,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:05,067 INFO:     Epoch: 67
2023-01-05 15:26:07,186 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3866033693154653, 'Total loss': 0.3866033693154653} | train loss {'Reaction outcome loss': 0.2955532171074234, 'Total loss': 0.2955532171074234}
2023-01-05 15:26:07,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:07,186 INFO:     Epoch: 68
2023-01-05 15:26:09,318 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38658852130174637, 'Total loss': 0.38658852130174637} | train loss {'Reaction outcome loss': 0.28144121525089666, 'Total loss': 0.28144121525089666}
2023-01-05 15:26:09,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:09,318 INFO:     Epoch: 69
2023-01-05 15:26:11,469 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.37069581151008607, 'Total loss': 0.37069581151008607} | train loss {'Reaction outcome loss': 0.2902629750811021, 'Total loss': 0.2902629750811021}
2023-01-05 15:26:11,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:11,470 INFO:     Epoch: 70
2023-01-05 15:26:13,632 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38901888877153395, 'Total loss': 0.38901888877153395} | train loss {'Reaction outcome loss': 0.28824580634275065, 'Total loss': 0.28824580634275065}
2023-01-05 15:26:13,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:13,632 INFO:     Epoch: 71
2023-01-05 15:26:15,802 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3914053315917651, 'Total loss': 0.3914053315917651} | train loss {'Reaction outcome loss': 0.2941534131066033, 'Total loss': 0.2941534131066033}
2023-01-05 15:26:15,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:15,803 INFO:     Epoch: 72
2023-01-05 15:26:17,944 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39738062421480813, 'Total loss': 0.39738062421480813} | train loss {'Reaction outcome loss': 0.2805151484825981, 'Total loss': 0.2805151484825981}
2023-01-05 15:26:17,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:17,944 INFO:     Epoch: 73
2023-01-05 15:26:20,090 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38601586520671843, 'Total loss': 0.38601586520671843} | train loss {'Reaction outcome loss': 0.2885241739263603, 'Total loss': 0.2885241739263603}
2023-01-05 15:26:20,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:20,090 INFO:     Epoch: 74
2023-01-05 15:26:22,223 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40418753723303474, 'Total loss': 0.40418753723303474} | train loss {'Reaction outcome loss': 0.27395183714073057, 'Total loss': 0.27395183714073057}
2023-01-05 15:26:22,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:22,224 INFO:     Epoch: 75
2023-01-05 15:26:24,462 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3678809920946757, 'Total loss': 0.3678809920946757} | train loss {'Reaction outcome loss': 0.28770823873552603, 'Total loss': 0.28770823873552603}
2023-01-05 15:26:24,463 INFO:     Found new best model at epoch 75
2023-01-05 15:26:24,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:24,464 INFO:     Epoch: 76
2023-01-05 15:26:26,702 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37243285377820334, 'Total loss': 0.37243285377820334} | train loss {'Reaction outcome loss': 0.2818345595521025, 'Total loss': 0.2818345595521025}
2023-01-05 15:26:26,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:26,703 INFO:     Epoch: 77
2023-01-05 15:26:28,941 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40193061729272206, 'Total loss': 0.40193061729272206} | train loss {'Reaction outcome loss': 0.2741607265842789, 'Total loss': 0.2741607265842789}
2023-01-05 15:26:28,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:28,941 INFO:     Epoch: 78
2023-01-05 15:26:31,163 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40928790271282195, 'Total loss': 0.40928790271282195} | train loss {'Reaction outcome loss': 0.2803438814282955, 'Total loss': 0.2803438814282955}
2023-01-05 15:26:31,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:31,163 INFO:     Epoch: 79
2023-01-05 15:26:33,402 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3711667244633039, 'Total loss': 0.3711667244633039} | train loss {'Reaction outcome loss': 0.2797455512094799, 'Total loss': 0.2797455512094799}
2023-01-05 15:26:33,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:33,402 INFO:     Epoch: 80
2023-01-05 15:26:35,535 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3718701511621475, 'Total loss': 0.3718701511621475} | train loss {'Reaction outcome loss': 0.2751531801001582, 'Total loss': 0.2751531801001582}
2023-01-05 15:26:35,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:35,536 INFO:     Epoch: 81
2023-01-05 15:26:37,678 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4010761340459188, 'Total loss': 0.4010761340459188} | train loss {'Reaction outcome loss': 0.27087210472471446, 'Total loss': 0.27087210472471446}
2023-01-05 15:26:37,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:37,678 INFO:     Epoch: 82
2023-01-05 15:26:39,848 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4253525560100873, 'Total loss': 0.4253525560100873} | train loss {'Reaction outcome loss': 0.2696316327617272, 'Total loss': 0.2696316327617272}
2023-01-05 15:26:39,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:39,848 INFO:     Epoch: 83
2023-01-05 15:26:41,988 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38015123307704923, 'Total loss': 0.38015123307704923} | train loss {'Reaction outcome loss': 0.26540369434208216, 'Total loss': 0.26540369434208216}
2023-01-05 15:26:41,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:41,989 INFO:     Epoch: 84
2023-01-05 15:26:44,141 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4430587480465571, 'Total loss': 0.4430587480465571} | train loss {'Reaction outcome loss': 0.2684641063132656, 'Total loss': 0.2684641063132656}
2023-01-05 15:26:44,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:44,141 INFO:     Epoch: 85
2023-01-05 15:26:46,293 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3964637885491053, 'Total loss': 0.3964637885491053} | train loss {'Reaction outcome loss': 0.26061968144957337, 'Total loss': 0.26061968144957337}
2023-01-05 15:26:46,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:46,293 INFO:     Epoch: 86
2023-01-05 15:26:48,449 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3777138958374659, 'Total loss': 0.3777138958374659} | train loss {'Reaction outcome loss': 0.26951756801738636, 'Total loss': 0.26951756801738636}
2023-01-05 15:26:48,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:48,450 INFO:     Epoch: 87
2023-01-05 15:26:50,608 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38721697628498075, 'Total loss': 0.38721697628498075} | train loss {'Reaction outcome loss': 0.26336681437998044, 'Total loss': 0.26336681437998044}
2023-01-05 15:26:50,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:50,608 INFO:     Epoch: 88
2023-01-05 15:26:52,792 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39899866580963134, 'Total loss': 0.39899866580963134} | train loss {'Reaction outcome loss': 0.25930693318953046, 'Total loss': 0.25930693318953046}
2023-01-05 15:26:52,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:52,792 INFO:     Epoch: 89
2023-01-05 15:26:54,984 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3897830585638682, 'Total loss': 0.3897830585638682} | train loss {'Reaction outcome loss': 0.26597153853342637, 'Total loss': 0.26597153853342637}
2023-01-05 15:26:54,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:54,985 INFO:     Epoch: 90
2023-01-05 15:26:57,164 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38740974068641665, 'Total loss': 0.38740974068641665} | train loss {'Reaction outcome loss': 0.25857187290457395, 'Total loss': 0.25857187290457395}
2023-01-05 15:26:57,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:57,164 INFO:     Epoch: 91
2023-01-05 15:26:59,357 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.37278628076116244, 'Total loss': 0.37278628076116244} | train loss {'Reaction outcome loss': 0.26399031956596064, 'Total loss': 0.26399031956596064}
2023-01-05 15:26:59,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:26:59,357 INFO:     Epoch: 92
2023-01-05 15:27:01,379 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3973247937858105, 'Total loss': 0.3973247937858105} | train loss {'Reaction outcome loss': 0.26849614274066064, 'Total loss': 0.26849614274066064}
2023-01-05 15:27:01,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:01,379 INFO:     Epoch: 93
2023-01-05 15:27:03,493 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3719057430823644, 'Total loss': 0.3719057430823644} | train loss {'Reaction outcome loss': 0.25871875886183354, 'Total loss': 0.25871875886183354}
2023-01-05 15:27:03,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:03,493 INFO:     Epoch: 94
2023-01-05 15:27:05,672 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3845376851658026, 'Total loss': 0.3845376851658026} | train loss {'Reaction outcome loss': 0.25250897595544586, 'Total loss': 0.25250897595544586}
2023-01-05 15:27:05,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:05,672 INFO:     Epoch: 95
2023-01-05 15:27:07,852 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3736191640297572, 'Total loss': 0.3736191640297572} | train loss {'Reaction outcome loss': 0.2590240905269819, 'Total loss': 0.2590240905269819}
2023-01-05 15:27:07,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:07,853 INFO:     Epoch: 96
2023-01-05 15:27:10,011 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3973530093828837, 'Total loss': 0.3973530093828837} | train loss {'Reaction outcome loss': 0.2601695264074346, 'Total loss': 0.2601695264074346}
2023-01-05 15:27:10,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:10,011 INFO:     Epoch: 97
2023-01-05 15:27:12,173 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3920362542072932, 'Total loss': 0.3920362542072932} | train loss {'Reaction outcome loss': 0.2497100642872201, 'Total loss': 0.2497100642872201}
2023-01-05 15:27:12,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:12,174 INFO:     Epoch: 98
2023-01-05 15:27:14,348 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3895099967718124, 'Total loss': 0.3895099967718124} | train loss {'Reaction outcome loss': 0.2530997933799717, 'Total loss': 0.2530997933799717}
2023-01-05 15:27:14,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:14,348 INFO:     Epoch: 99
2023-01-05 15:27:16,511 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4046589811642965, 'Total loss': 0.4046589811642965} | train loss {'Reaction outcome loss': 0.25186530153001474, 'Total loss': 0.25186530153001474}
2023-01-05 15:27:16,512 INFO:     Best model found after epoch 76 of 100.
2023-01-05 15:27:16,512 INFO:   Done with stage: TRAINING
2023-01-05 15:27:16,512 INFO:   Starting stage: EVALUATION
2023-01-05 15:27:16,639 INFO:   Done with stage: EVALUATION
2023-01-05 15:27:16,647 INFO:   Leaving out SEQ value Fold_0
2023-01-05 15:27:16,660 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 15:27:16,660 INFO:   Starting stage: FEATURE SCALING
2023-01-05 15:27:17,316 INFO:   Done with stage: FEATURE SCALING
2023-01-05 15:27:17,316 INFO:   Starting stage: SCALING TARGETS
2023-01-05 15:27:17,385 INFO:   Done with stage: SCALING TARGETS
2023-01-05 15:27:17,385 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:27:17,385 INFO:     No hyperparam tuning for this model
2023-01-05 15:27:17,385 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:27:17,385 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 15:27:17,386 INFO:     None feature selector for col prot
2023-01-05 15:27:17,386 INFO:     None feature selector for col prot
2023-01-05 15:27:17,386 INFO:     None feature selector for col prot
2023-01-05 15:27:17,387 INFO:     None feature selector for col chem
2023-01-05 15:27:17,387 INFO:     None feature selector for col chem
2023-01-05 15:27:17,387 INFO:     None feature selector for col chem
2023-01-05 15:27:17,387 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 15:27:17,387 INFO:   Starting stage: BUILD MODEL
2023-01-05 15:27:17,388 INFO:     Number of params in model 72901
2023-01-05 15:27:17,392 INFO:   Done with stage: BUILD MODEL
2023-01-05 15:27:17,392 INFO:   Starting stage: TRAINING
2023-01-05 15:27:17,450 INFO:     Val loss before train {'Reaction outcome loss': 0.9573568403720856, 'Total loss': 0.9573568403720856}
2023-01-05 15:27:17,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:17,451 INFO:     Epoch: 0
2023-01-05 15:27:19,595 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8248512148857117, 'Total loss': 0.8248512148857117} | train loss {'Reaction outcome loss': 0.9316136446120082, 'Total loss': 0.9316136446120082}
2023-01-05 15:27:19,596 INFO:     Found new best model at epoch 0
2023-01-05 15:27:19,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:19,597 INFO:     Epoch: 1
2023-01-05 15:27:21,759 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6144089261690776, 'Total loss': 0.6144089261690776} | train loss {'Reaction outcome loss': 0.7355168757697, 'Total loss': 0.7355168757697}
2023-01-05 15:27:21,759 INFO:     Found new best model at epoch 1
2023-01-05 15:27:21,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:21,760 INFO:     Epoch: 2
2023-01-05 15:27:23,908 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5563722531000773, 'Total loss': 0.5563722531000773} | train loss {'Reaction outcome loss': 0.5829675239713296, 'Total loss': 0.5829675239713296}
2023-01-05 15:27:23,908 INFO:     Found new best model at epoch 2
2023-01-05 15:27:23,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:23,909 INFO:     Epoch: 3
2023-01-05 15:27:26,080 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5820191284020741, 'Total loss': 0.5820191284020741} | train loss {'Reaction outcome loss': 0.5422863155481932, 'Total loss': 0.5422863155481932}
2023-01-05 15:27:26,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:26,080 INFO:     Epoch: 4
2023-01-05 15:27:28,231 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5638999958833059, 'Total loss': 0.5638999958833059} | train loss {'Reaction outcome loss': 0.5180908521633946, 'Total loss': 0.5180908521633946}
2023-01-05 15:27:28,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:28,231 INFO:     Epoch: 5
2023-01-05 15:27:30,386 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5569379647572835, 'Total loss': 0.5569379647572835} | train loss {'Reaction outcome loss': 0.5002124034428456, 'Total loss': 0.5002124034428456}
2023-01-05 15:27:30,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:30,386 INFO:     Epoch: 6
2023-01-05 15:27:32,545 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.537519653638204, 'Total loss': 0.537519653638204} | train loss {'Reaction outcome loss': 0.49538456601768976, 'Total loss': 0.49538456601768976}
2023-01-05 15:27:32,545 INFO:     Found new best model at epoch 6
2023-01-05 15:27:32,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:32,547 INFO:     Epoch: 7
2023-01-05 15:27:34,727 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5388787766297658, 'Total loss': 0.5388787766297658} | train loss {'Reaction outcome loss': 0.4860178390281626, 'Total loss': 0.4860178390281626}
2023-01-05 15:27:34,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:34,728 INFO:     Epoch: 8
2023-01-05 15:27:36,885 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5482200801372528, 'Total loss': 0.5482200801372528} | train loss {'Reaction outcome loss': 0.4825863525527867, 'Total loss': 0.4825863525527867}
2023-01-05 15:27:36,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:36,885 INFO:     Epoch: 9
2023-01-05 15:27:39,027 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5695109228293102, 'Total loss': 0.5695109228293102} | train loss {'Reaction outcome loss': 0.4837738786150442, 'Total loss': 0.4837738786150442}
2023-01-05 15:27:39,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:39,028 INFO:     Epoch: 10
2023-01-05 15:27:41,171 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5652933537960052, 'Total loss': 0.5652933537960052} | train loss {'Reaction outcome loss': 0.4694128456539002, 'Total loss': 0.4694128456539002}
2023-01-05 15:27:41,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:41,172 INFO:     Epoch: 11
2023-01-05 15:27:43,300 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.520214194059372, 'Total loss': 0.520214194059372} | train loss {'Reaction outcome loss': 0.4758009069963642, 'Total loss': 0.4758009069963642}
2023-01-05 15:27:43,301 INFO:     Found new best model at epoch 11
2023-01-05 15:27:43,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:43,302 INFO:     Epoch: 12
2023-01-05 15:27:45,450 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.525223579009374, 'Total loss': 0.525223579009374} | train loss {'Reaction outcome loss': 0.4637625475373605, 'Total loss': 0.4637625475373605}
2023-01-05 15:27:45,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:45,450 INFO:     Epoch: 13
2023-01-05 15:27:47,612 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5608656982580821, 'Total loss': 0.5608656982580821} | train loss {'Reaction outcome loss': 0.4560173968312101, 'Total loss': 0.4560173968312101}
2023-01-05 15:27:47,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:47,613 INFO:     Epoch: 14
2023-01-05 15:27:49,769 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.561813372373581, 'Total loss': 0.561813372373581} | train loss {'Reaction outcome loss': 0.4494405996201782, 'Total loss': 0.4494405996201782}
2023-01-05 15:27:49,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:49,769 INFO:     Epoch: 15
2023-01-05 15:27:51,912 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.520500534772873, 'Total loss': 0.520500534772873} | train loss {'Reaction outcome loss': 0.44674309910750826, 'Total loss': 0.44674309910750826}
2023-01-05 15:27:51,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:51,912 INFO:     Epoch: 16
2023-01-05 15:27:54,052 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5296436816453933, 'Total loss': 0.5296436816453933} | train loss {'Reaction outcome loss': 0.4415008432182915, 'Total loss': 0.4415008432182915}
2023-01-05 15:27:54,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:54,053 INFO:     Epoch: 17
2023-01-05 15:27:56,215 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5299094587564468, 'Total loss': 0.5299094587564468} | train loss {'Reaction outcome loss': 0.43648312131172395, 'Total loss': 0.43648312131172395}
2023-01-05 15:27:56,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:56,215 INFO:     Epoch: 18
2023-01-05 15:27:58,360 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5208696206410726, 'Total loss': 0.5208696206410726} | train loss {'Reaction outcome loss': 0.43339340502659424, 'Total loss': 0.43339340502659424}
2023-01-05 15:27:58,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:27:58,360 INFO:     Epoch: 19
2023-01-05 15:28:00,513 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5409051537513733, 'Total loss': 0.5409051537513733} | train loss {'Reaction outcome loss': 0.43338263965847873, 'Total loss': 0.43338263965847873}
2023-01-05 15:28:00,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:00,514 INFO:     Epoch: 20
2023-01-05 15:28:02,728 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.529783167441686, 'Total loss': 0.529783167441686} | train loss {'Reaction outcome loss': 0.4332117331821633, 'Total loss': 0.4332117331821633}
2023-01-05 15:28:02,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:02,728 INFO:     Epoch: 21
2023-01-05 15:28:04,876 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5446514705816905, 'Total loss': 0.5446514705816905} | train loss {'Reaction outcome loss': 0.43909253738820553, 'Total loss': 0.43909253738820553}
2023-01-05 15:28:04,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:04,876 INFO:     Epoch: 22
2023-01-05 15:28:07,021 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49770485709110895, 'Total loss': 0.49770485709110895} | train loss {'Reaction outcome loss': 0.42304294773013046, 'Total loss': 0.42304294773013046}
2023-01-05 15:28:07,021 INFO:     Found new best model at epoch 22
2023-01-05 15:28:07,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:07,022 INFO:     Epoch: 23
2023-01-05 15:28:09,178 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5163524836301804, 'Total loss': 0.5163524836301804} | train loss {'Reaction outcome loss': 0.41798141495108715, 'Total loss': 0.41798141495108715}
2023-01-05 15:28:09,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:09,178 INFO:     Epoch: 24
2023-01-05 15:28:11,340 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5286768774191538, 'Total loss': 0.5286768774191538} | train loss {'Reaction outcome loss': 0.40867598016030976, 'Total loss': 0.40867598016030976}
2023-01-05 15:28:11,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:11,341 INFO:     Epoch: 25
2023-01-05 15:28:13,504 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5508538464705149, 'Total loss': 0.5508538464705149} | train loss {'Reaction outcome loss': 0.4035351124169909, 'Total loss': 0.4035351124169909}
2023-01-05 15:28:13,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:13,504 INFO:     Epoch: 26
2023-01-05 15:28:15,652 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5299661010503769, 'Total loss': 0.5299661010503769} | train loss {'Reaction outcome loss': 0.4031214089406168, 'Total loss': 0.4031214089406168}
2023-01-05 15:28:15,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:15,652 INFO:     Epoch: 27
2023-01-05 15:28:17,803 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5107877890268961, 'Total loss': 0.5107877890268961} | train loss {'Reaction outcome loss': 0.398012809627487, 'Total loss': 0.398012809627487}
2023-01-05 15:28:17,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:17,804 INFO:     Epoch: 28
2023-01-05 15:28:19,958 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5230822384357452, 'Total loss': 0.5230822384357452} | train loss {'Reaction outcome loss': 0.3961780450772494, 'Total loss': 0.3961780450772494}
2023-01-05 15:28:19,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:19,958 INFO:     Epoch: 29
2023-01-05 15:28:22,178 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48088685870170594, 'Total loss': 0.48088685870170594} | train loss {'Reaction outcome loss': 0.3902219705532975, 'Total loss': 0.3902219705532975}
2023-01-05 15:28:22,178 INFO:     Found new best model at epoch 29
2023-01-05 15:28:22,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:22,179 INFO:     Epoch: 30
2023-01-05 15:28:24,389 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5401717980702718, 'Total loss': 0.5401717980702718} | train loss {'Reaction outcome loss': 0.3963007570473828, 'Total loss': 0.3963007570473828}
2023-01-05 15:28:24,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:24,390 INFO:     Epoch: 31
2023-01-05 15:28:26,580 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5058596968650818, 'Total loss': 0.5058596968650818} | train loss {'Reaction outcome loss': 0.3877982970249529, 'Total loss': 0.3877982970249529}
2023-01-05 15:28:26,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:26,580 INFO:     Epoch: 32
2023-01-05 15:28:28,789 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4977576782306035, 'Total loss': 0.4977576782306035} | train loss {'Reaction outcome loss': 0.3813901407731886, 'Total loss': 0.3813901407731886}
2023-01-05 15:28:28,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:28,790 INFO:     Epoch: 33
2023-01-05 15:28:30,951 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5015911231438319, 'Total loss': 0.5015911231438319} | train loss {'Reaction outcome loss': 0.37398858888364106, 'Total loss': 0.37398858888364106}
2023-01-05 15:28:30,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:30,951 INFO:     Epoch: 34
2023-01-05 15:28:33,128 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5176967471837998, 'Total loss': 0.5176967471837998} | train loss {'Reaction outcome loss': 0.3848008775840635, 'Total loss': 0.3848008775840635}
2023-01-05 15:28:33,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:33,129 INFO:     Epoch: 35
2023-01-05 15:28:35,256 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46106972098350524, 'Total loss': 0.46106972098350524} | train loss {'Reaction outcome loss': 0.4115039368187064, 'Total loss': 0.4115039368187064}
2023-01-05 15:28:35,256 INFO:     Found new best model at epoch 35
2023-01-05 15:28:35,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:35,257 INFO:     Epoch: 36
2023-01-05 15:28:37,468 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5139825363953908, 'Total loss': 0.5139825363953908} | train loss {'Reaction outcome loss': 0.3733698310249526, 'Total loss': 0.3733698310249526}
2023-01-05 15:28:37,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:37,469 INFO:     Epoch: 37
2023-01-05 15:28:39,680 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5258359591166178, 'Total loss': 0.5258359591166178} | train loss {'Reaction outcome loss': 0.3656385644875548, 'Total loss': 0.3656385644875548}
2023-01-05 15:28:39,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:39,680 INFO:     Epoch: 38
2023-01-05 15:28:41,834 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5333032468954723, 'Total loss': 0.5333032468954723} | train loss {'Reaction outcome loss': 0.36208548299644305, 'Total loss': 0.36208548299644305}
2023-01-05 15:28:41,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:41,835 INFO:     Epoch: 39
2023-01-05 15:28:43,984 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5048664768536886, 'Total loss': 0.5048664768536886} | train loss {'Reaction outcome loss': 0.35538556041580666, 'Total loss': 0.35538556041580666}
2023-01-05 15:28:43,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:43,984 INFO:     Epoch: 40
2023-01-05 15:28:46,143 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5142491281032562, 'Total loss': 0.5142491281032562} | train loss {'Reaction outcome loss': 0.3568996837711893, 'Total loss': 0.3568996837711893}
2023-01-05 15:28:46,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:46,143 INFO:     Epoch: 41
2023-01-05 15:28:48,282 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4710271418094635, 'Total loss': 0.4710271418094635} | train loss {'Reaction outcome loss': 0.355093680712963, 'Total loss': 0.355093680712963}
2023-01-05 15:28:48,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:48,283 INFO:     Epoch: 42
2023-01-05 15:28:50,417 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4843761662642161, 'Total loss': 0.4843761662642161} | train loss {'Reaction outcome loss': 0.34639928750255133, 'Total loss': 0.34639928750255133}
2023-01-05 15:28:50,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:50,417 INFO:     Epoch: 43
2023-01-05 15:28:52,556 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5048044959704081, 'Total loss': 0.5048044959704081} | train loss {'Reaction outcome loss': 0.34696145768722764, 'Total loss': 0.34696145768722764}
2023-01-05 15:28:52,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:52,557 INFO:     Epoch: 44
2023-01-05 15:28:54,703 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5255023707946141, 'Total loss': 0.5255023707946141} | train loss {'Reaction outcome loss': 0.3539053604050634, 'Total loss': 0.3539053604050634}
2023-01-05 15:28:54,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:54,705 INFO:     Epoch: 45
2023-01-05 15:28:56,868 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5380486071109771, 'Total loss': 0.5380486071109771} | train loss {'Reaction outcome loss': 0.3454464862099511, 'Total loss': 0.3454464862099511}
2023-01-05 15:28:56,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:56,868 INFO:     Epoch: 46
2023-01-05 15:28:59,017 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.51594431300958, 'Total loss': 0.51594431300958} | train loss {'Reaction outcome loss': 0.3423234982700956, 'Total loss': 0.3423234982700956}
2023-01-05 15:28:59,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:28:59,017 INFO:     Epoch: 47
2023-01-05 15:29:01,175 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48760404040416083, 'Total loss': 0.48760404040416083} | train loss {'Reaction outcome loss': 0.3369788953501299, 'Total loss': 0.3369788953501299}
2023-01-05 15:29:01,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:01,176 INFO:     Epoch: 48
2023-01-05 15:29:03,311 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48990251223246256, 'Total loss': 0.48990251223246256} | train loss {'Reaction outcome loss': 0.3351099190126727, 'Total loss': 0.3351099190126727}
2023-01-05 15:29:03,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:03,311 INFO:     Epoch: 49
2023-01-05 15:29:05,508 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4818392336368561, 'Total loss': 0.4818392336368561} | train loss {'Reaction outcome loss': 0.3371298084291967, 'Total loss': 0.3371298084291967}
2023-01-05 15:29:05,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:05,509 INFO:     Epoch: 50
2023-01-05 15:29:07,707 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49783995052178703, 'Total loss': 0.49783995052178703} | train loss {'Reaction outcome loss': 0.32183813672694983, 'Total loss': 0.32183813672694983}
2023-01-05 15:29:07,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:07,707 INFO:     Epoch: 51
2023-01-05 15:29:09,912 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4801232308149338, 'Total loss': 0.4801232308149338} | train loss {'Reaction outcome loss': 0.33760895714078576, 'Total loss': 0.33760895714078576}
2023-01-05 15:29:09,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:09,912 INFO:     Epoch: 52
2023-01-05 15:29:12,125 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4505290617545446, 'Total loss': 0.4505290617545446} | train loss {'Reaction outcome loss': 0.3284592063004232, 'Total loss': 0.3284592063004232}
2023-01-05 15:29:12,125 INFO:     Found new best model at epoch 52
2023-01-05 15:29:12,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:12,127 INFO:     Epoch: 53
2023-01-05 15:29:14,284 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5053644734124343, 'Total loss': 0.5053644734124343} | train loss {'Reaction outcome loss': 0.3215006548256286, 'Total loss': 0.3215006548256286}
2023-01-05 15:29:14,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:14,286 INFO:     Epoch: 54
2023-01-05 15:29:16,440 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4527320255835851, 'Total loss': 0.4527320255835851} | train loss {'Reaction outcome loss': 0.3216148894820092, 'Total loss': 0.3216148894820092}
2023-01-05 15:29:16,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:16,440 INFO:     Epoch: 55
2023-01-05 15:29:18,594 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4800436576207479, 'Total loss': 0.4800436576207479} | train loss {'Reaction outcome loss': 0.319335631945211, 'Total loss': 0.319335631945211}
2023-01-05 15:29:18,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:18,594 INFO:     Epoch: 56
2023-01-05 15:29:20,737 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5129115790128708, 'Total loss': 0.5129115790128708} | train loss {'Reaction outcome loss': 0.36917490680597426, 'Total loss': 0.36917490680597426}
2023-01-05 15:29:20,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:20,737 INFO:     Epoch: 57
2023-01-05 15:29:22,888 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44623285631338755, 'Total loss': 0.44623285631338755} | train loss {'Reaction outcome loss': 0.32603541413403075, 'Total loss': 0.32603541413403075}
2023-01-05 15:29:22,888 INFO:     Found new best model at epoch 57
2023-01-05 15:29:22,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:22,889 INFO:     Epoch: 58
2023-01-05 15:29:25,039 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4805471320947011, 'Total loss': 0.4805471320947011} | train loss {'Reaction outcome loss': 0.38146800068679493, 'Total loss': 0.38146800068679493}
2023-01-05 15:29:25,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:25,040 INFO:     Epoch: 59
2023-01-05 15:29:27,179 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.503474070628484, 'Total loss': 0.503474070628484} | train loss {'Reaction outcome loss': 0.3254292965259241, 'Total loss': 0.3254292965259241}
2023-01-05 15:29:27,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:27,180 INFO:     Epoch: 60
2023-01-05 15:29:29,339 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43990065281589824, 'Total loss': 0.43990065281589824} | train loss {'Reaction outcome loss': 0.3235220878454182, 'Total loss': 0.3235220878454182}
2023-01-05 15:29:29,339 INFO:     Found new best model at epoch 60
2023-01-05 15:29:29,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:29,340 INFO:     Epoch: 61
2023-01-05 15:29:31,475 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.462502787510554, 'Total loss': 0.462502787510554} | train loss {'Reaction outcome loss': 0.3193308484565089, 'Total loss': 0.3193308484565089}
2023-01-05 15:29:31,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:31,476 INFO:     Epoch: 62
2023-01-05 15:29:33,632 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.440867022673289, 'Total loss': 0.440867022673289} | train loss {'Reaction outcome loss': 0.31111571951128164, 'Total loss': 0.31111571951128164}
2023-01-05 15:29:33,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:33,632 INFO:     Epoch: 63
2023-01-05 15:29:35,784 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46071776549021404, 'Total loss': 0.46071776549021404} | train loss {'Reaction outcome loss': 0.30844640344941476, 'Total loss': 0.30844640344941476}
2023-01-05 15:29:35,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:35,784 INFO:     Epoch: 64
2023-01-05 15:29:37,933 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.455745275815328, 'Total loss': 0.455745275815328} | train loss {'Reaction outcome loss': 0.3065414659230147, 'Total loss': 0.3065414659230147}
2023-01-05 15:29:37,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:37,933 INFO:     Epoch: 65
2023-01-05 15:29:40,080 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4575133979320526, 'Total loss': 0.4575133979320526} | train loss {'Reaction outcome loss': 0.29975322797806747, 'Total loss': 0.29975322797806747}
2023-01-05 15:29:40,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:40,080 INFO:     Epoch: 66
2023-01-05 15:29:42,233 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45793748944997786, 'Total loss': 0.45793748944997786} | train loss {'Reaction outcome loss': 0.3070742904741749, 'Total loss': 0.3070742904741749}
2023-01-05 15:29:42,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:42,233 INFO:     Epoch: 67
2023-01-05 15:29:44,398 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45137206415335335, 'Total loss': 0.45137206415335335} | train loss {'Reaction outcome loss': 0.30381744895071344, 'Total loss': 0.30381744895071344}
2023-01-05 15:29:44,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:44,399 INFO:     Epoch: 68
2023-01-05 15:29:46,528 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4863459557294846, 'Total loss': 0.4863459557294846} | train loss {'Reaction outcome loss': 0.30673098226712237, 'Total loss': 0.30673098226712237}
2023-01-05 15:29:46,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:46,529 INFO:     Epoch: 69
2023-01-05 15:29:48,680 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44642389714717867, 'Total loss': 0.44642389714717867} | train loss {'Reaction outcome loss': 0.30815635931988555, 'Total loss': 0.30815635931988555}
2023-01-05 15:29:48,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:48,680 INFO:     Epoch: 70
2023-01-05 15:29:50,823 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4540180722872416, 'Total loss': 0.4540180722872416} | train loss {'Reaction outcome loss': 0.30351076961053786, 'Total loss': 0.30351076961053786}
2023-01-05 15:29:50,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:50,823 INFO:     Epoch: 71
2023-01-05 15:29:52,955 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47551230192184446, 'Total loss': 0.47551230192184446} | train loss {'Reaction outcome loss': 0.2913089663775611, 'Total loss': 0.2913089663775611}
2023-01-05 15:29:52,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:52,955 INFO:     Epoch: 72
2023-01-05 15:29:55,109 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5219826072454452, 'Total loss': 0.5219826072454452} | train loss {'Reaction outcome loss': 0.28923812890560296, 'Total loss': 0.28923812890560296}
2023-01-05 15:29:55,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:55,110 INFO:     Epoch: 73
2023-01-05 15:29:57,280 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48029613494873047, 'Total loss': 0.48029613494873047} | train loss {'Reaction outcome loss': 0.29166987443012116, 'Total loss': 0.29166987443012116}
2023-01-05 15:29:57,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:57,280 INFO:     Epoch: 74
2023-01-05 15:29:59,450 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42773645718892417, 'Total loss': 0.42773645718892417} | train loss {'Reaction outcome loss': 0.28384340135486075, 'Total loss': 0.28384340135486075}
2023-01-05 15:29:59,450 INFO:     Found new best model at epoch 74
2023-01-05 15:29:59,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:29:59,451 INFO:     Epoch: 75
2023-01-05 15:30:01,596 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4725510577360789, 'Total loss': 0.4725510577360789} | train loss {'Reaction outcome loss': 0.2877057700221169, 'Total loss': 0.2877057700221169}
2023-01-05 15:30:01,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:01,597 INFO:     Epoch: 76
2023-01-05 15:30:03,763 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4206159770488739, 'Total loss': 0.4206159770488739} | train loss {'Reaction outcome loss': 0.27778629199473065, 'Total loss': 0.27778629199473065}
2023-01-05 15:30:03,764 INFO:     Found new best model at epoch 76
2023-01-05 15:30:03,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:03,765 INFO:     Epoch: 77
2023-01-05 15:30:05,924 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43457158903280896, 'Total loss': 0.43457158903280896} | train loss {'Reaction outcome loss': 0.2829626989989555, 'Total loss': 0.2829626989989555}
2023-01-05 15:30:05,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:05,924 INFO:     Epoch: 78
2023-01-05 15:30:08,081 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4377677927414576, 'Total loss': 0.4377677927414576} | train loss {'Reaction outcome loss': 0.2839553891411186, 'Total loss': 0.2839553891411186}
2023-01-05 15:30:08,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:08,081 INFO:     Epoch: 79
2023-01-05 15:30:10,236 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4301941951115926, 'Total loss': 0.4301941951115926} | train loss {'Reaction outcome loss': 0.27632800555548404, 'Total loss': 0.27632800555548404}
2023-01-05 15:30:10,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:10,236 INFO:     Epoch: 80
2023-01-05 15:30:12,376 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4432551751534144, 'Total loss': 0.4432551751534144} | train loss {'Reaction outcome loss': 0.27445402448622347, 'Total loss': 0.27445402448622347}
2023-01-05 15:30:12,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:12,376 INFO:     Epoch: 81
2023-01-05 15:30:14,517 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46005183657010396, 'Total loss': 0.46005183657010396} | train loss {'Reaction outcome loss': 0.27736721182431, 'Total loss': 0.27736721182431}
2023-01-05 15:30:14,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:14,518 INFO:     Epoch: 82
2023-01-05 15:30:16,674 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4716883420944214, 'Total loss': 0.4716883420944214} | train loss {'Reaction outcome loss': 0.27560605158340995, 'Total loss': 0.27560605158340995}
2023-01-05 15:30:16,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:16,674 INFO:     Epoch: 83
2023-01-05 15:30:18,829 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42893240253130593, 'Total loss': 0.42893240253130593} | train loss {'Reaction outcome loss': 0.2717051913881258, 'Total loss': 0.2717051913881258}
2023-01-05 15:30:18,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:18,829 INFO:     Epoch: 84
2023-01-05 15:30:20,980 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4433804909388224, 'Total loss': 0.4433804909388224} | train loss {'Reaction outcome loss': 0.27960092894247046, 'Total loss': 0.27960092894247046}
2023-01-05 15:30:20,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:20,981 INFO:     Epoch: 85
2023-01-05 15:30:23,134 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4500864485899607, 'Total loss': 0.4500864485899607} | train loss {'Reaction outcome loss': 0.4086137327156367, 'Total loss': 0.4086137327156367}
2023-01-05 15:30:23,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:23,135 INFO:     Epoch: 86
2023-01-05 15:30:25,263 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4382741133371989, 'Total loss': 0.4382741133371989} | train loss {'Reaction outcome loss': 0.31700329363187507, 'Total loss': 0.31700329363187507}
2023-01-05 15:30:25,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:25,263 INFO:     Epoch: 87
2023-01-05 15:30:27,405 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4326048438747724, 'Total loss': 0.4326048438747724} | train loss {'Reaction outcome loss': 0.2875015829239324, 'Total loss': 0.2875015829239324}
2023-01-05 15:30:27,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:27,405 INFO:     Epoch: 88
2023-01-05 15:30:29,556 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4273183956742287, 'Total loss': 0.4273183956742287} | train loss {'Reaction outcome loss': 0.28166710064355016, 'Total loss': 0.28166710064355016}
2023-01-05 15:30:29,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:29,556 INFO:     Epoch: 89
2023-01-05 15:30:31,706 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47286963860193887, 'Total loss': 0.47286963860193887} | train loss {'Reaction outcome loss': 0.2830176661617757, 'Total loss': 0.2830176661617757}
2023-01-05 15:30:31,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:31,707 INFO:     Epoch: 90
2023-01-05 15:30:33,854 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4227848360935847, 'Total loss': 0.4227848360935847} | train loss {'Reaction outcome loss': 0.27872844239016925, 'Total loss': 0.27872844239016925}
2023-01-05 15:30:33,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:33,854 INFO:     Epoch: 91
2023-01-05 15:30:35,959 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47823261419932045, 'Total loss': 0.47823261419932045} | train loss {'Reaction outcome loss': 0.2785824132598213, 'Total loss': 0.2785824132598213}
2023-01-05 15:30:35,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:35,959 INFO:     Epoch: 92
2023-01-05 15:30:38,098 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4343887656927109, 'Total loss': 0.4343887656927109} | train loss {'Reaction outcome loss': 0.26587610141934315, 'Total loss': 0.26587610141934315}
2023-01-05 15:30:38,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:38,099 INFO:     Epoch: 93
2023-01-05 15:30:40,258 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42677926818529766, 'Total loss': 0.42677926818529766} | train loss {'Reaction outcome loss': 0.2670486182470231, 'Total loss': 0.2670486182470231}
2023-01-05 15:30:40,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:40,259 INFO:     Epoch: 94
2023-01-05 15:30:42,400 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4328318893909454, 'Total loss': 0.4328318893909454} | train loss {'Reaction outcome loss': 0.26642644874316274, 'Total loss': 0.26642644874316274}
2023-01-05 15:30:42,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:42,401 INFO:     Epoch: 95
2023-01-05 15:30:44,541 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4354428211847941, 'Total loss': 0.4354428211847941} | train loss {'Reaction outcome loss': 0.25855049061372987, 'Total loss': 0.25855049061372987}
2023-01-05 15:30:44,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:44,542 INFO:     Epoch: 96
2023-01-05 15:30:46,705 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4405200223128001, 'Total loss': 0.4405200223128001} | train loss {'Reaction outcome loss': 0.26454476232509583, 'Total loss': 0.26454476232509583}
2023-01-05 15:30:46,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:46,705 INFO:     Epoch: 97
2023-01-05 15:30:48,619 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4424748107790947, 'Total loss': 0.4424748107790947} | train loss {'Reaction outcome loss': 0.25919547464365766, 'Total loss': 0.25919547464365766}
2023-01-05 15:30:48,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:48,619 INFO:     Epoch: 98
2023-01-05 15:30:50,395 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4916982114315033, 'Total loss': 0.4916982114315033} | train loss {'Reaction outcome loss': 0.2632210503474778, 'Total loss': 0.2632210503474778}
2023-01-05 15:30:50,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:50,396 INFO:     Epoch: 99
2023-01-05 15:30:52,257 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42024738689263663, 'Total loss': 0.42024738689263663} | train loss {'Reaction outcome loss': 0.2638808442853337, 'Total loss': 0.2638808442853337}
2023-01-05 15:30:52,257 INFO:     Found new best model at epoch 99
2023-01-05 15:30:52,258 INFO:     Best model found after epoch 100 of 100.
2023-01-05 15:30:52,258 INFO:   Done with stage: TRAINING
2023-01-05 15:30:52,258 INFO:   Starting stage: EVALUATION
2023-01-05 15:30:52,391 INFO:   Done with stage: EVALUATION
2023-01-05 15:30:52,392 INFO:   Leaving out SEQ value Fold_1
2023-01-05 15:30:52,404 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 15:30:52,404 INFO:   Starting stage: FEATURE SCALING
2023-01-05 15:30:53,056 INFO:   Done with stage: FEATURE SCALING
2023-01-05 15:30:53,056 INFO:   Starting stage: SCALING TARGETS
2023-01-05 15:30:53,125 INFO:   Done with stage: SCALING TARGETS
2023-01-05 15:30:53,125 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:30:53,125 INFO:     No hyperparam tuning for this model
2023-01-05 15:30:53,125 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:30:53,125 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 15:30:53,126 INFO:     None feature selector for col prot
2023-01-05 15:30:53,126 INFO:     None feature selector for col prot
2023-01-05 15:30:53,126 INFO:     None feature selector for col prot
2023-01-05 15:30:53,127 INFO:     None feature selector for col chem
2023-01-05 15:30:53,127 INFO:     None feature selector for col chem
2023-01-05 15:30:53,127 INFO:     None feature selector for col chem
2023-01-05 15:30:53,127 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 15:30:53,127 INFO:   Starting stage: BUILD MODEL
2023-01-05 15:30:53,128 INFO:     Number of params in model 72901
2023-01-05 15:30:53,132 INFO:   Done with stage: BUILD MODEL
2023-01-05 15:30:53,132 INFO:   Starting stage: TRAINING
2023-01-05 15:30:53,192 INFO:     Val loss before train {'Reaction outcome loss': 0.9084722638130188, 'Total loss': 0.9084722638130188}
2023-01-05 15:30:53,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:53,192 INFO:     Epoch: 0
2023-01-05 15:30:55,358 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7667330821355184, 'Total loss': 0.7667330821355184} | train loss {'Reaction outcome loss': 0.9412332696678198, 'Total loss': 0.9412332696678198}
2023-01-05 15:30:55,358 INFO:     Found new best model at epoch 0
2023-01-05 15:30:55,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:55,360 INFO:     Epoch: 1
2023-01-05 15:30:57,530 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5650367140769958, 'Total loss': 0.5650367140769958} | train loss {'Reaction outcome loss': 0.7477903626319291, 'Total loss': 0.7477903626319291}
2023-01-05 15:30:57,530 INFO:     Found new best model at epoch 1
2023-01-05 15:30:57,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:57,532 INFO:     Epoch: 2
2023-01-05 15:30:59,687 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45747151573499045, 'Total loss': 0.45747151573499045} | train loss {'Reaction outcome loss': 0.5978072737647302, 'Total loss': 0.5978072737647302}
2023-01-05 15:30:59,687 INFO:     Found new best model at epoch 2
2023-01-05 15:30:59,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:30:59,689 INFO:     Epoch: 3
2023-01-05 15:31:01,885 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4527912219365438, 'Total loss': 0.4527912219365438} | train loss {'Reaction outcome loss': 0.5409014172568594, 'Total loss': 0.5409014172568594}
2023-01-05 15:31:01,886 INFO:     Found new best model at epoch 3
2023-01-05 15:31:01,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:01,887 INFO:     Epoch: 4
2023-01-05 15:31:04,038 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4321971356868744, 'Total loss': 0.4321971356868744} | train loss {'Reaction outcome loss': 0.513342195848489, 'Total loss': 0.513342195848489}
2023-01-05 15:31:04,038 INFO:     Found new best model at epoch 4
2023-01-05 15:31:04,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:04,039 INFO:     Epoch: 5
2023-01-05 15:31:06,012 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4569656352202098, 'Total loss': 0.4569656352202098} | train loss {'Reaction outcome loss': 0.505965925199722, 'Total loss': 0.505965925199722}
2023-01-05 15:31:06,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:06,012 INFO:     Epoch: 6
2023-01-05 15:31:08,186 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4507156868775686, 'Total loss': 0.4507156868775686} | train loss {'Reaction outcome loss': 0.491077669126832, 'Total loss': 0.491077669126832}
2023-01-05 15:31:08,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:08,187 INFO:     Epoch: 7
2023-01-05 15:31:10,357 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4366661548614502, 'Total loss': 0.4366661548614502} | train loss {'Reaction outcome loss': 0.4860049315493729, 'Total loss': 0.4860049315493729}
2023-01-05 15:31:10,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:10,357 INFO:     Epoch: 8
2023-01-05 15:31:12,505 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4457446912924449, 'Total loss': 0.4457446912924449} | train loss {'Reaction outcome loss': 0.4807199004875577, 'Total loss': 0.4807199004875577}
2023-01-05 15:31:12,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:12,506 INFO:     Epoch: 9
2023-01-05 15:31:14,643 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40600013683239616, 'Total loss': 0.40600013683239616} | train loss {'Reaction outcome loss': 0.47545756675236733, 'Total loss': 0.47545756675236733}
2023-01-05 15:31:14,643 INFO:     Found new best model at epoch 9
2023-01-05 15:31:14,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:14,644 INFO:     Epoch: 10
2023-01-05 15:31:16,785 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4009945938984553, 'Total loss': 0.4009945938984553} | train loss {'Reaction outcome loss': 0.4664746135847805, 'Total loss': 0.4664746135847805}
2023-01-05 15:31:16,785 INFO:     Found new best model at epoch 10
2023-01-05 15:31:16,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:16,787 INFO:     Epoch: 11
2023-01-05 15:31:18,951 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39274748172610996, 'Total loss': 0.39274748172610996} | train loss {'Reaction outcome loss': 0.4629660149010411, 'Total loss': 0.4629660149010411}
2023-01-05 15:31:18,952 INFO:     Found new best model at epoch 11
2023-01-05 15:31:18,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:18,953 INFO:     Epoch: 12
2023-01-05 15:31:21,129 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3906263917684555, 'Total loss': 0.3906263917684555} | train loss {'Reaction outcome loss': 0.4565068966560606, 'Total loss': 0.4565068966560606}
2023-01-05 15:31:21,130 INFO:     Found new best model at epoch 12
2023-01-05 15:31:21,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:21,131 INFO:     Epoch: 13
2023-01-05 15:31:23,301 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43361458778381345, 'Total loss': 0.43361458778381345} | train loss {'Reaction outcome loss': 0.48089087076917075, 'Total loss': 0.48089087076917075}
2023-01-05 15:31:23,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:23,301 INFO:     Epoch: 14
2023-01-05 15:31:25,474 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38833217819531757, 'Total loss': 0.38833217819531757} | train loss {'Reaction outcome loss': 0.44613365518634435, 'Total loss': 0.44613365518634435}
2023-01-05 15:31:25,474 INFO:     Found new best model at epoch 14
2023-01-05 15:31:25,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:25,475 INFO:     Epoch: 15
2023-01-05 15:31:27,643 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39274570445219675, 'Total loss': 0.39274570445219675} | train loss {'Reaction outcome loss': 0.44842784256299795, 'Total loss': 0.44842784256299795}
2023-01-05 15:31:27,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:27,644 INFO:     Epoch: 16
2023-01-05 15:31:29,815 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3963132361570994, 'Total loss': 0.3963132361570994} | train loss {'Reaction outcome loss': 0.43927854472185834, 'Total loss': 0.43927854472185834}
2023-01-05 15:31:29,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:29,815 INFO:     Epoch: 17
2023-01-05 15:31:31,953 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40405457019805907, 'Total loss': 0.40405457019805907} | train loss {'Reaction outcome loss': 0.4389076078887624, 'Total loss': 0.4389076078887624}
2023-01-05 15:31:31,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:31,953 INFO:     Epoch: 18
2023-01-05 15:31:34,099 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3845044319828351, 'Total loss': 0.3845044319828351} | train loss {'Reaction outcome loss': 0.4335994494554209, 'Total loss': 0.4335994494554209}
2023-01-05 15:31:34,099 INFO:     Found new best model at epoch 18
2023-01-05 15:31:34,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:34,101 INFO:     Epoch: 19
2023-01-05 15:31:36,264 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.372158286968867, 'Total loss': 0.372158286968867} | train loss {'Reaction outcome loss': 0.4255266203659973, 'Total loss': 0.4255266203659973}
2023-01-05 15:31:36,264 INFO:     Found new best model at epoch 19
2023-01-05 15:31:36,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:36,265 INFO:     Epoch: 20
2023-01-05 15:31:38,429 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3834015836318334, 'Total loss': 0.3834015836318334} | train loss {'Reaction outcome loss': 0.41834862552502233, 'Total loss': 0.41834862552502233}
2023-01-05 15:31:38,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:38,430 INFO:     Epoch: 21
2023-01-05 15:31:40,591 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4061894615491231, 'Total loss': 0.4061894615491231} | train loss {'Reaction outcome loss': 0.4184532101819481, 'Total loss': 0.4184532101819481}
2023-01-05 15:31:40,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:40,592 INFO:     Epoch: 22
2023-01-05 15:31:42,763 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3893819600343704, 'Total loss': 0.3893819600343704} | train loss {'Reaction outcome loss': 0.43739199600573897, 'Total loss': 0.43739199600573897}
2023-01-05 15:31:42,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:42,764 INFO:     Epoch: 23
2023-01-05 15:31:44,914 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3814679443836212, 'Total loss': 0.3814679443836212} | train loss {'Reaction outcome loss': 0.45524403658034146, 'Total loss': 0.45524403658034146}
2023-01-05 15:31:44,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:44,915 INFO:     Epoch: 24
2023-01-05 15:31:47,072 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3973536213239034, 'Total loss': 0.3973536213239034} | train loss {'Reaction outcome loss': 0.42467644027825713, 'Total loss': 0.42467644027825713}
2023-01-05 15:31:47,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:47,072 INFO:     Epoch: 25
2023-01-05 15:31:49,228 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.37538992961247764, 'Total loss': 0.37538992961247764} | train loss {'Reaction outcome loss': 0.41230682017740566, 'Total loss': 0.41230682017740566}
2023-01-05 15:31:49,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:49,228 INFO:     Epoch: 26
2023-01-05 15:31:51,387 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3761594116687775, 'Total loss': 0.3761594116687775} | train loss {'Reaction outcome loss': 0.4280129126340583, 'Total loss': 0.4280129126340583}
2023-01-05 15:31:51,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:51,387 INFO:     Epoch: 27
2023-01-05 15:31:53,544 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.368565892179807, 'Total loss': 0.368565892179807} | train loss {'Reaction outcome loss': 0.4075839403692795, 'Total loss': 0.4075839403692795}
2023-01-05 15:31:53,544 INFO:     Found new best model at epoch 27
2023-01-05 15:31:53,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:53,545 INFO:     Epoch: 28
2023-01-05 15:31:55,708 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.37243958512941994, 'Total loss': 0.37243958512941994} | train loss {'Reaction outcome loss': 0.4049302129196408, 'Total loss': 0.4049302129196408}
2023-01-05 15:31:55,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:55,709 INFO:     Epoch: 29
2023-01-05 15:31:57,845 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3838213006655375, 'Total loss': 0.3838213006655375} | train loss {'Reaction outcome loss': 0.3932757444541256, 'Total loss': 0.3932757444541256}
2023-01-05 15:31:57,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:31:57,846 INFO:     Epoch: 30
2023-01-05 15:32:00,011 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.36936047971248626, 'Total loss': 0.36936047971248626} | train loss {'Reaction outcome loss': 0.3912523408991705, 'Total loss': 0.3912523408991705}
2023-01-05 15:32:00,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:00,011 INFO:     Epoch: 31
2023-01-05 15:32:02,190 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3728894849618276, 'Total loss': 0.3728894849618276} | train loss {'Reaction outcome loss': 0.38404645837600465, 'Total loss': 0.38404645837600465}
2023-01-05 15:32:02,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:02,191 INFO:     Epoch: 32
2023-01-05 15:32:04,386 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3765982687473297, 'Total loss': 0.3765982687473297} | train loss {'Reaction outcome loss': 0.38208607599296124, 'Total loss': 0.38208607599296124}
2023-01-05 15:32:04,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:04,386 INFO:     Epoch: 33
2023-01-05 15:32:06,564 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.34090054258704183, 'Total loss': 0.34090054258704183} | train loss {'Reaction outcome loss': 0.37833075757320644, 'Total loss': 0.37833075757320644}
2023-01-05 15:32:06,564 INFO:     Found new best model at epoch 33
2023-01-05 15:32:06,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:06,565 INFO:     Epoch: 34
2023-01-05 15:32:08,743 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37468962619702023, 'Total loss': 0.37468962619702023} | train loss {'Reaction outcome loss': 0.38013141435879766, 'Total loss': 0.38013141435879766}
2023-01-05 15:32:08,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:08,744 INFO:     Epoch: 35
2023-01-05 15:32:10,930 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.37131144205729166, 'Total loss': 0.37131144205729166} | train loss {'Reaction outcome loss': 0.3770579618226359, 'Total loss': 0.3770579618226359}
2023-01-05 15:32:10,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:10,930 INFO:     Epoch: 36
2023-01-05 15:32:13,086 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3452971627314885, 'Total loss': 0.3452971627314885} | train loss {'Reaction outcome loss': 0.37238041974036395, 'Total loss': 0.37238041974036395}
2023-01-05 15:32:13,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:13,086 INFO:     Epoch: 37
2023-01-05 15:32:15,254 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37401556770006816, 'Total loss': 0.37401556770006816} | train loss {'Reaction outcome loss': 0.3781636707430732, 'Total loss': 0.3781636707430732}
2023-01-05 15:32:15,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:15,255 INFO:     Epoch: 38
2023-01-05 15:32:17,444 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3433404644330343, 'Total loss': 0.3433404644330343} | train loss {'Reaction outcome loss': 0.37871071933161304, 'Total loss': 0.37871071933161304}
2023-01-05 15:32:17,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:17,444 INFO:     Epoch: 39
2023-01-05 15:32:19,640 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3542185425758362, 'Total loss': 0.3542185425758362} | train loss {'Reaction outcome loss': 0.3762255405764217, 'Total loss': 0.3762255405764217}
2023-01-05 15:32:19,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:19,640 INFO:     Epoch: 40
2023-01-05 15:32:21,802 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3635366668303808, 'Total loss': 0.3635366668303808} | train loss {'Reaction outcome loss': 0.36525160967911413, 'Total loss': 0.36525160967911413}
2023-01-05 15:32:21,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:21,802 INFO:     Epoch: 41
2023-01-05 15:32:23,949 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3300001223882039, 'Total loss': 0.3300001223882039} | train loss {'Reaction outcome loss': 0.35919966497137956, 'Total loss': 0.35919966497137956}
2023-01-05 15:32:23,949 INFO:     Found new best model at epoch 41
2023-01-05 15:32:23,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:23,951 INFO:     Epoch: 42
2023-01-05 15:32:26,104 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39717336346705756, 'Total loss': 0.39717336346705756} | train loss {'Reaction outcome loss': 0.3494698160515248, 'Total loss': 0.3494698160515248}
2023-01-05 15:32:26,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:26,104 INFO:     Epoch: 43
2023-01-05 15:32:28,262 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3401519298553467, 'Total loss': 0.3401519298553467} | train loss {'Reaction outcome loss': 0.3475256703826006, 'Total loss': 0.3475256703826006}
2023-01-05 15:32:28,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:28,263 INFO:     Epoch: 44
2023-01-05 15:32:30,428 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.35470692018667854, 'Total loss': 0.35470692018667854} | train loss {'Reaction outcome loss': 0.3563638401312241, 'Total loss': 0.3563638401312241}
2023-01-05 15:32:30,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:30,429 INFO:     Epoch: 45
2023-01-05 15:32:32,591 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3650073071320852, 'Total loss': 0.3650073071320852} | train loss {'Reaction outcome loss': 0.3473888981798023, 'Total loss': 0.3473888981798023}
2023-01-05 15:32:32,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:32,591 INFO:     Epoch: 46
2023-01-05 15:32:34,750 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.34283563097318015, 'Total loss': 0.34283563097318015} | train loss {'Reaction outcome loss': 0.34376739070366835, 'Total loss': 0.34376739070366835}
2023-01-05 15:32:34,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:34,751 INFO:     Epoch: 47
2023-01-05 15:32:36,879 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38137084046999614, 'Total loss': 0.38137084046999614} | train loss {'Reaction outcome loss': 0.3364580425938281, 'Total loss': 0.3364580425938281}
2023-01-05 15:32:36,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:36,879 INFO:     Epoch: 48
2023-01-05 15:32:39,008 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.36981134017308553, 'Total loss': 0.36981134017308553} | train loss {'Reaction outcome loss': 0.3323978532689514, 'Total loss': 0.3323978532689514}
2023-01-05 15:32:39,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:39,009 INFO:     Epoch: 49
2023-01-05 15:32:41,182 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3294592579205831, 'Total loss': 0.3294592579205831} | train loss {'Reaction outcome loss': 0.3339928223994439, 'Total loss': 0.3339928223994439}
2023-01-05 15:32:41,182 INFO:     Found new best model at epoch 49
2023-01-05 15:32:41,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:41,184 INFO:     Epoch: 50
2023-01-05 15:32:43,355 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3466545273860296, 'Total loss': 0.3466545273860296} | train loss {'Reaction outcome loss': 0.33044750567194936, 'Total loss': 0.33044750567194936}
2023-01-05 15:32:43,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:43,355 INFO:     Epoch: 51
2023-01-05 15:32:45,501 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.34629061023394264, 'Total loss': 0.34629061023394264} | train loss {'Reaction outcome loss': 0.32640361824356345, 'Total loss': 0.32640361824356345}
2023-01-05 15:32:45,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:45,502 INFO:     Epoch: 52
2023-01-05 15:32:47,637 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3806947499513626, 'Total loss': 0.3806947499513626} | train loss {'Reaction outcome loss': 0.33042218395090406, 'Total loss': 0.33042218395090406}
2023-01-05 15:32:47,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:47,637 INFO:     Epoch: 53
2023-01-05 15:32:49,756 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36807634830474856, 'Total loss': 0.36807634830474856} | train loss {'Reaction outcome loss': 0.3292802654306296, 'Total loss': 0.3292802654306296}
2023-01-05 15:32:49,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:49,756 INFO:     Epoch: 54
2023-01-05 15:32:51,900 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3497747759024302, 'Total loss': 0.3497747759024302} | train loss {'Reaction outcome loss': 0.32330399747192184, 'Total loss': 0.32330399747192184}
2023-01-05 15:32:51,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:51,901 INFO:     Epoch: 55
2023-01-05 15:32:54,030 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3915501654148102, 'Total loss': 0.3915501654148102} | train loss {'Reaction outcome loss': 0.32313126690037874, 'Total loss': 0.32313126690037874}
2023-01-05 15:32:54,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:54,030 INFO:     Epoch: 56
2023-01-05 15:32:56,161 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.35870490968227386, 'Total loss': 0.35870490968227386} | train loss {'Reaction outcome loss': 0.32035242981277634, 'Total loss': 0.32035242981277634}
2023-01-05 15:32:56,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:56,161 INFO:     Epoch: 57
2023-01-05 15:32:58,331 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.36964512169361113, 'Total loss': 0.36964512169361113} | train loss {'Reaction outcome loss': 0.31674705193364533, 'Total loss': 0.31674705193364533}
2023-01-05 15:32:58,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:32:58,332 INFO:     Epoch: 58
2023-01-05 15:33:00,489 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.31442246238390603, 'Total loss': 0.31442246238390603} | train loss {'Reaction outcome loss': 0.31576007419916213, 'Total loss': 0.31576007419916213}
2023-01-05 15:33:00,490 INFO:     Found new best model at epoch 58
2023-01-05 15:33:00,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:00,491 INFO:     Epoch: 59
2023-01-05 15:33:02,626 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3516132141153018, 'Total loss': 0.3516132141153018} | train loss {'Reaction outcome loss': 0.31075655773580974, 'Total loss': 0.31075655773580974}
2023-01-05 15:33:02,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:02,626 INFO:     Epoch: 60
2023-01-05 15:33:04,767 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.34981742799282073, 'Total loss': 0.34981742799282073} | train loss {'Reaction outcome loss': 0.31403050901017326, 'Total loss': 0.31403050901017326}
2023-01-05 15:33:04,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:04,768 INFO:     Epoch: 61
2023-01-05 15:33:06,903 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.350184757510821, 'Total loss': 0.350184757510821} | train loss {'Reaction outcome loss': 0.30451620406518853, 'Total loss': 0.30451620406518853}
2023-01-05 15:33:06,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:06,903 INFO:     Epoch: 62
2023-01-05 15:33:09,060 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3420506512125333, 'Total loss': 0.3420506512125333} | train loss {'Reaction outcome loss': 0.30817291885052883, 'Total loss': 0.30817291885052883}
2023-01-05 15:33:09,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:09,060 INFO:     Epoch: 63
2023-01-05 15:33:11,232 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3527635306119919, 'Total loss': 0.3527635306119919} | train loss {'Reaction outcome loss': 0.2985770508298035, 'Total loss': 0.2985770508298035}
2023-01-05 15:33:11,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:11,232 INFO:     Epoch: 64
2023-01-05 15:33:13,377 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.34399468898773194, 'Total loss': 0.34399468898773194} | train loss {'Reaction outcome loss': 0.29616874617721, 'Total loss': 0.29616874617721}
2023-01-05 15:33:13,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:13,377 INFO:     Epoch: 65
2023-01-05 15:33:15,528 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3542961766322454, 'Total loss': 0.3542961766322454} | train loss {'Reaction outcome loss': 0.29716505671756854, 'Total loss': 0.29716505671756854}
2023-01-05 15:33:15,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:15,529 INFO:     Epoch: 66
2023-01-05 15:33:17,671 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3075320969025294, 'Total loss': 0.3075320969025294} | train loss {'Reaction outcome loss': 0.29651534785955225, 'Total loss': 0.29651534785955225}
2023-01-05 15:33:17,671 INFO:     Found new best model at epoch 66
2023-01-05 15:33:17,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:17,672 INFO:     Epoch: 67
2023-01-05 15:33:19,812 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3186302989721298, 'Total loss': 0.3186302989721298} | train loss {'Reaction outcome loss': 0.2965673166352486, 'Total loss': 0.2965673166352486}
2023-01-05 15:33:19,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:19,812 INFO:     Epoch: 68
2023-01-05 15:33:21,967 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.383771026134491, 'Total loss': 0.383771026134491} | train loss {'Reaction outcome loss': 0.2971732489599347, 'Total loss': 0.2971732489599347}
2023-01-05 15:33:21,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:21,968 INFO:     Epoch: 69
2023-01-05 15:33:24,108 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3412522887190183, 'Total loss': 0.3412522887190183} | train loss {'Reaction outcome loss': 0.2963704637041319, 'Total loss': 0.2963704637041319}
2023-01-05 15:33:24,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:24,109 INFO:     Epoch: 70
2023-01-05 15:33:26,258 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.33472060759862265, 'Total loss': 0.33472060759862265} | train loss {'Reaction outcome loss': 0.28884422667054593, 'Total loss': 0.28884422667054593}
2023-01-05 15:33:26,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:26,258 INFO:     Epoch: 71
2023-01-05 15:33:28,405 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3901497741540273, 'Total loss': 0.3901497741540273} | train loss {'Reaction outcome loss': 0.2887759174935628, 'Total loss': 0.2887759174935628}
2023-01-05 15:33:28,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:28,405 INFO:     Epoch: 72
2023-01-05 15:33:30,561 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.36122071047623955, 'Total loss': 0.36122071047623955} | train loss {'Reaction outcome loss': 0.30238494212634565, 'Total loss': 0.30238494212634565}
2023-01-05 15:33:30,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:30,561 INFO:     Epoch: 73
2023-01-05 15:33:32,717 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.30430172582467396, 'Total loss': 0.30430172582467396} | train loss {'Reaction outcome loss': 0.282144052335871, 'Total loss': 0.282144052335871}
2023-01-05 15:33:32,718 INFO:     Found new best model at epoch 73
2023-01-05 15:33:32,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:32,719 INFO:     Epoch: 74
2023-01-05 15:33:34,870 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.28646486562987167, 'Total loss': 0.28646486562987167} | train loss {'Reaction outcome loss': 0.2798169519276111, 'Total loss': 0.2798169519276111}
2023-01-05 15:33:34,871 INFO:     Found new best model at epoch 74
2023-01-05 15:33:34,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:34,872 INFO:     Epoch: 75
2023-01-05 15:33:37,032 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3905250589052836, 'Total loss': 0.3905250589052836} | train loss {'Reaction outcome loss': 0.2809073883408829, 'Total loss': 0.2809073883408829}
2023-01-05 15:33:37,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:37,032 INFO:     Epoch: 76
2023-01-05 15:33:39,192 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3322168121735255, 'Total loss': 0.3322168121735255} | train loss {'Reaction outcome loss': 0.27883992538503977, 'Total loss': 0.27883992538503977}
2023-01-05 15:33:39,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:39,192 INFO:     Epoch: 77
2023-01-05 15:33:41,340 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3534978887687127, 'Total loss': 0.3534978887687127} | train loss {'Reaction outcome loss': 0.273330567623961, 'Total loss': 0.273330567623961}
2023-01-05 15:33:41,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:41,340 INFO:     Epoch: 78
2023-01-05 15:33:43,482 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3189807817339897, 'Total loss': 0.3189807817339897} | train loss {'Reaction outcome loss': 0.2759284179900651, 'Total loss': 0.2759284179900651}
2023-01-05 15:33:43,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:43,482 INFO:     Epoch: 79
2023-01-05 15:33:45,616 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3370226711034775, 'Total loss': 0.3370226711034775} | train loss {'Reaction outcome loss': 0.27172437961216667, 'Total loss': 0.27172437961216667}
2023-01-05 15:33:45,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:45,618 INFO:     Epoch: 80
2023-01-05 15:33:47,768 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.33928120136260986, 'Total loss': 0.33928120136260986} | train loss {'Reaction outcome loss': 0.27563419850480714, 'Total loss': 0.27563419850480714}
2023-01-05 15:33:47,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:47,768 INFO:     Epoch: 81
2023-01-05 15:33:49,902 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.2994495635231336, 'Total loss': 0.2994495635231336} | train loss {'Reaction outcome loss': 0.2682619629979498, 'Total loss': 0.2682619629979498}
2023-01-05 15:33:49,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:49,902 INFO:     Epoch: 82
2023-01-05 15:33:52,059 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36091391295194625, 'Total loss': 0.36091391295194625} | train loss {'Reaction outcome loss': 0.26876914598055324, 'Total loss': 0.26876914598055324}
2023-01-05 15:33:52,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:52,060 INFO:     Epoch: 83
2023-01-05 15:33:54,190 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.330060701072216, 'Total loss': 0.330060701072216} | train loss {'Reaction outcome loss': 0.26614059762948233, 'Total loss': 0.26614059762948233}
2023-01-05 15:33:54,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:54,190 INFO:     Epoch: 84
2023-01-05 15:33:56,358 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.30653757105271023, 'Total loss': 0.30653757105271023} | train loss {'Reaction outcome loss': 0.2602281199968116, 'Total loss': 0.2602281199968116}
2023-01-05 15:33:56,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:56,358 INFO:     Epoch: 85
2023-01-05 15:33:58,491 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3519986639420191, 'Total loss': 0.3519986639420191} | train loss {'Reaction outcome loss': 0.2582601412347909, 'Total loss': 0.2582601412347909}
2023-01-05 15:33:58,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:33:58,491 INFO:     Epoch: 86
2023-01-05 15:34:00,645 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3409162739912669, 'Total loss': 0.3409162739912669} | train loss {'Reaction outcome loss': 0.26676857454720815, 'Total loss': 0.26676857454720815}
2023-01-05 15:34:00,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:00,645 INFO:     Epoch: 87
2023-01-05 15:34:02,905 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.33031327078739803, 'Total loss': 0.33031327078739803} | train loss {'Reaction outcome loss': 0.2621635909030295, 'Total loss': 0.2621635909030295}
2023-01-05 15:34:02,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:02,905 INFO:     Epoch: 88
2023-01-05 15:34:05,182 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3777749841411909, 'Total loss': 0.3777749841411909} | train loss {'Reaction outcome loss': 0.26781227038683963, 'Total loss': 0.26781227038683963}
2023-01-05 15:34:05,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:05,183 INFO:     Epoch: 89
2023-01-05 15:34:07,433 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3561592529217402, 'Total loss': 0.3561592529217402} | train loss {'Reaction outcome loss': 0.2634229691854368, 'Total loss': 0.2634229691854368}
2023-01-05 15:34:07,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:07,433 INFO:     Epoch: 90
2023-01-05 15:34:09,634 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3266029700636864, 'Total loss': 0.3266029700636864} | train loss {'Reaction outcome loss': 0.25913250898146, 'Total loss': 0.25913250898146}
2023-01-05 15:34:09,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:09,634 INFO:     Epoch: 91
2023-01-05 15:34:11,816 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3388932079076767, 'Total loss': 0.3388932079076767} | train loss {'Reaction outcome loss': 0.25841213991478307, 'Total loss': 0.25841213991478307}
2023-01-05 15:34:11,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:11,816 INFO:     Epoch: 92
2023-01-05 15:34:13,993 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.35069866850972176, 'Total loss': 0.35069866850972176} | train loss {'Reaction outcome loss': 0.2531780203892107, 'Total loss': 0.2531780203892107}
2023-01-05 15:34:13,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:13,993 INFO:     Epoch: 93
2023-01-05 15:34:16,145 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.35327542076508206, 'Total loss': 0.35327542076508206} | train loss {'Reaction outcome loss': 0.26785340945344366, 'Total loss': 0.26785340945344366}
2023-01-05 15:34:16,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:16,145 INFO:     Epoch: 94
2023-01-05 15:34:18,281 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.37850265701611835, 'Total loss': 0.37850265701611835} | train loss {'Reaction outcome loss': 0.2567651456498635, 'Total loss': 0.2567651456498635}
2023-01-05 15:34:18,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:18,281 INFO:     Epoch: 95
2023-01-05 15:34:20,428 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.32204821010430656, 'Total loss': 0.32204821010430656} | train loss {'Reaction outcome loss': 0.2523576921910295, 'Total loss': 0.2523576921910295}
2023-01-05 15:34:20,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:20,429 INFO:     Epoch: 96
2023-01-05 15:34:22,600 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.36885408957799276, 'Total loss': 0.36885408957799276} | train loss {'Reaction outcome loss': 0.2568384132034186, 'Total loss': 0.2568384132034186}
2023-01-05 15:34:22,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:22,600 INFO:     Epoch: 97
2023-01-05 15:34:24,769 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3497286528348923, 'Total loss': 0.3497286528348923} | train loss {'Reaction outcome loss': 0.2493104401474488, 'Total loss': 0.2493104401474488}
2023-01-05 15:34:24,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:24,769 INFO:     Epoch: 98
2023-01-05 15:34:26,934 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3602933719754219, 'Total loss': 0.3602933719754219} | train loss {'Reaction outcome loss': 0.25577242817540746, 'Total loss': 0.25577242817540746}
2023-01-05 15:34:26,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:26,935 INFO:     Epoch: 99
2023-01-05 15:34:29,097 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.34406286080678306, 'Total loss': 0.34406286080678306} | train loss {'Reaction outcome loss': 0.24828216552977328, 'Total loss': 0.24828216552977328}
2023-01-05 15:34:29,097 INFO:     Best model found after epoch 75 of 100.
2023-01-05 15:34:29,097 INFO:   Done with stage: TRAINING
2023-01-05 15:34:29,097 INFO:   Starting stage: EVALUATION
2023-01-05 15:34:29,231 INFO:   Done with stage: EVALUATION
2023-01-05 15:34:29,231 INFO:   Leaving out SEQ value Fold_2
2023-01-05 15:34:29,244 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-05 15:34:29,244 INFO:   Starting stage: FEATURE SCALING
2023-01-05 15:34:29,886 INFO:   Done with stage: FEATURE SCALING
2023-01-05 15:34:29,886 INFO:   Starting stage: SCALING TARGETS
2023-01-05 15:34:29,955 INFO:   Done with stage: SCALING TARGETS
2023-01-05 15:34:29,955 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:34:29,955 INFO:     No hyperparam tuning for this model
2023-01-05 15:34:29,955 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:34:29,955 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 15:34:29,956 INFO:     None feature selector for col prot
2023-01-05 15:34:29,956 INFO:     None feature selector for col prot
2023-01-05 15:34:29,956 INFO:     None feature selector for col prot
2023-01-05 15:34:29,957 INFO:     None feature selector for col chem
2023-01-05 15:34:29,957 INFO:     None feature selector for col chem
2023-01-05 15:34:29,957 INFO:     None feature selector for col chem
2023-01-05 15:34:29,957 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 15:34:29,957 INFO:   Starting stage: BUILD MODEL
2023-01-05 15:34:29,959 INFO:     Number of params in model 72901
2023-01-05 15:34:29,962 INFO:   Done with stage: BUILD MODEL
2023-01-05 15:34:29,962 INFO:   Starting stage: TRAINING
2023-01-05 15:34:30,008 INFO:     Val loss before train {'Reaction outcome loss': 0.995511598388354, 'Total loss': 0.995511598388354}
2023-01-05 15:34:30,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:30,009 INFO:     Epoch: 0
2023-01-05 15:34:31,745 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8950274050235748, 'Total loss': 0.8950274050235748} | train loss {'Reaction outcome loss': 0.9509939886767046, 'Total loss': 0.9509939886767046}
2023-01-05 15:34:31,745 INFO:     Found new best model at epoch 0
2023-01-05 15:34:31,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:31,747 INFO:     Epoch: 1
2023-01-05 15:34:33,492 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.648714957634608, 'Total loss': 0.648714957634608} | train loss {'Reaction outcome loss': 0.7725729269295161, 'Total loss': 0.7725729269295161}
2023-01-05 15:34:33,492 INFO:     Found new best model at epoch 1
2023-01-05 15:34:33,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:33,493 INFO:     Epoch: 2
2023-01-05 15:34:35,501 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5432024866342544, 'Total loss': 0.5432024866342544} | train loss {'Reaction outcome loss': 0.6057625341459394, 'Total loss': 0.6057625341459394}
2023-01-05 15:34:35,501 INFO:     Found new best model at epoch 2
2023-01-05 15:34:35,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:35,503 INFO:     Epoch: 3
2023-01-05 15:34:37,626 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48368109464645387, 'Total loss': 0.48368109464645387} | train loss {'Reaction outcome loss': 0.5409200094172876, 'Total loss': 0.5409200094172876}
2023-01-05 15:34:37,626 INFO:     Found new best model at epoch 3
2023-01-05 15:34:37,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:37,627 INFO:     Epoch: 4
2023-01-05 15:34:39,722 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.558557923634847, 'Total loss': 0.558557923634847} | train loss {'Reaction outcome loss': 0.5172709239255018, 'Total loss': 0.5172709239255018}
2023-01-05 15:34:39,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:39,723 INFO:     Epoch: 5
2023-01-05 15:34:41,809 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47978219389915466, 'Total loss': 0.47978219389915466} | train loss {'Reaction outcome loss': 0.5054769768926051, 'Total loss': 0.5054769768926051}
2023-01-05 15:34:41,809 INFO:     Found new best model at epoch 5
2023-01-05 15:34:41,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:41,810 INFO:     Epoch: 6
2023-01-05 15:34:43,909 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4973082780838013, 'Total loss': 0.4973082780838013} | train loss {'Reaction outcome loss': 0.49382433652657864, 'Total loss': 0.49382433652657864}
2023-01-05 15:34:43,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:43,909 INFO:     Epoch: 7
2023-01-05 15:34:45,990 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4760791470607122, 'Total loss': 0.4760791470607122} | train loss {'Reaction outcome loss': 0.4878040298379655, 'Total loss': 0.4878040298379655}
2023-01-05 15:34:45,991 INFO:     Found new best model at epoch 7
2023-01-05 15:34:45,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:45,992 INFO:     Epoch: 8
2023-01-05 15:34:48,096 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46078834012150766, 'Total loss': 0.46078834012150766} | train loss {'Reaction outcome loss': 0.4854807419860495, 'Total loss': 0.4854807419860495}
2023-01-05 15:34:48,096 INFO:     Found new best model at epoch 8
2023-01-05 15:34:48,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:48,098 INFO:     Epoch: 9
2023-01-05 15:34:50,196 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5206238130728403, 'Total loss': 0.5206238130728403} | train loss {'Reaction outcome loss': 0.48025021990726796, 'Total loss': 0.48025021990726796}
2023-01-05 15:34:50,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:50,197 INFO:     Epoch: 10
2023-01-05 15:34:52,310 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5153269420067469, 'Total loss': 0.5153269420067469} | train loss {'Reaction outcome loss': 0.4752380446534315, 'Total loss': 0.4752380446534315}
2023-01-05 15:34:52,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:52,311 INFO:     Epoch: 11
2023-01-05 15:34:54,395 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4593800683816274, 'Total loss': 0.4593800683816274} | train loss {'Reaction outcome loss': 0.4645383776443911, 'Total loss': 0.4645383776443911}
2023-01-05 15:34:54,395 INFO:     Found new best model at epoch 11
2023-01-05 15:34:54,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:54,396 INFO:     Epoch: 12
2023-01-05 15:34:56,495 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4690582970778147, 'Total loss': 0.4690582970778147} | train loss {'Reaction outcome loss': 0.46613905191201566, 'Total loss': 0.46613905191201566}
2023-01-05 15:34:56,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:56,496 INFO:     Epoch: 13
2023-01-05 15:34:58,588 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4596738616625468, 'Total loss': 0.4596738616625468} | train loss {'Reaction outcome loss': 0.45752789893933327, 'Total loss': 0.45752789893933327}
2023-01-05 15:34:58,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:34:58,589 INFO:     Epoch: 14
2023-01-05 15:35:00,704 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.468367862701416, 'Total loss': 0.468367862701416} | train loss {'Reaction outcome loss': 0.45491687128684616, 'Total loss': 0.45491687128684616}
2023-01-05 15:35:00,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:00,704 INFO:     Epoch: 15
2023-01-05 15:35:02,788 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4332153481741746, 'Total loss': 0.4332153481741746} | train loss {'Reaction outcome loss': 0.44565636271480263, 'Total loss': 0.44565636271480263}
2023-01-05 15:35:02,789 INFO:     Found new best model at epoch 15
2023-01-05 15:35:02,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:02,790 INFO:     Epoch: 16
2023-01-05 15:35:04,866 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4438897788524628, 'Total loss': 0.4438897788524628} | train loss {'Reaction outcome loss': 0.4479848043615088, 'Total loss': 0.4479848043615088}
2023-01-05 15:35:04,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:04,866 INFO:     Epoch: 17
2023-01-05 15:35:06,967 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4292296717564265, 'Total loss': 0.4292296717564265} | train loss {'Reaction outcome loss': 0.4389224200341095, 'Total loss': 0.4389224200341095}
2023-01-05 15:35:06,967 INFO:     Found new best model at epoch 17
2023-01-05 15:35:06,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:06,969 INFO:     Epoch: 18
2023-01-05 15:35:09,055 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46604100316762925, 'Total loss': 0.46604100316762925} | train loss {'Reaction outcome loss': 0.44079687314389815, 'Total loss': 0.44079687314389815}
2023-01-05 15:35:09,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:09,056 INFO:     Epoch: 19
2023-01-05 15:35:10,976 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4465409696102142, 'Total loss': 0.4465409696102142} | train loss {'Reaction outcome loss': 0.4385063017261424, 'Total loss': 0.4385063017261424}
2023-01-05 15:35:10,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:10,977 INFO:     Epoch: 20
2023-01-05 15:35:13,123 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45560795068740845, 'Total loss': 0.45560795068740845} | train loss {'Reaction outcome loss': 0.4341816662972264, 'Total loss': 0.4341816662972264}
2023-01-05 15:35:13,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:13,123 INFO:     Epoch: 21
2023-01-05 15:35:15,229 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44815191080172856, 'Total loss': 0.44815191080172856} | train loss {'Reaction outcome loss': 0.4278818975955358, 'Total loss': 0.4278818975955358}
2023-01-05 15:35:15,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:15,230 INFO:     Epoch: 22
2023-01-05 15:35:17,345 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41684193033725025, 'Total loss': 0.41684193033725025} | train loss {'Reaction outcome loss': 0.42115677860170275, 'Total loss': 0.42115677860170275}
2023-01-05 15:35:17,345 INFO:     Found new best model at epoch 22
2023-01-05 15:35:17,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:17,347 INFO:     Epoch: 23
2023-01-05 15:35:19,461 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43622927864392597, 'Total loss': 0.43622927864392597} | train loss {'Reaction outcome loss': 0.42114538878092467, 'Total loss': 0.42114538878092467}
2023-01-05 15:35:19,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:19,461 INFO:     Epoch: 24
2023-01-05 15:35:21,571 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4253745446602503, 'Total loss': 0.4253745446602503} | train loss {'Reaction outcome loss': 0.41669795336373616, 'Total loss': 0.41669795336373616}
2023-01-05 15:35:21,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:21,571 INFO:     Epoch: 25
2023-01-05 15:35:23,748 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4606999814510345, 'Total loss': 0.4606999814510345} | train loss {'Reaction outcome loss': 0.4146776582317159, 'Total loss': 0.4146776582317159}
2023-01-05 15:35:23,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:23,748 INFO:     Epoch: 26
2023-01-05 15:35:25,910 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42906626462936404, 'Total loss': 0.42906626462936404} | train loss {'Reaction outcome loss': 0.40872728604672137, 'Total loss': 0.40872728604672137}
2023-01-05 15:35:25,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:25,910 INFO:     Epoch: 27
2023-01-05 15:35:28,001 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4452253689368566, 'Total loss': 0.4452253689368566} | train loss {'Reaction outcome loss': 0.4005510200818526, 'Total loss': 0.4005510200818526}
2023-01-05 15:35:28,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:28,001 INFO:     Epoch: 28
2023-01-05 15:35:30,117 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4320169448852539, 'Total loss': 0.4320169448852539} | train loss {'Reaction outcome loss': 0.4078707321653507, 'Total loss': 0.4078707321653507}
2023-01-05 15:35:30,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:30,117 INFO:     Epoch: 29
2023-01-05 15:35:32,220 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4269200260440508, 'Total loss': 0.4269200260440508} | train loss {'Reaction outcome loss': 0.397382720480106, 'Total loss': 0.397382720480106}
2023-01-05 15:35:32,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:32,222 INFO:     Epoch: 30
2023-01-05 15:35:34,311 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47328390876452126, 'Total loss': 0.47328390876452126} | train loss {'Reaction outcome loss': 0.39814217311649747, 'Total loss': 0.39814217311649747}
2023-01-05 15:35:34,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:34,311 INFO:     Epoch: 31
2023-01-05 15:35:36,427 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44174527525901797, 'Total loss': 0.44174527525901797} | train loss {'Reaction outcome loss': 0.390524726292304, 'Total loss': 0.390524726292304}
2023-01-05 15:35:36,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:36,427 INFO:     Epoch: 32
2023-01-05 15:35:38,531 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4007122983535131, 'Total loss': 0.4007122983535131} | train loss {'Reaction outcome loss': 0.3905089646852764, 'Total loss': 0.3905089646852764}
2023-01-05 15:35:38,532 INFO:     Found new best model at epoch 32
2023-01-05 15:35:38,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:38,534 INFO:     Epoch: 33
2023-01-05 15:35:40,631 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4418038189411163, 'Total loss': 0.4418038189411163} | train loss {'Reaction outcome loss': 0.3798308648801378, 'Total loss': 0.3798308648801378}
2023-01-05 15:35:40,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:40,632 INFO:     Epoch: 34
2023-01-05 15:35:42,744 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4446486920118332, 'Total loss': 0.4446486920118332} | train loss {'Reaction outcome loss': 0.3818457686510693, 'Total loss': 0.3818457686510693}
2023-01-05 15:35:42,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:42,745 INFO:     Epoch: 35
2023-01-05 15:35:44,834 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40060733755429584, 'Total loss': 0.40060733755429584} | train loss {'Reaction outcome loss': 0.3777872970898213, 'Total loss': 0.3777872970898213}
2023-01-05 15:35:44,834 INFO:     Found new best model at epoch 35
2023-01-05 15:35:44,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:44,835 INFO:     Epoch: 36
2023-01-05 15:35:46,951 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4088558167219162, 'Total loss': 0.4088558167219162} | train loss {'Reaction outcome loss': 0.37187561326801116, 'Total loss': 0.37187561326801116}
2023-01-05 15:35:46,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:46,952 INFO:     Epoch: 37
2023-01-05 15:35:49,057 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42929104566574094, 'Total loss': 0.42929104566574094} | train loss {'Reaction outcome loss': 0.3743324242532253, 'Total loss': 0.3743324242532253}
2023-01-05 15:35:49,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:49,058 INFO:     Epoch: 38
2023-01-05 15:35:51,154 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39935479561487836, 'Total loss': 0.39935479561487836} | train loss {'Reaction outcome loss': 0.369042361354476, 'Total loss': 0.369042361354476}
2023-01-05 15:35:51,155 INFO:     Found new best model at epoch 38
2023-01-05 15:35:51,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:51,157 INFO:     Epoch: 39
2023-01-05 15:35:53,277 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3915411447485288, 'Total loss': 0.3915411447485288} | train loss {'Reaction outcome loss': 0.3643535387691976, 'Total loss': 0.3643535387691976}
2023-01-05 15:35:53,277 INFO:     Found new best model at epoch 39
2023-01-05 15:35:53,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:53,279 INFO:     Epoch: 40
2023-01-05 15:35:55,385 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41342816849549613, 'Total loss': 0.41342816849549613} | train loss {'Reaction outcome loss': 0.3625408273286485, 'Total loss': 0.3625408273286485}
2023-01-05 15:35:55,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:55,385 INFO:     Epoch: 41
2023-01-05 15:35:57,511 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4117440715432167, 'Total loss': 0.4117440715432167} | train loss {'Reaction outcome loss': 0.35948250621447264, 'Total loss': 0.35948250621447264}
2023-01-05 15:35:57,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:57,511 INFO:     Epoch: 42
2023-01-05 15:35:59,624 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40993292927742003, 'Total loss': 0.40993292927742003} | train loss {'Reaction outcome loss': 0.3576843656077156, 'Total loss': 0.3576843656077156}
2023-01-05 15:35:59,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:35:59,624 INFO:     Epoch: 43
2023-01-05 15:36:01,723 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42274682919184364, 'Total loss': 0.42274682919184364} | train loss {'Reaction outcome loss': 0.34698650590058183, 'Total loss': 0.34698650590058183}
2023-01-05 15:36:01,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:01,723 INFO:     Epoch: 44
2023-01-05 15:36:03,835 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41461144189039867, 'Total loss': 0.41461144189039867} | train loss {'Reaction outcome loss': 0.3530763117149747, 'Total loss': 0.3530763117149747}
2023-01-05 15:36:03,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:03,835 INFO:     Epoch: 45
2023-01-05 15:36:05,922 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4222161859273911, 'Total loss': 0.4222161859273911} | train loss {'Reaction outcome loss': 0.3425274049224009, 'Total loss': 0.3425274049224009}
2023-01-05 15:36:05,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:05,922 INFO:     Epoch: 46
2023-01-05 15:36:07,998 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37455672522385913, 'Total loss': 0.37455672522385913} | train loss {'Reaction outcome loss': 0.3444215253380392, 'Total loss': 0.3444215253380392}
2023-01-05 15:36:07,999 INFO:     Found new best model at epoch 46
2023-01-05 15:36:08,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:08,001 INFO:     Epoch: 47
2023-01-05 15:36:10,123 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4384642779827118, 'Total loss': 0.4384642779827118} | train loss {'Reaction outcome loss': 0.33987714561919, 'Total loss': 0.33987714561919}
2023-01-05 15:36:10,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:10,124 INFO:     Epoch: 48
2023-01-05 15:36:12,245 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4170969247817993, 'Total loss': 0.4170969247817993} | train loss {'Reaction outcome loss': 0.3316235654743395, 'Total loss': 0.3316235654743395}
2023-01-05 15:36:12,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:12,246 INFO:     Epoch: 49
2023-01-05 15:36:14,354 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43979157507419586, 'Total loss': 0.43979157507419586} | train loss {'Reaction outcome loss': 0.33039155990105273, 'Total loss': 0.33039155990105273}
2023-01-05 15:36:14,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:14,355 INFO:     Epoch: 50
2023-01-05 15:36:16,483 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45313997666041056, 'Total loss': 0.45313997666041056} | train loss {'Reaction outcome loss': 0.33123578356640804, 'Total loss': 0.33123578356640804}
2023-01-05 15:36:16,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:16,484 INFO:     Epoch: 51
2023-01-05 15:36:18,601 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43273644546667733, 'Total loss': 0.43273644546667733} | train loss {'Reaction outcome loss': 0.3302450539042479, 'Total loss': 0.3302450539042479}
2023-01-05 15:36:18,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:18,601 INFO:     Epoch: 52
2023-01-05 15:36:20,689 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43842472732067106, 'Total loss': 0.43842472732067106} | train loss {'Reaction outcome loss': 0.32538498330490173, 'Total loss': 0.32538498330490173}
2023-01-05 15:36:20,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:20,690 INFO:     Epoch: 53
2023-01-05 15:36:22,800 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.409211003780365, 'Total loss': 0.409211003780365} | train loss {'Reaction outcome loss': 0.3309759445405974, 'Total loss': 0.3309759445405974}
2023-01-05 15:36:22,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:22,800 INFO:     Epoch: 54
2023-01-05 15:36:24,925 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40834673841794333, 'Total loss': 0.40834673841794333} | train loss {'Reaction outcome loss': 0.32050495759697417, 'Total loss': 0.32050495759697417}
2023-01-05 15:36:24,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:24,925 INFO:     Epoch: 55
2023-01-05 15:36:27,039 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38413804055502015, 'Total loss': 0.38413804055502015} | train loss {'Reaction outcome loss': 0.32079208353568706, 'Total loss': 0.32079208353568706}
2023-01-05 15:36:27,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:27,040 INFO:     Epoch: 56
2023-01-05 15:36:29,167 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4362197826306025, 'Total loss': 0.4362197826306025} | train loss {'Reaction outcome loss': 0.32000074027676645, 'Total loss': 0.32000074027676645}
2023-01-05 15:36:29,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:29,167 INFO:     Epoch: 57
2023-01-05 15:36:31,275 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41530936658382417, 'Total loss': 0.41530936658382417} | train loss {'Reaction outcome loss': 0.316026908046535, 'Total loss': 0.316026908046535}
2023-01-05 15:36:31,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:31,275 INFO:     Epoch: 58
2023-01-05 15:36:33,360 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3767445902029673, 'Total loss': 0.3767445902029673} | train loss {'Reaction outcome loss': 0.31125740016848397, 'Total loss': 0.31125740016848397}
2023-01-05 15:36:33,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:33,360 INFO:     Epoch: 59
2023-01-05 15:36:35,471 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3869748423496882, 'Total loss': 0.3869748423496882} | train loss {'Reaction outcome loss': 0.31075404914322813, 'Total loss': 0.31075404914322813}
2023-01-05 15:36:35,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:35,472 INFO:     Epoch: 60
2023-01-05 15:36:37,571 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39634519070386887, 'Total loss': 0.39634519070386887} | train loss {'Reaction outcome loss': 0.3055581592600724, 'Total loss': 0.3055581592600724}
2023-01-05 15:36:37,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:37,572 INFO:     Epoch: 61
2023-01-05 15:36:39,677 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38997445106506345, 'Total loss': 0.38997445106506345} | train loss {'Reaction outcome loss': 0.3130658949653161, 'Total loss': 0.3130658949653161}
2023-01-05 15:36:39,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:39,677 INFO:     Epoch: 62
2023-01-05 15:36:41,805 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.382522252202034, 'Total loss': 0.382522252202034} | train loss {'Reaction outcome loss': 0.2984547836094325, 'Total loss': 0.2984547836094325}
2023-01-05 15:36:41,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:41,805 INFO:     Epoch: 63
2023-01-05 15:36:43,892 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4328337813417117, 'Total loss': 0.4328337813417117} | train loss {'Reaction outcome loss': 0.3048452851517174, 'Total loss': 0.3048452851517174}
2023-01-05 15:36:43,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:43,893 INFO:     Epoch: 64
2023-01-05 15:36:46,012 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4112355480591456, 'Total loss': 0.4112355480591456} | train loss {'Reaction outcome loss': 0.29953862356908645, 'Total loss': 0.29953862356908645}
2023-01-05 15:36:46,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:46,013 INFO:     Epoch: 65
2023-01-05 15:36:48,141 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38691330154736836, 'Total loss': 0.38691330154736836} | train loss {'Reaction outcome loss': 0.3012994578541205, 'Total loss': 0.3012994578541205}
2023-01-05 15:36:48,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:48,141 INFO:     Epoch: 66
2023-01-05 15:36:50,270 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39836850861708323, 'Total loss': 0.39836850861708323} | train loss {'Reaction outcome loss': 0.2965614235929018, 'Total loss': 0.2965614235929018}
2023-01-05 15:36:50,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:50,271 INFO:     Epoch: 67
2023-01-05 15:36:52,401 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38363465170065564, 'Total loss': 0.38363465170065564} | train loss {'Reaction outcome loss': 0.29441047972583684, 'Total loss': 0.29441047972583684}
2023-01-05 15:36:52,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:52,402 INFO:     Epoch: 68
2023-01-05 15:36:54,531 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4221210529406865, 'Total loss': 0.4221210529406865} | train loss {'Reaction outcome loss': 0.294039459933434, 'Total loss': 0.294039459933434}
2023-01-05 15:36:54,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:54,531 INFO:     Epoch: 69
2023-01-05 15:36:56,661 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.37576992784937224, 'Total loss': 0.37576992784937224} | train loss {'Reaction outcome loss': 0.29340694347100943, 'Total loss': 0.29340694347100943}
2023-01-05 15:36:56,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:56,661 INFO:     Epoch: 70
2023-01-05 15:36:58,796 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42122030854225156, 'Total loss': 0.42122030854225156} | train loss {'Reaction outcome loss': 0.29326191162381227, 'Total loss': 0.29326191162381227}
2023-01-05 15:36:58,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:36:58,796 INFO:     Epoch: 71
2023-01-05 15:37:00,887 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4178904841343562, 'Total loss': 0.4178904841343562} | train loss {'Reaction outcome loss': 0.29387349625740106, 'Total loss': 0.29387349625740106}
2023-01-05 15:37:00,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:00,887 INFO:     Epoch: 72
2023-01-05 15:37:03,000 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3847641477982203, 'Total loss': 0.3847641477982203} | train loss {'Reaction outcome loss': 0.2804061038577689, 'Total loss': 0.2804061038577689}
2023-01-05 15:37:03,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:03,002 INFO:     Epoch: 73
2023-01-05 15:37:05,114 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4178820570309957, 'Total loss': 0.4178820570309957} | train loss {'Reaction outcome loss': 0.28170538149306695, 'Total loss': 0.28170538149306695}
2023-01-05 15:37:05,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:05,114 INFO:     Epoch: 74
2023-01-05 15:37:07,220 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42879382769266766, 'Total loss': 0.42879382769266766} | train loss {'Reaction outcome loss': 0.28809933567838913, 'Total loss': 0.28809933567838913}
2023-01-05 15:37:07,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:07,221 INFO:     Epoch: 75
2023-01-05 15:37:09,328 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3980767140785853, 'Total loss': 0.3980767140785853} | train loss {'Reaction outcome loss': 0.2906748275117901, 'Total loss': 0.2906748275117901}
2023-01-05 15:37:09,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:09,328 INFO:     Epoch: 76
2023-01-05 15:37:11,399 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3858720431725184, 'Total loss': 0.3858720431725184} | train loss {'Reaction outcome loss': 0.28350728988042617, 'Total loss': 0.28350728988042617}
2023-01-05 15:37:11,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:11,400 INFO:     Epoch: 77
2023-01-05 15:37:13,499 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4287006398042043, 'Total loss': 0.4287006398042043} | train loss {'Reaction outcome loss': 0.2799766009804068, 'Total loss': 0.2799766009804068}
2023-01-05 15:37:13,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:13,499 INFO:     Epoch: 78
2023-01-05 15:37:15,601 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3979341735442479, 'Total loss': 0.3979341735442479} | train loss {'Reaction outcome loss': 0.28211358768308736, 'Total loss': 0.28211358768308736}
2023-01-05 15:37:15,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:15,601 INFO:     Epoch: 79
2023-01-05 15:37:17,735 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4017527570327123, 'Total loss': 0.4017527570327123} | train loss {'Reaction outcome loss': 0.278593395152765, 'Total loss': 0.278593395152765}
2023-01-05 15:37:17,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:17,736 INFO:     Epoch: 80
2023-01-05 15:37:19,830 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3958635846773783, 'Total loss': 0.3958635846773783} | train loss {'Reaction outcome loss': 0.2814181833201504, 'Total loss': 0.2814181833201504}
2023-01-05 15:37:19,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:19,831 INFO:     Epoch: 81
2023-01-05 15:37:21,928 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38441849847634635, 'Total loss': 0.38441849847634635} | train loss {'Reaction outcome loss': 0.2738714268657884, 'Total loss': 0.2738714268657884}
2023-01-05 15:37:21,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:21,928 INFO:     Epoch: 82
2023-01-05 15:37:24,025 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3893891682227453, 'Total loss': 0.3893891682227453} | train loss {'Reaction outcome loss': 0.2735041938584669, 'Total loss': 0.2735041938584669}
2023-01-05 15:37:24,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:24,025 INFO:     Epoch: 83
2023-01-05 15:37:26,150 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37064613699913024, 'Total loss': 0.37064613699913024} | train loss {'Reaction outcome loss': 0.27996644708998086, 'Total loss': 0.27996644708998086}
2023-01-05 15:37:26,151 INFO:     Found new best model at epoch 83
2023-01-05 15:37:26,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:26,152 INFO:     Epoch: 84
2023-01-05 15:37:28,273 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3906738559405009, 'Total loss': 0.3906738559405009} | train loss {'Reaction outcome loss': 0.27079981159954936, 'Total loss': 0.27079981159954936}
2023-01-05 15:37:28,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:28,273 INFO:     Epoch: 85
2023-01-05 15:37:30,397 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.404975500702858, 'Total loss': 0.404975500702858} | train loss {'Reaction outcome loss': 0.26574109761367426, 'Total loss': 0.26574109761367426}
2023-01-05 15:37:30,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:30,397 INFO:     Epoch: 86
2023-01-05 15:37:32,517 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3832066982984543, 'Total loss': 0.3832066982984543} | train loss {'Reaction outcome loss': 0.26840052330295977, 'Total loss': 0.26840052330295977}
2023-01-05 15:37:32,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:32,518 INFO:     Epoch: 87
2023-01-05 15:37:34,639 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3773699725667636, 'Total loss': 0.3773699725667636} | train loss {'Reaction outcome loss': 0.2742511180274161, 'Total loss': 0.2742511180274161}
2023-01-05 15:37:34,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:34,640 INFO:     Epoch: 88
2023-01-05 15:37:36,752 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39015352030595146, 'Total loss': 0.39015352030595146} | train loss {'Reaction outcome loss': 0.2711273837573414, 'Total loss': 0.2711273837573414}
2023-01-05 15:37:36,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:36,752 INFO:     Epoch: 89
2023-01-05 15:37:38,882 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37954374253749845, 'Total loss': 0.37954374253749845} | train loss {'Reaction outcome loss': 0.2605158250050351, 'Total loss': 0.2605158250050351}
2023-01-05 15:37:38,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:38,883 INFO:     Epoch: 90
2023-01-05 15:37:41,014 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38973561724027, 'Total loss': 0.38973561724027} | train loss {'Reaction outcome loss': 0.2601874589617622, 'Total loss': 0.2601874589617622}
2023-01-05 15:37:41,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:41,015 INFO:     Epoch: 91
2023-01-05 15:37:43,114 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.37159653279619914, 'Total loss': 0.37159653279619914} | train loss {'Reaction outcome loss': 0.26199288751132704, 'Total loss': 0.26199288751132704}
2023-01-05 15:37:43,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:43,114 INFO:     Epoch: 92
2023-01-05 15:37:45,232 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3983764628569285, 'Total loss': 0.3983764628569285} | train loss {'Reaction outcome loss': 0.2608198165151246, 'Total loss': 0.2608198165151246}
2023-01-05 15:37:45,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:45,232 INFO:     Epoch: 93
2023-01-05 15:37:47,352 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36262108335892357, 'Total loss': 0.36262108335892357} | train loss {'Reaction outcome loss': 0.25968281304759294, 'Total loss': 0.25968281304759294}
2023-01-05 15:37:47,352 INFO:     Found new best model at epoch 93
2023-01-05 15:37:47,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:47,353 INFO:     Epoch: 94
2023-01-05 15:37:49,469 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3987239534656207, 'Total loss': 0.3987239534656207} | train loss {'Reaction outcome loss': 0.2655448801128187, 'Total loss': 0.2655448801128187}
2023-01-05 15:37:49,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:49,469 INFO:     Epoch: 95
2023-01-05 15:37:51,589 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3784736732641856, 'Total loss': 0.3784736732641856} | train loss {'Reaction outcome loss': 0.26041340415548136, 'Total loss': 0.26041340415548136}
2023-01-05 15:37:51,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:51,589 INFO:     Epoch: 96
2023-01-05 15:37:53,707 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3903255124886831, 'Total loss': 0.3903255124886831} | train loss {'Reaction outcome loss': 0.2606210867252297, 'Total loss': 0.2606210867252297}
2023-01-05 15:37:53,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:53,707 INFO:     Epoch: 97
2023-01-05 15:37:55,826 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3863574624061584, 'Total loss': 0.3863574624061584} | train loss {'Reaction outcome loss': 0.25172410249655097, 'Total loss': 0.25172410249655097}
2023-01-05 15:37:55,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:55,827 INFO:     Epoch: 98
2023-01-05 15:37:57,936 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4462825338045756, 'Total loss': 0.4462825338045756} | train loss {'Reaction outcome loss': 0.2560771890122072, 'Total loss': 0.2560771890122072}
2023-01-05 15:37:57,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:37:57,936 INFO:     Epoch: 99
2023-01-05 15:38:00,019 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.36143460298577945, 'Total loss': 0.36143460298577945} | train loss {'Reaction outcome loss': 0.2539190055726859, 'Total loss': 0.2539190055726859}
2023-01-05 15:38:00,020 INFO:     Found new best model at epoch 99
2023-01-05 15:38:00,021 INFO:     Best model found after epoch 100 of 100.
2023-01-05 15:38:00,021 INFO:   Done with stage: TRAINING
2023-01-05 15:38:00,021 INFO:   Starting stage: EVALUATION
2023-01-05 15:38:00,175 INFO:   Done with stage: EVALUATION
2023-01-05 15:38:00,175 INFO:   Leaving out SEQ value Fold_3
2023-01-05 15:38:00,188 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-05 15:38:00,188 INFO:   Starting stage: FEATURE SCALING
2023-01-05 15:38:00,829 INFO:   Done with stage: FEATURE SCALING
2023-01-05 15:38:00,829 INFO:   Starting stage: SCALING TARGETS
2023-01-05 15:38:00,896 INFO:   Done with stage: SCALING TARGETS
2023-01-05 15:38:00,897 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:38:00,897 INFO:     No hyperparam tuning for this model
2023-01-05 15:38:00,897 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:38:00,897 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 15:38:00,897 INFO:     None feature selector for col prot
2023-01-05 15:38:00,898 INFO:     None feature selector for col prot
2023-01-05 15:38:00,898 INFO:     None feature selector for col prot
2023-01-05 15:38:00,898 INFO:     None feature selector for col chem
2023-01-05 15:38:00,898 INFO:     None feature selector for col chem
2023-01-05 15:38:00,898 INFO:     None feature selector for col chem
2023-01-05 15:38:00,898 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 15:38:00,898 INFO:   Starting stage: BUILD MODEL
2023-01-05 15:38:00,900 INFO:     Number of params in model 72901
2023-01-05 15:38:00,903 INFO:   Done with stage: BUILD MODEL
2023-01-05 15:38:00,903 INFO:   Starting stage: TRAINING
2023-01-05 15:38:00,963 INFO:     Val loss before train {'Reaction outcome loss': 1.1022684892018637, 'Total loss': 1.1022684892018637}
2023-01-05 15:38:00,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:00,963 INFO:     Epoch: 0
2023-01-05 15:38:03,078 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8494484543800354, 'Total loss': 0.8494484543800354} | train loss {'Reaction outcome loss': 0.9221022628330217, 'Total loss': 0.9221022628330217}
2023-01-05 15:38:03,079 INFO:     Found new best model at epoch 0
2023-01-05 15:38:03,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:03,081 INFO:     Epoch: 1
2023-01-05 15:38:05,204 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6755213638146719, 'Total loss': 0.6755213638146719} | train loss {'Reaction outcome loss': 0.7455340325832367, 'Total loss': 0.7455340325832367}
2023-01-05 15:38:05,204 INFO:     Found new best model at epoch 1
2023-01-05 15:38:05,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:05,206 INFO:     Epoch: 2
2023-01-05 15:38:07,308 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5244081020355225, 'Total loss': 0.5244081020355225} | train loss {'Reaction outcome loss': 0.5876098968556006, 'Total loss': 0.5876098968556006}
2023-01-05 15:38:07,308 INFO:     Found new best model at epoch 2
2023-01-05 15:38:07,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:07,309 INFO:     Epoch: 3
2023-01-05 15:38:09,416 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.556590735912323, 'Total loss': 0.556590735912323} | train loss {'Reaction outcome loss': 0.532185295631085, 'Total loss': 0.532185295631085}
2023-01-05 15:38:09,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:09,416 INFO:     Epoch: 4
2023-01-05 15:38:11,506 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.512430355946223, 'Total loss': 0.512430355946223} | train loss {'Reaction outcome loss': 0.5131695721422175, 'Total loss': 0.5131695721422175}
2023-01-05 15:38:11,506 INFO:     Found new best model at epoch 4
2023-01-05 15:38:11,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:11,507 INFO:     Epoch: 5
2023-01-05 15:38:13,603 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4962613383928935, 'Total loss': 0.4962613383928935} | train loss {'Reaction outcome loss': 0.4906037984848902, 'Total loss': 0.4906037984848902}
2023-01-05 15:38:13,603 INFO:     Found new best model at epoch 5
2023-01-05 15:38:13,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:13,605 INFO:     Epoch: 6
2023-01-05 15:38:15,675 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.544950403769811, 'Total loss': 0.544950403769811} | train loss {'Reaction outcome loss': 0.48325314463504565, 'Total loss': 0.48325314463504565}
2023-01-05 15:38:15,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:15,676 INFO:     Epoch: 7
2023-01-05 15:38:17,766 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49024585088094075, 'Total loss': 0.49024585088094075} | train loss {'Reaction outcome loss': 0.4816598459473395, 'Total loss': 0.4816598459473395}
2023-01-05 15:38:17,767 INFO:     Found new best model at epoch 7
2023-01-05 15:38:17,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:17,768 INFO:     Epoch: 8
2023-01-05 15:38:19,875 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4815218369166056, 'Total loss': 0.4815218369166056} | train loss {'Reaction outcome loss': 0.4749155363473505, 'Total loss': 0.4749155363473505}
2023-01-05 15:38:19,875 INFO:     Found new best model at epoch 8
2023-01-05 15:38:19,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:19,877 INFO:     Epoch: 9
2023-01-05 15:38:21,979 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5151114185651143, 'Total loss': 0.5151114185651143} | train loss {'Reaction outcome loss': 0.46794284825175453, 'Total loss': 0.46794284825175453}
2023-01-05 15:38:21,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:21,980 INFO:     Epoch: 10
2023-01-05 15:38:24,124 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48049121101697284, 'Total loss': 0.48049121101697284} | train loss {'Reaction outcome loss': 0.46070140308779545, 'Total loss': 0.46070140308779545}
2023-01-05 15:38:24,124 INFO:     Found new best model at epoch 10
2023-01-05 15:38:24,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:24,125 INFO:     Epoch: 11
2023-01-05 15:38:26,211 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48589811523755394, 'Total loss': 0.48589811523755394} | train loss {'Reaction outcome loss': 0.4555029485278464, 'Total loss': 0.4555029485278464}
2023-01-05 15:38:26,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:26,211 INFO:     Epoch: 12
2023-01-05 15:38:28,283 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4399875889221827, 'Total loss': 0.4399875889221827} | train loss {'Reaction outcome loss': 0.45378392329955014, 'Total loss': 0.45378392329955014}
2023-01-05 15:38:28,283 INFO:     Found new best model at epoch 12
2023-01-05 15:38:28,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:28,285 INFO:     Epoch: 13
2023-01-05 15:38:30,364 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44932635327180226, 'Total loss': 0.44932635327180226} | train loss {'Reaction outcome loss': 0.4443093167404847, 'Total loss': 0.4443093167404847}
2023-01-05 15:38:30,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:30,365 INFO:     Epoch: 14
2023-01-05 15:38:32,468 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4711960842212041, 'Total loss': 0.4711960842212041} | train loss {'Reaction outcome loss': 0.44111169038883435, 'Total loss': 0.44111169038883435}
2023-01-05 15:38:32,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:32,470 INFO:     Epoch: 15
2023-01-05 15:38:34,557 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.448183344801267, 'Total loss': 0.448183344801267} | train loss {'Reaction outcome loss': 0.43602745097501694, 'Total loss': 0.43602745097501694}
2023-01-05 15:38:34,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:34,558 INFO:     Epoch: 16
2023-01-05 15:38:36,660 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44467299381891884, 'Total loss': 0.44467299381891884} | train loss {'Reaction outcome loss': 0.43358506366775484, 'Total loss': 0.43358506366775484}
2023-01-05 15:38:36,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:36,661 INFO:     Epoch: 17
2023-01-05 15:38:38,764 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.465855332215627, 'Total loss': 0.465855332215627} | train loss {'Reaction outcome loss': 0.4347458442748693, 'Total loss': 0.4347458442748693}
2023-01-05 15:38:38,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:38,765 INFO:     Epoch: 18
2023-01-05 15:38:40,870 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4566412061452866, 'Total loss': 0.4566412061452866} | train loss {'Reaction outcome loss': 0.421842635997547, 'Total loss': 0.421842635997547}
2023-01-05 15:38:40,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:40,870 INFO:     Epoch: 19
2023-01-05 15:38:42,984 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4064974009990692, 'Total loss': 0.4064974009990692} | train loss {'Reaction outcome loss': 0.4187769341072913, 'Total loss': 0.4187769341072913}
2023-01-05 15:38:42,984 INFO:     Found new best model at epoch 19
2023-01-05 15:38:42,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:42,985 INFO:     Epoch: 20
2023-01-05 15:38:45,100 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3992355744043986, 'Total loss': 0.3992355744043986} | train loss {'Reaction outcome loss': 0.4203083418392167, 'Total loss': 0.4203083418392167}
2023-01-05 15:38:45,100 INFO:     Found new best model at epoch 20
2023-01-05 15:38:45,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:45,101 INFO:     Epoch: 21
2023-01-05 15:38:47,219 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4291817675034205, 'Total loss': 0.4291817675034205} | train loss {'Reaction outcome loss': 0.41645467968664485, 'Total loss': 0.41645467968664485}
2023-01-05 15:38:47,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:47,219 INFO:     Epoch: 22
2023-01-05 15:38:49,361 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44141765336195626, 'Total loss': 0.44141765336195626} | train loss {'Reaction outcome loss': 0.4076274130287206, 'Total loss': 0.4076274130287206}
2023-01-05 15:38:49,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:49,361 INFO:     Epoch: 23
2023-01-05 15:38:51,492 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42243264317512513, 'Total loss': 0.42243264317512513} | train loss {'Reaction outcome loss': 0.407773337076071, 'Total loss': 0.407773337076071}
2023-01-05 15:38:51,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:51,493 INFO:     Epoch: 24
2023-01-05 15:38:53,612 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4310170253117879, 'Total loss': 0.4310170253117879} | train loss {'Reaction outcome loss': 0.40035533346923075, 'Total loss': 0.40035533346923075}
2023-01-05 15:38:53,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:53,613 INFO:     Epoch: 25
2023-01-05 15:38:55,724 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4800050377845764, 'Total loss': 0.4800050377845764} | train loss {'Reaction outcome loss': 0.3979955230911719, 'Total loss': 0.3979955230911719}
2023-01-05 15:38:55,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:55,725 INFO:     Epoch: 26
2023-01-05 15:38:57,837 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41198400358359016, 'Total loss': 0.41198400358359016} | train loss {'Reaction outcome loss': 0.39580024809085135, 'Total loss': 0.39580024809085135}
2023-01-05 15:38:57,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:57,837 INFO:     Epoch: 27
2023-01-05 15:38:59,957 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4144194334745407, 'Total loss': 0.4144194334745407} | train loss {'Reaction outcome loss': 0.3923371242861026, 'Total loss': 0.3923371242861026}
2023-01-05 15:38:59,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:38:59,958 INFO:     Epoch: 28
2023-01-05 15:39:02,080 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43088462253411614, 'Total loss': 0.43088462253411614} | train loss {'Reaction outcome loss': 0.384784309076647, 'Total loss': 0.384784309076647}
2023-01-05 15:39:02,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:02,081 INFO:     Epoch: 29
2023-01-05 15:39:04,193 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46720440487066905, 'Total loss': 0.46720440487066905} | train loss {'Reaction outcome loss': 0.38321902855845835, 'Total loss': 0.38321902855845835}
2023-01-05 15:39:04,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:04,193 INFO:     Epoch: 30
2023-01-05 15:39:06,297 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42218518058458965, 'Total loss': 0.42218518058458965} | train loss {'Reaction outcome loss': 0.3743975161268922, 'Total loss': 0.3743975161268922}
2023-01-05 15:39:06,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:06,298 INFO:     Epoch: 31
2023-01-05 15:39:08,401 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43779449264208475, 'Total loss': 0.43779449264208475} | train loss {'Reaction outcome loss': 0.37505956931637663, 'Total loss': 0.37505956931637663}
2023-01-05 15:39:08,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:08,402 INFO:     Epoch: 32
2023-01-05 15:39:10,503 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4708232005437215, 'Total loss': 0.4708232005437215} | train loss {'Reaction outcome loss': 0.3754583263419211, 'Total loss': 0.3754583263419211}
2023-01-05 15:39:10,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:10,503 INFO:     Epoch: 33
2023-01-05 15:39:12,588 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40786717434724173, 'Total loss': 0.40786717434724173} | train loss {'Reaction outcome loss': 0.3634425762944556, 'Total loss': 0.3634425762944556}
2023-01-05 15:39:12,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:12,588 INFO:     Epoch: 34
2023-01-05 15:39:14,674 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4103645463784536, 'Total loss': 0.4103645463784536} | train loss {'Reaction outcome loss': 0.3616860690921875, 'Total loss': 0.3616860690921875}
2023-01-05 15:39:14,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:14,674 INFO:     Epoch: 35
2023-01-05 15:39:16,572 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44353776375452675, 'Total loss': 0.44353776375452675} | train loss {'Reaction outcome loss': 0.3617201494774695, 'Total loss': 0.3617201494774695}
2023-01-05 15:39:16,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:16,572 INFO:     Epoch: 36
2023-01-05 15:39:18,674 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45252601156632105, 'Total loss': 0.45252601156632105} | train loss {'Reaction outcome loss': 0.35676047533090705, 'Total loss': 0.35676047533090705}
2023-01-05 15:39:18,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:18,674 INFO:     Epoch: 37
2023-01-05 15:39:20,768 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3701384832461675, 'Total loss': 0.3701384832461675} | train loss {'Reaction outcome loss': 0.35257220906085196, 'Total loss': 0.35257220906085196}
2023-01-05 15:39:20,769 INFO:     Found new best model at epoch 37
2023-01-05 15:39:20,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:20,770 INFO:     Epoch: 38
2023-01-05 15:39:22,872 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40467959543069204, 'Total loss': 0.40467959543069204} | train loss {'Reaction outcome loss': 0.3464393120575215, 'Total loss': 0.3464393120575215}
2023-01-05 15:39:22,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:22,873 INFO:     Epoch: 39
2023-01-05 15:39:24,993 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4040072494186461, 'Total loss': 0.4040072494186461} | train loss {'Reaction outcome loss': 0.34842307817507057, 'Total loss': 0.34842307817507057}
2023-01-05 15:39:24,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:24,993 INFO:     Epoch: 40
2023-01-05 15:39:27,105 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4072330504655838, 'Total loss': 0.4072330504655838} | train loss {'Reaction outcome loss': 0.34020563050059816, 'Total loss': 0.34020563050059816}
2023-01-05 15:39:27,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:27,106 INFO:     Epoch: 41
2023-01-05 15:39:29,206 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45920976599057517, 'Total loss': 0.45920976599057517} | train loss {'Reaction outcome loss': 0.3369974080899325, 'Total loss': 0.3369974080899325}
2023-01-05 15:39:29,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:29,207 INFO:     Epoch: 42
2023-01-05 15:39:31,308 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42936306645472844, 'Total loss': 0.42936306645472844} | train loss {'Reaction outcome loss': 0.33947495701018293, 'Total loss': 0.33947495701018293}
2023-01-05 15:39:31,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:31,308 INFO:     Epoch: 43
2023-01-05 15:39:33,402 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41152432809273404, 'Total loss': 0.41152432809273404} | train loss {'Reaction outcome loss': 0.32695446185410243, 'Total loss': 0.32695446185410243}
2023-01-05 15:39:33,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:33,402 INFO:     Epoch: 44
2023-01-05 15:39:35,517 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3975025087594986, 'Total loss': 0.3975025087594986} | train loss {'Reaction outcome loss': 0.3334901774666406, 'Total loss': 0.3334901774666406}
2023-01-05 15:39:35,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:35,518 INFO:     Epoch: 45
2023-01-05 15:39:37,612 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41225579753518105, 'Total loss': 0.41225579753518105} | train loss {'Reaction outcome loss': 0.32826174748889636, 'Total loss': 0.32826174748889636}
2023-01-05 15:39:37,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:37,612 INFO:     Epoch: 46
2023-01-05 15:39:39,715 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40407682160536446, 'Total loss': 0.40407682160536446} | train loss {'Reaction outcome loss': 0.3222012373161712, 'Total loss': 0.3222012373161712}
2023-01-05 15:39:39,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:39,717 INFO:     Epoch: 47
2023-01-05 15:39:41,829 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4064030994971593, 'Total loss': 0.4064030994971593} | train loss {'Reaction outcome loss': 0.3267112019509627, 'Total loss': 0.3267112019509627}
2023-01-05 15:39:41,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:41,830 INFO:     Epoch: 48
2023-01-05 15:39:43,929 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40196628955503305, 'Total loss': 0.40196628955503305} | train loss {'Reaction outcome loss': 0.31517326356190156, 'Total loss': 0.31517326356190156}
2023-01-05 15:39:43,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:43,930 INFO:     Epoch: 49
2023-01-05 15:39:46,033 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40961810847123464, 'Total loss': 0.40961810847123464} | train loss {'Reaction outcome loss': 0.3151642407026018, 'Total loss': 0.3151642407026018}
2023-01-05 15:39:46,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:46,034 INFO:     Epoch: 50
2023-01-05 15:39:48,106 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3987216432889303, 'Total loss': 0.3987216432889303} | train loss {'Reaction outcome loss': 0.31867803492999164, 'Total loss': 0.31867803492999164}
2023-01-05 15:39:48,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:48,107 INFO:     Epoch: 51
2023-01-05 15:39:50,219 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40356162389119465, 'Total loss': 0.40356162389119465} | train loss {'Reaction outcome loss': 0.31329234107998905, 'Total loss': 0.31329234107998905}
2023-01-05 15:39:50,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:50,220 INFO:     Epoch: 52
2023-01-05 15:39:52,327 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3956863902509212, 'Total loss': 0.3956863902509212} | train loss {'Reaction outcome loss': 0.3037313410936686, 'Total loss': 0.3037313410936686}
2023-01-05 15:39:52,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:52,328 INFO:     Epoch: 53
2023-01-05 15:39:54,411 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40988827546437584, 'Total loss': 0.40988827546437584} | train loss {'Reaction outcome loss': 0.2975598493267909, 'Total loss': 0.2975598493267909}
2023-01-05 15:39:54,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:54,411 INFO:     Epoch: 54
2023-01-05 15:39:56,498 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39544717942674956, 'Total loss': 0.39544717942674956} | train loss {'Reaction outcome loss': 0.3036950918333777, 'Total loss': 0.3036950918333777}
2023-01-05 15:39:56,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:56,499 INFO:     Epoch: 55
2023-01-05 15:39:58,606 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38490172326564787, 'Total loss': 0.38490172326564787} | train loss {'Reaction outcome loss': 0.30498616232423326, 'Total loss': 0.30498616232423326}
2023-01-05 15:39:58,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:39:58,607 INFO:     Epoch: 56
2023-01-05 15:40:00,695 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38728071252504986, 'Total loss': 0.38728071252504986} | train loss {'Reaction outcome loss': 0.29674808936008007, 'Total loss': 0.29674808936008007}
2023-01-05 15:40:00,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:00,696 INFO:     Epoch: 57
2023-01-05 15:40:02,781 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4229454884926478, 'Total loss': 0.4229454884926478} | train loss {'Reaction outcome loss': 0.2982095633513153, 'Total loss': 0.2982095633513153}
2023-01-05 15:40:02,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:02,781 INFO:     Epoch: 58
2023-01-05 15:40:04,850 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41894057194391887, 'Total loss': 0.41894057194391887} | train loss {'Reaction outcome loss': 0.29603561635276926, 'Total loss': 0.29603561635276926}
2023-01-05 15:40:04,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:04,850 INFO:     Epoch: 59
2023-01-05 15:40:06,959 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.409169897561272, 'Total loss': 0.409169897561272} | train loss {'Reaction outcome loss': 0.3012901594814229, 'Total loss': 0.3012901594814229}
2023-01-05 15:40:06,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:06,959 INFO:     Epoch: 60
2023-01-05 15:40:09,058 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4186965028444926, 'Total loss': 0.4186965028444926} | train loss {'Reaction outcome loss': 0.28902472998273326, 'Total loss': 0.28902472998273326}
2023-01-05 15:40:09,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:09,060 INFO:     Epoch: 61
2023-01-05 15:40:11,167 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39776452084382374, 'Total loss': 0.39776452084382374} | train loss {'Reaction outcome loss': 0.2947043979684805, 'Total loss': 0.2947043979684805}
2023-01-05 15:40:11,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:11,167 INFO:     Epoch: 62
2023-01-05 15:40:13,277 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4157034387191137, 'Total loss': 0.4157034387191137} | train loss {'Reaction outcome loss': 0.28663782224169077, 'Total loss': 0.28663782224169077}
2023-01-05 15:40:13,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:13,277 INFO:     Epoch: 63
2023-01-05 15:40:15,388 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4124134510755539, 'Total loss': 0.4124134510755539} | train loss {'Reaction outcome loss': 0.2780509168948854, 'Total loss': 0.2780509168948854}
2023-01-05 15:40:15,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:15,389 INFO:     Epoch: 64
2023-01-05 15:40:17,516 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4276758114496867, 'Total loss': 0.4276758114496867} | train loss {'Reaction outcome loss': 0.2812186696006473, 'Total loss': 0.2812186696006473}
2023-01-05 15:40:17,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:17,516 INFO:     Epoch: 65
2023-01-05 15:40:19,630 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4204574962457021, 'Total loss': 0.4204574962457021} | train loss {'Reaction outcome loss': 0.28237472030564426, 'Total loss': 0.28237472030564426}
2023-01-05 15:40:19,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:19,630 INFO:     Epoch: 66
2023-01-05 15:40:21,747 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4298465043306351, 'Total loss': 0.4298465043306351} | train loss {'Reaction outcome loss': 0.2805946542438106, 'Total loss': 0.2805946542438106}
2023-01-05 15:40:21,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:21,747 INFO:     Epoch: 67
2023-01-05 15:40:23,889 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40335832387208936, 'Total loss': 0.40335832387208936} | train loss {'Reaction outcome loss': 0.27815232432801346, 'Total loss': 0.27815232432801346}
2023-01-05 15:40:23,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:23,889 INFO:     Epoch: 68
2023-01-05 15:40:26,046 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41243494153022764, 'Total loss': 0.41243494153022764} | train loss {'Reaction outcome loss': 0.2804089232426948, 'Total loss': 0.2804089232426948}
2023-01-05 15:40:26,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:26,046 INFO:     Epoch: 69
2023-01-05 15:40:28,119 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41659867266813916, 'Total loss': 0.41659867266813916} | train loss {'Reaction outcome loss': 0.28535388986068017, 'Total loss': 0.28535388986068017}
2023-01-05 15:40:28,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:28,120 INFO:     Epoch: 70
2023-01-05 15:40:30,229 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45949258704980217, 'Total loss': 0.45949258704980217} | train loss {'Reaction outcome loss': 0.27516980621812526, 'Total loss': 0.27516980621812526}
2023-01-05 15:40:30,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:30,229 INFO:     Epoch: 71
2023-01-05 15:40:32,333 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.397244160870711, 'Total loss': 0.397244160870711} | train loss {'Reaction outcome loss': 0.278965785384618, 'Total loss': 0.278965785384618}
2023-01-05 15:40:32,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:32,333 INFO:     Epoch: 72
2023-01-05 15:40:34,444 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39463433225949607, 'Total loss': 0.39463433225949607} | train loss {'Reaction outcome loss': 0.2761788545691879, 'Total loss': 0.2761788545691879}
2023-01-05 15:40:34,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:34,444 INFO:     Epoch: 73
2023-01-05 15:40:36,543 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.386836697657903, 'Total loss': 0.386836697657903} | train loss {'Reaction outcome loss': 0.2687900106996518, 'Total loss': 0.2687900106996518}
2023-01-05 15:40:36,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:36,543 INFO:     Epoch: 74
2023-01-05 15:40:38,663 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4610878805319468, 'Total loss': 0.4610878805319468} | train loss {'Reaction outcome loss': 0.2700883121370609, 'Total loss': 0.2700883121370609}
2023-01-05 15:40:38,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:38,664 INFO:     Epoch: 75
2023-01-05 15:40:40,773 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.445771786570549, 'Total loss': 0.445771786570549} | train loss {'Reaction outcome loss': 0.26705933756768924, 'Total loss': 0.26705933756768924}
2023-01-05 15:40:40,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:40,773 INFO:     Epoch: 76
2023-01-05 15:40:42,899 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3995927346870303, 'Total loss': 0.3995927346870303} | train loss {'Reaction outcome loss': 0.26450931155071267, 'Total loss': 0.26450931155071267}
2023-01-05 15:40:42,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:42,899 INFO:     Epoch: 77
2023-01-05 15:40:45,022 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40558335483074187, 'Total loss': 0.40558335483074187} | train loss {'Reaction outcome loss': 0.26680759060096915, 'Total loss': 0.26680759060096915}
2023-01-05 15:40:45,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:45,024 INFO:     Epoch: 78
2023-01-05 15:40:47,135 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3965387485921383, 'Total loss': 0.3965387485921383} | train loss {'Reaction outcome loss': 0.2597666400866205, 'Total loss': 0.2597666400866205}
2023-01-05 15:40:47,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:47,136 INFO:     Epoch: 79
2023-01-05 15:40:49,249 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40338763197263083, 'Total loss': 0.40338763197263083} | train loss {'Reaction outcome loss': 0.257628532937587, 'Total loss': 0.257628532937587}
2023-01-05 15:40:49,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:49,249 INFO:     Epoch: 80
2023-01-05 15:40:51,359 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3990298476768658, 'Total loss': 0.3990298476768658} | train loss {'Reaction outcome loss': 0.25689407129431785, 'Total loss': 0.25689407129431785}
2023-01-05 15:40:51,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:51,360 INFO:     Epoch: 81
2023-01-05 15:40:53,466 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42799322108427684, 'Total loss': 0.42799322108427684} | train loss {'Reaction outcome loss': 0.253295416541645, 'Total loss': 0.253295416541645}
2023-01-05 15:40:53,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:53,466 INFO:     Epoch: 82
2023-01-05 15:40:55,567 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43223894337813057, 'Total loss': 0.43223894337813057} | train loss {'Reaction outcome loss': 0.2558590371807783, 'Total loss': 0.2558590371807783}
2023-01-05 15:40:55,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:55,568 INFO:     Epoch: 83
2023-01-05 15:40:57,681 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38978376388549807, 'Total loss': 0.38978376388549807} | train loss {'Reaction outcome loss': 0.25757229956368677, 'Total loss': 0.25757229956368677}
2023-01-05 15:40:57,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:57,681 INFO:     Epoch: 84
2023-01-05 15:40:59,843 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4293525976439317, 'Total loss': 0.4293525976439317} | train loss {'Reaction outcome loss': 0.25361183121443015, 'Total loss': 0.25361183121443015}
2023-01-05 15:40:59,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:40:59,844 INFO:     Epoch: 85
2023-01-05 15:41:01,939 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3889568488424023, 'Total loss': 0.3889568488424023} | train loss {'Reaction outcome loss': 0.24696211689375203, 'Total loss': 0.24696211689375203}
2023-01-05 15:41:01,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:01,939 INFO:     Epoch: 86
2023-01-05 15:41:04,036 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4239025245110194, 'Total loss': 0.4239025245110194} | train loss {'Reaction outcome loss': 0.25401792684191926, 'Total loss': 0.25401792684191926}
2023-01-05 15:41:04,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:04,037 INFO:     Epoch: 87
2023-01-05 15:41:06,145 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4374761164188385, 'Total loss': 0.4374761164188385} | train loss {'Reaction outcome loss': 0.2542175145757924, 'Total loss': 0.2542175145757924}
2023-01-05 15:41:06,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:06,145 INFO:     Epoch: 88
2023-01-05 15:41:08,262 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43649340271949766, 'Total loss': 0.43649340271949766} | train loss {'Reaction outcome loss': 0.2524337020060013, 'Total loss': 0.2524337020060013}
2023-01-05 15:41:08,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:08,262 INFO:     Epoch: 89
2023-01-05 15:41:10,357 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4276897956927617, 'Total loss': 0.4276897956927617} | train loss {'Reaction outcome loss': 0.23932939345821244, 'Total loss': 0.23932939345821244}
2023-01-05 15:41:10,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:10,357 INFO:     Epoch: 90
2023-01-05 15:41:12,470 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4258603463570277, 'Total loss': 0.4258603463570277} | train loss {'Reaction outcome loss': 0.250952851199081, 'Total loss': 0.250952851199081}
2023-01-05 15:41:12,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:12,471 INFO:     Epoch: 91
2023-01-05 15:41:14,585 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.415147598584493, 'Total loss': 0.415147598584493} | train loss {'Reaction outcome loss': 0.251105188175596, 'Total loss': 0.251105188175596}
2023-01-05 15:41:14,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:14,586 INFO:     Epoch: 92
2023-01-05 15:41:16,682 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4127169335881869, 'Total loss': 0.4127169335881869} | train loss {'Reaction outcome loss': 0.24627396489091466, 'Total loss': 0.24627396489091466}
2023-01-05 15:41:16,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:16,682 INFO:     Epoch: 93
2023-01-05 15:41:18,786 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4216746264447769, 'Total loss': 0.4216746264447769} | train loss {'Reaction outcome loss': 0.2493778523470093, 'Total loss': 0.2493778523470093}
2023-01-05 15:41:18,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:18,786 INFO:     Epoch: 94
2023-01-05 15:41:20,890 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38799375494321187, 'Total loss': 0.38799375494321187} | train loss {'Reaction outcome loss': 0.23708287796960986, 'Total loss': 0.23708287796960986}
2023-01-05 15:41:20,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:20,892 INFO:     Epoch: 95
2023-01-05 15:41:23,001 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42530869791905085, 'Total loss': 0.42530869791905085} | train loss {'Reaction outcome loss': 0.24647008273853643, 'Total loss': 0.24647008273853643}
2023-01-05 15:41:23,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:23,002 INFO:     Epoch: 96
2023-01-05 15:41:25,096 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39331459055344264, 'Total loss': 0.39331459055344264} | train loss {'Reaction outcome loss': 0.24364222088533133, 'Total loss': 0.24364222088533133}
2023-01-05 15:41:25,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:25,096 INFO:     Epoch: 97
2023-01-05 15:41:27,206 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.37277018738289674, 'Total loss': 0.37277018738289674} | train loss {'Reaction outcome loss': 0.2404840953606851, 'Total loss': 0.2404840953606851}
2023-01-05 15:41:27,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:27,207 INFO:     Epoch: 98
2023-01-05 15:41:29,326 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4268190105756124, 'Total loss': 0.4268190105756124} | train loss {'Reaction outcome loss': 0.24014671237596286, 'Total loss': 0.24014671237596286}
2023-01-05 15:41:29,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:29,326 INFO:     Epoch: 99
2023-01-05 15:41:31,487 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40407283455133436, 'Total loss': 0.40407283455133436} | train loss {'Reaction outcome loss': 0.23356439071669624, 'Total loss': 0.23356439071669624}
2023-01-05 15:41:31,487 INFO:     Best model found after epoch 38 of 100.
2023-01-05 15:41:31,487 INFO:   Done with stage: TRAINING
2023-01-05 15:41:31,487 INFO:   Starting stage: EVALUATION
2023-01-05 15:41:31,638 INFO:   Done with stage: EVALUATION
2023-01-05 15:41:31,638 INFO:   Leaving out SEQ value Fold_4
2023-01-05 15:41:31,650 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 15:41:31,650 INFO:   Starting stage: FEATURE SCALING
2023-01-05 15:41:32,297 INFO:   Done with stage: FEATURE SCALING
2023-01-05 15:41:32,297 INFO:   Starting stage: SCALING TARGETS
2023-01-05 15:41:32,365 INFO:   Done with stage: SCALING TARGETS
2023-01-05 15:41:32,365 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:41:32,365 INFO:     No hyperparam tuning for this model
2023-01-05 15:41:32,365 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:41:32,365 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 15:41:32,366 INFO:     None feature selector for col prot
2023-01-05 15:41:32,366 INFO:     None feature selector for col prot
2023-01-05 15:41:32,366 INFO:     None feature selector for col prot
2023-01-05 15:41:32,367 INFO:     None feature selector for col chem
2023-01-05 15:41:32,367 INFO:     None feature selector for col chem
2023-01-05 15:41:32,367 INFO:     None feature selector for col chem
2023-01-05 15:41:32,367 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 15:41:32,367 INFO:   Starting stage: BUILD MODEL
2023-01-05 15:41:32,368 INFO:     Number of params in model 72901
2023-01-05 15:41:32,372 INFO:   Done with stage: BUILD MODEL
2023-01-05 15:41:32,372 INFO:   Starting stage: TRAINING
2023-01-05 15:41:32,432 INFO:     Val loss before train {'Reaction outcome loss': 0.9200439969698588, 'Total loss': 0.9200439969698588}
2023-01-05 15:41:32,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:32,432 INFO:     Epoch: 0
2023-01-05 15:41:34,620 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7524816433588664, 'Total loss': 0.7524816433588664} | train loss {'Reaction outcome loss': 0.9023053853735596, 'Total loss': 0.9023053853735596}
2023-01-05 15:41:34,620 INFO:     Found new best model at epoch 0
2023-01-05 15:41:34,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:34,621 INFO:     Epoch: 1
2023-01-05 15:41:36,793 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5532676219940186, 'Total loss': 0.5532676219940186} | train loss {'Reaction outcome loss': 0.7023048064123423, 'Total loss': 0.7023048064123423}
2023-01-05 15:41:36,794 INFO:     Found new best model at epoch 1
2023-01-05 15:41:36,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:36,795 INFO:     Epoch: 2
2023-01-05 15:41:38,973 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5077927589416504, 'Total loss': 0.5077927589416504} | train loss {'Reaction outcome loss': 0.5717411006293142, 'Total loss': 0.5717411006293142}
2023-01-05 15:41:38,973 INFO:     Found new best model at epoch 2
2023-01-05 15:41:38,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:38,974 INFO:     Epoch: 3
2023-01-05 15:41:41,173 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5258786976337433, 'Total loss': 0.5258786976337433} | train loss {'Reaction outcome loss': 0.5315368023267292, 'Total loss': 0.5315368023267292}
2023-01-05 15:41:41,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:41,173 INFO:     Epoch: 4
2023-01-05 15:41:43,387 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4733650267124176, 'Total loss': 0.4733650267124176} | train loss {'Reaction outcome loss': 0.5163507075301146, 'Total loss': 0.5163507075301146}
2023-01-05 15:41:43,388 INFO:     Found new best model at epoch 4
2023-01-05 15:41:43,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:43,389 INFO:     Epoch: 5
2023-01-05 15:41:45,591 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48080754776795703, 'Total loss': 0.48080754776795703} | train loss {'Reaction outcome loss': 0.49869289639194087, 'Total loss': 0.49869289639194087}
2023-01-05 15:41:45,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:45,591 INFO:     Epoch: 6
2023-01-05 15:41:47,801 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4494855284690857, 'Total loss': 0.4494855284690857} | train loss {'Reaction outcome loss': 0.49961948244149934, 'Total loss': 0.49961948244149934}
2023-01-05 15:41:47,801 INFO:     Found new best model at epoch 6
2023-01-05 15:41:47,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:47,802 INFO:     Epoch: 7
2023-01-05 15:41:49,976 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46851494113604225, 'Total loss': 0.46851494113604225} | train loss {'Reaction outcome loss': 0.4869324897385676, 'Total loss': 0.4869324897385676}
2023-01-05 15:41:49,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:49,976 INFO:     Epoch: 8
2023-01-05 15:41:52,157 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4592419058084488, 'Total loss': 0.4592419058084488} | train loss {'Reaction outcome loss': 0.47851716137965233, 'Total loss': 0.47851716137965233}
2023-01-05 15:41:52,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:52,157 INFO:     Epoch: 9
2023-01-05 15:41:54,337 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.481982413927714, 'Total loss': 0.481982413927714} | train loss {'Reaction outcome loss': 0.47215122775265456, 'Total loss': 0.47215122775265456}
2023-01-05 15:41:54,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:54,338 INFO:     Epoch: 10
2023-01-05 15:41:56,543 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44469290574391684, 'Total loss': 0.44469290574391684} | train loss {'Reaction outcome loss': 0.47046469711439703, 'Total loss': 0.47046469711439703}
2023-01-05 15:41:56,544 INFO:     Found new best model at epoch 10
2023-01-05 15:41:56,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:56,545 INFO:     Epoch: 11
2023-01-05 15:41:58,733 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4443313906590144, 'Total loss': 0.4443313906590144} | train loss {'Reaction outcome loss': 0.46342725408959473, 'Total loss': 0.46342725408959473}
2023-01-05 15:41:58,733 INFO:     Found new best model at epoch 11
2023-01-05 15:41:58,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:41:58,735 INFO:     Epoch: 12
2023-01-05 15:42:00,895 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4441191812356313, 'Total loss': 0.4441191812356313} | train loss {'Reaction outcome loss': 0.4615171729227266, 'Total loss': 0.4615171729227266}
2023-01-05 15:42:00,896 INFO:     Found new best model at epoch 12
2023-01-05 15:42:00,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:00,897 INFO:     Epoch: 13
2023-01-05 15:42:03,063 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4567875365416209, 'Total loss': 0.4567875365416209} | train loss {'Reaction outcome loss': 0.4528417983747992, 'Total loss': 0.4528417983747992}
2023-01-05 15:42:03,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:03,064 INFO:     Epoch: 14
2023-01-05 15:42:05,219 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4272173931201299, 'Total loss': 0.4272173931201299} | train loss {'Reaction outcome loss': 0.44783913825608335, 'Total loss': 0.44783913825608335}
2023-01-05 15:42:05,219 INFO:     Found new best model at epoch 14
2023-01-05 15:42:05,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:05,220 INFO:     Epoch: 15
2023-01-05 15:42:07,379 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41710226039091747, 'Total loss': 0.41710226039091747} | train loss {'Reaction outcome loss': 0.4481531255189262, 'Total loss': 0.4481531255189262}
2023-01-05 15:42:07,379 INFO:     Found new best model at epoch 15
2023-01-05 15:42:07,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:07,380 INFO:     Epoch: 16
2023-01-05 15:42:09,515 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44142351746559144, 'Total loss': 0.44142351746559144} | train loss {'Reaction outcome loss': 0.4373029724624183, 'Total loss': 0.4373029724624183}
2023-01-05 15:42:09,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:09,516 INFO:     Epoch: 17
2023-01-05 15:42:11,659 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4380292981863022, 'Total loss': 0.4380292981863022} | train loss {'Reaction outcome loss': 0.4381032817415382, 'Total loss': 0.4381032817415382}
2023-01-05 15:42:11,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:11,659 INFO:     Epoch: 18
2023-01-05 15:42:13,779 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43463653524716694, 'Total loss': 0.43463653524716694} | train loss {'Reaction outcome loss': 0.4325622516526212, 'Total loss': 0.4325622516526212}
2023-01-05 15:42:13,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:13,779 INFO:     Epoch: 19
2023-01-05 15:42:15,918 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4357910454273224, 'Total loss': 0.4357910454273224} | train loss {'Reaction outcome loss': 0.4303582108139131, 'Total loss': 0.4303582108139131}
2023-01-05 15:42:15,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:15,919 INFO:     Epoch: 20
2023-01-05 15:42:18,078 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4268135001262029, 'Total loss': 0.4268135001262029} | train loss {'Reaction outcome loss': 0.42346209925111883, 'Total loss': 0.42346209925111883}
2023-01-05 15:42:18,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:18,079 INFO:     Epoch: 21
2023-01-05 15:42:20,213 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4410984992980957, 'Total loss': 0.4410984992980957} | train loss {'Reaction outcome loss': 0.41655084835062817, 'Total loss': 0.41655084835062817}
2023-01-05 15:42:20,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:20,213 INFO:     Epoch: 22
2023-01-05 15:42:22,364 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4404878874619802, 'Total loss': 0.4404878874619802} | train loss {'Reaction outcome loss': 0.41613699103090307, 'Total loss': 0.41613699103090307}
2023-01-05 15:42:22,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:22,364 INFO:     Epoch: 23
2023-01-05 15:42:24,521 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.400811967253685, 'Total loss': 0.400811967253685} | train loss {'Reaction outcome loss': 0.4114531359840386, 'Total loss': 0.4114531359840386}
2023-01-05 15:42:24,522 INFO:     Found new best model at epoch 23
2023-01-05 15:42:24,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:24,523 INFO:     Epoch: 24
2023-01-05 15:42:26,663 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40250839591026305, 'Total loss': 0.40250839591026305} | train loss {'Reaction outcome loss': 0.408351582713721, 'Total loss': 0.408351582713721}
2023-01-05 15:42:26,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:26,663 INFO:     Epoch: 25
2023-01-05 15:42:28,815 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41617109179496764, 'Total loss': 0.41617109179496764} | train loss {'Reaction outcome loss': 0.4038367291865366, 'Total loss': 0.4038367291865366}
2023-01-05 15:42:28,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:28,815 INFO:     Epoch: 26
2023-01-05 15:42:30,964 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4151174008846283, 'Total loss': 0.4151174008846283} | train loss {'Reaction outcome loss': 0.3938109128053438, 'Total loss': 0.3938109128053438}
2023-01-05 15:42:30,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:30,965 INFO:     Epoch: 27
2023-01-05 15:42:33,110 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41274393498897555, 'Total loss': 0.41274393498897555} | train loss {'Reaction outcome loss': 0.3959961857929126, 'Total loss': 0.3959961857929126}
2023-01-05 15:42:33,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:33,111 INFO:     Epoch: 28
2023-01-05 15:42:35,250 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40178841451803843, 'Total loss': 0.40178841451803843} | train loss {'Reaction outcome loss': 0.39219437184531764, 'Total loss': 0.39219437184531764}
2023-01-05 15:42:35,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:35,250 INFO:     Epoch: 29
2023-01-05 15:42:37,384 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4148085574309031, 'Total loss': 0.4148085574309031} | train loss {'Reaction outcome loss': 0.3897891731038421, 'Total loss': 0.3897891731038421}
2023-01-05 15:42:37,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:37,384 INFO:     Epoch: 30
2023-01-05 15:42:39,547 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3793195346991221, 'Total loss': 0.3793195346991221} | train loss {'Reaction outcome loss': 0.38029027162691315, 'Total loss': 0.38029027162691315}
2023-01-05 15:42:39,547 INFO:     Found new best model at epoch 30
2023-01-05 15:42:39,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:39,549 INFO:     Epoch: 31
2023-01-05 15:42:41,696 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.401807709534963, 'Total loss': 0.401807709534963} | train loss {'Reaction outcome loss': 0.37300367274116525, 'Total loss': 0.37300367274116525}
2023-01-05 15:42:41,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:41,696 INFO:     Epoch: 32
2023-01-05 15:42:43,830 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39080027540524803, 'Total loss': 0.39080027540524803} | train loss {'Reaction outcome loss': 0.37812796068320637, 'Total loss': 0.37812796068320637}
2023-01-05 15:42:43,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:43,830 INFO:     Epoch: 33
2023-01-05 15:42:45,983 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4152514139811198, 'Total loss': 0.4152514139811198} | train loss {'Reaction outcome loss': 0.369969786450751, 'Total loss': 0.369969786450751}
2023-01-05 15:42:45,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:45,983 INFO:     Epoch: 34
2023-01-05 15:42:48,087 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4122328102588654, 'Total loss': 0.4122328102588654} | train loss {'Reaction outcome loss': 0.36936640405913124, 'Total loss': 0.36936640405913124}
2023-01-05 15:42:48,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:48,087 INFO:     Epoch: 35
2023-01-05 15:42:50,242 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4168253441651662, 'Total loss': 0.4168253441651662} | train loss {'Reaction outcome loss': 0.3644546342993471, 'Total loss': 0.3644546342993471}
2023-01-05 15:42:50,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:50,242 INFO:     Epoch: 36
2023-01-05 15:42:52,354 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4015704323848089, 'Total loss': 0.4015704323848089} | train loss {'Reaction outcome loss': 0.3580302742548583, 'Total loss': 0.3580302742548583}
2023-01-05 15:42:52,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:52,355 INFO:     Epoch: 37
2023-01-05 15:42:54,471 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4521790653467178, 'Total loss': 0.4521790653467178} | train loss {'Reaction outcome loss': 0.35952318685687407, 'Total loss': 0.35952318685687407}
2023-01-05 15:42:54,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:54,471 INFO:     Epoch: 38
2023-01-05 15:42:56,619 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3784858137369156, 'Total loss': 0.3784858137369156} | train loss {'Reaction outcome loss': 0.34679633686957806, 'Total loss': 0.34679633686957806}
2023-01-05 15:42:56,619 INFO:     Found new best model at epoch 38
2023-01-05 15:42:56,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:56,621 INFO:     Epoch: 39
2023-01-05 15:42:58,753 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3573562110463778, 'Total loss': 0.3573562110463778} | train loss {'Reaction outcome loss': 0.34475890471724396, 'Total loss': 0.34475890471724396}
2023-01-05 15:42:58,753 INFO:     Found new best model at epoch 39
2023-01-05 15:42:58,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:42:58,755 INFO:     Epoch: 40
2023-01-05 15:43:00,885 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.36109000047047934, 'Total loss': 0.36109000047047934} | train loss {'Reaction outcome loss': 0.345782498909759, 'Total loss': 0.345782498909759}
2023-01-05 15:43:00,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:00,886 INFO:     Epoch: 41
2023-01-05 15:43:03,026 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3718453735113144, 'Total loss': 0.3718453735113144} | train loss {'Reaction outcome loss': 0.3401464268242409, 'Total loss': 0.3401464268242409}
2023-01-05 15:43:03,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:03,026 INFO:     Epoch: 42
2023-01-05 15:43:05,187 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.373782745997111, 'Total loss': 0.373782745997111} | train loss {'Reaction outcome loss': 0.33901346423780876, 'Total loss': 0.33901346423780876}
2023-01-05 15:43:05,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:05,187 INFO:     Epoch: 43
2023-01-05 15:43:07,325 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4113616148630778, 'Total loss': 0.4113616148630778} | train loss {'Reaction outcome loss': 0.3337160367316933, 'Total loss': 0.3337160367316933}
2023-01-05 15:43:07,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:07,326 INFO:     Epoch: 44
2023-01-05 15:43:09,442 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3828129251797994, 'Total loss': 0.3828129251797994} | train loss {'Reaction outcome loss': 0.33318569032401385, 'Total loss': 0.33318569032401385}
2023-01-05 15:43:09,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:09,443 INFO:     Epoch: 45
2023-01-05 15:43:11,590 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3922335848212242, 'Total loss': 0.3922335848212242} | train loss {'Reaction outcome loss': 0.32833412644665166, 'Total loss': 0.32833412644665166}
2023-01-05 15:43:11,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:11,590 INFO:     Epoch: 46
2023-01-05 15:43:13,715 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.383816268046697, 'Total loss': 0.383816268046697} | train loss {'Reaction outcome loss': 0.33202668494588633, 'Total loss': 0.33202668494588633}
2023-01-05 15:43:13,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:13,715 INFO:     Epoch: 47
2023-01-05 15:43:15,846 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3575350970029831, 'Total loss': 0.3575350970029831} | train loss {'Reaction outcome loss': 0.3298370352398187, 'Total loss': 0.3298370352398187}
2023-01-05 15:43:15,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:15,847 INFO:     Epoch: 48
2023-01-05 15:43:17,799 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.35648112098375956, 'Total loss': 0.35648112098375956} | train loss {'Reaction outcome loss': 0.3208311869954482, 'Total loss': 0.3208311869954482}
2023-01-05 15:43:17,799 INFO:     Found new best model at epoch 48
2023-01-05 15:43:17,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:17,800 INFO:     Epoch: 49
2023-01-05 15:43:19,943 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40909418066342673, 'Total loss': 0.40909418066342673} | train loss {'Reaction outcome loss': 0.3221204661451522, 'Total loss': 0.3221204661451522}
2023-01-05 15:43:19,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:19,943 INFO:     Epoch: 50
2023-01-05 15:43:22,055 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37709735582272214, 'Total loss': 0.37709735582272214} | train loss {'Reaction outcome loss': 0.3100937908575853, 'Total loss': 0.3100937908575853}
2023-01-05 15:43:22,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:22,055 INFO:     Epoch: 51
2023-01-05 15:43:24,189 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.35494678616523745, 'Total loss': 0.35494678616523745} | train loss {'Reaction outcome loss': 0.3183705473607843, 'Total loss': 0.3183705473607843}
2023-01-05 15:43:24,189 INFO:     Found new best model at epoch 51
2023-01-05 15:43:24,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:24,190 INFO:     Epoch: 52
2023-01-05 15:43:26,355 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.364976250131925, 'Total loss': 0.364976250131925} | train loss {'Reaction outcome loss': 0.3098943485384168, 'Total loss': 0.3098943485384168}
2023-01-05 15:43:26,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:26,355 INFO:     Epoch: 53
2023-01-05 15:43:28,507 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3914524972438812, 'Total loss': 0.3914524972438812} | train loss {'Reaction outcome loss': 0.31010964655381246, 'Total loss': 0.31010964655381246}
2023-01-05 15:43:28,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:28,508 INFO:     Epoch: 54
2023-01-05 15:43:30,697 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3871283600727717, 'Total loss': 0.3871283600727717} | train loss {'Reaction outcome loss': 0.31118296657013117, 'Total loss': 0.31118296657013117}
2023-01-05 15:43:30,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:30,697 INFO:     Epoch: 55
2023-01-05 15:43:32,853 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3822926590840022, 'Total loss': 0.3822926590840022} | train loss {'Reaction outcome loss': 0.30549096503036116, 'Total loss': 0.30549096503036116}
2023-01-05 15:43:32,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:32,854 INFO:     Epoch: 56
2023-01-05 15:43:34,992 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.337019607424736, 'Total loss': 0.337019607424736} | train loss {'Reaction outcome loss': 0.3057384900076295, 'Total loss': 0.3057384900076295}
2023-01-05 15:43:34,993 INFO:     Found new best model at epoch 56
2023-01-05 15:43:34,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:34,994 INFO:     Epoch: 57
2023-01-05 15:43:37,158 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3421430766582489, 'Total loss': 0.3421430766582489} | train loss {'Reaction outcome loss': 0.298941083023802, 'Total loss': 0.298941083023802}
2023-01-05 15:43:37,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:37,158 INFO:     Epoch: 58
2023-01-05 15:43:39,314 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39912209113438923, 'Total loss': 0.39912209113438923} | train loss {'Reaction outcome loss': 0.2977689608985336, 'Total loss': 0.2977689608985336}
2023-01-05 15:43:39,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:39,315 INFO:     Epoch: 59
2023-01-05 15:43:41,447 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.36867403984069824, 'Total loss': 0.36867403984069824} | train loss {'Reaction outcome loss': 0.29533848493269205, 'Total loss': 0.29533848493269205}
2023-01-05 15:43:41,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:41,448 INFO:     Epoch: 60
2023-01-05 15:43:43,610 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3592064579327901, 'Total loss': 0.3592064579327901} | train loss {'Reaction outcome loss': 0.29818801840074655, 'Total loss': 0.29818801840074655}
2023-01-05 15:43:43,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:43,610 INFO:     Epoch: 61
2023-01-05 15:43:45,754 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3899546096722285, 'Total loss': 0.3899546096722285} | train loss {'Reaction outcome loss': 0.2947228192099595, 'Total loss': 0.2947228192099595}
2023-01-05 15:43:45,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:45,755 INFO:     Epoch: 62
2023-01-05 15:43:47,911 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3635348637898763, 'Total loss': 0.3635348637898763} | train loss {'Reaction outcome loss': 0.29740285491469964, 'Total loss': 0.29740285491469964}
2023-01-05 15:43:47,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:47,911 INFO:     Epoch: 63
2023-01-05 15:43:50,046 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.349010339876016, 'Total loss': 0.349010339876016} | train loss {'Reaction outcome loss': 0.2879740081270249, 'Total loss': 0.2879740081270249}
2023-01-05 15:43:50,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:50,047 INFO:     Epoch: 64
2023-01-05 15:43:52,208 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3887740795811017, 'Total loss': 0.3887740795811017} | train loss {'Reaction outcome loss': 0.2852496950372731, 'Total loss': 0.2852496950372731}
2023-01-05 15:43:52,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:52,208 INFO:     Epoch: 65
2023-01-05 15:43:54,376 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.33506224155426023, 'Total loss': 0.33506224155426023} | train loss {'Reaction outcome loss': 0.28570769560466175, 'Total loss': 0.28570769560466175}
2023-01-05 15:43:54,376 INFO:     Found new best model at epoch 65
2023-01-05 15:43:54,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:54,377 INFO:     Epoch: 66
2023-01-05 15:43:56,528 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.363903746008873, 'Total loss': 0.363903746008873} | train loss {'Reaction outcome loss': 0.28477568309821377, 'Total loss': 0.28477568309821377}
2023-01-05 15:43:56,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:56,528 INFO:     Epoch: 67
2023-01-05 15:43:58,681 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3639485160509745, 'Total loss': 0.3639485160509745} | train loss {'Reaction outcome loss': 0.28284884123165255, 'Total loss': 0.28284884123165255}
2023-01-05 15:43:58,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:43:58,682 INFO:     Epoch: 68
2023-01-05 15:44:00,888 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4029292846719424, 'Total loss': 0.4029292846719424} | train loss {'Reaction outcome loss': 0.2796363153424289, 'Total loss': 0.2796363153424289}
2023-01-05 15:44:00,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:00,889 INFO:     Epoch: 69
2023-01-05 15:44:03,109 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.34287076791127524, 'Total loss': 0.34287076791127524} | train loss {'Reaction outcome loss': 0.2835351188905833, 'Total loss': 0.2835351188905833}
2023-01-05 15:44:03,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:03,109 INFO:     Epoch: 70
2023-01-05 15:44:05,286 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3729897399743398, 'Total loss': 0.3729897399743398} | train loss {'Reaction outcome loss': 0.2816939427641755, 'Total loss': 0.2816939427641755}
2023-01-05 15:44:05,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:05,287 INFO:     Epoch: 71
2023-01-05 15:44:07,451 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3433168997367223, 'Total loss': 0.3433168997367223} | train loss {'Reaction outcome loss': 0.27744069719007947, 'Total loss': 0.27744069719007947}
2023-01-05 15:44:07,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:07,452 INFO:     Epoch: 72
2023-01-05 15:44:09,606 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.34155689403414724, 'Total loss': 0.34155689403414724} | train loss {'Reaction outcome loss': 0.26902113661223803, 'Total loss': 0.26902113661223803}
2023-01-05 15:44:09,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:09,606 INFO:     Epoch: 73
2023-01-05 15:44:11,776 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.324828939139843, 'Total loss': 0.324828939139843} | train loss {'Reaction outcome loss': 0.27983844538457986, 'Total loss': 0.27983844538457986}
2023-01-05 15:44:11,776 INFO:     Found new best model at epoch 73
2023-01-05 15:44:11,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:11,778 INFO:     Epoch: 74
2023-01-05 15:44:13,976 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.34712054481108984, 'Total loss': 0.34712054481108984} | train loss {'Reaction outcome loss': 0.2780011075646331, 'Total loss': 0.2780011075646331}
2023-01-05 15:44:13,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:13,976 INFO:     Epoch: 75
2023-01-05 15:44:16,157 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4035145044326782, 'Total loss': 0.4035145044326782} | train loss {'Reaction outcome loss': 0.2722777488106855, 'Total loss': 0.2722777488106855}
2023-01-05 15:44:16,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:16,159 INFO:     Epoch: 76
2023-01-05 15:44:18,322 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3192103539903959, 'Total loss': 0.3192103539903959} | train loss {'Reaction outcome loss': 0.26745381523663386, 'Total loss': 0.26745381523663386}
2023-01-05 15:44:18,322 INFO:     Found new best model at epoch 76
2023-01-05 15:44:18,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:18,323 INFO:     Epoch: 77
2023-01-05 15:44:20,460 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3798133065303167, 'Total loss': 0.3798133065303167} | train loss {'Reaction outcome loss': 0.2740122481696442, 'Total loss': 0.2740122481696442}
2023-01-05 15:44:20,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:20,461 INFO:     Epoch: 78
2023-01-05 15:44:22,618 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3670933117469152, 'Total loss': 0.3670933117469152} | train loss {'Reaction outcome loss': 0.2690587921021002, 'Total loss': 0.2690587921021002}
2023-01-05 15:44:22,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:22,619 INFO:     Epoch: 79
2023-01-05 15:44:24,770 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.37181540330251056, 'Total loss': 0.37181540330251056} | train loss {'Reaction outcome loss': 0.2715975872647784, 'Total loss': 0.2715975872647784}
2023-01-05 15:44:24,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:24,771 INFO:     Epoch: 80
2023-01-05 15:44:26,945 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.39345254202683766, 'Total loss': 0.39345254202683766} | train loss {'Reaction outcome loss': 0.27566226279961503, 'Total loss': 0.27566226279961503}
2023-01-05 15:44:26,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:26,945 INFO:     Epoch: 81
2023-01-05 15:44:29,119 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3962087780237198, 'Total loss': 0.3962087780237198} | train loss {'Reaction outcome loss': 0.2727421241735078, 'Total loss': 0.2727421241735078}
2023-01-05 15:44:29,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:29,119 INFO:     Epoch: 82
2023-01-05 15:44:31,291 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.31222045024236045, 'Total loss': 0.31222045024236045} | train loss {'Reaction outcome loss': 0.2668517759264806, 'Total loss': 0.2668517759264806}
2023-01-05 15:44:31,291 INFO:     Found new best model at epoch 82
2023-01-05 15:44:31,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:31,292 INFO:     Epoch: 83
2023-01-05 15:44:33,455 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.36818869411945343, 'Total loss': 0.36818869411945343} | train loss {'Reaction outcome loss': 0.2636147926995255, 'Total loss': 0.2636147926995255}
2023-01-05 15:44:33,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:33,455 INFO:     Epoch: 84
2023-01-05 15:44:35,630 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42008779644966127, 'Total loss': 0.42008779644966127} | train loss {'Reaction outcome loss': 0.25969925176500197, 'Total loss': 0.25969925176500197}
2023-01-05 15:44:35,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:35,631 INFO:     Epoch: 85
2023-01-05 15:44:37,808 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.33048512091239296, 'Total loss': 0.33048512091239296} | train loss {'Reaction outcome loss': 0.26776049098517707, 'Total loss': 0.26776049098517707}
2023-01-05 15:44:37,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:37,809 INFO:     Epoch: 86
2023-01-05 15:44:39,968 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.34894902606805167, 'Total loss': 0.34894902606805167} | train loss {'Reaction outcome loss': 0.2634972968283328, 'Total loss': 0.2634972968283328}
2023-01-05 15:44:39,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:39,968 INFO:     Epoch: 87
2023-01-05 15:44:42,135 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3334921730061372, 'Total loss': 0.3334921730061372} | train loss {'Reaction outcome loss': 0.2615594693563798, 'Total loss': 0.2615594693563798}
2023-01-05 15:44:42,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:42,136 INFO:     Epoch: 88
2023-01-05 15:44:44,277 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.34934424112240475, 'Total loss': 0.34934424112240475} | train loss {'Reaction outcome loss': 0.25999442512162757, 'Total loss': 0.25999442512162757}
2023-01-05 15:44:44,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:44,277 INFO:     Epoch: 89
2023-01-05 15:44:46,426 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3393036941687266, 'Total loss': 0.3393036941687266} | train loss {'Reaction outcome loss': 0.26829562134475915, 'Total loss': 0.26829562134475915}
2023-01-05 15:44:46,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:46,427 INFO:     Epoch: 90
2023-01-05 15:44:48,588 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.33267823259035745, 'Total loss': 0.33267823259035745} | train loss {'Reaction outcome loss': 0.25238959004409905, 'Total loss': 0.25238959004409905}
2023-01-05 15:44:48,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:48,588 INFO:     Epoch: 91
2023-01-05 15:44:50,760 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3464636395374934, 'Total loss': 0.3464636395374934} | train loss {'Reaction outcome loss': 0.2543221013048926, 'Total loss': 0.2543221013048926}
2023-01-05 15:44:50,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:50,761 INFO:     Epoch: 92
2023-01-05 15:44:52,906 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3432058205207189, 'Total loss': 0.3432058205207189} | train loss {'Reaction outcome loss': 0.25222121156241056, 'Total loss': 0.25222121156241056}
2023-01-05 15:44:52,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:52,907 INFO:     Epoch: 93
2023-01-05 15:44:55,075 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3230722216268381, 'Total loss': 0.3230722216268381} | train loss {'Reaction outcome loss': 0.2538314200904126, 'Total loss': 0.2538314200904126}
2023-01-05 15:44:55,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:55,076 INFO:     Epoch: 94
2023-01-05 15:44:57,235 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.36757315943638486, 'Total loss': 0.36757315943638486} | train loss {'Reaction outcome loss': 0.2538510038776303, 'Total loss': 0.2538510038776303}
2023-01-05 15:44:57,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:57,235 INFO:     Epoch: 95
2023-01-05 15:44:59,388 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35550561447938284, 'Total loss': 0.35550561447938284} | train loss {'Reaction outcome loss': 0.24734758205765636, 'Total loss': 0.24734758205765636}
2023-01-05 15:44:59,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:44:59,388 INFO:     Epoch: 96
2023-01-05 15:45:01,557 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39701957205931343, 'Total loss': 0.39701957205931343} | train loss {'Reaction outcome loss': 0.24684654164131367, 'Total loss': 0.24684654164131367}
2023-01-05 15:45:01,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:01,557 INFO:     Epoch: 97
2023-01-05 15:45:03,689 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3249953269958496, 'Total loss': 0.3249953269958496} | train loss {'Reaction outcome loss': 0.2520570096152999, 'Total loss': 0.2520570096152999}
2023-01-05 15:45:03,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:03,689 INFO:     Epoch: 98
2023-01-05 15:45:05,846 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.30886292407910027, 'Total loss': 0.30886292407910027} | train loss {'Reaction outcome loss': 0.24433826454091373, 'Total loss': 0.24433826454091373}
2023-01-05 15:45:05,847 INFO:     Found new best model at epoch 98
2023-01-05 15:45:05,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:05,849 INFO:     Epoch: 99
2023-01-05 15:45:07,994 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3630850161115328, 'Total loss': 0.3630850161115328} | train loss {'Reaction outcome loss': 0.2590984953399277, 'Total loss': 0.2590984953399277}
2023-01-05 15:45:07,994 INFO:     Best model found after epoch 99 of 100.
2023-01-05 15:45:07,994 INFO:   Done with stage: TRAINING
2023-01-05 15:45:07,994 INFO:   Starting stage: EVALUATION
2023-01-05 15:45:08,121 INFO:   Done with stage: EVALUATION
2023-01-05 15:45:08,122 INFO:   Leaving out SEQ value Fold_5
2023-01-05 15:45:08,134 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 15:45:08,134 INFO:   Starting stage: FEATURE SCALING
2023-01-05 15:45:08,783 INFO:   Done with stage: FEATURE SCALING
2023-01-05 15:45:08,783 INFO:   Starting stage: SCALING TARGETS
2023-01-05 15:45:08,853 INFO:   Done with stage: SCALING TARGETS
2023-01-05 15:45:08,853 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:45:08,853 INFO:     No hyperparam tuning for this model
2023-01-05 15:45:08,853 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:45:08,853 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 15:45:08,854 INFO:     None feature selector for col prot
2023-01-05 15:45:08,854 INFO:     None feature selector for col prot
2023-01-05 15:45:08,854 INFO:     None feature selector for col prot
2023-01-05 15:45:08,855 INFO:     None feature selector for col chem
2023-01-05 15:45:08,855 INFO:     None feature selector for col chem
2023-01-05 15:45:08,855 INFO:     None feature selector for col chem
2023-01-05 15:45:08,855 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 15:45:08,855 INFO:   Starting stage: BUILD MODEL
2023-01-05 15:45:08,857 INFO:     Number of params in model 72901
2023-01-05 15:45:08,860 INFO:   Done with stage: BUILD MODEL
2023-01-05 15:45:08,860 INFO:   Starting stage: TRAINING
2023-01-05 15:45:08,920 INFO:     Val loss before train {'Reaction outcome loss': 1.0622664014498393, 'Total loss': 1.0622664014498393}
2023-01-05 15:45:08,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:08,920 INFO:     Epoch: 0
2023-01-05 15:45:11,058 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8887507796287537, 'Total loss': 0.8887507796287537} | train loss {'Reaction outcome loss': 0.9431374102395816, 'Total loss': 0.9431374102395816}
2023-01-05 15:45:11,058 INFO:     Found new best model at epoch 0
2023-01-05 15:45:11,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:11,060 INFO:     Epoch: 1
2023-01-05 15:45:13,183 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7200767616430919, 'Total loss': 0.7200767616430919} | train loss {'Reaction outcome loss': 0.7817604794663234, 'Total loss': 0.7817604794663234}
2023-01-05 15:45:13,183 INFO:     Found new best model at epoch 1
2023-01-05 15:45:13,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:13,185 INFO:     Epoch: 2
2023-01-05 15:45:15,307 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6017872412999471, 'Total loss': 0.6017872412999471} | train loss {'Reaction outcome loss': 0.6154353152008822, 'Total loss': 0.6154353152008822}
2023-01-05 15:45:15,307 INFO:     Found new best model at epoch 2
2023-01-05 15:45:15,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:15,308 INFO:     Epoch: 3
2023-01-05 15:45:17,434 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5142355034748713, 'Total loss': 0.5142355034748713} | train loss {'Reaction outcome loss': 0.5564192324115412, 'Total loss': 0.5564192324115412}
2023-01-05 15:45:17,435 INFO:     Found new best model at epoch 3
2023-01-05 15:45:17,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:17,436 INFO:     Epoch: 4
2023-01-05 15:45:19,555 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5220157583554585, 'Total loss': 0.5220157583554585} | train loss {'Reaction outcome loss': 0.5242149192758285, 'Total loss': 0.5242149192758285}
2023-01-05 15:45:19,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:19,555 INFO:     Epoch: 5
2023-01-05 15:45:21,686 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5326332946618398, 'Total loss': 0.5326332946618398} | train loss {'Reaction outcome loss': 0.5023262180986195, 'Total loss': 0.5023262180986195}
2023-01-05 15:45:21,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:21,687 INFO:     Epoch: 6
2023-01-05 15:45:23,807 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5235953509807587, 'Total loss': 0.5235953509807587} | train loss {'Reaction outcome loss': 0.4945975548594537, 'Total loss': 0.4945975548594537}
2023-01-05 15:45:23,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:23,808 INFO:     Epoch: 7
2023-01-05 15:45:25,922 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5118045091629029, 'Total loss': 0.5118045091629029} | train loss {'Reaction outcome loss': 0.4865151433831584, 'Total loss': 0.4865151433831584}
2023-01-05 15:45:25,922 INFO:     Found new best model at epoch 7
2023-01-05 15:45:25,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:25,923 INFO:     Epoch: 8
2023-01-05 15:45:28,066 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5048056185245514, 'Total loss': 0.5048056185245514} | train loss {'Reaction outcome loss': 0.4799133385837513, 'Total loss': 0.4799133385837513}
2023-01-05 15:45:28,066 INFO:     Found new best model at epoch 8
2023-01-05 15:45:28,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:28,068 INFO:     Epoch: 9
2023-01-05 15:45:30,181 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4959649801254272, 'Total loss': 0.4959649801254272} | train loss {'Reaction outcome loss': 0.47218241906949204, 'Total loss': 0.47218241906949204}
2023-01-05 15:45:30,182 INFO:     Found new best model at epoch 9
2023-01-05 15:45:30,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:30,183 INFO:     Epoch: 10
2023-01-05 15:45:32,315 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4936863124370575, 'Total loss': 0.4936863124370575} | train loss {'Reaction outcome loss': 0.46030239812540313, 'Total loss': 0.46030239812540313}
2023-01-05 15:45:32,315 INFO:     Found new best model at epoch 10
2023-01-05 15:45:32,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:32,316 INFO:     Epoch: 11
2023-01-05 15:45:34,435 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5255772372086843, 'Total loss': 0.5255772372086843} | train loss {'Reaction outcome loss': 0.4628766218241114, 'Total loss': 0.4628766218241114}
2023-01-05 15:45:34,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:34,435 INFO:     Epoch: 12
2023-01-05 15:45:36,564 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5182648440202077, 'Total loss': 0.5182648440202077} | train loss {'Reaction outcome loss': 0.4581158244642463, 'Total loss': 0.4581158244642463}
2023-01-05 15:45:36,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:36,565 INFO:     Epoch: 13
2023-01-05 15:45:38,709 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47678243815898896, 'Total loss': 0.47678243815898896} | train loss {'Reaction outcome loss': 0.4567238978606506, 'Total loss': 0.4567238978606506}
2023-01-05 15:45:38,709 INFO:     Found new best model at epoch 13
2023-01-05 15:45:38,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:38,710 INFO:     Epoch: 14
2023-01-05 15:45:40,886 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5314216633637746, 'Total loss': 0.5314216633637746} | train loss {'Reaction outcome loss': 0.4452004336962735, 'Total loss': 0.4452004336962735}
2023-01-05 15:45:40,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:40,886 INFO:     Epoch: 15
2023-01-05 15:45:43,005 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5093082164724668, 'Total loss': 0.5093082164724668} | train loss {'Reaction outcome loss': 0.4403842217186942, 'Total loss': 0.4403842217186942}
2023-01-05 15:45:43,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:43,005 INFO:     Epoch: 16
2023-01-05 15:45:45,145 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.463446851571401, 'Total loss': 0.463446851571401} | train loss {'Reaction outcome loss': 0.43714359788781537, 'Total loss': 0.43714359788781537}
2023-01-05 15:45:45,145 INFO:     Found new best model at epoch 16
2023-01-05 15:45:45,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:45,146 INFO:     Epoch: 17
2023-01-05 15:45:47,334 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.480515060822169, 'Total loss': 0.480515060822169} | train loss {'Reaction outcome loss': 0.43047891192845184, 'Total loss': 0.43047891192845184}
2023-01-05 15:45:47,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:47,335 INFO:     Epoch: 18
2023-01-05 15:45:49,484 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4708365827798843, 'Total loss': 0.4708365827798843} | train loss {'Reaction outcome loss': 0.43453819737055877, 'Total loss': 0.43453819737055877}
2023-01-05 15:45:49,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:49,485 INFO:     Epoch: 19
2023-01-05 15:45:51,627 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4475446383158366, 'Total loss': 0.4475446383158366} | train loss {'Reaction outcome loss': 0.4271704980111035, 'Total loss': 0.4271704980111035}
2023-01-05 15:45:51,627 INFO:     Found new best model at epoch 19
2023-01-05 15:45:51,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:51,628 INFO:     Epoch: 20
2023-01-05 15:45:53,760 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4873440101742744, 'Total loss': 0.4873440101742744} | train loss {'Reaction outcome loss': 0.42316495103720764, 'Total loss': 0.42316495103720764}
2023-01-05 15:45:53,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:53,761 INFO:     Epoch: 21
2023-01-05 15:45:55,897 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46512395441532134, 'Total loss': 0.46512395441532134} | train loss {'Reaction outcome loss': 0.4172642452601534, 'Total loss': 0.4172642452601534}
2023-01-05 15:45:55,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:55,898 INFO:     Epoch: 22
2023-01-05 15:45:58,044 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4820687850316366, 'Total loss': 0.4820687850316366} | train loss {'Reaction outcome loss': 0.4116063720009623, 'Total loss': 0.4116063720009623}
2023-01-05 15:45:58,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:45:58,044 INFO:     Epoch: 23
2023-01-05 15:46:00,180 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4251191422343254, 'Total loss': 0.4251191422343254} | train loss {'Reaction outcome loss': 0.4126622503093124, 'Total loss': 0.4126622503093124}
2023-01-05 15:46:00,180 INFO:     Found new best model at epoch 23
2023-01-05 15:46:00,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:00,181 INFO:     Epoch: 24
2023-01-05 15:46:02,314 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4528440614541372, 'Total loss': 0.4528440614541372} | train loss {'Reaction outcome loss': 0.40669861794823275, 'Total loss': 0.40669861794823275}
2023-01-05 15:46:02,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:02,314 INFO:     Epoch: 25
2023-01-05 15:46:04,447 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4696963687737783, 'Total loss': 0.4696963687737783} | train loss {'Reaction outcome loss': 0.39835091014086765, 'Total loss': 0.39835091014086765}
2023-01-05 15:46:04,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:04,447 INFO:     Epoch: 26
2023-01-05 15:46:06,590 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4534166256586711, 'Total loss': 0.4534166256586711} | train loss {'Reaction outcome loss': 0.39756195703997227, 'Total loss': 0.39756195703997227}
2023-01-05 15:46:06,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:06,591 INFO:     Epoch: 27
2023-01-05 15:46:08,778 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45215457876523335, 'Total loss': 0.45215457876523335} | train loss {'Reaction outcome loss': 0.3906363309191091, 'Total loss': 0.3906363309191091}
2023-01-05 15:46:08,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:08,779 INFO:     Epoch: 28
2023-01-05 15:46:10,913 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47729456424713135, 'Total loss': 0.47729456424713135} | train loss {'Reaction outcome loss': 0.38986627757549286, 'Total loss': 0.38986627757549286}
2023-01-05 15:46:10,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:10,914 INFO:     Epoch: 29
2023-01-05 15:46:13,053 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4473104159037272, 'Total loss': 0.4473104159037272} | train loss {'Reaction outcome loss': 0.3883532245718215, 'Total loss': 0.3883532245718215}
2023-01-05 15:46:13,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:13,053 INFO:     Epoch: 30
2023-01-05 15:46:15,192 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43165087898572285, 'Total loss': 0.43165087898572285} | train loss {'Reaction outcome loss': 0.3800814102546577, 'Total loss': 0.3800814102546577}
2023-01-05 15:46:15,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:15,192 INFO:     Epoch: 31
2023-01-05 15:46:17,312 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45158938467502596, 'Total loss': 0.45158938467502596} | train loss {'Reaction outcome loss': 0.37037450629864294, 'Total loss': 0.37037450629864294}
2023-01-05 15:46:17,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:17,313 INFO:     Epoch: 32
2023-01-05 15:46:19,440 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4471070577700933, 'Total loss': 0.4471070577700933} | train loss {'Reaction outcome loss': 0.3748086615581147, 'Total loss': 0.3748086615581147}
2023-01-05 15:46:19,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:19,441 INFO:     Epoch: 33
2023-01-05 15:46:21,584 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46095871527989707, 'Total loss': 0.46095871527989707} | train loss {'Reaction outcome loss': 0.3727543201215946, 'Total loss': 0.3727543201215946}
2023-01-05 15:46:21,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:21,584 INFO:     Epoch: 34
2023-01-05 15:46:23,724 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41935626963774364, 'Total loss': 0.41935626963774364} | train loss {'Reaction outcome loss': 0.3634440420861662, 'Total loss': 0.3634440420861662}
2023-01-05 15:46:23,725 INFO:     Found new best model at epoch 34
2023-01-05 15:46:23,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:23,727 INFO:     Epoch: 35
2023-01-05 15:46:25,861 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46375500957171123, 'Total loss': 0.46375500957171123} | train loss {'Reaction outcome loss': 0.35750384408518343, 'Total loss': 0.35750384408518343}
2023-01-05 15:46:25,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:25,861 INFO:     Epoch: 36
2023-01-05 15:46:27,984 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4319179753462474, 'Total loss': 0.4319179753462474} | train loss {'Reaction outcome loss': 0.35802415377684754, 'Total loss': 0.35802415377684754}
2023-01-05 15:46:27,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:27,984 INFO:     Epoch: 37
2023-01-05 15:46:30,111 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4512093385060628, 'Total loss': 0.4512093385060628} | train loss {'Reaction outcome loss': 0.3571218540416147, 'Total loss': 0.3571218540416147}
2023-01-05 15:46:30,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:30,112 INFO:     Epoch: 38
2023-01-05 15:46:32,245 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4323610226313273, 'Total loss': 0.4323610226313273} | train loss {'Reaction outcome loss': 0.35086743507778995, 'Total loss': 0.35086743507778995}
2023-01-05 15:46:32,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:32,245 INFO:     Epoch: 39
2023-01-05 15:46:34,381 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43734063108762106, 'Total loss': 0.43734063108762106} | train loss {'Reaction outcome loss': 0.3442689526255113, 'Total loss': 0.3442689526255113}
2023-01-05 15:46:34,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:34,381 INFO:     Epoch: 40
2023-01-05 15:46:36,487 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4618326927224795, 'Total loss': 0.4618326927224795} | train loss {'Reaction outcome loss': 0.3435399375420852, 'Total loss': 0.3435399375420852}
2023-01-05 15:46:36,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:36,488 INFO:     Epoch: 41
2023-01-05 15:46:38,606 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43407825380563736, 'Total loss': 0.43407825380563736} | train loss {'Reaction outcome loss': 0.34122895650620005, 'Total loss': 0.34122895650620005}
2023-01-05 15:46:38,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:38,607 INFO:     Epoch: 42
2023-01-05 15:46:40,739 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4366600463787715, 'Total loss': 0.4366600463787715} | train loss {'Reaction outcome loss': 0.33531226342829473, 'Total loss': 0.33531226342829473}
2023-01-05 15:46:40,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:40,739 INFO:     Epoch: 43
2023-01-05 15:46:42,868 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.428118962670366, 'Total loss': 0.428118962670366} | train loss {'Reaction outcome loss': 0.33534234686054454, 'Total loss': 0.33534234686054454}
2023-01-05 15:46:42,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:42,869 INFO:     Epoch: 44
2023-01-05 15:46:45,034 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4085266311963399, 'Total loss': 0.4085266311963399} | train loss {'Reaction outcome loss': 0.33647852683997287, 'Total loss': 0.33647852683997287}
2023-01-05 15:46:45,034 INFO:     Found new best model at epoch 44
2023-01-05 15:46:45,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:45,036 INFO:     Epoch: 45
2023-01-05 15:46:47,210 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42861969470977784, 'Total loss': 0.42861969470977784} | train loss {'Reaction outcome loss': 0.33090907323724816, 'Total loss': 0.33090907323724816}
2023-01-05 15:46:47,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:47,210 INFO:     Epoch: 46
2023-01-05 15:46:49,348 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3989176352818807, 'Total loss': 0.3989176352818807} | train loss {'Reaction outcome loss': 0.32841718776056367, 'Total loss': 0.32841718776056367}
2023-01-05 15:46:49,348 INFO:     Found new best model at epoch 46
2023-01-05 15:46:49,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:49,350 INFO:     Epoch: 47
2023-01-05 15:46:51,468 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43568045695622765, 'Total loss': 0.43568045695622765} | train loss {'Reaction outcome loss': 0.3194791133767062, 'Total loss': 0.3194791133767062}
2023-01-05 15:46:51,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:51,468 INFO:     Epoch: 48
2023-01-05 15:46:53,599 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4441563725471497, 'Total loss': 0.4441563725471497} | train loss {'Reaction outcome loss': 0.32383251585827694, 'Total loss': 0.32383251585827694}
2023-01-05 15:46:53,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:53,600 INFO:     Epoch: 49
2023-01-05 15:46:55,726 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43967656592528026, 'Total loss': 0.43967656592528026} | train loss {'Reaction outcome loss': 0.3175139460257207, 'Total loss': 0.3175139460257207}
2023-01-05 15:46:55,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:55,726 INFO:     Epoch: 50
2023-01-05 15:46:57,865 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.444177116950353, 'Total loss': 0.444177116950353} | train loss {'Reaction outcome loss': 0.3194625799945236, 'Total loss': 0.3194625799945236}
2023-01-05 15:46:57,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:46:57,866 INFO:     Epoch: 51
2023-01-05 15:47:00,003 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43695317904154457, 'Total loss': 0.43695317904154457} | train loss {'Reaction outcome loss': 0.31370776532775296, 'Total loss': 0.31370776532775296}
2023-01-05 15:47:00,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:00,004 INFO:     Epoch: 52
2023-01-05 15:47:02,131 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42576944877703987, 'Total loss': 0.42576944877703987} | train loss {'Reaction outcome loss': 0.31475495767990386, 'Total loss': 0.31475495767990386}
2023-01-05 15:47:02,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:02,131 INFO:     Epoch: 53
2023-01-05 15:47:04,257 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45710834066073097, 'Total loss': 0.45710834066073097} | train loss {'Reaction outcome loss': 0.3070388536655555, 'Total loss': 0.3070388536655555}
2023-01-05 15:47:04,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:04,257 INFO:     Epoch: 54
2023-01-05 15:47:06,384 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4142986426750819, 'Total loss': 0.4142986426750819} | train loss {'Reaction outcome loss': 0.3069414082357157, 'Total loss': 0.3069414082357157}
2023-01-05 15:47:06,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:06,384 INFO:     Epoch: 55
2023-01-05 15:47:08,536 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4129257241884867, 'Total loss': 0.4129257241884867} | train loss {'Reaction outcome loss': 0.3091922524745447, 'Total loss': 0.3091922524745447}
2023-01-05 15:47:08,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:08,537 INFO:     Epoch: 56
2023-01-05 15:47:10,699 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4147110794981321, 'Total loss': 0.4147110794981321} | train loss {'Reaction outcome loss': 0.2924388535184799, 'Total loss': 0.2924388535184799}
2023-01-05 15:47:10,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:10,699 INFO:     Epoch: 57
2023-01-05 15:47:12,804 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4446532885233561, 'Total loss': 0.4446532885233561} | train loss {'Reaction outcome loss': 0.30026484222362076, 'Total loss': 0.30026484222362076}
2023-01-05 15:47:12,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:12,805 INFO:     Epoch: 58
2023-01-05 15:47:14,920 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42850979790091515, 'Total loss': 0.42850979790091515} | train loss {'Reaction outcome loss': 0.3000485457915024, 'Total loss': 0.3000485457915024}
2023-01-05 15:47:14,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:14,921 INFO:     Epoch: 59
2023-01-05 15:47:17,054 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4664215475320816, 'Total loss': 0.4664215475320816} | train loss {'Reaction outcome loss': 0.29410136991391217, 'Total loss': 0.29410136991391217}
2023-01-05 15:47:17,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:17,054 INFO:     Epoch: 60
2023-01-05 15:47:19,158 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48344051937262217, 'Total loss': 0.48344051937262217} | train loss {'Reaction outcome loss': 0.28409862834416383, 'Total loss': 0.28409862834416383}
2023-01-05 15:47:19,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:19,158 INFO:     Epoch: 61
2023-01-05 15:47:21,289 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.431031608581543, 'Total loss': 0.431031608581543} | train loss {'Reaction outcome loss': 0.2951718882460446, 'Total loss': 0.2951718882460446}
2023-01-05 15:47:21,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:21,290 INFO:     Epoch: 62
2023-01-05 15:47:23,225 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.418215777973334, 'Total loss': 0.418215777973334} | train loss {'Reaction outcome loss': 0.28213997772575294, 'Total loss': 0.28213997772575294}
2023-01-05 15:47:23,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:23,225 INFO:     Epoch: 63
2023-01-05 15:47:25,352 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4320680684099595, 'Total loss': 0.4320680684099595} | train loss {'Reaction outcome loss': 0.2829193468647499, 'Total loss': 0.2829193468647499}
2023-01-05 15:47:25,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:25,353 INFO:     Epoch: 64
2023-01-05 15:47:27,480 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42265918652216594, 'Total loss': 0.42265918652216594} | train loss {'Reaction outcome loss': 0.2775273762208267, 'Total loss': 0.2775273762208267}
2023-01-05 15:47:27,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:27,480 INFO:     Epoch: 65
2023-01-05 15:47:29,612 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44010280867417656, 'Total loss': 0.44010280867417656} | train loss {'Reaction outcome loss': 0.2847433845736902, 'Total loss': 0.2847433845736902}
2023-01-05 15:47:29,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:29,613 INFO:     Epoch: 66
2023-01-05 15:47:31,741 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42902702192465464, 'Total loss': 0.42902702192465464} | train loss {'Reaction outcome loss': 0.27403089983973405, 'Total loss': 0.27403089983973405}
2023-01-05 15:47:31,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:31,741 INFO:     Epoch: 67
2023-01-05 15:47:33,869 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4204974661270777, 'Total loss': 0.4204974661270777} | train loss {'Reaction outcome loss': 0.27919603506252716, 'Total loss': 0.27919603506252716}
2023-01-05 15:47:33,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:33,870 INFO:     Epoch: 68
2023-01-05 15:47:35,997 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4143068974216779, 'Total loss': 0.4143068974216779} | train loss {'Reaction outcome loss': 0.2730112582118842, 'Total loss': 0.2730112582118842}
2023-01-05 15:47:35,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:35,998 INFO:     Epoch: 69
2023-01-05 15:47:38,193 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4257368206977844, 'Total loss': 0.4257368206977844} | train loss {'Reaction outcome loss': 0.26977957299754135, 'Total loss': 0.26977957299754135}
2023-01-05 15:47:38,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:38,193 INFO:     Epoch: 70
2023-01-05 15:47:40,398 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38462464610735575, 'Total loss': 0.38462464610735575} | train loss {'Reaction outcome loss': 0.2727000700024358, 'Total loss': 0.2727000700024358}
2023-01-05 15:47:40,398 INFO:     Found new best model at epoch 70
2023-01-05 15:47:40,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:40,399 INFO:     Epoch: 71
2023-01-05 15:47:42,612 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4041586697101593, 'Total loss': 0.4041586697101593} | train loss {'Reaction outcome loss': 0.2701890919439114, 'Total loss': 0.2701890919439114}
2023-01-05 15:47:42,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:42,613 INFO:     Epoch: 72
2023-01-05 15:47:44,814 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40645108620325726, 'Total loss': 0.40645108620325726} | train loss {'Reaction outcome loss': 0.2714284311871242, 'Total loss': 0.2714284311871242}
2023-01-05 15:47:44,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:44,815 INFO:     Epoch: 73
2023-01-05 15:47:47,009 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44014086027940114, 'Total loss': 0.44014086027940114} | train loss {'Reaction outcome loss': 0.2582961438923911, 'Total loss': 0.2582961438923911}
2023-01-05 15:47:47,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:47,010 INFO:     Epoch: 74
2023-01-05 15:47:49,128 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4040014018615087, 'Total loss': 0.4040014018615087} | train loss {'Reaction outcome loss': 0.25992936265049843, 'Total loss': 0.25992936265049843}
2023-01-05 15:47:49,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:49,129 INFO:     Epoch: 75
2023-01-05 15:47:51,254 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4293601622184118, 'Total loss': 0.4293601622184118} | train loss {'Reaction outcome loss': 0.2709077502172576, 'Total loss': 0.2709077502172576}
2023-01-05 15:47:51,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:51,255 INFO:     Epoch: 76
2023-01-05 15:47:53,364 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46123791535695396, 'Total loss': 0.46123791535695396} | train loss {'Reaction outcome loss': 0.2613318154765089, 'Total loss': 0.2613318154765089}
2023-01-05 15:47:53,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:53,364 INFO:     Epoch: 77
2023-01-05 15:47:55,487 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4592617601156235, 'Total loss': 0.4592617601156235} | train loss {'Reaction outcome loss': 0.26077120471065934, 'Total loss': 0.26077120471065934}
2023-01-05 15:47:55,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:55,487 INFO:     Epoch: 78
2023-01-05 15:47:57,627 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43430904746055604, 'Total loss': 0.43430904746055604} | train loss {'Reaction outcome loss': 0.2531394892351797, 'Total loss': 0.2531394892351797}
2023-01-05 15:47:57,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:57,627 INFO:     Epoch: 79
2023-01-05 15:47:59,751 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45457445631424587, 'Total loss': 0.45457445631424587} | train loss {'Reaction outcome loss': 0.2509965328159776, 'Total loss': 0.2509965328159776}
2023-01-05 15:47:59,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:47:59,751 INFO:     Epoch: 80
2023-01-05 15:48:01,874 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4518534560998281, 'Total loss': 0.4518534560998281} | train loss {'Reaction outcome loss': 0.2507105840465231, 'Total loss': 0.2507105840465231}
2023-01-05 15:48:01,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:01,874 INFO:     Epoch: 81
2023-01-05 15:48:04,002 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45821829289197924, 'Total loss': 0.45821829289197924} | train loss {'Reaction outcome loss': 0.24622330374091211, 'Total loss': 0.24622330374091211}
2023-01-05 15:48:04,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:04,002 INFO:     Epoch: 82
2023-01-05 15:48:06,118 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4570273578166962, 'Total loss': 0.4570273578166962} | train loss {'Reaction outcome loss': 0.2531029643171406, 'Total loss': 0.2531029643171406}
2023-01-05 15:48:06,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:06,119 INFO:     Epoch: 83
2023-01-05 15:48:08,239 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45508966147899627, 'Total loss': 0.45508966147899627} | train loss {'Reaction outcome loss': 0.25684635374817427, 'Total loss': 0.25684635374817427}
2023-01-05 15:48:08,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:08,239 INFO:     Epoch: 84
2023-01-05 15:48:10,380 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4676660771171252, 'Total loss': 0.4676660771171252} | train loss {'Reaction outcome loss': 0.2470459307673095, 'Total loss': 0.2470459307673095}
2023-01-05 15:48:10,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:10,380 INFO:     Epoch: 85
2023-01-05 15:48:12,496 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4349517946441968, 'Total loss': 0.4349517946441968} | train loss {'Reaction outcome loss': 0.25273311173502544, 'Total loss': 0.25273311173502544}
2023-01-05 15:48:12,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:12,497 INFO:     Epoch: 86
2023-01-05 15:48:14,631 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4603294491767883, 'Total loss': 0.4603294491767883} | train loss {'Reaction outcome loss': 0.2481116724139365, 'Total loss': 0.2481116724139365}
2023-01-05 15:48:14,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:14,631 INFO:     Epoch: 87
2023-01-05 15:48:16,761 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4428075720866521, 'Total loss': 0.4428075720866521} | train loss {'Reaction outcome loss': 0.2538854358038002, 'Total loss': 0.2538854358038002}
2023-01-05 15:48:16,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:16,762 INFO:     Epoch: 88
2023-01-05 15:48:18,898 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43489302645126976, 'Total loss': 0.43489302645126976} | train loss {'Reaction outcome loss': 0.24393122869604913, 'Total loss': 0.24393122869604913}
2023-01-05 15:48:18,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:18,898 INFO:     Epoch: 89
2023-01-05 15:48:21,028 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4142260938882828, 'Total loss': 0.4142260938882828} | train loss {'Reaction outcome loss': 0.24573569080323307, 'Total loss': 0.24573569080323307}
2023-01-05 15:48:21,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:21,028 INFO:     Epoch: 90
2023-01-05 15:48:23,140 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44571805497010547, 'Total loss': 0.44571805497010547} | train loss {'Reaction outcome loss': 0.24293893980147846, 'Total loss': 0.24293893980147846}
2023-01-05 15:48:23,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:23,141 INFO:     Epoch: 91
2023-01-05 15:48:25,286 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4674271752436956, 'Total loss': 0.4674271752436956} | train loss {'Reaction outcome loss': 0.2402221235942884, 'Total loss': 0.2402221235942884}
2023-01-05 15:48:25,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:25,287 INFO:     Epoch: 92
2023-01-05 15:48:27,418 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42562965750694276, 'Total loss': 0.42562965750694276} | train loss {'Reaction outcome loss': 0.2401809799586878, 'Total loss': 0.2401809799586878}
2023-01-05 15:48:27,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:27,419 INFO:     Epoch: 93
2023-01-05 15:48:29,562 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44294413725535076, 'Total loss': 0.44294413725535076} | train loss {'Reaction outcome loss': 0.23336056897579863, 'Total loss': 0.23336056897579863}
2023-01-05 15:48:29,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:29,563 INFO:     Epoch: 94
2023-01-05 15:48:31,701 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44954840739568075, 'Total loss': 0.44954840739568075} | train loss {'Reaction outcome loss': 0.2387054668753034, 'Total loss': 0.2387054668753034}
2023-01-05 15:48:31,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:31,701 INFO:     Epoch: 95
2023-01-05 15:48:33,829 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4327166825532913, 'Total loss': 0.4327166825532913} | train loss {'Reaction outcome loss': 0.23911990321846338, 'Total loss': 0.23911990321846338}
2023-01-05 15:48:33,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:33,829 INFO:     Epoch: 96
2023-01-05 15:48:35,979 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4558954417705536, 'Total loss': 0.4558954417705536} | train loss {'Reaction outcome loss': 0.2316226596964428, 'Total loss': 0.2316226596964428}
2023-01-05 15:48:35,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:35,980 INFO:     Epoch: 97
2023-01-05 15:48:38,137 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4362083405256271, 'Total loss': 0.4362083405256271} | train loss {'Reaction outcome loss': 0.23961052184339857, 'Total loss': 0.23961052184339857}
2023-01-05 15:48:38,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:38,137 INFO:     Epoch: 98
2023-01-05 15:48:40,274 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43744802474975586, 'Total loss': 0.43744802474975586} | train loss {'Reaction outcome loss': 0.23078518691914576, 'Total loss': 0.23078518691914576}
2023-01-05 15:48:40,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:40,274 INFO:     Epoch: 99
2023-01-05 15:48:42,423 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4329475370856623, 'Total loss': 0.4329475370856623} | train loss {'Reaction outcome loss': 0.235024802583902, 'Total loss': 0.235024802583902}
2023-01-05 15:48:42,424 INFO:     Best model found after epoch 71 of 100.
2023-01-05 15:48:42,424 INFO:   Done with stage: TRAINING
2023-01-05 15:48:42,424 INFO:   Starting stage: EVALUATION
2023-01-05 15:48:42,563 INFO:   Done with stage: EVALUATION
2023-01-05 15:48:42,563 INFO:   Leaving out SEQ value Fold_6
2023-01-05 15:48:42,576 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 15:48:42,576 INFO:   Starting stage: FEATURE SCALING
2023-01-05 15:48:43,239 INFO:   Done with stage: FEATURE SCALING
2023-01-05 15:48:43,239 INFO:   Starting stage: SCALING TARGETS
2023-01-05 15:48:43,308 INFO:   Done with stage: SCALING TARGETS
2023-01-05 15:48:43,308 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:48:43,308 INFO:     No hyperparam tuning for this model
2023-01-05 15:48:43,308 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:48:43,308 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 15:48:43,309 INFO:     None feature selector for col prot
2023-01-05 15:48:43,309 INFO:     None feature selector for col prot
2023-01-05 15:48:43,309 INFO:     None feature selector for col prot
2023-01-05 15:48:43,310 INFO:     None feature selector for col chem
2023-01-05 15:48:43,310 INFO:     None feature selector for col chem
2023-01-05 15:48:43,310 INFO:     None feature selector for col chem
2023-01-05 15:48:43,310 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 15:48:43,310 INFO:   Starting stage: BUILD MODEL
2023-01-05 15:48:43,311 INFO:     Number of params in model 72901
2023-01-05 15:48:43,315 INFO:   Done with stage: BUILD MODEL
2023-01-05 15:48:43,315 INFO:   Starting stage: TRAINING
2023-01-05 15:48:43,375 INFO:     Val loss before train {'Reaction outcome loss': 1.0120510697364806, 'Total loss': 1.0120510697364806}
2023-01-05 15:48:43,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:43,375 INFO:     Epoch: 0
2023-01-05 15:48:45,532 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8381653547286987, 'Total loss': 0.8381653547286987} | train loss {'Reaction outcome loss': 0.9210073016180459, 'Total loss': 0.9210073016180459}
2023-01-05 15:48:45,532 INFO:     Found new best model at epoch 0
2023-01-05 15:48:45,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:45,533 INFO:     Epoch: 1
2023-01-05 15:48:47,703 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6528408050537109, 'Total loss': 0.6528408050537109} | train loss {'Reaction outcome loss': 0.7825794941896996, 'Total loss': 0.7825794941896996}
2023-01-05 15:48:47,704 INFO:     Found new best model at epoch 1
2023-01-05 15:48:47,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:47,705 INFO:     Epoch: 2
2023-01-05 15:48:49,875 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5210092504819234, 'Total loss': 0.5210092504819234} | train loss {'Reaction outcome loss': 0.628411290877993, 'Total loss': 0.628411290877993}
2023-01-05 15:48:49,875 INFO:     Found new best model at epoch 2
2023-01-05 15:48:49,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:49,876 INFO:     Epoch: 3
2023-01-05 15:48:52,028 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48751731117566427, 'Total loss': 0.48751731117566427} | train loss {'Reaction outcome loss': 0.5443817016665256, 'Total loss': 0.5443817016665256}
2023-01-05 15:48:52,028 INFO:     Found new best model at epoch 3
2023-01-05 15:48:52,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:52,029 INFO:     Epoch: 4
2023-01-05 15:48:54,217 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4545692374308904, 'Total loss': 0.4545692374308904} | train loss {'Reaction outcome loss': 0.5230433969398698, 'Total loss': 0.5230433969398698}
2023-01-05 15:48:54,217 INFO:     Found new best model at epoch 4
2023-01-05 15:48:54,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:54,218 INFO:     Epoch: 5
2023-01-05 15:48:56,401 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46749725739161174, 'Total loss': 0.46749725739161174} | train loss {'Reaction outcome loss': 0.5079140032671849, 'Total loss': 0.5079140032671849}
2023-01-05 15:48:56,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:56,401 INFO:     Epoch: 6
2023-01-05 15:48:58,571 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43611466884613037, 'Total loss': 0.43611466884613037} | train loss {'Reaction outcome loss': 0.4968905994392905, 'Total loss': 0.4968905994392905}
2023-01-05 15:48:58,571 INFO:     Found new best model at epoch 6
2023-01-05 15:48:58,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:48:58,573 INFO:     Epoch: 7
2023-01-05 15:49:00,733 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4420088728268941, 'Total loss': 0.4420088728268941} | train loss {'Reaction outcome loss': 0.4877588931296276, 'Total loss': 0.4877588931296276}
2023-01-05 15:49:00,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:00,733 INFO:     Epoch: 8
2023-01-05 15:49:02,880 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4402700444062551, 'Total loss': 0.4402700444062551} | train loss {'Reaction outcome loss': 0.4799103702986714, 'Total loss': 0.4799103702986714}
2023-01-05 15:49:02,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:02,880 INFO:     Epoch: 9
2023-01-05 15:49:05,052 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4278447876373927, 'Total loss': 0.4278447876373927} | train loss {'Reaction outcome loss': 0.4740250525384173, 'Total loss': 0.4740250525384173}
2023-01-05 15:49:05,052 INFO:     Found new best model at epoch 9
2023-01-05 15:49:05,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:05,053 INFO:     Epoch: 10
2023-01-05 15:49:07,219 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4386362969875336, 'Total loss': 0.4386362969875336} | train loss {'Reaction outcome loss': 0.4707351938051437, 'Total loss': 0.4707351938051437}
2023-01-05 15:49:07,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:07,219 INFO:     Epoch: 11
2023-01-05 15:49:09,373 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44610857566197715, 'Total loss': 0.44610857566197715} | train loss {'Reaction outcome loss': 0.4660332260471819, 'Total loss': 0.4660332260471819}
2023-01-05 15:49:09,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:09,374 INFO:     Epoch: 12
2023-01-05 15:49:11,543 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.462749058008194, 'Total loss': 0.462749058008194} | train loss {'Reaction outcome loss': 0.46059367528676126, 'Total loss': 0.46059367528676126}
2023-01-05 15:49:11,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:11,544 INFO:     Epoch: 13
2023-01-05 15:49:13,716 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4277434587478638, 'Total loss': 0.4277434587478638} | train loss {'Reaction outcome loss': 0.45071168372992576, 'Total loss': 0.45071168372992576}
2023-01-05 15:49:13,716 INFO:     Found new best model at epoch 13
2023-01-05 15:49:13,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:13,717 INFO:     Epoch: 14
2023-01-05 15:49:15,876 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4281385918458303, 'Total loss': 0.4281385918458303} | train loss {'Reaction outcome loss': 0.44955945321584007, 'Total loss': 0.44955945321584007}
2023-01-05 15:49:15,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:15,876 INFO:     Epoch: 15
2023-01-05 15:49:18,040 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.428212567170461, 'Total loss': 0.428212567170461} | train loss {'Reaction outcome loss': 0.44811754646822005, 'Total loss': 0.44811754646822005}
2023-01-05 15:49:18,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:18,041 INFO:     Epoch: 16
2023-01-05 15:49:20,204 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4075279081861178, 'Total loss': 0.4075279081861178} | train loss {'Reaction outcome loss': 0.4417912078893572, 'Total loss': 0.4417912078893572}
2023-01-05 15:49:20,204 INFO:     Found new best model at epoch 16
2023-01-05 15:49:20,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:20,205 INFO:     Epoch: 17
2023-01-05 15:49:22,358 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4302704413731893, 'Total loss': 0.4302704413731893} | train loss {'Reaction outcome loss': 0.43859779291419776, 'Total loss': 0.43859779291419776}
2023-01-05 15:49:22,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:22,359 INFO:     Epoch: 18
2023-01-05 15:49:24,512 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40190066893895465, 'Total loss': 0.40190066893895465} | train loss {'Reaction outcome loss': 0.4368142164732575, 'Total loss': 0.4368142164732575}
2023-01-05 15:49:24,512 INFO:     Found new best model at epoch 18
2023-01-05 15:49:24,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:24,514 INFO:     Epoch: 19
2023-01-05 15:49:26,672 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42213239073753356, 'Total loss': 0.42213239073753356} | train loss {'Reaction outcome loss': 0.43017376101296734, 'Total loss': 0.43017376101296734}
2023-01-05 15:49:26,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:26,672 INFO:     Epoch: 20
2023-01-05 15:49:28,837 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3908940573533376, 'Total loss': 0.3908940573533376} | train loss {'Reaction outcome loss': 0.427029995119959, 'Total loss': 0.427029995119959}
2023-01-05 15:49:28,837 INFO:     Found new best model at epoch 20
2023-01-05 15:49:28,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:28,838 INFO:     Epoch: 21
2023-01-05 15:49:31,018 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3907012636462847, 'Total loss': 0.3907012636462847} | train loss {'Reaction outcome loss': 0.4259165756754066, 'Total loss': 0.4259165756754066}
2023-01-05 15:49:31,018 INFO:     Found new best model at epoch 21
2023-01-05 15:49:31,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:31,020 INFO:     Epoch: 22
2023-01-05 15:49:33,176 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41906486749649047, 'Total loss': 0.41906486749649047} | train loss {'Reaction outcome loss': 0.4224643459281336, 'Total loss': 0.4224643459281336}
2023-01-05 15:49:33,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:33,176 INFO:     Epoch: 23
2023-01-05 15:49:35,340 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40384162664413453, 'Total loss': 0.40384162664413453} | train loss {'Reaction outcome loss': 0.4181687264208974, 'Total loss': 0.4181687264208974}
2023-01-05 15:49:35,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:35,340 INFO:     Epoch: 24
2023-01-05 15:49:37,493 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3840694189071655, 'Total loss': 0.3840694189071655} | train loss {'Reaction outcome loss': 0.4166341373152251, 'Total loss': 0.4166341373152251}
2023-01-05 15:49:37,493 INFO:     Found new best model at epoch 24
2023-01-05 15:49:37,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:37,494 INFO:     Epoch: 25
2023-01-05 15:49:39,659 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.35089333752791085, 'Total loss': 0.35089333752791085} | train loss {'Reaction outcome loss': 0.41243733212835954, 'Total loss': 0.41243733212835954}
2023-01-05 15:49:39,659 INFO:     Found new best model at epoch 25
2023-01-05 15:49:39,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:39,661 INFO:     Epoch: 26
2023-01-05 15:49:41,843 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3742304732402166, 'Total loss': 0.3742304732402166} | train loss {'Reaction outcome loss': 0.40726020402318736, 'Total loss': 0.40726020402318736}
2023-01-05 15:49:41,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:41,843 INFO:     Epoch: 27
2023-01-05 15:49:44,004 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3927316009998322, 'Total loss': 0.3927316009998322} | train loss {'Reaction outcome loss': 0.40529190278225424, 'Total loss': 0.40529190278225424}
2023-01-05 15:49:44,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:44,005 INFO:     Epoch: 28
2023-01-05 15:49:46,178 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38432604173819224, 'Total loss': 0.38432604173819224} | train loss {'Reaction outcome loss': 0.40350831619426875, 'Total loss': 0.40350831619426875}
2023-01-05 15:49:46,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:46,178 INFO:     Epoch: 29
2023-01-05 15:49:48,344 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4002543012301127, 'Total loss': 0.4002543012301127} | train loss {'Reaction outcome loss': 0.39969523046636407, 'Total loss': 0.39969523046636407}
2023-01-05 15:49:48,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:48,345 INFO:     Epoch: 30
2023-01-05 15:49:50,498 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3892575154701869, 'Total loss': 0.3892575154701869} | train loss {'Reaction outcome loss': 0.3996307747404928, 'Total loss': 0.3996307747404928}
2023-01-05 15:49:50,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:50,498 INFO:     Epoch: 31
2023-01-05 15:49:52,669 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38422719736893973, 'Total loss': 0.38422719736893973} | train loss {'Reaction outcome loss': 0.3985217753730526, 'Total loss': 0.3985217753730526}
2023-01-05 15:49:52,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:52,670 INFO:     Epoch: 32
2023-01-05 15:49:54,844 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3459366758664449, 'Total loss': 0.3459366758664449} | train loss {'Reaction outcome loss': 0.39133678578405173, 'Total loss': 0.39133678578405173}
2023-01-05 15:49:54,845 INFO:     Found new best model at epoch 32
2023-01-05 15:49:54,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:54,846 INFO:     Epoch: 33
2023-01-05 15:49:57,001 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.37932161887486776, 'Total loss': 0.37932161887486776} | train loss {'Reaction outcome loss': 0.38637528234978447, 'Total loss': 0.38637528234978447}
2023-01-05 15:49:57,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:57,001 INFO:     Epoch: 34
2023-01-05 15:49:59,165 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4012076536814372, 'Total loss': 0.4012076536814372} | train loss {'Reaction outcome loss': 0.38322978219293086, 'Total loss': 0.38322978219293086}
2023-01-05 15:49:59,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:49:59,166 INFO:     Epoch: 35
2023-01-05 15:50:01,326 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38388751248518627, 'Total loss': 0.38388751248518627} | train loss {'Reaction outcome loss': 0.37695411942388174, 'Total loss': 0.37695411942388174}
2023-01-05 15:50:01,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:01,326 INFO:     Epoch: 36
2023-01-05 15:50:03,499 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37242733538150785, 'Total loss': 0.37242733538150785} | train loss {'Reaction outcome loss': 0.3758988521777981, 'Total loss': 0.3758988521777981}
2023-01-05 15:50:03,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:03,499 INFO:     Epoch: 37
2023-01-05 15:50:05,661 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3859036087989807, 'Total loss': 0.3859036087989807} | train loss {'Reaction outcome loss': 0.3743508759926372, 'Total loss': 0.3743508759926372}
2023-01-05 15:50:05,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:05,661 INFO:     Epoch: 38
2023-01-05 15:50:07,592 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3470520223180453, 'Total loss': 0.3470520223180453} | train loss {'Reaction outcome loss': 0.3657215030507491, 'Total loss': 0.3657215030507491}
2023-01-05 15:50:07,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:07,593 INFO:     Epoch: 39
2023-01-05 15:50:09,347 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3530276765426, 'Total loss': 0.3530276765426} | train loss {'Reaction outcome loss': 0.36539577203214385, 'Total loss': 0.36539577203214385}
2023-01-05 15:50:09,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:09,347 INFO:     Epoch: 40
2023-01-05 15:50:11,175 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3482438350717227, 'Total loss': 0.3482438350717227} | train loss {'Reaction outcome loss': 0.35915546113833624, 'Total loss': 0.35915546113833624}
2023-01-05 15:50:11,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:11,175 INFO:     Epoch: 41
2023-01-05 15:50:13,297 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.361052139600118, 'Total loss': 0.361052139600118} | train loss {'Reaction outcome loss': 0.35676608853284203, 'Total loss': 0.35676608853284203}
2023-01-05 15:50:13,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:13,298 INFO:     Epoch: 42
2023-01-05 15:50:15,435 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4048869788646698, 'Total loss': 0.4048869788646698} | train loss {'Reaction outcome loss': 0.35797746334265285, 'Total loss': 0.35797746334265285}
2023-01-05 15:50:15,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:15,436 INFO:     Epoch: 43
2023-01-05 15:50:17,594 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.34034389555454253, 'Total loss': 0.34034389555454253} | train loss {'Reaction outcome loss': 0.3519905608429805, 'Total loss': 0.3519905608429805}
2023-01-05 15:50:17,594 INFO:     Found new best model at epoch 43
2023-01-05 15:50:17,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:17,595 INFO:     Epoch: 44
2023-01-05 15:50:19,734 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.35357585847377776, 'Total loss': 0.35357585847377776} | train loss {'Reaction outcome loss': 0.34851899070645065, 'Total loss': 0.34851899070645065}
2023-01-05 15:50:19,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:19,734 INFO:     Epoch: 45
2023-01-05 15:50:21,917 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3493870427211126, 'Total loss': 0.3493870427211126} | train loss {'Reaction outcome loss': 0.34347862073822144, 'Total loss': 0.34347862073822144}
2023-01-05 15:50:21,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:21,917 INFO:     Epoch: 46
2023-01-05 15:50:24,036 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.33170233766237894, 'Total loss': 0.33170233766237894} | train loss {'Reaction outcome loss': 0.3380550248447523, 'Total loss': 0.3380550248447523}
2023-01-05 15:50:24,037 INFO:     Found new best model at epoch 46
2023-01-05 15:50:24,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:24,038 INFO:     Epoch: 47
2023-01-05 15:50:26,226 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3511553183197975, 'Total loss': 0.3511553183197975} | train loss {'Reaction outcome loss': 0.3385876519370165, 'Total loss': 0.3385876519370165}
2023-01-05 15:50:26,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:26,227 INFO:     Epoch: 48
2023-01-05 15:50:28,475 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3359731237093608, 'Total loss': 0.3359731237093608} | train loss {'Reaction outcome loss': 0.3333497837132065, 'Total loss': 0.3333497837132065}
2023-01-05 15:50:28,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:28,475 INFO:     Epoch: 49
2023-01-05 15:50:30,621 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.333435183763504, 'Total loss': 0.333435183763504} | train loss {'Reaction outcome loss': 0.3329793798875077, 'Total loss': 0.3329793798875077}
2023-01-05 15:50:30,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:30,622 INFO:     Epoch: 50
2023-01-05 15:50:32,779 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3622308979431788, 'Total loss': 0.3622308979431788} | train loss {'Reaction outcome loss': 0.3296440609054983, 'Total loss': 0.3296440609054983}
2023-01-05 15:50:32,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:32,779 INFO:     Epoch: 51
2023-01-05 15:50:34,922 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.35547040502230326, 'Total loss': 0.35547040502230326} | train loss {'Reaction outcome loss': 0.32668389620709937, 'Total loss': 0.32668389620709937}
2023-01-05 15:50:34,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:34,922 INFO:     Epoch: 52
2023-01-05 15:50:37,070 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.34931890219449996, 'Total loss': 0.34931890219449996} | train loss {'Reaction outcome loss': 0.32212886071700053, 'Total loss': 0.32212886071700053}
2023-01-05 15:50:37,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:37,070 INFO:     Epoch: 53
2023-01-05 15:50:39,208 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.33650116523106893, 'Total loss': 0.33650116523106893} | train loss {'Reaction outcome loss': 0.3224698063860301, 'Total loss': 0.3224698063860301}
2023-01-05 15:50:39,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:39,208 INFO:     Epoch: 54
2023-01-05 15:50:41,381 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.35552108387152354, 'Total loss': 0.35552108387152354} | train loss {'Reaction outcome loss': 0.3168406205298883, 'Total loss': 0.3168406205298883}
2023-01-05 15:50:41,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:41,382 INFO:     Epoch: 55
2023-01-05 15:50:43,515 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3229392498731613, 'Total loss': 0.3229392498731613} | train loss {'Reaction outcome loss': 0.3113615012959668, 'Total loss': 0.3113615012959668}
2023-01-05 15:50:43,516 INFO:     Found new best model at epoch 55
2023-01-05 15:50:43,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:43,517 INFO:     Epoch: 56
2023-01-05 15:50:45,677 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3730605940024058, 'Total loss': 0.3730605940024058} | train loss {'Reaction outcome loss': 0.3130919187992058, 'Total loss': 0.3130919187992058}
2023-01-05 15:50:45,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:45,678 INFO:     Epoch: 57
2023-01-05 15:50:47,809 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3461599181095759, 'Total loss': 0.3461599181095759} | train loss {'Reaction outcome loss': 0.3116644308482051, 'Total loss': 0.3116644308482051}
2023-01-05 15:50:47,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:47,809 INFO:     Epoch: 58
2023-01-05 15:50:49,962 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3628897686799367, 'Total loss': 0.3628897686799367} | train loss {'Reaction outcome loss': 0.30856250078561936, 'Total loss': 0.30856250078561936}
2023-01-05 15:50:49,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:49,963 INFO:     Epoch: 59
2023-01-05 15:50:52,129 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3385370890299479, 'Total loss': 0.3385370890299479} | train loss {'Reaction outcome loss': 0.3063443587951712, 'Total loss': 0.3063443587951712}
2023-01-05 15:50:52,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:52,129 INFO:     Epoch: 60
2023-01-05 15:50:54,293 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3452349374691645, 'Total loss': 0.3452349374691645} | train loss {'Reaction outcome loss': 0.3036101047850688, 'Total loss': 0.3036101047850688}
2023-01-05 15:50:54,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:54,293 INFO:     Epoch: 61
2023-01-05 15:50:56,447 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.36501990457375844, 'Total loss': 0.36501990457375844} | train loss {'Reaction outcome loss': 0.2967511614253375, 'Total loss': 0.2967511614253375}
2023-01-05 15:50:56,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:56,447 INFO:     Epoch: 62
2023-01-05 15:50:58,592 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.33902022391557696, 'Total loss': 0.33902022391557696} | train loss {'Reaction outcome loss': 0.3001354502292101, 'Total loss': 0.3001354502292101}
2023-01-05 15:50:58,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:50:58,592 INFO:     Epoch: 63
2023-01-05 15:51:00,768 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36755539774894713, 'Total loss': 0.36755539774894713} | train loss {'Reaction outcome loss': 0.2942390942589686, 'Total loss': 0.2942390942589686}
2023-01-05 15:51:00,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:00,769 INFO:     Epoch: 64
2023-01-05 15:51:02,923 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.32413263246417046, 'Total loss': 0.32413263246417046} | train loss {'Reaction outcome loss': 0.2888772556430489, 'Total loss': 0.2888772556430489}
2023-01-05 15:51:02,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:02,924 INFO:     Epoch: 65
2023-01-05 15:51:05,081 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.35441618065039315, 'Total loss': 0.35441618065039315} | train loss {'Reaction outcome loss': 0.2940305650825965, 'Total loss': 0.2940305650825965}
2023-01-05 15:51:05,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:05,081 INFO:     Epoch: 66
2023-01-05 15:51:07,250 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.33895827730496725, 'Total loss': 0.33895827730496725} | train loss {'Reaction outcome loss': 0.2945452919801435, 'Total loss': 0.2945452919801435}
2023-01-05 15:51:07,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:07,251 INFO:     Epoch: 67
2023-01-05 15:51:09,391 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3554647147655487, 'Total loss': 0.3554647147655487} | train loss {'Reaction outcome loss': 0.28853421176814, 'Total loss': 0.28853421176814}
2023-01-05 15:51:09,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:09,391 INFO:     Epoch: 68
2023-01-05 15:51:11,547 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3442939867575963, 'Total loss': 0.3442939867575963} | train loss {'Reaction outcome loss': 0.2868545643299388, 'Total loss': 0.2868545643299388}
2023-01-05 15:51:11,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:11,547 INFO:     Epoch: 69
2023-01-05 15:51:13,728 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.35543241947889326, 'Total loss': 0.35543241947889326} | train loss {'Reaction outcome loss': 0.2928326045875757, 'Total loss': 0.2928326045875757}
2023-01-05 15:51:13,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:13,728 INFO:     Epoch: 70
2023-01-05 15:51:15,918 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3827176953355471, 'Total loss': 0.3827176953355471} | train loss {'Reaction outcome loss': 0.28691464589928894, 'Total loss': 0.28691464589928894}
2023-01-05 15:51:15,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:15,918 INFO:     Epoch: 71
2023-01-05 15:51:18,128 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3657247374455134, 'Total loss': 0.3657247374455134} | train loss {'Reaction outcome loss': 0.2828606005677355, 'Total loss': 0.2828606005677355}
2023-01-05 15:51:18,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:18,128 INFO:     Epoch: 72
2023-01-05 15:51:20,338 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3208502660195033, 'Total loss': 0.3208502660195033} | train loss {'Reaction outcome loss': 0.27663721056782814, 'Total loss': 0.27663721056782814}
2023-01-05 15:51:20,339 INFO:     Found new best model at epoch 72
2023-01-05 15:51:20,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:20,340 INFO:     Epoch: 73
2023-01-05 15:51:22,524 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.33056768476963044, 'Total loss': 0.33056768476963044} | train loss {'Reaction outcome loss': 0.2809023751409906, 'Total loss': 0.2809023751409906}
2023-01-05 15:51:22,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:22,524 INFO:     Epoch: 74
2023-01-05 15:51:24,748 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3504397178689639, 'Total loss': 0.3504397178689639} | train loss {'Reaction outcome loss': 0.28564711376379115, 'Total loss': 0.28564711376379115}
2023-01-05 15:51:24,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:24,748 INFO:     Epoch: 75
2023-01-05 15:51:26,852 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3283448467652003, 'Total loss': 0.3283448467652003} | train loss {'Reaction outcome loss': 0.2798099127809924, 'Total loss': 0.2798099127809924}
2023-01-05 15:51:26,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:26,852 INFO:     Epoch: 76
2023-01-05 15:51:29,023 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3572289856771628, 'Total loss': 0.3572289856771628} | train loss {'Reaction outcome loss': 0.2776016471571279, 'Total loss': 0.2776016471571279}
2023-01-05 15:51:29,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:29,023 INFO:     Epoch: 77
2023-01-05 15:51:31,232 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.32905529042085013, 'Total loss': 0.32905529042085013} | train loss {'Reaction outcome loss': 0.2692664487267229, 'Total loss': 0.2692664487267229}
2023-01-05 15:51:31,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:31,233 INFO:     Epoch: 78
2023-01-05 15:51:33,429 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.32413649062315625, 'Total loss': 0.32413649062315625} | train loss {'Reaction outcome loss': 0.2683471423785609, 'Total loss': 0.2683471423785609}
2023-01-05 15:51:33,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:33,429 INFO:     Epoch: 79
2023-01-05 15:51:35,628 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.34257063567638396, 'Total loss': 0.34257063567638396} | train loss {'Reaction outcome loss': 0.2679220633413172, 'Total loss': 0.2679220633413172}
2023-01-05 15:51:35,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:35,629 INFO:     Epoch: 80
2023-01-05 15:51:37,833 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3595885773499807, 'Total loss': 0.3595885773499807} | train loss {'Reaction outcome loss': 0.2719589185897624, 'Total loss': 0.2719589185897624}
2023-01-05 15:51:37,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:37,834 INFO:     Epoch: 81
2023-01-05 15:51:40,031 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.34671308199564616, 'Total loss': 0.34671308199564616} | train loss {'Reaction outcome loss': 0.26726171218316047, 'Total loss': 0.26726171218316047}
2023-01-05 15:51:40,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:40,031 INFO:     Epoch: 82
2023-01-05 15:51:42,199 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3653842975695928, 'Total loss': 0.3653842975695928} | train loss {'Reaction outcome loss': 0.27231158496348007, 'Total loss': 0.27231158496348007}
2023-01-05 15:51:42,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:42,199 INFO:     Epoch: 83
2023-01-05 15:51:44,357 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.33977928857008616, 'Total loss': 0.33977928857008616} | train loss {'Reaction outcome loss': 0.2722578178822241, 'Total loss': 0.2722578178822241}
2023-01-05 15:51:44,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:44,357 INFO:     Epoch: 84
2023-01-05 15:51:46,506 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37236504554748534, 'Total loss': 0.37236504554748534} | train loss {'Reaction outcome loss': 0.26300618158727346, 'Total loss': 0.26300618158727346}
2023-01-05 15:51:46,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:46,506 INFO:     Epoch: 85
2023-01-05 15:51:48,694 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3139900714159012, 'Total loss': 0.3139900714159012} | train loss {'Reaction outcome loss': 0.262543051184192, 'Total loss': 0.262543051184192}
2023-01-05 15:51:48,694 INFO:     Found new best model at epoch 85
2023-01-05 15:51:48,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:48,695 INFO:     Epoch: 86
2023-01-05 15:51:50,856 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3191654125849406, 'Total loss': 0.3191654125849406} | train loss {'Reaction outcome loss': 0.26264827839680527, 'Total loss': 0.26264827839680527}
2023-01-05 15:51:50,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:50,857 INFO:     Epoch: 87
2023-01-05 15:51:53,017 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3457700570424398, 'Total loss': 0.3457700570424398} | train loss {'Reaction outcome loss': 0.2607777271123892, 'Total loss': 0.2607777271123892}
2023-01-05 15:51:53,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:53,018 INFO:     Epoch: 88
2023-01-05 15:51:55,164 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.387584096690019, 'Total loss': 0.387584096690019} | train loss {'Reaction outcome loss': 0.25663684273562276, 'Total loss': 0.25663684273562276}
2023-01-05 15:51:55,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:55,165 INFO:     Epoch: 89
2023-01-05 15:51:57,329 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3566932275891304, 'Total loss': 0.3566932275891304} | train loss {'Reaction outcome loss': 0.2529195108945189, 'Total loss': 0.2529195108945189}
2023-01-05 15:51:57,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:57,329 INFO:     Epoch: 90
2023-01-05 15:51:59,499 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3512313157320023, 'Total loss': 0.3512313157320023} | train loss {'Reaction outcome loss': 0.25880099253372596, 'Total loss': 0.25880099253372596}
2023-01-05 15:51:59,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:51:59,499 INFO:     Epoch: 91
2023-01-05 15:52:01,669 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.34265001863241196, 'Total loss': 0.34265001863241196} | train loss {'Reaction outcome loss': 0.258153990018669, 'Total loss': 0.258153990018669}
2023-01-05 15:52:01,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:01,670 INFO:     Epoch: 92
2023-01-05 15:52:03,831 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.32754185994466145, 'Total loss': 0.32754185994466145} | train loss {'Reaction outcome loss': 0.26359787045403077, 'Total loss': 0.26359787045403077}
2023-01-05 15:52:03,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:03,831 INFO:     Epoch: 93
2023-01-05 15:52:05,990 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3392399917046229, 'Total loss': 0.3392399917046229} | train loss {'Reaction outcome loss': 0.26470264534227256, 'Total loss': 0.26470264534227256}
2023-01-05 15:52:05,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:05,991 INFO:     Epoch: 94
2023-01-05 15:52:08,145 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.34518794864416125, 'Total loss': 0.34518794864416125} | train loss {'Reaction outcome loss': 0.26047691296019493, 'Total loss': 0.26047691296019493}
2023-01-05 15:52:08,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:08,145 INFO:     Epoch: 95
2023-01-05 15:52:10,293 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35467433035373686, 'Total loss': 0.35467433035373686} | train loss {'Reaction outcome loss': 0.2488615116245695, 'Total loss': 0.2488615116245695}
2023-01-05 15:52:10,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:10,294 INFO:     Epoch: 96
2023-01-05 15:52:12,441 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3251194678246975, 'Total loss': 0.3251194678246975} | train loss {'Reaction outcome loss': 0.2538968839881007, 'Total loss': 0.2538968839881007}
2023-01-05 15:52:12,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:12,441 INFO:     Epoch: 97
2023-01-05 15:52:14,593 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.31964031706253687, 'Total loss': 0.31964031706253687} | train loss {'Reaction outcome loss': 0.25638079741425035, 'Total loss': 0.25638079741425035}
2023-01-05 15:52:14,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:14,593 INFO:     Epoch: 98
2023-01-05 15:52:16,754 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.36575272878011067, 'Total loss': 0.36575272878011067} | train loss {'Reaction outcome loss': 0.24798456087896756, 'Total loss': 0.24798456087896756}
2023-01-05 15:52:16,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:16,754 INFO:     Epoch: 99
2023-01-05 15:52:18,904 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.33087160289287565, 'Total loss': 0.33087160289287565} | train loss {'Reaction outcome loss': 0.2446912323605498, 'Total loss': 0.2446912323605498}
2023-01-05 15:52:18,904 INFO:     Best model found after epoch 86 of 100.
2023-01-05 15:52:18,905 INFO:   Done with stage: TRAINING
2023-01-05 15:52:18,905 INFO:   Starting stage: EVALUATION
2023-01-05 15:52:19,031 INFO:   Done with stage: EVALUATION
2023-01-05 15:52:19,031 INFO:   Leaving out SEQ value Fold_7
2023-01-05 15:52:19,044 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 15:52:19,044 INFO:   Starting stage: FEATURE SCALING
2023-01-05 15:52:19,686 INFO:   Done with stage: FEATURE SCALING
2023-01-05 15:52:19,686 INFO:   Starting stage: SCALING TARGETS
2023-01-05 15:52:19,755 INFO:   Done with stage: SCALING TARGETS
2023-01-05 15:52:19,755 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:52:19,755 INFO:     No hyperparam tuning for this model
2023-01-05 15:52:19,755 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:52:19,755 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 15:52:19,756 INFO:     None feature selector for col prot
2023-01-05 15:52:19,756 INFO:     None feature selector for col prot
2023-01-05 15:52:19,756 INFO:     None feature selector for col prot
2023-01-05 15:52:19,757 INFO:     None feature selector for col chem
2023-01-05 15:52:19,757 INFO:     None feature selector for col chem
2023-01-05 15:52:19,757 INFO:     None feature selector for col chem
2023-01-05 15:52:19,757 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 15:52:19,757 INFO:   Starting stage: BUILD MODEL
2023-01-05 15:52:19,758 INFO:     Number of params in model 72901
2023-01-05 15:52:19,761 INFO:   Done with stage: BUILD MODEL
2023-01-05 15:52:19,762 INFO:   Starting stage: TRAINING
2023-01-05 15:52:19,823 INFO:     Val loss before train {'Reaction outcome loss': 1.0525378266970316, 'Total loss': 1.0525378266970316}
2023-01-05 15:52:19,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:19,823 INFO:     Epoch: 0
2023-01-05 15:52:21,959 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.863107951482137, 'Total loss': 0.863107951482137} | train loss {'Reaction outcome loss': 0.9268495793377018, 'Total loss': 0.9268495793377018}
2023-01-05 15:52:21,960 INFO:     Found new best model at epoch 0
2023-01-05 15:52:21,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:21,961 INFO:     Epoch: 1
2023-01-05 15:52:24,123 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6582973182201386, 'Total loss': 0.6582973182201386} | train loss {'Reaction outcome loss': 0.7408340519516047, 'Total loss': 0.7408340519516047}
2023-01-05 15:52:24,123 INFO:     Found new best model at epoch 1
2023-01-05 15:52:24,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:24,125 INFO:     Epoch: 2
2023-01-05 15:52:26,282 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5727177103360493, 'Total loss': 0.5727177103360493} | train loss {'Reaction outcome loss': 0.5890231328858365, 'Total loss': 0.5890231328858365}
2023-01-05 15:52:26,283 INFO:     Found new best model at epoch 2
2023-01-05 15:52:26,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:26,284 INFO:     Epoch: 3
2023-01-05 15:52:28,445 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5533900856971741, 'Total loss': 0.5533900856971741} | train loss {'Reaction outcome loss': 0.5379512342842908, 'Total loss': 0.5379512342842908}
2023-01-05 15:52:28,445 INFO:     Found new best model at epoch 3
2023-01-05 15:52:28,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:28,446 INFO:     Epoch: 4
2023-01-05 15:52:30,593 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5160486112038295, 'Total loss': 0.5160486112038295} | train loss {'Reaction outcome loss': 0.5179922478777838, 'Total loss': 0.5179922478777838}
2023-01-05 15:52:30,593 INFO:     Found new best model at epoch 4
2023-01-05 15:52:30,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:30,595 INFO:     Epoch: 5
2023-01-05 15:52:32,718 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5241397500038147, 'Total loss': 0.5241397500038147} | train loss {'Reaction outcome loss': 0.5008086379254337, 'Total loss': 0.5008086379254337}
2023-01-05 15:52:32,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:32,720 INFO:     Epoch: 6
2023-01-05 15:52:34,863 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5047665158907573, 'Total loss': 0.5047665158907573} | train loss {'Reaction outcome loss': 0.4946210455915988, 'Total loss': 0.4946210455915988}
2023-01-05 15:52:34,863 INFO:     Found new best model at epoch 6
2023-01-05 15:52:34,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:34,864 INFO:     Epoch: 7
2023-01-05 15:52:37,039 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4889472166697184, 'Total loss': 0.4889472166697184} | train loss {'Reaction outcome loss': 0.4866251612505758, 'Total loss': 0.4866251612505758}
2023-01-05 15:52:37,039 INFO:     Found new best model at epoch 7
2023-01-05 15:52:37,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:37,041 INFO:     Epoch: 8
2023-01-05 15:52:39,203 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4828733911116918, 'Total loss': 0.4828733911116918} | train loss {'Reaction outcome loss': 0.47606412480023796, 'Total loss': 0.47606412480023796}
2023-01-05 15:52:39,204 INFO:     Found new best model at epoch 8
2023-01-05 15:52:39,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:39,205 INFO:     Epoch: 9
2023-01-05 15:52:41,365 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4825545395414034, 'Total loss': 0.4825545395414034} | train loss {'Reaction outcome loss': 0.47190451681183565, 'Total loss': 0.47190451681183565}
2023-01-05 15:52:41,365 INFO:     Found new best model at epoch 9
2023-01-05 15:52:41,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:41,367 INFO:     Epoch: 10
2023-01-05 15:52:43,490 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4786989688873291, 'Total loss': 0.4786989688873291} | train loss {'Reaction outcome loss': 0.46548854465519046, 'Total loss': 0.46548854465519046}
2023-01-05 15:52:43,490 INFO:     Found new best model at epoch 10
2023-01-05 15:52:43,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:43,491 INFO:     Epoch: 11
2023-01-05 15:52:45,632 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4770273496707281, 'Total loss': 0.4770273496707281} | train loss {'Reaction outcome loss': 0.4632254310409515, 'Total loss': 0.4632254310409515}
2023-01-05 15:52:45,632 INFO:     Found new best model at epoch 11
2023-01-05 15:52:45,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:45,634 INFO:     Epoch: 12
2023-01-05 15:52:47,772 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4906473159790039, 'Total loss': 0.4906473159790039} | train loss {'Reaction outcome loss': 0.45790874828930794, 'Total loss': 0.45790874828930794}
2023-01-05 15:52:47,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:47,773 INFO:     Epoch: 13
2023-01-05 15:52:49,923 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49003756841023766, 'Total loss': 0.49003756841023766} | train loss {'Reaction outcome loss': 0.4530010522218818, 'Total loss': 0.4530010522218818}
2023-01-05 15:52:49,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:49,923 INFO:     Epoch: 14
2023-01-05 15:52:52,075 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48640671372413635, 'Total loss': 0.48640671372413635} | train loss {'Reaction outcome loss': 0.44640301157205975, 'Total loss': 0.44640301157205975}
2023-01-05 15:52:52,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:52,076 INFO:     Epoch: 15
2023-01-05 15:52:54,223 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.469208358724912, 'Total loss': 0.469208358724912} | train loss {'Reaction outcome loss': 0.4455655913275502, 'Total loss': 0.4455655913275502}
2023-01-05 15:52:54,223 INFO:     Found new best model at epoch 15
2023-01-05 15:52:54,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:54,224 INFO:     Epoch: 16
2023-01-05 15:52:56,373 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46383376121520997, 'Total loss': 0.46383376121520997} | train loss {'Reaction outcome loss': 0.4468363485826912, 'Total loss': 0.4468363485826912}
2023-01-05 15:52:56,373 INFO:     Found new best model at epoch 16
2023-01-05 15:52:56,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:56,374 INFO:     Epoch: 17
2023-01-05 15:52:58,530 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45449373026688894, 'Total loss': 0.45449373026688894} | train loss {'Reaction outcome loss': 0.4342440573317049, 'Total loss': 0.4342440573317049}
2023-01-05 15:52:58,530 INFO:     Found new best model at epoch 17
2023-01-05 15:52:58,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:52:58,531 INFO:     Epoch: 18
2023-01-05 15:53:00,695 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4680028264721235, 'Total loss': 0.4680028264721235} | train loss {'Reaction outcome loss': 0.434100041589582, 'Total loss': 0.434100041589582}
2023-01-05 15:53:00,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:00,696 INFO:     Epoch: 19
2023-01-05 15:53:02,858 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4703213095664978, 'Total loss': 0.4703213095664978} | train loss {'Reaction outcome loss': 0.42687558178329293, 'Total loss': 0.42687558178329293}
2023-01-05 15:53:02,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:02,859 INFO:     Epoch: 20
2023-01-05 15:53:05,015 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4590439995129903, 'Total loss': 0.4590439995129903} | train loss {'Reaction outcome loss': 0.4236249549025233, 'Total loss': 0.4236249549025233}
2023-01-05 15:53:05,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:05,016 INFO:     Epoch: 21
2023-01-05 15:53:07,159 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46468146046002706, 'Total loss': 0.46468146046002706} | train loss {'Reaction outcome loss': 0.4176317794981416, 'Total loss': 0.4176317794981416}
2023-01-05 15:53:07,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:07,160 INFO:     Epoch: 22
2023-01-05 15:53:09,318 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4481150488058726, 'Total loss': 0.4481150488058726} | train loss {'Reaction outcome loss': 0.41959411223227366, 'Total loss': 0.41959411223227366}
2023-01-05 15:53:09,319 INFO:     Found new best model at epoch 22
2023-01-05 15:53:09,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:09,320 INFO:     Epoch: 23
2023-01-05 15:53:11,460 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46865938703219095, 'Total loss': 0.46865938703219095} | train loss {'Reaction outcome loss': 0.4087561316223351, 'Total loss': 0.4087561316223351}
2023-01-05 15:53:11,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:11,460 INFO:     Epoch: 24
2023-01-05 15:53:13,624 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4559942066669464, 'Total loss': 0.4559942066669464} | train loss {'Reaction outcome loss': 0.40343890175061964, 'Total loss': 0.40343890175061964}
2023-01-05 15:53:13,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:13,624 INFO:     Epoch: 25
2023-01-05 15:53:15,769 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.452156870563825, 'Total loss': 0.452156870563825} | train loss {'Reaction outcome loss': 0.4006066638640118, 'Total loss': 0.4006066638640118}
2023-01-05 15:53:15,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:15,769 INFO:     Epoch: 26
2023-01-05 15:53:17,911 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47761939068635306, 'Total loss': 0.47761939068635306} | train loss {'Reaction outcome loss': 0.40207807491079567, 'Total loss': 0.40207807491079567}
2023-01-05 15:53:17,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:17,911 INFO:     Epoch: 27
2023-01-05 15:53:20,036 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5135173896948496, 'Total loss': 0.5135173896948496} | train loss {'Reaction outcome loss': 0.3990200481206071, 'Total loss': 0.3990200481206071}
2023-01-05 15:53:20,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:20,036 INFO:     Epoch: 28
2023-01-05 15:53:22,203 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.463654754559199, 'Total loss': 0.463654754559199} | train loss {'Reaction outcome loss': 0.3979398495776559, 'Total loss': 0.3979398495776559}
2023-01-05 15:53:22,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:22,204 INFO:     Epoch: 29
2023-01-05 15:53:24,357 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44187075992425284, 'Total loss': 0.44187075992425284} | train loss {'Reaction outcome loss': 0.3922798558800659, 'Total loss': 0.3922798558800659}
2023-01-05 15:53:24,358 INFO:     Found new best model at epoch 29
2023-01-05 15:53:24,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:24,359 INFO:     Epoch: 30
2023-01-05 15:53:26,523 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41548087894916536, 'Total loss': 0.41548087894916536} | train loss {'Reaction outcome loss': 0.38631741939253755, 'Total loss': 0.38631741939253755}
2023-01-05 15:53:26,524 INFO:     Found new best model at epoch 30
2023-01-05 15:53:26,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:26,525 INFO:     Epoch: 31
2023-01-05 15:53:28,674 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44059866666793823, 'Total loss': 0.44059866666793823} | train loss {'Reaction outcome loss': 0.38438665718916093, 'Total loss': 0.38438665718916093}
2023-01-05 15:53:28,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:28,674 INFO:     Epoch: 32
2023-01-05 15:53:30,819 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4481247196594874, 'Total loss': 0.4481247196594874} | train loss {'Reaction outcome loss': 0.379846993847229, 'Total loss': 0.379846993847229}
2023-01-05 15:53:30,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:30,820 INFO:     Epoch: 33
2023-01-05 15:53:32,991 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.432555894056956, 'Total loss': 0.432555894056956} | train loss {'Reaction outcome loss': 0.37127694312738596, 'Total loss': 0.37127694312738596}
2023-01-05 15:53:32,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:32,991 INFO:     Epoch: 34
2023-01-05 15:53:35,184 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4797484676043193, 'Total loss': 0.4797484676043193} | train loss {'Reaction outcome loss': 0.3764942550110473, 'Total loss': 0.3764942550110473}
2023-01-05 15:53:35,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:35,184 INFO:     Epoch: 35
2023-01-05 15:53:37,375 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4570874492327372, 'Total loss': 0.4570874492327372} | train loss {'Reaction outcome loss': 0.3719510086122833, 'Total loss': 0.3719510086122833}
2023-01-05 15:53:37,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:37,375 INFO:     Epoch: 36
2023-01-05 15:53:39,529 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4261074701944987, 'Total loss': 0.4261074701944987} | train loss {'Reaction outcome loss': 0.37204647814646524, 'Total loss': 0.37204647814646524}
2023-01-05 15:53:39,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:39,530 INFO:     Epoch: 37
2023-01-05 15:53:41,754 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4365141252676646, 'Total loss': 0.4365141252676646} | train loss {'Reaction outcome loss': 0.3684897755511401, 'Total loss': 0.3684897755511401}
2023-01-05 15:53:41,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:41,755 INFO:     Epoch: 38
2023-01-05 15:53:43,895 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4421497325102488, 'Total loss': 0.4421497325102488} | train loss {'Reaction outcome loss': 0.3582978394111141, 'Total loss': 0.3582978394111141}
2023-01-05 15:53:43,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:43,895 INFO:     Epoch: 39
2023-01-05 15:53:46,060 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4279144088427226, 'Total loss': 0.4279144088427226} | train loss {'Reaction outcome loss': 0.36256164906795274, 'Total loss': 0.36256164906795274}
2023-01-05 15:53:46,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:46,061 INFO:     Epoch: 40
2023-01-05 15:53:48,219 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46596917311350505, 'Total loss': 0.46596917311350505} | train loss {'Reaction outcome loss': 0.35453888986407633, 'Total loss': 0.35453888986407633}
2023-01-05 15:53:48,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:48,219 INFO:     Epoch: 41
2023-01-05 15:53:50,356 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.455371884504954, 'Total loss': 0.455371884504954} | train loss {'Reaction outcome loss': 0.35183105929771485, 'Total loss': 0.35183105929771485}
2023-01-05 15:53:50,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:50,356 INFO:     Epoch: 42
2023-01-05 15:53:52,502 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4193253974119822, 'Total loss': 0.4193253974119822} | train loss {'Reaction outcome loss': 0.34709841836015237, 'Total loss': 0.34709841836015237}
2023-01-05 15:53:52,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:52,502 INFO:     Epoch: 43
2023-01-05 15:53:54,654 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43261055449644725, 'Total loss': 0.43261055449644725} | train loss {'Reaction outcome loss': 0.34692585823337957, 'Total loss': 0.34692585823337957}
2023-01-05 15:53:54,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:54,654 INFO:     Epoch: 44
2023-01-05 15:53:56,823 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4365139752626419, 'Total loss': 0.4365139752626419} | train loss {'Reaction outcome loss': 0.3407959547230053, 'Total loss': 0.3407959547230053}
2023-01-05 15:53:56,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:56,823 INFO:     Epoch: 45
2023-01-05 15:53:59,007 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41379600365956626, 'Total loss': 0.41379600365956626} | train loss {'Reaction outcome loss': 0.3409615180821625, 'Total loss': 0.3409615180821625}
2023-01-05 15:53:59,008 INFO:     Found new best model at epoch 45
2023-01-05 15:53:59,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:53:59,009 INFO:     Epoch: 46
2023-01-05 15:54:01,162 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45219963093598686, 'Total loss': 0.45219963093598686} | train loss {'Reaction outcome loss': 0.34303418178420636, 'Total loss': 0.34303418178420636}
2023-01-05 15:54:01,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:01,162 INFO:     Epoch: 47
2023-01-05 15:54:03,333 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4434390554825465, 'Total loss': 0.4434390554825465} | train loss {'Reaction outcome loss': 0.3348029578635839, 'Total loss': 0.3348029578635839}
2023-01-05 15:54:03,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:03,334 INFO:     Epoch: 48
2023-01-05 15:54:05,511 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4293646772702535, 'Total loss': 0.4293646772702535} | train loss {'Reaction outcome loss': 0.32844354272803244, 'Total loss': 0.32844354272803244}
2023-01-05 15:54:05,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:05,512 INFO:     Epoch: 49
2023-01-05 15:54:07,341 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46306952436765036, 'Total loss': 0.46306952436765036} | train loss {'Reaction outcome loss': 0.3331684583952711, 'Total loss': 0.3331684583952711}
2023-01-05 15:54:07,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:07,342 INFO:     Epoch: 50
2023-01-05 15:54:09,140 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43295985559622446, 'Total loss': 0.43295985559622446} | train loss {'Reaction outcome loss': 0.3305262685333133, 'Total loss': 0.3305262685333133}
2023-01-05 15:54:09,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:09,141 INFO:     Epoch: 51
2023-01-05 15:54:11,153 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.437778373559316, 'Total loss': 0.437778373559316} | train loss {'Reaction outcome loss': 0.3289860861396101, 'Total loss': 0.3289860861396101}
2023-01-05 15:54:11,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:11,154 INFO:     Epoch: 52
2023-01-05 15:54:13,294 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45029499332110084, 'Total loss': 0.45029499332110084} | train loss {'Reaction outcome loss': 0.31809316143823874, 'Total loss': 0.31809316143823874}
2023-01-05 15:54:13,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:13,295 INFO:     Epoch: 53
2023-01-05 15:54:15,455 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4594418744246165, 'Total loss': 0.4594418744246165} | train loss {'Reaction outcome loss': 0.32335567458226794, 'Total loss': 0.32335567458226794}
2023-01-05 15:54:15,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:15,456 INFO:     Epoch: 54
2023-01-05 15:54:17,585 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43744142949581144, 'Total loss': 0.43744142949581144} | train loss {'Reaction outcome loss': 0.31618447851941045, 'Total loss': 0.31618447851941045}
2023-01-05 15:54:17,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:17,585 INFO:     Epoch: 55
2023-01-05 15:54:19,727 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46582337419191994, 'Total loss': 0.46582337419191994} | train loss {'Reaction outcome loss': 0.31980521721422456, 'Total loss': 0.31980521721422456}
2023-01-05 15:54:19,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:19,727 INFO:     Epoch: 56
2023-01-05 15:54:21,874 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4223720719416936, 'Total loss': 0.4223720719416936} | train loss {'Reaction outcome loss': 0.31469743580150583, 'Total loss': 0.31469743580150583}
2023-01-05 15:54:21,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:21,874 INFO:     Epoch: 57
2023-01-05 15:54:24,016 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46228466033935545, 'Total loss': 0.46228466033935545} | train loss {'Reaction outcome loss': 0.3093342441487183, 'Total loss': 0.3093342441487183}
2023-01-05 15:54:24,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:24,016 INFO:     Epoch: 58
2023-01-05 15:54:26,190 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43854394753774006, 'Total loss': 0.43854394753774006} | train loss {'Reaction outcome loss': 0.3036901636405542, 'Total loss': 0.3036901636405542}
2023-01-05 15:54:26,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:26,190 INFO:     Epoch: 59
2023-01-05 15:54:28,333 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4125959893067678, 'Total loss': 0.4125959893067678} | train loss {'Reaction outcome loss': 0.3082631419846512, 'Total loss': 0.3082631419846512}
2023-01-05 15:54:28,334 INFO:     Found new best model at epoch 59
2023-01-05 15:54:28,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:28,335 INFO:     Epoch: 60
2023-01-05 15:54:30,487 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4435676530003548, 'Total loss': 0.4435676530003548} | train loss {'Reaction outcome loss': 0.30034615126327485, 'Total loss': 0.30034615126327485}
2023-01-05 15:54:30,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:30,487 INFO:     Epoch: 61
2023-01-05 15:54:32,641 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4303601185480754, 'Total loss': 0.4303601185480754} | train loss {'Reaction outcome loss': 0.3084732194562251, 'Total loss': 0.3084732194562251}
2023-01-05 15:54:32,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:32,641 INFO:     Epoch: 62
2023-01-05 15:54:34,800 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4463709314664205, 'Total loss': 0.4463709314664205} | train loss {'Reaction outcome loss': 0.3008522421040905, 'Total loss': 0.3008522421040905}
2023-01-05 15:54:34,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:34,801 INFO:     Epoch: 63
2023-01-05 15:54:36,943 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4471752564112345, 'Total loss': 0.4471752564112345} | train loss {'Reaction outcome loss': 0.2986307887004063, 'Total loss': 0.2986307887004063}
2023-01-05 15:54:36,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:36,944 INFO:     Epoch: 64
2023-01-05 15:54:39,098 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42691808144251503, 'Total loss': 0.42691808144251503} | train loss {'Reaction outcome loss': 0.29737845966289833, 'Total loss': 0.29737845966289833}
2023-01-05 15:54:39,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:39,099 INFO:     Epoch: 65
2023-01-05 15:54:41,224 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4749228894710541, 'Total loss': 0.4749228894710541} | train loss {'Reaction outcome loss': 0.29703813795309636, 'Total loss': 0.29703813795309636}
2023-01-05 15:54:41,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:41,224 INFO:     Epoch: 66
2023-01-05 15:54:43,372 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45781788527965545, 'Total loss': 0.45781788527965545} | train loss {'Reaction outcome loss': 0.2941367603192906, 'Total loss': 0.2941367603192906}
2023-01-05 15:54:43,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:43,373 INFO:     Epoch: 67
2023-01-05 15:54:45,522 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44640915592511493, 'Total loss': 0.44640915592511493} | train loss {'Reaction outcome loss': 0.2932141448307231, 'Total loss': 0.2932141448307231}
2023-01-05 15:54:45,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:45,522 INFO:     Epoch: 68
2023-01-05 15:54:47,658 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47142740289370216, 'Total loss': 0.47142740289370216} | train loss {'Reaction outcome loss': 0.2917421595109391, 'Total loss': 0.2917421595109391}
2023-01-05 15:54:47,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:47,658 INFO:     Epoch: 69
2023-01-05 15:54:49,780 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4131594489018122, 'Total loss': 0.4131594489018122} | train loss {'Reaction outcome loss': 0.2937315943708058, 'Total loss': 0.2937315943708058}
2023-01-05 15:54:49,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:49,780 INFO:     Epoch: 70
2023-01-05 15:54:51,942 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44312940537929535, 'Total loss': 0.44312940537929535} | train loss {'Reaction outcome loss': 0.28249914157422873, 'Total loss': 0.28249914157422873}
2023-01-05 15:54:51,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:51,942 INFO:     Epoch: 71
2023-01-05 15:54:54,086 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4680896987517675, 'Total loss': 0.4680896987517675} | train loss {'Reaction outcome loss': 0.2858172882792106, 'Total loss': 0.2858172882792106}
2023-01-05 15:54:54,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:54,086 INFO:     Epoch: 72
2023-01-05 15:54:56,237 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4746659964323044, 'Total loss': 0.4746659964323044} | train loss {'Reaction outcome loss': 0.28522142110264687, 'Total loss': 0.28522142110264687}
2023-01-05 15:54:56,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:56,237 INFO:     Epoch: 73
2023-01-05 15:54:58,345 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4629148870706558, 'Total loss': 0.4629148870706558} | train loss {'Reaction outcome loss': 0.2810088578302292, 'Total loss': 0.2810088578302292}
2023-01-05 15:54:58,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:54:58,346 INFO:     Epoch: 74
2023-01-05 15:55:00,479 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43339146474997203, 'Total loss': 0.43339146474997203} | train loss {'Reaction outcome loss': 0.27731008962173326, 'Total loss': 0.27731008962173326}
2023-01-05 15:55:00,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:00,479 INFO:     Epoch: 75
2023-01-05 15:55:02,623 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4603672087192535, 'Total loss': 0.4603672087192535} | train loss {'Reaction outcome loss': 0.2815873933693777, 'Total loss': 0.2815873933693777}
2023-01-05 15:55:02,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:02,624 INFO:     Epoch: 76
2023-01-05 15:55:04,764 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4391748984654745, 'Total loss': 0.4391748984654745} | train loss {'Reaction outcome loss': 0.28113285149531675, 'Total loss': 0.28113285149531675}
2023-01-05 15:55:04,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:04,764 INFO:     Epoch: 77
2023-01-05 15:55:06,915 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4469434966643651, 'Total loss': 0.4469434966643651} | train loss {'Reaction outcome loss': 0.27822532285583146, 'Total loss': 0.27822532285583146}
2023-01-05 15:55:06,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:06,915 INFO:     Epoch: 78
2023-01-05 15:55:09,067 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5131409009297688, 'Total loss': 0.5131409009297688} | train loss {'Reaction outcome loss': 0.27610158654003797, 'Total loss': 0.27610158654003797}
2023-01-05 15:55:09,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:09,067 INFO:     Epoch: 79
2023-01-05 15:55:11,205 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4629735549290975, 'Total loss': 0.4629735549290975} | train loss {'Reaction outcome loss': 0.2721183744497893, 'Total loss': 0.2721183744497893}
2023-01-05 15:55:11,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:11,206 INFO:     Epoch: 80
2023-01-05 15:55:13,357 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4719912896553675, 'Total loss': 0.4719912896553675} | train loss {'Reaction outcome loss': 0.2719160682699956, 'Total loss': 0.2719160682699956}
2023-01-05 15:55:13,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:13,357 INFO:     Epoch: 81
2023-01-05 15:55:15,498 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4696376870075862, 'Total loss': 0.4696376870075862} | train loss {'Reaction outcome loss': 0.27276664201694706, 'Total loss': 0.27276664201694706}
2023-01-05 15:55:15,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:15,499 INFO:     Epoch: 82
2023-01-05 15:55:17,650 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44418259064356486, 'Total loss': 0.44418259064356486} | train loss {'Reaction outcome loss': 0.2771943650924557, 'Total loss': 0.2771943650924557}
2023-01-05 15:55:17,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:17,651 INFO:     Epoch: 83
2023-01-05 15:55:19,787 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47271768450737, 'Total loss': 0.47271768450737} | train loss {'Reaction outcome loss': 0.2711248991721804, 'Total loss': 0.2711248991721804}
2023-01-05 15:55:19,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:19,787 INFO:     Epoch: 84
2023-01-05 15:55:21,918 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46359468897183737, 'Total loss': 0.46359468897183737} | train loss {'Reaction outcome loss': 0.27294119561783675, 'Total loss': 0.27294119561783675}
2023-01-05 15:55:21,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:21,919 INFO:     Epoch: 85
2023-01-05 15:55:24,081 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44804489413897197, 'Total loss': 0.44804489413897197} | train loss {'Reaction outcome loss': 0.2687291646315733, 'Total loss': 0.2687291646315733}
2023-01-05 15:55:24,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:24,082 INFO:     Epoch: 86
2023-01-05 15:55:26,247 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44123100241025287, 'Total loss': 0.44123100241025287} | train loss {'Reaction outcome loss': 0.2642736758982985, 'Total loss': 0.2642736758982985}
2023-01-05 15:55:26,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:26,247 INFO:     Epoch: 87
2023-01-05 15:55:28,417 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4861861288547516, 'Total loss': 0.4861861288547516} | train loss {'Reaction outcome loss': 0.26527740969070457, 'Total loss': 0.26527740969070457}
2023-01-05 15:55:28,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:28,418 INFO:     Epoch: 88
2023-01-05 15:55:30,385 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4630342441300551, 'Total loss': 0.4630342441300551} | train loss {'Reaction outcome loss': 0.2619802719822644, 'Total loss': 0.2619802719822644}
2023-01-05 15:55:30,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:30,385 INFO:     Epoch: 89
2023-01-05 15:55:32,541 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49023722211519877, 'Total loss': 0.49023722211519877} | train loss {'Reaction outcome loss': 0.25961082958572607, 'Total loss': 0.25961082958572607}
2023-01-05 15:55:32,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:32,542 INFO:     Epoch: 90
2023-01-05 15:55:34,707 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.503908467789491, 'Total loss': 0.503908467789491} | train loss {'Reaction outcome loss': 0.26284165832378803, 'Total loss': 0.26284165832378803}
2023-01-05 15:55:34,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:34,708 INFO:     Epoch: 91
2023-01-05 15:55:36,872 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4628898491462072, 'Total loss': 0.4628898491462072} | train loss {'Reaction outcome loss': 0.26177309741289606, 'Total loss': 0.26177309741289606}
2023-01-05 15:55:36,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:36,872 INFO:     Epoch: 92
2023-01-05 15:55:39,007 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4554935485124588, 'Total loss': 0.4554935485124588} | train loss {'Reaction outcome loss': 0.25434368807109686, 'Total loss': 0.25434368807109686}
2023-01-05 15:55:39,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:39,007 INFO:     Epoch: 93
2023-01-05 15:55:41,153 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44981918931007386, 'Total loss': 0.44981918931007386} | train loss {'Reaction outcome loss': 0.2555280230966286, 'Total loss': 0.2555280230966286}
2023-01-05 15:55:41,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:41,153 INFO:     Epoch: 94
2023-01-05 15:55:43,305 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4212232768535614, 'Total loss': 0.4212232768535614} | train loss {'Reaction outcome loss': 0.2602337098038261, 'Total loss': 0.2602337098038261}
2023-01-05 15:55:43,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:43,306 INFO:     Epoch: 95
2023-01-05 15:55:45,429 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44135009696086247, 'Total loss': 0.44135009696086247} | train loss {'Reaction outcome loss': 0.26147394904375937, 'Total loss': 0.26147394904375937}
2023-01-05 15:55:45,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:45,429 INFO:     Epoch: 96
2023-01-05 15:55:47,578 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4891133576631546, 'Total loss': 0.4891133576631546} | train loss {'Reaction outcome loss': 0.2549432117209538, 'Total loss': 0.2549432117209538}
2023-01-05 15:55:47,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:47,578 INFO:     Epoch: 97
2023-01-05 15:55:49,686 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.430953515569369, 'Total loss': 0.430953515569369} | train loss {'Reaction outcome loss': 0.26019466151264814, 'Total loss': 0.26019466151264814}
2023-01-05 15:55:49,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:49,687 INFO:     Epoch: 98
2023-01-05 15:55:51,813 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4413305381933848, 'Total loss': 0.4413305381933848} | train loss {'Reaction outcome loss': 0.2535740260626542, 'Total loss': 0.2535740260626542}
2023-01-05 15:55:51,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:51,814 INFO:     Epoch: 99
2023-01-05 15:55:53,952 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4582895119984945, 'Total loss': 0.4582895119984945} | train loss {'Reaction outcome loss': 0.24873100904687326, 'Total loss': 0.24873100904687326}
2023-01-05 15:55:53,953 INFO:     Best model found after epoch 60 of 100.
2023-01-05 15:55:53,953 INFO:   Done with stage: TRAINING
2023-01-05 15:55:53,953 INFO:   Starting stage: EVALUATION
2023-01-05 15:55:54,079 INFO:   Done with stage: EVALUATION
2023-01-05 15:55:54,079 INFO:   Leaving out SEQ value Fold_8
2023-01-05 15:55:54,091 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 15:55:54,091 INFO:   Starting stage: FEATURE SCALING
2023-01-05 15:55:54,726 INFO:   Done with stage: FEATURE SCALING
2023-01-05 15:55:54,726 INFO:   Starting stage: SCALING TARGETS
2023-01-05 15:55:54,793 INFO:   Done with stage: SCALING TARGETS
2023-01-05 15:55:54,793 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:55:54,793 INFO:     No hyperparam tuning for this model
2023-01-05 15:55:54,793 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:55:54,793 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 15:55:54,794 INFO:     None feature selector for col prot
2023-01-05 15:55:54,794 INFO:     None feature selector for col prot
2023-01-05 15:55:54,794 INFO:     None feature selector for col prot
2023-01-05 15:55:54,794 INFO:     None feature selector for col chem
2023-01-05 15:55:54,794 INFO:     None feature selector for col chem
2023-01-05 15:55:54,794 INFO:     None feature selector for col chem
2023-01-05 15:55:54,795 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 15:55:54,795 INFO:   Starting stage: BUILD MODEL
2023-01-05 15:55:54,797 INFO:     Number of params in model 72901
2023-01-05 15:55:54,800 INFO:   Done with stage: BUILD MODEL
2023-01-05 15:55:54,800 INFO:   Starting stage: TRAINING
2023-01-05 15:55:54,857 INFO:     Val loss before train {'Reaction outcome loss': 0.9417384346326192, 'Total loss': 0.9417384346326192}
2023-01-05 15:55:54,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:54,857 INFO:     Epoch: 0
2023-01-05 15:55:56,974 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7731679439544678, 'Total loss': 0.7731679439544678} | train loss {'Reaction outcome loss': 0.9280395359888564, 'Total loss': 0.9280395359888564}
2023-01-05 15:55:56,974 INFO:     Found new best model at epoch 0
2023-01-05 15:55:56,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:56,975 INFO:     Epoch: 1
2023-01-05 15:55:59,075 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5803598622481029, 'Total loss': 0.5803598622481029} | train loss {'Reaction outcome loss': 0.7326450740551427, 'Total loss': 0.7326450740551427}
2023-01-05 15:55:59,076 INFO:     Found new best model at epoch 1
2023-01-05 15:55:59,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:55:59,077 INFO:     Epoch: 2
2023-01-05 15:56:01,191 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5092536568641662, 'Total loss': 0.5092536568641662} | train loss {'Reaction outcome loss': 0.5841711258148625, 'Total loss': 0.5841711258148625}
2023-01-05 15:56:01,191 INFO:     Found new best model at epoch 2
2023-01-05 15:56:01,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:01,192 INFO:     Epoch: 3
2023-01-05 15:56:03,281 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46479374170303345, 'Total loss': 0.46479374170303345} | train loss {'Reaction outcome loss': 0.5275217903247715, 'Total loss': 0.5275217903247715}
2023-01-05 15:56:03,281 INFO:     Found new best model at epoch 3
2023-01-05 15:56:03,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:03,282 INFO:     Epoch: 4
2023-01-05 15:56:05,402 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44678952594598137, 'Total loss': 0.44678952594598137} | train loss {'Reaction outcome loss': 0.5049687130444677, 'Total loss': 0.5049687130444677}
2023-01-05 15:56:05,402 INFO:     Found new best model at epoch 4
2023-01-05 15:56:05,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:05,403 INFO:     Epoch: 5
2023-01-05 15:56:07,507 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4637984335422516, 'Total loss': 0.4637984335422516} | train loss {'Reaction outcome loss': 0.48385491010046355, 'Total loss': 0.48385491010046355}
2023-01-05 15:56:07,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:07,507 INFO:     Epoch: 6
2023-01-05 15:56:09,608 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4518207242091497, 'Total loss': 0.4518207242091497} | train loss {'Reaction outcome loss': 0.48077486303165884, 'Total loss': 0.48077486303165884}
2023-01-05 15:56:09,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:09,608 INFO:     Epoch: 7
2023-01-05 15:56:11,720 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4791350901126862, 'Total loss': 0.4791350901126862} | train loss {'Reaction outcome loss': 0.4691287963549151, 'Total loss': 0.4691287963549151}
2023-01-05 15:56:11,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:11,721 INFO:     Epoch: 8
2023-01-05 15:56:13,843 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46957849760850273, 'Total loss': 0.46957849760850273} | train loss {'Reaction outcome loss': 0.46448948446416505, 'Total loss': 0.46448948446416505}
2023-01-05 15:56:13,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:13,843 INFO:     Epoch: 9
2023-01-05 15:56:15,964 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44027144511540733, 'Total loss': 0.44027144511540733} | train loss {'Reaction outcome loss': 0.46082406670507725, 'Total loss': 0.46082406670507725}
2023-01-05 15:56:15,965 INFO:     Found new best model at epoch 9
2023-01-05 15:56:15,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:15,966 INFO:     Epoch: 10
2023-01-05 15:56:18,085 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4407656967639923, 'Total loss': 0.4407656967639923} | train loss {'Reaction outcome loss': 0.4577057818970541, 'Total loss': 0.4577057818970541}
2023-01-05 15:56:18,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:18,085 INFO:     Epoch: 11
2023-01-05 15:56:20,188 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48398066163063047, 'Total loss': 0.48398066163063047} | train loss {'Reaction outcome loss': 0.4439653826564768, 'Total loss': 0.4439653826564768}
2023-01-05 15:56:20,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:20,188 INFO:     Epoch: 12
2023-01-05 15:56:22,308 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42773793240388236, 'Total loss': 0.42773793240388236} | train loss {'Reaction outcome loss': 0.4422212316498269, 'Total loss': 0.4422212316498269}
2023-01-05 15:56:22,308 INFO:     Found new best model at epoch 12
2023-01-05 15:56:22,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:22,309 INFO:     Epoch: 13
2023-01-05 15:56:24,435 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43022873997688293, 'Total loss': 0.43022873997688293} | train loss {'Reaction outcome loss': 0.436721313309713, 'Total loss': 0.436721313309713}
2023-01-05 15:56:24,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:24,435 INFO:     Epoch: 14
2023-01-05 15:56:26,588 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42892871499061586, 'Total loss': 0.42892871499061586} | train loss {'Reaction outcome loss': 0.42716474591815556, 'Total loss': 0.42716474591815556}
2023-01-05 15:56:26,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:26,589 INFO:     Epoch: 15
2023-01-05 15:56:28,700 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46020929018656415, 'Total loss': 0.46020929018656415} | train loss {'Reaction outcome loss': 0.42887356771278556, 'Total loss': 0.42887356771278556}
2023-01-05 15:56:28,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:28,700 INFO:     Epoch: 16
2023-01-05 15:56:30,809 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4341875751813253, 'Total loss': 0.4341875751813253} | train loss {'Reaction outcome loss': 0.4253084675891556, 'Total loss': 0.4253084675891556}
2023-01-05 15:56:30,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:30,809 INFO:     Epoch: 17
2023-01-05 15:56:32,910 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40654154618581134, 'Total loss': 0.40654154618581134} | train loss {'Reaction outcome loss': 0.4257967070180134, 'Total loss': 0.4257967070180134}
2023-01-05 15:56:32,911 INFO:     Found new best model at epoch 17
2023-01-05 15:56:32,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:32,912 INFO:     Epoch: 18
2023-01-05 15:56:35,017 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4125840703646342, 'Total loss': 0.4125840703646342} | train loss {'Reaction outcome loss': 0.41453193772557007, 'Total loss': 0.41453193772557007}
2023-01-05 15:56:35,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:35,018 INFO:     Epoch: 19
2023-01-05 15:56:37,135 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4518322984377543, 'Total loss': 0.4518322984377543} | train loss {'Reaction outcome loss': 0.4066986213472203, 'Total loss': 0.4066986213472203}
2023-01-05 15:56:37,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:37,136 INFO:     Epoch: 20
2023-01-05 15:56:39,245 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44288843870162964, 'Total loss': 0.44288843870162964} | train loss {'Reaction outcome loss': 0.40725068946498155, 'Total loss': 0.40725068946498155}
2023-01-05 15:56:39,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:39,245 INFO:     Epoch: 21
2023-01-05 15:56:41,383 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4126942873001099, 'Total loss': 0.4126942873001099} | train loss {'Reaction outcome loss': 0.4012649463911126, 'Total loss': 0.4012649463911126}
2023-01-05 15:56:41,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:41,383 INFO:     Epoch: 22
2023-01-05 15:56:43,510 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4131684919198354, 'Total loss': 0.4131684919198354} | train loss {'Reaction outcome loss': 0.3981071744848342, 'Total loss': 0.3981071744848342}
2023-01-05 15:56:43,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:43,510 INFO:     Epoch: 23
2023-01-05 15:56:45,647 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4103012889623642, 'Total loss': 0.4103012889623642} | train loss {'Reaction outcome loss': 0.39278875076531494, 'Total loss': 0.39278875076531494}
2023-01-05 15:56:45,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:45,648 INFO:     Epoch: 24
2023-01-05 15:56:47,769 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43084384202957154, 'Total loss': 0.43084384202957154} | train loss {'Reaction outcome loss': 0.3926569187510623, 'Total loss': 0.3926569187510623}
2023-01-05 15:56:47,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:47,769 INFO:     Epoch: 25
2023-01-05 15:56:49,883 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4157752106587092, 'Total loss': 0.4157752106587092} | train loss {'Reaction outcome loss': 0.38892468195544544, 'Total loss': 0.38892468195544544}
2023-01-05 15:56:49,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:49,884 INFO:     Epoch: 26
2023-01-05 15:56:52,021 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40858649611473086, 'Total loss': 0.40858649611473086} | train loss {'Reaction outcome loss': 0.3841032045927361, 'Total loss': 0.3841032045927361}
2023-01-05 15:56:52,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:52,021 INFO:     Epoch: 27
2023-01-05 15:56:54,132 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40311776076753936, 'Total loss': 0.40311776076753936} | train loss {'Reaction outcome loss': 0.37786636705489923, 'Total loss': 0.37786636705489923}
2023-01-05 15:56:54,132 INFO:     Found new best model at epoch 27
2023-01-05 15:56:54,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:54,133 INFO:     Epoch: 28
2023-01-05 15:56:56,252 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4123606344064077, 'Total loss': 0.4123606344064077} | train loss {'Reaction outcome loss': 0.37948640210241297, 'Total loss': 0.37948640210241297}
2023-01-05 15:56:56,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:56,252 INFO:     Epoch: 29
2023-01-05 15:56:58,388 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42186734278996785, 'Total loss': 0.42186734278996785} | train loss {'Reaction outcome loss': 0.3799975433651983, 'Total loss': 0.3799975433651983}
2023-01-05 15:56:58,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:56:58,389 INFO:     Epoch: 30
2023-01-05 15:57:00,512 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42005063345034915, 'Total loss': 0.42005063345034915} | train loss {'Reaction outcome loss': 0.36875049865050036, 'Total loss': 0.36875049865050036}
2023-01-05 15:57:00,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:00,512 INFO:     Epoch: 31
2023-01-05 15:57:02,646 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3907216856877009, 'Total loss': 0.3907216856877009} | train loss {'Reaction outcome loss': 0.3704141202199198, 'Total loss': 0.3704141202199198}
2023-01-05 15:57:02,648 INFO:     Found new best model at epoch 31
2023-01-05 15:57:02,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:02,649 INFO:     Epoch: 32
2023-01-05 15:57:04,778 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4502413441737493, 'Total loss': 0.4502413441737493} | train loss {'Reaction outcome loss': 0.36269062975027266, 'Total loss': 0.36269062975027266}
2023-01-05 15:57:04,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:04,778 INFO:     Epoch: 33
2023-01-05 15:57:06,861 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3906030535697937, 'Total loss': 0.3906030535697937} | train loss {'Reaction outcome loss': 0.3665802040184936, 'Total loss': 0.3665802040184936}
2023-01-05 15:57:06,861 INFO:     Found new best model at epoch 33
2023-01-05 15:57:06,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:06,862 INFO:     Epoch: 34
2023-01-05 15:57:08,966 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43107320268948873, 'Total loss': 0.43107320268948873} | train loss {'Reaction outcome loss': 0.3582337967725131, 'Total loss': 0.3582337967725131}
2023-01-05 15:57:08,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:08,967 INFO:     Epoch: 35
2023-01-05 15:57:11,091 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4038544833660126, 'Total loss': 0.4038544833660126} | train loss {'Reaction outcome loss': 0.3513766323644532, 'Total loss': 0.3513766323644532}
2023-01-05 15:57:11,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:11,091 INFO:     Epoch: 36
2023-01-05 15:57:13,240 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37223351498444873, 'Total loss': 0.37223351498444873} | train loss {'Reaction outcome loss': 0.3487398707899299, 'Total loss': 0.3487398707899299}
2023-01-05 15:57:13,240 INFO:     Found new best model at epoch 36
2023-01-05 15:57:13,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:13,241 INFO:     Epoch: 37
2023-01-05 15:57:15,418 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4326290667057037, 'Total loss': 0.4326290667057037} | train loss {'Reaction outcome loss': 0.34671289268473204, 'Total loss': 0.34671289268473204}
2023-01-05 15:57:15,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:15,418 INFO:     Epoch: 38
2023-01-05 15:57:17,537 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4063493182261785, 'Total loss': 0.4063493182261785} | train loss {'Reaction outcome loss': 0.34182588573898715, 'Total loss': 0.34182588573898715}
2023-01-05 15:57:17,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:17,538 INFO:     Epoch: 39
2023-01-05 15:57:19,662 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38735430836677553, 'Total loss': 0.38735430836677553} | train loss {'Reaction outcome loss': 0.33985498789561924, 'Total loss': 0.33985498789561924}
2023-01-05 15:57:19,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:19,662 INFO:     Epoch: 40
2023-01-05 15:57:21,798 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41104543109734853, 'Total loss': 0.41104543109734853} | train loss {'Reaction outcome loss': 0.33951199544172217, 'Total loss': 0.33951199544172217}
2023-01-05 15:57:21,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:21,799 INFO:     Epoch: 41
2023-01-05 15:57:23,924 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39214331010977427, 'Total loss': 0.39214331010977427} | train loss {'Reaction outcome loss': 0.3296484962703973, 'Total loss': 0.3296484962703973}
2023-01-05 15:57:23,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:23,924 INFO:     Epoch: 42
2023-01-05 15:57:26,039 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40360175718863806, 'Total loss': 0.40360175718863806} | train loss {'Reaction outcome loss': 0.3333486685814866, 'Total loss': 0.3333486685814866}
2023-01-05 15:57:26,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:26,039 INFO:     Epoch: 43
2023-01-05 15:57:28,152 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39835879305998484, 'Total loss': 0.39835879305998484} | train loss {'Reaction outcome loss': 0.327026632553252, 'Total loss': 0.327026632553252}
2023-01-05 15:57:28,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:28,153 INFO:     Epoch: 44
2023-01-05 15:57:30,279 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3762654225031535, 'Total loss': 0.3762654225031535} | train loss {'Reaction outcome loss': 0.329208349958606, 'Total loss': 0.329208349958606}
2023-01-05 15:57:30,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:30,279 INFO:     Epoch: 45
2023-01-05 15:57:32,416 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3662802090247472, 'Total loss': 0.3662802090247472} | train loss {'Reaction outcome loss': 0.3253720778237729, 'Total loss': 0.3253720778237729}
2023-01-05 15:57:32,416 INFO:     Found new best model at epoch 45
2023-01-05 15:57:32,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:32,418 INFO:     Epoch: 46
2023-01-05 15:57:34,541 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3998906577626864, 'Total loss': 0.3998906577626864} | train loss {'Reaction outcome loss': 0.32066212863708937, 'Total loss': 0.32066212863708937}
2023-01-05 15:57:34,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:34,542 INFO:     Epoch: 47
2023-01-05 15:57:36,660 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4116511305173238, 'Total loss': 0.4116511305173238} | train loss {'Reaction outcome loss': 0.3107827563844893, 'Total loss': 0.3107827563844893}
2023-01-05 15:57:36,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:36,660 INFO:     Epoch: 48
2023-01-05 15:57:38,796 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3816175897916158, 'Total loss': 0.3816175897916158} | train loss {'Reaction outcome loss': 0.31700069682985327, 'Total loss': 0.31700069682985327}
2023-01-05 15:57:38,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:38,797 INFO:     Epoch: 49
2023-01-05 15:57:40,903 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40738556583722435, 'Total loss': 0.40738556583722435} | train loss {'Reaction outcome loss': 0.3118279894038926, 'Total loss': 0.3118279894038926}
2023-01-05 15:57:40,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:40,904 INFO:     Epoch: 50
2023-01-05 15:57:43,021 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3965591644247373, 'Total loss': 0.3965591644247373} | train loss {'Reaction outcome loss': 0.30537844083550636, 'Total loss': 0.30537844083550636}
2023-01-05 15:57:43,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:43,022 INFO:     Epoch: 51
2023-01-05 15:57:45,152 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3799656997124354, 'Total loss': 0.3799656997124354} | train loss {'Reaction outcome loss': 0.30322247002627295, 'Total loss': 0.30322247002627295}
2023-01-05 15:57:45,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:45,153 INFO:     Epoch: 52
2023-01-05 15:57:47,304 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39094227850437163, 'Total loss': 0.39094227850437163} | train loss {'Reaction outcome loss': 0.30320295429768135, 'Total loss': 0.30320295429768135}
2023-01-05 15:57:47,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:47,304 INFO:     Epoch: 53
2023-01-05 15:57:49,458 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3991981486479441, 'Total loss': 0.3991981486479441} | train loss {'Reaction outcome loss': 0.30142696064482205, 'Total loss': 0.30142696064482205}
2023-01-05 15:57:49,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:49,458 INFO:     Epoch: 54
2023-01-05 15:57:51,586 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3728966216246287, 'Total loss': 0.3728966216246287} | train loss {'Reaction outcome loss': 0.30199844063851083, 'Total loss': 0.30199844063851083}
2023-01-05 15:57:51,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:51,586 INFO:     Epoch: 55
2023-01-05 15:57:53,771 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37818752229213715, 'Total loss': 0.37818752229213715} | train loss {'Reaction outcome loss': 0.30435148362804504, 'Total loss': 0.30435148362804504}
2023-01-05 15:57:53,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:53,772 INFO:     Epoch: 56
2023-01-05 15:57:56,000 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40761357148488364, 'Total loss': 0.40761357148488364} | train loss {'Reaction outcome loss': 0.29299377662258863, 'Total loss': 0.29299377662258863}
2023-01-05 15:57:56,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:56,000 INFO:     Epoch: 57
2023-01-05 15:57:58,242 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3582245657841365, 'Total loss': 0.3582245657841365} | train loss {'Reaction outcome loss': 0.29629539869671323, 'Total loss': 0.29629539869671323}
2023-01-05 15:57:58,243 INFO:     Found new best model at epoch 57
2023-01-05 15:57:58,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:57:58,245 INFO:     Epoch: 58
2023-01-05 15:58:00,477 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.36366012742122017, 'Total loss': 0.36366012742122017} | train loss {'Reaction outcome loss': 0.2865532367714565, 'Total loss': 0.2865532367714565}
2023-01-05 15:58:00,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:00,477 INFO:     Epoch: 59
2023-01-05 15:58:02,703 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3943957696358363, 'Total loss': 0.3943957696358363} | train loss {'Reaction outcome loss': 0.2859948858156474, 'Total loss': 0.2859948858156474}
2023-01-05 15:58:02,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:02,703 INFO:     Epoch: 60
2023-01-05 15:58:04,924 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.38643502195676166, 'Total loss': 0.38643502195676166} | train loss {'Reaction outcome loss': 0.2886104037386984, 'Total loss': 0.2886104037386984}
2023-01-05 15:58:04,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:04,924 INFO:     Epoch: 61
2023-01-05 15:58:07,150 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3963000724713008, 'Total loss': 0.3963000724713008} | train loss {'Reaction outcome loss': 0.2846949233870654, 'Total loss': 0.2846949233870654}
2023-01-05 15:58:07,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:07,151 INFO:     Epoch: 62
2023-01-05 15:58:09,348 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41571068316698073, 'Total loss': 0.41571068316698073} | train loss {'Reaction outcome loss': 0.28026257111371433, 'Total loss': 0.28026257111371433}
2023-01-05 15:58:09,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:09,348 INFO:     Epoch: 63
2023-01-05 15:58:11,494 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37064385612805684, 'Total loss': 0.37064385612805684} | train loss {'Reaction outcome loss': 0.28224415669258496, 'Total loss': 0.28224415669258496}
2023-01-05 15:58:11,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:11,494 INFO:     Epoch: 64
2023-01-05 15:58:13,635 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.36004937092463174, 'Total loss': 0.36004937092463174} | train loss {'Reaction outcome loss': 0.2770567393324671, 'Total loss': 0.2770567393324671}
2023-01-05 15:58:13,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:13,635 INFO:     Epoch: 65
2023-01-05 15:58:15,784 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3816903313000997, 'Total loss': 0.3816903313000997} | train loss {'Reaction outcome loss': 0.2777827986427685, 'Total loss': 0.2777827986427685}
2023-01-05 15:58:15,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:15,785 INFO:     Epoch: 66
2023-01-05 15:58:17,924 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.36724199801683427, 'Total loss': 0.36724199801683427} | train loss {'Reaction outcome loss': 0.27623563901568854, 'Total loss': 0.27623563901568854}
2023-01-05 15:58:17,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:17,924 INFO:     Epoch: 67
2023-01-05 15:58:20,063 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3825999120871226, 'Total loss': 0.3825999120871226} | train loss {'Reaction outcome loss': 0.26735668054978995, 'Total loss': 0.26735668054978995}
2023-01-05 15:58:20,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:20,063 INFO:     Epoch: 68
2023-01-05 15:58:22,234 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.34958940198024113, 'Total loss': 0.34958940198024113} | train loss {'Reaction outcome loss': 0.2756502685157487, 'Total loss': 0.2756502685157487}
2023-01-05 15:58:22,234 INFO:     Found new best model at epoch 68
2023-01-05 15:58:22,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:22,236 INFO:     Epoch: 69
2023-01-05 15:58:24,382 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.36766571005185444, 'Total loss': 0.36766571005185444} | train loss {'Reaction outcome loss': 0.2766317854071186, 'Total loss': 0.2766317854071186}
2023-01-05 15:58:24,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:24,382 INFO:     Epoch: 70
2023-01-05 15:58:26,496 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37216057976086936, 'Total loss': 0.37216057976086936} | train loss {'Reaction outcome loss': 0.26394010107474825, 'Total loss': 0.26394010107474825}
2023-01-05 15:58:26,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:26,496 INFO:     Epoch: 71
2023-01-05 15:58:28,648 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.357940141359965, 'Total loss': 0.357940141359965} | train loss {'Reaction outcome loss': 0.270878814650278, 'Total loss': 0.270878814650278}
2023-01-05 15:58:28,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:28,648 INFO:     Epoch: 72
2023-01-05 15:58:30,849 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3468982477982839, 'Total loss': 0.3468982477982839} | train loss {'Reaction outcome loss': 0.27047861582280075, 'Total loss': 0.27047861582280075}
2023-01-05 15:58:30,849 INFO:     Found new best model at epoch 72
2023-01-05 15:58:30,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:30,850 INFO:     Epoch: 73
2023-01-05 15:58:33,063 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40629835923512775, 'Total loss': 0.40629835923512775} | train loss {'Reaction outcome loss': 0.26828261655177515, 'Total loss': 0.26828261655177515}
2023-01-05 15:58:33,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:33,063 INFO:     Epoch: 74
2023-01-05 15:58:35,245 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41626619597276054, 'Total loss': 0.41626619597276054} | train loss {'Reaction outcome loss': 0.2586460274909317, 'Total loss': 0.2586460274909317}
2023-01-05 15:58:35,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:35,246 INFO:     Epoch: 75
2023-01-05 15:58:37,388 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3938977042833964, 'Total loss': 0.3938977042833964} | train loss {'Reaction outcome loss': 0.2667300240374612, 'Total loss': 0.2667300240374612}
2023-01-05 15:58:37,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:37,389 INFO:     Epoch: 76
2023-01-05 15:58:39,565 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4067963550488154, 'Total loss': 0.4067963550488154} | train loss {'Reaction outcome loss': 0.26123431902786676, 'Total loss': 0.26123431902786676}
2023-01-05 15:58:39,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:39,566 INFO:     Epoch: 77
2023-01-05 15:58:41,765 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40969128410021466, 'Total loss': 0.40969128410021466} | train loss {'Reaction outcome loss': 0.2571545779215593, 'Total loss': 0.2571545779215593}
2023-01-05 15:58:41,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:41,765 INFO:     Epoch: 78
2023-01-05 15:58:43,927 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40408725341161095, 'Total loss': 0.40408725341161095} | train loss {'Reaction outcome loss': 0.25638339657635584, 'Total loss': 0.25638339657635584}
2023-01-05 15:58:43,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:43,928 INFO:     Epoch: 79
2023-01-05 15:58:46,099 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38067179123560585, 'Total loss': 0.38067179123560585} | train loss {'Reaction outcome loss': 0.25565289504091887, 'Total loss': 0.25565289504091887}
2023-01-05 15:58:46,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:46,100 INFO:     Epoch: 80
2023-01-05 15:58:48,257 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.36123270690441134, 'Total loss': 0.36123270690441134} | train loss {'Reaction outcome loss': 0.25519804400561824, 'Total loss': 0.25519804400561824}
2023-01-05 15:58:48,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:48,258 INFO:     Epoch: 81
2023-01-05 15:58:50,352 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38265756766001385, 'Total loss': 0.38265756766001385} | train loss {'Reaction outcome loss': 0.2550857796190973, 'Total loss': 0.2550857796190973}
2023-01-05 15:58:50,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:50,352 INFO:     Epoch: 82
2023-01-05 15:58:52,479 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.355552543203036, 'Total loss': 0.355552543203036} | train loss {'Reaction outcome loss': 0.24916485514165493, 'Total loss': 0.24916485514165493}
2023-01-05 15:58:52,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:52,479 INFO:     Epoch: 83
2023-01-05 15:58:54,614 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40602285663286847, 'Total loss': 0.40602285663286847} | train loss {'Reaction outcome loss': 0.2515211599287543, 'Total loss': 0.2515211599287543}
2023-01-05 15:58:54,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:54,614 INFO:     Epoch: 84
2023-01-05 15:58:56,749 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3654396047194799, 'Total loss': 0.3654396047194799} | train loss {'Reaction outcome loss': 0.25261930188667164, 'Total loss': 0.25261930188667164}
2023-01-05 15:58:56,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:56,749 INFO:     Epoch: 85
2023-01-05 15:58:58,889 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38140542109807335, 'Total loss': 0.38140542109807335} | train loss {'Reaction outcome loss': 0.24781767704462918, 'Total loss': 0.24781767704462918}
2023-01-05 15:58:58,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:58:58,889 INFO:     Epoch: 86
2023-01-05 15:59:01,019 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3631154221793016, 'Total loss': 0.3631154221793016} | train loss {'Reaction outcome loss': 0.24905636326756572, 'Total loss': 0.24905636326756572}
2023-01-05 15:59:01,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:01,019 INFO:     Epoch: 87
2023-01-05 15:59:03,153 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.37656004428863527, 'Total loss': 0.37656004428863527} | train loss {'Reaction outcome loss': 0.25245345526639995, 'Total loss': 0.25245345526639995}
2023-01-05 15:59:03,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:03,153 INFO:     Epoch: 88
2023-01-05 15:59:05,281 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4049520015716553, 'Total loss': 0.4049520015716553} | train loss {'Reaction outcome loss': 0.2483311858653587, 'Total loss': 0.2483311858653587}
2023-01-05 15:59:05,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:05,282 INFO:     Epoch: 89
2023-01-05 15:59:07,412 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38659559885660805, 'Total loss': 0.38659559885660805} | train loss {'Reaction outcome loss': 0.23986883658276748, 'Total loss': 0.23986883658276748}
2023-01-05 15:59:07,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:07,413 INFO:     Epoch: 90
2023-01-05 15:59:09,536 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3380201578140259, 'Total loss': 0.3380201578140259} | train loss {'Reaction outcome loss': 0.24233910214346255, 'Total loss': 0.24233910214346255}
2023-01-05 15:59:09,536 INFO:     Found new best model at epoch 90
2023-01-05 15:59:09,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:09,537 INFO:     Epoch: 91
2023-01-05 15:59:11,647 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.37615243246157964, 'Total loss': 0.37615243246157964} | train loss {'Reaction outcome loss': 0.2509727221845656, 'Total loss': 0.2509727221845656}
2023-01-05 15:59:11,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:11,647 INFO:     Epoch: 92
2023-01-05 15:59:13,757 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3904519339402517, 'Total loss': 0.3904519339402517} | train loss {'Reaction outcome loss': 0.24613113840022227, 'Total loss': 0.24613113840022227}
2023-01-05 15:59:13,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:13,757 INFO:     Epoch: 93
2023-01-05 15:59:15,880 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38605569998423256, 'Total loss': 0.38605569998423256} | train loss {'Reaction outcome loss': 0.2451471149391175, 'Total loss': 0.2451471149391175}
2023-01-05 15:59:15,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:15,881 INFO:     Epoch: 94
2023-01-05 15:59:18,052 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3559490621089935, 'Total loss': 0.3559490621089935} | train loss {'Reaction outcome loss': 0.2411996400133319, 'Total loss': 0.2411996400133319}
2023-01-05 15:59:18,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:18,053 INFO:     Epoch: 95
2023-01-05 15:59:20,205 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43208573162555697, 'Total loss': 0.43208573162555697} | train loss {'Reaction outcome loss': 0.244926034408302, 'Total loss': 0.244926034408302}
2023-01-05 15:59:20,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:20,206 INFO:     Epoch: 96
2023-01-05 15:59:22,330 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3981638977924983, 'Total loss': 0.3981638977924983} | train loss {'Reaction outcome loss': 0.23861328279599547, 'Total loss': 0.23861328279599547}
2023-01-05 15:59:22,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:22,330 INFO:     Epoch: 97
2023-01-05 15:59:24,433 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.37111802597840626, 'Total loss': 0.37111802597840626} | train loss {'Reaction outcome loss': 0.23231460334202886, 'Total loss': 0.23231460334202886}
2023-01-05 15:59:24,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:24,433 INFO:     Epoch: 98
2023-01-05 15:59:26,551 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3904603153467178, 'Total loss': 0.3904603153467178} | train loss {'Reaction outcome loss': 0.2364927187262878, 'Total loss': 0.2364927187262878}
2023-01-05 15:59:26,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:26,551 INFO:     Epoch: 99
2023-01-05 15:59:28,683 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3990904937187831, 'Total loss': 0.3990904937187831} | train loss {'Reaction outcome loss': 0.23698411248352405, 'Total loss': 0.23698411248352405}
2023-01-05 15:59:28,683 INFO:     Best model found after epoch 91 of 100.
2023-01-05 15:59:28,683 INFO:   Done with stage: TRAINING
2023-01-05 15:59:28,683 INFO:   Starting stage: EVALUATION
2023-01-05 15:59:28,821 INFO:   Done with stage: EVALUATION
2023-01-05 15:59:28,822 INFO:   Leaving out SEQ value Fold_9
2023-01-05 15:59:28,834 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 15:59:28,834 INFO:   Starting stage: FEATURE SCALING
2023-01-05 15:59:29,488 INFO:   Done with stage: FEATURE SCALING
2023-01-05 15:59:29,488 INFO:   Starting stage: SCALING TARGETS
2023-01-05 15:59:29,557 INFO:   Done with stage: SCALING TARGETS
2023-01-05 15:59:29,557 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:59:29,557 INFO:     No hyperparam tuning for this model
2023-01-05 15:59:29,557 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 15:59:29,557 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 15:59:29,558 INFO:     None feature selector for col prot
2023-01-05 15:59:29,558 INFO:     None feature selector for col prot
2023-01-05 15:59:29,558 INFO:     None feature selector for col prot
2023-01-05 15:59:29,559 INFO:     None feature selector for col chem
2023-01-05 15:59:29,559 INFO:     None feature selector for col chem
2023-01-05 15:59:29,559 INFO:     None feature selector for col chem
2023-01-05 15:59:29,559 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 15:59:29,559 INFO:   Starting stage: BUILD MODEL
2023-01-05 15:59:29,560 INFO:     Number of params in model 72901
2023-01-05 15:59:29,564 INFO:   Done with stage: BUILD MODEL
2023-01-05 15:59:29,564 INFO:   Starting stage: TRAINING
2023-01-05 15:59:29,622 INFO:     Val loss before train {'Reaction outcome loss': 0.8948517878850301, 'Total loss': 0.8948517878850301}
2023-01-05 15:59:29,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:29,622 INFO:     Epoch: 0
2023-01-05 15:59:31,795 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7058967590332031, 'Total loss': 0.7058967590332031} | train loss {'Reaction outcome loss': 0.9301072382754798, 'Total loss': 0.9301072382754798}
2023-01-05 15:59:31,795 INFO:     Found new best model at epoch 0
2023-01-05 15:59:31,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:31,796 INFO:     Epoch: 1
2023-01-05 15:59:33,756 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5684576690196991, 'Total loss': 0.5684576690196991} | train loss {'Reaction outcome loss': 0.724133002521329, 'Total loss': 0.724133002521329}
2023-01-05 15:59:33,756 INFO:     Found new best model at epoch 1
2023-01-05 15:59:33,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:33,757 INFO:     Epoch: 2
2023-01-05 15:59:35,903 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5005468606948853, 'Total loss': 0.5005468606948853} | train loss {'Reaction outcome loss': 0.575307899218604, 'Total loss': 0.575307899218604}
2023-01-05 15:59:35,904 INFO:     Found new best model at epoch 2
2023-01-05 15:59:35,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:35,905 INFO:     Epoch: 3
2023-01-05 15:59:38,064 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.503062105178833, 'Total loss': 0.503062105178833} | train loss {'Reaction outcome loss': 0.5336395262703568, 'Total loss': 0.5336395262703568}
2023-01-05 15:59:38,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:38,064 INFO:     Epoch: 4
2023-01-05 15:59:40,238 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.480929030974706, 'Total loss': 0.480929030974706} | train loss {'Reaction outcome loss': 0.5176135665780801, 'Total loss': 0.5176135665780801}
2023-01-05 15:59:40,238 INFO:     Found new best model at epoch 4
2023-01-05 15:59:40,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:40,240 INFO:     Epoch: 5
2023-01-05 15:59:42,431 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4494156132141749, 'Total loss': 0.4494156132141749} | train loss {'Reaction outcome loss': 0.506125908304638, 'Total loss': 0.506125908304638}
2023-01-05 15:59:42,431 INFO:     Found new best model at epoch 5
2023-01-05 15:59:42,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:42,432 INFO:     Epoch: 6
2023-01-05 15:59:44,617 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46513232787450154, 'Total loss': 0.46513232787450154} | train loss {'Reaction outcome loss': 0.4967970065369072, 'Total loss': 0.4967970065369072}
2023-01-05 15:59:44,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:44,617 INFO:     Epoch: 7
2023-01-05 15:59:46,781 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4619482934474945, 'Total loss': 0.4619482934474945} | train loss {'Reaction outcome loss': 0.4859387736619595, 'Total loss': 0.4859387736619595}
2023-01-05 15:59:46,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:46,781 INFO:     Epoch: 8
2023-01-05 15:59:48,920 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44526897569497426, 'Total loss': 0.44526897569497426} | train loss {'Reaction outcome loss': 0.4782636546217147, 'Total loss': 0.4782636546217147}
2023-01-05 15:59:48,920 INFO:     Found new best model at epoch 8
2023-01-05 15:59:48,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:48,921 INFO:     Epoch: 9
2023-01-05 15:59:51,056 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.434226597348849, 'Total loss': 0.434226597348849} | train loss {'Reaction outcome loss': 0.4731890177791299, 'Total loss': 0.4731890177791299}
2023-01-05 15:59:51,056 INFO:     Found new best model at epoch 9
2023-01-05 15:59:51,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:51,057 INFO:     Epoch: 10
2023-01-05 15:59:53,201 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.433040064573288, 'Total loss': 0.433040064573288} | train loss {'Reaction outcome loss': 0.46739284688815314, 'Total loss': 0.46739284688815314}
2023-01-05 15:59:53,202 INFO:     Found new best model at epoch 10
2023-01-05 15:59:53,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:53,203 INFO:     Epoch: 11
2023-01-05 15:59:55,351 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4577933589617411, 'Total loss': 0.4577933589617411} | train loss {'Reaction outcome loss': 0.4653570028526258, 'Total loss': 0.4653570028526258}
2023-01-05 15:59:55,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:55,351 INFO:     Epoch: 12
2023-01-05 15:59:57,502 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4264676749706268, 'Total loss': 0.4264676749706268} | train loss {'Reaction outcome loss': 0.4602139848233991, 'Total loss': 0.4602139848233991}
2023-01-05 15:59:57,502 INFO:     Found new best model at epoch 12
2023-01-05 15:59:57,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:57,503 INFO:     Epoch: 13
2023-01-05 15:59:59,680 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.448394900560379, 'Total loss': 0.448394900560379} | train loss {'Reaction outcome loss': 0.46225795440295114, 'Total loss': 0.46225795440295114}
2023-01-05 15:59:59,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 15:59:59,681 INFO:     Epoch: 14
2023-01-05 16:00:01,843 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4325788736343384, 'Total loss': 0.4325788736343384} | train loss {'Reaction outcome loss': 0.45092260019873887, 'Total loss': 0.45092260019873887}
2023-01-05 16:00:01,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:01,844 INFO:     Epoch: 15
2023-01-05 16:00:03,988 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4684387693802516, 'Total loss': 0.4684387693802516} | train loss {'Reaction outcome loss': 0.4454786350634554, 'Total loss': 0.4454786350634554}
2023-01-05 16:00:03,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:03,989 INFO:     Epoch: 16
2023-01-05 16:00:06,143 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.419511416554451, 'Total loss': 0.419511416554451} | train loss {'Reaction outcome loss': 0.4432456274432826, 'Total loss': 0.4432456274432826}
2023-01-05 16:00:06,143 INFO:     Found new best model at epoch 16
2023-01-05 16:00:06,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:06,144 INFO:     Epoch: 17
2023-01-05 16:00:08,300 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42635827759901684, 'Total loss': 0.42635827759901684} | train loss {'Reaction outcome loss': 0.4440433138490584, 'Total loss': 0.4440433138490584}
2023-01-05 16:00:08,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:08,301 INFO:     Epoch: 18
2023-01-05 16:00:10,437 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4219302405913671, 'Total loss': 0.4219302405913671} | train loss {'Reaction outcome loss': 0.44010006709004135, 'Total loss': 0.44010006709004135}
2023-01-05 16:00:10,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:10,437 INFO:     Epoch: 19
2023-01-05 16:00:12,600 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4374189486106237, 'Total loss': 0.4374189486106237} | train loss {'Reaction outcome loss': 0.4328607704611461, 'Total loss': 0.4328607704611461}
2023-01-05 16:00:12,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:12,601 INFO:     Epoch: 20
2023-01-05 16:00:14,748 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4236796389023463, 'Total loss': 0.4236796389023463} | train loss {'Reaction outcome loss': 0.4255812588258771, 'Total loss': 0.4255812588258771}
2023-01-05 16:00:14,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:14,748 INFO:     Epoch: 21
2023-01-05 16:00:16,908 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.417052298784256, 'Total loss': 0.417052298784256} | train loss {'Reaction outcome loss': 0.4281555347225296, 'Total loss': 0.4281555347225296}
2023-01-05 16:00:16,908 INFO:     Found new best model at epoch 21
2023-01-05 16:00:16,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:16,909 INFO:     Epoch: 22
2023-01-05 16:00:19,068 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.441655474777023, 'Total loss': 0.441655474777023} | train loss {'Reaction outcome loss': 0.42123554289233384, 'Total loss': 0.42123554289233384}
2023-01-05 16:00:19,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:19,068 INFO:     Epoch: 23
2023-01-05 16:00:21,218 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44009039799372357, 'Total loss': 0.44009039799372357} | train loss {'Reaction outcome loss': 0.414100399731729, 'Total loss': 0.414100399731729}
2023-01-05 16:00:21,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:21,219 INFO:     Epoch: 24
2023-01-05 16:00:23,387 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3989759455124537, 'Total loss': 0.3989759455124537} | train loss {'Reaction outcome loss': 0.40949278424362845, 'Total loss': 0.40949278424362845}
2023-01-05 16:00:23,388 INFO:     Found new best model at epoch 24
2023-01-05 16:00:23,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:23,389 INFO:     Epoch: 25
2023-01-05 16:00:25,545 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4338923136393229, 'Total loss': 0.4338923136393229} | train loss {'Reaction outcome loss': 0.4074861710144725, 'Total loss': 0.4074861710144725}
2023-01-05 16:00:25,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:25,545 INFO:     Epoch: 26
2023-01-05 16:00:27,707 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3923772364854813, 'Total loss': 0.3923772364854813} | train loss {'Reaction outcome loss': 0.4037036547968534, 'Total loss': 0.4037036547968534}
2023-01-05 16:00:27,707 INFO:     Found new best model at epoch 26
2023-01-05 16:00:27,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:27,708 INFO:     Epoch: 27
2023-01-05 16:00:29,884 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4087131510178248, 'Total loss': 0.4087131510178248} | train loss {'Reaction outcome loss': 0.39703729065531856, 'Total loss': 0.39703729065531856}
2023-01-05 16:00:29,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:29,885 INFO:     Epoch: 28
2023-01-05 16:00:32,047 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.406888954838117, 'Total loss': 0.406888954838117} | train loss {'Reaction outcome loss': 0.39531019921767585, 'Total loss': 0.39531019921767585}
2023-01-05 16:00:32,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:32,047 INFO:     Epoch: 29
2023-01-05 16:00:34,213 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42689959704875946, 'Total loss': 0.42689959704875946} | train loss {'Reaction outcome loss': 0.39240689642915655, 'Total loss': 0.39240689642915655}
2023-01-05 16:00:34,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:34,214 INFO:     Epoch: 30
2023-01-05 16:00:36,372 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4073779215415319, 'Total loss': 0.4073779215415319} | train loss {'Reaction outcome loss': 0.38427867546731387, 'Total loss': 0.38427867546731387}
2023-01-05 16:00:36,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:36,373 INFO:     Epoch: 31
2023-01-05 16:00:38,530 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41245978673299155, 'Total loss': 0.41245978673299155} | train loss {'Reaction outcome loss': 0.38160895314134846, 'Total loss': 0.38160895314134846}
2023-01-05 16:00:38,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:38,530 INFO:     Epoch: 32
2023-01-05 16:00:40,712 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4373198797305425, 'Total loss': 0.4373198797305425} | train loss {'Reaction outcome loss': 0.37811843642043724, 'Total loss': 0.37811843642043724}
2023-01-05 16:00:40,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:40,712 INFO:     Epoch: 33
2023-01-05 16:00:42,875 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42786155740420023, 'Total loss': 0.42786155740420023} | train loss {'Reaction outcome loss': 0.3686234348248489, 'Total loss': 0.3686234348248489}
2023-01-05 16:00:42,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:42,876 INFO:     Epoch: 34
2023-01-05 16:00:45,013 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3874754617611567, 'Total loss': 0.3874754617611567} | train loss {'Reaction outcome loss': 0.36305246886793885, 'Total loss': 0.36305246886793885}
2023-01-05 16:00:45,013 INFO:     Found new best model at epoch 34
2023-01-05 16:00:45,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:45,014 INFO:     Epoch: 35
2023-01-05 16:00:47,162 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4179484973351161, 'Total loss': 0.4179484973351161} | train loss {'Reaction outcome loss': 0.359757356009436, 'Total loss': 0.359757356009436}
2023-01-05 16:00:47,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:47,163 INFO:     Epoch: 36
2023-01-05 16:00:49,335 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3922554795940717, 'Total loss': 0.3922554795940717} | train loss {'Reaction outcome loss': 0.36231917278699927, 'Total loss': 0.36231917278699927}
2023-01-05 16:00:49,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:49,335 INFO:     Epoch: 37
2023-01-05 16:00:51,523 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3863803724447886, 'Total loss': 0.3863803724447886} | train loss {'Reaction outcome loss': 0.3571240832820696, 'Total loss': 0.3571240832820696}
2023-01-05 16:00:51,523 INFO:     Found new best model at epoch 37
2023-01-05 16:00:51,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:51,524 INFO:     Epoch: 38
2023-01-05 16:00:53,704 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39503320554892224, 'Total loss': 0.39503320554892224} | train loss {'Reaction outcome loss': 0.35593707555575493, 'Total loss': 0.35593707555575493}
2023-01-05 16:00:53,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:53,705 INFO:     Epoch: 39
2023-01-05 16:00:55,871 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39745447039604187, 'Total loss': 0.39745447039604187} | train loss {'Reaction outcome loss': 0.3505555537902491, 'Total loss': 0.3505555537902491}
2023-01-05 16:00:55,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:55,871 INFO:     Epoch: 40
2023-01-05 16:00:58,046 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.382012864947319, 'Total loss': 0.382012864947319} | train loss {'Reaction outcome loss': 0.34526498548498225, 'Total loss': 0.34526498548498225}
2023-01-05 16:00:58,046 INFO:     Found new best model at epoch 40
2023-01-05 16:00:58,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:00:58,047 INFO:     Epoch: 41
2023-01-05 16:01:00,175 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42317953904469807, 'Total loss': 0.42317953904469807} | train loss {'Reaction outcome loss': 0.34274120141990777, 'Total loss': 0.34274120141990777}
2023-01-05 16:01:00,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:00,175 INFO:     Epoch: 42
2023-01-05 16:01:02,333 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.401667616267999, 'Total loss': 0.401667616267999} | train loss {'Reaction outcome loss': 0.33614797470586827, 'Total loss': 0.33614797470586827}
2023-01-05 16:01:02,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:02,333 INFO:     Epoch: 43
2023-01-05 16:01:04,505 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38761513829231264, 'Total loss': 0.38761513829231264} | train loss {'Reaction outcome loss': 0.3383182664586749, 'Total loss': 0.3383182664586749}
2023-01-05 16:01:04,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:04,505 INFO:     Epoch: 44
2023-01-05 16:01:06,681 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3941003461678823, 'Total loss': 0.3941003461678823} | train loss {'Reaction outcome loss': 0.337047903788434, 'Total loss': 0.337047903788434}
2023-01-05 16:01:06,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:06,681 INFO:     Epoch: 45
2023-01-05 16:01:08,837 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.37631215850512184, 'Total loss': 0.37631215850512184} | train loss {'Reaction outcome loss': 0.3337201398363613, 'Total loss': 0.3337201398363613}
2023-01-05 16:01:08,837 INFO:     Found new best model at epoch 45
2023-01-05 16:01:08,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:08,839 INFO:     Epoch: 46
2023-01-05 16:01:11,013 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41175928711891174, 'Total loss': 0.41175928711891174} | train loss {'Reaction outcome loss': 0.32143978918448685, 'Total loss': 0.32143978918448685}
2023-01-05 16:01:11,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:11,013 INFO:     Epoch: 47
2023-01-05 16:01:13,218 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3889965653419495, 'Total loss': 0.3889965653419495} | train loss {'Reaction outcome loss': 0.32556136681392306, 'Total loss': 0.32556136681392306}
2023-01-05 16:01:13,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:13,219 INFO:     Epoch: 48
2023-01-05 16:01:15,364 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39842112561066945, 'Total loss': 0.39842112561066945} | train loss {'Reaction outcome loss': 0.3251814644797184, 'Total loss': 0.3251814644797184}
2023-01-05 16:01:15,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:15,364 INFO:     Epoch: 49
2023-01-05 16:01:17,524 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37853797475496925, 'Total loss': 0.37853797475496925} | train loss {'Reaction outcome loss': 0.3234423369518901, 'Total loss': 0.3234423369518901}
2023-01-05 16:01:17,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:17,524 INFO:     Epoch: 50
2023-01-05 16:01:19,655 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3662738844752312, 'Total loss': 0.3662738844752312} | train loss {'Reaction outcome loss': 0.3234777715769916, 'Total loss': 0.3234777715769916}
2023-01-05 16:01:19,655 INFO:     Found new best model at epoch 50
2023-01-05 16:01:19,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:19,656 INFO:     Epoch: 51
2023-01-05 16:01:21,814 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3635647604862849, 'Total loss': 0.3635647604862849} | train loss {'Reaction outcome loss': 0.3126697269022895, 'Total loss': 0.3126697269022895}
2023-01-05 16:01:21,814 INFO:     Found new best model at epoch 51
2023-01-05 16:01:21,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:21,815 INFO:     Epoch: 52
2023-01-05 16:01:23,972 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4044151797890663, 'Total loss': 0.4044151797890663} | train loss {'Reaction outcome loss': 0.3129227740643042, 'Total loss': 0.3129227740643042}
2023-01-05 16:01:23,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:23,972 INFO:     Epoch: 53
2023-01-05 16:01:26,151 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40221649408340454, 'Total loss': 0.40221649408340454} | train loss {'Reaction outcome loss': 0.3092277832127543, 'Total loss': 0.3092277832127543}
2023-01-05 16:01:26,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:26,151 INFO:     Epoch: 54
2023-01-05 16:01:28,311 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38830310901006065, 'Total loss': 0.38830310901006065} | train loss {'Reaction outcome loss': 0.3054003864795723, 'Total loss': 0.3054003864795723}
2023-01-05 16:01:28,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:28,311 INFO:     Epoch: 55
2023-01-05 16:01:30,468 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3573430746793747, 'Total loss': 0.3573430746793747} | train loss {'Reaction outcome loss': 0.3059529267009415, 'Total loss': 0.3059529267009415}
2023-01-05 16:01:30,469 INFO:     Found new best model at epoch 55
2023-01-05 16:01:30,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:30,470 INFO:     Epoch: 56
2023-01-05 16:01:32,628 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3718213732043902, 'Total loss': 0.3718213732043902} | train loss {'Reaction outcome loss': 0.29782067691160885, 'Total loss': 0.29782067691160885}
2023-01-05 16:01:32,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:32,628 INFO:     Epoch: 57
2023-01-05 16:01:34,788 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4185348888238271, 'Total loss': 0.4185348888238271} | train loss {'Reaction outcome loss': 0.3056673075102727, 'Total loss': 0.3056673075102727}
2023-01-05 16:01:34,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:34,788 INFO:     Epoch: 58
2023-01-05 16:01:36,937 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.36887149115403495, 'Total loss': 0.36887149115403495} | train loss {'Reaction outcome loss': 0.3050708117548524, 'Total loss': 0.3050708117548524}
2023-01-05 16:01:36,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:36,938 INFO:     Epoch: 59
2023-01-05 16:01:39,093 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4028964837392171, 'Total loss': 0.4028964837392171} | train loss {'Reaction outcome loss': 0.2919624581771637, 'Total loss': 0.2919624581771637}
2023-01-05 16:01:39,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:39,093 INFO:     Epoch: 60
2023-01-05 16:01:41,249 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3768873115380605, 'Total loss': 0.3768873115380605} | train loss {'Reaction outcome loss': 0.30825832351665633, 'Total loss': 0.30825832351665633}
2023-01-05 16:01:41,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:41,249 INFO:     Epoch: 61
2023-01-05 16:01:43,392 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3690330356359482, 'Total loss': 0.3690330356359482} | train loss {'Reaction outcome loss': 0.2919765016339746, 'Total loss': 0.2919765016339746}
2023-01-05 16:01:43,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:43,392 INFO:     Epoch: 62
2023-01-05 16:01:45,542 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4038600335518519, 'Total loss': 0.4038600335518519} | train loss {'Reaction outcome loss': 0.2990054132060454, 'Total loss': 0.2990054132060454}
2023-01-05 16:01:45,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:45,543 INFO:     Epoch: 63
2023-01-05 16:01:47,683 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39151479105154674, 'Total loss': 0.39151479105154674} | train loss {'Reaction outcome loss': 0.2918856826741988, 'Total loss': 0.2918856826741988}
2023-01-05 16:01:47,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:47,683 INFO:     Epoch: 64
2023-01-05 16:01:49,836 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3830108861128489, 'Total loss': 0.3830108861128489} | train loss {'Reaction outcome loss': 0.2883109438639901, 'Total loss': 0.2883109438639901}
2023-01-05 16:01:49,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:49,836 INFO:     Epoch: 65
2023-01-05 16:01:52,011 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38981300592422485, 'Total loss': 0.38981300592422485} | train loss {'Reaction outcome loss': 0.2863343940503115, 'Total loss': 0.2863343940503115}
2023-01-05 16:01:52,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:52,012 INFO:     Epoch: 66
2023-01-05 16:01:54,162 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41001128156979877, 'Total loss': 0.41001128156979877} | train loss {'Reaction outcome loss': 0.28800916050422926, 'Total loss': 0.28800916050422926}
2023-01-05 16:01:54,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:54,163 INFO:     Epoch: 67
2023-01-05 16:01:56,315 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.35823947985967003, 'Total loss': 0.35823947985967003} | train loss {'Reaction outcome loss': 0.28246028920373334, 'Total loss': 0.28246028920373334}
2023-01-05 16:01:56,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:56,315 INFO:     Epoch: 68
2023-01-05 16:01:58,458 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39141064087549843, 'Total loss': 0.39141064087549843} | train loss {'Reaction outcome loss': 0.28355518302170807, 'Total loss': 0.28355518302170807}
2023-01-05 16:01:58,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:01:58,458 INFO:     Epoch: 69
2023-01-05 16:02:00,592 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4156353453795115, 'Total loss': 0.4156353453795115} | train loss {'Reaction outcome loss': 0.28793565522112785, 'Total loss': 0.28793565522112785}
2023-01-05 16:02:00,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:00,594 INFO:     Epoch: 70
2023-01-05 16:02:02,738 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39812171285351117, 'Total loss': 0.39812171285351117} | train loss {'Reaction outcome loss': 0.28437667474527223, 'Total loss': 0.28437667474527223}
2023-01-05 16:02:02,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:02,738 INFO:     Epoch: 71
2023-01-05 16:02:04,881 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4079345097144445, 'Total loss': 0.4079345097144445} | train loss {'Reaction outcome loss': 0.2761660055778517, 'Total loss': 0.2761660055778517}
2023-01-05 16:02:04,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:04,881 INFO:     Epoch: 72
2023-01-05 16:02:07,031 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38577102025349935, 'Total loss': 0.38577102025349935} | train loss {'Reaction outcome loss': 0.27914530504158686, 'Total loss': 0.27914530504158686}
2023-01-05 16:02:07,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:07,032 INFO:     Epoch: 73
2023-01-05 16:02:09,162 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40204224089781443, 'Total loss': 0.40204224089781443} | train loss {'Reaction outcome loss': 0.2747371029848441, 'Total loss': 0.2747371029848441}
2023-01-05 16:02:09,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:09,162 INFO:     Epoch: 74
2023-01-05 16:02:11,293 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.36914494236310325, 'Total loss': 0.36914494236310325} | train loss {'Reaction outcome loss': 0.27777904311080703, 'Total loss': 0.27777904311080703}
2023-01-05 16:02:11,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:11,293 INFO:     Epoch: 75
2023-01-05 16:02:13,451 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39388701220353445, 'Total loss': 0.39388701220353445} | train loss {'Reaction outcome loss': 0.26582071872340646, 'Total loss': 0.26582071872340646}
2023-01-05 16:02:13,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:13,451 INFO:     Epoch: 76
2023-01-05 16:02:15,599 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.389238898952802, 'Total loss': 0.389238898952802} | train loss {'Reaction outcome loss': 0.2699980383691805, 'Total loss': 0.2699980383691805}
2023-01-05 16:02:15,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:15,600 INFO:     Epoch: 77
2023-01-05 16:02:17,749 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38435416917006177, 'Total loss': 0.38435416917006177} | train loss {'Reaction outcome loss': 0.28306079965878267, 'Total loss': 0.28306079965878267}
2023-01-05 16:02:17,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:17,749 INFO:     Epoch: 78
2023-01-05 16:02:19,898 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.34639766812324524, 'Total loss': 0.34639766812324524} | train loss {'Reaction outcome loss': 0.26586726037550057, 'Total loss': 0.26586726037550057}
2023-01-05 16:02:19,899 INFO:     Found new best model at epoch 78
2023-01-05 16:02:19,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:19,900 INFO:     Epoch: 79
2023-01-05 16:02:22,056 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39157598515351616, 'Total loss': 0.39157598515351616} | train loss {'Reaction outcome loss': 0.2842794242600779, 'Total loss': 0.2842794242600779}
2023-01-05 16:02:22,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:22,057 INFO:     Epoch: 80
2023-01-05 16:02:24,213 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3928651730219523, 'Total loss': 0.3928651730219523} | train loss {'Reaction outcome loss': 0.27319345515665167, 'Total loss': 0.27319345515665167}
2023-01-05 16:02:24,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:24,213 INFO:     Epoch: 81
2023-01-05 16:02:26,382 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3852943370739619, 'Total loss': 0.3852943370739619} | train loss {'Reaction outcome loss': 0.2720821462437134, 'Total loss': 0.2720821462437134}
2023-01-05 16:02:26,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:26,382 INFO:     Epoch: 82
2023-01-05 16:02:28,535 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3786020358403524, 'Total loss': 0.3786020358403524} | train loss {'Reaction outcome loss': 0.26396490016192303, 'Total loss': 0.26396490016192303}
2023-01-05 16:02:28,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:28,535 INFO:     Epoch: 83
2023-01-05 16:02:30,713 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3676827927430471, 'Total loss': 0.3676827927430471} | train loss {'Reaction outcome loss': 0.2677171476528264, 'Total loss': 0.2677171476528264}
2023-01-05 16:02:30,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:30,714 INFO:     Epoch: 84
2023-01-05 16:02:32,874 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3904278328021367, 'Total loss': 0.3904278328021367} | train loss {'Reaction outcome loss': 0.2642463275806353, 'Total loss': 0.2642463275806353}
2023-01-05 16:02:32,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:32,874 INFO:     Epoch: 85
2023-01-05 16:02:35,029 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3826113055149714, 'Total loss': 0.3826113055149714} | train loss {'Reaction outcome loss': 0.26306183635852287, 'Total loss': 0.26306183635852287}
2023-01-05 16:02:35,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:35,030 INFO:     Epoch: 86
2023-01-05 16:02:37,189 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3788498222827911, 'Total loss': 0.3788498222827911} | train loss {'Reaction outcome loss': 0.2578977616066752, 'Total loss': 0.2578977616066752}
2023-01-05 16:02:37,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:37,190 INFO:     Epoch: 87
2023-01-05 16:02:39,318 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40521264374256133, 'Total loss': 0.40521264374256133} | train loss {'Reaction outcome loss': 0.2598929985053165, 'Total loss': 0.2598929985053165}
2023-01-05 16:02:39,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:39,319 INFO:     Epoch: 88
2023-01-05 16:02:41,479 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37744848330815634, 'Total loss': 0.37744848330815634} | train loss {'Reaction outcome loss': 0.25819986491104324, 'Total loss': 0.25819986491104324}
2023-01-05 16:02:41,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:41,479 INFO:     Epoch: 89
2023-01-05 16:02:43,653 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4017285873492559, 'Total loss': 0.4017285873492559} | train loss {'Reaction outcome loss': 0.2596438722987575, 'Total loss': 0.2596438722987575}
2023-01-05 16:02:43,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:43,654 INFO:     Epoch: 90
2023-01-05 16:02:45,805 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4008205602566401, 'Total loss': 0.4008205602566401} | train loss {'Reaction outcome loss': 0.25863523753057316, 'Total loss': 0.25863523753057316}
2023-01-05 16:02:45,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:45,805 INFO:     Epoch: 91
2023-01-05 16:02:47,976 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39304585258165997, 'Total loss': 0.39304585258165997} | train loss {'Reaction outcome loss': 0.2602139150838129, 'Total loss': 0.2602139150838129}
2023-01-05 16:02:47,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:47,976 INFO:     Epoch: 92
2023-01-05 16:02:50,128 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3736932953198751, 'Total loss': 0.3736932953198751} | train loss {'Reaction outcome loss': 0.2519110335433849, 'Total loss': 0.2519110335433849}
2023-01-05 16:02:50,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:50,129 INFO:     Epoch: 93
2023-01-05 16:02:52,267 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37815300226211546, 'Total loss': 0.37815300226211546} | train loss {'Reaction outcome loss': 0.2498545714953262, 'Total loss': 0.2498545714953262}
2023-01-05 16:02:52,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:52,267 INFO:     Epoch: 94
2023-01-05 16:02:54,414 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4129996915658315, 'Total loss': 0.4129996915658315} | train loss {'Reaction outcome loss': 0.25672095088752167, 'Total loss': 0.25672095088752167}
2023-01-05 16:02:54,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:54,414 INFO:     Epoch: 95
2023-01-05 16:02:56,574 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39746539990107216, 'Total loss': 0.39746539990107216} | train loss {'Reaction outcome loss': 0.25998706806330046, 'Total loss': 0.25998706806330046}
2023-01-05 16:02:56,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:56,575 INFO:     Epoch: 96
2023-01-05 16:02:58,726 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3870686759551366, 'Total loss': 0.3870686759551366} | train loss {'Reaction outcome loss': 0.25465926035754516, 'Total loss': 0.25465926035754516}
2023-01-05 16:02:58,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:02:58,727 INFO:     Epoch: 97
2023-01-05 16:03:00,893 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40295130213101704, 'Total loss': 0.40295130213101704} | train loss {'Reaction outcome loss': 0.25032768450973264, 'Total loss': 0.25032768450973264}
2023-01-05 16:03:00,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:03:00,894 INFO:     Epoch: 98
2023-01-05 16:03:03,058 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41468754708766936, 'Total loss': 0.41468754708766936} | train loss {'Reaction outcome loss': 0.2479842658010093, 'Total loss': 0.2479842658010093}
2023-01-05 16:03:03,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 16:03:03,058 INFO:     Epoch: 99
2023-01-05 16:03:05,232 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3673609221975009, 'Total loss': 0.3673609221975009} | train loss {'Reaction outcome loss': 0.2474274102948095, 'Total loss': 0.2474274102948095}
2023-01-05 16:03:05,232 INFO:     Best model found after epoch 79 of 100.
2023-01-05 16:03:05,233 INFO:   Done with stage: TRAINING
2023-01-05 16:03:05,233 INFO:   Starting stage: EVALUATION
2023-01-05 16:03:05,359 INFO:   Done with stage: EVALUATION
2023-01-05 16:03:05,359 INFO: Done with stage: RUNNING SPLITS
2023-01-05 16:03:05,359 INFO: Starting stage: COMPUTE METRICS
2023-01-05 16:03:06,556 INFO: Done with stage: COMPUTE METRICS
2023-01-05 16:03:06,557 INFO: Starting stage: EXPORT RESULTS
2023-01-05 16:03:06,575 INFO:   Final results averaged over 50 folds: 
2023-01-05 16:03:06,579 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.187839           NaN  0.348319       NaN
2023-01-05 16:03:08,213 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2023-01-05 16:03:08,219 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2023-01-05 16:03:08,220 DEBUG:   interactive is False
2023-01-05 16:03:08,221 DEBUG:   platform is linux
2023-01-05 16:03:08,221 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.naming', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2023-01-05 16:03:08,404 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2023-01-05 16:03:08,407 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2023-01-05 16:03:08,856 DEBUG:   Loaded backend agg version unknown.
2023-01-05 16:03:08,858 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-05 16:03:08,859 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,859 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,859 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,859 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 16:03:08,859 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 16:03:08,859 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 16:03:08,859 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,859 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,859 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,859 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,859 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 16:03:08,859 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 16:03:08,859 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,859 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,860 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,860 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 16:03:08,860 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,860 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 16:03:08,860 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,860 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,860 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-05 16:03:08,860 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 16:03:08,860 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 16:03:08,860 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,860 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,860 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,860 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,860 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,860 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,860 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,861 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,861 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,861 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-05 16:03:08,861 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,861 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,861 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,861 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,861 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 16:03:08,861 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 16:03:08,861 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,861 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,861 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,861 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 16:03:08,861 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,861 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-05 16:03:08,898 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2023-01-05 16:03:08,898 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 16:03:08,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 16:03:08,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 16:03:08,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 16:03:08,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 16:03:08,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 16:03:08,899 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 16:03:08,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-05 16:03:08,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 16:03:08,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 16:03:08,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-05 16:03:08,900 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,901 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,901 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,901 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,901 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 16:03:08,901 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 16:03:08,901 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,901 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,901 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,901 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 16:03:08,901 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,901 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-05 16:03:08,910 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-05 16:03:08,910 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,910 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,910 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,910 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 16:03:08,910 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 16:03:08,910 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 16:03:08,910 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,910 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,910 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,911 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,911 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 16:03:08,911 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 16:03:08,911 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,911 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,911 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,911 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 16:03:08,911 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,911 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 16:03:08,911 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,911 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,911 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-05 16:03:08,911 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 16:03:08,911 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 16:03:08,911 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,911 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,912 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,912 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,912 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,912 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,912 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,912 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,912 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,912 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-05 16:03:08,912 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,912 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,912 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,912 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,912 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 16:03:08,912 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 16:03:08,912 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,912 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,912 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 16:03:08,913 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 16:03:08,913 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 16:03:08,913 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-05 16:03:09,382 INFO: Done with stage: EXPORT RESULTS
2023-01-05 16:03:09,382 INFO: Starting stage: SAVE MODEL
2023-01-05 16:03:09,438 INFO: Done with stage: SAVE MODEL
2023-01-05 16:03:09,438 INFO: Wall time for program:  10773.59 seconds
