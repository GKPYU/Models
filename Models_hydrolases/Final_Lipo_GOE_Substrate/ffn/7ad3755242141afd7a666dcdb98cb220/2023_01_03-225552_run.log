2023-01-04 09:56:42,254 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/7ad3755242141afd7a666dcdb98cb220/2023_01_03-225552",
  "seed": 3,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.95,
  "val_size": 0.05,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 30,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2023-01-04 09:56:42,266 INFO: Starting stage: BUILD FEATURIZERS
2023-01-04 09:56:42,273 INFO:   Creating esm representation model
2023-01-04 09:56:42,273 INFO:   Done esm representation model
2023-01-04 09:56:42,273 INFO: Done with stage: BUILD FEATURIZERS
2023-01-04 09:56:42,273 INFO: Starting stage: BUILDING DATASET
2023-01-04 09:56:42,337 INFO: Done with stage: BUILDING DATASET
2023-01-04 09:56:42,337 INFO: Starting stage: FEATURIZING DATA
2023-01-04 09:56:42,337 INFO:   Featurizing proteins
2023-01-04 09:56:42,341 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2023-01-04 09:56:42,346 INFO:   Loaded feature cache of size 489
2023-01-04 09:56:42,347 INFO:   Starting to pool ESM Embeddings
2023-01-04 09:56:42,484 INFO:   Featurizing molecules
2023-01-04 09:56:42,488 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2023-01-04 09:56:42,491 INFO:   Loaded feature cache of size 498
2023-01-04 09:56:43,876 INFO: Done with stage: FEATURIZING DATA
2023-01-04 09:56:43,876 INFO: Starting stage: RUNNING SPLITS
2023-01-04 09:56:43,885 INFO:   Leaving out SEQ value Fold_0
2023-01-04 09:56:43,899 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 09:56:43,899 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:56:44,552 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:56:44,552 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:56:44,619 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:56:44,619 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:56:44,619 INFO:     No hyperparam tuning for this model
2023-01-04 09:56:44,619 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:56:44,619 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:56:44,620 INFO:     None feature selector for col prot
2023-01-04 09:56:44,620 INFO:     None feature selector for col prot
2023-01-04 09:56:44,620 INFO:     None feature selector for col prot
2023-01-04 09:56:44,621 INFO:     None feature selector for col chem
2023-01-04 09:56:44,621 INFO:     None feature selector for col chem
2023-01-04 09:56:44,621 INFO:     None feature selector for col chem
2023-01-04 09:56:44,621 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:56:44,621 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:56:44,622 INFO:     Number of params in model 70111
2023-01-04 09:56:44,622 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:56:44,622 INFO:   Starting stage: TRAINING
2023-01-04 09:56:46,229 INFO:     Val loss before train {'Reaction outcome loss': 1.0555115501085917, 'Total loss': 1.0555115501085917}
2023-01-04 09:56:46,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:46,230 INFO:     Epoch: 0
2023-01-04 09:56:47,773 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7843960642814636, 'Total loss': 0.7843960642814636} | train loss {'Reaction outcome loss': 0.8322098076125204, 'Total loss': 0.8322098076125204}
2023-01-04 09:56:47,773 INFO:     Found new best model at epoch 0
2023-01-04 09:56:47,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:47,774 INFO:     Epoch: 1
2023-01-04 09:56:49,340 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6425767819086711, 'Total loss': 0.6425767819086711} | train loss {'Reaction outcome loss': 0.6766804261303647, 'Total loss': 0.6766804261303647}
2023-01-04 09:56:49,341 INFO:     Found new best model at epoch 1
2023-01-04 09:56:49,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:49,341 INFO:     Epoch: 2
2023-01-04 09:56:50,896 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5838410119215648, 'Total loss': 0.5838410119215648} | train loss {'Reaction outcome loss': 0.5838875844801739, 'Total loss': 0.5838875844801739}
2023-01-04 09:56:50,896 INFO:     Found new best model at epoch 2
2023-01-04 09:56:50,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:50,897 INFO:     Epoch: 3
2023-01-04 09:56:52,421 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5662528097629547, 'Total loss': 0.5662528097629547} | train loss {'Reaction outcome loss': 0.5359557636164047, 'Total loss': 0.5359557636164047}
2023-01-04 09:56:52,421 INFO:     Found new best model at epoch 3
2023-01-04 09:56:52,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:52,422 INFO:     Epoch: 4
2023-01-04 09:56:53,997 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5290050049622853, 'Total loss': 0.5290050049622853} | train loss {'Reaction outcome loss': 0.5158089315279936, 'Total loss': 0.5158089315279936}
2023-01-04 09:56:53,997 INFO:     Found new best model at epoch 4
2023-01-04 09:56:53,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:53,998 INFO:     Epoch: 5
2023-01-04 09:56:55,539 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5052626013755799, 'Total loss': 0.5052626013755799} | train loss {'Reaction outcome loss': 0.5051812761541687, 'Total loss': 0.5051812761541687}
2023-01-04 09:56:55,539 INFO:     Found new best model at epoch 5
2023-01-04 09:56:55,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:55,540 INFO:     Epoch: 6
2023-01-04 09:56:57,114 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.510469384988149, 'Total loss': 0.510469384988149} | train loss {'Reaction outcome loss': 0.4956047639196172, 'Total loss': 0.4956047639196172}
2023-01-04 09:56:57,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:57,115 INFO:     Epoch: 7
2023-01-04 09:56:58,687 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49027071545521417, 'Total loss': 0.49027071545521417} | train loss {'Reaction outcome loss': 0.48185254420552937, 'Total loss': 0.48185254420552937}
2023-01-04 09:56:58,687 INFO:     Found new best model at epoch 7
2023-01-04 09:56:58,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:56:58,687 INFO:     Epoch: 8
2023-01-04 09:57:00,232 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49307489196459453, 'Total loss': 0.49307489196459453} | train loss {'Reaction outcome loss': 0.4789125867488183, 'Total loss': 0.4789125867488183}
2023-01-04 09:57:00,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:00,232 INFO:     Epoch: 9
2023-01-04 09:57:01,750 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5060756166776021, 'Total loss': 0.5060756166776021} | train loss {'Reaction outcome loss': 0.47112733049270433, 'Total loss': 0.47112733049270433}
2023-01-04 09:57:01,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:01,750 INFO:     Epoch: 10
2023-01-04 09:57:03,309 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48798877398173013, 'Total loss': 0.48798877398173013} | train loss {'Reaction outcome loss': 0.4635144040643514, 'Total loss': 0.4635144040643514}
2023-01-04 09:57:03,309 INFO:     Found new best model at epoch 10
2023-01-04 09:57:03,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:03,310 INFO:     Epoch: 11
2023-01-04 09:57:04,820 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4756267408529917, 'Total loss': 0.4756267408529917} | train loss {'Reaction outcome loss': 0.4629718025962075, 'Total loss': 0.4629718025962075}
2023-01-04 09:57:04,820 INFO:     Found new best model at epoch 11
2023-01-04 09:57:04,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:04,821 INFO:     Epoch: 12
2023-01-04 09:57:06,373 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4753444294134776, 'Total loss': 0.4753444294134776} | train loss {'Reaction outcome loss': 0.4534972438882122, 'Total loss': 0.4534972438882122}
2023-01-04 09:57:06,373 INFO:     Found new best model at epoch 12
2023-01-04 09:57:06,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:06,374 INFO:     Epoch: 13
2023-01-04 09:57:07,931 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4620683173338572, 'Total loss': 0.4620683173338572} | train loss {'Reaction outcome loss': 0.44941617182759575, 'Total loss': 0.44941617182759575}
2023-01-04 09:57:07,931 INFO:     Found new best model at epoch 13
2023-01-04 09:57:07,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:07,932 INFO:     Epoch: 14
2023-01-04 09:57:09,486 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4766224682331085, 'Total loss': 0.4766224682331085} | train loss {'Reaction outcome loss': 0.4477067455485627, 'Total loss': 0.4477067455485627}
2023-01-04 09:57:09,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:09,486 INFO:     Epoch: 15
2023-01-04 09:57:11,019 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46802519758542377, 'Total loss': 0.46802519758542377} | train loss {'Reaction outcome loss': 0.4424923292118988, 'Total loss': 0.4424923292118988}
2023-01-04 09:57:11,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:11,020 INFO:     Epoch: 16
2023-01-04 09:57:12,575 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4739530940850576, 'Total loss': 0.4739530940850576} | train loss {'Reaction outcome loss': 0.44111389077299246, 'Total loss': 0.44111389077299246}
2023-01-04 09:57:12,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:12,575 INFO:     Epoch: 17
2023-01-04 09:57:14,076 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4676218231519063, 'Total loss': 0.4676218231519063} | train loss {'Reaction outcome loss': 0.4285665375518275, 'Total loss': 0.4285665375518275}
2023-01-04 09:57:14,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:14,076 INFO:     Epoch: 18
2023-01-04 09:57:15,620 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44870632390181225, 'Total loss': 0.44870632390181225} | train loss {'Reaction outcome loss': 0.4250030815601349, 'Total loss': 0.4250030815601349}
2023-01-04 09:57:15,620 INFO:     Found new best model at epoch 18
2023-01-04 09:57:15,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:15,621 INFO:     Epoch: 19
2023-01-04 09:57:17,184 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45788556238015493, 'Total loss': 0.45788556238015493} | train loss {'Reaction outcome loss': 0.42076098149294383, 'Total loss': 0.42076098149294383}
2023-01-04 09:57:17,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:17,185 INFO:     Epoch: 20
2023-01-04 09:57:18,707 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47467794418334963, 'Total loss': 0.47467794418334963} | train loss {'Reaction outcome loss': 0.4181086178664323, 'Total loss': 0.4181086178664323}
2023-01-04 09:57:18,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:18,709 INFO:     Epoch: 21
2023-01-04 09:57:20,266 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.455238143603007, 'Total loss': 0.455238143603007} | train loss {'Reaction outcome loss': 0.4125418934575367, 'Total loss': 0.4125418934575367}
2023-01-04 09:57:20,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:20,267 INFO:     Epoch: 22
2023-01-04 09:57:21,826 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4449773460626602, 'Total loss': 0.4449773460626602} | train loss {'Reaction outcome loss': 0.4092078190638032, 'Total loss': 0.4092078190638032}
2023-01-04 09:57:21,826 INFO:     Found new best model at epoch 22
2023-01-04 09:57:21,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:21,827 INFO:     Epoch: 23
2023-01-04 09:57:23,345 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4412257442871729, 'Total loss': 0.4412257442871729} | train loss {'Reaction outcome loss': 0.4049289972681702, 'Total loss': 0.4049289972681702}
2023-01-04 09:57:23,345 INFO:     Found new best model at epoch 23
2023-01-04 09:57:23,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:23,346 INFO:     Epoch: 24
2023-01-04 09:57:24,873 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4412972549597422, 'Total loss': 0.4412972549597422} | train loss {'Reaction outcome loss': 0.4038015346933197, 'Total loss': 0.4038015346933197}
2023-01-04 09:57:24,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:24,874 INFO:     Epoch: 25
2023-01-04 09:57:26,425 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4639745275179545, 'Total loss': 0.4639745275179545} | train loss {'Reaction outcome loss': 0.39832445673453504, 'Total loss': 0.39832445673453504}
2023-01-04 09:57:26,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:26,425 INFO:     Epoch: 26
2023-01-04 09:57:27,880 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47678636610507963, 'Total loss': 0.47678636610507963} | train loss {'Reaction outcome loss': 0.39549733851200497, 'Total loss': 0.39549733851200497}
2023-01-04 09:57:27,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:27,881 INFO:     Epoch: 27
2023-01-04 09:57:28,900 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4516884028911591, 'Total loss': 0.4516884028911591} | train loss {'Reaction outcome loss': 0.38872052827379205, 'Total loss': 0.38872052827379205}
2023-01-04 09:57:28,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:28,900 INFO:     Epoch: 28
2023-01-04 09:57:29,914 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43060073256492615, 'Total loss': 0.43060073256492615} | train loss {'Reaction outcome loss': 0.3881508429353927, 'Total loss': 0.3881508429353927}
2023-01-04 09:57:29,914 INFO:     Found new best model at epoch 28
2023-01-04 09:57:29,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:29,915 INFO:     Epoch: 29
2023-01-04 09:57:30,931 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45563459595044453, 'Total loss': 0.45563459595044453} | train loss {'Reaction outcome loss': 0.3826714915397403, 'Total loss': 0.3826714915397403}
2023-01-04 09:57:30,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:30,932 INFO:     Epoch: 30
2023-01-04 09:57:31,983 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4374780555566152, 'Total loss': 0.4374780555566152} | train loss {'Reaction outcome loss': 0.3782882101751946, 'Total loss': 0.3782882101751946}
2023-01-04 09:57:31,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:31,983 INFO:     Epoch: 31
2023-01-04 09:57:33,527 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4309123694896698, 'Total loss': 0.4309123694896698} | train loss {'Reaction outcome loss': 0.37185595536624994, 'Total loss': 0.37185595536624994}
2023-01-04 09:57:33,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:33,527 INFO:     Epoch: 32
2023-01-04 09:57:35,072 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43531737128893533, 'Total loss': 0.43531737128893533} | train loss {'Reaction outcome loss': 0.3680278788910899, 'Total loss': 0.3680278788910899}
2023-01-04 09:57:35,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:35,072 INFO:     Epoch: 33
2023-01-04 09:57:36,623 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42779286702473956, 'Total loss': 0.42779286702473956} | train loss {'Reaction outcome loss': 0.3691661048121068, 'Total loss': 0.3691661048121068}
2023-01-04 09:57:36,623 INFO:     Found new best model at epoch 33
2023-01-04 09:57:36,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:36,624 INFO:     Epoch: 34
2023-01-04 09:57:38,146 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41441889107227325, 'Total loss': 0.41441889107227325} | train loss {'Reaction outcome loss': 0.36385134468366814, 'Total loss': 0.36385134468366814}
2023-01-04 09:57:38,146 INFO:     Found new best model at epoch 34
2023-01-04 09:57:38,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:38,147 INFO:     Epoch: 35
2023-01-04 09:57:39,700 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4373236149549484, 'Total loss': 0.4373236149549484} | train loss {'Reaction outcome loss': 0.36068558022925706, 'Total loss': 0.36068558022925706}
2023-01-04 09:57:39,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:39,701 INFO:     Epoch: 36
2023-01-04 09:57:41,228 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44290651579697926, 'Total loss': 0.44290651579697926} | train loss {'Reaction outcome loss': 0.3580674081358499, 'Total loss': 0.3580674081358499}
2023-01-04 09:57:41,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:41,229 INFO:     Epoch: 37
2023-01-04 09:57:42,800 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41169610917568206, 'Total loss': 0.41169610917568206} | train loss {'Reaction outcome loss': 0.3574938655390844, 'Total loss': 0.3574938655390844}
2023-01-04 09:57:42,801 INFO:     Found new best model at epoch 37
2023-01-04 09:57:42,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:42,801 INFO:     Epoch: 38
2023-01-04 09:57:44,382 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40705978572368623, 'Total loss': 0.40705978572368623} | train loss {'Reaction outcome loss': 0.35398572500481273, 'Total loss': 0.35398572500481273}
2023-01-04 09:57:44,382 INFO:     Found new best model at epoch 38
2023-01-04 09:57:44,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:44,383 INFO:     Epoch: 39
2023-01-04 09:57:45,979 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.411876184741656, 'Total loss': 0.411876184741656} | train loss {'Reaction outcome loss': 0.34994834710608475, 'Total loss': 0.34994834710608475}
2023-01-04 09:57:45,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:45,979 INFO:     Epoch: 40
2023-01-04 09:57:47,529 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43209089438120524, 'Total loss': 0.43209089438120524} | train loss {'Reaction outcome loss': 0.34769256715918634, 'Total loss': 0.34769256715918634}
2023-01-04 09:57:47,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:47,529 INFO:     Epoch: 41
2023-01-04 09:57:49,095 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44475882351398466, 'Total loss': 0.44475882351398466} | train loss {'Reaction outcome loss': 0.3455432426361811, 'Total loss': 0.3455432426361811}
2023-01-04 09:57:49,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:49,095 INFO:     Epoch: 42
2023-01-04 09:57:50,639 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43210858503977456, 'Total loss': 0.43210858503977456} | train loss {'Reaction outcome loss': 0.3418944295181896, 'Total loss': 0.3418944295181896}
2023-01-04 09:57:50,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:50,639 INFO:     Epoch: 43
2023-01-04 09:57:52,224 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43051382998625437, 'Total loss': 0.43051382998625437} | train loss {'Reaction outcome loss': 0.33989500868451467, 'Total loss': 0.33989500868451467}
2023-01-04 09:57:52,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:52,224 INFO:     Epoch: 44
2023-01-04 09:57:53,792 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40517994165420534, 'Total loss': 0.40517994165420534} | train loss {'Reaction outcome loss': 0.34148211023964725, 'Total loss': 0.34148211023964725}
2023-01-04 09:57:53,793 INFO:     Found new best model at epoch 44
2023-01-04 09:57:53,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:53,794 INFO:     Epoch: 45
2023-01-04 09:57:55,363 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45793456087509793, 'Total loss': 0.45793456087509793} | train loss {'Reaction outcome loss': 0.33685939142228044, 'Total loss': 0.33685939142228044}
2023-01-04 09:57:55,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:55,363 INFO:     Epoch: 46
2023-01-04 09:57:56,884 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4486167112986247, 'Total loss': 0.4486167112986247} | train loss {'Reaction outcome loss': 0.3327535486919976, 'Total loss': 0.3327535486919976}
2023-01-04 09:57:56,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:56,885 INFO:     Epoch: 47
2023-01-04 09:57:58,448 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4019301399588585, 'Total loss': 0.4019301399588585} | train loss {'Reaction outcome loss': 0.33051589925538055, 'Total loss': 0.33051589925538055}
2023-01-04 09:57:58,448 INFO:     Found new best model at epoch 47
2023-01-04 09:57:58,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:58,449 INFO:     Epoch: 48
2023-01-04 09:57:59,970 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40995084345340727, 'Total loss': 0.40995084345340727} | train loss {'Reaction outcome loss': 0.3281343740039256, 'Total loss': 0.3281343740039256}
2023-01-04 09:57:59,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:57:59,971 INFO:     Epoch: 49
2023-01-04 09:58:01,532 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4122270415226618, 'Total loss': 0.4122270415226618} | train loss {'Reaction outcome loss': 0.3324447976145552, 'Total loss': 0.3324447976145552}
2023-01-04 09:58:01,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:01,532 INFO:     Epoch: 50
2023-01-04 09:58:03,100 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4219447354475657, 'Total loss': 0.4219447354475657} | train loss {'Reaction outcome loss': 0.3243616774350732, 'Total loss': 0.3243616774350732}
2023-01-04 09:58:03,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:03,100 INFO:     Epoch: 51
2023-01-04 09:58:04,668 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42237944304943087, 'Total loss': 0.42237944304943087} | train loss {'Reaction outcome loss': 0.3230851427157283, 'Total loss': 0.3230851427157283}
2023-01-04 09:58:04,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:04,668 INFO:     Epoch: 52
2023-01-04 09:58:06,202 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40906789104143776, 'Total loss': 0.40906789104143776} | train loss {'Reaction outcome loss': 0.31973071216226934, 'Total loss': 0.31973071216226934}
2023-01-04 09:58:06,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:06,202 INFO:     Epoch: 53
2023-01-04 09:58:07,756 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4242239514986674, 'Total loss': 0.4242239514986674} | train loss {'Reaction outcome loss': 0.32397496151727634, 'Total loss': 0.32397496151727634}
2023-01-04 09:58:07,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:07,756 INFO:     Epoch: 54
2023-01-04 09:58:09,277 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42105623881022136, 'Total loss': 0.42105623881022136} | train loss {'Reaction outcome loss': 0.3162512937799478, 'Total loss': 0.3162512937799478}
2023-01-04 09:58:09,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:09,277 INFO:     Epoch: 55
2023-01-04 09:58:10,857 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4102581908305486, 'Total loss': 0.4102581908305486} | train loss {'Reaction outcome loss': 0.31672714757067816, 'Total loss': 0.31672714757067816}
2023-01-04 09:58:10,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:10,857 INFO:     Epoch: 56
2023-01-04 09:58:12,470 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44168175260225934, 'Total loss': 0.44168175260225934} | train loss {'Reaction outcome loss': 0.31883704572261035, 'Total loss': 0.31883704572261035}
2023-01-04 09:58:12,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:12,471 INFO:     Epoch: 57
2023-01-04 09:58:14,068 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42082611421744026, 'Total loss': 0.42082611421744026} | train loss {'Reaction outcome loss': 0.3150928951390497, 'Total loss': 0.3150928951390497}
2023-01-04 09:58:14,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:14,068 INFO:     Epoch: 58
2023-01-04 09:58:15,621 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4482097864151001, 'Total loss': 0.4482097864151001} | train loss {'Reaction outcome loss': 0.3150877841772177, 'Total loss': 0.3150877841772177}
2023-01-04 09:58:15,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:15,622 INFO:     Epoch: 59
2023-01-04 09:58:17,163 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4435606280962626, 'Total loss': 0.4435606280962626} | train loss {'Reaction outcome loss': 0.3069146703724023, 'Total loss': 0.3069146703724023}
2023-01-04 09:58:17,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:17,164 INFO:     Epoch: 60
2023-01-04 09:58:18,692 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4186094562212626, 'Total loss': 0.4186094562212626} | train loss {'Reaction outcome loss': 0.3067574481387715, 'Total loss': 0.3067574481387715}
2023-01-04 09:58:18,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:18,692 INFO:     Epoch: 61
2023-01-04 09:58:20,225 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40877217253049214, 'Total loss': 0.40877217253049214} | train loss {'Reaction outcome loss': 0.30862504172892796, 'Total loss': 0.30862504172892796}
2023-01-04 09:58:20,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:20,226 INFO:     Epoch: 62
2023-01-04 09:58:21,764 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.410171473522981, 'Total loss': 0.410171473522981} | train loss {'Reaction outcome loss': 0.30745217215010534, 'Total loss': 0.30745217215010534}
2023-01-04 09:58:21,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:21,765 INFO:     Epoch: 63
2023-01-04 09:58:23,292 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4639597773551941, 'Total loss': 0.4639597773551941} | train loss {'Reaction outcome loss': 0.2994097681381764, 'Total loss': 0.2994097681381764}
2023-01-04 09:58:23,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:23,292 INFO:     Epoch: 64
2023-01-04 09:58:24,837 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4089336474736532, 'Total loss': 0.4089336474736532} | train loss {'Reaction outcome loss': 0.3035616417016302, 'Total loss': 0.3035616417016302}
2023-01-04 09:58:24,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:24,839 INFO:     Epoch: 65
2023-01-04 09:58:26,375 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4241140842437744, 'Total loss': 0.4241140842437744} | train loss {'Reaction outcome loss': 0.29653389795577567, 'Total loss': 0.29653389795577567}
2023-01-04 09:58:26,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:26,375 INFO:     Epoch: 66
2023-01-04 09:58:27,916 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4255726079146067, 'Total loss': 0.4255726079146067} | train loss {'Reaction outcome loss': 0.3014166154540502, 'Total loss': 0.3014166154540502}
2023-01-04 09:58:27,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:27,916 INFO:     Epoch: 67
2023-01-04 09:58:29,467 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40593746105829875, 'Total loss': 0.40593746105829875} | train loss {'Reaction outcome loss': 0.294141197515713, 'Total loss': 0.294141197515713}
2023-01-04 09:58:29,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:29,467 INFO:     Epoch: 68
2023-01-04 09:58:31,008 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3957763989766439, 'Total loss': 0.3957763989766439} | train loss {'Reaction outcome loss': 0.2961754497318041, 'Total loss': 0.2961754497318041}
2023-01-04 09:58:31,009 INFO:     Found new best model at epoch 68
2023-01-04 09:58:31,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:31,010 INFO:     Epoch: 69
2023-01-04 09:58:32,531 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4133009061217308, 'Total loss': 0.4133009061217308} | train loss {'Reaction outcome loss': 0.30023979182754246, 'Total loss': 0.30023979182754246}
2023-01-04 09:58:32,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:32,531 INFO:     Epoch: 70
2023-01-04 09:58:34,079 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4029404789209366, 'Total loss': 0.4029404789209366} | train loss {'Reaction outcome loss': 0.29500843783765485, 'Total loss': 0.29500843783765485}
2023-01-04 09:58:34,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:34,079 INFO:     Epoch: 71
2023-01-04 09:58:35,619 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39439506630102794, 'Total loss': 0.39439506630102794} | train loss {'Reaction outcome loss': 0.29374067648058083, 'Total loss': 0.29374067648058083}
2023-01-04 09:58:35,619 INFO:     Found new best model at epoch 71
2023-01-04 09:58:35,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:35,620 INFO:     Epoch: 72
2023-01-04 09:58:37,166 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3933676689863205, 'Total loss': 0.3933676689863205} | train loss {'Reaction outcome loss': 0.2894935042976023, 'Total loss': 0.2894935042976023}
2023-01-04 09:58:37,167 INFO:     Found new best model at epoch 72
2023-01-04 09:58:37,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:37,168 INFO:     Epoch: 73
2023-01-04 09:58:38,710 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4218881885210673, 'Total loss': 0.4218881885210673} | train loss {'Reaction outcome loss': 0.2874552210172017, 'Total loss': 0.2874552210172017}
2023-01-04 09:58:38,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:38,711 INFO:     Epoch: 74
2023-01-04 09:58:40,255 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39684339066346486, 'Total loss': 0.39684339066346486} | train loss {'Reaction outcome loss': 0.29255172299159754, 'Total loss': 0.29255172299159754}
2023-01-04 09:58:40,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:40,256 INFO:     Epoch: 75
2023-01-04 09:58:41,767 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4086076964934667, 'Total loss': 0.4086076964934667} | train loss {'Reaction outcome loss': 0.29040439874479623, 'Total loss': 0.29040439874479623}
2023-01-04 09:58:41,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:41,767 INFO:     Epoch: 76
2023-01-04 09:58:43,318 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4161017427841822, 'Total loss': 0.4161017427841822} | train loss {'Reaction outcome loss': 0.29053021770912213, 'Total loss': 0.29053021770912213}
2023-01-04 09:58:43,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:43,319 INFO:     Epoch: 77
2023-01-04 09:58:44,835 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4015410507718722, 'Total loss': 0.4015410507718722} | train loss {'Reaction outcome loss': 0.28578191754090915, 'Total loss': 0.28578191754090915}
2023-01-04 09:58:44,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:44,835 INFO:     Epoch: 78
2023-01-04 09:58:46,386 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4180302997430166, 'Total loss': 0.4180302997430166} | train loss {'Reaction outcome loss': 0.2884111476741431, 'Total loss': 0.2884111476741431}
2023-01-04 09:58:46,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:46,386 INFO:     Epoch: 79
2023-01-04 09:58:47,962 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3885031849145889, 'Total loss': 0.3885031849145889} | train loss {'Reaction outcome loss': 0.2804001675366045, 'Total loss': 0.2804001675366045}
2023-01-04 09:58:47,962 INFO:     Found new best model at epoch 79
2023-01-04 09:58:47,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:47,963 INFO:     Epoch: 80
2023-01-04 09:58:49,513 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42321555912494657, 'Total loss': 0.42321555912494657} | train loss {'Reaction outcome loss': 0.2823555006376116, 'Total loss': 0.2823555006376116}
2023-01-04 09:58:49,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:49,513 INFO:     Epoch: 81
2023-01-04 09:58:51,050 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42633279860019685, 'Total loss': 0.42633279860019685} | train loss {'Reaction outcome loss': 0.28073066102525035, 'Total loss': 0.28073066102525035}
2023-01-04 09:58:51,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:51,051 INFO:     Epoch: 82
2023-01-04 09:58:52,612 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3832895706097285, 'Total loss': 0.3832895706097285} | train loss {'Reaction outcome loss': 0.2794692866203986, 'Total loss': 0.2794692866203986}
2023-01-04 09:58:52,612 INFO:     Found new best model at epoch 82
2023-01-04 09:58:52,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:52,613 INFO:     Epoch: 83
2023-01-04 09:58:54,128 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4297013332446416, 'Total loss': 0.4297013332446416} | train loss {'Reaction outcome loss': 0.27639122763068685, 'Total loss': 0.27639122763068685}
2023-01-04 09:58:54,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:54,128 INFO:     Epoch: 84
2023-01-04 09:58:55,640 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42113914887110393, 'Total loss': 0.42113914887110393} | train loss {'Reaction outcome loss': 0.2781579744466495, 'Total loss': 0.2781579744466495}
2023-01-04 09:58:55,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:55,641 INFO:     Epoch: 85
2023-01-04 09:58:57,179 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38029629389444985, 'Total loss': 0.38029629389444985} | train loss {'Reaction outcome loss': 0.2799336921573777, 'Total loss': 0.2799336921573777}
2023-01-04 09:58:57,179 INFO:     Found new best model at epoch 85
2023-01-04 09:58:57,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:57,180 INFO:     Epoch: 86
2023-01-04 09:58:58,737 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.422752712170283, 'Total loss': 0.422752712170283} | train loss {'Reaction outcome loss': 0.2753966196061491, 'Total loss': 0.2753966196061491}
2023-01-04 09:58:58,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:58:58,737 INFO:     Epoch: 87
2023-01-04 09:59:00,266 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38278071184953055, 'Total loss': 0.38278071184953055} | train loss {'Reaction outcome loss': 0.27035814681987624, 'Total loss': 0.27035814681987624}
2023-01-04 09:59:00,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:00,266 INFO:     Epoch: 88
2023-01-04 09:59:01,831 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4028319408496221, 'Total loss': 0.4028319408496221} | train loss {'Reaction outcome loss': 0.27476901820291094, 'Total loss': 0.27476901820291094}
2023-01-04 09:59:01,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:01,832 INFO:     Epoch: 89
2023-01-04 09:59:03,355 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4475532988707224, 'Total loss': 0.4475532988707224} | train loss {'Reaction outcome loss': 0.2724838642464889, 'Total loss': 0.2724838642464889}
2023-01-04 09:59:03,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:03,355 INFO:     Epoch: 90
2023-01-04 09:59:04,906 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4105117420355479, 'Total loss': 0.4105117420355479} | train loss {'Reaction outcome loss': 0.2767638632065647, 'Total loss': 0.2767638632065647}
2023-01-04 09:59:04,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:04,906 INFO:     Epoch: 91
2023-01-04 09:59:06,466 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38612563014030454, 'Total loss': 0.38612563014030454} | train loss {'Reaction outcome loss': 0.271952796502264, 'Total loss': 0.271952796502264}
2023-01-04 09:59:06,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:06,466 INFO:     Epoch: 92
2023-01-04 09:59:08,003 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4094914158185323, 'Total loss': 0.4094914158185323} | train loss {'Reaction outcome loss': 0.26933371060060496, 'Total loss': 0.26933371060060496}
2023-01-04 09:59:08,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:08,003 INFO:     Epoch: 93
2023-01-04 09:59:09,512 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4291130761305491, 'Total loss': 0.4291130761305491} | train loss {'Reaction outcome loss': 0.2679273750319149, 'Total loss': 0.2679273750319149}
2023-01-04 09:59:09,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:09,512 INFO:     Epoch: 94
2023-01-04 09:59:11,063 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40321767727533975, 'Total loss': 0.40321767727533975} | train loss {'Reaction outcome loss': 0.26330072002915234, 'Total loss': 0.26330072002915234}
2023-01-04 09:59:11,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:11,064 INFO:     Epoch: 95
2023-01-04 09:59:12,608 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4324215074380239, 'Total loss': 0.4324215074380239} | train loss {'Reaction outcome loss': 0.26684285424677007, 'Total loss': 0.26684285424677007}
2023-01-04 09:59:12,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:12,609 INFO:     Epoch: 96
2023-01-04 09:59:14,197 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4036529839038849, 'Total loss': 0.4036529839038849} | train loss {'Reaction outcome loss': 0.26333052295195314, 'Total loss': 0.26333052295195314}
2023-01-04 09:59:14,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:14,198 INFO:     Epoch: 97
2023-01-04 09:59:15,758 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43299688150485355, 'Total loss': 0.43299688150485355} | train loss {'Reaction outcome loss': 0.2595383813365912, 'Total loss': 0.2595383813365912}
2023-01-04 09:59:15,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:15,759 INFO:     Epoch: 98
2023-01-04 09:59:17,327 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41735618313153583, 'Total loss': 0.41735618313153583} | train loss {'Reaction outcome loss': 0.2669353991637736, 'Total loss': 0.2669353991637736}
2023-01-04 09:59:17,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:17,327 INFO:     Epoch: 99
2023-01-04 09:59:18,842 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40833126107851664, 'Total loss': 0.40833126107851664} | train loss {'Reaction outcome loss': 0.26506130880379414, 'Total loss': 0.26506130880379414}
2023-01-04 09:59:18,842 INFO:     Best model found after epoch 86 of 100.
2023-01-04 09:59:18,842 INFO:   Done with stage: TRAINING
2023-01-04 09:59:18,842 INFO:   Starting stage: EVALUATION
2023-01-04 09:59:18,983 INFO:   Done with stage: EVALUATION
2023-01-04 09:59:18,983 INFO:   Leaving out SEQ value Fold_1
2023-01-04 09:59:18,996 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 09:59:18,996 INFO:   Starting stage: FEATURE SCALING
2023-01-04 09:59:19,655 INFO:   Done with stage: FEATURE SCALING
2023-01-04 09:59:19,655 INFO:   Starting stage: SCALING TARGETS
2023-01-04 09:59:19,723 INFO:   Done with stage: SCALING TARGETS
2023-01-04 09:59:19,723 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:59:19,723 INFO:     No hyperparam tuning for this model
2023-01-04 09:59:19,723 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 09:59:19,723 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 09:59:19,724 INFO:     None feature selector for col prot
2023-01-04 09:59:19,724 INFO:     None feature selector for col prot
2023-01-04 09:59:19,724 INFO:     None feature selector for col prot
2023-01-04 09:59:19,725 INFO:     None feature selector for col chem
2023-01-04 09:59:19,725 INFO:     None feature selector for col chem
2023-01-04 09:59:19,725 INFO:     None feature selector for col chem
2023-01-04 09:59:19,725 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 09:59:19,725 INFO:   Starting stage: BUILD MODEL
2023-01-04 09:59:19,726 INFO:     Number of params in model 70111
2023-01-04 09:59:19,729 INFO:   Done with stage: BUILD MODEL
2023-01-04 09:59:19,729 INFO:   Starting stage: TRAINING
2023-01-04 09:59:19,773 INFO:     Val loss before train {'Reaction outcome loss': 1.1395809531211853, 'Total loss': 1.1395809531211853}
2023-01-04 09:59:19,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:19,773 INFO:     Epoch: 0
2023-01-04 09:59:21,313 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7747049768765767, 'Total loss': 0.7747049768765767} | train loss {'Reaction outcome loss': 0.847703346091768, 'Total loss': 0.847703346091768}
2023-01-04 09:59:21,313 INFO:     Found new best model at epoch 0
2023-01-04 09:59:21,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:21,314 INFO:     Epoch: 1
2023-01-04 09:59:22,880 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6316996375719707, 'Total loss': 0.6316996375719707} | train loss {'Reaction outcome loss': 0.6530265694727069, 'Total loss': 0.6530265694727069}
2023-01-04 09:59:22,880 INFO:     Found new best model at epoch 1
2023-01-04 09:59:22,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:22,881 INFO:     Epoch: 2
2023-01-04 09:59:24,443 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6095422983169556, 'Total loss': 0.6095422983169556} | train loss {'Reaction outcome loss': 0.57167005430961, 'Total loss': 0.57167005430961}
2023-01-04 09:59:24,443 INFO:     Found new best model at epoch 2
2023-01-04 09:59:24,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:24,444 INFO:     Epoch: 3
2023-01-04 09:59:26,018 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5881623069445292, 'Total loss': 0.5881623069445292} | train loss {'Reaction outcome loss': 0.5347533994438667, 'Total loss': 0.5347533994438667}
2023-01-04 09:59:26,020 INFO:     Found new best model at epoch 3
2023-01-04 09:59:26,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:26,020 INFO:     Epoch: 4
2023-01-04 09:59:27,566 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5576993564764658, 'Total loss': 0.5576993564764658} | train loss {'Reaction outcome loss': 0.5118605310529254, 'Total loss': 0.5118605310529254}
2023-01-04 09:59:27,566 INFO:     Found new best model at epoch 4
2023-01-04 09:59:27,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:27,567 INFO:     Epoch: 5
2023-01-04 09:59:29,146 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5406995296478272, 'Total loss': 0.5406995296478272} | train loss {'Reaction outcome loss': 0.5123012925943603, 'Total loss': 0.5123012925943603}
2023-01-04 09:59:29,146 INFO:     Found new best model at epoch 5
2023-01-04 09:59:29,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:29,147 INFO:     Epoch: 6
2023-01-04 09:59:30,674 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5477935900290807, 'Total loss': 0.5477935900290807} | train loss {'Reaction outcome loss': 0.5315792314924191, 'Total loss': 0.5315792314924191}
2023-01-04 09:59:30,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:30,675 INFO:     Epoch: 7
2023-01-04 09:59:32,234 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5247224668661753, 'Total loss': 0.5247224668661753} | train loss {'Reaction outcome loss': 0.5000102012705031, 'Total loss': 0.5000102012705031}
2023-01-04 09:59:32,235 INFO:     Found new best model at epoch 7
2023-01-04 09:59:32,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:32,236 INFO:     Epoch: 8
2023-01-04 09:59:33,827 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5159346501032511, 'Total loss': 0.5159346501032511} | train loss {'Reaction outcome loss': 0.4731906515986747, 'Total loss': 0.4731906515986747}
2023-01-04 09:59:33,827 INFO:     Found new best model at epoch 8
2023-01-04 09:59:33,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:33,828 INFO:     Epoch: 9
2023-01-04 09:59:35,393 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5003078753749529, 'Total loss': 0.5003078753749529} | train loss {'Reaction outcome loss': 0.4652605803710395, 'Total loss': 0.4652605803710395}
2023-01-04 09:59:35,393 INFO:     Found new best model at epoch 9
2023-01-04 09:59:35,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:35,394 INFO:     Epoch: 10
2023-01-04 09:59:36,949 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5212488353252411, 'Total loss': 0.5212488353252411} | train loss {'Reaction outcome loss': 0.468635072418745, 'Total loss': 0.468635072418745}
2023-01-04 09:59:36,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:36,949 INFO:     Epoch: 11
2023-01-04 09:59:38,511 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5260542372862498, 'Total loss': 0.5260542372862498} | train loss {'Reaction outcome loss': 0.467498657239628, 'Total loss': 0.467498657239628}
2023-01-04 09:59:38,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:38,511 INFO:     Epoch: 12
2023-01-04 09:59:40,051 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5066225339968999, 'Total loss': 0.5066225339968999} | train loss {'Reaction outcome loss': 0.45859921843662776, 'Total loss': 0.45859921843662776}
2023-01-04 09:59:40,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:40,051 INFO:     Epoch: 13
2023-01-04 09:59:41,635 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5208283523718517, 'Total loss': 0.5208283523718517} | train loss {'Reaction outcome loss': 0.4499727964042034, 'Total loss': 0.4499727964042034}
2023-01-04 09:59:41,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:41,635 INFO:     Epoch: 14
2023-01-04 09:59:43,224 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5292239268620809, 'Total loss': 0.5292239268620809} | train loss {'Reaction outcome loss': 0.45658972411268, 'Total loss': 0.45658972411268}
2023-01-04 09:59:43,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:43,224 INFO:     Epoch: 15
2023-01-04 09:59:44,763 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5130940278371176, 'Total loss': 0.5130940278371176} | train loss {'Reaction outcome loss': 0.45166200678795576, 'Total loss': 0.45166200678795576}
2023-01-04 09:59:44,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:44,764 INFO:     Epoch: 16
2023-01-04 09:59:46,333 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4731470127900442, 'Total loss': 0.4731470127900442} | train loss {'Reaction outcome loss': 0.4407926342834759, 'Total loss': 0.4407926342834759}
2023-01-04 09:59:46,333 INFO:     Found new best model at epoch 16
2023-01-04 09:59:46,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:46,334 INFO:     Epoch: 17
2023-01-04 09:59:47,876 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5020956059296926, 'Total loss': 0.5020956059296926} | train loss {'Reaction outcome loss': 0.4338315081499193, 'Total loss': 0.4338315081499193}
2023-01-04 09:59:47,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:47,876 INFO:     Epoch: 18
2023-01-04 09:59:49,443 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5070803542931874, 'Total loss': 0.5070803542931874} | train loss {'Reaction outcome loss': 0.42883957481767604, 'Total loss': 0.42883957481767604}
2023-01-04 09:59:49,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:49,443 INFO:     Epoch: 19
2023-01-04 09:59:51,017 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5035856366157532, 'Total loss': 0.5035856366157532} | train loss {'Reaction outcome loss': 0.4267202283882543, 'Total loss': 0.4267202283882543}
2023-01-04 09:59:51,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:51,017 INFO:     Epoch: 20
2023-01-04 09:59:52,594 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4917325923840205, 'Total loss': 0.4917325923840205} | train loss {'Reaction outcome loss': 0.4254729438411153, 'Total loss': 0.4254729438411153}
2023-01-04 09:59:52,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:52,595 INFO:     Epoch: 21
2023-01-04 09:59:54,140 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.479290509223938, 'Total loss': 0.479290509223938} | train loss {'Reaction outcome loss': 0.42609081613709743, 'Total loss': 0.42609081613709743}
2023-01-04 09:59:54,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:54,141 INFO:     Epoch: 22
2023-01-04 09:59:55,722 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5025180101394653, 'Total loss': 0.5025180101394653} | train loss {'Reaction outcome loss': 0.41497906453509315, 'Total loss': 0.41497906453509315}
2023-01-04 09:59:55,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:55,722 INFO:     Epoch: 23
2023-01-04 09:59:57,252 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4908276230096817, 'Total loss': 0.4908276230096817} | train loss {'Reaction outcome loss': 0.4124863613768062, 'Total loss': 0.4124863613768062}
2023-01-04 09:59:57,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:57,254 INFO:     Epoch: 24
2023-01-04 09:59:58,825 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4746349920829137, 'Total loss': 0.4746349920829137} | train loss {'Reaction outcome loss': 0.40994854395082087, 'Total loss': 0.40994854395082087}
2023-01-04 09:59:58,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 09:59:58,825 INFO:     Epoch: 25
2023-01-04 10:00:00,409 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48538411458333336, 'Total loss': 0.48538411458333336} | train loss {'Reaction outcome loss': 0.4092811284235854, 'Total loss': 0.4092811284235854}
2023-01-04 10:00:00,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:00,409 INFO:     Epoch: 26
2023-01-04 10:00:01,970 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4674558699131012, 'Total loss': 0.4674558699131012} | train loss {'Reaction outcome loss': 0.4124611514094083, 'Total loss': 0.4124611514094083}
2023-01-04 10:00:01,970 INFO:     Found new best model at epoch 26
2023-01-04 10:00:01,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:01,971 INFO:     Epoch: 27
2023-01-04 10:00:03,504 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5018480201562245, 'Total loss': 0.5018480201562245} | train loss {'Reaction outcome loss': 0.4073338631162609, 'Total loss': 0.4073338631162609}
2023-01-04 10:00:03,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:03,505 INFO:     Epoch: 28
2023-01-04 10:00:05,117 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47076233526070915, 'Total loss': 0.47076233526070915} | train loss {'Reaction outcome loss': 0.4081092458218336, 'Total loss': 0.4081092458218336}
2023-01-04 10:00:05,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:05,118 INFO:     Epoch: 29
2023-01-04 10:00:06,665 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4662143995364507, 'Total loss': 0.4662143995364507} | train loss {'Reaction outcome loss': 0.3941830750272198, 'Total loss': 0.3941830750272198}
2023-01-04 10:00:06,666 INFO:     Found new best model at epoch 29
2023-01-04 10:00:06,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:06,666 INFO:     Epoch: 30
2023-01-04 10:00:08,269 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5102433204650879, 'Total loss': 0.5102433204650879} | train loss {'Reaction outcome loss': 0.3927063276262387, 'Total loss': 0.3927063276262387}
2023-01-04 10:00:08,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:08,270 INFO:     Epoch: 31
2023-01-04 10:00:09,858 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46934944291909536, 'Total loss': 0.46934944291909536} | train loss {'Reaction outcome loss': 0.41645856387913227, 'Total loss': 0.41645856387913227}
2023-01-04 10:00:09,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:09,858 INFO:     Epoch: 32
2023-01-04 10:00:11,437 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4795128067334493, 'Total loss': 0.4795128067334493} | train loss {'Reaction outcome loss': 0.38235167757586064, 'Total loss': 0.38235167757586064}
2023-01-04 10:00:11,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:11,437 INFO:     Epoch: 33
2023-01-04 10:00:12,981 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4539806544780731, 'Total loss': 0.4539806544780731} | train loss {'Reaction outcome loss': 0.3821682687578858, 'Total loss': 0.3821682687578858}
2023-01-04 10:00:12,981 INFO:     Found new best model at epoch 33
2023-01-04 10:00:12,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:12,982 INFO:     Epoch: 34
2023-01-04 10:00:14,553 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4665346026420593, 'Total loss': 0.4665346026420593} | train loss {'Reaction outcome loss': 0.39060619190011336, 'Total loss': 0.39060619190011336}
2023-01-04 10:00:14,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:14,553 INFO:     Epoch: 35
2023-01-04 10:00:16,113 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47685051957766217, 'Total loss': 0.47685051957766217} | train loss {'Reaction outcome loss': 0.38107541279353335, 'Total loss': 0.38107541279353335}
2023-01-04 10:00:16,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:16,114 INFO:     Epoch: 36
2023-01-04 10:00:17,704 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48018389542897544, 'Total loss': 0.48018389542897544} | train loss {'Reaction outcome loss': 0.3699385949041006, 'Total loss': 0.3699385949041006}
2023-01-04 10:00:17,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:17,705 INFO:     Epoch: 37
2023-01-04 10:00:19,301 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4794443557659785, 'Total loss': 0.4794443557659785} | train loss {'Reaction outcome loss': 0.36579382122980186, 'Total loss': 0.36579382122980186}
2023-01-04 10:00:19,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:19,301 INFO:     Epoch: 38
2023-01-04 10:00:20,872 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4753778795401255, 'Total loss': 0.4753778795401255} | train loss {'Reaction outcome loss': 0.37015133287649654, 'Total loss': 0.37015133287649654}
2023-01-04 10:00:20,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:20,873 INFO:     Epoch: 39
2023-01-04 10:00:22,453 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4619822641213735, 'Total loss': 0.4619822641213735} | train loss {'Reaction outcome loss': 0.3619312382627117, 'Total loss': 0.3619312382627117}
2023-01-04 10:00:22,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:22,453 INFO:     Epoch: 40
2023-01-04 10:00:24,015 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5147807826598485, 'Total loss': 0.5147807826598485} | train loss {'Reaction outcome loss': 0.3581697626066381, 'Total loss': 0.3581697626066381}
2023-01-04 10:00:24,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:24,015 INFO:     Epoch: 41
2023-01-04 10:00:25,575 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4727116117874781, 'Total loss': 0.4727116117874781} | train loss {'Reaction outcome loss': 0.3611633505510247, 'Total loss': 0.3611633505510247}
2023-01-04 10:00:25,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:25,575 INFO:     Epoch: 42
2023-01-04 10:00:27,184 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48797118465105693, 'Total loss': 0.48797118465105693} | train loss {'Reaction outcome loss': 0.352671497412856, 'Total loss': 0.352671497412856}
2023-01-04 10:00:27,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:27,184 INFO:     Epoch: 43
2023-01-04 10:00:28,802 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4754156192143758, 'Total loss': 0.4754156192143758} | train loss {'Reaction outcome loss': 0.349774025839524, 'Total loss': 0.349774025839524}
2023-01-04 10:00:28,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:28,803 INFO:     Epoch: 44
2023-01-04 10:00:30,380 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45223839581012726, 'Total loss': 0.45223839581012726} | train loss {'Reaction outcome loss': 0.3523569053728167, 'Total loss': 0.3523569053728167}
2023-01-04 10:00:30,380 INFO:     Found new best model at epoch 44
2023-01-04 10:00:30,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:30,381 INFO:     Epoch: 45
2023-01-04 10:00:31,972 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46857769091924034, 'Total loss': 0.46857769091924034} | train loss {'Reaction outcome loss': 0.3441238562201919, 'Total loss': 0.3441238562201919}
2023-01-04 10:00:31,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:31,972 INFO:     Epoch: 46
2023-01-04 10:00:33,539 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4567217687765757, 'Total loss': 0.4567217687765757} | train loss {'Reaction outcome loss': 0.34241462490973534, 'Total loss': 0.34241462490973534}
2023-01-04 10:00:33,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:33,540 INFO:     Epoch: 47
2023-01-04 10:00:35,157 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4757611811161041, 'Total loss': 0.4757611811161041} | train loss {'Reaction outcome loss': 0.34390072942967864, 'Total loss': 0.34390072942967864}
2023-01-04 10:00:35,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:35,157 INFO:     Epoch: 48
2023-01-04 10:00:36,771 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.470378307501475, 'Total loss': 0.470378307501475} | train loss {'Reaction outcome loss': 0.3466451050632674, 'Total loss': 0.3466451050632674}
2023-01-04 10:00:36,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:36,771 INFO:     Epoch: 49
2023-01-04 10:00:38,398 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4652602394421895, 'Total loss': 0.4652602394421895} | train loss {'Reaction outcome loss': 0.34486015287457383, 'Total loss': 0.34486015287457383}
2023-01-04 10:00:38,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:38,398 INFO:     Epoch: 50
2023-01-04 10:00:39,968 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46048081119855244, 'Total loss': 0.46048081119855244} | train loss {'Reaction outcome loss': 0.3316149627384932, 'Total loss': 0.3316149627384932}
2023-01-04 10:00:39,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:39,969 INFO:     Epoch: 51
2023-01-04 10:00:41,579 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48395755092302956, 'Total loss': 0.48395755092302956} | train loss {'Reaction outcome loss': 0.3277658714197468, 'Total loss': 0.3277658714197468}
2023-01-04 10:00:41,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:41,579 INFO:     Epoch: 52
2023-01-04 10:00:43,135 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4811674853165944, 'Total loss': 0.4811674853165944} | train loss {'Reaction outcome loss': 0.3301379092685554, 'Total loss': 0.3301379092685554}
2023-01-04 10:00:43,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:43,135 INFO:     Epoch: 53
2023-01-04 10:00:44,669 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46361926992734276, 'Total loss': 0.46361926992734276} | train loss {'Reaction outcome loss': 0.32652889053080825, 'Total loss': 0.32652889053080825}
2023-01-04 10:00:44,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:44,670 INFO:     Epoch: 54
2023-01-04 10:00:46,216 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48297332127889, 'Total loss': 0.48297332127889} | train loss {'Reaction outcome loss': 0.33974101324228273, 'Total loss': 0.33974101324228273}
2023-01-04 10:00:46,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:46,217 INFO:     Epoch: 55
2023-01-04 10:00:47,774 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4842571228742599, 'Total loss': 0.4842571228742599} | train loss {'Reaction outcome loss': 0.3829746198556993, 'Total loss': 0.3829746198556993}
2023-01-04 10:00:47,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:47,774 INFO:     Epoch: 56
2023-01-04 10:00:49,301 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4559317429860433, 'Total loss': 0.4559317429860433} | train loss {'Reaction outcome loss': 0.3240725016997111, 'Total loss': 0.3240725016997111}
2023-01-04 10:00:49,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:49,302 INFO:     Epoch: 57
2023-01-04 10:00:50,932 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48521066705385846, 'Total loss': 0.48521066705385846} | train loss {'Reaction outcome loss': 0.3172828222935398, 'Total loss': 0.3172828222935398}
2023-01-04 10:00:50,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:50,932 INFO:     Epoch: 58
2023-01-04 10:00:52,505 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44343843311071396, 'Total loss': 0.44343843311071396} | train loss {'Reaction outcome loss': 0.31603671515873377, 'Total loss': 0.31603671515873377}
2023-01-04 10:00:52,506 INFO:     Found new best model at epoch 58
2023-01-04 10:00:52,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:52,507 INFO:     Epoch: 59
2023-01-04 10:00:54,124 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4640604019165039, 'Total loss': 0.4640604019165039} | train loss {'Reaction outcome loss': 0.3196565328246873, 'Total loss': 0.3196565328246873}
2023-01-04 10:00:54,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:54,125 INFO:     Epoch: 60
2023-01-04 10:00:55,736 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45683388511339823, 'Total loss': 0.45683388511339823} | train loss {'Reaction outcome loss': 0.3526754884953624, 'Total loss': 0.3526754884953624}
2023-01-04 10:00:55,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:55,736 INFO:     Epoch: 61
2023-01-04 10:00:57,355 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46790840923786164, 'Total loss': 0.46790840923786164} | train loss {'Reaction outcome loss': 0.32690973861987743, 'Total loss': 0.32690973861987743}
2023-01-04 10:00:57,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:57,355 INFO:     Epoch: 62
2023-01-04 10:00:58,948 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4770429829756419, 'Total loss': 0.4770429829756419} | train loss {'Reaction outcome loss': 0.3170675653964281, 'Total loss': 0.3170675653964281}
2023-01-04 10:00:58,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:00:58,948 INFO:     Epoch: 63
2023-01-04 10:01:00,571 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47309347887833914, 'Total loss': 0.47309347887833914} | train loss {'Reaction outcome loss': 0.324501188686185, 'Total loss': 0.324501188686185}
2023-01-04 10:01:00,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:00,571 INFO:     Epoch: 64
2023-01-04 10:01:02,157 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45531961719195047, 'Total loss': 0.45531961719195047} | train loss {'Reaction outcome loss': 0.3112124898943348, 'Total loss': 0.3112124898943348}
2023-01-04 10:01:02,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:02,157 INFO:     Epoch: 65
2023-01-04 10:01:03,786 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4456367164850235, 'Total loss': 0.4456367164850235} | train loss {'Reaction outcome loss': 0.3111865354560154, 'Total loss': 0.3111865354560154}
2023-01-04 10:01:03,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:03,786 INFO:     Epoch: 66
2023-01-04 10:01:05,402 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47323691050211586, 'Total loss': 0.47323691050211586} | train loss {'Reaction outcome loss': 0.30569194226215285, 'Total loss': 0.30569194226215285}
2023-01-04 10:01:05,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:05,402 INFO:     Epoch: 67
2023-01-04 10:01:06,973 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.456434828042984, 'Total loss': 0.456434828042984} | train loss {'Reaction outcome loss': 0.31194597505626903, 'Total loss': 0.31194597505626903}
2023-01-04 10:01:06,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:06,973 INFO:     Epoch: 68
2023-01-04 10:01:08,602 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46690400640169777, 'Total loss': 0.46690400640169777} | train loss {'Reaction outcome loss': 0.3019130913527224, 'Total loss': 0.3019130913527224}
2023-01-04 10:01:08,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:08,603 INFO:     Epoch: 69
2023-01-04 10:01:10,178 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46022894779841106, 'Total loss': 0.46022894779841106} | train loss {'Reaction outcome loss': 0.3020396411749602, 'Total loss': 0.3020396411749602}
2023-01-04 10:01:10,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:10,178 INFO:     Epoch: 70
2023-01-04 10:01:11,789 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45952763557434084, 'Total loss': 0.45952763557434084} | train loss {'Reaction outcome loss': 0.3038899238859101, 'Total loss': 0.3038899238859101}
2023-01-04 10:01:11,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:11,789 INFO:     Epoch: 71
2023-01-04 10:01:13,420 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47482727964719135, 'Total loss': 0.47482727964719135} | train loss {'Reaction outcome loss': 0.298110470921476, 'Total loss': 0.298110470921476}
2023-01-04 10:01:13,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:13,421 INFO:     Epoch: 72
2023-01-04 10:01:15,047 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4630326390266418, 'Total loss': 0.4630326390266418} | train loss {'Reaction outcome loss': 0.2964222463036793, 'Total loss': 0.2964222463036793}
2023-01-04 10:01:15,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:15,048 INFO:     Epoch: 73
2023-01-04 10:01:16,627 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46036670804023744, 'Total loss': 0.46036670804023744} | train loss {'Reaction outcome loss': 0.3039446800888806, 'Total loss': 0.3039446800888806}
2023-01-04 10:01:16,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:16,627 INFO:     Epoch: 74
2023-01-04 10:01:18,255 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43392060274879135, 'Total loss': 0.43392060274879135} | train loss {'Reaction outcome loss': 0.2989295072705094, 'Total loss': 0.2989295072705094}
2023-01-04 10:01:18,255 INFO:     Found new best model at epoch 74
2023-01-04 10:01:18,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:18,257 INFO:     Epoch: 75
2023-01-04 10:01:19,842 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4653244157632192, 'Total loss': 0.4653244157632192} | train loss {'Reaction outcome loss': 0.2957941563892772, 'Total loss': 0.2957941563892772}
2023-01-04 10:01:19,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:19,843 INFO:     Epoch: 76
2023-01-04 10:01:21,470 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45782797237237294, 'Total loss': 0.45782797237237294} | train loss {'Reaction outcome loss': 0.2889612041838953, 'Total loss': 0.2889612041838953}
2023-01-04 10:01:21,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:21,471 INFO:     Epoch: 77
2023-01-04 10:01:23,100 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4487667183081309, 'Total loss': 0.4487667183081309} | train loss {'Reaction outcome loss': 0.2922958141307522, 'Total loss': 0.2922958141307522}
2023-01-04 10:01:23,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:23,101 INFO:     Epoch: 78
2023-01-04 10:01:24,679 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45470185577869415, 'Total loss': 0.45470185577869415} | train loss {'Reaction outcome loss': 0.29031424326957134, 'Total loss': 0.29031424326957134}
2023-01-04 10:01:24,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:24,679 INFO:     Epoch: 79
2023-01-04 10:01:26,249 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44863371054331463, 'Total loss': 0.44863371054331463} | train loss {'Reaction outcome loss': 0.307333520937549, 'Total loss': 0.307333520937549}
2023-01-04 10:01:26,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:26,249 INFO:     Epoch: 80
2023-01-04 10:01:27,823 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4544372061888377, 'Total loss': 0.4544372061888377} | train loss {'Reaction outcome loss': 0.29738029319391435, 'Total loss': 0.29738029319391435}
2023-01-04 10:01:27,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:27,824 INFO:     Epoch: 81
2023-01-04 10:01:29,385 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44963054060935975, 'Total loss': 0.44963054060935975} | train loss {'Reaction outcome loss': 0.2948737724657184, 'Total loss': 0.2948737724657184}
2023-01-04 10:01:29,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:29,385 INFO:     Epoch: 82
2023-01-04 10:01:30,968 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4678485850493113, 'Total loss': 0.4678485850493113} | train loss {'Reaction outcome loss': 0.2958340856079619, 'Total loss': 0.2958340856079619}
2023-01-04 10:01:30,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:30,968 INFO:     Epoch: 83
2023-01-04 10:01:32,543 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4471033970514933, 'Total loss': 0.4471033970514933} | train loss {'Reaction outcome loss': 0.29769368534502777, 'Total loss': 0.29769368534502777}
2023-01-04 10:01:32,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:32,543 INFO:     Epoch: 84
2023-01-04 10:01:34,084 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4376765042543411, 'Total loss': 0.4376765042543411} | train loss {'Reaction outcome loss': 0.3235536373808366, 'Total loss': 0.3235536373808366}
2023-01-04 10:01:34,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:34,084 INFO:     Epoch: 85
2023-01-04 10:01:35,672 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4360056002934774, 'Total loss': 0.4360056002934774} | train loss {'Reaction outcome loss': 0.2890372471797998, 'Total loss': 0.2890372471797998}
2023-01-04 10:01:35,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:35,672 INFO:     Epoch: 86
2023-01-04 10:01:37,248 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44725451469421384, 'Total loss': 0.44725451469421384} | train loss {'Reaction outcome loss': 0.28608350737857213, 'Total loss': 0.28608350737857213}
2023-01-04 10:01:37,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:37,248 INFO:     Epoch: 87
2023-01-04 10:01:38,836 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47298867801825206, 'Total loss': 0.47298867801825206} | train loss {'Reaction outcome loss': 0.3003261582520993, 'Total loss': 0.3003261582520993}
2023-01-04 10:01:38,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:38,837 INFO:     Epoch: 88
2023-01-04 10:01:40,429 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4571476976076762, 'Total loss': 0.4571476976076762} | train loss {'Reaction outcome loss': 0.28383247221084446, 'Total loss': 0.28383247221084446}
2023-01-04 10:01:40,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:40,429 INFO:     Epoch: 89
2023-01-04 10:01:42,045 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46898608406384784, 'Total loss': 0.46898608406384784} | train loss {'Reaction outcome loss': 0.2780327695502859, 'Total loss': 0.2780327695502859}
2023-01-04 10:01:42,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:42,046 INFO:     Epoch: 90
2023-01-04 10:01:43,599 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45328162908554076, 'Total loss': 0.45328162908554076} | train loss {'Reaction outcome loss': 0.2789119938345826, 'Total loss': 0.2789119938345826}
2023-01-04 10:01:43,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:43,600 INFO:     Epoch: 91
2023-01-04 10:01:45,210 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46375539104143776, 'Total loss': 0.46375539104143776} | train loss {'Reaction outcome loss': 0.28144248945270944, 'Total loss': 0.28144248945270944}
2023-01-04 10:01:45,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:45,212 INFO:     Epoch: 92
2023-01-04 10:01:46,788 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46484908858935037, 'Total loss': 0.46484908858935037} | train loss {'Reaction outcome loss': 0.27137237231152644, 'Total loss': 0.27137237231152644}
2023-01-04 10:01:46,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:46,788 INFO:     Epoch: 93
2023-01-04 10:01:48,400 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4482342710097631, 'Total loss': 0.4482342710097631} | train loss {'Reaction outcome loss': 0.2752419937633153, 'Total loss': 0.2752419937633153}
2023-01-04 10:01:48,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:48,400 INFO:     Epoch: 94
2023-01-04 10:01:50,012 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46980199913183845, 'Total loss': 0.46980199913183845} | train loss {'Reaction outcome loss': 0.27910885783216066, 'Total loss': 0.27910885783216066}
2023-01-04 10:01:50,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:50,013 INFO:     Epoch: 95
2023-01-04 10:01:51,586 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4384709646304448, 'Total loss': 0.4384709646304448} | train loss {'Reaction outcome loss': 0.2767336926409516, 'Total loss': 0.2767336926409516}
2023-01-04 10:01:51,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:51,586 INFO:     Epoch: 96
2023-01-04 10:01:53,125 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41647612750530244, 'Total loss': 0.41647612750530244} | train loss {'Reaction outcome loss': 0.2752997999098928, 'Total loss': 0.2752997999098928}
2023-01-04 10:01:53,125 INFO:     Found new best model at epoch 96
2023-01-04 10:01:53,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:53,125 INFO:     Epoch: 97
2023-01-04 10:01:54,713 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4628845403591792, 'Total loss': 0.4628845403591792} | train loss {'Reaction outcome loss': 0.2671050647439425, 'Total loss': 0.2671050647439425}
2023-01-04 10:01:54,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:54,714 INFO:     Epoch: 98
2023-01-04 10:01:56,246 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4725031753381093, 'Total loss': 0.4725031753381093} | train loss {'Reaction outcome loss': 0.27234609923123015, 'Total loss': 0.27234609923123015}
2023-01-04 10:01:56,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:56,246 INFO:     Epoch: 99
2023-01-04 10:01:57,826 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4605019787947337, 'Total loss': 0.4605019787947337} | train loss {'Reaction outcome loss': 0.30126390311615187, 'Total loss': 0.30126390311615187}
2023-01-04 10:01:57,827 INFO:     Best model found after epoch 97 of 100.
2023-01-04 10:01:57,827 INFO:   Done with stage: TRAINING
2023-01-04 10:01:57,827 INFO:   Starting stage: EVALUATION
2023-01-04 10:01:57,953 INFO:   Done with stage: EVALUATION
2023-01-04 10:01:57,953 INFO:   Leaving out SEQ value Fold_2
2023-01-04 10:01:57,966 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 10:01:57,966 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:01:58,611 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:01:58,611 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:01:58,679 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:01:58,679 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:01:58,679 INFO:     No hyperparam tuning for this model
2023-01-04 10:01:58,680 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:01:58,680 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:01:58,680 INFO:     None feature selector for col prot
2023-01-04 10:01:58,680 INFO:     None feature selector for col prot
2023-01-04 10:01:58,681 INFO:     None feature selector for col prot
2023-01-04 10:01:58,681 INFO:     None feature selector for col chem
2023-01-04 10:01:58,681 INFO:     None feature selector for col chem
2023-01-04 10:01:58,681 INFO:     None feature selector for col chem
2023-01-04 10:01:58,681 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:01:58,681 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:01:58,682 INFO:     Number of params in model 70111
2023-01-04 10:01:58,685 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:01:58,685 INFO:   Starting stage: TRAINING
2023-01-04 10:01:58,728 INFO:     Val loss before train {'Reaction outcome loss': 0.9661193589369456, 'Total loss': 0.9661193589369456}
2023-01-04 10:01:58,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:01:58,729 INFO:     Epoch: 0
2023-01-04 10:02:00,308 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7427771369616191, 'Total loss': 0.7427771369616191} | train loss {'Reaction outcome loss': 0.8602758929842994, 'Total loss': 0.8602758929842994}
2023-01-04 10:02:00,308 INFO:     Found new best model at epoch 0
2023-01-04 10:02:00,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:00,309 INFO:     Epoch: 1
2023-01-04 10:02:01,813 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.584355358282725, 'Total loss': 0.584355358282725} | train loss {'Reaction outcome loss': 0.7055646855752546, 'Total loss': 0.7055646855752546}
2023-01-04 10:02:01,813 INFO:     Found new best model at epoch 1
2023-01-04 10:02:01,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:01,814 INFO:     Epoch: 2
2023-01-04 10:02:03,402 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.545287412405014, 'Total loss': 0.545287412405014} | train loss {'Reaction outcome loss': 0.6020150957526741, 'Total loss': 0.6020150957526741}
2023-01-04 10:02:03,402 INFO:     Found new best model at epoch 2
2023-01-04 10:02:03,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:03,404 INFO:     Epoch: 3
2023-01-04 10:02:04,929 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.501805325349172, 'Total loss': 0.501805325349172} | train loss {'Reaction outcome loss': 0.5568666069498865, 'Total loss': 0.5568666069498865}
2023-01-04 10:02:04,929 INFO:     Found new best model at epoch 3
2023-01-04 10:02:04,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:04,930 INFO:     Epoch: 4
2023-01-04 10:02:06,484 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5053719361623128, 'Total loss': 0.5053719361623128} | train loss {'Reaction outcome loss': 0.5325949918001126, 'Total loss': 0.5325949918001126}
2023-01-04 10:02:06,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:06,485 INFO:     Epoch: 5
2023-01-04 10:02:08,047 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5004644532998402, 'Total loss': 0.5004644532998402} | train loss {'Reaction outcome loss': 0.5148590158521037, 'Total loss': 0.5148590158521037}
2023-01-04 10:02:08,048 INFO:     Found new best model at epoch 5
2023-01-04 10:02:08,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:08,048 INFO:     Epoch: 6
2023-01-04 10:02:09,601 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4667119085788727, 'Total loss': 0.4667119085788727} | train loss {'Reaction outcome loss': 0.5028358573987807, 'Total loss': 0.5028358573987807}
2023-01-04 10:02:09,601 INFO:     Found new best model at epoch 6
2023-01-04 10:02:09,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:09,602 INFO:     Epoch: 7
2023-01-04 10:02:11,115 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4737883895635605, 'Total loss': 0.4737883895635605} | train loss {'Reaction outcome loss': 0.4936578018324716, 'Total loss': 0.4936578018324716}
2023-01-04 10:02:11,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:11,115 INFO:     Epoch: 8
2023-01-04 10:02:12,669 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4774509330590566, 'Total loss': 0.4774509330590566} | train loss {'Reaction outcome loss': 0.48493039302336866, 'Total loss': 0.48493039302336866}
2023-01-04 10:02:12,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:12,670 INFO:     Epoch: 9
2023-01-04 10:02:14,181 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46284261147181194, 'Total loss': 0.46284261147181194} | train loss {'Reaction outcome loss': 0.47629609829558556, 'Total loss': 0.47629609829558556}
2023-01-04 10:02:14,181 INFO:     Found new best model at epoch 9
2023-01-04 10:02:14,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:14,182 INFO:     Epoch: 10
2023-01-04 10:02:15,733 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44849594831466677, 'Total loss': 0.44849594831466677} | train loss {'Reaction outcome loss': 0.47097622125576705, 'Total loss': 0.47097622125576705}
2023-01-04 10:02:15,734 INFO:     Found new best model at epoch 10
2023-01-04 10:02:15,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:15,735 INFO:     Epoch: 11
2023-01-04 10:02:17,270 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4560227354367574, 'Total loss': 0.4560227354367574} | train loss {'Reaction outcome loss': 0.4640948390895194, 'Total loss': 0.4640948390895194}
2023-01-04 10:02:17,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:17,270 INFO:     Epoch: 12
2023-01-04 10:02:18,829 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4559578756491343, 'Total loss': 0.4559578756491343} | train loss {'Reaction outcome loss': 0.46040605821888964, 'Total loss': 0.46040605821888964}
2023-01-04 10:02:18,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:18,830 INFO:     Epoch: 13
2023-01-04 10:02:20,339 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4556507925192515, 'Total loss': 0.4556507925192515} | train loss {'Reaction outcome loss': 0.4592489004680962, 'Total loss': 0.4592489004680962}
2023-01-04 10:02:20,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:20,339 INFO:     Epoch: 14
2023-01-04 10:02:21,908 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4683128048976262, 'Total loss': 0.4683128048976262} | train loss {'Reaction outcome loss': 0.4577549173609241, 'Total loss': 0.4577549173609241}
2023-01-04 10:02:21,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:21,909 INFO:     Epoch: 15
2023-01-04 10:02:23,426 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4324478606383006, 'Total loss': 0.4324478606383006} | train loss {'Reaction outcome loss': 0.44883385851924673, 'Total loss': 0.44883385851924673}
2023-01-04 10:02:23,427 INFO:     Found new best model at epoch 15
2023-01-04 10:02:23,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:23,427 INFO:     Epoch: 16
2023-01-04 10:02:24,971 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4453877329826355, 'Total loss': 0.4453877329826355} | train loss {'Reaction outcome loss': 0.44345860052239766, 'Total loss': 0.44345860052239766}
2023-01-04 10:02:24,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:24,972 INFO:     Epoch: 17
2023-01-04 10:02:26,520 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4207858443260193, 'Total loss': 0.4207858443260193} | train loss {'Reaction outcome loss': 0.43782280627024045, 'Total loss': 0.43782280627024045}
2023-01-04 10:02:26,520 INFO:     Found new best model at epoch 17
2023-01-04 10:02:26,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:26,521 INFO:     Epoch: 18
2023-01-04 10:02:28,065 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44858008027076723, 'Total loss': 0.44858008027076723} | train loss {'Reaction outcome loss': 0.4348927786498716, 'Total loss': 0.4348927786498716}
2023-01-04 10:02:28,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:28,065 INFO:     Epoch: 19
2023-01-04 10:02:29,596 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42783126632372537, 'Total loss': 0.42783126632372537} | train loss {'Reaction outcome loss': 0.43624537746548214, 'Total loss': 0.43624537746548214}
2023-01-04 10:02:29,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:29,596 INFO:     Epoch: 20
2023-01-04 10:02:31,137 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4377612958351771, 'Total loss': 0.4377612958351771} | train loss {'Reaction outcome loss': 0.42880019804824404, 'Total loss': 0.42880019804824404}
2023-01-04 10:02:31,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:31,137 INFO:     Epoch: 21
2023-01-04 10:02:32,683 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4418762187163035, 'Total loss': 0.4418762187163035} | train loss {'Reaction outcome loss': 0.42181898260509576, 'Total loss': 0.42181898260509576}
2023-01-04 10:02:32,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:32,683 INFO:     Epoch: 22
2023-01-04 10:02:34,248 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41088885962963106, 'Total loss': 0.41088885962963106} | train loss {'Reaction outcome loss': 0.4192707804969816, 'Total loss': 0.4192707804969816}
2023-01-04 10:02:34,249 INFO:     Found new best model at epoch 22
2023-01-04 10:02:34,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:34,250 INFO:     Epoch: 23
2023-01-04 10:02:35,810 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4090079337358475, 'Total loss': 0.4090079337358475} | train loss {'Reaction outcome loss': 0.41693880395356553, 'Total loss': 0.41693880395356553}
2023-01-04 10:02:35,810 INFO:     Found new best model at epoch 23
2023-01-04 10:02:35,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:35,811 INFO:     Epoch: 24
2023-01-04 10:02:37,345 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42087538639704386, 'Total loss': 0.42087538639704386} | train loss {'Reaction outcome loss': 0.41633459778277426, 'Total loss': 0.41633459778277426}
2023-01-04 10:02:37,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:37,345 INFO:     Epoch: 25
2023-01-04 10:02:38,914 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4304149846235911, 'Total loss': 0.4304149846235911} | train loss {'Reaction outcome loss': 0.40801722340749735, 'Total loss': 0.40801722340749735}
2023-01-04 10:02:38,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:38,915 INFO:     Epoch: 26
2023-01-04 10:02:40,431 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4263145049413045, 'Total loss': 0.4263145049413045} | train loss {'Reaction outcome loss': 0.4041020784786333, 'Total loss': 0.4041020784786333}
2023-01-04 10:02:40,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:40,432 INFO:     Epoch: 27
2023-01-04 10:02:41,989 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4153329918781916, 'Total loss': 0.4153329918781916} | train loss {'Reaction outcome loss': 0.40316060411951915, 'Total loss': 0.40316060411951915}
2023-01-04 10:02:41,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:41,989 INFO:     Epoch: 28
2023-01-04 10:02:43,539 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4253989224632581, 'Total loss': 0.4253989224632581} | train loss {'Reaction outcome loss': 0.39379431361898837, 'Total loss': 0.39379431361898837}
2023-01-04 10:02:43,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:43,539 INFO:     Epoch: 29
2023-01-04 10:02:45,100 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40498428146044413, 'Total loss': 0.40498428146044413} | train loss {'Reaction outcome loss': 0.39156957838561507, 'Total loss': 0.39156957838561507}
2023-01-04 10:02:45,100 INFO:     Found new best model at epoch 29
2023-01-04 10:02:45,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:45,101 INFO:     Epoch: 30
2023-01-04 10:02:46,634 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4204418381055196, 'Total loss': 0.4204418381055196} | train loss {'Reaction outcome loss': 0.3879677927319383, 'Total loss': 0.3879677927319383}
2023-01-04 10:02:46,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:46,634 INFO:     Epoch: 31
2023-01-04 10:02:48,187 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4310057073831558, 'Total loss': 0.4310057073831558} | train loss {'Reaction outcome loss': 0.3888089382823134, 'Total loss': 0.3888089382823134}
2023-01-04 10:02:48,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:48,187 INFO:     Epoch: 32
2023-01-04 10:02:49,706 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3910287549098333, 'Total loss': 0.3910287549098333} | train loss {'Reaction outcome loss': 0.3816512541456537, 'Total loss': 0.3816512541456537}
2023-01-04 10:02:49,706 INFO:     Found new best model at epoch 32
2023-01-04 10:02:49,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:49,707 INFO:     Epoch: 33
2023-01-04 10:02:51,278 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41181377371152245, 'Total loss': 0.41181377371152245} | train loss {'Reaction outcome loss': 0.3793701717268416, 'Total loss': 0.3793701717268416}
2023-01-04 10:02:51,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:51,279 INFO:     Epoch: 34
2023-01-04 10:02:52,843 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4014809528986613, 'Total loss': 0.4014809528986613} | train loss {'Reaction outcome loss': 0.37622756240787086, 'Total loss': 0.37622756240787086}
2023-01-04 10:02:52,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:52,843 INFO:     Epoch: 35
2023-01-04 10:02:54,409 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3865361462036769, 'Total loss': 0.3865361462036769} | train loss {'Reaction outcome loss': 0.37491837250334875, 'Total loss': 0.37491837250334875}
2023-01-04 10:02:54,409 INFO:     Found new best model at epoch 35
2023-01-04 10:02:54,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:54,410 INFO:     Epoch: 36
2023-01-04 10:02:55,956 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43344643314679465, 'Total loss': 0.43344643314679465} | train loss {'Reaction outcome loss': 0.36868957481978143, 'Total loss': 0.36868957481978143}
2023-01-04 10:02:55,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:55,956 INFO:     Epoch: 37
2023-01-04 10:02:57,512 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3994205599029859, 'Total loss': 0.3994205599029859} | train loss {'Reaction outcome loss': 0.366341844583169, 'Total loss': 0.366341844583169}
2023-01-04 10:02:57,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:57,513 INFO:     Epoch: 38
2023-01-04 10:02:59,051 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42306375602881113, 'Total loss': 0.42306375602881113} | train loss {'Reaction outcome loss': 0.36086551179161, 'Total loss': 0.36086551179161}
2023-01-04 10:02:59,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:02:59,051 INFO:     Epoch: 39
2023-01-04 10:03:00,602 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38396086990833284, 'Total loss': 0.38396086990833284} | train loss {'Reaction outcome loss': 0.3589661421574952, 'Total loss': 0.3589661421574952}
2023-01-04 10:03:00,602 INFO:     Found new best model at epoch 39
2023-01-04 10:03:00,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:00,603 INFO:     Epoch: 40
2023-01-04 10:03:02,158 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41258461674054464, 'Total loss': 0.41258461674054464} | train loss {'Reaction outcome loss': 0.35398364812135696, 'Total loss': 0.35398364812135696}
2023-01-04 10:03:02,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:02,158 INFO:     Epoch: 41
2023-01-04 10:03:03,719 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3785577913125356, 'Total loss': 0.3785577913125356} | train loss {'Reaction outcome loss': 0.35044199514847535, 'Total loss': 0.35044199514847535}
2023-01-04 10:03:03,719 INFO:     Found new best model at epoch 41
2023-01-04 10:03:03,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:03,720 INFO:     Epoch: 42
2023-01-04 10:03:05,253 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4003553728262583, 'Total loss': 0.4003553728262583} | train loss {'Reaction outcome loss': 0.35261893900104496, 'Total loss': 0.35261893900104496}
2023-01-04 10:03:05,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:05,253 INFO:     Epoch: 43
2023-01-04 10:03:06,818 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4056909464299679, 'Total loss': 0.4056909464299679} | train loss {'Reaction outcome loss': 0.3460448081485736, 'Total loss': 0.3460448081485736}
2023-01-04 10:03:06,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:06,818 INFO:     Epoch: 44
2023-01-04 10:03:08,321 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3921304702758789, 'Total loss': 0.3921304702758789} | train loss {'Reaction outcome loss': 0.34287621544830965, 'Total loss': 0.34287621544830965}
2023-01-04 10:03:08,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:08,322 INFO:     Epoch: 45
2023-01-04 10:03:09,858 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.36911485393842064, 'Total loss': 0.36911485393842064} | train loss {'Reaction outcome loss': 0.3419191384817654, 'Total loss': 0.3419191384817654}
2023-01-04 10:03:09,859 INFO:     Found new best model at epoch 45
2023-01-04 10:03:09,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:09,860 INFO:     Epoch: 46
2023-01-04 10:03:11,403 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38873535295327505, 'Total loss': 0.38873535295327505} | train loss {'Reaction outcome loss': 0.3356051151623656, 'Total loss': 0.3356051151623656}
2023-01-04 10:03:11,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:11,403 INFO:     Epoch: 47
2023-01-04 10:03:12,952 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3925123671690623, 'Total loss': 0.3925123671690623} | train loss {'Reaction outcome loss': 0.33270504194629064, 'Total loss': 0.33270504194629064}
2023-01-04 10:03:12,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:12,952 INFO:     Epoch: 48
2023-01-04 10:03:14,473 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3916756590207418, 'Total loss': 0.3916756590207418} | train loss {'Reaction outcome loss': 0.3353129680722188, 'Total loss': 0.3353129680722188}
2023-01-04 10:03:14,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:14,473 INFO:     Epoch: 49
2023-01-04 10:03:16,034 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40461524327596027, 'Total loss': 0.40461524327596027} | train loss {'Reaction outcome loss': 0.32796023243990463, 'Total loss': 0.32796023243990463}
2023-01-04 10:03:16,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:16,034 INFO:     Epoch: 50
2023-01-04 10:03:17,572 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3678368429342906, 'Total loss': 0.3678368429342906} | train loss {'Reaction outcome loss': 0.3295249310168591, 'Total loss': 0.3295249310168591}
2023-01-04 10:03:17,572 INFO:     Found new best model at epoch 50
2023-01-04 10:03:17,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:17,573 INFO:     Epoch: 51
2023-01-04 10:03:19,148 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39327611525853473, 'Total loss': 0.39327611525853473} | train loss {'Reaction outcome loss': 0.32718239691886275, 'Total loss': 0.32718239691886275}
2023-01-04 10:03:19,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:19,148 INFO:     Epoch: 52
2023-01-04 10:03:20,701 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3952545434236526, 'Total loss': 0.3952545434236526} | train loss {'Reaction outcome loss': 0.32713376951741646, 'Total loss': 0.32713376951741646}
2023-01-04 10:03:20,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:20,701 INFO:     Epoch: 53
2023-01-04 10:03:22,254 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3921151041984558, 'Total loss': 0.3921151041984558} | train loss {'Reaction outcome loss': 0.3253257656299369, 'Total loss': 0.3253257656299369}
2023-01-04 10:03:22,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:22,254 INFO:     Epoch: 54
2023-01-04 10:03:23,759 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3810219297806422, 'Total loss': 0.3810219297806422} | train loss {'Reaction outcome loss': 0.3211475305886932, 'Total loss': 0.3211475305886932}
2023-01-04 10:03:23,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:23,759 INFO:     Epoch: 55
2023-01-04 10:03:25,315 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40903142690658567, 'Total loss': 0.40903142690658567} | train loss {'Reaction outcome loss': 0.3226483721326996, 'Total loss': 0.3226483721326996}
2023-01-04 10:03:25,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:25,316 INFO:     Epoch: 56
2023-01-04 10:03:26,826 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3959623843431473, 'Total loss': 0.3959623843431473} | train loss {'Reaction outcome loss': 0.3179619409717046, 'Total loss': 0.3179619409717046}
2023-01-04 10:03:26,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:26,827 INFO:     Epoch: 57
2023-01-04 10:03:28,368 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3889084349075953, 'Total loss': 0.3889084349075953} | train loss {'Reaction outcome loss': 0.31184279200904097, 'Total loss': 0.31184279200904097}
2023-01-04 10:03:28,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:28,368 INFO:     Epoch: 58
2023-01-04 10:03:29,908 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40571805437405906, 'Total loss': 0.40571805437405906} | train loss {'Reaction outcome loss': 0.3110192699200941, 'Total loss': 0.3110192699200941}
2023-01-04 10:03:29,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:29,908 INFO:     Epoch: 59
2023-01-04 10:03:31,451 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.35768550833066304, 'Total loss': 0.35768550833066304} | train loss {'Reaction outcome loss': 0.308725844031616, 'Total loss': 0.308725844031616}
2023-01-04 10:03:31,452 INFO:     Found new best model at epoch 59
2023-01-04 10:03:31,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:31,452 INFO:     Epoch: 60
2023-01-04 10:03:32,960 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39180875023206074, 'Total loss': 0.39180875023206074} | train loss {'Reaction outcome loss': 0.30932053994564784, 'Total loss': 0.30932053994564784}
2023-01-04 10:03:32,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:32,961 INFO:     Epoch: 61
2023-01-04 10:03:34,490 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37090699225664137, 'Total loss': 0.37090699225664137} | train loss {'Reaction outcome loss': 0.30782062855068143, 'Total loss': 0.30782062855068143}
2023-01-04 10:03:34,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:34,490 INFO:     Epoch: 62
2023-01-04 10:03:36,025 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.363732298463583, 'Total loss': 0.363732298463583} | train loss {'Reaction outcome loss': 0.3022621033010465, 'Total loss': 0.3022621033010465}
2023-01-04 10:03:36,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:36,026 INFO:     Epoch: 63
2023-01-04 10:03:37,566 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4478430946667989, 'Total loss': 0.4478430946667989} | train loss {'Reaction outcome loss': 0.3005748138977931, 'Total loss': 0.3005748138977931}
2023-01-04 10:03:37,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:37,567 INFO:     Epoch: 64
2023-01-04 10:03:39,115 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4144841273625692, 'Total loss': 0.4144841273625692} | train loss {'Reaction outcome loss': 0.30051302213917724, 'Total loss': 0.30051302213917724}
2023-01-04 10:03:39,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:39,116 INFO:     Epoch: 65
2023-01-04 10:03:40,653 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37040282289187115, 'Total loss': 0.37040282289187115} | train loss {'Reaction outcome loss': 0.2984203665138601, 'Total loss': 0.2984203665138601}
2023-01-04 10:03:40,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:40,653 INFO:     Epoch: 66
2023-01-04 10:03:42,202 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39189273019631704, 'Total loss': 0.39189273019631704} | train loss {'Reaction outcome loss': 0.30176332661192934, 'Total loss': 0.30176332661192934}
2023-01-04 10:03:42,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:42,202 INFO:     Epoch: 67
2023-01-04 10:03:43,739 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3923186729351679, 'Total loss': 0.3923186729351679} | train loss {'Reaction outcome loss': 0.29438934420600477, 'Total loss': 0.29438934420600477}
2023-01-04 10:03:43,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:43,739 INFO:     Epoch: 68
2023-01-04 10:03:45,312 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40536325971285503, 'Total loss': 0.40536325971285503} | train loss {'Reaction outcome loss': 0.2945048049392499, 'Total loss': 0.2945048049392499}
2023-01-04 10:03:45,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:45,313 INFO:     Epoch: 69
2023-01-04 10:03:46,893 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.37206826110680896, 'Total loss': 0.37206826110680896} | train loss {'Reaction outcome loss': 0.29380762596843224, 'Total loss': 0.29380762596843224}
2023-01-04 10:03:46,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:46,893 INFO:     Epoch: 70
2023-01-04 10:03:48,503 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4031036600470543, 'Total loss': 0.4031036600470543} | train loss {'Reaction outcome loss': 0.2935919514669603, 'Total loss': 0.2935919514669603}
2023-01-04 10:03:48,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:48,503 INFO:     Epoch: 71
2023-01-04 10:03:50,059 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37735172857840854, 'Total loss': 0.37735172857840854} | train loss {'Reaction outcome loss': 0.2886185691838627, 'Total loss': 0.2886185691838627}
2023-01-04 10:03:50,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:50,059 INFO:     Epoch: 72
2023-01-04 10:03:51,628 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.36779534022013344, 'Total loss': 0.36779534022013344} | train loss {'Reaction outcome loss': 0.28917216605100876, 'Total loss': 0.28917216605100876}
2023-01-04 10:03:51,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:51,628 INFO:     Epoch: 73
2023-01-04 10:03:53,174 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39990004897117615, 'Total loss': 0.39990004897117615} | train loss {'Reaction outcome loss': 0.28539097200969965, 'Total loss': 0.28539097200969965}
2023-01-04 10:03:53,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:53,174 INFO:     Epoch: 74
2023-01-04 10:03:54,749 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3644422103961309, 'Total loss': 0.3644422103961309} | train loss {'Reaction outcome loss': 0.28882305531493035, 'Total loss': 0.28882305531493035}
2023-01-04 10:03:54,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:54,749 INFO:     Epoch: 75
2023-01-04 10:03:56,356 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.36649589935938515, 'Total loss': 0.36649589935938515} | train loss {'Reaction outcome loss': 0.28539608861063864, 'Total loss': 0.28539608861063864}
2023-01-04 10:03:56,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:56,356 INFO:     Epoch: 76
2023-01-04 10:03:57,954 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38683105607827506, 'Total loss': 0.38683105607827506} | train loss {'Reaction outcome loss': 0.28510490612505557, 'Total loss': 0.28510490612505557}
2023-01-04 10:03:57,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:57,955 INFO:     Epoch: 77
2023-01-04 10:03:59,524 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3846776098012924, 'Total loss': 0.3846776098012924} | train loss {'Reaction outcome loss': 0.2805529180163647, 'Total loss': 0.2805529180163647}
2023-01-04 10:03:59,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:03:59,524 INFO:     Epoch: 78
2023-01-04 10:04:01,135 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.37794104317824045, 'Total loss': 0.37794104317824045} | train loss {'Reaction outcome loss': 0.2810396044327444, 'Total loss': 0.2810396044327444}
2023-01-04 10:04:01,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:01,136 INFO:     Epoch: 79
2023-01-04 10:04:02,703 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3763052195310593, 'Total loss': 0.3763052195310593} | train loss {'Reaction outcome loss': 0.2820992385797994, 'Total loss': 0.2820992385797994}
2023-01-04 10:04:02,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:02,703 INFO:     Epoch: 80
2023-01-04 10:04:04,302 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3838121950626373, 'Total loss': 0.3838121950626373} | train loss {'Reaction outcome loss': 0.2802055268497257, 'Total loss': 0.2802055268497257}
2023-01-04 10:04:04,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:04,303 INFO:     Epoch: 81
2023-01-04 10:04:05,910 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3886478235324224, 'Total loss': 0.3886478235324224} | train loss {'Reaction outcome loss': 0.282417672703336, 'Total loss': 0.282417672703336}
2023-01-04 10:04:05,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:05,911 INFO:     Epoch: 82
2023-01-04 10:04:07,523 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3789487938086192, 'Total loss': 0.3789487938086192} | train loss {'Reaction outcome loss': 0.2750945869464796, 'Total loss': 0.2750945869464796}
2023-01-04 10:04:07,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:07,523 INFO:     Epoch: 83
2023-01-04 10:04:09,097 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38284851213296256, 'Total loss': 0.38284851213296256} | train loss {'Reaction outcome loss': 0.27188427440631086, 'Total loss': 0.27188427440631086}
2023-01-04 10:04:09,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:09,097 INFO:     Epoch: 84
2023-01-04 10:04:10,705 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3910463919242223, 'Total loss': 0.3910463919242223} | train loss {'Reaction outcome loss': 0.27615758970775556, 'Total loss': 0.27615758970775556}
2023-01-04 10:04:10,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:10,705 INFO:     Epoch: 85
2023-01-04 10:04:12,261 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3910016189018885, 'Total loss': 0.3910016189018885} | train loss {'Reaction outcome loss': 0.27485926408361605, 'Total loss': 0.27485926408361605}
2023-01-04 10:04:12,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:12,261 INFO:     Epoch: 86
2023-01-04 10:04:13,864 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37475673456986747, 'Total loss': 0.37475673456986747} | train loss {'Reaction outcome loss': 0.2774184977997354, 'Total loss': 0.2774184977997354}
2023-01-04 10:04:13,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:13,864 INFO:     Epoch: 87
2023-01-04 10:04:15,466 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3838399032751719, 'Total loss': 0.3838399032751719} | train loss {'Reaction outcome loss': 0.27260118042674913, 'Total loss': 0.27260118042674913}
2023-01-04 10:04:15,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:15,466 INFO:     Epoch: 88
2023-01-04 10:04:17,055 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.381625493367513, 'Total loss': 0.381625493367513} | train loss {'Reaction outcome loss': 0.26903301785826245, 'Total loss': 0.26903301785826245}
2023-01-04 10:04:17,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:17,056 INFO:     Epoch: 89
2023-01-04 10:04:18,635 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3527081380287806, 'Total loss': 0.3527081380287806} | train loss {'Reaction outcome loss': 0.27508094702120667, 'Total loss': 0.27508094702120667}
2023-01-04 10:04:18,635 INFO:     Found new best model at epoch 89
2023-01-04 10:04:18,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:18,636 INFO:     Epoch: 90
2023-01-04 10:04:20,196 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3715613096952438, 'Total loss': 0.3715613096952438} | train loss {'Reaction outcome loss': 0.2654960770091731, 'Total loss': 0.2654960770091731}
2023-01-04 10:04:20,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:20,196 INFO:     Epoch: 91
2023-01-04 10:04:21,796 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.36509623726209006, 'Total loss': 0.36509623726209006} | train loss {'Reaction outcome loss': 0.2697954607834091, 'Total loss': 0.2697954607834091}
2023-01-04 10:04:21,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:21,796 INFO:     Epoch: 92
2023-01-04 10:04:23,384 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.35324113965034487, 'Total loss': 0.35324113965034487} | train loss {'Reaction outcome loss': 0.2616142565827994, 'Total loss': 0.2616142565827994}
2023-01-04 10:04:23,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:23,385 INFO:     Epoch: 93
2023-01-04 10:04:24,990 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3842032154401143, 'Total loss': 0.3842032154401143} | train loss {'Reaction outcome loss': 0.26659342362767174, 'Total loss': 0.26659342362767174}
2023-01-04 10:04:24,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:24,991 INFO:     Epoch: 94
2023-01-04 10:04:26,543 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3648392856121063, 'Total loss': 0.3648392856121063} | train loss {'Reaction outcome loss': 0.26830265190684316, 'Total loss': 0.26830265190684316}
2023-01-04 10:04:26,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:26,543 INFO:     Epoch: 95
2023-01-04 10:04:28,137 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3788426607847214, 'Total loss': 0.3788426607847214} | train loss {'Reaction outcome loss': 0.2638881247995537, 'Total loss': 0.2638881247995537}
2023-01-04 10:04:28,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:28,137 INFO:     Epoch: 96
2023-01-04 10:04:29,689 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38700762192408245, 'Total loss': 0.38700762192408245} | train loss {'Reaction outcome loss': 0.26591398633825475, 'Total loss': 0.26591398633825475}
2023-01-04 10:04:29,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:29,689 INFO:     Epoch: 97
2023-01-04 10:04:31,295 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.39068146447340646, 'Total loss': 0.39068146447340646} | train loss {'Reaction outcome loss': 0.2598397021519614, 'Total loss': 0.2598397021519614}
2023-01-04 10:04:31,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:31,295 INFO:     Epoch: 98
2023-01-04 10:04:32,903 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37672032614549, 'Total loss': 0.37672032614549} | train loss {'Reaction outcome loss': 0.262973594593546, 'Total loss': 0.262973594593546}
2023-01-04 10:04:32,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:32,904 INFO:     Epoch: 99
2023-01-04 10:04:34,507 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.35324176251888273, 'Total loss': 0.35324176251888273} | train loss {'Reaction outcome loss': 0.261453519646938, 'Total loss': 0.261453519646938}
2023-01-04 10:04:34,508 INFO:     Best model found after epoch 90 of 100.
2023-01-04 10:04:34,508 INFO:   Done with stage: TRAINING
2023-01-04 10:04:34,508 INFO:   Starting stage: EVALUATION
2023-01-04 10:04:34,646 INFO:   Done with stage: EVALUATION
2023-01-04 10:04:34,647 INFO:   Leaving out SEQ value Fold_3
2023-01-04 10:04:34,659 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-04 10:04:34,659 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:04:35,296 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:04:35,296 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:04:35,363 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:04:35,363 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:04:35,364 INFO:     No hyperparam tuning for this model
2023-01-04 10:04:35,364 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:04:35,364 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:04:35,364 INFO:     None feature selector for col prot
2023-01-04 10:04:35,364 INFO:     None feature selector for col prot
2023-01-04 10:04:35,365 INFO:     None feature selector for col prot
2023-01-04 10:04:35,365 INFO:     None feature selector for col chem
2023-01-04 10:04:35,365 INFO:     None feature selector for col chem
2023-01-04 10:04:35,365 INFO:     None feature selector for col chem
2023-01-04 10:04:35,365 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:04:35,365 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:04:35,366 INFO:     Number of params in model 70111
2023-01-04 10:04:35,370 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:04:35,370 INFO:   Starting stage: TRAINING
2023-01-04 10:04:35,412 INFO:     Val loss before train {'Reaction outcome loss': 0.9791510144869486, 'Total loss': 0.9791510144869486}
2023-01-04 10:04:35,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:35,412 INFO:     Epoch: 0
2023-01-04 10:04:37,006 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6965997695922852, 'Total loss': 0.6965997695922852} | train loss {'Reaction outcome loss': 0.8399472122262764, 'Total loss': 0.8399472122262764}
2023-01-04 10:04:37,006 INFO:     Found new best model at epoch 0
2023-01-04 10:04:37,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:37,007 INFO:     Epoch: 1
2023-01-04 10:04:38,557 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.582760073741277, 'Total loss': 0.582760073741277} | train loss {'Reaction outcome loss': 0.6765981564002723, 'Total loss': 0.6765981564002723}
2023-01-04 10:04:38,558 INFO:     Found new best model at epoch 1
2023-01-04 10:04:38,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:38,558 INFO:     Epoch: 2
2023-01-04 10:04:40,145 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49470969339211784, 'Total loss': 0.49470969339211784} | train loss {'Reaction outcome loss': 0.5855868746873637, 'Total loss': 0.5855868746873637}
2023-01-04 10:04:40,146 INFO:     Found new best model at epoch 2
2023-01-04 10:04:40,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:40,147 INFO:     Epoch: 3
2023-01-04 10:04:41,743 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4989679495493571, 'Total loss': 0.4989679495493571} | train loss {'Reaction outcome loss': 0.5352542812204009, 'Total loss': 0.5352542812204009}
2023-01-04 10:04:41,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:41,743 INFO:     Epoch: 4
2023-01-04 10:04:43,340 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4958168486754099, 'Total loss': 0.4958168486754099} | train loss {'Reaction outcome loss': 0.5130659994493991, 'Total loss': 0.5130659994493991}
2023-01-04 10:04:43,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:43,340 INFO:     Epoch: 5
2023-01-04 10:04:44,886 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43856237133344017, 'Total loss': 0.43856237133344017} | train loss {'Reaction outcome loss': 0.4874396805833626, 'Total loss': 0.4874396805833626}
2023-01-04 10:04:44,886 INFO:     Found new best model at epoch 5
2023-01-04 10:04:44,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:44,887 INFO:     Epoch: 6
2023-01-04 10:04:46,471 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45475507974624635, 'Total loss': 0.45475507974624635} | train loss {'Reaction outcome loss': 0.4800041176076305, 'Total loss': 0.4800041176076305}
2023-01-04 10:04:46,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:46,472 INFO:     Epoch: 7
2023-01-04 10:04:48,023 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4876051435867945, 'Total loss': 0.4876051435867945} | train loss {'Reaction outcome loss': 0.46754780807618285, 'Total loss': 0.46754780807618285}
2023-01-04 10:04:48,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:48,024 INFO:     Epoch: 8
2023-01-04 10:04:49,598 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4498046239217122, 'Total loss': 0.4498046239217122} | train loss {'Reaction outcome loss': 0.4614260182389474, 'Total loss': 0.4614260182389474}
2023-01-04 10:04:49,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:49,598 INFO:     Epoch: 9
2023-01-04 10:04:51,160 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40022285977999367, 'Total loss': 0.40022285977999367} | train loss {'Reaction outcome loss': 0.4489765034170608, 'Total loss': 0.4489765034170608}
2023-01-04 10:04:51,160 INFO:     Found new best model at epoch 9
2023-01-04 10:04:51,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:51,161 INFO:     Epoch: 10
2023-01-04 10:04:52,754 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39290176033973695, 'Total loss': 0.39290176033973695} | train loss {'Reaction outcome loss': 0.44112670795504016, 'Total loss': 0.44112670795504016}
2023-01-04 10:04:52,755 INFO:     Found new best model at epoch 10
2023-01-04 10:04:52,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:52,756 INFO:     Epoch: 11
2023-01-04 10:04:54,304 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4057097276051839, 'Total loss': 0.4057097276051839} | train loss {'Reaction outcome loss': 0.44164662431526885, 'Total loss': 0.44164662431526885}
2023-01-04 10:04:54,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:54,304 INFO:     Epoch: 12
2023-01-04 10:04:55,902 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.431338170170784, 'Total loss': 0.431338170170784} | train loss {'Reaction outcome loss': 0.4298708615927679, 'Total loss': 0.4298708615927679}
2023-01-04 10:04:55,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:55,902 INFO:     Epoch: 13
2023-01-04 10:04:57,434 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39338696698347725, 'Total loss': 0.39338696698347725} | train loss {'Reaction outcome loss': 0.4274662288792459, 'Total loss': 0.4274662288792459}
2023-01-04 10:04:57,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:57,435 INFO:     Epoch: 14
2023-01-04 10:04:59,008 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3948429495096207, 'Total loss': 0.3948429495096207} | train loss {'Reaction outcome loss': 0.4249733265530579, 'Total loss': 0.4249733265530579}
2023-01-04 10:04:59,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:04:59,008 INFO:     Epoch: 15
2023-01-04 10:05:00,598 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41281195481618244, 'Total loss': 0.41281195481618244} | train loss {'Reaction outcome loss': 0.41530588351712455, 'Total loss': 0.41530588351712455}
2023-01-04 10:05:00,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:00,598 INFO:     Epoch: 16
2023-01-04 10:05:02,161 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41386584838231405, 'Total loss': 0.41386584838231405} | train loss {'Reaction outcome loss': 0.4093283780496499, 'Total loss': 0.4093283780496499}
2023-01-04 10:05:02,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:02,161 INFO:     Epoch: 17
2023-01-04 10:05:03,738 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40874310632546745, 'Total loss': 0.40874310632546745} | train loss {'Reaction outcome loss': 0.4062936867680057, 'Total loss': 0.4062936867680057}
2023-01-04 10:05:03,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:03,738 INFO:     Epoch: 18
2023-01-04 10:05:05,301 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.37537788550059, 'Total loss': 0.37537788550059} | train loss {'Reaction outcome loss': 0.40303877864816534, 'Total loss': 0.40303877864816534}
2023-01-04 10:05:05,301 INFO:     Found new best model at epoch 18
2023-01-04 10:05:05,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:05,302 INFO:     Epoch: 19
2023-01-04 10:05:06,897 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3873948713143667, 'Total loss': 0.3873948713143667} | train loss {'Reaction outcome loss': 0.3993025309100362, 'Total loss': 0.3993025309100362}
2023-01-04 10:05:06,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:06,897 INFO:     Epoch: 20
2023-01-04 10:05:08,482 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.37240744531154635, 'Total loss': 0.37240744531154635} | train loss {'Reaction outcome loss': 0.3918700523646995, 'Total loss': 0.3918700523646995}
2023-01-04 10:05:08,483 INFO:     Found new best model at epoch 20
2023-01-04 10:05:08,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:08,483 INFO:     Epoch: 21
2023-01-04 10:05:10,041 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39320638179779055, 'Total loss': 0.39320638179779055} | train loss {'Reaction outcome loss': 0.38928819659451275, 'Total loss': 0.38928819659451275}
2023-01-04 10:05:10,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:10,042 INFO:     Epoch: 22
2023-01-04 10:05:11,588 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4011304845412572, 'Total loss': 0.4011304845412572} | train loss {'Reaction outcome loss': 0.3842226200603031, 'Total loss': 0.3842226200603031}
2023-01-04 10:05:11,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:11,588 INFO:     Epoch: 23
2023-01-04 10:05:13,175 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3839351038138072, 'Total loss': 0.3839351038138072} | train loss {'Reaction outcome loss': 0.3800913508692791, 'Total loss': 0.3800913508692791}
2023-01-04 10:05:13,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:13,176 INFO:     Epoch: 24
2023-01-04 10:05:14,738 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.36794017230470977, 'Total loss': 0.36794017230470977} | train loss {'Reaction outcome loss': 0.3772061530954284, 'Total loss': 0.3772061530954284}
2023-01-04 10:05:14,738 INFO:     Found new best model at epoch 24
2023-01-04 10:05:14,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:14,739 INFO:     Epoch: 25
2023-01-04 10:05:16,285 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3462431242068609, 'Total loss': 0.3462431242068609} | train loss {'Reaction outcome loss': 0.37285690361503304, 'Total loss': 0.37285690361503304}
2023-01-04 10:05:16,285 INFO:     Found new best model at epoch 25
2023-01-04 10:05:16,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:16,286 INFO:     Epoch: 26
2023-01-04 10:05:17,810 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3618771553039551, 'Total loss': 0.3618771553039551} | train loss {'Reaction outcome loss': 0.37291458526770566, 'Total loss': 0.37291458526770566}
2023-01-04 10:05:17,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:17,810 INFO:     Epoch: 27
2023-01-04 10:05:19,326 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.365199343363444, 'Total loss': 0.365199343363444} | train loss {'Reaction outcome loss': 0.3644757862460569, 'Total loss': 0.3644757862460569}
2023-01-04 10:05:19,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:19,326 INFO:     Epoch: 28
2023-01-04 10:05:20,816 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3548546388745308, 'Total loss': 0.3548546388745308} | train loss {'Reaction outcome loss': 0.3635534483568255, 'Total loss': 0.3635534483568255}
2023-01-04 10:05:20,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:20,816 INFO:     Epoch: 29
2023-01-04 10:05:22,329 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3651786168416341, 'Total loss': 0.3651786168416341} | train loss {'Reaction outcome loss': 0.35922980325028464, 'Total loss': 0.35922980325028464}
2023-01-04 10:05:22,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:22,329 INFO:     Epoch: 30
2023-01-04 10:05:23,818 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3886824289957682, 'Total loss': 0.3886824289957682} | train loss {'Reaction outcome loss': 0.35490219289526287, 'Total loss': 0.35490219289526287}
2023-01-04 10:05:23,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:23,818 INFO:     Epoch: 31
2023-01-04 10:05:25,353 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.35479012032349905, 'Total loss': 0.35479012032349905} | train loss {'Reaction outcome loss': 0.35304039373059115, 'Total loss': 0.35304039373059115}
2023-01-04 10:05:25,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:25,353 INFO:     Epoch: 32
2023-01-04 10:05:26,882 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3702678203582764, 'Total loss': 0.3702678203582764} | train loss {'Reaction outcome loss': 0.3533120975998055, 'Total loss': 0.3533120975998055}
2023-01-04 10:05:26,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:26,882 INFO:     Epoch: 33
2023-01-04 10:05:28,393 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.37670248945554097, 'Total loss': 0.37670248945554097} | train loss {'Reaction outcome loss': 0.34746290218236264, 'Total loss': 0.34746290218236264}
2023-01-04 10:05:28,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:28,394 INFO:     Epoch: 34
2023-01-04 10:05:29,888 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3693472663561503, 'Total loss': 0.3693472663561503} | train loss {'Reaction outcome loss': 0.3447006630446638, 'Total loss': 0.3447006630446638}
2023-01-04 10:05:29,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:29,889 INFO:     Epoch: 35
2023-01-04 10:05:31,420 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3623694747686386, 'Total loss': 0.3623694747686386} | train loss {'Reaction outcome loss': 0.34062666616426623, 'Total loss': 0.34062666616426623}
2023-01-04 10:05:31,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:31,420 INFO:     Epoch: 36
2023-01-04 10:05:32,924 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.34211865067481995, 'Total loss': 0.34211865067481995} | train loss {'Reaction outcome loss': 0.34021089151776585, 'Total loss': 0.34021089151776585}
2023-01-04 10:05:32,924 INFO:     Found new best model at epoch 36
2023-01-04 10:05:32,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:32,925 INFO:     Epoch: 37
2023-01-04 10:05:34,442 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3470268060763677, 'Total loss': 0.3470268060763677} | train loss {'Reaction outcome loss': 0.33641676742212356, 'Total loss': 0.33641676742212356}
2023-01-04 10:05:34,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:34,443 INFO:     Epoch: 38
2023-01-04 10:05:35,960 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.33575372795263925, 'Total loss': 0.33575372795263925} | train loss {'Reaction outcome loss': 0.32968566580452163, 'Total loss': 0.32968566580452163}
2023-01-04 10:05:35,960 INFO:     Found new best model at epoch 38
2023-01-04 10:05:35,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:35,961 INFO:     Epoch: 39
2023-01-04 10:05:37,490 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.37293018996715543, 'Total loss': 0.37293018996715543} | train loss {'Reaction outcome loss': 0.3310381435820097, 'Total loss': 0.3310381435820097}
2023-01-04 10:05:37,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:37,490 INFO:     Epoch: 40
2023-01-04 10:05:38,969 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3435859799385071, 'Total loss': 0.3435859799385071} | train loss {'Reaction outcome loss': 0.32680353643269555, 'Total loss': 0.32680353643269555}
2023-01-04 10:05:38,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:38,969 INFO:     Epoch: 41
2023-01-04 10:05:40,498 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38726281424363457, 'Total loss': 0.38726281424363457} | train loss {'Reaction outcome loss': 0.32838410906136256, 'Total loss': 0.32838410906136256}
2023-01-04 10:05:40,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:40,498 INFO:     Epoch: 42
2023-01-04 10:05:41,987 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.33975356618563335, 'Total loss': 0.33975356618563335} | train loss {'Reaction outcome loss': 0.32873426361277536, 'Total loss': 0.32873426361277536}
2023-01-04 10:05:41,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:41,988 INFO:     Epoch: 43
2023-01-04 10:05:43,508 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3531564146280289, 'Total loss': 0.3531564146280289} | train loss {'Reaction outcome loss': 0.3209085314091281, 'Total loss': 0.3209085314091281}
2023-01-04 10:05:43,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:43,508 INFO:     Epoch: 44
2023-01-04 10:05:45,041 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.34402441382408144, 'Total loss': 0.34402441382408144} | train loss {'Reaction outcome loss': 0.31773385602114823, 'Total loss': 0.31773385602114823}
2023-01-04 10:05:45,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:45,042 INFO:     Epoch: 45
2023-01-04 10:05:46,572 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3432271813352903, 'Total loss': 0.3432271813352903} | train loss {'Reaction outcome loss': 0.31702126849896356, 'Total loss': 0.31702126849896356}
2023-01-04 10:05:46,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:46,572 INFO:     Epoch: 46
2023-01-04 10:05:48,085 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.35646027823289234, 'Total loss': 0.35646027823289234} | train loss {'Reaction outcome loss': 0.3156047507405721, 'Total loss': 0.3156047507405721}
2023-01-04 10:05:48,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:48,085 INFO:     Epoch: 47
2023-01-04 10:05:49,609 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3534814258416494, 'Total loss': 0.3534814258416494} | train loss {'Reaction outcome loss': 0.30861376184708955, 'Total loss': 0.30861376184708955}
2023-01-04 10:05:49,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:49,609 INFO:     Epoch: 48
2023-01-04 10:05:51,106 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3370867093404134, 'Total loss': 0.3370867093404134} | train loss {'Reaction outcome loss': 0.3115198326836653, 'Total loss': 0.3115198326836653}
2023-01-04 10:05:51,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:51,107 INFO:     Epoch: 49
2023-01-04 10:05:52,634 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.33938103914260864, 'Total loss': 0.33938103914260864} | train loss {'Reaction outcome loss': 0.30880741467115186, 'Total loss': 0.30880741467115186}
2023-01-04 10:05:52,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:52,635 INFO:     Epoch: 50
2023-01-04 10:05:54,158 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3514485756556193, 'Total loss': 0.3514485756556193} | train loss {'Reaction outcome loss': 0.30183776279712077, 'Total loss': 0.30183776279712077}
2023-01-04 10:05:54,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:54,159 INFO:     Epoch: 51
2023-01-04 10:05:55,681 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.34803374161322914, 'Total loss': 0.34803374161322914} | train loss {'Reaction outcome loss': 0.3020512527095436, 'Total loss': 0.3020512527095436}
2023-01-04 10:05:55,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:55,681 INFO:     Epoch: 52
2023-01-04 10:05:57,183 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3154181718826294, 'Total loss': 0.3154181718826294} | train loss {'Reaction outcome loss': 0.2962227517333418, 'Total loss': 0.2962227517333418}
2023-01-04 10:05:57,183 INFO:     Found new best model at epoch 52
2023-01-04 10:05:57,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:57,184 INFO:     Epoch: 53
2023-01-04 10:05:58,743 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.34465246746937434, 'Total loss': 0.34465246746937434} | train loss {'Reaction outcome loss': 0.2995025232654216, 'Total loss': 0.2995025232654216}
2023-01-04 10:05:58,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:05:58,743 INFO:     Epoch: 54
2023-01-04 10:06:00,249 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.323468054831028, 'Total loss': 0.323468054831028} | train loss {'Reaction outcome loss': 0.2989783118654221, 'Total loss': 0.2989783118654221}
2023-01-04 10:06:00,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:00,250 INFO:     Epoch: 55
2023-01-04 10:06:01,782 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37101043065389, 'Total loss': 0.37101043065389} | train loss {'Reaction outcome loss': 0.29792864469474534, 'Total loss': 0.29792864469474534}
2023-01-04 10:06:01,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:01,782 INFO:     Epoch: 56
2023-01-04 10:06:03,316 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37989804744720457, 'Total loss': 0.37989804744720457} | train loss {'Reaction outcome loss': 0.2916598820653349, 'Total loss': 0.2916598820653349}
2023-01-04 10:06:03,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:03,317 INFO:     Epoch: 57
2023-01-04 10:06:04,849 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3883359601100286, 'Total loss': 0.3883359601100286} | train loss {'Reaction outcome loss': 0.28847295197063705, 'Total loss': 0.28847295197063705}
2023-01-04 10:06:04,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:04,849 INFO:     Epoch: 58
2023-01-04 10:06:06,326 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.36595216393470764, 'Total loss': 0.36595216393470764} | train loss {'Reaction outcome loss': 0.2954283272538238, 'Total loss': 0.2954283272538238}
2023-01-04 10:06:06,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:06,326 INFO:     Epoch: 59
2023-01-04 10:06:07,857 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3355336328347524, 'Total loss': 0.3355336328347524} | train loss {'Reaction outcome loss': 0.2912524761116593, 'Total loss': 0.2912524761116593}
2023-01-04 10:06:07,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:07,857 INFO:     Epoch: 60
2023-01-04 10:06:09,358 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.35553208688894905, 'Total loss': 0.35553208688894905} | train loss {'Reaction outcome loss': 0.28743379257921803, 'Total loss': 0.28743379257921803}
2023-01-04 10:06:09,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:09,358 INFO:     Epoch: 61
2023-01-04 10:06:10,898 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3426176533102989, 'Total loss': 0.3426176533102989} | train loss {'Reaction outcome loss': 0.28662618510837484, 'Total loss': 0.28662618510837484}
2023-01-04 10:06:10,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:10,899 INFO:     Epoch: 62
2023-01-04 10:06:12,418 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3372110406557719, 'Total loss': 0.3372110406557719} | train loss {'Reaction outcome loss': 0.28655331840264403, 'Total loss': 0.28655331840264403}
2023-01-04 10:06:12,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:12,419 INFO:     Epoch: 63
2023-01-04 10:06:13,943 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.351786274711291, 'Total loss': 0.351786274711291} | train loss {'Reaction outcome loss': 0.28286299637322937, 'Total loss': 0.28286299637322937}
2023-01-04 10:06:13,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:13,943 INFO:     Epoch: 64
2023-01-04 10:06:15,454 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.34473777016003926, 'Total loss': 0.34473777016003926} | train loss {'Reaction outcome loss': 0.27949057665148347, 'Total loss': 0.27949057665148347}
2023-01-04 10:06:15,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:15,456 INFO:     Epoch: 65
2023-01-04 10:06:16,997 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.36774744689464567, 'Total loss': 0.36774744689464567} | train loss {'Reaction outcome loss': 0.27896273252983816, 'Total loss': 0.27896273252983816}
2023-01-04 10:06:16,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:16,998 INFO:     Epoch: 66
2023-01-04 10:06:18,512 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3184024562438329, 'Total loss': 0.3184024562438329} | train loss {'Reaction outcome loss': 0.2812636653683062, 'Total loss': 0.2812636653683062}
2023-01-04 10:06:18,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:18,512 INFO:     Epoch: 67
2023-01-04 10:06:20,060 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3433210675915082, 'Total loss': 0.3433210675915082} | train loss {'Reaction outcome loss': 0.27213487040072787, 'Total loss': 0.27213487040072787}
2023-01-04 10:06:20,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:20,060 INFO:     Epoch: 68
2023-01-04 10:06:21,600 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3659032300114632, 'Total loss': 0.3659032300114632} | train loss {'Reaction outcome loss': 0.27068131348991087, 'Total loss': 0.27068131348991087}
2023-01-04 10:06:21,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:21,601 INFO:     Epoch: 69
2023-01-04 10:06:23,203 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3368195136388143, 'Total loss': 0.3368195136388143} | train loss {'Reaction outcome loss': 0.27335947958195783, 'Total loss': 0.27335947958195783}
2023-01-04 10:06:23,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:23,203 INFO:     Epoch: 70
2023-01-04 10:06:24,744 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.35824721654256186, 'Total loss': 0.35824721654256186} | train loss {'Reaction outcome loss': 0.27557991123397413, 'Total loss': 0.27557991123397413}
2023-01-04 10:06:24,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:24,744 INFO:     Epoch: 71
2023-01-04 10:06:26,321 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3342193971077601, 'Total loss': 0.3342193971077601} | train loss {'Reaction outcome loss': 0.2716150856216015, 'Total loss': 0.2716150856216015}
2023-01-04 10:06:26,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:26,322 INFO:     Epoch: 72
2023-01-04 10:06:27,856 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3555861900250117, 'Total loss': 0.3555861900250117} | train loss {'Reaction outcome loss': 0.26760289578860097, 'Total loss': 0.26760289578860097}
2023-01-04 10:06:27,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:27,856 INFO:     Epoch: 73
2023-01-04 10:06:29,435 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.33890383690595627, 'Total loss': 0.33890383690595627} | train loss {'Reaction outcome loss': 0.2686677834919458, 'Total loss': 0.2686677834919458}
2023-01-04 10:06:29,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:29,435 INFO:     Epoch: 74
2023-01-04 10:06:31,018 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3376698603232702, 'Total loss': 0.3376698603232702} | train loss {'Reaction outcome loss': 0.26463885080220517, 'Total loss': 0.26463885080220517}
2023-01-04 10:06:31,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:31,018 INFO:     Epoch: 75
2023-01-04 10:06:32,608 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3821797490119934, 'Total loss': 0.3821797490119934} | train loss {'Reaction outcome loss': 0.2642543066251762, 'Total loss': 0.2642543066251762}
2023-01-04 10:06:32,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:32,608 INFO:     Epoch: 76
2023-01-04 10:06:34,157 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3398374577363332, 'Total loss': 0.3398374577363332} | train loss {'Reaction outcome loss': 0.266228697355493, 'Total loss': 0.266228697355493}
2023-01-04 10:06:34,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:34,158 INFO:     Epoch: 77
2023-01-04 10:06:35,753 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3744828750689824, 'Total loss': 0.3744828750689824} | train loss {'Reaction outcome loss': 0.26353425411610587, 'Total loss': 0.26353425411610587}
2023-01-04 10:06:35,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:35,753 INFO:     Epoch: 78
2023-01-04 10:06:37,313 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.34215860267480214, 'Total loss': 0.34215860267480214} | train loss {'Reaction outcome loss': 0.25871331650227636, 'Total loss': 0.25871331650227636}
2023-01-04 10:06:37,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:37,313 INFO:     Epoch: 79
2023-01-04 10:06:38,900 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.370080973704656, 'Total loss': 0.370080973704656} | train loss {'Reaction outcome loss': 0.25798346979261766, 'Total loss': 0.25798346979261766}
2023-01-04 10:06:38,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:38,900 INFO:     Epoch: 80
2023-01-04 10:06:40,479 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.31784463226795195, 'Total loss': 0.31784463226795195} | train loss {'Reaction outcome loss': 0.2581305543160087, 'Total loss': 0.2581305543160087}
2023-01-04 10:06:40,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:40,479 INFO:     Epoch: 81
2023-01-04 10:06:42,067 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3256265252828598, 'Total loss': 0.3256265252828598} | train loss {'Reaction outcome loss': 0.2623312468760788, 'Total loss': 0.2623312468760788}
2023-01-04 10:06:42,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:42,067 INFO:     Epoch: 82
2023-01-04 10:06:43,613 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.35129463076591494, 'Total loss': 0.35129463076591494} | train loss {'Reaction outcome loss': 0.2573031552300902, 'Total loss': 0.2573031552300902}
2023-01-04 10:06:43,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:43,613 INFO:     Epoch: 83
2023-01-04 10:06:45,176 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3467807829380035, 'Total loss': 0.3467807829380035} | train loss {'Reaction outcome loss': 0.25169192548717517, 'Total loss': 0.25169192548717517}
2023-01-04 10:06:45,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:45,176 INFO:     Epoch: 84
2023-01-04 10:06:46,745 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.34078641136487325, 'Total loss': 0.34078641136487325} | train loss {'Reaction outcome loss': 0.2568483944033785, 'Total loss': 0.2568483944033785}
2023-01-04 10:06:46,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:46,746 INFO:     Epoch: 85
2023-01-04 10:06:48,341 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.35834808958073455, 'Total loss': 0.35834808958073455} | train loss {'Reaction outcome loss': 0.25575120747089386, 'Total loss': 0.25575120747089386}
2023-01-04 10:06:48,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:48,341 INFO:     Epoch: 86
2023-01-04 10:06:49,938 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3746535062789917, 'Total loss': 0.3746535062789917} | train loss {'Reaction outcome loss': 0.25076943271659397, 'Total loss': 0.25076943271659397}
2023-01-04 10:06:49,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:49,939 INFO:     Epoch: 87
2023-01-04 10:06:51,484 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.36126862665017445, 'Total loss': 0.36126862665017445} | train loss {'Reaction outcome loss': 0.25278074552762114, 'Total loss': 0.25278074552762114}
2023-01-04 10:06:51,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:51,484 INFO:     Epoch: 88
2023-01-04 10:06:53,070 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3516692837079366, 'Total loss': 0.3516692837079366} | train loss {'Reaction outcome loss': 0.2528007499928624, 'Total loss': 0.2528007499928624}
2023-01-04 10:06:53,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:53,071 INFO:     Epoch: 89
2023-01-04 10:06:54,599 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3523807505766551, 'Total loss': 0.3523807505766551} | train loss {'Reaction outcome loss': 0.24557723498102485, 'Total loss': 0.24557723498102485}
2023-01-04 10:06:54,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:54,599 INFO:     Epoch: 90
2023-01-04 10:06:56,178 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.33671197096506755, 'Total loss': 0.33671197096506755} | train loss {'Reaction outcome loss': 0.25163263540261344, 'Total loss': 0.25163263540261344}
2023-01-04 10:06:56,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:56,178 INFO:     Epoch: 91
2023-01-04 10:06:57,700 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3813623289267222, 'Total loss': 0.3813623289267222} | train loss {'Reaction outcome loss': 0.24463250144381365, 'Total loss': 0.24463250144381365}
2023-01-04 10:06:57,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:57,700 INFO:     Epoch: 92
2023-01-04 10:06:59,231 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37069082458813984, 'Total loss': 0.37069082458813984} | train loss {'Reaction outcome loss': 0.24694772272257348, 'Total loss': 0.24694772272257348}
2023-01-04 10:06:59,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:06:59,231 INFO:     Epoch: 93
2023-01-04 10:07:00,735 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.33211123645305635, 'Total loss': 0.33211123645305635} | train loss {'Reaction outcome loss': 0.24343927075392205, 'Total loss': 0.24343927075392205}
2023-01-04 10:07:00,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:00,735 INFO:     Epoch: 94
2023-01-04 10:07:02,260 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3697011878093084, 'Total loss': 0.3697011878093084} | train loss {'Reaction outcome loss': 0.2454385019123994, 'Total loss': 0.2454385019123994}
2023-01-04 10:07:02,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:02,260 INFO:     Epoch: 95
2023-01-04 10:07:03,764 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3279062007864316, 'Total loss': 0.3279062007864316} | train loss {'Reaction outcome loss': 0.24559187795623202, 'Total loss': 0.24559187795623202}
2023-01-04 10:07:03,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:03,764 INFO:     Epoch: 96
2023-01-04 10:07:05,304 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3304428701599439, 'Total loss': 0.3304428701599439} | train loss {'Reaction outcome loss': 0.24426355288532386, 'Total loss': 0.24426355288532386}
2023-01-04 10:07:05,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:05,305 INFO:     Epoch: 97
2023-01-04 10:07:06,843 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40129134654998777, 'Total loss': 0.40129134654998777} | train loss {'Reaction outcome loss': 0.24148265012570852, 'Total loss': 0.24148265012570852}
2023-01-04 10:07:06,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:06,844 INFO:     Epoch: 98
2023-01-04 10:07:08,359 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37548277378082273, 'Total loss': 0.37548277378082273} | train loss {'Reaction outcome loss': 0.24557994545275874, 'Total loss': 0.24557994545275874}
2023-01-04 10:07:08,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:08,360 INFO:     Epoch: 99
2023-01-04 10:07:09,871 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.32434219817320503, 'Total loss': 0.32434219817320503} | train loss {'Reaction outcome loss': 0.23975747851208126, 'Total loss': 0.23975747851208126}
2023-01-04 10:07:09,872 INFO:     Best model found after epoch 53 of 100.
2023-01-04 10:07:09,872 INFO:   Done with stage: TRAINING
2023-01-04 10:07:09,872 INFO:   Starting stage: EVALUATION
2023-01-04 10:07:10,015 INFO:   Done with stage: EVALUATION
2023-01-04 10:07:10,015 INFO:   Leaving out SEQ value Fold_4
2023-01-04 10:07:10,028 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 10:07:10,028 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:07:10,680 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:07:10,680 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:07:10,748 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:07:10,748 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:07:10,748 INFO:     No hyperparam tuning for this model
2023-01-04 10:07:10,748 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:07:10,748 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:07:10,749 INFO:     None feature selector for col prot
2023-01-04 10:07:10,749 INFO:     None feature selector for col prot
2023-01-04 10:07:10,749 INFO:     None feature selector for col prot
2023-01-04 10:07:10,750 INFO:     None feature selector for col chem
2023-01-04 10:07:10,750 INFO:     None feature selector for col chem
2023-01-04 10:07:10,750 INFO:     None feature selector for col chem
2023-01-04 10:07:10,750 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:07:10,750 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:07:10,751 INFO:     Number of params in model 70111
2023-01-04 10:07:10,754 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:07:10,754 INFO:   Starting stage: TRAINING
2023-01-04 10:07:10,797 INFO:     Val loss before train {'Reaction outcome loss': 1.0813486576080322, 'Total loss': 1.0813486576080322}
2023-01-04 10:07:10,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:10,797 INFO:     Epoch: 0
2023-01-04 10:07:12,327 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.801872718334198, 'Total loss': 0.801872718334198} | train loss {'Reaction outcome loss': 0.8569712879649107, 'Total loss': 0.8569712879649107}
2023-01-04 10:07:12,327 INFO:     Found new best model at epoch 0
2023-01-04 10:07:12,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:12,327 INFO:     Epoch: 1
2023-01-04 10:07:13,893 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.613886833190918, 'Total loss': 0.613886833190918} | train loss {'Reaction outcome loss': 0.6826399131745532, 'Total loss': 0.6826399131745532}
2023-01-04 10:07:13,893 INFO:     Found new best model at epoch 1
2023-01-04 10:07:13,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:13,894 INFO:     Epoch: 2
2023-01-04 10:07:15,456 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5344095369180043, 'Total loss': 0.5344095369180043} | train loss {'Reaction outcome loss': 0.5733007505549577, 'Total loss': 0.5733007505549577}
2023-01-04 10:07:15,456 INFO:     Found new best model at epoch 2
2023-01-04 10:07:15,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:15,457 INFO:     Epoch: 3
2023-01-04 10:07:17,024 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4924452781677246, 'Total loss': 0.4924452781677246} | train loss {'Reaction outcome loss': 0.5320833496570481, 'Total loss': 0.5320833496570481}
2023-01-04 10:07:17,025 INFO:     Found new best model at epoch 3
2023-01-04 10:07:17,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:17,026 INFO:     Epoch: 4
2023-01-04 10:07:18,449 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4948495050271352, 'Total loss': 0.4948495050271352} | train loss {'Reaction outcome loss': 0.5130254855730395, 'Total loss': 0.5130254855730395}
2023-01-04 10:07:18,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:18,449 INFO:     Epoch: 5
2023-01-04 10:07:19,473 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49241536657015483, 'Total loss': 0.49241536657015483} | train loss {'Reaction outcome loss': 0.5007204451341776, 'Total loss': 0.5007204451341776}
2023-01-04 10:07:19,473 INFO:     Found new best model at epoch 5
2023-01-04 10:07:19,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:19,474 INFO:     Epoch: 6
2023-01-04 10:07:20,506 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4669859170913696, 'Total loss': 0.4669859170913696} | train loss {'Reaction outcome loss': 0.48782891436544096, 'Total loss': 0.48782891436544096}
2023-01-04 10:07:20,506 INFO:     Found new best model at epoch 6
2023-01-04 10:07:20,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:20,507 INFO:     Epoch: 7
2023-01-04 10:07:21,521 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4747116138537725, 'Total loss': 0.4747116138537725} | train loss {'Reaction outcome loss': 0.48400741447762086, 'Total loss': 0.48400741447762086}
2023-01-04 10:07:21,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:21,522 INFO:     Epoch: 8
2023-01-04 10:07:22,534 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4516081194082896, 'Total loss': 0.4516081194082896} | train loss {'Reaction outcome loss': 0.47192924193481356, 'Total loss': 0.47192924193481356}
2023-01-04 10:07:22,535 INFO:     Found new best model at epoch 8
2023-01-04 10:07:22,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:22,535 INFO:     Epoch: 9
2023-01-04 10:07:23,956 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4516687750816345, 'Total loss': 0.4516687750816345} | train loss {'Reaction outcome loss': 0.4655980964707587, 'Total loss': 0.4655980964707587}
2023-01-04 10:07:23,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:23,957 INFO:     Epoch: 10
2023-01-04 10:07:25,510 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4761657416820526, 'Total loss': 0.4761657416820526} | train loss {'Reaction outcome loss': 0.459262276967596, 'Total loss': 0.459262276967596}
2023-01-04 10:07:25,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:25,510 INFO:     Epoch: 11
2023-01-04 10:07:27,061 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.463917734225591, 'Total loss': 0.463917734225591} | train loss {'Reaction outcome loss': 0.45696718613570725, 'Total loss': 0.45696718613570725}
2023-01-04 10:07:27,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:27,062 INFO:     Epoch: 12
2023-01-04 10:07:28,589 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46023941139380137, 'Total loss': 0.46023941139380137} | train loss {'Reaction outcome loss': 0.4539462844098824, 'Total loss': 0.4539462844098824}
2023-01-04 10:07:28,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:28,589 INFO:     Epoch: 13
2023-01-04 10:07:30,131 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43748243153095245, 'Total loss': 0.43748243153095245} | train loss {'Reaction outcome loss': 0.44942130780090456, 'Total loss': 0.44942130780090456}
2023-01-04 10:07:30,131 INFO:     Found new best model at epoch 13
2023-01-04 10:07:30,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:30,132 INFO:     Epoch: 14
2023-01-04 10:07:31,678 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42900352279345194, 'Total loss': 0.42900352279345194} | train loss {'Reaction outcome loss': 0.46190931658813916, 'Total loss': 0.46190931658813916}
2023-01-04 10:07:31,678 INFO:     Found new best model at epoch 14
2023-01-04 10:07:31,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:31,678 INFO:     Epoch: 15
2023-01-04 10:07:33,199 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45900996724764503, 'Total loss': 0.45900996724764503} | train loss {'Reaction outcome loss': 0.4444777157623321, 'Total loss': 0.4444777157623321}
2023-01-04 10:07:33,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:33,200 INFO:     Epoch: 16
2023-01-04 10:07:34,738 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42234048843383787, 'Total loss': 0.42234048843383787} | train loss {'Reaction outcome loss': 0.43404177180828823, 'Total loss': 0.43404177180828823}
2023-01-04 10:07:34,738 INFO:     Found new best model at epoch 16
2023-01-04 10:07:34,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:34,739 INFO:     Epoch: 17
2023-01-04 10:07:36,280 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4208223621050517, 'Total loss': 0.4208223621050517} | train loss {'Reaction outcome loss': 0.42911546995215444, 'Total loss': 0.42911546995215444}
2023-01-04 10:07:36,281 INFO:     Found new best model at epoch 17
2023-01-04 10:07:36,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:36,281 INFO:     Epoch: 18
2023-01-04 10:07:37,804 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44093862374623616, 'Total loss': 0.44093862374623616} | train loss {'Reaction outcome loss': 0.42998985660792177, 'Total loss': 0.42998985660792177}
2023-01-04 10:07:37,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:37,804 INFO:     Epoch: 19
2023-01-04 10:07:39,353 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4535715192556381, 'Total loss': 0.4535715192556381} | train loss {'Reaction outcome loss': 0.42383158169428975, 'Total loss': 0.42383158169428975}
2023-01-04 10:07:39,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:39,354 INFO:     Epoch: 20
2023-01-04 10:07:40,898 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4091779882709185, 'Total loss': 0.4091779882709185} | train loss {'Reaction outcome loss': 0.4208517427137796, 'Total loss': 0.4208517427137796}
2023-01-04 10:07:40,898 INFO:     Found new best model at epoch 20
2023-01-04 10:07:40,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:40,899 INFO:     Epoch: 21
2023-01-04 10:07:42,428 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4317375123500824, 'Total loss': 0.4317375123500824} | train loss {'Reaction outcome loss': 0.4200298624734084, 'Total loss': 0.4200298624734084}
2023-01-04 10:07:42,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:42,428 INFO:     Epoch: 22
2023-01-04 10:07:43,980 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41497484147548674, 'Total loss': 0.41497484147548674} | train loss {'Reaction outcome loss': 0.42122717663321807, 'Total loss': 0.42122717663321807}
2023-01-04 10:07:43,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:43,980 INFO:     Epoch: 23
2023-01-04 10:07:45,555 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4277873953183492, 'Total loss': 0.4277873953183492} | train loss {'Reaction outcome loss': 0.4136263373360885, 'Total loss': 0.4136263373360885}
2023-01-04 10:07:45,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:45,555 INFO:     Epoch: 24
2023-01-04 10:07:47,062 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41273314754168194, 'Total loss': 0.41273314754168194} | train loss {'Reaction outcome loss': 0.41647088506083557, 'Total loss': 0.41647088506083557}
2023-01-04 10:07:47,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:47,063 INFO:     Epoch: 25
2023-01-04 10:07:48,617 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4243445426225662, 'Total loss': 0.4243445426225662} | train loss {'Reaction outcome loss': 0.4244069125017394, 'Total loss': 0.4244069125017394}
2023-01-04 10:07:48,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:48,618 INFO:     Epoch: 26
2023-01-04 10:07:50,156 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4377261916796366, 'Total loss': 0.4377261916796366} | train loss {'Reaction outcome loss': 0.4164115962019001, 'Total loss': 0.4164115962019001}
2023-01-04 10:07:50,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:50,156 INFO:     Epoch: 27
2023-01-04 10:07:51,744 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4205215970675151, 'Total loss': 0.4205215970675151} | train loss {'Reaction outcome loss': 0.414428217606484, 'Total loss': 0.414428217606484}
2023-01-04 10:07:51,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:51,745 INFO:     Epoch: 28
2023-01-04 10:07:53,342 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4282672961552938, 'Total loss': 0.4282672961552938} | train loss {'Reaction outcome loss': 0.4323442048676636, 'Total loss': 0.4323442048676636}
2023-01-04 10:07:53,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:53,342 INFO:     Epoch: 29
2023-01-04 10:07:54,893 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4237422853708267, 'Total loss': 0.4237422853708267} | train loss {'Reaction outcome loss': 0.40532770079216396, 'Total loss': 0.40532770079216396}
2023-01-04 10:07:54,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:54,894 INFO:     Epoch: 30
2023-01-04 10:07:56,473 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41081679811080296, 'Total loss': 0.41081679811080296} | train loss {'Reaction outcome loss': 0.39286185045173205, 'Total loss': 0.39286185045173205}
2023-01-04 10:07:56,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:56,473 INFO:     Epoch: 31
2023-01-04 10:07:58,049 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41130250493685405, 'Total loss': 0.41130250493685405} | train loss {'Reaction outcome loss': 0.3973735646324475, 'Total loss': 0.3973735646324475}
2023-01-04 10:07:58,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:58,050 INFO:     Epoch: 32
2023-01-04 10:07:59,609 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4001394048333168, 'Total loss': 0.4001394048333168} | train loss {'Reaction outcome loss': 0.38655737698402093, 'Total loss': 0.38655737698402093}
2023-01-04 10:07:59,609 INFO:     Found new best model at epoch 32
2023-01-04 10:07:59,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:07:59,610 INFO:     Epoch: 33
2023-01-04 10:08:01,186 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38977644642194115, 'Total loss': 0.38977644642194115} | train loss {'Reaction outcome loss': 0.3829215140608342, 'Total loss': 0.3829215140608342}
2023-01-04 10:08:01,186 INFO:     Found new best model at epoch 33
2023-01-04 10:08:01,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:01,187 INFO:     Epoch: 34
2023-01-04 10:08:02,773 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39832510749499, 'Total loss': 0.39832510749499} | train loss {'Reaction outcome loss': 0.37969445956147957, 'Total loss': 0.37969445956147957}
2023-01-04 10:08:02,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:02,773 INFO:     Epoch: 35
2023-01-04 10:08:04,300 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4072558383146922, 'Total loss': 0.4072558383146922} | train loss {'Reaction outcome loss': 0.37926521106029226, 'Total loss': 0.37926521106029226}
2023-01-04 10:08:04,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:04,301 INFO:     Epoch: 36
2023-01-04 10:08:05,859 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3796386127670606, 'Total loss': 0.3796386127670606} | train loss {'Reaction outcome loss': 0.3790233785092942, 'Total loss': 0.3790233785092942}
2023-01-04 10:08:05,859 INFO:     Found new best model at epoch 36
2023-01-04 10:08:05,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:05,860 INFO:     Epoch: 37
2023-01-04 10:08:07,453 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44337753852208456, 'Total loss': 0.44337753852208456} | train loss {'Reaction outcome loss': 0.3874705161737359, 'Total loss': 0.3874705161737359}
2023-01-04 10:08:07,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:07,454 INFO:     Epoch: 38
2023-01-04 10:08:09,011 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39866375078757604, 'Total loss': 0.39866375078757604} | train loss {'Reaction outcome loss': 0.39658657145396253, 'Total loss': 0.39658657145396253}
2023-01-04 10:08:09,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:09,012 INFO:     Epoch: 39
2023-01-04 10:08:10,567 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41255748371283213, 'Total loss': 0.41255748371283213} | train loss {'Reaction outcome loss': 0.36961881201579305, 'Total loss': 0.36961881201579305}
2023-01-04 10:08:10,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:10,568 INFO:     Epoch: 40
2023-01-04 10:08:12,139 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39473013977209725, 'Total loss': 0.39473013977209725} | train loss {'Reaction outcome loss': 0.3651472840840301, 'Total loss': 0.3651472840840301}
2023-01-04 10:08:12,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:12,140 INFO:     Epoch: 41
2023-01-04 10:08:13,659 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40524451111753784, 'Total loss': 0.40524451111753784} | train loss {'Reaction outcome loss': 0.36216547011154826, 'Total loss': 0.36216547011154826}
2023-01-04 10:08:13,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:13,659 INFO:     Epoch: 42
2023-01-04 10:08:15,254 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3724004030227661, 'Total loss': 0.3724004030227661} | train loss {'Reaction outcome loss': 0.3591065314206956, 'Total loss': 0.3591065314206956}
2023-01-04 10:08:15,254 INFO:     Found new best model at epoch 42
2023-01-04 10:08:15,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:15,255 INFO:     Epoch: 43
2023-01-04 10:08:16,811 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3883878191312154, 'Total loss': 0.3883878191312154} | train loss {'Reaction outcome loss': 0.3595283908399996, 'Total loss': 0.3595283908399996}
2023-01-04 10:08:16,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:16,811 INFO:     Epoch: 44
2023-01-04 10:08:18,354 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42713438868522646, 'Total loss': 0.42713438868522646} | train loss {'Reaction outcome loss': 0.3516522181976209, 'Total loss': 0.3516522181976209}
2023-01-04 10:08:18,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:18,354 INFO:     Epoch: 45
2023-01-04 10:08:19,923 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38414035240809125, 'Total loss': 0.38414035240809125} | train loss {'Reaction outcome loss': 0.35704124207626114, 'Total loss': 0.35704124207626114}
2023-01-04 10:08:19,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:19,924 INFO:     Epoch: 46
2023-01-04 10:08:21,495 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3998559206724167, 'Total loss': 0.3998559206724167} | train loss {'Reaction outcome loss': 0.34764220557459025, 'Total loss': 0.34764220557459025}
2023-01-04 10:08:21,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:21,495 INFO:     Epoch: 47
2023-01-04 10:08:23,022 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3922409156958262, 'Total loss': 0.3922409156958262} | train loss {'Reaction outcome loss': 0.3469338994321999, 'Total loss': 0.3469338994321999}
2023-01-04 10:08:23,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:23,022 INFO:     Epoch: 48
2023-01-04 10:08:24,568 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3863526980082194, 'Total loss': 0.3863526980082194} | train loss {'Reaction outcome loss': 0.34492142950994487, 'Total loss': 0.34492142950994487}
2023-01-04 10:08:24,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:24,569 INFO:     Epoch: 49
2023-01-04 10:08:26,122 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40743321776390073, 'Total loss': 0.40743321776390073} | train loss {'Reaction outcome loss': 0.3391119595153082, 'Total loss': 0.3391119595153082}
2023-01-04 10:08:26,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:26,122 INFO:     Epoch: 50
2023-01-04 10:08:27,641 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38426667749881743, 'Total loss': 0.38426667749881743} | train loss {'Reaction outcome loss': 0.3502606514679349, 'Total loss': 0.3502606514679349}
2023-01-04 10:08:27,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:27,641 INFO:     Epoch: 51
2023-01-04 10:08:29,190 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42285839716593426, 'Total loss': 0.42285839716593426} | train loss {'Reaction outcome loss': 0.3905310990369838, 'Total loss': 0.3905310990369838}
2023-01-04 10:08:29,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:29,190 INFO:     Epoch: 52
2023-01-04 10:08:30,752 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39608275691668193, 'Total loss': 0.39608275691668193} | train loss {'Reaction outcome loss': 0.35109430312624446, 'Total loss': 0.35109430312624446}
2023-01-04 10:08:30,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:30,753 INFO:     Epoch: 53
2023-01-04 10:08:32,290 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47242894570032756, 'Total loss': 0.47242894570032756} | train loss {'Reaction outcome loss': 0.3489380578469971, 'Total loss': 0.3489380578469971}
2023-01-04 10:08:32,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:32,290 INFO:     Epoch: 54
2023-01-04 10:08:33,848 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39331830938657125, 'Total loss': 0.39331830938657125} | train loss {'Reaction outcome loss': 0.38759277164396166, 'Total loss': 0.38759277164396166}
2023-01-04 10:08:33,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:33,848 INFO:     Epoch: 55
2023-01-04 10:08:35,438 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37213708460330963, 'Total loss': 0.37213708460330963} | train loss {'Reaction outcome loss': 0.3304841517566946, 'Total loss': 0.3304841517566946}
2023-01-04 10:08:35,438 INFO:     Found new best model at epoch 55
2023-01-04 10:08:35,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:35,439 INFO:     Epoch: 56
2023-01-04 10:08:36,972 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.373071093360583, 'Total loss': 0.373071093360583} | train loss {'Reaction outcome loss': 0.3310982890777624, 'Total loss': 0.3310982890777624}
2023-01-04 10:08:36,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:36,972 INFO:     Epoch: 57
2023-01-04 10:08:38,530 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37610777020454406, 'Total loss': 0.37610777020454406} | train loss {'Reaction outcome loss': 0.3265089259785136, 'Total loss': 0.3265089259785136}
2023-01-04 10:08:38,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:38,530 INFO:     Epoch: 58
2023-01-04 10:08:40,097 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3911664247512817, 'Total loss': 0.3911664247512817} | train loss {'Reaction outcome loss': 0.32534267337641853, 'Total loss': 0.32534267337641853}
2023-01-04 10:08:40,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:40,097 INFO:     Epoch: 59
2023-01-04 10:08:41,616 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38618837893009184, 'Total loss': 0.38618837893009184} | train loss {'Reaction outcome loss': 0.32316610093387327, 'Total loss': 0.32316610093387327}
2023-01-04 10:08:41,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:41,616 INFO:     Epoch: 60
2023-01-04 10:08:43,170 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37768401503562926, 'Total loss': 0.37768401503562926} | train loss {'Reaction outcome loss': 0.3238822760303383, 'Total loss': 0.3238822760303383}
2023-01-04 10:08:43,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:43,170 INFO:     Epoch: 61
2023-01-04 10:08:44,698 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3823689455787341, 'Total loss': 0.3823689455787341} | train loss {'Reaction outcome loss': 0.329784827074036, 'Total loss': 0.329784827074036}
2023-01-04 10:08:44,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:44,698 INFO:     Epoch: 62
2023-01-04 10:08:46,243 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3712894668181737, 'Total loss': 0.3712894668181737} | train loss {'Reaction outcome loss': 0.3159199691769006, 'Total loss': 0.3159199691769006}
2023-01-04 10:08:46,243 INFO:     Found new best model at epoch 62
2023-01-04 10:08:46,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:46,244 INFO:     Epoch: 63
2023-01-04 10:08:47,813 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3909161567687988, 'Total loss': 0.3909161567687988} | train loss {'Reaction outcome loss': 0.3221455214788084, 'Total loss': 0.3221455214788084}
2023-01-04 10:08:47,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:47,813 INFO:     Epoch: 64
2023-01-04 10:08:49,376 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3874421606461207, 'Total loss': 0.3874421606461207} | train loss {'Reaction outcome loss': 0.3197889983850895, 'Total loss': 0.3197889983850895}
2023-01-04 10:08:49,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:49,376 INFO:     Epoch: 65
2023-01-04 10:08:50,925 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41916214327017465, 'Total loss': 0.41916214327017465} | train loss {'Reaction outcome loss': 0.3117978484302327, 'Total loss': 0.3117978484302327}
2023-01-04 10:08:50,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:50,925 INFO:     Epoch: 66
2023-01-04 10:08:52,507 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3881926874319712, 'Total loss': 0.3881926874319712} | train loss {'Reaction outcome loss': 0.3229966387692569, 'Total loss': 0.3229966387692569}
2023-01-04 10:08:52,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:52,508 INFO:     Epoch: 67
2023-01-04 10:08:54,044 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38577811121940614, 'Total loss': 0.38577811121940614} | train loss {'Reaction outcome loss': 0.3265568325481634, 'Total loss': 0.3265568325481634}
2023-01-04 10:08:54,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:54,044 INFO:     Epoch: 68
2023-01-04 10:08:55,629 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3987175097068151, 'Total loss': 0.3987175097068151} | train loss {'Reaction outcome loss': 0.30961842228071357, 'Total loss': 0.30961842228071357}
2023-01-04 10:08:55,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:55,629 INFO:     Epoch: 69
2023-01-04 10:08:57,210 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41251594622929894, 'Total loss': 0.41251594622929894} | train loss {'Reaction outcome loss': 0.31071960560106876, 'Total loss': 0.31071960560106876}
2023-01-04 10:08:57,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:57,210 INFO:     Epoch: 70
2023-01-04 10:08:58,752 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38183924853801726, 'Total loss': 0.38183924853801726} | train loss {'Reaction outcome loss': 0.3057243420773665, 'Total loss': 0.3057243420773665}
2023-01-04 10:08:58,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:08:58,752 INFO:     Epoch: 71
2023-01-04 10:09:00,339 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3818196972211202, 'Total loss': 0.3818196972211202} | train loss {'Reaction outcome loss': 0.30135203119847365, 'Total loss': 0.30135203119847365}
2023-01-04 10:09:00,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:00,340 INFO:     Epoch: 72
2023-01-04 10:09:01,913 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3820864260196686, 'Total loss': 0.3820864260196686} | train loss {'Reaction outcome loss': 0.30038039119023346, 'Total loss': 0.30038039119023346}
2023-01-04 10:09:01,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:01,913 INFO:     Epoch: 73
2023-01-04 10:09:03,441 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39718855122725166, 'Total loss': 0.39718855122725166} | train loss {'Reaction outcome loss': 0.3121119252823321, 'Total loss': 0.3121119252823321}
2023-01-04 10:09:03,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:03,441 INFO:     Epoch: 74
2023-01-04 10:09:04,990 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37324938078721365, 'Total loss': 0.37324938078721365} | train loss {'Reaction outcome loss': 0.3029817758428365, 'Total loss': 0.3029817758428365}
2023-01-04 10:09:04,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:04,990 INFO:     Epoch: 75
2023-01-04 10:09:06,560 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4445584535598755, 'Total loss': 0.4445584535598755} | train loss {'Reaction outcome loss': 0.3030543240948, 'Total loss': 0.3030543240948}
2023-01-04 10:09:06,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:06,561 INFO:     Epoch: 76
2023-01-04 10:09:08,140 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39224102795124055, 'Total loss': 0.39224102795124055} | train loss {'Reaction outcome loss': 0.32284924777501356, 'Total loss': 0.32284924777501356}
2023-01-04 10:09:08,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:08,141 INFO:     Epoch: 77
2023-01-04 10:09:09,709 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37205418646335603, 'Total loss': 0.37205418646335603} | train loss {'Reaction outcome loss': 0.29925291601724946, 'Total loss': 0.29925291601724946}
2023-01-04 10:09:09,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:09,709 INFO:     Epoch: 78
2023-01-04 10:09:11,292 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4007258375485738, 'Total loss': 0.4007258375485738} | train loss {'Reaction outcome loss': 0.2996768579143753, 'Total loss': 0.2996768579143753}
2023-01-04 10:09:11,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:11,293 INFO:     Epoch: 79
2023-01-04 10:09:12,811 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3787051200866699, 'Total loss': 0.3787051200866699} | train loss {'Reaction outcome loss': 0.29367258992262074, 'Total loss': 0.29367258992262074}
2023-01-04 10:09:12,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:12,811 INFO:     Epoch: 80
2023-01-04 10:09:14,390 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3790512541929881, 'Total loss': 0.3790512541929881} | train loss {'Reaction outcome loss': 0.2911878521527546, 'Total loss': 0.2911878521527546}
2023-01-04 10:09:14,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:14,390 INFO:     Epoch: 81
2023-01-04 10:09:15,961 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3828411748011907, 'Total loss': 0.3828411748011907} | train loss {'Reaction outcome loss': 0.2913844439241549, 'Total loss': 0.2913844439241549}
2023-01-04 10:09:15,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:15,962 INFO:     Epoch: 82
2023-01-04 10:09:17,511 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3750084986289342, 'Total loss': 0.3750084986289342} | train loss {'Reaction outcome loss': 0.294720684189562, 'Total loss': 0.294720684189562}
2023-01-04 10:09:17,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:17,511 INFO:     Epoch: 83
2023-01-04 10:09:19,093 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4079282810290655, 'Total loss': 0.4079282810290655} | train loss {'Reaction outcome loss': 0.28796558642415737, 'Total loss': 0.28796558642415737}
2023-01-04 10:09:19,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:19,094 INFO:     Epoch: 84
2023-01-04 10:09:20,682 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3940675914287567, 'Total loss': 0.3940675914287567} | train loss {'Reaction outcome loss': 0.2908782792763542, 'Total loss': 0.2908782792763542}
2023-01-04 10:09:20,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:20,682 INFO:     Epoch: 85
2023-01-04 10:09:22,229 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38202250401178994, 'Total loss': 0.38202250401178994} | train loss {'Reaction outcome loss': 0.2897288602493379, 'Total loss': 0.2897288602493379}
2023-01-04 10:09:22,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:22,229 INFO:     Epoch: 86
2023-01-04 10:09:23,807 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.369149241844813, 'Total loss': 0.369149241844813} | train loss {'Reaction outcome loss': 0.2844865686948533, 'Total loss': 0.2844865686948533}
2023-01-04 10:09:23,807 INFO:     Found new best model at epoch 86
2023-01-04 10:09:23,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:23,808 INFO:     Epoch: 87
2023-01-04 10:09:25,382 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38140725791454316, 'Total loss': 0.38140725791454316} | train loss {'Reaction outcome loss': 0.2834678818134294, 'Total loss': 0.2834678818134294}
2023-01-04 10:09:25,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:25,382 INFO:     Epoch: 88
2023-01-04 10:09:26,970 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38405906955401103, 'Total loss': 0.38405906955401103} | train loss {'Reaction outcome loss': 0.2802273405722572, 'Total loss': 0.2802273405722572}
2023-01-04 10:09:26,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:26,970 INFO:     Epoch: 89
2023-01-04 10:09:28,588 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39909904400507606, 'Total loss': 0.39909904400507606} | train loss {'Reaction outcome loss': 0.28058291661369184, 'Total loss': 0.28058291661369184}
2023-01-04 10:09:28,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:28,589 INFO:     Epoch: 90
2023-01-04 10:09:30,208 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.37708304127057396, 'Total loss': 0.37708304127057396} | train loss {'Reaction outcome loss': 0.28000567680388433, 'Total loss': 0.28000567680388433}
2023-01-04 10:09:30,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:30,208 INFO:     Epoch: 91
2023-01-04 10:09:31,795 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3719077875216802, 'Total loss': 0.3719077875216802} | train loss {'Reaction outcome loss': 0.3039229341607163, 'Total loss': 0.3039229341607163}
2023-01-04 10:09:31,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:31,795 INFO:     Epoch: 92
2023-01-04 10:09:33,413 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3987503667672475, 'Total loss': 0.3987503667672475} | train loss {'Reaction outcome loss': 0.28471373844945774, 'Total loss': 0.28471373844945774}
2023-01-04 10:09:33,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:33,413 INFO:     Epoch: 93
2023-01-04 10:09:34,996 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38778095245361327, 'Total loss': 0.38778095245361327} | train loss {'Reaction outcome loss': 0.2917467225030861, 'Total loss': 0.2917467225030861}
2023-01-04 10:09:34,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:34,997 INFO:     Epoch: 94
2023-01-04 10:09:36,636 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40148383180300395, 'Total loss': 0.40148383180300395} | train loss {'Reaction outcome loss': 0.27808826926933683, 'Total loss': 0.27808826926933683}
2023-01-04 10:09:36,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:36,636 INFO:     Epoch: 95
2023-01-04 10:09:38,282 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40414925416310626, 'Total loss': 0.40414925416310626} | train loss {'Reaction outcome loss': 0.2946421768570292, 'Total loss': 0.2946421768570292}
2023-01-04 10:09:38,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:38,283 INFO:     Epoch: 96
2023-01-04 10:09:39,893 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39335563282171887, 'Total loss': 0.39335563282171887} | train loss {'Reaction outcome loss': 0.27551914422192436, 'Total loss': 0.27551914422192436}
2023-01-04 10:09:39,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:39,894 INFO:     Epoch: 97
2023-01-04 10:09:41,546 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36797790626684823, 'Total loss': 0.36797790626684823} | train loss {'Reaction outcome loss': 0.2793404251267244, 'Total loss': 0.2793404251267244}
2023-01-04 10:09:41,546 INFO:     Found new best model at epoch 97
2023-01-04 10:09:41,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:41,548 INFO:     Epoch: 98
2023-01-04 10:09:43,211 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39008533855279287, 'Total loss': 0.39008533855279287} | train loss {'Reaction outcome loss': 0.27062106410554354, 'Total loss': 0.27062106410554354}
2023-01-04 10:09:43,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:43,211 INFO:     Epoch: 99
2023-01-04 10:09:44,852 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3858916034301122, 'Total loss': 0.3858916034301122} | train loss {'Reaction outcome loss': 0.2696499984999916, 'Total loss': 0.2696499984999916}
2023-01-04 10:09:44,852 INFO:     Best model found after epoch 98 of 100.
2023-01-04 10:09:44,853 INFO:   Done with stage: TRAINING
2023-01-04 10:09:44,853 INFO:   Starting stage: EVALUATION
2023-01-04 10:09:44,998 INFO:   Done with stage: EVALUATION
2023-01-04 10:09:44,999 INFO:   Leaving out SEQ value Fold_5
2023-01-04 10:09:45,012 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 10:09:45,012 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:09:45,714 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:09:45,714 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:09:45,792 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:09:45,792 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:09:45,792 INFO:     No hyperparam tuning for this model
2023-01-04 10:09:45,792 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:09:45,792 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:09:45,793 INFO:     None feature selector for col prot
2023-01-04 10:09:45,793 INFO:     None feature selector for col prot
2023-01-04 10:09:45,793 INFO:     None feature selector for col prot
2023-01-04 10:09:45,794 INFO:     None feature selector for col chem
2023-01-04 10:09:45,794 INFO:     None feature selector for col chem
2023-01-04 10:09:45,794 INFO:     None feature selector for col chem
2023-01-04 10:09:45,794 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:09:45,794 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:09:45,795 INFO:     Number of params in model 70111
2023-01-04 10:09:45,799 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:09:45,799 INFO:   Starting stage: TRAINING
2023-01-04 10:09:45,845 INFO:     Val loss before train {'Reaction outcome loss': 1.086195949713389, 'Total loss': 1.086195949713389}
2023-01-04 10:09:45,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:45,845 INFO:     Epoch: 0
2023-01-04 10:09:47,484 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.789654932419459, 'Total loss': 0.789654932419459} | train loss {'Reaction outcome loss': 0.8521969977604307, 'Total loss': 0.8521969977604307}
2023-01-04 10:09:47,484 INFO:     Found new best model at epoch 0
2023-01-04 10:09:47,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:47,486 INFO:     Epoch: 1
2023-01-04 10:09:49,088 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6509815394878388, 'Total loss': 0.6509815394878388} | train loss {'Reaction outcome loss': 0.6839707699111677, 'Total loss': 0.6839707699111677}
2023-01-04 10:09:49,088 INFO:     Found new best model at epoch 1
2023-01-04 10:09:49,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:49,089 INFO:     Epoch: 2
2023-01-04 10:09:50,716 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6262796084086101, 'Total loss': 0.6262796084086101} | train loss {'Reaction outcome loss': 0.5897259971762137, 'Total loss': 0.5897259971762137}
2023-01-04 10:09:50,716 INFO:     Found new best model at epoch 2
2023-01-04 10:09:50,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:50,717 INFO:     Epoch: 3
2023-01-04 10:09:52,368 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6298996726671855, 'Total loss': 0.6298996726671855} | train loss {'Reaction outcome loss': 0.556527617400971, 'Total loss': 0.556527617400971}
2023-01-04 10:09:52,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:52,368 INFO:     Epoch: 4
2023-01-04 10:09:53,981 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6084753413995106, 'Total loss': 0.6084753413995106} | train loss {'Reaction outcome loss': 0.5436023441118026, 'Total loss': 0.5436023441118026}
2023-01-04 10:09:53,981 INFO:     Found new best model at epoch 4
2023-01-04 10:09:53,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:53,983 INFO:     Epoch: 5
2023-01-04 10:09:55,618 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5440365493297576, 'Total loss': 0.5440365493297576} | train loss {'Reaction outcome loss': 0.5100353311779369, 'Total loss': 0.5100353311779369}
2023-01-04 10:09:55,618 INFO:     Found new best model at epoch 5
2023-01-04 10:09:55,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:55,620 INFO:     Epoch: 6
2023-01-04 10:09:57,280 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.558261348803838, 'Total loss': 0.558261348803838} | train loss {'Reaction outcome loss': 0.4971251388390859, 'Total loss': 0.4971251388390859}
2023-01-04 10:09:57,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:57,280 INFO:     Epoch: 7
2023-01-04 10:09:58,882 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5474047670761745, 'Total loss': 0.5474047670761745} | train loss {'Reaction outcome loss': 0.49414308804451773, 'Total loss': 0.49414308804451773}
2023-01-04 10:09:58,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:09:58,883 INFO:     Epoch: 8
2023-01-04 10:10:00,507 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5620887299378713, 'Total loss': 0.5620887299378713} | train loss {'Reaction outcome loss': 0.48404167700504913, 'Total loss': 0.48404167700504913}
2023-01-04 10:10:00,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:00,507 INFO:     Epoch: 9
2023-01-04 10:10:02,096 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5555527567863464, 'Total loss': 0.5555527567863464} | train loss {'Reaction outcome loss': 0.48631017185423686, 'Total loss': 0.48631017185423686}
2023-01-04 10:10:02,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:02,096 INFO:     Epoch: 10
2023-01-04 10:10:03,690 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5357517659664154, 'Total loss': 0.5357517659664154} | train loss {'Reaction outcome loss': 0.4662833566898885, 'Total loss': 0.4662833566898885}
2023-01-04 10:10:03,690 INFO:     Found new best model at epoch 10
2023-01-04 10:10:03,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:03,691 INFO:     Epoch: 11
2023-01-04 10:10:05,325 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.561813501516978, 'Total loss': 0.561813501516978} | train loss {'Reaction outcome loss': 0.46606667340814095, 'Total loss': 0.46606667340814095}
2023-01-04 10:10:05,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:05,326 INFO:     Epoch: 12
2023-01-04 10:10:06,907 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5275594532489777, 'Total loss': 0.5275594532489777} | train loss {'Reaction outcome loss': 0.4628970194068076, 'Total loss': 0.4628970194068076}
2023-01-04 10:10:06,907 INFO:     Found new best model at epoch 12
2023-01-04 10:10:06,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:06,908 INFO:     Epoch: 13
2023-01-04 10:10:08,447 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5244078288475672, 'Total loss': 0.5244078288475672} | train loss {'Reaction outcome loss': 0.45251708186676126, 'Total loss': 0.45251708186676126}
2023-01-04 10:10:08,447 INFO:     Found new best model at epoch 13
2023-01-04 10:10:08,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:08,448 INFO:     Epoch: 14
2023-01-04 10:10:10,072 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5199810047944387, 'Total loss': 0.5199810047944387} | train loss {'Reaction outcome loss': 0.45083106656396843, 'Total loss': 0.45083106656396843}
2023-01-04 10:10:10,072 INFO:     Found new best model at epoch 14
2023-01-04 10:10:10,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:10,073 INFO:     Epoch: 15
2023-01-04 10:10:11,658 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5186851600805918, 'Total loss': 0.5186851600805918} | train loss {'Reaction outcome loss': 0.4454597278592595, 'Total loss': 0.4454597278592595}
2023-01-04 10:10:11,659 INFO:     Found new best model at epoch 15
2023-01-04 10:10:11,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:11,660 INFO:     Epoch: 16
2023-01-04 10:10:13,291 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.516287354628245, 'Total loss': 0.516287354628245} | train loss {'Reaction outcome loss': 0.4458765807563738, 'Total loss': 0.4458765807563738}
2023-01-04 10:10:13,291 INFO:     Found new best model at epoch 16
2023-01-04 10:10:13,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:13,292 INFO:     Epoch: 17
2023-01-04 10:10:14,914 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5075810134410859, 'Total loss': 0.5075810134410859} | train loss {'Reaction outcome loss': 0.44028786221600097, 'Total loss': 0.44028786221600097}
2023-01-04 10:10:14,914 INFO:     Found new best model at epoch 17
2023-01-04 10:10:14,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:14,915 INFO:     Epoch: 18
2023-01-04 10:10:16,538 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5210610846678416, 'Total loss': 0.5210610846678416} | train loss {'Reaction outcome loss': 0.4405430148261181, 'Total loss': 0.4405430148261181}
2023-01-04 10:10:16,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:16,539 INFO:     Epoch: 19
2023-01-04 10:10:18,132 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5174335797627767, 'Total loss': 0.5174335797627767} | train loss {'Reaction outcome loss': 0.4457944248249565, 'Total loss': 0.4457944248249565}
2023-01-04 10:10:18,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:18,133 INFO:     Epoch: 20
2023-01-04 10:10:19,765 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5091893593470256, 'Total loss': 0.5091893593470256} | train loss {'Reaction outcome loss': 0.42867741999688785, 'Total loss': 0.42867741999688785}
2023-01-04 10:10:19,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:19,766 INFO:     Epoch: 21
2023-01-04 10:10:21,334 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5158942878246308, 'Total loss': 0.5158942878246308} | train loss {'Reaction outcome loss': 0.4257335917808224, 'Total loss': 0.4257335917808224}
2023-01-04 10:10:21,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:21,334 INFO:     Epoch: 22
2023-01-04 10:10:22,964 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5027098635832469, 'Total loss': 0.5027098635832469} | train loss {'Reaction outcome loss': 0.41955634581191864, 'Total loss': 0.41955634581191864}
2023-01-04 10:10:22,964 INFO:     Found new best model at epoch 22
2023-01-04 10:10:22,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:22,965 INFO:     Epoch: 23
2023-01-04 10:10:24,589 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5002020577589671, 'Total loss': 0.5002020577589671} | train loss {'Reaction outcome loss': 0.4151065501289955, 'Total loss': 0.4151065501289955}
2023-01-04 10:10:24,589 INFO:     Found new best model at epoch 23
2023-01-04 10:10:24,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:24,590 INFO:     Epoch: 24
2023-01-04 10:10:26,171 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5051628390947978, 'Total loss': 0.5051628390947978} | train loss {'Reaction outcome loss': 0.4164137465126839, 'Total loss': 0.4164137465126839}
2023-01-04 10:10:26,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:26,171 INFO:     Epoch: 25
2023-01-04 10:10:27,792 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48838105201721194, 'Total loss': 0.48838105201721194} | train loss {'Reaction outcome loss': 0.42323579733678396, 'Total loss': 0.42323579733678396}
2023-01-04 10:10:27,792 INFO:     Found new best model at epoch 25
2023-01-04 10:10:27,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:27,793 INFO:     Epoch: 26
2023-01-04 10:10:29,410 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5663409908612569, 'Total loss': 0.5663409908612569} | train loss {'Reaction outcome loss': 0.44344610548105795, 'Total loss': 0.44344610548105795}
2023-01-04 10:10:29,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:29,410 INFO:     Epoch: 27
2023-01-04 10:10:31,012 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5392187356948852, 'Total loss': 0.5392187356948852} | train loss {'Reaction outcome loss': 0.42590962515374564, 'Total loss': 0.42590962515374564}
2023-01-04 10:10:31,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:31,013 INFO:     Epoch: 28
2023-01-04 10:10:32,641 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4841349164644877, 'Total loss': 0.4841349164644877} | train loss {'Reaction outcome loss': 0.406245291793206, 'Total loss': 0.406245291793206}
2023-01-04 10:10:32,641 INFO:     Found new best model at epoch 28
2023-01-04 10:10:32,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:32,642 INFO:     Epoch: 29
2023-01-04 10:10:34,256 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5050605098406474, 'Total loss': 0.5050605098406474} | train loss {'Reaction outcome loss': 0.3975708792593492, 'Total loss': 0.3975708792593492}
2023-01-04 10:10:34,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:34,257 INFO:     Epoch: 30
2023-01-04 10:10:35,839 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4824147135019302, 'Total loss': 0.4824147135019302} | train loss {'Reaction outcome loss': 0.39663317335351533, 'Total loss': 0.39663317335351533}
2023-01-04 10:10:35,839 INFO:     Found new best model at epoch 30
2023-01-04 10:10:35,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:35,839 INFO:     Epoch: 31
2023-01-04 10:10:37,466 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4828025996685028, 'Total loss': 0.4828025996685028} | train loss {'Reaction outcome loss': 0.3946906099824802, 'Total loss': 0.3946906099824802}
2023-01-04 10:10:37,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:37,466 INFO:     Epoch: 32
2023-01-04 10:10:39,046 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4939636011918386, 'Total loss': 0.4939636011918386} | train loss {'Reaction outcome loss': 0.40167415665759554, 'Total loss': 0.40167415665759554}
2023-01-04 10:10:39,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:39,047 INFO:     Epoch: 33
2023-01-04 10:10:40,670 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47595176299413045, 'Total loss': 0.47595176299413045} | train loss {'Reaction outcome loss': 0.38645871122961567, 'Total loss': 0.38645871122961567}
2023-01-04 10:10:40,671 INFO:     Found new best model at epoch 33
2023-01-04 10:10:40,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:40,671 INFO:     Epoch: 34
2023-01-04 10:10:42,286 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4844517131646474, 'Total loss': 0.4844517131646474} | train loss {'Reaction outcome loss': 0.3810265198977583, 'Total loss': 0.3810265198977583}
2023-01-04 10:10:42,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:42,287 INFO:     Epoch: 35
2023-01-04 10:10:43,893 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4785385727882385, 'Total loss': 0.4785385727882385} | train loss {'Reaction outcome loss': 0.3799244325230087, 'Total loss': 0.3799244325230087}
2023-01-04 10:10:43,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:43,893 INFO:     Epoch: 36
2023-01-04 10:10:45,451 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4459260324637095, 'Total loss': 0.4459260324637095} | train loss {'Reaction outcome loss': 0.3808704324967592, 'Total loss': 0.3808704324967592}
2023-01-04 10:10:45,451 INFO:     Found new best model at epoch 36
2023-01-04 10:10:45,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:45,451 INFO:     Epoch: 37
2023-01-04 10:10:47,018 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4875212440888087, 'Total loss': 0.4875212440888087} | train loss {'Reaction outcome loss': 0.3712526397674979, 'Total loss': 0.3712526397674979}
2023-01-04 10:10:47,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:47,018 INFO:     Epoch: 38
2023-01-04 10:10:48,556 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4633238057295481, 'Total loss': 0.4633238057295481} | train loss {'Reaction outcome loss': 0.36681274773445033, 'Total loss': 0.36681274773445033}
2023-01-04 10:10:48,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:48,557 INFO:     Epoch: 39
2023-01-04 10:10:50,157 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4823710242907206, 'Total loss': 0.4823710242907206} | train loss {'Reaction outcome loss': 0.36813453530809004, 'Total loss': 0.36813453530809004}
2023-01-04 10:10:50,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:50,158 INFO:     Epoch: 40
2023-01-04 10:10:51,745 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44125547260046005, 'Total loss': 0.44125547260046005} | train loss {'Reaction outcome loss': 0.3645458500089961, 'Total loss': 0.3645458500089961}
2023-01-04 10:10:51,745 INFO:     Found new best model at epoch 40
2023-01-04 10:10:51,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:51,745 INFO:     Epoch: 41
2023-01-04 10:10:53,328 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4588172207276026, 'Total loss': 0.4588172207276026} | train loss {'Reaction outcome loss': 0.3593932442313087, 'Total loss': 0.3593932442313087}
2023-01-04 10:10:53,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:53,328 INFO:     Epoch: 42
2023-01-04 10:10:54,907 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48503716886043546, 'Total loss': 0.48503716886043546} | train loss {'Reaction outcome loss': 0.3595743766999331, 'Total loss': 0.3595743766999331}
2023-01-04 10:10:54,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:54,908 INFO:     Epoch: 43
2023-01-04 10:10:56,498 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47589402198791503, 'Total loss': 0.47589402198791503} | train loss {'Reaction outcome loss': 0.366022210744078, 'Total loss': 0.366022210744078}
2023-01-04 10:10:56,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:56,498 INFO:     Epoch: 44
2023-01-04 10:10:58,052 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4723791857560476, 'Total loss': 0.4723791857560476} | train loss {'Reaction outcome loss': 0.35305044499176985, 'Total loss': 0.35305044499176985}
2023-01-04 10:10:58,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:58,053 INFO:     Epoch: 45
2023-01-04 10:10:59,620 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4346757287780444, 'Total loss': 0.4346757287780444} | train loss {'Reaction outcome loss': 0.35552596723984764, 'Total loss': 0.35552596723984764}
2023-01-04 10:10:59,620 INFO:     Found new best model at epoch 45
2023-01-04 10:10:59,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:10:59,621 INFO:     Epoch: 46
2023-01-04 10:11:01,188 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47135056257247926, 'Total loss': 0.47135056257247926} | train loss {'Reaction outcome loss': 0.3532675096387233, 'Total loss': 0.3532675096387233}
2023-01-04 10:11:01,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:01,189 INFO:     Epoch: 47
2023-01-04 10:11:02,723 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48463688691457113, 'Total loss': 0.48463688691457113} | train loss {'Reaction outcome loss': 0.3591153393836989, 'Total loss': 0.3591153393836989}
2023-01-04 10:11:02,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:02,723 INFO:     Epoch: 48
2023-01-04 10:11:04,305 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4762901306152344, 'Total loss': 0.4762901306152344} | train loss {'Reaction outcome loss': 0.37154719074952364, 'Total loss': 0.37154719074952364}
2023-01-04 10:11:04,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:04,305 INFO:     Epoch: 49
2023-01-04 10:11:05,868 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45102250277996064, 'Total loss': 0.45102250277996064} | train loss {'Reaction outcome loss': 0.3403809246846704, 'Total loss': 0.3403809246846704}
2023-01-04 10:11:05,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:05,868 INFO:     Epoch: 50
2023-01-04 10:11:07,417 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45499235490957896, 'Total loss': 0.45499235490957896} | train loss {'Reaction outcome loss': 0.33564976157377596, 'Total loss': 0.33564976157377596}
2023-01-04 10:11:07,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:07,418 INFO:     Epoch: 51
2023-01-04 10:11:09,004 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4386052578687668, 'Total loss': 0.4386052578687668} | train loss {'Reaction outcome loss': 0.33297911562249943, 'Total loss': 0.33297911562249943}
2023-01-04 10:11:09,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:09,004 INFO:     Epoch: 52
2023-01-04 10:11:10,573 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48099130392074585, 'Total loss': 0.48099130392074585} | train loss {'Reaction outcome loss': 0.33326954061730235, 'Total loss': 0.33326954061730235}
2023-01-04 10:11:10,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:10,574 INFO:     Epoch: 53
2023-01-04 10:11:12,108 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42236564060052234, 'Total loss': 0.42236564060052234} | train loss {'Reaction outcome loss': 0.32932804908562935, 'Total loss': 0.32932804908562935}
2023-01-04 10:11:12,108 INFO:     Found new best model at epoch 53
2023-01-04 10:11:12,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:12,109 INFO:     Epoch: 54
2023-01-04 10:11:13,696 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5008832295735677, 'Total loss': 0.5008832295735677} | train loss {'Reaction outcome loss': 0.3270101112624009, 'Total loss': 0.3270101112624009}
2023-01-04 10:11:13,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:13,697 INFO:     Epoch: 55
2023-01-04 10:11:15,240 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44026355147361756, 'Total loss': 0.44026355147361756} | train loss {'Reaction outcome loss': 0.3433777141457329, 'Total loss': 0.3433777141457329}
2023-01-04 10:11:15,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:15,240 INFO:     Epoch: 56
2023-01-04 10:11:16,821 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4568670064210892, 'Total loss': 0.4568670064210892} | train loss {'Reaction outcome loss': 0.32176511575454386, 'Total loss': 0.32176511575454386}
2023-01-04 10:11:16,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:16,821 INFO:     Epoch: 57
2023-01-04 10:11:18,396 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4421655903259913, 'Total loss': 0.4421655903259913} | train loss {'Reaction outcome loss': 0.32681729042551655, 'Total loss': 0.32681729042551655}
2023-01-04 10:11:18,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:18,397 INFO:     Epoch: 58
2023-01-04 10:11:19,982 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4368317246437073, 'Total loss': 0.4368317246437073} | train loss {'Reaction outcome loss': 0.3597237653490426, 'Total loss': 0.3597237653490426}
2023-01-04 10:11:19,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:19,983 INFO:     Epoch: 59
2023-01-04 10:11:21,555 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4444003899892171, 'Total loss': 0.4444003899892171} | train loss {'Reaction outcome loss': 0.3147558445812994, 'Total loss': 0.3147558445812994}
2023-01-04 10:11:21,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:21,556 INFO:     Epoch: 60
2023-01-04 10:11:23,144 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43258033990859984, 'Total loss': 0.43258033990859984} | train loss {'Reaction outcome loss': 0.31368675641715527, 'Total loss': 0.31368675641715527}
2023-01-04 10:11:23,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:23,144 INFO:     Epoch: 61
2023-01-04 10:11:24,698 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4591805815696716, 'Total loss': 0.4591805815696716} | train loss {'Reaction outcome loss': 0.3132834093142436, 'Total loss': 0.3132834093142436}
2023-01-04 10:11:24,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:24,699 INFO:     Epoch: 62
2023-01-04 10:11:26,284 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47449597517649333, 'Total loss': 0.47449597517649333} | train loss {'Reaction outcome loss': 0.309330810158365, 'Total loss': 0.309330810158365}
2023-01-04 10:11:26,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:26,284 INFO:     Epoch: 63
2023-01-04 10:11:27,864 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44287683367729186, 'Total loss': 0.44287683367729186} | train loss {'Reaction outcome loss': 0.32335737141092186, 'Total loss': 0.32335737141092186}
2023-01-04 10:11:27,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:27,864 INFO:     Epoch: 64
2023-01-04 10:11:29,435 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44000886181990306, 'Total loss': 0.44000886181990306} | train loss {'Reaction outcome loss': 0.3172778744196546, 'Total loss': 0.3172778744196546}
2023-01-04 10:11:29,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:29,435 INFO:     Epoch: 65
2023-01-04 10:11:30,982 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45468995372454324, 'Total loss': 0.45468995372454324} | train loss {'Reaction outcome loss': 0.30676251537469384, 'Total loss': 0.30676251537469384}
2023-01-04 10:11:30,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:30,982 INFO:     Epoch: 66
2023-01-04 10:11:32,587 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4354814291000366, 'Total loss': 0.4354814291000366} | train loss {'Reaction outcome loss': 0.30716006876563356, 'Total loss': 0.30716006876563356}
2023-01-04 10:11:32,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:32,588 INFO:     Epoch: 67
2023-01-04 10:11:34,136 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4495583971341451, 'Total loss': 0.4495583971341451} | train loss {'Reaction outcome loss': 0.3005701537257519, 'Total loss': 0.3005701537257519}
2023-01-04 10:11:34,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:34,136 INFO:     Epoch: 68
2023-01-04 10:11:35,678 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41540583272775017, 'Total loss': 0.41540583272775017} | train loss {'Reaction outcome loss': 0.3011215425117964, 'Total loss': 0.3011215425117964}
2023-01-04 10:11:35,678 INFO:     Found new best model at epoch 68
2023-01-04 10:11:35,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:35,679 INFO:     Epoch: 69
2023-01-04 10:11:37,269 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43682732383410133, 'Total loss': 0.43682732383410133} | train loss {'Reaction outcome loss': 0.2969796369611488, 'Total loss': 0.2969796369611488}
2023-01-04 10:11:37,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:37,270 INFO:     Epoch: 70
2023-01-04 10:11:38,860 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4465453714132309, 'Total loss': 0.4465453714132309} | train loss {'Reaction outcome loss': 0.2993408703663643, 'Total loss': 0.2993408703663643}
2023-01-04 10:11:38,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:38,861 INFO:     Epoch: 71
2023-01-04 10:11:40,415 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47982281843821206, 'Total loss': 0.47982281843821206} | train loss {'Reaction outcome loss': 0.3133451691153797, 'Total loss': 0.3133451691153797}
2023-01-04 10:11:40,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:40,415 INFO:     Epoch: 72
2023-01-04 10:11:41,989 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45836369742949806, 'Total loss': 0.45836369742949806} | train loss {'Reaction outcome loss': 0.3031321348271508, 'Total loss': 0.3031321348271508}
2023-01-04 10:11:41,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:41,989 INFO:     Epoch: 73
2023-01-04 10:11:43,540 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4830665449301402, 'Total loss': 0.4830665449301402} | train loss {'Reaction outcome loss': 0.32792454650220665, 'Total loss': 0.32792454650220665}
2023-01-04 10:11:43,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:43,540 INFO:     Epoch: 74
2023-01-04 10:11:45,106 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4455303490161896, 'Total loss': 0.4455303490161896} | train loss {'Reaction outcome loss': 0.2974259726166644, 'Total loss': 0.2974259726166644}
2023-01-04 10:11:45,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:45,106 INFO:     Epoch: 75
2023-01-04 10:11:46,673 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.461554894844691, 'Total loss': 0.461554894844691} | train loss {'Reaction outcome loss': 0.29793600368725165, 'Total loss': 0.29793600368725165}
2023-01-04 10:11:46,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:46,673 INFO:     Epoch: 76
2023-01-04 10:11:48,237 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45271711349487304, 'Total loss': 0.45271711349487304} | train loss {'Reaction outcome loss': 0.2895712730596247, 'Total loss': 0.2895712730596247}
2023-01-04 10:11:48,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:48,239 INFO:     Epoch: 77
2023-01-04 10:11:49,792 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45664047797520957, 'Total loss': 0.45664047797520957} | train loss {'Reaction outcome loss': 0.2920853947525493, 'Total loss': 0.2920853947525493}
2023-01-04 10:11:49,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:49,792 INFO:     Epoch: 78
2023-01-04 10:11:51,345 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45284437040487924, 'Total loss': 0.45284437040487924} | train loss {'Reaction outcome loss': 0.28807076000890264, 'Total loss': 0.28807076000890264}
2023-01-04 10:11:51,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:51,345 INFO:     Epoch: 79
2023-01-04 10:11:52,928 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4642061273256938, 'Total loss': 0.4642061273256938} | train loss {'Reaction outcome loss': 0.29191050188324036, 'Total loss': 0.29191050188324036}
2023-01-04 10:11:52,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:52,928 INFO:     Epoch: 80
2023-01-04 10:11:54,516 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44229400555292764, 'Total loss': 0.44229400555292764} | train loss {'Reaction outcome loss': 0.28658201534678973, 'Total loss': 0.28658201534678973}
2023-01-04 10:11:54,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:54,517 INFO:     Epoch: 81
2023-01-04 10:11:56,100 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4652138580878576, 'Total loss': 0.4652138580878576} | train loss {'Reaction outcome loss': 0.29470201484197617, 'Total loss': 0.29470201484197617}
2023-01-04 10:11:56,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:56,101 INFO:     Epoch: 82
2023-01-04 10:11:57,682 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43177085320154823, 'Total loss': 0.43177085320154823} | train loss {'Reaction outcome loss': 0.28703868723865866, 'Total loss': 0.28703868723865866}
2023-01-04 10:11:57,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:57,683 INFO:     Epoch: 83
2023-01-04 10:11:59,245 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4288821220397949, 'Total loss': 0.4288821220397949} | train loss {'Reaction outcome loss': 0.28111537673290854, 'Total loss': 0.28111537673290854}
2023-01-04 10:11:59,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:11:59,245 INFO:     Epoch: 84
2023-01-04 10:12:00,805 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42994420528411864, 'Total loss': 0.42994420528411864} | train loss {'Reaction outcome loss': 0.2860311468206076, 'Total loss': 0.2860311468206076}
2023-01-04 10:12:00,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:00,806 INFO:     Epoch: 85
2023-01-04 10:12:02,371 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4748449981212616, 'Total loss': 0.4748449981212616} | train loss {'Reaction outcome loss': 0.2827871816597231, 'Total loss': 0.2827871816597231}
2023-01-04 10:12:02,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:02,371 INFO:     Epoch: 86
2023-01-04 10:12:03,933 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4475900769233704, 'Total loss': 0.4475900769233704} | train loss {'Reaction outcome loss': 0.2840658547322981, 'Total loss': 0.2840658547322981}
2023-01-04 10:12:03,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:03,933 INFO:     Epoch: 87
2023-01-04 10:12:05,499 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4561708112557729, 'Total loss': 0.4561708112557729} | train loss {'Reaction outcome loss': 0.2790465975480586, 'Total loss': 0.2790465975480586}
2023-01-04 10:12:05,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:05,499 INFO:     Epoch: 88
2023-01-04 10:12:07,038 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44611712694168093, 'Total loss': 0.44611712694168093} | train loss {'Reaction outcome loss': 0.28293221018722525, 'Total loss': 0.28293221018722525}
2023-01-04 10:12:07,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:07,039 INFO:     Epoch: 89
2023-01-04 10:12:08,605 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48859598735968274, 'Total loss': 0.48859598735968274} | train loss {'Reaction outcome loss': 0.30677042526287446, 'Total loss': 0.30677042526287446}
2023-01-04 10:12:08,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:08,605 INFO:     Epoch: 90
2023-01-04 10:12:10,136 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4897831638654073, 'Total loss': 0.4897831638654073} | train loss {'Reaction outcome loss': 0.2830799018856192, 'Total loss': 0.2830799018856192}
2023-01-04 10:12:10,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:10,136 INFO:     Epoch: 91
2023-01-04 10:12:11,703 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4527464578549067, 'Total loss': 0.4527464578549067} | train loss {'Reaction outcome loss': 0.2788967662201975, 'Total loss': 0.2788967662201975}
2023-01-04 10:12:11,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:11,703 INFO:     Epoch: 92
2023-01-04 10:12:13,250 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.454942520459493, 'Total loss': 0.454942520459493} | train loss {'Reaction outcome loss': 0.2751398704145633, 'Total loss': 0.2751398704145633}
2023-01-04 10:12:13,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:13,251 INFO:     Epoch: 93
2023-01-04 10:12:14,830 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45769020915031433, 'Total loss': 0.45769020915031433} | train loss {'Reaction outcome loss': 0.268893306558206, 'Total loss': 0.268893306558206}
2023-01-04 10:12:14,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:14,830 INFO:     Epoch: 94
2023-01-04 10:12:16,356 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4333594113588333, 'Total loss': 0.4333594113588333} | train loss {'Reaction outcome loss': 0.2745669705749395, 'Total loss': 0.2745669705749395}
2023-01-04 10:12:16,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:16,356 INFO:     Epoch: 95
2023-01-04 10:12:17,927 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45918092628320056, 'Total loss': 0.45918092628320056} | train loss {'Reaction outcome loss': 0.26443820441752486, 'Total loss': 0.26443820441752486}
2023-01-04 10:12:17,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:17,927 INFO:     Epoch: 96
2023-01-04 10:12:19,447 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42915655771891276, 'Total loss': 0.42915655771891276} | train loss {'Reaction outcome loss': 0.2688879241468385, 'Total loss': 0.2688879241468385}
2023-01-04 10:12:19,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:19,448 INFO:     Epoch: 97
2023-01-04 10:12:21,006 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45826193590958914, 'Total loss': 0.45826193590958914} | train loss {'Reaction outcome loss': 0.2630368055964726, 'Total loss': 0.2630368055964726}
2023-01-04 10:12:21,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:21,006 INFO:     Epoch: 98
2023-01-04 10:12:22,568 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4895784606536229, 'Total loss': 0.4895784606536229} | train loss {'Reaction outcome loss': 0.2668378044966274, 'Total loss': 0.2668378044966274}
2023-01-04 10:12:22,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:22,568 INFO:     Epoch: 99
2023-01-04 10:12:24,130 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48105522294839226, 'Total loss': 0.48105522294839226} | train loss {'Reaction outcome loss': 0.26979873051269626, 'Total loss': 0.26979873051269626}
2023-01-04 10:12:24,130 INFO:     Best model found after epoch 69 of 100.
2023-01-04 10:12:24,131 INFO:   Done with stage: TRAINING
2023-01-04 10:12:24,131 INFO:   Starting stage: EVALUATION
2023-01-04 10:12:24,258 INFO:   Done with stage: EVALUATION
2023-01-04 10:12:24,258 INFO:   Leaving out SEQ value Fold_6
2023-01-04 10:12:24,270 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 10:12:24,270 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:12:24,909 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:12:24,909 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:12:24,977 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:12:24,977 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:12:24,977 INFO:     No hyperparam tuning for this model
2023-01-04 10:12:24,977 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:12:24,977 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:12:24,978 INFO:     None feature selector for col prot
2023-01-04 10:12:24,978 INFO:     None feature selector for col prot
2023-01-04 10:12:24,978 INFO:     None feature selector for col prot
2023-01-04 10:12:24,979 INFO:     None feature selector for col chem
2023-01-04 10:12:24,979 INFO:     None feature selector for col chem
2023-01-04 10:12:24,979 INFO:     None feature selector for col chem
2023-01-04 10:12:24,979 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:12:24,979 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:12:24,980 INFO:     Number of params in model 70111
2023-01-04 10:12:24,983 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:12:24,983 INFO:   Starting stage: TRAINING
2023-01-04 10:12:25,026 INFO:     Val loss before train {'Reaction outcome loss': 1.0820044875144958, 'Total loss': 1.0820044875144958}
2023-01-04 10:12:25,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:25,026 INFO:     Epoch: 0
2023-01-04 10:12:26,571 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8260332783063252, 'Total loss': 0.8260332783063252} | train loss {'Reaction outcome loss': 0.8452037725637966, 'Total loss': 0.8452037725637966}
2023-01-04 10:12:26,572 INFO:     Found new best model at epoch 0
2023-01-04 10:12:26,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:26,572 INFO:     Epoch: 1
2023-01-04 10:12:28,093 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6599123140176137, 'Total loss': 0.6599123140176137} | train loss {'Reaction outcome loss': 0.6976023162530217, 'Total loss': 0.6976023162530217}
2023-01-04 10:12:28,093 INFO:     Found new best model at epoch 1
2023-01-04 10:12:28,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:28,094 INFO:     Epoch: 2
2023-01-04 10:12:29,661 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5715713222821553, 'Total loss': 0.5715713222821553} | train loss {'Reaction outcome loss': 0.6071798729337079, 'Total loss': 0.6071798729337079}
2023-01-04 10:12:29,662 INFO:     Found new best model at epoch 2
2023-01-04 10:12:29,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:29,662 INFO:     Epoch: 3
2023-01-04 10:12:31,233 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5507299681504567, 'Total loss': 0.5507299681504567} | train loss {'Reaction outcome loss': 0.5586641209758145, 'Total loss': 0.5586641209758145}
2023-01-04 10:12:31,234 INFO:     Found new best model at epoch 3
2023-01-04 10:12:31,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:31,234 INFO:     Epoch: 4
2023-01-04 10:12:32,816 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.547469734152158, 'Total loss': 0.547469734152158} | train loss {'Reaction outcome loss': 0.5284998824665262, 'Total loss': 0.5284998824665262}
2023-01-04 10:12:32,816 INFO:     Found new best model at epoch 4
2023-01-04 10:12:32,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:32,817 INFO:     Epoch: 5
2023-01-04 10:12:34,365 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5382804652055104, 'Total loss': 0.5382804652055104} | train loss {'Reaction outcome loss': 0.5125681105395947, 'Total loss': 0.5125681105395947}
2023-01-04 10:12:34,365 INFO:     Found new best model at epoch 5
2023-01-04 10:12:34,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:34,366 INFO:     Epoch: 6
2023-01-04 10:12:35,955 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5105235735575359, 'Total loss': 0.5105235735575359} | train loss {'Reaction outcome loss': 0.49687072962845275, 'Total loss': 0.49687072962845275}
2023-01-04 10:12:35,955 INFO:     Found new best model at epoch 6
2023-01-04 10:12:35,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:35,956 INFO:     Epoch: 7
2023-01-04 10:12:37,022 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5103049019972483, 'Total loss': 0.5103049019972483} | train loss {'Reaction outcome loss': 0.491429222297152, 'Total loss': 0.491429222297152}
2023-01-04 10:12:37,022 INFO:     Found new best model at epoch 7
2023-01-04 10:12:37,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:37,023 INFO:     Epoch: 8
2023-01-04 10:12:38,045 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5045981466770172, 'Total loss': 0.5045981466770172} | train loss {'Reaction outcome loss': 0.4846095164383792, 'Total loss': 0.4846095164383792}
2023-01-04 10:12:38,046 INFO:     Found new best model at epoch 8
2023-01-04 10:12:38,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:38,046 INFO:     Epoch: 9
2023-01-04 10:12:39,068 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4934594025214513, 'Total loss': 0.4934594025214513} | train loss {'Reaction outcome loss': 0.47437246466586735, 'Total loss': 0.47437246466586735}
2023-01-04 10:12:39,069 INFO:     Found new best model at epoch 9
2023-01-04 10:12:39,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:39,070 INFO:     Epoch: 10
2023-01-04 10:12:40,087 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5069225231806437, 'Total loss': 0.5069225231806437} | train loss {'Reaction outcome loss': 0.4730574656479625, 'Total loss': 0.4730574656479625}
2023-01-04 10:12:40,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:40,087 INFO:     Epoch: 11
2023-01-04 10:12:41,484 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4894564499457677, 'Total loss': 0.4894564499457677} | train loss {'Reaction outcome loss': 0.46174446044200596, 'Total loss': 0.46174446044200596}
2023-01-04 10:12:41,484 INFO:     Found new best model at epoch 11
2023-01-04 10:12:41,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:41,485 INFO:     Epoch: 12
2023-01-04 10:12:43,052 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5118751029173533, 'Total loss': 0.5118751029173533} | train loss {'Reaction outcome loss': 0.4589342459067971, 'Total loss': 0.4589342459067971}
2023-01-04 10:12:43,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:43,052 INFO:     Epoch: 13
2023-01-04 10:12:44,619 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4911075194676717, 'Total loss': 0.4911075194676717} | train loss {'Reaction outcome loss': 0.4524804623763914, 'Total loss': 0.4524804623763914}
2023-01-04 10:12:44,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:44,619 INFO:     Epoch: 14
2023-01-04 10:12:46,188 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4773702104886373, 'Total loss': 0.4773702104886373} | train loss {'Reaction outcome loss': 0.44705342643958135, 'Total loss': 0.44705342643958135}
2023-01-04 10:12:46,188 INFO:     Found new best model at epoch 14
2023-01-04 10:12:46,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:46,189 INFO:     Epoch: 15
2023-01-04 10:12:47,750 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47828882535298667, 'Total loss': 0.47828882535298667} | train loss {'Reaction outcome loss': 0.45032703811941593, 'Total loss': 0.45032703811941593}
2023-01-04 10:12:47,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:47,750 INFO:     Epoch: 16
2023-01-04 10:12:49,298 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48770243922869366, 'Total loss': 0.48770243922869366} | train loss {'Reaction outcome loss': 0.44223131347003825, 'Total loss': 0.44223131347003825}
2023-01-04 10:12:49,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:49,298 INFO:     Epoch: 17
2023-01-04 10:12:50,729 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46701640884081524, 'Total loss': 0.46701640884081524} | train loss {'Reaction outcome loss': 0.43611675839777025, 'Total loss': 0.43611675839777025}
2023-01-04 10:12:50,730 INFO:     Found new best model at epoch 17
2023-01-04 10:12:50,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:50,731 INFO:     Epoch: 18
2023-01-04 10:12:52,302 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4506525715192159, 'Total loss': 0.4506525715192159} | train loss {'Reaction outcome loss': 0.43116895418735185, 'Total loss': 0.43116895418735185}
2023-01-04 10:12:52,302 INFO:     Found new best model at epoch 18
2023-01-04 10:12:52,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:52,303 INFO:     Epoch: 19
2023-01-04 10:12:53,863 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4584887464841207, 'Total loss': 0.4584887464841207} | train loss {'Reaction outcome loss': 0.42854808550664236, 'Total loss': 0.42854808550664236}
2023-01-04 10:12:53,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:53,863 INFO:     Epoch: 20
2023-01-04 10:12:55,446 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4807372430960337, 'Total loss': 0.4807372430960337} | train loss {'Reaction outcome loss': 0.4245427712152581, 'Total loss': 0.4245427712152581}
2023-01-04 10:12:55,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:55,446 INFO:     Epoch: 21
2023-01-04 10:12:57,012 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47188390493392945, 'Total loss': 0.47188390493392945} | train loss {'Reaction outcome loss': 0.4179561669645757, 'Total loss': 0.4179561669645757}
2023-01-04 10:12:57,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:57,012 INFO:     Epoch: 22
2023-01-04 10:12:58,496 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4619343022505442, 'Total loss': 0.4619343022505442} | train loss {'Reaction outcome loss': 0.4137836115885297, 'Total loss': 0.4137836115885297}
2023-01-04 10:12:58,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:12:58,496 INFO:     Epoch: 23
2023-01-04 10:13:00,012 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4630511264006297, 'Total loss': 0.4630511264006297} | train loss {'Reaction outcome loss': 0.41094203379395206, 'Total loss': 0.41094203379395206}
2023-01-04 10:13:00,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:00,012 INFO:     Epoch: 24
2023-01-04 10:13:01,562 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4528630991776784, 'Total loss': 0.4528630991776784} | train loss {'Reaction outcome loss': 0.40625751811997557, 'Total loss': 0.40625751811997557}
2023-01-04 10:13:01,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:01,562 INFO:     Epoch: 25
2023-01-04 10:13:03,133 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4526091476281484, 'Total loss': 0.4526091476281484} | train loss {'Reaction outcome loss': 0.40522836961040426, 'Total loss': 0.40522836961040426}
2023-01-04 10:13:03,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:03,134 INFO:     Epoch: 26
2023-01-04 10:13:04,699 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.483751384417216, 'Total loss': 0.483751384417216} | train loss {'Reaction outcome loss': 0.39480353934885365, 'Total loss': 0.39480353934885365}
2023-01-04 10:13:04,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:04,699 INFO:     Epoch: 27
2023-01-04 10:13:06,273 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4378850181897481, 'Total loss': 0.4378850181897481} | train loss {'Reaction outcome loss': 0.39274624221376564, 'Total loss': 0.39274624221376564}
2023-01-04 10:13:06,274 INFO:     Found new best model at epoch 27
2023-01-04 10:13:06,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:06,274 INFO:     Epoch: 28
2023-01-04 10:13:07,709 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4314234038194021, 'Total loss': 0.4314234038194021} | train loss {'Reaction outcome loss': 0.39309090709428063, 'Total loss': 0.39309090709428063}
2023-01-04 10:13:07,709 INFO:     Found new best model at epoch 28
2023-01-04 10:13:07,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:07,710 INFO:     Epoch: 29
2023-01-04 10:13:09,272 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4320039451122284, 'Total loss': 0.4320039451122284} | train loss {'Reaction outcome loss': 0.3852609022106935, 'Total loss': 0.3852609022106935}
2023-01-04 10:13:09,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:09,273 INFO:     Epoch: 30
2023-01-04 10:13:10,886 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4426476776599884, 'Total loss': 0.4426476776599884} | train loss {'Reaction outcome loss': 0.38447035851784134, 'Total loss': 0.38447035851784134}
2023-01-04 10:13:10,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:10,886 INFO:     Epoch: 31
2023-01-04 10:13:12,524 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43076634109020234, 'Total loss': 0.43076634109020234} | train loss {'Reaction outcome loss': 0.37879200255505013, 'Total loss': 0.37879200255505013}
2023-01-04 10:13:12,525 INFO:     Found new best model at epoch 31
2023-01-04 10:13:12,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:12,525 INFO:     Epoch: 32
2023-01-04 10:13:14,150 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42376840611298877, 'Total loss': 0.42376840611298877} | train loss {'Reaction outcome loss': 0.3766194272665341, 'Total loss': 0.3766194272665341}
2023-01-04 10:13:14,150 INFO:     Found new best model at epoch 32
2023-01-04 10:13:14,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:14,151 INFO:     Epoch: 33
2023-01-04 10:13:15,785 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45703736146291096, 'Total loss': 0.45703736146291096} | train loss {'Reaction outcome loss': 0.37467096772865266, 'Total loss': 0.37467096772865266}
2023-01-04 10:13:15,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:15,785 INFO:     Epoch: 34
2023-01-04 10:13:17,278 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4498191048701604, 'Total loss': 0.4498191048701604} | train loss {'Reaction outcome loss': 0.3684409411913221, 'Total loss': 0.3684409411913221}
2023-01-04 10:13:17,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:17,278 INFO:     Epoch: 35
2023-01-04 10:13:18,897 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4463519096374512, 'Total loss': 0.4463519096374512} | train loss {'Reaction outcome loss': 0.36755503679118, 'Total loss': 0.36755503679118}
2023-01-04 10:13:18,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:18,897 INFO:     Epoch: 36
2023-01-04 10:13:20,527 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43753229280312855, 'Total loss': 0.43753229280312855} | train loss {'Reaction outcome loss': 0.3684796448864231, 'Total loss': 0.3684796448864231}
2023-01-04 10:13:20,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:20,527 INFO:     Epoch: 37
2023-01-04 10:13:22,158 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4289264142513275, 'Total loss': 0.4289264142513275} | train loss {'Reaction outcome loss': 0.36464983805852674, 'Total loss': 0.36464983805852674}
2023-01-04 10:13:22,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:22,159 INFO:     Epoch: 38
2023-01-04 10:13:23,782 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4318967302640279, 'Total loss': 0.4318967302640279} | train loss {'Reaction outcome loss': 0.3597341157791847, 'Total loss': 0.3597341157791847}
2023-01-04 10:13:23,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:23,783 INFO:     Epoch: 39
2023-01-04 10:13:25,414 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42955882449944816, 'Total loss': 0.42955882449944816} | train loss {'Reaction outcome loss': 0.3565337962676041, 'Total loss': 0.3565337962676041}
2023-01-04 10:13:25,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:25,415 INFO:     Epoch: 40
2023-01-04 10:13:26,915 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4599667380253474, 'Total loss': 0.4599667380253474} | train loss {'Reaction outcome loss': 0.3505492968894945, 'Total loss': 0.3505492968894945}
2023-01-04 10:13:26,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:26,915 INFO:     Epoch: 41
2023-01-04 10:13:28,533 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4443610926469167, 'Total loss': 0.4443610926469167} | train loss {'Reaction outcome loss': 0.3495548516511917, 'Total loss': 0.3495548516511917}
2023-01-04 10:13:28,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:28,534 INFO:     Epoch: 42
2023-01-04 10:13:30,161 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42269909878571826, 'Total loss': 0.42269909878571826} | train loss {'Reaction outcome loss': 0.34329640908361775, 'Total loss': 0.34329640908361775}
2023-01-04 10:13:30,161 INFO:     Found new best model at epoch 42
2023-01-04 10:13:30,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:30,162 INFO:     Epoch: 43
2023-01-04 10:13:31,776 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43798298835754396, 'Total loss': 0.43798298835754396} | train loss {'Reaction outcome loss': 0.3438161478414863, 'Total loss': 0.3438161478414863}
2023-01-04 10:13:31,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:31,777 INFO:     Epoch: 44
2023-01-04 10:13:33,395 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.416891884803772, 'Total loss': 0.416891884803772} | train loss {'Reaction outcome loss': 0.34215788457152646, 'Total loss': 0.34215788457152646}
2023-01-04 10:13:33,395 INFO:     Found new best model at epoch 44
2023-01-04 10:13:33,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:33,396 INFO:     Epoch: 45
2023-01-04 10:13:34,964 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44883008301258087, 'Total loss': 0.44883008301258087} | train loss {'Reaction outcome loss': 0.33677492981998497, 'Total loss': 0.33677492981998497}
2023-01-04 10:13:34,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:34,964 INFO:     Epoch: 46
2023-01-04 10:13:36,552 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45585564374923704, 'Total loss': 0.45585564374923704} | train loss {'Reaction outcome loss': 0.33296807352386226, 'Total loss': 0.33296807352386226}
2023-01-04 10:13:36,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:36,552 INFO:     Epoch: 47
2023-01-04 10:13:38,184 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4462652345498403, 'Total loss': 0.4462652345498403} | train loss {'Reaction outcome loss': 0.33374896330846343, 'Total loss': 0.33374896330846343}
2023-01-04 10:13:38,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:38,184 INFO:     Epoch: 48
2023-01-04 10:13:39,807 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4361850589513779, 'Total loss': 0.4361850589513779} | train loss {'Reaction outcome loss': 0.3308110245863238, 'Total loss': 0.3308110245863238}
2023-01-04 10:13:39,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:39,807 INFO:     Epoch: 49
2023-01-04 10:13:41,431 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43905827204386394, 'Total loss': 0.43905827204386394} | train loss {'Reaction outcome loss': 0.3247284717884735, 'Total loss': 0.3247284717884735}
2023-01-04 10:13:41,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:41,432 INFO:     Epoch: 50
2023-01-04 10:13:43,063 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4569315999746323, 'Total loss': 0.4569315999746323} | train loss {'Reaction outcome loss': 0.3233097034509862, 'Total loss': 0.3233097034509862}
2023-01-04 10:13:43,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:43,063 INFO:     Epoch: 51
2023-01-04 10:13:44,542 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43559299906094867, 'Total loss': 0.43559299906094867} | train loss {'Reaction outcome loss': 0.32399294261790357, 'Total loss': 0.32399294261790357}
2023-01-04 10:13:44,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:44,543 INFO:     Epoch: 52
2023-01-04 10:13:46,168 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4208258370558421, 'Total loss': 0.4208258370558421} | train loss {'Reaction outcome loss': 0.32111055062350813, 'Total loss': 0.32111055062350813}
2023-01-04 10:13:46,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:46,168 INFO:     Epoch: 53
2023-01-04 10:13:47,720 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44370755553245544, 'Total loss': 0.44370755553245544} | train loss {'Reaction outcome loss': 0.3197759975164806, 'Total loss': 0.3197759975164806}
2023-01-04 10:13:47,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:47,720 INFO:     Epoch: 54
2023-01-04 10:13:49,279 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43861977259318036, 'Total loss': 0.43861977259318036} | train loss {'Reaction outcome loss': 0.31536439626010315, 'Total loss': 0.31536439626010315}
2023-01-04 10:13:49,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:49,279 INFO:     Epoch: 55
2023-01-04 10:13:50,828 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43452121516068776, 'Total loss': 0.43452121516068776} | train loss {'Reaction outcome loss': 0.3154170747294968, 'Total loss': 0.3154170747294968}
2023-01-04 10:13:50,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:50,828 INFO:     Epoch: 56
2023-01-04 10:13:52,387 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4602530876795451, 'Total loss': 0.4602530876795451} | train loss {'Reaction outcome loss': 0.3066442899863212, 'Total loss': 0.3066442899863212}
2023-01-04 10:13:52,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:52,387 INFO:     Epoch: 57
2023-01-04 10:13:53,807 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43595495919386545, 'Total loss': 0.43595495919386545} | train loss {'Reaction outcome loss': 0.31302855244504846, 'Total loss': 0.31302855244504846}
2023-01-04 10:13:53,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:53,807 INFO:     Epoch: 58
2023-01-04 10:13:55,361 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4392295201619466, 'Total loss': 0.4392295201619466} | train loss {'Reaction outcome loss': 0.311626074412024, 'Total loss': 0.311626074412024}
2023-01-04 10:13:55,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:55,361 INFO:     Epoch: 59
2023-01-04 10:13:56,916 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43401288191477455, 'Total loss': 0.43401288191477455} | train loss {'Reaction outcome loss': 0.3041814546023465, 'Total loss': 0.3041814546023465}
2023-01-04 10:13:56,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:56,917 INFO:     Epoch: 60
2023-01-04 10:13:58,493 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43844153682390846, 'Total loss': 0.43844153682390846} | train loss {'Reaction outcome loss': 0.29991935970873607, 'Total loss': 0.29991935970873607}
2023-01-04 10:13:58,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:13:58,493 INFO:     Epoch: 61
2023-01-04 10:14:00,056 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44044115642706555, 'Total loss': 0.44044115642706555} | train loss {'Reaction outcome loss': 0.30410676608231957, 'Total loss': 0.30410676608231957}
2023-01-04 10:14:00,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:00,056 INFO:     Epoch: 62
2023-01-04 10:14:01,620 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42842968106269835, 'Total loss': 0.42842968106269835} | train loss {'Reaction outcome loss': 0.3025882818638633, 'Total loss': 0.3025882818638633}
2023-01-04 10:14:01,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:01,622 INFO:     Epoch: 63
2023-01-04 10:14:03,041 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43466560045878094, 'Total loss': 0.43466560045878094} | train loss {'Reaction outcome loss': 0.30279456062867754, 'Total loss': 0.30279456062867754}
2023-01-04 10:14:03,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:03,041 INFO:     Epoch: 64
2023-01-04 10:14:04,612 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43579997718334196, 'Total loss': 0.43579997718334196} | train loss {'Reaction outcome loss': 0.2942491847793118, 'Total loss': 0.2942491847793118}
2023-01-04 10:14:04,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:04,612 INFO:     Epoch: 65
2023-01-04 10:14:06,190 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.447444760799408, 'Total loss': 0.447444760799408} | train loss {'Reaction outcome loss': 0.2959862686290207, 'Total loss': 0.2959862686290207}
2023-01-04 10:14:06,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:06,190 INFO:     Epoch: 66
2023-01-04 10:14:07,755 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41966609259446463, 'Total loss': 0.41966609259446463} | train loss {'Reaction outcome loss': 0.29491095263712674, 'Total loss': 0.29491095263712674}
2023-01-04 10:14:07,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:07,756 INFO:     Epoch: 67
2023-01-04 10:14:09,313 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43139488299687706, 'Total loss': 0.43139488299687706} | train loss {'Reaction outcome loss': 0.2910557015385438, 'Total loss': 0.2910557015385438}
2023-01-04 10:14:09,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:09,313 INFO:     Epoch: 68
2023-01-04 10:14:10,878 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4533894161383311, 'Total loss': 0.4533894161383311} | train loss {'Reaction outcome loss': 0.2953280629825506, 'Total loss': 0.2953280629825506}
2023-01-04 10:14:10,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:10,878 INFO:     Epoch: 69
2023-01-04 10:14:12,272 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45038356085618336, 'Total loss': 0.45038356085618336} | train loss {'Reaction outcome loss': 0.29222423841484185, 'Total loss': 0.29222423841484185}
2023-01-04 10:14:12,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:12,272 INFO:     Epoch: 70
2023-01-04 10:14:13,844 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4492489139238993, 'Total loss': 0.4492489139238993} | train loss {'Reaction outcome loss': 0.29089476564892364, 'Total loss': 0.29089476564892364}
2023-01-04 10:14:13,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:13,844 INFO:     Epoch: 71
2023-01-04 10:14:15,409 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4312006672223409, 'Total loss': 0.4312006672223409} | train loss {'Reaction outcome loss': 0.2906482062077264, 'Total loss': 0.2906482062077264}
2023-01-04 10:14:15,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:15,409 INFO:     Epoch: 72
2023-01-04 10:14:16,972 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43044520616531373, 'Total loss': 0.43044520616531373} | train loss {'Reaction outcome loss': 0.28353997435595585, 'Total loss': 0.28353997435595585}
2023-01-04 10:14:16,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:16,972 INFO:     Epoch: 73
2023-01-04 10:14:18,535 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4460945626099904, 'Total loss': 0.4460945626099904} | train loss {'Reaction outcome loss': 0.28480963513846863, 'Total loss': 0.28480963513846863}
2023-01-04 10:14:18,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:18,535 INFO:     Epoch: 74
2023-01-04 10:14:20,140 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.427017014225324, 'Total loss': 0.427017014225324} | train loss {'Reaction outcome loss': 0.2822268250186521, 'Total loss': 0.2822268250186521}
2023-01-04 10:14:20,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:20,141 INFO:     Epoch: 75
2023-01-04 10:14:21,619 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44474719762802123, 'Total loss': 0.44474719762802123} | train loss {'Reaction outcome loss': 0.28657936600679096, 'Total loss': 0.28657936600679096}
2023-01-04 10:14:21,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:21,619 INFO:     Epoch: 76
2023-01-04 10:14:23,227 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4352437138557434, 'Total loss': 0.4352437138557434} | train loss {'Reaction outcome loss': 0.28040299381697653, 'Total loss': 0.28040299381697653}
2023-01-04 10:14:23,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:23,227 INFO:     Epoch: 77
2023-01-04 10:14:24,829 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44612464706103006, 'Total loss': 0.44612464706103006} | train loss {'Reaction outcome loss': 0.27733771825740483, 'Total loss': 0.27733771825740483}
2023-01-04 10:14:24,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:24,829 INFO:     Epoch: 78
2023-01-04 10:14:26,438 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45017247994740806, 'Total loss': 0.45017247994740806} | train loss {'Reaction outcome loss': 0.2799275022820445, 'Total loss': 0.2799275022820445}
2023-01-04 10:14:26,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:26,438 INFO:     Epoch: 79
2023-01-04 10:14:28,035 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4407868355512619, 'Total loss': 0.4407868355512619} | train loss {'Reaction outcome loss': 0.27873628176345294, 'Total loss': 0.27873628176345294}
2023-01-04 10:14:28,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:28,035 INFO:     Epoch: 80
2023-01-04 10:14:29,575 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47818996012210846, 'Total loss': 0.47818996012210846} | train loss {'Reaction outcome loss': 0.27509126145164026, 'Total loss': 0.27509126145164026}
2023-01-04 10:14:29,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:29,575 INFO:     Epoch: 81
2023-01-04 10:14:31,132 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4506316641966502, 'Total loss': 0.4506316641966502} | train loss {'Reaction outcome loss': 0.27590545924508186, 'Total loss': 0.27590545924508186}
2023-01-04 10:14:31,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:31,133 INFO:     Epoch: 82
2023-01-04 10:14:32,737 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45682568748792013, 'Total loss': 0.45682568748792013} | train loss {'Reaction outcome loss': 0.2776781812659885, 'Total loss': 0.2776781812659885}
2023-01-04 10:14:32,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:32,739 INFO:     Epoch: 83
2023-01-04 10:14:34,372 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4476797809203466, 'Total loss': 0.4476797809203466} | train loss {'Reaction outcome loss': 0.27486986419461695, 'Total loss': 0.27486986419461695}
2023-01-04 10:14:34,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:34,373 INFO:     Epoch: 84
2023-01-04 10:14:35,982 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44729270339012145, 'Total loss': 0.44729270339012145} | train loss {'Reaction outcome loss': 0.27590508999753516, 'Total loss': 0.27590508999753516}
2023-01-04 10:14:35,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:35,983 INFO:     Epoch: 85
2023-01-04 10:14:37,619 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45331091781457267, 'Total loss': 0.45331091781457267} | train loss {'Reaction outcome loss': 0.27237972349520195, 'Total loss': 0.27237972349520195}
2023-01-04 10:14:37,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:37,619 INFO:     Epoch: 86
2023-01-04 10:14:39,100 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4456751227378845, 'Total loss': 0.4456751227378845} | train loss {'Reaction outcome loss': 0.2738892089588978, 'Total loss': 0.2738892089588978}
2023-01-04 10:14:39,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:39,101 INFO:     Epoch: 87
2023-01-04 10:14:40,715 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4547847121953964, 'Total loss': 0.4547847121953964} | train loss {'Reaction outcome loss': 0.26537919191085474, 'Total loss': 0.26537919191085474}
2023-01-04 10:14:40,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:40,715 INFO:     Epoch: 88
2023-01-04 10:14:42,347 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.449878990650177, 'Total loss': 0.449878990650177} | train loss {'Reaction outcome loss': 0.2710130481782373, 'Total loss': 0.2710130481782373}
2023-01-04 10:14:42,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:42,347 INFO:     Epoch: 89
2023-01-04 10:14:43,982 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44773002962271374, 'Total loss': 0.44773002962271374} | train loss {'Reaction outcome loss': 0.2718222637253978, 'Total loss': 0.2718222637253978}
2023-01-04 10:14:43,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:43,982 INFO:     Epoch: 90
2023-01-04 10:14:45,594 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46420097947120664, 'Total loss': 0.46420097947120664} | train loss {'Reaction outcome loss': 0.26656289565434094, 'Total loss': 0.26656289565434094}
2023-01-04 10:14:45,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:45,595 INFO:     Epoch: 91
2023-01-04 10:14:47,204 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4676180521647135, 'Total loss': 0.4676180521647135} | train loss {'Reaction outcome loss': 0.2668779240080596, 'Total loss': 0.2668779240080596}
2023-01-04 10:14:47,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:47,204 INFO:     Epoch: 92
2023-01-04 10:14:48,657 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4537195007006327, 'Total loss': 0.4537195007006327} | train loss {'Reaction outcome loss': 0.26543868448760105, 'Total loss': 0.26543868448760105}
2023-01-04 10:14:48,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:48,658 INFO:     Epoch: 93
2023-01-04 10:14:50,248 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4601078987121582, 'Total loss': 0.4601078987121582} | train loss {'Reaction outcome loss': 0.2658905113781617, 'Total loss': 0.2658905113781617}
2023-01-04 10:14:50,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:50,248 INFO:     Epoch: 94
2023-01-04 10:14:51,854 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4964048574368159, 'Total loss': 0.4964048574368159} | train loss {'Reaction outcome loss': 0.26743859843441725, 'Total loss': 0.26743859843441725}
2023-01-04 10:14:51,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:51,855 INFO:     Epoch: 95
2023-01-04 10:14:53,449 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45215452909469606, 'Total loss': 0.45215452909469606} | train loss {'Reaction outcome loss': 0.2639704234091168, 'Total loss': 0.2639704234091168}
2023-01-04 10:14:53,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:53,449 INFO:     Epoch: 96
2023-01-04 10:14:55,046 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45429976284503937, 'Total loss': 0.45429976284503937} | train loss {'Reaction outcome loss': 0.2623571348561492, 'Total loss': 0.2623571348561492}
2023-01-04 10:14:55,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:55,047 INFO:     Epoch: 97
2023-01-04 10:14:56,656 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45328131715456643, 'Total loss': 0.45328131715456643} | train loss {'Reaction outcome loss': 0.2626799351202882, 'Total loss': 0.2626799351202882}
2023-01-04 10:14:56,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:56,656 INFO:     Epoch: 98
2023-01-04 10:14:58,102 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45980433424313866, 'Total loss': 0.45980433424313866} | train loss {'Reaction outcome loss': 0.26006340421063806, 'Total loss': 0.26006340421063806}
2023-01-04 10:14:58,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:14:58,102 INFO:     Epoch: 99
2023-01-04 10:14:59,692 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4580737253030141, 'Total loss': 0.4580737253030141} | train loss {'Reaction outcome loss': 0.26526648596951247, 'Total loss': 0.26526648596951247}
2023-01-04 10:14:59,693 INFO:     Best model found after epoch 45 of 100.
2023-01-04 10:14:59,693 INFO:   Done with stage: TRAINING
2023-01-04 10:14:59,693 INFO:   Starting stage: EVALUATION
2023-01-04 10:14:59,817 INFO:   Done with stage: EVALUATION
2023-01-04 10:14:59,817 INFO:   Leaving out SEQ value Fold_7
2023-01-04 10:14:59,830 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 10:14:59,830 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:15:00,492 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:15:00,492 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:15:00,561 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:15:00,561 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:15:00,561 INFO:     No hyperparam tuning for this model
2023-01-04 10:15:00,561 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:15:00,561 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:15:00,562 INFO:     None feature selector for col prot
2023-01-04 10:15:00,562 INFO:     None feature selector for col prot
2023-01-04 10:15:00,562 INFO:     None feature selector for col prot
2023-01-04 10:15:00,562 INFO:     None feature selector for col chem
2023-01-04 10:15:00,562 INFO:     None feature selector for col chem
2023-01-04 10:15:00,562 INFO:     None feature selector for col chem
2023-01-04 10:15:00,563 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:15:00,563 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:15:00,564 INFO:     Number of params in model 70111
2023-01-04 10:15:00,567 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:15:00,567 INFO:   Starting stage: TRAINING
2023-01-04 10:15:00,609 INFO:     Val loss before train {'Reaction outcome loss': 0.9683849493662516, 'Total loss': 0.9683849493662516}
2023-01-04 10:15:00,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:00,609 INFO:     Epoch: 0
2023-01-04 10:15:02,223 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7220078408718109, 'Total loss': 0.7220078408718109} | train loss {'Reaction outcome loss': 0.8352741128292637, 'Total loss': 0.8352741128292637}
2023-01-04 10:15:02,223 INFO:     Found new best model at epoch 0
2023-01-04 10:15:02,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:02,224 INFO:     Epoch: 1
2023-01-04 10:15:03,815 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5998316129048665, 'Total loss': 0.5998316129048665} | train loss {'Reaction outcome loss': 0.6790706878527999, 'Total loss': 0.6790706878527999}
2023-01-04 10:15:03,816 INFO:     Found new best model at epoch 1
2023-01-04 10:15:03,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:03,816 INFO:     Epoch: 2
2023-01-04 10:15:05,400 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5398618380228678, 'Total loss': 0.5398618380228678} | train loss {'Reaction outcome loss': 0.5860316836531612, 'Total loss': 0.5860316836531612}
2023-01-04 10:15:05,401 INFO:     Found new best model at epoch 2
2023-01-04 10:15:05,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:05,401 INFO:     Epoch: 3
2023-01-04 10:15:06,874 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5126513739426931, 'Total loss': 0.5126513739426931} | train loss {'Reaction outcome loss': 0.5465002256998981, 'Total loss': 0.5465002256998981}
2023-01-04 10:15:06,875 INFO:     Found new best model at epoch 3
2023-01-04 10:15:06,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:06,875 INFO:     Epoch: 4
2023-01-04 10:15:08,467 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48783968687057494, 'Total loss': 0.48783968687057494} | train loss {'Reaction outcome loss': 0.5376029465941415, 'Total loss': 0.5376029465941415}
2023-01-04 10:15:08,467 INFO:     Found new best model at epoch 4
2023-01-04 10:15:08,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:08,468 INFO:     Epoch: 5
2023-01-04 10:15:10,031 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4972168207168579, 'Total loss': 0.4972168207168579} | train loss {'Reaction outcome loss': 0.5150808103220619, 'Total loss': 0.5150808103220619}
2023-01-04 10:15:10,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:10,031 INFO:     Epoch: 6
2023-01-04 10:15:11,595 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45503173271814984, 'Total loss': 0.45503173271814984} | train loss {'Reaction outcome loss': 0.4982512428600719, 'Total loss': 0.4982512428600719}
2023-01-04 10:15:11,595 INFO:     Found new best model at epoch 6
2023-01-04 10:15:11,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:11,596 INFO:     Epoch: 7
2023-01-04 10:15:13,170 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46308507521947223, 'Total loss': 0.46308507521947223} | train loss {'Reaction outcome loss': 0.490465035189645, 'Total loss': 0.490465035189645}
2023-01-04 10:15:13,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:13,170 INFO:     Epoch: 8
2023-01-04 10:15:14,715 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46924853026866914, 'Total loss': 0.46924853026866914} | train loss {'Reaction outcome loss': 0.49076538344008336, 'Total loss': 0.49076538344008336}
2023-01-04 10:15:14,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:14,716 INFO:     Epoch: 9
2023-01-04 10:15:16,207 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.448010128736496, 'Total loss': 0.448010128736496} | train loss {'Reaction outcome loss': 0.4898792467808918, 'Total loss': 0.4898792467808918}
2023-01-04 10:15:16,207 INFO:     Found new best model at epoch 9
2023-01-04 10:15:16,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:16,208 INFO:     Epoch: 10
2023-01-04 10:15:17,774 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4572625736395518, 'Total loss': 0.4572625736395518} | train loss {'Reaction outcome loss': 0.4676093084440715, 'Total loss': 0.4676093084440715}
2023-01-04 10:15:17,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:17,774 INFO:     Epoch: 11
2023-01-04 10:15:19,358 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43744198282559715, 'Total loss': 0.43744198282559715} | train loss {'Reaction outcome loss': 0.4662090866633293, 'Total loss': 0.4662090866633293}
2023-01-04 10:15:19,358 INFO:     Found new best model at epoch 11
2023-01-04 10:15:19,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:19,359 INFO:     Epoch: 12
2023-01-04 10:15:20,963 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4503625422716141, 'Total loss': 0.4503625422716141} | train loss {'Reaction outcome loss': 0.45756374643035774, 'Total loss': 0.45756374643035774}
2023-01-04 10:15:20,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:20,963 INFO:     Epoch: 13
2023-01-04 10:15:22,566 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4345228602488836, 'Total loss': 0.4345228602488836} | train loss {'Reaction outcome loss': 0.44583072908576665, 'Total loss': 0.44583072908576665}
2023-01-04 10:15:22,567 INFO:     Found new best model at epoch 13
2023-01-04 10:15:22,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:22,568 INFO:     Epoch: 14
2023-01-04 10:15:24,047 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42290265957514445, 'Total loss': 0.42290265957514445} | train loss {'Reaction outcome loss': 0.4435115955074898, 'Total loss': 0.4435115955074898}
2023-01-04 10:15:24,047 INFO:     Found new best model at epoch 14
2023-01-04 10:15:24,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:24,048 INFO:     Epoch: 15
2023-01-04 10:15:25,633 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4347860584656397, 'Total loss': 0.4347860584656397} | train loss {'Reaction outcome loss': 0.4393313519692089, 'Total loss': 0.4393313519692089}
2023-01-04 10:15:25,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:25,633 INFO:     Epoch: 16
2023-01-04 10:15:27,213 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4222567687431971, 'Total loss': 0.4222567687431971} | train loss {'Reaction outcome loss': 0.4367355414614249, 'Total loss': 0.4367355414614249}
2023-01-04 10:15:27,213 INFO:     Found new best model at epoch 16
2023-01-04 10:15:27,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:27,214 INFO:     Epoch: 17
2023-01-04 10:15:28,806 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42316125830014545, 'Total loss': 0.42316125830014545} | train loss {'Reaction outcome loss': 0.4330664934536469, 'Total loss': 0.4330664934536469}
2023-01-04 10:15:28,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:28,806 INFO:     Epoch: 18
2023-01-04 10:15:30,416 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42385875980059307, 'Total loss': 0.42385875980059307} | train loss {'Reaction outcome loss': 0.4260419420560525, 'Total loss': 0.4260419420560525}
2023-01-04 10:15:30,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:30,416 INFO:     Epoch: 19
2023-01-04 10:15:32,032 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.407711790005366, 'Total loss': 0.407711790005366} | train loss {'Reaction outcome loss': 0.42197569856501144, 'Total loss': 0.42197569856501144}
2023-01-04 10:15:32,032 INFO:     Found new best model at epoch 19
2023-01-04 10:15:32,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:32,033 INFO:     Epoch: 20
2023-01-04 10:15:33,488 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43610764741897584, 'Total loss': 0.43610764741897584} | train loss {'Reaction outcome loss': 0.4211831826226319, 'Total loss': 0.4211831826226319}
2023-01-04 10:15:33,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:33,490 INFO:     Epoch: 21
2023-01-04 10:15:35,070 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41604621211687726, 'Total loss': 0.41604621211687726} | train loss {'Reaction outcome loss': 0.42061709626105387, 'Total loss': 0.42061709626105387}
2023-01-04 10:15:35,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:35,071 INFO:     Epoch: 22
2023-01-04 10:15:36,639 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4245259513457616, 'Total loss': 0.4245259513457616} | train loss {'Reaction outcome loss': 0.4251747706203141, 'Total loss': 0.4251747706203141}
2023-01-04 10:15:36,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:36,640 INFO:     Epoch: 23
2023-01-04 10:15:38,230 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41733184854189553, 'Total loss': 0.41733184854189553} | train loss {'Reaction outcome loss': 0.40845023642253614, 'Total loss': 0.40845023642253614}
2023-01-04 10:15:38,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:38,230 INFO:     Epoch: 24
2023-01-04 10:15:39,812 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4175665020942688, 'Total loss': 0.4175665020942688} | train loss {'Reaction outcome loss': 0.4000394099857658, 'Total loss': 0.4000394099857658}
2023-01-04 10:15:39,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:39,813 INFO:     Epoch: 25
2023-01-04 10:15:41,402 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41988218824068707, 'Total loss': 0.41988218824068707} | train loss {'Reaction outcome loss': 0.39637246220904077, 'Total loss': 0.39637246220904077}
2023-01-04 10:15:41,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:41,402 INFO:     Epoch: 26
2023-01-04 10:15:42,875 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39188432097435, 'Total loss': 0.39188432097435} | train loss {'Reaction outcome loss': 0.39386650518365746, 'Total loss': 0.39386650518365746}
2023-01-04 10:15:42,875 INFO:     Found new best model at epoch 26
2023-01-04 10:15:42,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:42,876 INFO:     Epoch: 27
2023-01-04 10:15:44,463 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4098671366771062, 'Total loss': 0.4098671366771062} | train loss {'Reaction outcome loss': 0.39032844786086807, 'Total loss': 0.39032844786086807}
2023-01-04 10:15:44,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:44,463 INFO:     Epoch: 28
2023-01-04 10:15:46,053 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4108136196931203, 'Total loss': 0.4108136196931203} | train loss {'Reaction outcome loss': 0.38629962256443146, 'Total loss': 0.38629962256443146}
2023-01-04 10:15:46,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:46,053 INFO:     Epoch: 29
2023-01-04 10:15:47,634 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4258666843175888, 'Total loss': 0.4258666843175888} | train loss {'Reaction outcome loss': 0.38524931334499, 'Total loss': 0.38524931334499}
2023-01-04 10:15:47,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:47,634 INFO:     Epoch: 30
2023-01-04 10:15:49,230 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4161479522784551, 'Total loss': 0.4161479522784551} | train loss {'Reaction outcome loss': 0.39384610748485377, 'Total loss': 0.39384610748485377}
2023-01-04 10:15:49,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:49,230 INFO:     Epoch: 31
2023-01-04 10:15:50,822 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3845555126667023, 'Total loss': 0.3845555126667023} | train loss {'Reaction outcome loss': 0.3870089957288102, 'Total loss': 0.3870089957288102}
2023-01-04 10:15:50,823 INFO:     Found new best model at epoch 31
2023-01-04 10:15:50,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:50,823 INFO:     Epoch: 32
2023-01-04 10:15:52,276 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4242079337437948, 'Total loss': 0.4242079337437948} | train loss {'Reaction outcome loss': 0.37718879220926244, 'Total loss': 0.37718879220926244}
2023-01-04 10:15:52,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:52,277 INFO:     Epoch: 33
2023-01-04 10:15:53,857 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4156122903029124, 'Total loss': 0.4156122903029124} | train loss {'Reaction outcome loss': 0.389075013846024, 'Total loss': 0.389075013846024}
2023-01-04 10:15:53,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:53,857 INFO:     Epoch: 34
2023-01-04 10:15:55,430 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4214802185694377, 'Total loss': 0.4214802185694377} | train loss {'Reaction outcome loss': 0.3697085755044574, 'Total loss': 0.3697085755044574}
2023-01-04 10:15:55,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:55,430 INFO:     Epoch: 35
2023-01-04 10:15:56,993 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41247095465660094, 'Total loss': 0.41247095465660094} | train loss {'Reaction outcome loss': 0.3639381685251188, 'Total loss': 0.3639381685251188}
2023-01-04 10:15:56,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:56,993 INFO:     Epoch: 36
2023-01-04 10:15:58,578 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4368160287539164, 'Total loss': 0.4368160287539164} | train loss {'Reaction outcome loss': 0.36746407348824583, 'Total loss': 0.36746407348824583}
2023-01-04 10:15:58,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:15:58,578 INFO:     Epoch: 37
2023-01-04 10:16:00,172 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43130526741345726, 'Total loss': 0.43130526741345726} | train loss {'Reaction outcome loss': 0.37328692001503205, 'Total loss': 0.37328692001503205}
2023-01-04 10:16:00,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:00,172 INFO:     Epoch: 38
2023-01-04 10:16:01,632 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4019768714904785, 'Total loss': 0.4019768714904785} | train loss {'Reaction outcome loss': 0.35784423873933585, 'Total loss': 0.35784423873933585}
2023-01-04 10:16:01,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:01,632 INFO:     Epoch: 39
2023-01-04 10:16:03,199 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.418349160750707, 'Total loss': 0.418349160750707} | train loss {'Reaction outcome loss': 0.35083786622229696, 'Total loss': 0.35083786622229696}
2023-01-04 10:16:03,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:03,199 INFO:     Epoch: 40
2023-01-04 10:16:04,750 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41857704520225525, 'Total loss': 0.41857704520225525} | train loss {'Reaction outcome loss': 0.3542896583136441, 'Total loss': 0.3542896583136441}
2023-01-04 10:16:04,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:04,751 INFO:     Epoch: 41
2023-01-04 10:16:06,331 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39744675358136494, 'Total loss': 0.39744675358136494} | train loss {'Reaction outcome loss': 0.34706295042195817, 'Total loss': 0.34706295042195817}
2023-01-04 10:16:06,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:06,331 INFO:     Epoch: 42
2023-01-04 10:16:07,940 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39935628871122997, 'Total loss': 0.39935628871122997} | train loss {'Reaction outcome loss': 0.34642382877190475, 'Total loss': 0.34642382877190475}
2023-01-04 10:16:07,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:07,940 INFO:     Epoch: 43
2023-01-04 10:16:09,404 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4028762012720108, 'Total loss': 0.4028762012720108} | train loss {'Reaction outcome loss': 0.3562405255717644, 'Total loss': 0.3562405255717644}
2023-01-04 10:16:09,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:09,405 INFO:     Epoch: 44
2023-01-04 10:16:10,957 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4163369546333949, 'Total loss': 0.4163369546333949} | train loss {'Reaction outcome loss': 0.3533087802605461, 'Total loss': 0.3533087802605461}
2023-01-04 10:16:10,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:10,958 INFO:     Epoch: 45
2023-01-04 10:16:12,544 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3991439719994863, 'Total loss': 0.3991439719994863} | train loss {'Reaction outcome loss': 0.34057695776952995, 'Total loss': 0.34057695776952995}
2023-01-04 10:16:12,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:12,544 INFO:     Epoch: 46
2023-01-04 10:16:14,118 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4213315745194753, 'Total loss': 0.4213315745194753} | train loss {'Reaction outcome loss': 0.33659786560937116, 'Total loss': 0.33659786560937116}
2023-01-04 10:16:14,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:14,119 INFO:     Epoch: 47
2023-01-04 10:16:15,677 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4144521584113439, 'Total loss': 0.4144521584113439} | train loss {'Reaction outcome loss': 0.3431257177684186, 'Total loss': 0.3431257177684186}
2023-01-04 10:16:15,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:15,677 INFO:     Epoch: 48
2023-01-04 10:16:17,253 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4307708541552226, 'Total loss': 0.4307708541552226} | train loss {'Reaction outcome loss': 0.3366893128516473, 'Total loss': 0.3366893128516473}
2023-01-04 10:16:17,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:17,254 INFO:     Epoch: 49
2023-01-04 10:16:18,695 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4127394596735636, 'Total loss': 0.4127394596735636} | train loss {'Reaction outcome loss': 0.3293911679604629, 'Total loss': 0.3293911679604629}
2023-01-04 10:16:18,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:18,696 INFO:     Epoch: 50
2023-01-04 10:16:20,266 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40302561968564987, 'Total loss': 0.40302561968564987} | train loss {'Reaction outcome loss': 0.33092884327946365, 'Total loss': 0.33092884327946365}
2023-01-04 10:16:20,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:20,267 INFO:     Epoch: 51
2023-01-04 10:16:21,847 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3854218333959579, 'Total loss': 0.3854218333959579} | train loss {'Reaction outcome loss': 0.3351032564389533, 'Total loss': 0.3351032564389533}
2023-01-04 10:16:21,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:21,848 INFO:     Epoch: 52
2023-01-04 10:16:23,410 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3958278030157089, 'Total loss': 0.3958278030157089} | train loss {'Reaction outcome loss': 0.32402165269182215, 'Total loss': 0.32402165269182215}
2023-01-04 10:16:23,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:23,411 INFO:     Epoch: 53
2023-01-04 10:16:24,983 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39120304584503174, 'Total loss': 0.39120304584503174} | train loss {'Reaction outcome loss': 0.32927928611204244, 'Total loss': 0.32927928611204244}
2023-01-04 10:16:24,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:24,983 INFO:     Epoch: 54
2023-01-04 10:16:26,561 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4064821183681488, 'Total loss': 0.4064821183681488} | train loss {'Reaction outcome loss': 0.33775341599122866, 'Total loss': 0.33775341599122866}
2023-01-04 10:16:26,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:26,562 INFO:     Epoch: 55
2023-01-04 10:16:27,990 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4075971295436223, 'Total loss': 0.4075971295436223} | train loss {'Reaction outcome loss': 0.3158482302287959, 'Total loss': 0.3158482302287959}
2023-01-04 10:16:27,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:27,991 INFO:     Epoch: 56
2023-01-04 10:16:29,577 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4202149709065755, 'Total loss': 0.4202149709065755} | train loss {'Reaction outcome loss': 0.3142754027107056, 'Total loss': 0.3142754027107056}
2023-01-04 10:16:29,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:29,577 INFO:     Epoch: 57
2023-01-04 10:16:31,171 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.398421340684096, 'Total loss': 0.398421340684096} | train loss {'Reaction outcome loss': 0.3322106946961603, 'Total loss': 0.3322106946961603}
2023-01-04 10:16:31,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:31,171 INFO:     Epoch: 58
2023-01-04 10:16:32,749 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.389487624168396, 'Total loss': 0.389487624168396} | train loss {'Reaction outcome loss': 0.3406994840369789, 'Total loss': 0.3406994840369789}
2023-01-04 10:16:32,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:32,749 INFO:     Epoch: 59
2023-01-04 10:16:34,323 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4007487962643305, 'Total loss': 0.4007487962643305} | train loss {'Reaction outcome loss': 0.31631732572787913, 'Total loss': 0.31631732572787913}
2023-01-04 10:16:34,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:34,323 INFO:     Epoch: 60
2023-01-04 10:16:35,899 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42402757207552594, 'Total loss': 0.42402757207552594} | train loss {'Reaction outcome loss': 0.3296249438063714, 'Total loss': 0.3296249438063714}
2023-01-04 10:16:35,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:35,901 INFO:     Epoch: 61
2023-01-04 10:16:37,354 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.407662570476532, 'Total loss': 0.407662570476532} | train loss {'Reaction outcome loss': 0.31343334187092126, 'Total loss': 0.31343334187092126}
2023-01-04 10:16:37,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:37,354 INFO:     Epoch: 62
2023-01-04 10:16:38,943 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4106537361939748, 'Total loss': 0.4106537361939748} | train loss {'Reaction outcome loss': 0.31499393603872455, 'Total loss': 0.31499393603872455}
2023-01-04 10:16:38,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:38,943 INFO:     Epoch: 63
2023-01-04 10:16:40,553 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4099151700735092, 'Total loss': 0.4099151700735092} | train loss {'Reaction outcome loss': 0.311692766332324, 'Total loss': 0.311692766332324}
2023-01-04 10:16:40,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:40,553 INFO:     Epoch: 64
2023-01-04 10:16:42,147 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41770168642203015, 'Total loss': 0.41770168642203015} | train loss {'Reaction outcome loss': 0.3066321787005965, 'Total loss': 0.3066321787005965}
2023-01-04 10:16:42,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:42,148 INFO:     Epoch: 65
2023-01-04 10:16:43,714 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4140502572059631, 'Total loss': 0.4140502572059631} | train loss {'Reaction outcome loss': 0.3038320408752728, 'Total loss': 0.3038320408752728}
2023-01-04 10:16:43,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:43,714 INFO:     Epoch: 66
2023-01-04 10:16:45,297 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39074857930342355, 'Total loss': 0.39074857930342355} | train loss {'Reaction outcome loss': 0.3010891868817334, 'Total loss': 0.3010891868817334}
2023-01-04 10:16:45,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:45,298 INFO:     Epoch: 67
2023-01-04 10:16:46,749 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41451012194156645, 'Total loss': 0.41451012194156645} | train loss {'Reaction outcome loss': 0.30125727890433907, 'Total loss': 0.30125727890433907}
2023-01-04 10:16:46,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:46,749 INFO:     Epoch: 68
2023-01-04 10:16:48,331 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3743797610203425, 'Total loss': 0.3743797610203425} | train loss {'Reaction outcome loss': 0.29669532480218785, 'Total loss': 0.29669532480218785}
2023-01-04 10:16:48,331 INFO:     Found new best model at epoch 68
2023-01-04 10:16:48,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:48,332 INFO:     Epoch: 69
2023-01-04 10:16:49,927 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39316030343373615, 'Total loss': 0.39316030343373615} | train loss {'Reaction outcome loss': 0.29548203485804453, 'Total loss': 0.29548203485804453}
2023-01-04 10:16:49,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:49,927 INFO:     Epoch: 70
2023-01-04 10:16:51,524 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39822600881258646, 'Total loss': 0.39822600881258646} | train loss {'Reaction outcome loss': 0.294247985410882, 'Total loss': 0.294247985410882}
2023-01-04 10:16:51,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:51,524 INFO:     Epoch: 71
2023-01-04 10:16:53,098 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40858048349618914, 'Total loss': 0.40858048349618914} | train loss {'Reaction outcome loss': 0.30661254567836504, 'Total loss': 0.30661254567836504}
2023-01-04 10:16:53,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:53,099 INFO:     Epoch: 72
2023-01-04 10:16:54,654 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41297510464986165, 'Total loss': 0.41297510464986165} | train loss {'Reaction outcome loss': 0.32474894295410195, 'Total loss': 0.32474894295410195}
2023-01-04 10:16:54,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:54,655 INFO:     Epoch: 73
2023-01-04 10:16:56,134 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3857117702563604, 'Total loss': 0.3857117702563604} | train loss {'Reaction outcome loss': 0.2927384261650108, 'Total loss': 0.2927384261650108}
2023-01-04 10:16:56,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:56,134 INFO:     Epoch: 74
2023-01-04 10:16:57,708 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4032131145397822, 'Total loss': 0.4032131145397822} | train loss {'Reaction outcome loss': 0.2871770841491367, 'Total loss': 0.2871770841491367}
2023-01-04 10:16:57,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:57,709 INFO:     Epoch: 75
2023-01-04 10:16:59,311 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4162235125899315, 'Total loss': 0.4162235125899315} | train loss {'Reaction outcome loss': 0.29171590264076774, 'Total loss': 0.29171590264076774}
2023-01-04 10:16:59,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:16:59,311 INFO:     Epoch: 76
2023-01-04 10:17:00,880 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41023930807908376, 'Total loss': 0.41023930807908376} | train loss {'Reaction outcome loss': 0.28743558967202576, 'Total loss': 0.28743558967202576}
2023-01-04 10:17:00,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:00,880 INFO:     Epoch: 77
2023-01-04 10:17:02,451 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40677820444107055, 'Total loss': 0.40677820444107055} | train loss {'Reaction outcome loss': 0.2825056791149056, 'Total loss': 0.2825056791149056}
2023-01-04 10:17:02,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:02,451 INFO:     Epoch: 78
2023-01-04 10:17:03,900 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40438200334707897, 'Total loss': 0.40438200334707897} | train loss {'Reaction outcome loss': 0.288949612096168, 'Total loss': 0.288949612096168}
2023-01-04 10:17:03,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:03,900 INFO:     Epoch: 79
2023-01-04 10:17:05,474 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4088633249203364, 'Total loss': 0.4088633249203364} | train loss {'Reaction outcome loss': 0.2902711130766387, 'Total loss': 0.2902711130766387}
2023-01-04 10:17:05,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:05,474 INFO:     Epoch: 80
2023-01-04 10:17:07,073 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3992461701234182, 'Total loss': 0.3992461701234182} | train loss {'Reaction outcome loss': 0.28099846561056346, 'Total loss': 0.28099846561056346}
2023-01-04 10:17:07,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:07,073 INFO:     Epoch: 81
2023-01-04 10:17:08,646 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.415718878308932, 'Total loss': 0.415718878308932} | train loss {'Reaction outcome loss': 0.2803079431260298, 'Total loss': 0.2803079431260298}
2023-01-04 10:17:08,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:08,646 INFO:     Epoch: 82
2023-01-04 10:17:10,231 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4265077223380407, 'Total loss': 0.4265077223380407} | train loss {'Reaction outcome loss': 0.2755260760649158, 'Total loss': 0.2755260760649158}
2023-01-04 10:17:10,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:10,231 INFO:     Epoch: 83
2023-01-04 10:17:11,799 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4250461230675379, 'Total loss': 0.4250461230675379} | train loss {'Reaction outcome loss': 0.2815749002607924, 'Total loss': 0.2815749002607924}
2023-01-04 10:17:11,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:11,800 INFO:     Epoch: 84
2023-01-04 10:17:13,217 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42012386123339335, 'Total loss': 0.42012386123339335} | train loss {'Reaction outcome loss': 0.27798442536226026, 'Total loss': 0.27798442536226026}
2023-01-04 10:17:13,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:13,218 INFO:     Epoch: 85
2023-01-04 10:17:14,786 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40464588602383933, 'Total loss': 0.40464588602383933} | train loss {'Reaction outcome loss': 0.27627778710977535, 'Total loss': 0.27627778710977535}
2023-01-04 10:17:14,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:14,787 INFO:     Epoch: 86
2023-01-04 10:17:16,362 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41176830728848773, 'Total loss': 0.41176830728848773} | train loss {'Reaction outcome loss': 0.271323877953509, 'Total loss': 0.271323877953509}
2023-01-04 10:17:16,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:16,363 INFO:     Epoch: 87
2023-01-04 10:17:17,924 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.428121962149938, 'Total loss': 0.428121962149938} | train loss {'Reaction outcome loss': 0.27617389747899945, 'Total loss': 0.27617389747899945}
2023-01-04 10:17:17,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:17,925 INFO:     Epoch: 88
2023-01-04 10:17:19,485 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40818925698598224, 'Total loss': 0.40818925698598224} | train loss {'Reaction outcome loss': 0.2846421008268236, 'Total loss': 0.2846421008268236}
2023-01-04 10:17:19,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:19,485 INFO:     Epoch: 89
2023-01-04 10:17:21,062 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42427745560805, 'Total loss': 0.42427745560805} | train loss {'Reaction outcome loss': 0.29580950755895913, 'Total loss': 0.29580950755895913}
2023-01-04 10:17:21,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:21,063 INFO:     Epoch: 90
2023-01-04 10:17:22,509 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41245873669783273, 'Total loss': 0.41245873669783273} | train loss {'Reaction outcome loss': 0.35023057715380157, 'Total loss': 0.35023057715380157}
2023-01-04 10:17:22,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:22,509 INFO:     Epoch: 91
2023-01-04 10:17:24,080 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4189332644144694, 'Total loss': 0.4189332644144694} | train loss {'Reaction outcome loss': 0.2978040452648386, 'Total loss': 0.2978040452648386}
2023-01-04 10:17:24,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:24,080 INFO:     Epoch: 92
2023-01-04 10:17:25,633 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.416233237584432, 'Total loss': 0.416233237584432} | train loss {'Reaction outcome loss': 0.2862691241986492, 'Total loss': 0.2862691241986492}
2023-01-04 10:17:25,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:25,634 INFO:     Epoch: 93
2023-01-04 10:17:27,182 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4076974143584569, 'Total loss': 0.4076974143584569} | train loss {'Reaction outcome loss': 0.27437366970074095, 'Total loss': 0.27437366970074095}
2023-01-04 10:17:27,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:27,183 INFO:     Epoch: 94
2023-01-04 10:17:28,748 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39794209202130637, 'Total loss': 0.39794209202130637} | train loss {'Reaction outcome loss': 0.27135130866056145, 'Total loss': 0.27135130866056145}
2023-01-04 10:17:28,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:28,748 INFO:     Epoch: 95
2023-01-04 10:17:30,312 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41530933578809104, 'Total loss': 0.41530933578809104} | train loss {'Reaction outcome loss': 0.27554922043413355, 'Total loss': 0.27554922043413355}
2023-01-04 10:17:30,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:30,313 INFO:     Epoch: 96
2023-01-04 10:17:31,753 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42074038585027057, 'Total loss': 0.42074038585027057} | train loss {'Reaction outcome loss': 0.29773981171108416, 'Total loss': 0.29773981171108416}
2023-01-04 10:17:31,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:31,753 INFO:     Epoch: 97
2023-01-04 10:17:33,312 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41143202086289726, 'Total loss': 0.41143202086289726} | train loss {'Reaction outcome loss': 0.27623885088141303, 'Total loss': 0.27623885088141303}
2023-01-04 10:17:33,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:33,312 INFO:     Epoch: 98
2023-01-04 10:17:34,856 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4127624670664469, 'Total loss': 0.4127624670664469} | train loss {'Reaction outcome loss': 0.2741989964354392, 'Total loss': 0.2741989964354392}
2023-01-04 10:17:34,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:34,856 INFO:     Epoch: 99
2023-01-04 10:17:36,423 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42305788695812224, 'Total loss': 0.42305788695812224} | train loss {'Reaction outcome loss': 0.2703187932678755, 'Total loss': 0.2703187932678755}
2023-01-04 10:17:36,423 INFO:     Best model found after epoch 69 of 100.
2023-01-04 10:17:36,423 INFO:   Done with stage: TRAINING
2023-01-04 10:17:36,423 INFO:   Starting stage: EVALUATION
2023-01-04 10:17:36,551 INFO:   Done with stage: EVALUATION
2023-01-04 10:17:36,551 INFO:   Leaving out SEQ value Fold_8
2023-01-04 10:17:36,563 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 10:17:36,563 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:17:37,204 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:17:37,204 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:17:37,273 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:17:37,273 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:17:37,273 INFO:     No hyperparam tuning for this model
2023-01-04 10:17:37,273 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:17:37,273 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:17:37,274 INFO:     None feature selector for col prot
2023-01-04 10:17:37,274 INFO:     None feature selector for col prot
2023-01-04 10:17:37,274 INFO:     None feature selector for col prot
2023-01-04 10:17:37,275 INFO:     None feature selector for col chem
2023-01-04 10:17:37,275 INFO:     None feature selector for col chem
2023-01-04 10:17:37,275 INFO:     None feature selector for col chem
2023-01-04 10:17:37,275 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:17:37,275 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:17:37,276 INFO:     Number of params in model 70111
2023-01-04 10:17:37,279 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:17:37,279 INFO:   Starting stage: TRAINING
2023-01-04 10:17:37,321 INFO:     Val loss before train {'Reaction outcome loss': 1.1241504947344463, 'Total loss': 1.1241504947344463}
2023-01-04 10:17:37,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:37,321 INFO:     Epoch: 0
2023-01-04 10:17:38,890 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7884978830814362, 'Total loss': 0.7884978830814362} | train loss {'Reaction outcome loss': 0.8260282681521957, 'Total loss': 0.8260282681521957}
2023-01-04 10:17:38,890 INFO:     Found new best model at epoch 0
2023-01-04 10:17:38,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:38,891 INFO:     Epoch: 1
2023-01-04 10:17:40,345 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.640087350209554, 'Total loss': 0.640087350209554} | train loss {'Reaction outcome loss': 0.6565217614604247, 'Total loss': 0.6565217614604247}
2023-01-04 10:17:40,345 INFO:     Found new best model at epoch 1
2023-01-04 10:17:40,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:40,346 INFO:     Epoch: 2
2023-01-04 10:17:41,936 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5867681960264842, 'Total loss': 0.5867681960264842} | train loss {'Reaction outcome loss': 0.5696013870006864, 'Total loss': 0.5696013870006864}
2023-01-04 10:17:41,936 INFO:     Found new best model at epoch 2
2023-01-04 10:17:41,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:41,937 INFO:     Epoch: 3
2023-01-04 10:17:43,521 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5712297042210897, 'Total loss': 0.5712297042210897} | train loss {'Reaction outcome loss': 0.5279143398311594, 'Total loss': 0.5279143398311594}
2023-01-04 10:17:43,521 INFO:     Found new best model at epoch 3
2023-01-04 10:17:43,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:43,522 INFO:     Epoch: 4
2023-01-04 10:17:45,088 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5351042012373607, 'Total loss': 0.5351042012373607} | train loss {'Reaction outcome loss': 0.5057309088616595, 'Total loss': 0.5057309088616595}
2023-01-04 10:17:45,088 INFO:     Found new best model at epoch 4
2023-01-04 10:17:45,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:45,089 INFO:     Epoch: 5
2023-01-04 10:17:46,661 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5206931968530019, 'Total loss': 0.5206931968530019} | train loss {'Reaction outcome loss': 0.4926160976613472, 'Total loss': 0.4926160976613472}
2023-01-04 10:17:46,662 INFO:     Found new best model at epoch 5
2023-01-04 10:17:46,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:46,663 INFO:     Epoch: 6
2023-01-04 10:17:48,234 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.507638132572174, 'Total loss': 0.507638132572174} | train loss {'Reaction outcome loss': 0.4816059268446175, 'Total loss': 0.4816059268446175}
2023-01-04 10:17:48,234 INFO:     Found new best model at epoch 6
2023-01-04 10:17:48,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:48,235 INFO:     Epoch: 7
2023-01-04 10:17:49,665 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5493973632653554, 'Total loss': 0.5493973632653554} | train loss {'Reaction outcome loss': 0.46823217929593064, 'Total loss': 0.46823217929593064}
2023-01-04 10:17:49,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:49,665 INFO:     Epoch: 8
2023-01-04 10:17:51,237 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.502752290169398, 'Total loss': 0.502752290169398} | train loss {'Reaction outcome loss': 0.4645832414984273, 'Total loss': 0.4645832414984273}
2023-01-04 10:17:51,238 INFO:     Found new best model at epoch 8
2023-01-04 10:17:51,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:51,238 INFO:     Epoch: 9
2023-01-04 10:17:52,827 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5164626280466715, 'Total loss': 0.5164626280466715} | train loss {'Reaction outcome loss': 0.45739302273153826, 'Total loss': 0.45739302273153826}
2023-01-04 10:17:52,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:52,828 INFO:     Epoch: 10
2023-01-04 10:17:54,390 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4837428112824758, 'Total loss': 0.4837428112824758} | train loss {'Reaction outcome loss': 0.45157763985950594, 'Total loss': 0.45157763985950594}
2023-01-04 10:17:54,390 INFO:     Found new best model at epoch 10
2023-01-04 10:17:54,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:54,391 INFO:     Epoch: 11
2023-01-04 10:17:55,945 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4954765737056732, 'Total loss': 0.4954765737056732} | train loss {'Reaction outcome loss': 0.44571406526040513, 'Total loss': 0.44571406526040513}
2023-01-04 10:17:55,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:55,945 INFO:     Epoch: 12
2023-01-04 10:17:57,498 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4894973377386729, 'Total loss': 0.4894973377386729} | train loss {'Reaction outcome loss': 0.4452900131256572, 'Total loss': 0.4452900131256572}
2023-01-04 10:17:57,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:57,499 INFO:     Epoch: 13
2023-01-04 10:17:58,958 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48332626024881997, 'Total loss': 0.48332626024881997} | train loss {'Reaction outcome loss': 0.4386171264446169, 'Total loss': 0.4386171264446169}
2023-01-04 10:17:58,958 INFO:     Found new best model at epoch 13
2023-01-04 10:17:58,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:17:58,959 INFO:     Epoch: 14
2023-01-04 10:18:00,522 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4904380818208059, 'Total loss': 0.4904380818208059} | train loss {'Reaction outcome loss': 0.4276088809708826, 'Total loss': 0.4276088809708826}
2023-01-04 10:18:00,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:00,523 INFO:     Epoch: 15
2023-01-04 10:18:02,094 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.505862432718277, 'Total loss': 0.505862432718277} | train loss {'Reaction outcome loss': 0.42430378426713633, 'Total loss': 0.42430378426713633}
2023-01-04 10:18:02,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:02,094 INFO:     Epoch: 16
2023-01-04 10:18:03,656 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.471631387869517, 'Total loss': 0.471631387869517} | train loss {'Reaction outcome loss': 0.4195167742911659, 'Total loss': 0.4195167742911659}
2023-01-04 10:18:03,656 INFO:     Found new best model at epoch 16
2023-01-04 10:18:03,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:03,657 INFO:     Epoch: 17
2023-01-04 10:18:05,215 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.467348446448644, 'Total loss': 0.467348446448644} | train loss {'Reaction outcome loss': 0.4184320270477219, 'Total loss': 0.4184320270477219}
2023-01-04 10:18:05,216 INFO:     Found new best model at epoch 17
2023-01-04 10:18:05,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:05,217 INFO:     Epoch: 18
2023-01-04 10:18:06,778 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47126124103864037, 'Total loss': 0.47126124103864037} | train loss {'Reaction outcome loss': 0.41487099284084267, 'Total loss': 0.41487099284084267}
2023-01-04 10:18:06,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:06,778 INFO:     Epoch: 19
2023-01-04 10:18:08,224 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4675140460332235, 'Total loss': 0.4675140460332235} | train loss {'Reaction outcome loss': 0.40998739404906437, 'Total loss': 0.40998739404906437}
2023-01-04 10:18:08,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:08,224 INFO:     Epoch: 20
2023-01-04 10:18:09,806 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48016033371289574, 'Total loss': 0.48016033371289574} | train loss {'Reaction outcome loss': 0.4048628900132885, 'Total loss': 0.4048628900132885}
2023-01-04 10:18:09,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:09,806 INFO:     Epoch: 21
2023-01-04 10:18:11,396 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4451395352681478, 'Total loss': 0.4451395352681478} | train loss {'Reaction outcome loss': 0.39949240731848706, 'Total loss': 0.39949240731848706}
2023-01-04 10:18:11,396 INFO:     Found new best model at epoch 21
2023-01-04 10:18:11,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:11,397 INFO:     Epoch: 22
2023-01-04 10:18:12,979 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4677603175242742, 'Total loss': 0.4677603175242742} | train loss {'Reaction outcome loss': 0.39735638788676003, 'Total loss': 0.39735638788676003}
2023-01-04 10:18:12,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:12,979 INFO:     Epoch: 23
2023-01-04 10:18:14,563 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4562408765157064, 'Total loss': 0.4562408765157064} | train loss {'Reaction outcome loss': 0.39180547222226103, 'Total loss': 0.39180547222226103}
2023-01-04 10:18:14,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:14,563 INFO:     Epoch: 24
2023-01-04 10:18:16,059 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4867102364699046, 'Total loss': 0.4867102364699046} | train loss {'Reaction outcome loss': 0.391002605833947, 'Total loss': 0.391002605833947}
2023-01-04 10:18:16,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:16,060 INFO:     Epoch: 25
2023-01-04 10:18:17,616 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4464033742745717, 'Total loss': 0.4464033742745717} | train loss {'Reaction outcome loss': 0.38621793940179183, 'Total loss': 0.38621793940179183}
2023-01-04 10:18:17,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:17,617 INFO:     Epoch: 26
2023-01-04 10:18:19,186 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47342466910680137, 'Total loss': 0.47342466910680137} | train loss {'Reaction outcome loss': 0.3828017925742731, 'Total loss': 0.3828017925742731}
2023-01-04 10:18:19,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:19,186 INFO:     Epoch: 27
2023-01-04 10:18:20,775 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5024421672026317, 'Total loss': 0.5024421672026317} | train loss {'Reaction outcome loss': 0.3755783019083071, 'Total loss': 0.3755783019083071}
2023-01-04 10:18:20,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:20,775 INFO:     Epoch: 28
2023-01-04 10:18:22,363 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4897952775160472, 'Total loss': 0.4897952775160472} | train loss {'Reaction outcome loss': 0.3741585570875058, 'Total loss': 0.3741585570875058}
2023-01-04 10:18:22,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:22,363 INFO:     Epoch: 29
2023-01-04 10:18:23,966 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4711052566766739, 'Total loss': 0.4711052566766739} | train loss {'Reaction outcome loss': 0.3674716535780834, 'Total loss': 0.3674716535780834}
2023-01-04 10:18:23,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:23,967 INFO:     Epoch: 30
2023-01-04 10:18:25,454 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4470489263534546, 'Total loss': 0.4470489263534546} | train loss {'Reaction outcome loss': 0.37136490844754966, 'Total loss': 0.37136490844754966}
2023-01-04 10:18:25,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:25,454 INFO:     Epoch: 31
2023-01-04 10:18:27,043 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46640271743138634, 'Total loss': 0.46640271743138634} | train loss {'Reaction outcome loss': 0.36464111469282573, 'Total loss': 0.36464111469282573}
2023-01-04 10:18:27,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:27,044 INFO:     Epoch: 32
2023-01-04 10:18:28,632 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46528663436571754, 'Total loss': 0.46528663436571754} | train loss {'Reaction outcome loss': 0.36501238409039777, 'Total loss': 0.36501238409039777}
2023-01-04 10:18:28,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:28,632 INFO:     Epoch: 33
2023-01-04 10:18:30,227 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46960045099258424, 'Total loss': 0.46960045099258424} | train loss {'Reaction outcome loss': 0.35753654320102307, 'Total loss': 0.35753654320102307}
2023-01-04 10:18:30,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:30,227 INFO:     Epoch: 34
2023-01-04 10:18:31,813 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4730976909399033, 'Total loss': 0.4730976909399033} | train loss {'Reaction outcome loss': 0.3534622412403568, 'Total loss': 0.3534622412403568}
2023-01-04 10:18:31,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:31,813 INFO:     Epoch: 35
2023-01-04 10:18:33,409 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.455896000067393, 'Total loss': 0.455896000067393} | train loss {'Reaction outcome loss': 0.3548311997837108, 'Total loss': 0.3548311997837108}
2023-01-04 10:18:33,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:33,409 INFO:     Epoch: 36
2023-01-04 10:18:34,875 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4740706910689672, 'Total loss': 0.4740706910689672} | train loss {'Reaction outcome loss': 0.35001043700999734, 'Total loss': 0.35001043700999734}
2023-01-04 10:18:34,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:34,875 INFO:     Epoch: 37
2023-01-04 10:18:36,457 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4484443912903468, 'Total loss': 0.4484443912903468} | train loss {'Reaction outcome loss': 0.347880080288498, 'Total loss': 0.347880080288498}
2023-01-04 10:18:36,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:36,458 INFO:     Epoch: 38
2023-01-04 10:18:38,036 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45220793386300406, 'Total loss': 0.45220793386300406} | train loss {'Reaction outcome loss': 0.350204451850175, 'Total loss': 0.350204451850175}
2023-01-04 10:18:38,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:38,036 INFO:     Epoch: 39
2023-01-04 10:18:39,632 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44564041097958884, 'Total loss': 0.44564041097958884} | train loss {'Reaction outcome loss': 0.3454788815673938, 'Total loss': 0.3454788815673938}
2023-01-04 10:18:39,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:39,632 INFO:     Epoch: 40
2023-01-04 10:18:41,226 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46901702682177226, 'Total loss': 0.46901702682177226} | train loss {'Reaction outcome loss': 0.33883419552219474, 'Total loss': 0.33883419552219474}
2023-01-04 10:18:41,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:41,226 INFO:     Epoch: 41
2023-01-04 10:18:42,808 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4700937827428182, 'Total loss': 0.4700937827428182} | train loss {'Reaction outcome loss': 0.3383022180425561, 'Total loss': 0.3383022180425561}
2023-01-04 10:18:42,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:42,808 INFO:     Epoch: 42
2023-01-04 10:18:44,300 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46174900929133095, 'Total loss': 0.46174900929133095} | train loss {'Reaction outcome loss': 0.33503477487861033, 'Total loss': 0.33503477487861033}
2023-01-04 10:18:44,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:44,300 INFO:     Epoch: 43
2023-01-04 10:18:45,889 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4509237498044968, 'Total loss': 0.4509237498044968} | train loss {'Reaction outcome loss': 0.3347919425701837, 'Total loss': 0.3347919425701837}
2023-01-04 10:18:45,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:45,890 INFO:     Epoch: 44
2023-01-04 10:18:47,470 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.422654124101003, 'Total loss': 0.422654124101003} | train loss {'Reaction outcome loss': 0.32898193024878897, 'Total loss': 0.32898193024878897}
2023-01-04 10:18:47,470 INFO:     Found new best model at epoch 44
2023-01-04 10:18:47,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:47,471 INFO:     Epoch: 45
2023-01-04 10:18:49,050 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44000884691874187, 'Total loss': 0.44000884691874187} | train loss {'Reaction outcome loss': 0.3286804403531422, 'Total loss': 0.3286804403531422}
2023-01-04 10:18:49,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:49,051 INFO:     Epoch: 46
2023-01-04 10:18:50,629 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4361284683148066, 'Total loss': 0.4361284683148066} | train loss {'Reaction outcome loss': 0.3261761074408297, 'Total loss': 0.3261761074408297}
2023-01-04 10:18:50,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:50,629 INFO:     Epoch: 47
2023-01-04 10:18:52,180 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46836472352345787, 'Total loss': 0.46836472352345787} | train loss {'Reaction outcome loss': 0.3249815343895974, 'Total loss': 0.3249815343895974}
2023-01-04 10:18:52,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:52,181 INFO:     Epoch: 48
2023-01-04 10:18:53,666 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4600187599658966, 'Total loss': 0.4600187599658966} | train loss {'Reaction outcome loss': 0.32489541735136984, 'Total loss': 0.32489541735136984}
2023-01-04 10:18:53,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:53,666 INFO:     Epoch: 49
2023-01-04 10:18:55,237 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4330244779586792, 'Total loss': 0.4330244779586792} | train loss {'Reaction outcome loss': 0.3235139179477192, 'Total loss': 0.3235139179477192}
2023-01-04 10:18:55,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:55,238 INFO:     Epoch: 50
2023-01-04 10:18:56,802 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4534469376007716, 'Total loss': 0.4534469376007716} | train loss {'Reaction outcome loss': 0.3180025258918531, 'Total loss': 0.3180025258918531}
2023-01-04 10:18:56,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:56,802 INFO:     Epoch: 51
2023-01-04 10:18:58,361 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4121904507279396, 'Total loss': 0.4121904507279396} | train loss {'Reaction outcome loss': 0.32140935232546786, 'Total loss': 0.32140935232546786}
2023-01-04 10:18:58,361 INFO:     Found new best model at epoch 51
2023-01-04 10:18:58,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:58,362 INFO:     Epoch: 52
2023-01-04 10:18:59,927 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4456837187210719, 'Total loss': 0.4456837187210719} | train loss {'Reaction outcome loss': 0.3174055900007809, 'Total loss': 0.3174055900007809}
2023-01-04 10:18:59,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:18:59,928 INFO:     Epoch: 53
2023-01-04 10:19:01,414 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4429724246263504, 'Total loss': 0.4429724246263504} | train loss {'Reaction outcome loss': 0.30969796593331256, 'Total loss': 0.30969796593331256}
2023-01-04 10:19:01,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:01,414 INFO:     Epoch: 54
2023-01-04 10:19:02,978 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47310054302215576, 'Total loss': 0.47310054302215576} | train loss {'Reaction outcome loss': 0.3149870499054017, 'Total loss': 0.3149870499054017}
2023-01-04 10:19:02,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:02,978 INFO:     Epoch: 55
2023-01-04 10:19:04,533 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4372103542089462, 'Total loss': 0.4372103542089462} | train loss {'Reaction outcome loss': 0.31011981393348437, 'Total loss': 0.31011981393348437}
2023-01-04 10:19:04,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:04,533 INFO:     Epoch: 56
2023-01-04 10:19:06,110 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4254591117302577, 'Total loss': 0.4254591117302577} | train loss {'Reaction outcome loss': 0.3068434861270099, 'Total loss': 0.3068434861270099}
2023-01-04 10:19:06,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:06,111 INFO:     Epoch: 57
2023-01-04 10:19:07,686 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45536103248596194, 'Total loss': 0.45536103248596194} | train loss {'Reaction outcome loss': 0.31160391953232486, 'Total loss': 0.31160391953232486}
2023-01-04 10:19:07,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:07,687 INFO:     Epoch: 58
2023-01-04 10:19:09,261 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4711394250392914, 'Total loss': 0.4711394250392914} | train loss {'Reaction outcome loss': 0.3058313865765983, 'Total loss': 0.3058313865765983}
2023-01-04 10:19:09,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:09,261 INFO:     Epoch: 59
2023-01-04 10:19:10,747 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43687413930892943, 'Total loss': 0.43687413930892943} | train loss {'Reaction outcome loss': 0.299889845645815, 'Total loss': 0.299889845645815}
2023-01-04 10:19:10,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:10,748 INFO:     Epoch: 60
2023-01-04 10:19:12,335 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4339038093884786, 'Total loss': 0.4339038093884786} | train loss {'Reaction outcome loss': 0.30071140559464155, 'Total loss': 0.30071140559464155}
2023-01-04 10:19:12,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:12,335 INFO:     Epoch: 61
2023-01-04 10:19:13,926 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40711825688680015, 'Total loss': 0.40711825688680015} | train loss {'Reaction outcome loss': 0.3026370392702116, 'Total loss': 0.3026370392702116}
2023-01-04 10:19:13,926 INFO:     Found new best model at epoch 61
2023-01-04 10:19:13,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:13,927 INFO:     Epoch: 62
2023-01-04 10:19:15,494 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4228654762109121, 'Total loss': 0.4228654762109121} | train loss {'Reaction outcome loss': 0.2990419623519324, 'Total loss': 0.2990419623519324}
2023-01-04 10:19:15,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:15,495 INFO:     Epoch: 63
2023-01-04 10:19:17,059 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4384762008984884, 'Total loss': 0.4384762008984884} | train loss {'Reaction outcome loss': 0.30126229256714293, 'Total loss': 0.30126229256714293}
2023-01-04 10:19:17,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:17,059 INFO:     Epoch: 64
2023-01-04 10:19:18,623 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4465499222278595, 'Total loss': 0.4465499222278595} | train loss {'Reaction outcome loss': 0.2976348050449729, 'Total loss': 0.2976348050449729}
2023-01-04 10:19:18,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:18,623 INFO:     Epoch: 65
2023-01-04 10:19:20,112 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4287400503953298, 'Total loss': 0.4287400503953298} | train loss {'Reaction outcome loss': 0.2942891179143522, 'Total loss': 0.2942891179143522}
2023-01-04 10:19:20,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:20,112 INFO:     Epoch: 66
2023-01-04 10:19:21,700 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4243408610423406, 'Total loss': 0.4243408610423406} | train loss {'Reaction outcome loss': 0.2928565738971483, 'Total loss': 0.2928565738971483}
2023-01-04 10:19:21,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:21,700 INFO:     Epoch: 67
2023-01-04 10:19:23,285 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42940685749053953, 'Total loss': 0.42940685749053953} | train loss {'Reaction outcome loss': 0.2908439618478183, 'Total loss': 0.2908439618478183}
2023-01-04 10:19:23,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:23,286 INFO:     Epoch: 68
2023-01-04 10:19:24,871 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4363248775402705, 'Total loss': 0.4363248775402705} | train loss {'Reaction outcome loss': 0.29464242891122716, 'Total loss': 0.29464242891122716}
2023-01-04 10:19:24,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:24,872 INFO:     Epoch: 69
2023-01-04 10:19:26,459 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4143805662790934, 'Total loss': 0.4143805662790934} | train loss {'Reaction outcome loss': 0.28999618099269453, 'Total loss': 0.28999618099269453}
2023-01-04 10:19:26,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:26,459 INFO:     Epoch: 70
2023-01-04 10:19:28,032 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4335229496161143, 'Total loss': 0.4335229496161143} | train loss {'Reaction outcome loss': 0.2918419565480969, 'Total loss': 0.2918419565480969}
2023-01-04 10:19:28,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:28,032 INFO:     Epoch: 71
2023-01-04 10:19:29,509 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45193608005841573, 'Total loss': 0.45193608005841573} | train loss {'Reaction outcome loss': 0.2883437955583906, 'Total loss': 0.2883437955583906}
2023-01-04 10:19:29,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:29,509 INFO:     Epoch: 72
2023-01-04 10:19:31,069 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4559254805246989, 'Total loss': 0.4559254805246989} | train loss {'Reaction outcome loss': 0.2894136247490718, 'Total loss': 0.2894136247490718}
2023-01-04 10:19:31,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:31,070 INFO:     Epoch: 73
2023-01-04 10:19:32,671 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4426904559135437, 'Total loss': 0.4426904559135437} | train loss {'Reaction outcome loss': 0.28488305163996747, 'Total loss': 0.28488305163996747}
2023-01-04 10:19:32,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:32,671 INFO:     Epoch: 74
2023-01-04 10:19:34,240 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44331502517064414, 'Total loss': 0.44331502517064414} | train loss {'Reaction outcome loss': 0.2821959591595059, 'Total loss': 0.2821959591595059}
2023-01-04 10:19:34,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:34,240 INFO:     Epoch: 75
2023-01-04 10:19:35,825 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45731181899706524, 'Total loss': 0.45731181899706524} | train loss {'Reaction outcome loss': 0.2837661596465627, 'Total loss': 0.2837661596465627}
2023-01-04 10:19:35,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:35,825 INFO:     Epoch: 76
2023-01-04 10:19:37,408 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40985178053379057, 'Total loss': 0.40985178053379057} | train loss {'Reaction outcome loss': 0.2825736671632378, 'Total loss': 0.2825736671632378}
2023-01-04 10:19:37,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:37,408 INFO:     Epoch: 77
2023-01-04 10:19:38,899 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4311316172281901, 'Total loss': 0.4311316172281901} | train loss {'Reaction outcome loss': 0.28452059720720196, 'Total loss': 0.28452059720720196}
2023-01-04 10:19:38,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:38,899 INFO:     Epoch: 78
2023-01-04 10:19:40,498 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4331219176451365, 'Total loss': 0.4331219176451365} | train loss {'Reaction outcome loss': 0.2801824293304436, 'Total loss': 0.2801824293304436}
2023-01-04 10:19:40,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:40,498 INFO:     Epoch: 79
2023-01-04 10:19:42,110 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44916220704714455, 'Total loss': 0.44916220704714455} | train loss {'Reaction outcome loss': 0.27995570517726753, 'Total loss': 0.27995570517726753}
2023-01-04 10:19:42,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:42,110 INFO:     Epoch: 80
2023-01-04 10:19:43,685 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4435393253962199, 'Total loss': 0.4435393253962199} | train loss {'Reaction outcome loss': 0.28084499450797207, 'Total loss': 0.28084499450797207}
2023-01-04 10:19:43,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:43,686 INFO:     Epoch: 81
2023-01-04 10:19:45,241 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44854889114697777, 'Total loss': 0.44854889114697777} | train loss {'Reaction outcome loss': 0.2737644116532071, 'Total loss': 0.2737644116532071}
2023-01-04 10:19:45,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:45,241 INFO:     Epoch: 82
2023-01-04 10:19:46,800 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4543164173762004, 'Total loss': 0.4543164173762004} | train loss {'Reaction outcome loss': 0.27729366039218456, 'Total loss': 0.27729366039218456}
2023-01-04 10:19:46,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:46,801 INFO:     Epoch: 83
2023-01-04 10:19:48,292 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42607365747292836, 'Total loss': 0.42607365747292836} | train loss {'Reaction outcome loss': 0.27238789085123943, 'Total loss': 0.27238789085123943}
2023-01-04 10:19:48,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:48,292 INFO:     Epoch: 84
2023-01-04 10:19:49,860 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40912398099899294, 'Total loss': 0.40912398099899294} | train loss {'Reaction outcome loss': 0.26831958869250244, 'Total loss': 0.26831958869250244}
2023-01-04 10:19:49,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:49,860 INFO:     Epoch: 85
2023-01-04 10:19:51,427 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41084284881750743, 'Total loss': 0.41084284881750743} | train loss {'Reaction outcome loss': 0.26745370154131193, 'Total loss': 0.26745370154131193}
2023-01-04 10:19:51,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:51,427 INFO:     Epoch: 86
2023-01-04 10:19:52,983 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44963382681210834, 'Total loss': 0.44963382681210834} | train loss {'Reaction outcome loss': 0.26726144887103503, 'Total loss': 0.26726144887103503}
2023-01-04 10:19:52,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:52,984 INFO:     Epoch: 87
2023-01-04 10:19:54,560 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45696557660897574, 'Total loss': 0.45696557660897574} | train loss {'Reaction outcome loss': 0.2770103558037255, 'Total loss': 0.2770103558037255}
2023-01-04 10:19:54,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:54,560 INFO:     Epoch: 88
2023-01-04 10:19:56,084 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4326540489991506, 'Total loss': 0.4326540489991506} | train loss {'Reaction outcome loss': 0.2686702229001892, 'Total loss': 0.2686702229001892}
2023-01-04 10:19:56,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:56,084 INFO:     Epoch: 89
2023-01-04 10:19:57,650 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4502538055181503, 'Total loss': 0.4502538055181503} | train loss {'Reaction outcome loss': 0.26821380767581265, 'Total loss': 0.26821380767581265}
2023-01-04 10:19:57,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:57,650 INFO:     Epoch: 90
2023-01-04 10:19:59,240 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45790746609369914, 'Total loss': 0.45790746609369914} | train loss {'Reaction outcome loss': 0.26696254009051446, 'Total loss': 0.26696254009051446}
2023-01-04 10:19:59,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:19:59,241 INFO:     Epoch: 91
2023-01-04 10:20:00,832 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43107887109120685, 'Total loss': 0.43107887109120685} | train loss {'Reaction outcome loss': 0.26666112170833756, 'Total loss': 0.26666112170833756}
2023-01-04 10:20:00,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:00,833 INFO:     Epoch: 92
2023-01-04 10:20:02,435 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4757986510793368, 'Total loss': 0.4757986510793368} | train loss {'Reaction outcome loss': 0.26540331077166845, 'Total loss': 0.26540331077166845}
2023-01-04 10:20:02,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:02,436 INFO:     Epoch: 93
2023-01-04 10:20:04,037 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43095491925875345, 'Total loss': 0.43095491925875345} | train loss {'Reaction outcome loss': 0.26185833461017816, 'Total loss': 0.26185833461017816}
2023-01-04 10:20:04,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:04,038 INFO:     Epoch: 94
2023-01-04 10:20:05,540 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43422669967015587, 'Total loss': 0.43422669967015587} | train loss {'Reaction outcome loss': 0.2653075782077837, 'Total loss': 0.2653075782077837}
2023-01-04 10:20:05,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:05,540 INFO:     Epoch: 95
2023-01-04 10:20:07,116 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4202153901259104, 'Total loss': 0.4202153901259104} | train loss {'Reaction outcome loss': 0.2666356481800011, 'Total loss': 0.2666356481800011}
2023-01-04 10:20:07,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:07,117 INFO:     Epoch: 96
2023-01-04 10:20:08,699 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44695121149222056, 'Total loss': 0.44695121149222056} | train loss {'Reaction outcome loss': 0.2653441861513935, 'Total loss': 0.2653441861513935}
2023-01-04 10:20:08,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:08,699 INFO:     Epoch: 97
2023-01-04 10:20:10,281 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4348674178123474, 'Total loss': 0.4348674178123474} | train loss {'Reaction outcome loss': 0.2603903706942009, 'Total loss': 0.2603903706942009}
2023-01-04 10:20:10,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:10,281 INFO:     Epoch: 98
2023-01-04 10:20:11,860 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4172573735316594, 'Total loss': 0.4172573735316594} | train loss {'Reaction outcome loss': 0.263209369800151, 'Total loss': 0.263209369800151}
2023-01-04 10:20:11,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:11,861 INFO:     Epoch: 99
2023-01-04 10:20:13,435 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42342450718084973, 'Total loss': 0.42342450718084973} | train loss {'Reaction outcome loss': 0.2618544963507876, 'Total loss': 0.2618544963507876}
2023-01-04 10:20:13,436 INFO:     Best model found after epoch 62 of 100.
2023-01-04 10:20:13,436 INFO:   Done with stage: TRAINING
2023-01-04 10:20:13,436 INFO:   Starting stage: EVALUATION
2023-01-04 10:20:13,556 INFO:   Done with stage: EVALUATION
2023-01-04 10:20:13,556 INFO:   Leaving out SEQ value Fold_9
2023-01-04 10:20:13,569 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 10:20:13,569 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:20:14,211 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:20:14,212 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:20:14,280 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:20:14,280 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:20:14,280 INFO:     No hyperparam tuning for this model
2023-01-04 10:20:14,280 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:20:14,280 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:20:14,281 INFO:     None feature selector for col prot
2023-01-04 10:20:14,281 INFO:     None feature selector for col prot
2023-01-04 10:20:14,281 INFO:     None feature selector for col prot
2023-01-04 10:20:14,281 INFO:     None feature selector for col chem
2023-01-04 10:20:14,282 INFO:     None feature selector for col chem
2023-01-04 10:20:14,282 INFO:     None feature selector for col chem
2023-01-04 10:20:14,282 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:20:14,282 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:20:14,283 INFO:     Number of params in model 70111
2023-01-04 10:20:14,286 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:20:14,286 INFO:   Starting stage: TRAINING
2023-01-04 10:20:14,330 INFO:     Val loss before train {'Reaction outcome loss': 0.989765481154124, 'Total loss': 0.989765481154124}
2023-01-04 10:20:14,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:14,330 INFO:     Epoch: 0
2023-01-04 10:20:15,896 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6895800252755483, 'Total loss': 0.6895800252755483} | train loss {'Reaction outcome loss': 0.8579884952586481, 'Total loss': 0.8579884952586481}
2023-01-04 10:20:15,896 INFO:     Found new best model at epoch 0
2023-01-04 10:20:15,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:15,896 INFO:     Epoch: 1
2023-01-04 10:20:17,472 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6047434349854787, 'Total loss': 0.6047434349854787} | train loss {'Reaction outcome loss': 0.6979964145254142, 'Total loss': 0.6979964145254142}
2023-01-04 10:20:17,472 INFO:     Found new best model at epoch 1
2023-01-04 10:20:17,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:17,472 INFO:     Epoch: 2
2023-01-04 10:20:19,039 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5169196824232737, 'Total loss': 0.5169196824232737} | train loss {'Reaction outcome loss': 0.6159589866223318, 'Total loss': 0.6159589866223318}
2023-01-04 10:20:19,039 INFO:     Found new best model at epoch 2
2023-01-04 10:20:19,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:19,040 INFO:     Epoch: 3
2023-01-04 10:20:20,609 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5081947982311249, 'Total loss': 0.5081947982311249} | train loss {'Reaction outcome loss': 0.5618321523339309, 'Total loss': 0.5618321523339309}
2023-01-04 10:20:20,610 INFO:     Found new best model at epoch 3
2023-01-04 10:20:20,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:20,611 INFO:     Epoch: 4
2023-01-04 10:20:22,186 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4707340439160665, 'Total loss': 0.4707340439160665} | train loss {'Reaction outcome loss': 0.5370405730572848, 'Total loss': 0.5370405730572848}
2023-01-04 10:20:22,186 INFO:     Found new best model at epoch 4
2023-01-04 10:20:22,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:22,187 INFO:     Epoch: 5
2023-01-04 10:20:23,668 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4601484457651774, 'Total loss': 0.4601484457651774} | train loss {'Reaction outcome loss': 0.5196098771336276, 'Total loss': 0.5196098771336276}
2023-01-04 10:20:23,668 INFO:     Found new best model at epoch 5
2023-01-04 10:20:23,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:23,669 INFO:     Epoch: 6
2023-01-04 10:20:25,233 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.468053404490153, 'Total loss': 0.468053404490153} | train loss {'Reaction outcome loss': 0.5091949438790552, 'Total loss': 0.5091949438790552}
2023-01-04 10:20:25,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:25,233 INFO:     Epoch: 7
2023-01-04 10:20:26,815 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4328637917836507, 'Total loss': 0.4328637917836507} | train loss {'Reaction outcome loss': 0.498143445929035, 'Total loss': 0.498143445929035}
2023-01-04 10:20:26,816 INFO:     Found new best model at epoch 7
2023-01-04 10:20:26,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:26,816 INFO:     Epoch: 8
2023-01-04 10:20:28,388 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42518221139907836, 'Total loss': 0.42518221139907836} | train loss {'Reaction outcome loss': 0.4874972384221287, 'Total loss': 0.4874972384221287}
2023-01-04 10:20:28,388 INFO:     Found new best model at epoch 8
2023-01-04 10:20:28,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:28,389 INFO:     Epoch: 9
2023-01-04 10:20:29,954 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4352560997009277, 'Total loss': 0.4352560997009277} | train loss {'Reaction outcome loss': 0.4812939716267672, 'Total loss': 0.4812939716267672}
2023-01-04 10:20:29,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:29,954 INFO:     Epoch: 10
2023-01-04 10:20:31,540 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40754025280475614, 'Total loss': 0.40754025280475614} | train loss {'Reaction outcome loss': 0.4742485676969432, 'Total loss': 0.4742485676969432}
2023-01-04 10:20:31,540 INFO:     Found new best model at epoch 10
2023-01-04 10:20:31,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:31,541 INFO:     Epoch: 11
2023-01-04 10:20:33,017 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43660845756530764, 'Total loss': 0.43660845756530764} | train loss {'Reaction outcome loss': 0.46572740903184734, 'Total loss': 0.46572740903184734}
2023-01-04 10:20:33,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:33,017 INFO:     Epoch: 12
2023-01-04 10:20:34,593 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43175803621610004, 'Total loss': 0.43175803621610004} | train loss {'Reaction outcome loss': 0.4618764294829179, 'Total loss': 0.4618764294829179}
2023-01-04 10:20:34,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:34,593 INFO:     Epoch: 13
2023-01-04 10:20:36,155 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4316373775402705, 'Total loss': 0.4316373775402705} | train loss {'Reaction outcome loss': 0.45884524780705516, 'Total loss': 0.45884524780705516}
2023-01-04 10:20:36,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:36,156 INFO:     Epoch: 14
2023-01-04 10:20:37,748 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42277489602565765, 'Total loss': 0.42277489602565765} | train loss {'Reaction outcome loss': 0.4552515932368888, 'Total loss': 0.4552515932368888}
2023-01-04 10:20:37,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:37,748 INFO:     Epoch: 15
2023-01-04 10:20:39,329 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4232360730568568, 'Total loss': 0.4232360730568568} | train loss {'Reaction outcome loss': 0.4490222872809813, 'Total loss': 0.4490222872809813}
2023-01-04 10:20:39,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:39,329 INFO:     Epoch: 16
2023-01-04 10:20:40,902 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41343496441841127, 'Total loss': 0.41343496441841127} | train loss {'Reaction outcome loss': 0.4470734265414386, 'Total loss': 0.4470734265414386}
2023-01-04 10:20:40,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:40,903 INFO:     Epoch: 17
2023-01-04 10:20:42,395 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41520130038261416, 'Total loss': 0.41520130038261416} | train loss {'Reaction outcome loss': 0.4378546179954756, 'Total loss': 0.4378546179954756}
2023-01-04 10:20:42,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:42,396 INFO:     Epoch: 18
2023-01-04 10:20:43,963 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40185121993223827, 'Total loss': 0.40185121993223827} | train loss {'Reaction outcome loss': 0.4349449537290993, 'Total loss': 0.4349449537290993}
2023-01-04 10:20:43,963 INFO:     Found new best model at epoch 18
2023-01-04 10:20:43,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:43,964 INFO:     Epoch: 19
2023-01-04 10:20:45,552 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40591654578844705, 'Total loss': 0.40591654578844705} | train loss {'Reaction outcome loss': 0.42687458483105534, 'Total loss': 0.42687458483105534}
2023-01-04 10:20:45,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:45,552 INFO:     Epoch: 20
2023-01-04 10:20:47,120 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39671169718106586, 'Total loss': 0.39671169718106586} | train loss {'Reaction outcome loss': 0.42753374135451194, 'Total loss': 0.42753374135451194}
2023-01-04 10:20:47,120 INFO:     Found new best model at epoch 20
2023-01-04 10:20:47,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:47,121 INFO:     Epoch: 21
2023-01-04 10:20:48,693 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40937894582748413, 'Total loss': 0.40937894582748413} | train loss {'Reaction outcome loss': 0.42325721460559307, 'Total loss': 0.42325721460559307}
2023-01-04 10:20:48,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:48,693 INFO:     Epoch: 22
2023-01-04 10:20:50,261 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3957652846972148, 'Total loss': 0.3957652846972148} | train loss {'Reaction outcome loss': 0.42029012037636143, 'Total loss': 0.42029012037636143}
2023-01-04 10:20:50,261 INFO:     Found new best model at epoch 22
2023-01-04 10:20:50,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:50,262 INFO:     Epoch: 23
2023-01-04 10:20:51,754 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41295443574587504, 'Total loss': 0.41295443574587504} | train loss {'Reaction outcome loss': 0.41503127788055677, 'Total loss': 0.41503127788055677}
2023-01-04 10:20:51,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:51,754 INFO:     Epoch: 24
2023-01-04 10:20:53,317 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40177860458691916, 'Total loss': 0.40177860458691916} | train loss {'Reaction outcome loss': 0.4090460272579847, 'Total loss': 0.4090460272579847}
2023-01-04 10:20:53,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:53,317 INFO:     Epoch: 25
2023-01-04 10:20:54,883 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42525014877319334, 'Total loss': 0.42525014877319334} | train loss {'Reaction outcome loss': 0.40658474129890276, 'Total loss': 0.40658474129890276}
2023-01-04 10:20:54,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:54,884 INFO:     Epoch: 26
2023-01-04 10:20:56,451 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39744022289911907, 'Total loss': 0.39744022289911907} | train loss {'Reaction outcome loss': 0.40296336599635735, 'Total loss': 0.40296336599635735}
2023-01-04 10:20:56,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:56,451 INFO:     Epoch: 27
2023-01-04 10:20:58,032 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41171359618504844, 'Total loss': 0.41171359618504844} | train loss {'Reaction outcome loss': 0.3963909417337029, 'Total loss': 0.3963909417337029}
2023-01-04 10:20:58,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:58,032 INFO:     Epoch: 28
2023-01-04 10:20:59,554 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40479258000850676, 'Total loss': 0.40479258000850676} | train loss {'Reaction outcome loss': 0.39091811267262333, 'Total loss': 0.39091811267262333}
2023-01-04 10:20:59,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:20:59,554 INFO:     Epoch: 29
2023-01-04 10:21:01,113 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3956483662128448, 'Total loss': 0.3956483662128448} | train loss {'Reaction outcome loss': 0.3931881539012551, 'Total loss': 0.3931881539012551}
2023-01-04 10:21:01,113 INFO:     Found new best model at epoch 29
2023-01-04 10:21:01,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:01,114 INFO:     Epoch: 30
2023-01-04 10:21:02,695 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4256724258263906, 'Total loss': 0.4256724258263906} | train loss {'Reaction outcome loss': 0.38298926537432826, 'Total loss': 0.38298926537432826}
2023-01-04 10:21:02,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:02,695 INFO:     Epoch: 31
2023-01-04 10:21:04,269 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39394988417625426, 'Total loss': 0.39394988417625426} | train loss {'Reaction outcome loss': 0.3845395783924024, 'Total loss': 0.3845395783924024}
2023-01-04 10:21:04,269 INFO:     Found new best model at epoch 31
2023-01-04 10:21:04,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:04,269 INFO:     Epoch: 32
2023-01-04 10:21:05,856 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38523181676864626, 'Total loss': 0.38523181676864626} | train loss {'Reaction outcome loss': 0.3772411538483003, 'Total loss': 0.3772411538483003}
2023-01-04 10:21:05,856 INFO:     Found new best model at epoch 32
2023-01-04 10:21:05,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:05,857 INFO:     Epoch: 33
2023-01-04 10:21:07,443 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3808863947788874, 'Total loss': 0.3808863947788874} | train loss {'Reaction outcome loss': 0.37494319965155115, 'Total loss': 0.37494319965155115}
2023-01-04 10:21:07,444 INFO:     Found new best model at epoch 33
2023-01-04 10:21:07,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:07,444 INFO:     Epoch: 34
2023-01-04 10:21:08,969 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38343099852403006, 'Total loss': 0.38343099852403006} | train loss {'Reaction outcome loss': 0.36984794772488977, 'Total loss': 0.36984794772488977}
2023-01-04 10:21:08,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:08,969 INFO:     Epoch: 35
2023-01-04 10:21:10,532 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38200586338837944, 'Total loss': 0.38200586338837944} | train loss {'Reaction outcome loss': 0.3673834541698225, 'Total loss': 0.3673834541698225}
2023-01-04 10:21:10,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:10,532 INFO:     Epoch: 36
2023-01-04 10:21:12,109 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3682383522391319, 'Total loss': 0.3682383522391319} | train loss {'Reaction outcome loss': 0.3606664491582003, 'Total loss': 0.3606664491582003}
2023-01-04 10:21:12,109 INFO:     Found new best model at epoch 36
2023-01-04 10:21:12,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:12,109 INFO:     Epoch: 37
2023-01-04 10:21:13,700 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39528167247772217, 'Total loss': 0.39528167247772217} | train loss {'Reaction outcome loss': 0.36077592312106155, 'Total loss': 0.36077592312106155}
2023-01-04 10:21:13,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:13,700 INFO:     Epoch: 38
2023-01-04 10:21:15,296 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3965410421291987, 'Total loss': 0.3965410421291987} | train loss {'Reaction outcome loss': 0.3548474020260766, 'Total loss': 0.3548474020260766}
2023-01-04 10:21:15,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:15,296 INFO:     Epoch: 39
2023-01-04 10:21:16,858 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.36943463087081907, 'Total loss': 0.36943463087081907} | train loss {'Reaction outcome loss': 0.3509282246232033, 'Total loss': 0.3509282246232033}
2023-01-04 10:21:16,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:16,858 INFO:     Epoch: 40
2023-01-04 10:21:18,387 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39465460379918416, 'Total loss': 0.39465460379918416} | train loss {'Reaction outcome loss': 0.35195487070600046, 'Total loss': 0.35195487070600046}
2023-01-04 10:21:18,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:18,387 INFO:     Epoch: 41
2023-01-04 10:21:20,021 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3765908986330032, 'Total loss': 0.3765908986330032} | train loss {'Reaction outcome loss': 0.34694767850938685, 'Total loss': 0.34694767850938685}
2023-01-04 10:21:20,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:20,022 INFO:     Epoch: 42
2023-01-04 10:21:21,657 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38177982171376545, 'Total loss': 0.38177982171376545} | train loss {'Reaction outcome loss': 0.3413714115047283, 'Total loss': 0.3413714115047283}
2023-01-04 10:21:21,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:21,657 INFO:     Epoch: 43
2023-01-04 10:21:23,282 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3815528412659963, 'Total loss': 0.3815528412659963} | train loss {'Reaction outcome loss': 0.339862891375373, 'Total loss': 0.339862891375373}
2023-01-04 10:21:23,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:23,282 INFO:     Epoch: 44
2023-01-04 10:21:24,915 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4135396808385849, 'Total loss': 0.4135396808385849} | train loss {'Reaction outcome loss': 0.3359593145334118, 'Total loss': 0.3359593145334118}
2023-01-04 10:21:24,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:24,916 INFO:     Epoch: 45
2023-01-04 10:21:26,542 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3876948873202006, 'Total loss': 0.3876948873202006} | train loss {'Reaction outcome loss': 0.33482822923776473, 'Total loss': 0.33482822923776473}
2023-01-04 10:21:26,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:26,543 INFO:     Epoch: 46
2023-01-04 10:21:28,076 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40408882598082224, 'Total loss': 0.40408882598082224} | train loss {'Reaction outcome loss': 0.33347785833295074, 'Total loss': 0.33347785833295074}
2023-01-04 10:21:28,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:28,077 INFO:     Epoch: 47
2023-01-04 10:21:29,685 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38701218863328296, 'Total loss': 0.38701218863328296} | train loss {'Reaction outcome loss': 0.3307264098621878, 'Total loss': 0.3307264098621878}
2023-01-04 10:21:29,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:29,686 INFO:     Epoch: 48
2023-01-04 10:21:31,285 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3688900907834371, 'Total loss': 0.3688900907834371} | train loss {'Reaction outcome loss': 0.32596500137222373, 'Total loss': 0.32596500137222373}
2023-01-04 10:21:31,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:31,285 INFO:     Epoch: 49
2023-01-04 10:21:32,892 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4000705639521281, 'Total loss': 0.4000705639521281} | train loss {'Reaction outcome loss': 0.32235468326923217, 'Total loss': 0.32235468326923217}
2023-01-04 10:21:32,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:32,892 INFO:     Epoch: 50
2023-01-04 10:21:34,512 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37628746529420215, 'Total loss': 0.37628746529420215} | train loss {'Reaction outcome loss': 0.3218967215248824, 'Total loss': 0.3218967215248824}
2023-01-04 10:21:34,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:34,513 INFO:     Epoch: 51
2023-01-04 10:21:36,043 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.37033885916074116, 'Total loss': 0.37033885916074116} | train loss {'Reaction outcome loss': 0.3168290122966904, 'Total loss': 0.3168290122966904}
2023-01-04 10:21:36,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:36,043 INFO:     Epoch: 52
2023-01-04 10:21:37,677 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3909308950106303, 'Total loss': 0.3909308950106303} | train loss {'Reaction outcome loss': 0.3160575987091994, 'Total loss': 0.3160575987091994}
2023-01-04 10:21:37,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:37,678 INFO:     Epoch: 53
2023-01-04 10:21:39,306 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38862436413764956, 'Total loss': 0.38862436413764956} | train loss {'Reaction outcome loss': 0.3173919122948543, 'Total loss': 0.3173919122948543}
2023-01-04 10:21:39,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:39,307 INFO:     Epoch: 54
2023-01-04 10:21:40,928 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3814008245865504, 'Total loss': 0.3814008245865504} | train loss {'Reaction outcome loss': 0.3113159748863442, 'Total loss': 0.3113159748863442}
2023-01-04 10:21:40,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:40,928 INFO:     Epoch: 55
2023-01-04 10:21:42,563 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3912576287984848, 'Total loss': 0.3912576287984848} | train loss {'Reaction outcome loss': 0.3079911432218896, 'Total loss': 0.3079911432218896}
2023-01-04 10:21:42,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:42,564 INFO:     Epoch: 56
2023-01-04 10:21:44,193 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37899378935496014, 'Total loss': 0.37899378935496014} | train loss {'Reaction outcome loss': 0.3074806605327861, 'Total loss': 0.3074806605327861}
2023-01-04 10:21:44,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:44,194 INFO:     Epoch: 57
2023-01-04 10:21:45,722 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39776959717273713, 'Total loss': 0.39776959717273713} | train loss {'Reaction outcome loss': 0.3055643471031843, 'Total loss': 0.3055643471031843}
2023-01-04 10:21:45,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:45,722 INFO:     Epoch: 58
2023-01-04 10:21:47,334 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.377119039495786, 'Total loss': 0.377119039495786} | train loss {'Reaction outcome loss': 0.3053106341632049, 'Total loss': 0.3053106341632049}
2023-01-04 10:21:47,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:47,334 INFO:     Epoch: 59
2023-01-04 10:21:48,963 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.36960792938868203, 'Total loss': 0.36960792938868203} | train loss {'Reaction outcome loss': 0.30477364908648313, 'Total loss': 0.30477364908648313}
2023-01-04 10:21:48,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:48,964 INFO:     Epoch: 60
2023-01-04 10:21:50,584 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39877360264460243, 'Total loss': 0.39877360264460243} | train loss {'Reaction outcome loss': 0.29692346946965054, 'Total loss': 0.29692346946965054}
2023-01-04 10:21:50,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:50,585 INFO:     Epoch: 61
2023-01-04 10:21:52,204 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40572281877199806, 'Total loss': 0.40572281877199806} | train loss {'Reaction outcome loss': 0.29878040368161046, 'Total loss': 0.29878040368161046}
2023-01-04 10:21:52,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:52,204 INFO:     Epoch: 62
2023-01-04 10:21:53,833 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39563263257344566, 'Total loss': 0.39563263257344566} | train loss {'Reaction outcome loss': 0.296221997763706, 'Total loss': 0.296221997763706}
2023-01-04 10:21:53,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:53,833 INFO:     Epoch: 63
2023-01-04 10:21:55,359 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3998984624942144, 'Total loss': 0.3998984624942144} | train loss {'Reaction outcome loss': 0.29670262428182126, 'Total loss': 0.29670262428182126}
2023-01-04 10:21:55,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:55,359 INFO:     Epoch: 64
2023-01-04 10:21:56,991 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3805304596821467, 'Total loss': 0.3805304596821467} | train loss {'Reaction outcome loss': 0.2921052835478249, 'Total loss': 0.2921052835478249}
2023-01-04 10:21:56,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:56,992 INFO:     Epoch: 65
2023-01-04 10:21:58,620 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4044523984193802, 'Total loss': 0.4044523984193802} | train loss {'Reaction outcome loss': 0.2933218345207428, 'Total loss': 0.2933218345207428}
2023-01-04 10:21:58,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:21:58,620 INFO:     Epoch: 66
2023-01-04 10:22:00,260 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3945788602034251, 'Total loss': 0.3945788602034251} | train loss {'Reaction outcome loss': 0.2904198245827902, 'Total loss': 0.2904198245827902}
2023-01-04 10:22:00,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:00,260 INFO:     Epoch: 67
2023-01-04 10:22:01,901 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4053810874621073, 'Total loss': 0.4053810874621073} | train loss {'Reaction outcome loss': 0.28463773878580395, 'Total loss': 0.28463773878580395}
2023-01-04 10:22:01,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:01,902 INFO:     Epoch: 68
2023-01-04 10:22:03,447 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38895854850610095, 'Total loss': 0.38895854850610095} | train loss {'Reaction outcome loss': 0.2859201499324843, 'Total loss': 0.2859201499324843}
2023-01-04 10:22:03,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:03,448 INFO:     Epoch: 69
2023-01-04 10:22:05,067 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.37846066753069557, 'Total loss': 0.37846066753069557} | train loss {'Reaction outcome loss': 0.28659981209448526, 'Total loss': 0.28659981209448526}
2023-01-04 10:22:05,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:05,067 INFO:     Epoch: 70
2023-01-04 10:22:06,702 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38879055082798003, 'Total loss': 0.38879055082798003} | train loss {'Reaction outcome loss': 0.2878301232676644, 'Total loss': 0.2878301232676644}
2023-01-04 10:22:06,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:06,702 INFO:     Epoch: 71
2023-01-04 10:22:08,330 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37575001219908394, 'Total loss': 0.37575001219908394} | train loss {'Reaction outcome loss': 0.2844351922777155, 'Total loss': 0.2844351922777155}
2023-01-04 10:22:08,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:08,331 INFO:     Epoch: 72
2023-01-04 10:22:09,957 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37979114751021065, 'Total loss': 0.37979114751021065} | train loss {'Reaction outcome loss': 0.2818913846562485, 'Total loss': 0.2818913846562485}
2023-01-04 10:22:09,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:09,957 INFO:     Epoch: 73
2023-01-04 10:22:11,547 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3707629029949506, 'Total loss': 0.3707629029949506} | train loss {'Reaction outcome loss': 0.28138940880875296, 'Total loss': 0.28138940880875296}
2023-01-04 10:22:11,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:11,547 INFO:     Epoch: 74
2023-01-04 10:22:13,043 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.389618656784296, 'Total loss': 0.389618656784296} | train loss {'Reaction outcome loss': 0.28324472892101493, 'Total loss': 0.28324472892101493}
2023-01-04 10:22:13,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:13,044 INFO:     Epoch: 75
2023-01-04 10:22:14,634 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37482099831104276, 'Total loss': 0.37482099831104276} | train loss {'Reaction outcome loss': 0.273542760377111, 'Total loss': 0.273542760377111}
2023-01-04 10:22:14,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:14,634 INFO:     Epoch: 76
2023-01-04 10:22:16,230 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3870561043421427, 'Total loss': 0.3870561043421427} | train loss {'Reaction outcome loss': 0.2778420142210778, 'Total loss': 0.2778420142210778}
2023-01-04 10:22:16,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:16,230 INFO:     Epoch: 77
2023-01-04 10:22:17,801 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3917693148056666, 'Total loss': 0.3917693148056666} | train loss {'Reaction outcome loss': 0.2765507276038831, 'Total loss': 0.2765507276038831}
2023-01-04 10:22:17,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:17,802 INFO:     Epoch: 78
2023-01-04 10:22:19,367 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.34642661809921266, 'Total loss': 0.34642661809921266} | train loss {'Reaction outcome loss': 0.27757860632741066, 'Total loss': 0.27757860632741066}
2023-01-04 10:22:19,367 INFO:     Found new best model at epoch 78
2023-01-04 10:22:19,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:19,368 INFO:     Epoch: 79
2023-01-04 10:22:20,944 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40166709770758946, 'Total loss': 0.40166709770758946} | train loss {'Reaction outcome loss': 0.27113406193385486, 'Total loss': 0.27113406193385486}
2023-01-04 10:22:20,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:20,944 INFO:     Epoch: 80
2023-01-04 10:22:22,432 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38199840585390726, 'Total loss': 0.38199840585390726} | train loss {'Reaction outcome loss': 0.27203637592844154, 'Total loss': 0.27203637592844154}
2023-01-04 10:22:22,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:22,432 INFO:     Epoch: 81
2023-01-04 10:22:24,050 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3837102691332499, 'Total loss': 0.3837102691332499} | train loss {'Reaction outcome loss': 0.2730479430044171, 'Total loss': 0.2730479430044171}
2023-01-04 10:22:24,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:24,050 INFO:     Epoch: 82
2023-01-04 10:22:25,667 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.375507752597332, 'Total loss': 0.375507752597332} | train loss {'Reaction outcome loss': 0.27247977627959064, 'Total loss': 0.27247977627959064}
2023-01-04 10:22:25,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:25,667 INFO:     Epoch: 83
2023-01-04 10:22:27,269 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.34699082126220065, 'Total loss': 0.34699082126220065} | train loss {'Reaction outcome loss': 0.2727567858267777, 'Total loss': 0.2727567858267777}
2023-01-04 10:22:27,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:27,269 INFO:     Epoch: 84
2023-01-04 10:22:28,858 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3737366944551468, 'Total loss': 0.3737366944551468} | train loss {'Reaction outcome loss': 0.2659052519484117, 'Total loss': 0.2659052519484117}
2023-01-04 10:22:28,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:28,858 INFO:     Epoch: 85
2023-01-04 10:22:30,442 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37024227579434715, 'Total loss': 0.37024227579434715} | train loss {'Reaction outcome loss': 0.26808094553353556, 'Total loss': 0.26808094553353556}
2023-01-04 10:22:30,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:30,442 INFO:     Epoch: 86
2023-01-04 10:22:31,540 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3879037539164225, 'Total loss': 0.3879037539164225} | train loss {'Reaction outcome loss': 0.26723058841826686, 'Total loss': 0.26723058841826686}
2023-01-04 10:22:31,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:31,541 INFO:     Epoch: 87
2023-01-04 10:22:32,572 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.34434676766395567, 'Total loss': 0.34434676766395567} | train loss {'Reaction outcome loss': 0.2666562282302104, 'Total loss': 0.2666562282302104}
2023-01-04 10:22:32,572 INFO:     Found new best model at epoch 87
2023-01-04 10:22:32,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:32,573 INFO:     Epoch: 88
2023-01-04 10:22:33,593 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.36958374579747516, 'Total loss': 0.36958374579747516} | train loss {'Reaction outcome loss': 0.26566726895930104, 'Total loss': 0.26566726895930104}
2023-01-04 10:22:33,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:33,593 INFO:     Epoch: 89
2023-01-04 10:22:34,613 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41542626122633614, 'Total loss': 0.41542626122633614} | train loss {'Reaction outcome loss': 0.2616396550667415, 'Total loss': 0.2616396550667415}
2023-01-04 10:22:34,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:34,614 INFO:     Epoch: 90
2023-01-04 10:22:35,718 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3742695907751719, 'Total loss': 0.3742695907751719} | train loss {'Reaction outcome loss': 0.2635647159352199, 'Total loss': 0.2635647159352199}
2023-01-04 10:22:35,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:35,718 INFO:     Epoch: 91
2023-01-04 10:22:37,285 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38640502393245696, 'Total loss': 0.38640502393245696} | train loss {'Reaction outcome loss': 0.2664447135362599, 'Total loss': 0.2664447135362599}
2023-01-04 10:22:37,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:37,285 INFO:     Epoch: 92
2023-01-04 10:22:38,891 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37242432236671447, 'Total loss': 0.37242432236671447} | train loss {'Reaction outcome loss': 0.2610207462031058, 'Total loss': 0.2610207462031058}
2023-01-04 10:22:38,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:38,892 INFO:     Epoch: 93
2023-01-04 10:22:40,494 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38723469798763593, 'Total loss': 0.38723469798763593} | train loss {'Reaction outcome loss': 0.2619760993612587, 'Total loss': 0.2619760993612587}
2023-01-04 10:22:40,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:40,494 INFO:     Epoch: 94
2023-01-04 10:22:42,099 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.36835028032461803, 'Total loss': 0.36835028032461803} | train loss {'Reaction outcome loss': 0.2583363716245128, 'Total loss': 0.2583363716245128}
2023-01-04 10:22:42,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:42,099 INFO:     Epoch: 95
2023-01-04 10:22:43,717 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3962280809879303, 'Total loss': 0.3962280809879303} | train loss {'Reaction outcome loss': 0.2568193192892987, 'Total loss': 0.2568193192892987}
2023-01-04 10:22:43,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:43,719 INFO:     Epoch: 96
2023-01-04 10:22:45,286 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38400734663009645, 'Total loss': 0.38400734663009645} | train loss {'Reaction outcome loss': 0.25916322522430213, 'Total loss': 0.25916322522430213}
2023-01-04 10:22:45,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:45,286 INFO:     Epoch: 97
2023-01-04 10:22:46,851 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3886014272769292, 'Total loss': 0.3886014272769292} | train loss {'Reaction outcome loss': 0.2563755495157698, 'Total loss': 0.2563755495157698}
2023-01-04 10:22:46,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:46,852 INFO:     Epoch: 98
2023-01-04 10:22:48,449 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3749482333660126, 'Total loss': 0.3749482333660126} | train loss {'Reaction outcome loss': 0.2559348415274052, 'Total loss': 0.2559348415274052}
2023-01-04 10:22:48,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:48,450 INFO:     Epoch: 99
2023-01-04 10:22:50,044 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37011969486872354, 'Total loss': 0.37011969486872354} | train loss {'Reaction outcome loss': 0.2612096687597273, 'Total loss': 0.2612096687597273}
2023-01-04 10:22:50,045 INFO:     Best model found after epoch 88 of 100.
2023-01-04 10:22:50,045 INFO:   Done with stage: TRAINING
2023-01-04 10:22:50,045 INFO:   Starting stage: EVALUATION
2023-01-04 10:22:50,168 INFO:   Done with stage: EVALUATION
2023-01-04 10:22:50,177 INFO:   Leaving out SEQ value Fold_0
2023-01-04 10:22:50,189 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 10:22:50,190 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:22:50,840 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:22:50,840 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:22:50,907 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:22:50,908 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:22:50,908 INFO:     No hyperparam tuning for this model
2023-01-04 10:22:50,908 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:22:50,908 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:22:50,909 INFO:     None feature selector for col prot
2023-01-04 10:22:50,909 INFO:     None feature selector for col prot
2023-01-04 10:22:50,909 INFO:     None feature selector for col prot
2023-01-04 10:22:50,909 INFO:     None feature selector for col chem
2023-01-04 10:22:50,909 INFO:     None feature selector for col chem
2023-01-04 10:22:50,909 INFO:     None feature selector for col chem
2023-01-04 10:22:50,909 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:22:50,910 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:22:50,911 INFO:     Number of params in model 70111
2023-01-04 10:22:50,914 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:22:50,914 INFO:   Starting stage: TRAINING
2023-01-04 10:22:50,957 INFO:     Val loss before train {'Reaction outcome loss': 1.0280609647432963, 'Total loss': 1.0280609647432963}
2023-01-04 10:22:50,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:50,957 INFO:     Epoch: 0
2023-01-04 10:22:52,524 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7439713319142659, 'Total loss': 0.7439713319142659} | train loss {'Reaction outcome loss': 0.845361779641061, 'Total loss': 0.845361779641061}
2023-01-04 10:22:52,524 INFO:     Found new best model at epoch 0
2023-01-04 10:22:52,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:52,525 INFO:     Epoch: 1
2023-01-04 10:22:54,060 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6535911083221435, 'Total loss': 0.6535911083221435} | train loss {'Reaction outcome loss': 0.687198288358041, 'Total loss': 0.687198288358041}
2023-01-04 10:22:54,060 INFO:     Found new best model at epoch 1
2023-01-04 10:22:54,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:54,061 INFO:     Epoch: 2
2023-01-04 10:22:55,608 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5728899776935578, 'Total loss': 0.5728899776935578} | train loss {'Reaction outcome loss': 0.6037455189728389, 'Total loss': 0.6037455189728389}
2023-01-04 10:22:55,608 INFO:     Found new best model at epoch 2
2023-01-04 10:22:55,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:55,609 INFO:     Epoch: 3
2023-01-04 10:22:57,182 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5672297875086466, 'Total loss': 0.5672297875086466} | train loss {'Reaction outcome loss': 0.5557312199669163, 'Total loss': 0.5557312199669163}
2023-01-04 10:22:57,182 INFO:     Found new best model at epoch 3
2023-01-04 10:22:57,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:57,183 INFO:     Epoch: 4
2023-01-04 10:22:58,745 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.552839171886444, 'Total loss': 0.552839171886444} | train loss {'Reaction outcome loss': 0.5295853983529293, 'Total loss': 0.5295853983529293}
2023-01-04 10:22:58,745 INFO:     Found new best model at epoch 4
2023-01-04 10:22:58,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:22:58,746 INFO:     Epoch: 5
2023-01-04 10:23:00,320 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.505879666407903, 'Total loss': 0.505879666407903} | train loss {'Reaction outcome loss': 0.5114008878378102, 'Total loss': 0.5114008878378102}
2023-01-04 10:23:00,320 INFO:     Found new best model at epoch 5
2023-01-04 10:23:00,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:00,320 INFO:     Epoch: 6
2023-01-04 10:23:01,903 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5329413851102193, 'Total loss': 0.5329413851102193} | train loss {'Reaction outcome loss': 0.4961414399699573, 'Total loss': 0.4961414399699573}
2023-01-04 10:23:01,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:01,903 INFO:     Epoch: 7
2023-01-04 10:23:03,443 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5265634089708329, 'Total loss': 0.5265634089708329} | train loss {'Reaction outcome loss': 0.4832556975910263, 'Total loss': 0.4832556975910263}
2023-01-04 10:23:03,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:03,444 INFO:     Epoch: 8
2023-01-04 10:23:04,985 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5110181053479512, 'Total loss': 0.5110181053479512} | train loss {'Reaction outcome loss': 0.47389935348590795, 'Total loss': 0.47389935348590795}
2023-01-04 10:23:04,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:04,985 INFO:     Epoch: 9
2023-01-04 10:23:06,562 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5062087337176006, 'Total loss': 0.5062087337176006} | train loss {'Reaction outcome loss': 0.4709416665408733, 'Total loss': 0.4709416665408733}
2023-01-04 10:23:06,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:06,562 INFO:     Epoch: 10
2023-01-04 10:23:08,181 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4850508332252502, 'Total loss': 0.4850508332252502} | train loss {'Reaction outcome loss': 0.4625196017216157, 'Total loss': 0.4625196017216157}
2023-01-04 10:23:08,181 INFO:     Found new best model at epoch 10
2023-01-04 10:23:08,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:08,182 INFO:     Epoch: 11
2023-01-04 10:23:09,781 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47943177123864494, 'Total loss': 0.47943177123864494} | train loss {'Reaction outcome loss': 0.4549435594112334, 'Total loss': 0.4549435594112334}
2023-01-04 10:23:09,781 INFO:     Found new best model at epoch 11
2023-01-04 10:23:09,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:09,782 INFO:     Epoch: 12
2023-01-04 10:23:11,367 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4780988395214081, 'Total loss': 0.4780988395214081} | train loss {'Reaction outcome loss': 0.45218364970527425, 'Total loss': 0.45218364970527425}
2023-01-04 10:23:11,367 INFO:     Found new best model at epoch 12
2023-01-04 10:23:11,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:11,368 INFO:     Epoch: 13
2023-01-04 10:23:12,881 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4847370405991872, 'Total loss': 0.4847370405991872} | train loss {'Reaction outcome loss': 0.44447382088125187, 'Total loss': 0.44447382088125187}
2023-01-04 10:23:12,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:12,882 INFO:     Epoch: 14
2023-01-04 10:23:14,448 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4907227019468943, 'Total loss': 0.4907227019468943} | train loss {'Reaction outcome loss': 0.44115718600958803, 'Total loss': 0.44115718600958803}
2023-01-04 10:23:14,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:14,449 INFO:     Epoch: 15
2023-01-04 10:23:16,027 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47174474199612937, 'Total loss': 0.47174474199612937} | train loss {'Reaction outcome loss': 0.4330916116489981, 'Total loss': 0.4330916116489981}
2023-01-04 10:23:16,027 INFO:     Found new best model at epoch 15
2023-01-04 10:23:16,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:16,028 INFO:     Epoch: 16
2023-01-04 10:23:17,618 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4668586830298106, 'Total loss': 0.4668586830298106} | train loss {'Reaction outcome loss': 0.4364073554692912, 'Total loss': 0.4364073554692912}
2023-01-04 10:23:17,618 INFO:     Found new best model at epoch 16
2023-01-04 10:23:17,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:17,619 INFO:     Epoch: 17
2023-01-04 10:23:19,204 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46952863534291583, 'Total loss': 0.46952863534291583} | train loss {'Reaction outcome loss': 0.4277625908925585, 'Total loss': 0.4277625908925585}
2023-01-04 10:23:19,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:19,204 INFO:     Epoch: 18
2023-01-04 10:23:20,755 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4836954027414322, 'Total loss': 0.4836954027414322} | train loss {'Reaction outcome loss': 0.42130354449261714, 'Total loss': 0.42130354449261714}
2023-01-04 10:23:20,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:20,755 INFO:     Epoch: 19
2023-01-04 10:23:22,299 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46768701473871865, 'Total loss': 0.46768701473871865} | train loss {'Reaction outcome loss': 0.417991295266543, 'Total loss': 0.417991295266543}
2023-01-04 10:23:22,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:22,299 INFO:     Epoch: 20
2023-01-04 10:23:23,876 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43915262818336487, 'Total loss': 0.43915262818336487} | train loss {'Reaction outcome loss': 0.4148207550501301, 'Total loss': 0.4148207550501301}
2023-01-04 10:23:23,876 INFO:     Found new best model at epoch 20
2023-01-04 10:23:23,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:23,876 INFO:     Epoch: 21
2023-01-04 10:23:25,429 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4538340409596761, 'Total loss': 0.4538340409596761} | train loss {'Reaction outcome loss': 0.41188804419153796, 'Total loss': 0.41188804419153796}
2023-01-04 10:23:25,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:25,429 INFO:     Epoch: 22
2023-01-04 10:23:26,989 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4474096953868866, 'Total loss': 0.4474096953868866} | train loss {'Reaction outcome loss': 0.4097023173677225, 'Total loss': 0.4097023173677225}
2023-01-04 10:23:26,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:26,989 INFO:     Epoch: 23
2023-01-04 10:23:28,545 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4560228755076726, 'Total loss': 0.4560228755076726} | train loss {'Reaction outcome loss': 0.4032124067745069, 'Total loss': 0.4032124067745069}
2023-01-04 10:23:28,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:28,545 INFO:     Epoch: 24
2023-01-04 10:23:30,059 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4416750649611155, 'Total loss': 0.4416750649611155} | train loss {'Reaction outcome loss': 0.40222032966404936, 'Total loss': 0.40222032966404936}
2023-01-04 10:23:30,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:30,059 INFO:     Epoch: 25
2023-01-04 10:23:31,573 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4530534605185191, 'Total loss': 0.4530534605185191} | train loss {'Reaction outcome loss': 0.3994446933595803, 'Total loss': 0.3994446933595803}
2023-01-04 10:23:31,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:31,573 INFO:     Epoch: 26
2023-01-04 10:23:33,144 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.450286332766215, 'Total loss': 0.450286332766215} | train loss {'Reaction outcome loss': 0.39613620572499114, 'Total loss': 0.39613620572499114}
2023-01-04 10:23:33,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:33,145 INFO:     Epoch: 27
2023-01-04 10:23:34,708 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44182791908582053, 'Total loss': 0.44182791908582053} | train loss {'Reaction outcome loss': 0.3893927749871773, 'Total loss': 0.3893927749871773}
2023-01-04 10:23:34,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:34,708 INFO:     Epoch: 28
2023-01-04 10:23:36,277 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43829420308272043, 'Total loss': 0.43829420308272043} | train loss {'Reaction outcome loss': 0.38843579481552987, 'Total loss': 0.38843579481552987}
2023-01-04 10:23:36,277 INFO:     Found new best model at epoch 28
2023-01-04 10:23:36,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:36,278 INFO:     Epoch: 29
2023-01-04 10:23:37,828 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4269153942664464, 'Total loss': 0.4269153942664464} | train loss {'Reaction outcome loss': 0.3871975756474655, 'Total loss': 0.3871975756474655}
2023-01-04 10:23:37,828 INFO:     Found new best model at epoch 29
2023-01-04 10:23:37,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:37,829 INFO:     Epoch: 30
2023-01-04 10:23:39,348 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42545835971832274, 'Total loss': 0.42545835971832274} | train loss {'Reaction outcome loss': 0.37846994296695197, 'Total loss': 0.37846994296695197}
2023-01-04 10:23:39,348 INFO:     Found new best model at epoch 30
2023-01-04 10:23:39,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:39,349 INFO:     Epoch: 31
2023-01-04 10:23:40,865 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4584019641081492, 'Total loss': 0.4584019641081492} | train loss {'Reaction outcome loss': 0.38073722188816456, 'Total loss': 0.38073722188816456}
2023-01-04 10:23:40,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:40,865 INFO:     Epoch: 32
2023-01-04 10:23:42,429 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4105391621589661, 'Total loss': 0.4105391621589661} | train loss {'Reaction outcome loss': 0.3774717532533364, 'Total loss': 0.3774717532533364}
2023-01-04 10:23:42,429 INFO:     Found new best model at epoch 32
2023-01-04 10:23:42,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:42,430 INFO:     Epoch: 33
2023-01-04 10:23:43,973 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4139106144507726, 'Total loss': 0.4139106144507726} | train loss {'Reaction outcome loss': 0.3748325728913293, 'Total loss': 0.3748325728913293}
2023-01-04 10:23:43,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:43,973 INFO:     Epoch: 34
2023-01-04 10:23:45,527 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.430789989233017, 'Total loss': 0.430789989233017} | train loss {'Reaction outcome loss': 0.3718249944113467, 'Total loss': 0.3718249944113467}
2023-01-04 10:23:45,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:45,528 INFO:     Epoch: 35
2023-01-04 10:23:47,101 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43413638571898144, 'Total loss': 0.43413638571898144} | train loss {'Reaction outcome loss': 0.3664415132009635, 'Total loss': 0.3664415132009635}
2023-01-04 10:23:47,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:47,102 INFO:     Epoch: 36
2023-01-04 10:23:48,640 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42593358357747396, 'Total loss': 0.42593358357747396} | train loss {'Reaction outcome loss': 0.3629157987498019, 'Total loss': 0.3629157987498019}
2023-01-04 10:23:48,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:48,641 INFO:     Epoch: 37
2023-01-04 10:23:50,189 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.443861648440361, 'Total loss': 0.443861648440361} | train loss {'Reaction outcome loss': 0.3620561429836454, 'Total loss': 0.3620561429836454}
2023-01-04 10:23:50,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:50,189 INFO:     Epoch: 38
2023-01-04 10:23:51,750 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4395397245883942, 'Total loss': 0.4395397245883942} | train loss {'Reaction outcome loss': 0.35876332851548265, 'Total loss': 0.35876332851548265}
2023-01-04 10:23:51,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:51,751 INFO:     Epoch: 39
2023-01-04 10:23:53,313 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42615747849146524, 'Total loss': 0.42615747849146524} | train loss {'Reaction outcome loss': 0.35778443754589473, 'Total loss': 0.35778443754589473}
2023-01-04 10:23:53,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:53,313 INFO:     Epoch: 40
2023-01-04 10:23:54,868 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44510899583498637, 'Total loss': 0.44510899583498637} | train loss {'Reaction outcome loss': 0.3554789696405404, 'Total loss': 0.3554789696405404}
2023-01-04 10:23:54,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:54,868 INFO:     Epoch: 41
2023-01-04 10:23:56,420 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4381342848141988, 'Total loss': 0.4381342848141988} | train loss {'Reaction outcome loss': 0.3497759670998058, 'Total loss': 0.3497759670998058}
2023-01-04 10:23:56,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:56,420 INFO:     Epoch: 42
2023-01-04 10:23:57,921 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4000723709662755, 'Total loss': 0.4000723709662755} | train loss {'Reaction outcome loss': 0.3496585246855325, 'Total loss': 0.3496585246855325}
2023-01-04 10:23:57,921 INFO:     Found new best model at epoch 42
2023-01-04 10:23:57,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:57,922 INFO:     Epoch: 43
2023-01-04 10:23:59,444 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39018204311529797, 'Total loss': 0.39018204311529797} | train loss {'Reaction outcome loss': 0.3459818812127966, 'Total loss': 0.3459818812127966}
2023-01-04 10:23:59,444 INFO:     Found new best model at epoch 43
2023-01-04 10:23:59,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:23:59,445 INFO:     Epoch: 44
2023-01-04 10:24:00,997 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4200204392274221, 'Total loss': 0.4200204392274221} | train loss {'Reaction outcome loss': 0.34621586125806303, 'Total loss': 0.34621586125806303}
2023-01-04 10:24:00,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:00,997 INFO:     Epoch: 45
2023-01-04 10:24:02,526 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4299155573050181, 'Total loss': 0.4299155573050181} | train loss {'Reaction outcome loss': 0.33939647130722544, 'Total loss': 0.33939647130722544}
2023-01-04 10:24:02,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:02,526 INFO:     Epoch: 46
2023-01-04 10:24:04,063 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39694437781969705, 'Total loss': 0.39694437781969705} | train loss {'Reaction outcome loss': 0.33616504432076083, 'Total loss': 0.33616504432076083}
2023-01-04 10:24:04,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:04,064 INFO:     Epoch: 47
2023-01-04 10:24:05,610 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39371692538261416, 'Total loss': 0.39371692538261416} | train loss {'Reaction outcome loss': 0.3389323586801978, 'Total loss': 0.3389323586801978}
2023-01-04 10:24:05,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:05,611 INFO:     Epoch: 48
2023-01-04 10:24:07,121 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4249865690867106, 'Total loss': 0.4249865690867106} | train loss {'Reaction outcome loss': 0.33238550463188304, 'Total loss': 0.33238550463188304}
2023-01-04 10:24:07,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:07,121 INFO:     Epoch: 49
2023-01-04 10:24:08,658 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41628320813179015, 'Total loss': 0.41628320813179015} | train loss {'Reaction outcome loss': 0.33481869406073633, 'Total loss': 0.33481869406073633}
2023-01-04 10:24:08,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:08,658 INFO:     Epoch: 50
2023-01-04 10:24:10,211 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4069945161541303, 'Total loss': 0.4069945161541303} | train loss {'Reaction outcome loss': 0.33178525893901384, 'Total loss': 0.33178525893901384}
2023-01-04 10:24:10,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:10,211 INFO:     Epoch: 51
2023-01-04 10:24:11,820 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40866750478744507, 'Total loss': 0.40866750478744507} | train loss {'Reaction outcome loss': 0.3278918601844433, 'Total loss': 0.3278918601844433}
2023-01-04 10:24:11,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:11,821 INFO:     Epoch: 52
2023-01-04 10:24:13,419 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40226767361164095, 'Total loss': 0.40226767361164095} | train loss {'Reaction outcome loss': 0.3276035590981045, 'Total loss': 0.3276035590981045}
2023-01-04 10:24:13,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:13,419 INFO:     Epoch: 53
2023-01-04 10:24:15,030 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4303055425484975, 'Total loss': 0.4303055425484975} | train loss {'Reaction outcome loss': 0.3223058999291737, 'Total loss': 0.3223058999291737}
2023-01-04 10:24:15,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:15,030 INFO:     Epoch: 54
2023-01-04 10:24:16,567 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40744027694066365, 'Total loss': 0.40744027694066365} | train loss {'Reaction outcome loss': 0.3215430360967225, 'Total loss': 0.3215430360967225}
2023-01-04 10:24:16,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:16,568 INFO:     Epoch: 55
2023-01-04 10:24:18,175 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4063485791285833, 'Total loss': 0.4063485791285833} | train loss {'Reaction outcome loss': 0.3210095307198319, 'Total loss': 0.3210095307198319}
2023-01-04 10:24:18,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:18,175 INFO:     Epoch: 56
2023-01-04 10:24:19,783 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4080145368973414, 'Total loss': 0.4080145368973414} | train loss {'Reaction outcome loss': 0.3179647232929285, 'Total loss': 0.3179647232929285}
2023-01-04 10:24:19,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:19,783 INFO:     Epoch: 57
2023-01-04 10:24:21,381 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4042889396349589, 'Total loss': 0.4042889396349589} | train loss {'Reaction outcome loss': 0.31326855606243126, 'Total loss': 0.31326855606243126}
2023-01-04 10:24:21,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:21,382 INFO:     Epoch: 58
2023-01-04 10:24:22,927 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42979939381281534, 'Total loss': 0.42979939381281534} | train loss {'Reaction outcome loss': 0.3130125421894728, 'Total loss': 0.3130125421894728}
2023-01-04 10:24:22,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:22,928 INFO:     Epoch: 59
2023-01-04 10:24:24,439 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4018751492102941, 'Total loss': 0.4018751492102941} | train loss {'Reaction outcome loss': 0.31147404520833577, 'Total loss': 0.31147404520833577}
2023-01-04 10:24:24,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:24,439 INFO:     Epoch: 60
2023-01-04 10:24:25,939 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41106947759787243, 'Total loss': 0.41106947759787243} | train loss {'Reaction outcome loss': 0.3096439125437806, 'Total loss': 0.3096439125437806}
2023-01-04 10:24:25,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:25,939 INFO:     Epoch: 61
2023-01-04 10:24:27,489 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.394743816057841, 'Total loss': 0.394743816057841} | train loss {'Reaction outcome loss': 0.31352328974073823, 'Total loss': 0.31352328974073823}
2023-01-04 10:24:27,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:27,489 INFO:     Epoch: 62
2023-01-04 10:24:29,046 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39617640574773155, 'Total loss': 0.39617640574773155} | train loss {'Reaction outcome loss': 0.3069296610833955, 'Total loss': 0.3069296610833955}
2023-01-04 10:24:29,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:29,046 INFO:     Epoch: 63
2023-01-04 10:24:30,592 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41906175563732784, 'Total loss': 0.41906175563732784} | train loss {'Reaction outcome loss': 0.30264193515707977, 'Total loss': 0.30264193515707977}
2023-01-04 10:24:30,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:30,592 INFO:     Epoch: 64
2023-01-04 10:24:32,149 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42186214923858645, 'Total loss': 0.42186214923858645} | train loss {'Reaction outcome loss': 0.30688661712147025, 'Total loss': 0.30688661712147025}
2023-01-04 10:24:32,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:32,150 INFO:     Epoch: 65
2023-01-04 10:24:33,679 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42245237628618876, 'Total loss': 0.42245237628618876} | train loss {'Reaction outcome loss': 0.3038761022697835, 'Total loss': 0.3038761022697835}
2023-01-04 10:24:33,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:33,679 INFO:     Epoch: 66
2023-01-04 10:24:35,211 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4234384626150131, 'Total loss': 0.4234384626150131} | train loss {'Reaction outcome loss': 0.30223234044048036, 'Total loss': 0.30223234044048036}
2023-01-04 10:24:35,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:35,212 INFO:     Epoch: 67
2023-01-04 10:24:36,772 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39818796614805857, 'Total loss': 0.39818796614805857} | train loss {'Reaction outcome loss': 0.3025455860570617, 'Total loss': 0.3025455860570617}
2023-01-04 10:24:36,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:36,772 INFO:     Epoch: 68
2023-01-04 10:24:38,314 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39019966721534727, 'Total loss': 0.39019966721534727} | train loss {'Reaction outcome loss': 0.2998280453148985, 'Total loss': 0.2998280453148985}
2023-01-04 10:24:38,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:38,314 INFO:     Epoch: 69
2023-01-04 10:24:39,897 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39642806599537533, 'Total loss': 0.39642806599537533} | train loss {'Reaction outcome loss': 0.30167058202689584, 'Total loss': 0.30167058202689584}
2023-01-04 10:24:39,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:39,897 INFO:     Epoch: 70
2023-01-04 10:24:41,449 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41642005443573, 'Total loss': 0.41642005443573} | train loss {'Reaction outcome loss': 0.3001490083461913, 'Total loss': 0.3001490083461913}
2023-01-04 10:24:41,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:41,449 INFO:     Epoch: 71
2023-01-04 10:24:42,966 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39967673023541767, 'Total loss': 0.39967673023541767} | train loss {'Reaction outcome loss': 0.29539504739707406, 'Total loss': 0.29539504739707406}
2023-01-04 10:24:42,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:42,966 INFO:     Epoch: 72
2023-01-04 10:24:44,478 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3858187973499298, 'Total loss': 0.3858187973499298} | train loss {'Reaction outcome loss': 0.2966708977346438, 'Total loss': 0.2966708977346438}
2023-01-04 10:24:44,478 INFO:     Found new best model at epoch 72
2023-01-04 10:24:44,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:44,479 INFO:     Epoch: 73
2023-01-04 10:24:46,031 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4001130074262619, 'Total loss': 0.4001130074262619} | train loss {'Reaction outcome loss': 0.2946682428247737, 'Total loss': 0.2946682428247737}
2023-01-04 10:24:46,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:46,031 INFO:     Epoch: 74
2023-01-04 10:24:47,592 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4279481013615926, 'Total loss': 0.4279481013615926} | train loss {'Reaction outcome loss': 0.2942611174046123, 'Total loss': 0.2942611174046123}
2023-01-04 10:24:47,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:47,592 INFO:     Epoch: 75
2023-01-04 10:24:49,143 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39889198293288547, 'Total loss': 0.39889198293288547} | train loss {'Reaction outcome loss': 0.2930780068094278, 'Total loss': 0.2930780068094278}
2023-01-04 10:24:49,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:49,144 INFO:     Epoch: 76
2023-01-04 10:24:50,697 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4048876186211904, 'Total loss': 0.4048876186211904} | train loss {'Reaction outcome loss': 0.29225586985584595, 'Total loss': 0.29225586985584595}
2023-01-04 10:24:50,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:50,697 INFO:     Epoch: 77
2023-01-04 10:24:52,226 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41645058890183767, 'Total loss': 0.41645058890183767} | train loss {'Reaction outcome loss': 0.28711917553178584, 'Total loss': 0.28711917553178584}
2023-01-04 10:24:52,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:52,227 INFO:     Epoch: 78
2023-01-04 10:24:53,735 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3820367207129796, 'Total loss': 0.3820367207129796} | train loss {'Reaction outcome loss': 0.2857090170719545, 'Total loss': 0.2857090170719545}
2023-01-04 10:24:53,735 INFO:     Found new best model at epoch 78
2023-01-04 10:24:53,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:53,736 INFO:     Epoch: 79
2023-01-04 10:24:55,294 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3974481145540873, 'Total loss': 0.3974481145540873} | train loss {'Reaction outcome loss': 0.2857508935088659, 'Total loss': 0.2857508935088659}
2023-01-04 10:24:55,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:55,295 INFO:     Epoch: 80
2023-01-04 10:24:56,867 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4088108112414678, 'Total loss': 0.4088108112414678} | train loss {'Reaction outcome loss': 0.2846812596476644, 'Total loss': 0.2846812596476644}
2023-01-04 10:24:56,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:56,867 INFO:     Epoch: 81
2023-01-04 10:24:58,434 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4161346763372421, 'Total loss': 0.4161346763372421} | train loss {'Reaction outcome loss': 0.2815576241943088, 'Total loss': 0.2815576241943088}
2023-01-04 10:24:58,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:24:58,435 INFO:     Epoch: 82
2023-01-04 10:25:00,010 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4390925258398056, 'Total loss': 0.4390925258398056} | train loss {'Reaction outcome loss': 0.2846759522646448, 'Total loss': 0.2846759522646448}
2023-01-04 10:25:00,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:00,011 INFO:     Epoch: 83
2023-01-04 10:25:01,518 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3863443672657013, 'Total loss': 0.3863443672657013} | train loss {'Reaction outcome loss': 0.2824424276413926, 'Total loss': 0.2824424276413926}
2023-01-04 10:25:01,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:01,518 INFO:     Epoch: 84
2023-01-04 10:25:03,042 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3957162941495577, 'Total loss': 0.3957162941495577} | train loss {'Reaction outcome loss': 0.28519119115641517, 'Total loss': 0.28519119115641517}
2023-01-04 10:25:03,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:03,042 INFO:     Epoch: 85
2023-01-04 10:25:04,602 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40644849638144176, 'Total loss': 0.40644849638144176} | train loss {'Reaction outcome loss': 0.2834590403431088, 'Total loss': 0.2834590403431088}
2023-01-04 10:25:04,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:04,602 INFO:     Epoch: 86
2023-01-04 10:25:06,156 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40989580551783245, 'Total loss': 0.40989580551783245} | train loss {'Reaction outcome loss': 0.2781453670757095, 'Total loss': 0.2781453670757095}
2023-01-04 10:25:06,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:06,157 INFO:     Epoch: 87
2023-01-04 10:25:07,715 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3957491159439087, 'Total loss': 0.3957491159439087} | train loss {'Reaction outcome loss': 0.2780880087537922, 'Total loss': 0.2780880087537922}
2023-01-04 10:25:07,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:07,715 INFO:     Epoch: 88
2023-01-04 10:25:09,277 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40712795158227283, 'Total loss': 0.40712795158227283} | train loss {'Reaction outcome loss': 0.27447367878290857, 'Total loss': 0.27447367878290857}
2023-01-04 10:25:09,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:09,277 INFO:     Epoch: 89
2023-01-04 10:25:10,801 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4195718735456467, 'Total loss': 0.4195718735456467} | train loss {'Reaction outcome loss': 0.27709487531959576, 'Total loss': 0.27709487531959576}
2023-01-04 10:25:10,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:10,802 INFO:     Epoch: 90
2023-01-04 10:25:12,353 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40380443235238395, 'Total loss': 0.40380443235238395} | train loss {'Reaction outcome loss': 0.27796083161213103, 'Total loss': 0.27796083161213103}
2023-01-04 10:25:12,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:12,353 INFO:     Epoch: 91
2023-01-04 10:25:13,890 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41423620929320654, 'Total loss': 0.41423620929320654} | train loss {'Reaction outcome loss': 0.27228176376245317, 'Total loss': 0.27228176376245317}
2023-01-04 10:25:13,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:13,890 INFO:     Epoch: 92
2023-01-04 10:25:15,452 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.38387933721144996, 'Total loss': 0.38387933721144996} | train loss {'Reaction outcome loss': 0.27563981518801983, 'Total loss': 0.27563981518801983}
2023-01-04 10:25:15,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:15,452 INFO:     Epoch: 93
2023-01-04 10:25:16,999 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4016331930955251, 'Total loss': 0.4016331930955251} | train loss {'Reaction outcome loss': 0.27216299708905445, 'Total loss': 0.27216299708905445}
2023-01-04 10:25:16,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:16,999 INFO:     Epoch: 94
2023-01-04 10:25:18,525 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41832516590754193, 'Total loss': 0.41832516590754193} | train loss {'Reaction outcome loss': 0.27263789349337564, 'Total loss': 0.27263789349337564}
2023-01-04 10:25:18,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:18,526 INFO:     Epoch: 95
2023-01-04 10:25:20,021 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3880734999974569, 'Total loss': 0.3880734999974569} | train loss {'Reaction outcome loss': 0.2675585810938021, 'Total loss': 0.2675585810938021}
2023-01-04 10:25:20,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:20,021 INFO:     Epoch: 96
2023-01-04 10:25:21,570 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41850017408529916, 'Total loss': 0.41850017408529916} | train loss {'Reaction outcome loss': 0.2723453322384697, 'Total loss': 0.2723453322384697}
2023-01-04 10:25:21,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:21,570 INFO:     Epoch: 97
2023-01-04 10:25:23,130 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3872653936346372, 'Total loss': 0.3872653936346372} | train loss {'Reaction outcome loss': 0.2675912068327413, 'Total loss': 0.2675912068327413}
2023-01-04 10:25:23,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:23,131 INFO:     Epoch: 98
2023-01-04 10:25:24,678 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3913278192281723, 'Total loss': 0.3913278192281723} | train loss {'Reaction outcome loss': 0.2680927339098314, 'Total loss': 0.2680927339098314}
2023-01-04 10:25:24,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:24,678 INFO:     Epoch: 99
2023-01-04 10:25:26,231 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42634173333644865, 'Total loss': 0.42634173333644865} | train loss {'Reaction outcome loss': 0.27028415324914196, 'Total loss': 0.27028415324914196}
2023-01-04 10:25:26,232 INFO:     Best model found after epoch 79 of 100.
2023-01-04 10:25:26,232 INFO:   Done with stage: TRAINING
2023-01-04 10:25:26,232 INFO:   Starting stage: EVALUATION
2023-01-04 10:25:26,367 INFO:   Done with stage: EVALUATION
2023-01-04 10:25:26,367 INFO:   Leaving out SEQ value Fold_1
2023-01-04 10:25:26,380 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 10:25:26,380 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:25:27,021 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:25:27,021 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:25:27,088 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:25:27,089 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:25:27,089 INFO:     No hyperparam tuning for this model
2023-01-04 10:25:27,089 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:25:27,089 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:25:27,089 INFO:     None feature selector for col prot
2023-01-04 10:25:27,090 INFO:     None feature selector for col prot
2023-01-04 10:25:27,090 INFO:     None feature selector for col prot
2023-01-04 10:25:27,090 INFO:     None feature selector for col chem
2023-01-04 10:25:27,090 INFO:     None feature selector for col chem
2023-01-04 10:25:27,090 INFO:     None feature selector for col chem
2023-01-04 10:25:27,090 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:25:27,090 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:25:27,091 INFO:     Number of params in model 70111
2023-01-04 10:25:27,095 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:25:27,095 INFO:   Starting stage: TRAINING
2023-01-04 10:25:27,137 INFO:     Val loss before train {'Reaction outcome loss': 0.9953874270121257, 'Total loss': 0.9953874270121257}
2023-01-04 10:25:27,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:27,137 INFO:     Epoch: 0
2023-01-04 10:25:28,622 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7232247511545817, 'Total loss': 0.7232247511545817} | train loss {'Reaction outcome loss': 0.8286543497203911, 'Total loss': 0.8286543497203911}
2023-01-04 10:25:28,623 INFO:     Found new best model at epoch 0
2023-01-04 10:25:28,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:28,624 INFO:     Epoch: 1
2023-01-04 10:25:30,163 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5918465197086334, 'Total loss': 0.5918465197086334} | train loss {'Reaction outcome loss': 0.6633303002284391, 'Total loss': 0.6633303002284391}
2023-01-04 10:25:30,163 INFO:     Found new best model at epoch 1
2023-01-04 10:25:30,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:30,164 INFO:     Epoch: 2
2023-01-04 10:25:31,725 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.566329030195872, 'Total loss': 0.566329030195872} | train loss {'Reaction outcome loss': 0.5739403325167015, 'Total loss': 0.5739403325167015}
2023-01-04 10:25:31,725 INFO:     Found new best model at epoch 2
2023-01-04 10:25:31,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:31,726 INFO:     Epoch: 3
2023-01-04 10:25:33,274 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5600593030452728, 'Total loss': 0.5600593030452728} | train loss {'Reaction outcome loss': 0.5366149838388401, 'Total loss': 0.5366149838388401}
2023-01-04 10:25:33,274 INFO:     Found new best model at epoch 3
2023-01-04 10:25:33,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:33,275 INFO:     Epoch: 4
2023-01-04 10:25:34,847 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5373085220654805, 'Total loss': 0.5373085220654805} | train loss {'Reaction outcome loss': 0.5153081353998532, 'Total loss': 0.5153081353998532}
2023-01-04 10:25:34,847 INFO:     Found new best model at epoch 4
2023-01-04 10:25:34,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:34,848 INFO:     Epoch: 5
2023-01-04 10:25:36,401 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5219062825043996, 'Total loss': 0.5219062825043996} | train loss {'Reaction outcome loss': 0.5028683327845413, 'Total loss': 0.5028683327845413}
2023-01-04 10:25:36,401 INFO:     Found new best model at epoch 5
2023-01-04 10:25:36,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:36,401 INFO:     Epoch: 6
2023-01-04 10:25:37,920 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5062003453572591, 'Total loss': 0.5062003453572591} | train loss {'Reaction outcome loss': 0.49066786000328344, 'Total loss': 0.49066786000328344}
2023-01-04 10:25:37,920 INFO:     Found new best model at epoch 6
2023-01-04 10:25:37,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:37,921 INFO:     Epoch: 7
2023-01-04 10:25:39,485 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5097584168116251, 'Total loss': 0.5097584168116251} | train loss {'Reaction outcome loss': 0.48128535647461884, 'Total loss': 0.48128535647461884}
2023-01-04 10:25:39,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:39,486 INFO:     Epoch: 8
2023-01-04 10:25:41,066 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5091832141081493, 'Total loss': 0.5091832141081493} | train loss {'Reaction outcome loss': 0.475406242602498, 'Total loss': 0.475406242602498}
2023-01-04 10:25:41,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:41,066 INFO:     Epoch: 9
2023-01-04 10:25:42,637 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4824969867865245, 'Total loss': 0.4824969867865245} | train loss {'Reaction outcome loss': 0.4687823739147534, 'Total loss': 0.4687823739147534}
2023-01-04 10:25:42,638 INFO:     Found new best model at epoch 9
2023-01-04 10:25:42,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:42,638 INFO:     Epoch: 10
2023-01-04 10:25:44,214 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4952920695145925, 'Total loss': 0.4952920695145925} | train loss {'Reaction outcome loss': 0.4629434188352014, 'Total loss': 0.4629434188352014}
2023-01-04 10:25:44,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:44,214 INFO:     Epoch: 11
2023-01-04 10:25:45,745 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4816659430662791, 'Total loss': 0.4816659430662791} | train loss {'Reaction outcome loss': 0.4567074921988223, 'Total loss': 0.4567074921988223}
2023-01-04 10:25:45,745 INFO:     Found new best model at epoch 11
2023-01-04 10:25:45,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:45,746 INFO:     Epoch: 12
2023-01-04 10:25:47,270 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4848894476890564, 'Total loss': 0.4848894476890564} | train loss {'Reaction outcome loss': 0.44967515581715717, 'Total loss': 0.44967515581715717}
2023-01-04 10:25:47,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:47,271 INFO:     Epoch: 13
2023-01-04 10:25:48,822 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49152179559071857, 'Total loss': 0.49152179559071857} | train loss {'Reaction outcome loss': 0.44837329346333105, 'Total loss': 0.44837329346333105}
2023-01-04 10:25:48,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:48,823 INFO:     Epoch: 14
2023-01-04 10:25:50,388 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5038784583409627, 'Total loss': 0.5038784583409627} | train loss {'Reaction outcome loss': 0.4418007475289985, 'Total loss': 0.4418007475289985}
2023-01-04 10:25:50,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:50,388 INFO:     Epoch: 15
2023-01-04 10:25:51,942 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4864567905664444, 'Total loss': 0.4864567905664444} | train loss {'Reaction outcome loss': 0.43732958814523515, 'Total loss': 0.43732958814523515}
2023-01-04 10:25:51,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:51,943 INFO:     Epoch: 16
2023-01-04 10:25:53,527 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5098742286364237, 'Total loss': 0.5098742286364237} | train loss {'Reaction outcome loss': 0.4344167878212285, 'Total loss': 0.4344167878212285}
2023-01-04 10:25:53,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:53,527 INFO:     Epoch: 17
2023-01-04 10:25:55,060 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4922556181748708, 'Total loss': 0.4922556181748708} | train loss {'Reaction outcome loss': 0.43034423517919806, 'Total loss': 0.43034423517919806}
2023-01-04 10:25:55,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:55,061 INFO:     Epoch: 18
2023-01-04 10:25:56,603 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47214129169782004, 'Total loss': 0.47214129169782004} | train loss {'Reaction outcome loss': 0.42400186062946804, 'Total loss': 0.42400186062946804}
2023-01-04 10:25:56,603 INFO:     Found new best model at epoch 18
2023-01-04 10:25:56,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:56,604 INFO:     Epoch: 19
2023-01-04 10:25:58,192 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46384818355242413, 'Total loss': 0.46384818355242413} | train loss {'Reaction outcome loss': 0.42147063420419273, 'Total loss': 0.42147063420419273}
2023-01-04 10:25:58,193 INFO:     Found new best model at epoch 19
2023-01-04 10:25:58,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:58,194 INFO:     Epoch: 20
2023-01-04 10:25:59,772 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4995950639247894, 'Total loss': 0.4995950639247894} | train loss {'Reaction outcome loss': 0.41603169185075445, 'Total loss': 0.41603169185075445}
2023-01-04 10:25:59,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:25:59,772 INFO:     Epoch: 21
2023-01-04 10:26:01,354 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4809372027715047, 'Total loss': 0.4809372027715047} | train loss {'Reaction outcome loss': 0.41201653146613254, 'Total loss': 0.41201653146613254}
2023-01-04 10:26:01,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:01,354 INFO:     Epoch: 22
2023-01-04 10:26:02,932 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4834906101226807, 'Total loss': 0.4834906101226807} | train loss {'Reaction outcome loss': 0.41272102715107645, 'Total loss': 0.41272102715107645}
2023-01-04 10:26:02,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:02,932 INFO:     Epoch: 23
2023-01-04 10:26:04,486 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46912594735622404, 'Total loss': 0.46912594735622404} | train loss {'Reaction outcome loss': 0.40532435629054575, 'Total loss': 0.40532435629054575}
2023-01-04 10:26:04,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:04,487 INFO:     Epoch: 24
2023-01-04 10:26:06,039 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4460225164890289, 'Total loss': 0.4460225164890289} | train loss {'Reaction outcome loss': 0.40231066414692107, 'Total loss': 0.40231066414692107}
2023-01-04 10:26:06,039 INFO:     Found new best model at epoch 24
2023-01-04 10:26:06,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:06,040 INFO:     Epoch: 25
2023-01-04 10:26:07,625 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4866555978854497, 'Total loss': 0.4866555978854497} | train loss {'Reaction outcome loss': 0.39279278993171496, 'Total loss': 0.39279278993171496}
2023-01-04 10:26:07,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:07,626 INFO:     Epoch: 26
2023-01-04 10:26:09,207 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44836391309897106, 'Total loss': 0.44836391309897106} | train loss {'Reaction outcome loss': 0.3933243301228015, 'Total loss': 0.3933243301228015}
2023-01-04 10:26:09,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:09,207 INFO:     Epoch: 27
2023-01-04 10:26:10,790 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47514089941978455, 'Total loss': 0.47514089941978455} | train loss {'Reaction outcome loss': 0.3930626942837325, 'Total loss': 0.3930626942837325}
2023-01-04 10:26:10,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:10,790 INFO:     Epoch: 28
2023-01-04 10:26:12,349 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4657619297504425, 'Total loss': 0.4657619297504425} | train loss {'Reaction outcome loss': 0.38461384193523085, 'Total loss': 0.38461384193523085}
2023-01-04 10:26:12,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:12,349 INFO:     Epoch: 29
2023-01-04 10:26:13,909 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4530865212281545, 'Total loss': 0.4530865212281545} | train loss {'Reaction outcome loss': 0.3832110139357783, 'Total loss': 0.3832110139357783}
2023-01-04 10:26:13,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:13,909 INFO:     Epoch: 30
2023-01-04 10:26:15,466 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4523682564496994, 'Total loss': 0.4523682564496994} | train loss {'Reaction outcome loss': 0.3778411060789206, 'Total loss': 0.3778411060789206}
2023-01-04 10:26:15,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:15,466 INFO:     Epoch: 31
2023-01-04 10:26:17,040 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4398749987284342, 'Total loss': 0.4398749987284342} | train loss {'Reaction outcome loss': 0.3738352507624748, 'Total loss': 0.3738352507624748}
2023-01-04 10:26:17,040 INFO:     Found new best model at epoch 31
2023-01-04 10:26:17,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:17,041 INFO:     Epoch: 32
2023-01-04 10:26:18,634 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46994276841481525, 'Total loss': 0.46994276841481525} | train loss {'Reaction outcome loss': 0.3711599261656295, 'Total loss': 0.3711599261656295}
2023-01-04 10:26:18,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:18,635 INFO:     Epoch: 33
2023-01-04 10:26:20,196 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4616809179385503, 'Total loss': 0.4616809179385503} | train loss {'Reaction outcome loss': 0.368638879028115, 'Total loss': 0.368638879028115}
2023-01-04 10:26:20,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:20,196 INFO:     Epoch: 34
2023-01-04 10:26:21,776 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4489624341328939, 'Total loss': 0.4489624341328939} | train loss {'Reaction outcome loss': 0.36465103663232207, 'Total loss': 0.36465103663232207}
2023-01-04 10:26:21,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:21,776 INFO:     Epoch: 35
2023-01-04 10:26:23,283 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4262786452968915, 'Total loss': 0.4262786452968915} | train loss {'Reaction outcome loss': 0.3640364093882759, 'Total loss': 0.3640364093882759}
2023-01-04 10:26:23,283 INFO:     Found new best model at epoch 35
2023-01-04 10:26:23,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:23,284 INFO:     Epoch: 36
2023-01-04 10:26:24,859 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44832925001780194, 'Total loss': 0.44832925001780194} | train loss {'Reaction outcome loss': 0.3626219799646931, 'Total loss': 0.3626219799646931}
2023-01-04 10:26:24,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:24,860 INFO:     Epoch: 37
2023-01-04 10:26:26,428 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.476667974392573, 'Total loss': 0.476667974392573} | train loss {'Reaction outcome loss': 0.3566518899624365, 'Total loss': 0.3566518899624365}
2023-01-04 10:26:26,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:26,428 INFO:     Epoch: 38
2023-01-04 10:26:27,997 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46381025662024816, 'Total loss': 0.46381025662024816} | train loss {'Reaction outcome loss': 0.35169696361914166, 'Total loss': 0.35169696361914166}
2023-01-04 10:26:27,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:27,997 INFO:     Epoch: 39
2023-01-04 10:26:29,577 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4796384274959564, 'Total loss': 0.4796384274959564} | train loss {'Reaction outcome loss': 0.34964296564351033, 'Total loss': 0.34964296564351033}
2023-01-04 10:26:29,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:29,578 INFO:     Epoch: 40
2023-01-04 10:26:31,096 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4387512803077698, 'Total loss': 0.4387512803077698} | train loss {'Reaction outcome loss': 0.34438684221057997, 'Total loss': 0.34438684221057997}
2023-01-04 10:26:31,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:31,096 INFO:     Epoch: 41
2023-01-04 10:26:32,611 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47659543057282766, 'Total loss': 0.47659543057282766} | train loss {'Reaction outcome loss': 0.3450534464995356, 'Total loss': 0.3450534464995356}
2023-01-04 10:26:32,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:32,612 INFO:     Epoch: 42
2023-01-04 10:26:34,175 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44831393162409466, 'Total loss': 0.44831393162409466} | train loss {'Reaction outcome loss': 0.3400920324680144, 'Total loss': 0.3400920324680144}
2023-01-04 10:26:34,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:34,176 INFO:     Epoch: 43
2023-01-04 10:26:35,717 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4692539672056834, 'Total loss': 0.4692539672056834} | train loss {'Reaction outcome loss': 0.3372627895352614, 'Total loss': 0.3372627895352614}
2023-01-04 10:26:35,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:35,718 INFO:     Epoch: 44
2023-01-04 10:26:37,315 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4587469349304835, 'Total loss': 0.4587469349304835} | train loss {'Reaction outcome loss': 0.3380175735121661, 'Total loss': 0.3380175735121661}
2023-01-04 10:26:37,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:37,315 INFO:     Epoch: 45
2023-01-04 10:26:38,890 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45875120063622793, 'Total loss': 0.45875120063622793} | train loss {'Reaction outcome loss': 0.3349322629344724, 'Total loss': 0.3349322629344724}
2023-01-04 10:26:38,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:38,890 INFO:     Epoch: 46
2023-01-04 10:26:40,426 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4430170327425003, 'Total loss': 0.4430170327425003} | train loss {'Reaction outcome loss': 0.3275483056739734, 'Total loss': 0.3275483056739734}
2023-01-04 10:26:40,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:40,426 INFO:     Epoch: 47
2023-01-04 10:26:41,977 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4624056488275528, 'Total loss': 0.4624056488275528} | train loss {'Reaction outcome loss': 0.3311373359204209, 'Total loss': 0.3311373359204209}
2023-01-04 10:26:41,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:41,977 INFO:     Epoch: 48
2023-01-04 10:26:43,548 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47004650831222533, 'Total loss': 0.47004650831222533} | train loss {'Reaction outcome loss': 0.33049755263393815, 'Total loss': 0.33049755263393815}
2023-01-04 10:26:43,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:43,548 INFO:     Epoch: 49
2023-01-04 10:26:45,130 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.450607497493426, 'Total loss': 0.450607497493426} | train loss {'Reaction outcome loss': 0.32531727181516423, 'Total loss': 0.32531727181516423}
2023-01-04 10:26:45,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:45,130 INFO:     Epoch: 50
2023-01-04 10:26:46,727 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44173023899396263, 'Total loss': 0.44173023899396263} | train loss {'Reaction outcome loss': 0.32150829110267387, 'Total loss': 0.32150829110267387}
2023-01-04 10:26:46,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:46,727 INFO:     Epoch: 51
2023-01-04 10:26:48,321 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4619141697883606, 'Total loss': 0.4619141697883606} | train loss {'Reaction outcome loss': 0.3181464738708778, 'Total loss': 0.3181464738708778}
2023-01-04 10:26:48,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:48,322 INFO:     Epoch: 52
2023-01-04 10:26:49,874 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4467999756336212, 'Total loss': 0.4467999756336212} | train loss {'Reaction outcome loss': 0.3221123015956722, 'Total loss': 0.3221123015956722}
2023-01-04 10:26:49,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:49,874 INFO:     Epoch: 53
2023-01-04 10:26:51,421 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45027439097563426, 'Total loss': 0.45027439097563426} | train loss {'Reaction outcome loss': 0.31666949709510284, 'Total loss': 0.31666949709510284}
2023-01-04 10:26:51,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:51,422 INFO:     Epoch: 54
2023-01-04 10:26:52,998 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4329869545996189, 'Total loss': 0.4329869545996189} | train loss {'Reaction outcome loss': 0.31169210972577116, 'Total loss': 0.31169210972577116}
2023-01-04 10:26:52,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:52,998 INFO:     Epoch: 55
2023-01-04 10:26:54,591 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4460760494073232, 'Total loss': 0.4460760494073232} | train loss {'Reaction outcome loss': 0.31448370392305136, 'Total loss': 0.31448370392305136}
2023-01-04 10:26:54,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:54,592 INFO:     Epoch: 56
2023-01-04 10:26:56,198 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4481329788764318, 'Total loss': 0.4481329788764318} | train loss {'Reaction outcome loss': 0.3115721682399294, 'Total loss': 0.3115721682399294}
2023-01-04 10:26:56,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:56,199 INFO:     Epoch: 57
2023-01-04 10:26:57,789 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47487453917662303, 'Total loss': 0.47487453917662303} | train loss {'Reaction outcome loss': 0.30874159255058226, 'Total loss': 0.30874159255058226}
2023-01-04 10:26:57,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:57,790 INFO:     Epoch: 58
2023-01-04 10:26:59,333 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46767589847246804, 'Total loss': 0.46767589847246804} | train loss {'Reaction outcome loss': 0.3069912844276341, 'Total loss': 0.3069912844276341}
2023-01-04 10:26:59,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:26:59,333 INFO:     Epoch: 59
2023-01-04 10:27:00,890 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4900806327660879, 'Total loss': 0.4900806327660879} | train loss {'Reaction outcome loss': 0.30508806502079444, 'Total loss': 0.30508806502079444}
2023-01-04 10:27:00,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:00,890 INFO:     Epoch: 60
2023-01-04 10:27:02,466 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4709185024102529, 'Total loss': 0.4709185024102529} | train loss {'Reaction outcome loss': 0.30689045525815367, 'Total loss': 0.30689045525815367}
2023-01-04 10:27:02,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:02,466 INFO:     Epoch: 61
2023-01-04 10:27:04,031 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46810454726219175, 'Total loss': 0.46810454726219175} | train loss {'Reaction outcome loss': 0.30288913446295, 'Total loss': 0.30288913446295}
2023-01-04 10:27:04,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:04,032 INFO:     Epoch: 62
2023-01-04 10:27:05,615 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46938476860523226, 'Total loss': 0.46938476860523226} | train loss {'Reaction outcome loss': 0.30512623793452326, 'Total loss': 0.30512623793452326}
2023-01-04 10:27:05,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:05,616 INFO:     Epoch: 63
2023-01-04 10:27:07,202 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.494508953889211, 'Total loss': 0.494508953889211} | train loss {'Reaction outcome loss': 0.3012271662426256, 'Total loss': 0.3012271662426256}
2023-01-04 10:27:07,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:07,202 INFO:     Epoch: 64
2023-01-04 10:27:08,710 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46588927805423735, 'Total loss': 0.46588927805423735} | train loss {'Reaction outcome loss': 0.2972672791050298, 'Total loss': 0.2972672791050298}
2023-01-04 10:27:08,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:08,710 INFO:     Epoch: 65
2023-01-04 10:27:10,298 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4876618981361389, 'Total loss': 0.4876618981361389} | train loss {'Reaction outcome loss': 0.29643844160502847, 'Total loss': 0.29643844160502847}
2023-01-04 10:27:10,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:10,298 INFO:     Epoch: 66
2023-01-04 10:27:11,880 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4445181647936503, 'Total loss': 0.4445181647936503} | train loss {'Reaction outcome loss': 0.29909367802260567, 'Total loss': 0.29909367802260567}
2023-01-04 10:27:11,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:11,881 INFO:     Epoch: 67
2023-01-04 10:27:13,455 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45801474452018737, 'Total loss': 0.45801474452018737} | train loss {'Reaction outcome loss': 0.28992858768379604, 'Total loss': 0.28992858768379604}
2023-01-04 10:27:13,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:13,455 INFO:     Epoch: 68
2023-01-04 10:27:15,028 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46043724517027534, 'Total loss': 0.46043724517027534} | train loss {'Reaction outcome loss': 0.2909287186815356, 'Total loss': 0.2909287186815356}
2023-01-04 10:27:15,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:15,028 INFO:     Epoch: 69
2023-01-04 10:27:16,585 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44013164689143497, 'Total loss': 0.44013164689143497} | train loss {'Reaction outcome loss': 0.2934701715725182, 'Total loss': 0.2934701715725182}
2023-01-04 10:27:16,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:16,585 INFO:     Epoch: 70
2023-01-04 10:27:18,118 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46881872713565825, 'Total loss': 0.46881872713565825} | train loss {'Reaction outcome loss': 0.2901554762582927, 'Total loss': 0.2901554762582927}
2023-01-04 10:27:18,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:18,118 INFO:     Epoch: 71
2023-01-04 10:27:19,684 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4547930330038071, 'Total loss': 0.4547930330038071} | train loss {'Reaction outcome loss': 0.2873110028976289, 'Total loss': 0.2873110028976289}
2023-01-04 10:27:19,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:19,684 INFO:     Epoch: 72
2023-01-04 10:27:21,252 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4442482272783915, 'Total loss': 0.4442482272783915} | train loss {'Reaction outcome loss': 0.28328893605592476, 'Total loss': 0.28328893605592476}
2023-01-04 10:27:21,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:21,252 INFO:     Epoch: 73
2023-01-04 10:27:22,846 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.434609717130661, 'Total loss': 0.434609717130661} | train loss {'Reaction outcome loss': 0.2913742977174094, 'Total loss': 0.2913742977174094}
2023-01-04 10:27:22,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:22,847 INFO:     Epoch: 74
2023-01-04 10:27:24,444 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4490396698315938, 'Total loss': 0.4490396698315938} | train loss {'Reaction outcome loss': 0.28376721840922847, 'Total loss': 0.28376721840922847}
2023-01-04 10:27:24,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:24,444 INFO:     Epoch: 75
2023-01-04 10:27:25,986 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4598139603932699, 'Total loss': 0.4598139603932699} | train loss {'Reaction outcome loss': 0.2848639319358516, 'Total loss': 0.2848639319358516}
2023-01-04 10:27:25,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:25,987 INFO:     Epoch: 76
2023-01-04 10:27:27,543 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48749164839585624, 'Total loss': 0.48749164839585624} | train loss {'Reaction outcome loss': 0.2790267587143139, 'Total loss': 0.2790267587143139}
2023-01-04 10:27:27,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:27,543 INFO:     Epoch: 77
2023-01-04 10:27:29,134 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4606477916240692, 'Total loss': 0.4606477916240692} | train loss {'Reaction outcome loss': 0.2779126177902204, 'Total loss': 0.2779126177902204}
2023-01-04 10:27:29,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:29,135 INFO:     Epoch: 78
2023-01-04 10:27:30,711 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49839146931966144, 'Total loss': 0.49839146931966144} | train loss {'Reaction outcome loss': 0.2787961095544326, 'Total loss': 0.2787961095544326}
2023-01-04 10:27:30,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:30,711 INFO:     Epoch: 79
2023-01-04 10:27:32,288 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44590196510155994, 'Total loss': 0.44590196510155994} | train loss {'Reaction outcome loss': 0.2790959517124796, 'Total loss': 0.2790959517124796}
2023-01-04 10:27:32,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:32,288 INFO:     Epoch: 80
2023-01-04 10:27:33,858 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45475896696249646, 'Total loss': 0.45475896696249646} | train loss {'Reaction outcome loss': 0.2804110831696622, 'Total loss': 0.2804110831696622}
2023-01-04 10:27:33,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:33,858 INFO:     Epoch: 81
2023-01-04 10:27:35,391 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4423896978298823, 'Total loss': 0.4423896978298823} | train loss {'Reaction outcome loss': 0.27778613852867245, 'Total loss': 0.27778613852867245}
2023-01-04 10:27:35,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:35,391 INFO:     Epoch: 82
2023-01-04 10:27:36,929 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47769185503323874, 'Total loss': 0.47769185503323874} | train loss {'Reaction outcome loss': 0.27280816767555083, 'Total loss': 0.27280816767555083}
2023-01-04 10:27:36,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:36,929 INFO:     Epoch: 83
2023-01-04 10:27:38,464 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4470636775096258, 'Total loss': 0.4470636775096258} | train loss {'Reaction outcome loss': 0.2757801761864311, 'Total loss': 0.2757801761864311}
2023-01-04 10:27:38,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:38,465 INFO:     Epoch: 84
2023-01-04 10:27:40,018 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4685691624879837, 'Total loss': 0.4685691624879837} | train loss {'Reaction outcome loss': 0.2722741678955346, 'Total loss': 0.2722741678955346}
2023-01-04 10:27:40,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:40,018 INFO:     Epoch: 85
2023-01-04 10:27:41,568 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4641473243633906, 'Total loss': 0.4641473243633906} | train loss {'Reaction outcome loss': 0.27182032112168136, 'Total loss': 0.27182032112168136}
2023-01-04 10:27:41,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:41,569 INFO:     Epoch: 86
2023-01-04 10:27:43,104 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44446189403533937, 'Total loss': 0.44446189403533937} | train loss {'Reaction outcome loss': 0.27117519934464546, 'Total loss': 0.27117519934464546}
2023-01-04 10:27:43,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:43,104 INFO:     Epoch: 87
2023-01-04 10:27:44,627 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43997422357400257, 'Total loss': 0.43997422357400257} | train loss {'Reaction outcome loss': 0.27013879149717135, 'Total loss': 0.27013879149717135}
2023-01-04 10:27:44,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:44,627 INFO:     Epoch: 88
2023-01-04 10:27:45,742 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4454773704210917, 'Total loss': 0.4454773704210917} | train loss {'Reaction outcome loss': 0.2664429476878939, 'Total loss': 0.2664429476878939}
2023-01-04 10:27:45,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:45,742 INFO:     Epoch: 89
2023-01-04 10:27:46,788 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4554701134562492, 'Total loss': 0.4554701134562492} | train loss {'Reaction outcome loss': 0.26720937776522047, 'Total loss': 0.26720937776522047}
2023-01-04 10:27:46,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:46,789 INFO:     Epoch: 90
2023-01-04 10:27:47,818 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45290030936400094, 'Total loss': 0.45290030936400094} | train loss {'Reaction outcome loss': 0.26654129491670286, 'Total loss': 0.26654129491670286}
2023-01-04 10:27:47,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:47,819 INFO:     Epoch: 91
2023-01-04 10:27:48,851 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44998206694920856, 'Total loss': 0.44998206694920856} | train loss {'Reaction outcome loss': 0.2620715211369913, 'Total loss': 0.2620715211369913}
2023-01-04 10:27:48,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:48,851 INFO:     Epoch: 92
2023-01-04 10:27:50,301 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46721159617106117, 'Total loss': 0.46721159617106117} | train loss {'Reaction outcome loss': 0.26548452154617674, 'Total loss': 0.26548452154617674}
2023-01-04 10:27:50,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:50,301 INFO:     Epoch: 93
2023-01-04 10:27:51,880 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4486419161160787, 'Total loss': 0.4486419161160787} | train loss {'Reaction outcome loss': 0.2632614516646323, 'Total loss': 0.2632614516646323}
2023-01-04 10:27:51,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:51,880 INFO:     Epoch: 94
2023-01-04 10:27:53,457 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45282316704591113, 'Total loss': 0.45282316704591113} | train loss {'Reaction outcome loss': 0.2624942105752926, 'Total loss': 0.2624942105752926}
2023-01-04 10:27:53,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:53,457 INFO:     Epoch: 95
2023-01-04 10:27:55,039 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44472983678181965, 'Total loss': 0.44472983678181965} | train loss {'Reaction outcome loss': 0.2589096386447875, 'Total loss': 0.2589096386447875}
2023-01-04 10:27:55,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:55,039 INFO:     Epoch: 96
2023-01-04 10:27:56,611 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4793521891037623, 'Total loss': 0.4793521891037623} | train loss {'Reaction outcome loss': 0.25723543333528687, 'Total loss': 0.25723543333528687}
2023-01-04 10:27:56,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:56,612 INFO:     Epoch: 97
2023-01-04 10:27:58,180 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43151096304257713, 'Total loss': 0.43151096304257713} | train loss {'Reaction outcome loss': 0.25884327032759674, 'Total loss': 0.25884327032759674}
2023-01-04 10:27:58,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:58,181 INFO:     Epoch: 98
2023-01-04 10:27:59,669 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4748601675033569, 'Total loss': 0.4748601675033569} | train loss {'Reaction outcome loss': 0.25562488998755484, 'Total loss': 0.25562488998755484}
2023-01-04 10:27:59,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:27:59,669 INFO:     Epoch: 99
2023-01-04 10:28:01,269 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4432126581668854, 'Total loss': 0.4432126581668854} | train loss {'Reaction outcome loss': 0.25972268873159465, 'Total loss': 0.25972268873159465}
2023-01-04 10:28:01,269 INFO:     Best model found after epoch 36 of 100.
2023-01-04 10:28:01,270 INFO:   Done with stage: TRAINING
2023-01-04 10:28:01,270 INFO:   Starting stage: EVALUATION
2023-01-04 10:28:01,404 INFO:   Done with stage: EVALUATION
2023-01-04 10:28:01,404 INFO:   Leaving out SEQ value Fold_2
2023-01-04 10:28:01,416 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 10:28:01,417 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:28:02,055 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:28:02,055 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:28:02,122 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:28:02,122 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:28:02,122 INFO:     No hyperparam tuning for this model
2023-01-04 10:28:02,122 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:28:02,122 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:28:02,123 INFO:     None feature selector for col prot
2023-01-04 10:28:02,123 INFO:     None feature selector for col prot
2023-01-04 10:28:02,123 INFO:     None feature selector for col prot
2023-01-04 10:28:02,124 INFO:     None feature selector for col chem
2023-01-04 10:28:02,124 INFO:     None feature selector for col chem
2023-01-04 10:28:02,124 INFO:     None feature selector for col chem
2023-01-04 10:28:02,124 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:28:02,124 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:28:02,125 INFO:     Number of params in model 70111
2023-01-04 10:28:02,128 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:28:02,128 INFO:   Starting stage: TRAINING
2023-01-04 10:28:02,170 INFO:     Val loss before train {'Reaction outcome loss': 0.916697617371877, 'Total loss': 0.916697617371877}
2023-01-04 10:28:02,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:02,170 INFO:     Epoch: 0
2023-01-04 10:28:03,730 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6689108490943909, 'Total loss': 0.6689108490943909} | train loss {'Reaction outcome loss': 0.8490680751455573, 'Total loss': 0.8490680751455573}
2023-01-04 10:28:03,730 INFO:     Found new best model at epoch 0
2023-01-04 10:28:03,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:03,731 INFO:     Epoch: 1
2023-01-04 10:28:05,305 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5739489038785298, 'Total loss': 0.5739489038785298} | train loss {'Reaction outcome loss': 0.696366487732737, 'Total loss': 0.696366487732737}
2023-01-04 10:28:05,305 INFO:     Found new best model at epoch 1
2023-01-04 10:28:05,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:05,306 INFO:     Epoch: 2
2023-01-04 10:28:06,867 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5387674311796824, 'Total loss': 0.5387674311796824} | train loss {'Reaction outcome loss': 0.6001582693704318, 'Total loss': 0.6001582693704318}
2023-01-04 10:28:06,867 INFO:     Found new best model at epoch 2
2023-01-04 10:28:06,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:06,868 INFO:     Epoch: 3
2023-01-04 10:28:08,379 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.525728048880895, 'Total loss': 0.525728048880895} | train loss {'Reaction outcome loss': 0.5629016497742125, 'Total loss': 0.5629016497742125}
2023-01-04 10:28:08,379 INFO:     Found new best model at epoch 3
2023-01-04 10:28:08,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:08,380 INFO:     Epoch: 4
2023-01-04 10:28:09,957 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5012904221812884, 'Total loss': 0.5012904221812884} | train loss {'Reaction outcome loss': 0.5300436028630742, 'Total loss': 0.5300436028630742}
2023-01-04 10:28:09,957 INFO:     Found new best model at epoch 4
2023-01-04 10:28:09,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:09,958 INFO:     Epoch: 5
2023-01-04 10:28:11,538 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4980741858482361, 'Total loss': 0.4980741858482361} | train loss {'Reaction outcome loss': 0.5155152407212135, 'Total loss': 0.5155152407212135}
2023-01-04 10:28:11,538 INFO:     Found new best model at epoch 5
2023-01-04 10:28:11,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:11,539 INFO:     Epoch: 6
2023-01-04 10:28:13,099 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49470288256804146, 'Total loss': 0.49470288256804146} | train loss {'Reaction outcome loss': 0.5051399718819957, 'Total loss': 0.5051399718819957}
2023-01-04 10:28:13,099 INFO:     Found new best model at epoch 6
2023-01-04 10:28:13,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:13,100 INFO:     Epoch: 7
2023-01-04 10:28:14,662 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4680022945006688, 'Total loss': 0.4680022945006688} | train loss {'Reaction outcome loss': 0.4929586945326774, 'Total loss': 0.4929586945326774}
2023-01-04 10:28:14,662 INFO:     Found new best model at epoch 7
2023-01-04 10:28:14,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:14,663 INFO:     Epoch: 8
2023-01-04 10:28:16,186 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49058809181054436, 'Total loss': 0.49058809181054436} | train loss {'Reaction outcome loss': 0.48247781510536486, 'Total loss': 0.48247781510536486}
2023-01-04 10:28:16,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:16,186 INFO:     Epoch: 9
2023-01-04 10:28:17,708 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.476676141222318, 'Total loss': 0.476676141222318} | train loss {'Reaction outcome loss': 0.47553282179238593, 'Total loss': 0.47553282179238593}
2023-01-04 10:28:17,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:17,710 INFO:     Epoch: 10
2023-01-04 10:28:19,280 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.491493284702301, 'Total loss': 0.491493284702301} | train loss {'Reaction outcome loss': 0.47068826455773016, 'Total loss': 0.47068826455773016}
2023-01-04 10:28:19,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:19,280 INFO:     Epoch: 11
2023-01-04 10:28:20,851 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4755461275577545, 'Total loss': 0.4755461275577545} | train loss {'Reaction outcome loss': 0.4602824290702631, 'Total loss': 0.4602824290702631}
2023-01-04 10:28:20,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:20,852 INFO:     Epoch: 12
2023-01-04 10:28:22,450 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4914000928401947, 'Total loss': 0.4914000928401947} | train loss {'Reaction outcome loss': 0.45753021707464925, 'Total loss': 0.45753021707464925}
2023-01-04 10:28:22,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:22,450 INFO:     Epoch: 13
2023-01-04 10:28:24,049 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45361128548781077, 'Total loss': 0.45361128548781077} | train loss {'Reaction outcome loss': 0.4512274790377844, 'Total loss': 0.4512274790377844}
2023-01-04 10:28:24,049 INFO:     Found new best model at epoch 13
2023-01-04 10:28:24,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:24,050 INFO:     Epoch: 14
2023-01-04 10:28:25,598 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4895651916662852, 'Total loss': 0.4895651916662852} | train loss {'Reaction outcome loss': 0.4487049924039142, 'Total loss': 0.4487049924039142}
2023-01-04 10:28:25,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:25,598 INFO:     Epoch: 15
2023-01-04 10:28:27,133 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4691564440727234, 'Total loss': 0.4691564440727234} | train loss {'Reaction outcome loss': 0.4480461475231272, 'Total loss': 0.4480461475231272}
2023-01-04 10:28:27,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:27,133 INFO:     Epoch: 16
2023-01-04 10:28:28,726 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4829760869344076, 'Total loss': 0.4829760869344076} | train loss {'Reaction outcome loss': 0.44047587231183666, 'Total loss': 0.44047587231183666}
2023-01-04 10:28:28,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:28,726 INFO:     Epoch: 17
2023-01-04 10:28:30,315 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4587711185216904, 'Total loss': 0.4587711185216904} | train loss {'Reaction outcome loss': 0.43703090320358345, 'Total loss': 0.43703090320358345}
2023-01-04 10:28:30,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:30,316 INFO:     Epoch: 18
2023-01-04 10:28:31,875 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4604078491528829, 'Total loss': 0.4604078491528829} | train loss {'Reaction outcome loss': 0.42514793814975266, 'Total loss': 0.42514793814975266}
2023-01-04 10:28:31,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:31,875 INFO:     Epoch: 19
2023-01-04 10:28:33,459 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4718562056620916, 'Total loss': 0.4718562056620916} | train loss {'Reaction outcome loss': 0.4223236799676776, 'Total loss': 0.4223236799676776}
2023-01-04 10:28:33,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:33,459 INFO:     Epoch: 20
2023-01-04 10:28:35,014 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44631768961747487, 'Total loss': 0.44631768961747487} | train loss {'Reaction outcome loss': 0.4213854970185311, 'Total loss': 0.4213854970185311}
2023-01-04 10:28:35,014 INFO:     Found new best model at epoch 20
2023-01-04 10:28:35,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:35,015 INFO:     Epoch: 21
2023-01-04 10:28:36,565 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4636864572763443, 'Total loss': 0.4636864572763443} | train loss {'Reaction outcome loss': 0.4184238964439312, 'Total loss': 0.4184238964439312}
2023-01-04 10:28:36,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:36,566 INFO:     Epoch: 22
2023-01-04 10:28:38,154 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46281323830286664, 'Total loss': 0.46281323830286664} | train loss {'Reaction outcome loss': 0.41624740934197285, 'Total loss': 0.41624740934197285}
2023-01-04 10:28:38,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:38,154 INFO:     Epoch: 23
2023-01-04 10:28:39,736 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4660117715597153, 'Total loss': 0.4660117715597153} | train loss {'Reaction outcome loss': 0.4093838909934292, 'Total loss': 0.4093838909934292}
2023-01-04 10:28:39,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:39,737 INFO:     Epoch: 24
2023-01-04 10:28:41,321 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48959566056728365, 'Total loss': 0.48959566056728365} | train loss {'Reaction outcome loss': 0.4093935497023247, 'Total loss': 0.4093935497023247}
2023-01-04 10:28:41,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:41,321 INFO:     Epoch: 25
2023-01-04 10:28:42,886 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4586604078610738, 'Total loss': 0.4586604078610738} | train loss {'Reaction outcome loss': 0.40365714724465607, 'Total loss': 0.40365714724465607}
2023-01-04 10:28:42,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:42,886 INFO:     Epoch: 26
2023-01-04 10:28:44,413 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45516787966092426, 'Total loss': 0.45516787966092426} | train loss {'Reaction outcome loss': 0.4004569641508899, 'Total loss': 0.4004569641508899}
2023-01-04 10:28:44,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:44,413 INFO:     Epoch: 27
2023-01-04 10:28:45,979 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4486023406187693, 'Total loss': 0.4486023406187693} | train loss {'Reaction outcome loss': 0.3939938750459161, 'Total loss': 0.3939938750459161}
2023-01-04 10:28:45,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:45,979 INFO:     Epoch: 28
2023-01-04 10:28:47,569 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4526476462682088, 'Total loss': 0.4526476462682088} | train loss {'Reaction outcome loss': 0.3926756766252902, 'Total loss': 0.3926756766252902}
2023-01-04 10:28:47,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:47,569 INFO:     Epoch: 29
2023-01-04 10:28:49,139 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4358570039272308, 'Total loss': 0.4358570039272308} | train loss {'Reaction outcome loss': 0.38722409078708064, 'Total loss': 0.38722409078708064}
2023-01-04 10:28:49,139 INFO:     Found new best model at epoch 29
2023-01-04 10:28:49,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:49,140 INFO:     Epoch: 30
2023-01-04 10:28:50,711 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43269669115543363, 'Total loss': 0.43269669115543363} | train loss {'Reaction outcome loss': 0.3844470475619529, 'Total loss': 0.3844470475619529}
2023-01-04 10:28:50,711 INFO:     Found new best model at epoch 30
2023-01-04 10:28:50,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:50,712 INFO:     Epoch: 31
2023-01-04 10:28:52,269 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46563424269358317, 'Total loss': 0.46563424269358317} | train loss {'Reaction outcome loss': 0.38259136764121143, 'Total loss': 0.38259136764121143}
2023-01-04 10:28:52,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:52,270 INFO:     Epoch: 32
2023-01-04 10:28:53,770 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4600864847501119, 'Total loss': 0.4600864847501119} | train loss {'Reaction outcome loss': 0.37368509001456773, 'Total loss': 0.37368509001456773}
2023-01-04 10:28:53,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:53,770 INFO:     Epoch: 33
2023-01-04 10:28:55,345 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45774354934692385, 'Total loss': 0.45774354934692385} | train loss {'Reaction outcome loss': 0.3737152032144777, 'Total loss': 0.3737152032144777}
2023-01-04 10:28:55,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:55,345 INFO:     Epoch: 34
2023-01-04 10:28:56,930 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4316502660512924, 'Total loss': 0.4316502660512924} | train loss {'Reaction outcome loss': 0.3750083131558729, 'Total loss': 0.3750083131558729}
2023-01-04 10:28:56,930 INFO:     Found new best model at epoch 34
2023-01-04 10:28:56,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:56,931 INFO:     Epoch: 35
2023-01-04 10:28:58,520 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.423334813863039, 'Total loss': 0.423334813863039} | train loss {'Reaction outcome loss': 0.36828392361983275, 'Total loss': 0.36828392361983275}
2023-01-04 10:28:58,521 INFO:     Found new best model at epoch 35
2023-01-04 10:28:58,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:28:58,521 INFO:     Epoch: 36
2023-01-04 10:29:00,113 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4296662290891012, 'Total loss': 0.4296662290891012} | train loss {'Reaction outcome loss': 0.3680562041836344, 'Total loss': 0.3680562041836344}
2023-01-04 10:29:00,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:00,113 INFO:     Epoch: 37
2023-01-04 10:29:01,657 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42222981055577596, 'Total loss': 0.42222981055577596} | train loss {'Reaction outcome loss': 0.36304863755192074, 'Total loss': 0.36304863755192074}
2023-01-04 10:29:01,657 INFO:     Found new best model at epoch 37
2023-01-04 10:29:01,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:01,658 INFO:     Epoch: 38
2023-01-04 10:29:03,173 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4211596588293711, 'Total loss': 0.4211596588293711} | train loss {'Reaction outcome loss': 0.35986166174486006, 'Total loss': 0.35986166174486006}
2023-01-04 10:29:03,173 INFO:     Found new best model at epoch 38
2023-01-04 10:29:03,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:03,174 INFO:     Epoch: 39
2023-01-04 10:29:04,763 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4477981835603714, 'Total loss': 0.4477981835603714} | train loss {'Reaction outcome loss': 0.354170452162023, 'Total loss': 0.354170452162023}
2023-01-04 10:29:04,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:04,764 INFO:     Epoch: 40
2023-01-04 10:29:06,337 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4193682650725047, 'Total loss': 0.4193682650725047} | train loss {'Reaction outcome loss': 0.35435884898944653, 'Total loss': 0.35435884898944653}
2023-01-04 10:29:06,337 INFO:     Found new best model at epoch 40
2023-01-04 10:29:06,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:06,338 INFO:     Epoch: 41
2023-01-04 10:29:07,927 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43589480221271515, 'Total loss': 0.43589480221271515} | train loss {'Reaction outcome loss': 0.353185035779581, 'Total loss': 0.353185035779581}
2023-01-04 10:29:07,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:07,927 INFO:     Epoch: 42
2023-01-04 10:29:09,517 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41647896766662595, 'Total loss': 0.41647896766662595} | train loss {'Reaction outcome loss': 0.34651923867372364, 'Total loss': 0.34651923867372364}
2023-01-04 10:29:09,517 INFO:     Found new best model at epoch 42
2023-01-04 10:29:09,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:09,518 INFO:     Epoch: 43
2023-01-04 10:29:11,058 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43536970019340515, 'Total loss': 0.43536970019340515} | train loss {'Reaction outcome loss': 0.3470811962863028, 'Total loss': 0.3470811962863028}
2023-01-04 10:29:11,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:11,059 INFO:     Epoch: 44
2023-01-04 10:29:12,611 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41728406846523286, 'Total loss': 0.41728406846523286} | train loss {'Reaction outcome loss': 0.3461654646383537, 'Total loss': 0.3461654646383537}
2023-01-04 10:29:12,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:12,611 INFO:     Epoch: 45
2023-01-04 10:29:14,203 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42214631537596387, 'Total loss': 0.42214631537596387} | train loss {'Reaction outcome loss': 0.33857622273239024, 'Total loss': 0.33857622273239024}
2023-01-04 10:29:14,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:14,203 INFO:     Epoch: 46
2023-01-04 10:29:15,800 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4469955086708069, 'Total loss': 0.4469955086708069} | train loss {'Reaction outcome loss': 0.3419804403578842, 'Total loss': 0.3419804403578842}
2023-01-04 10:29:15,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:15,800 INFO:     Epoch: 47
2023-01-04 10:29:17,377 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41971409718195596, 'Total loss': 0.41971409718195596} | train loss {'Reaction outcome loss': 0.332205590283696, 'Total loss': 0.332205590283696}
2023-01-04 10:29:17,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:17,377 INFO:     Epoch: 48
2023-01-04 10:29:18,944 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5029269655545553, 'Total loss': 0.5029269655545553} | train loss {'Reaction outcome loss': 0.3307830778397483, 'Total loss': 0.3307830778397483}
2023-01-04 10:29:18,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:18,944 INFO:     Epoch: 49
2023-01-04 10:29:20,489 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4290978570779165, 'Total loss': 0.4290978570779165} | train loss {'Reaction outcome loss': 0.3289629305839102, 'Total loss': 0.3289629305839102}
2023-01-04 10:29:20,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:20,489 INFO:     Epoch: 50
2023-01-04 10:29:22,029 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4194101462761561, 'Total loss': 0.4194101462761561} | train loss {'Reaction outcome loss': 0.33018833090424976, 'Total loss': 0.33018833090424976}
2023-01-04 10:29:22,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:22,029 INFO:     Epoch: 51
2023-01-04 10:29:23,591 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41348964273929595, 'Total loss': 0.41348964273929595} | train loss {'Reaction outcome loss': 0.3291392518214254, 'Total loss': 0.3291392518214254}
2023-01-04 10:29:23,592 INFO:     Found new best model at epoch 51
2023-01-04 10:29:23,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:23,593 INFO:     Epoch: 52
2023-01-04 10:29:25,160 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4563404659430186, 'Total loss': 0.4563404659430186} | train loss {'Reaction outcome loss': 0.3234570951306776, 'Total loss': 0.3234570951306776}
2023-01-04 10:29:25,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:25,161 INFO:     Epoch: 53
2023-01-04 10:29:26,725 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40298264970382053, 'Total loss': 0.40298264970382053} | train loss {'Reaction outcome loss': 0.32533353324229025, 'Total loss': 0.32533353324229025}
2023-01-04 10:29:26,725 INFO:     Found new best model at epoch 53
2023-01-04 10:29:26,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:26,726 INFO:     Epoch: 54
2023-01-04 10:29:28,302 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3985644519329071, 'Total loss': 0.3985644519329071} | train loss {'Reaction outcome loss': 0.31558372380532623, 'Total loss': 0.31558372380532623}
2023-01-04 10:29:28,302 INFO:     Found new best model at epoch 54
2023-01-04 10:29:28,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:28,303 INFO:     Epoch: 55
2023-01-04 10:29:29,823 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4601970911026001, 'Total loss': 0.4601970911026001} | train loss {'Reaction outcome loss': 0.316394621690551, 'Total loss': 0.316394621690551}
2023-01-04 10:29:29,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:29,824 INFO:     Epoch: 56
2023-01-04 10:29:31,362 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4346259648601214, 'Total loss': 0.4346259648601214} | train loss {'Reaction outcome loss': 0.31379429039446427, 'Total loss': 0.31379429039446427}
2023-01-04 10:29:31,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:31,363 INFO:     Epoch: 57
2023-01-04 10:29:32,929 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40516835649808247, 'Total loss': 0.40516835649808247} | train loss {'Reaction outcome loss': 0.3181680373492695, 'Total loss': 0.3181680373492695}
2023-01-04 10:29:32,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:32,929 INFO:     Epoch: 58
2023-01-04 10:29:34,483 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42145922978719075, 'Total loss': 0.42145922978719075} | train loss {'Reaction outcome loss': 0.3129498175321481, 'Total loss': 0.3129498175321481}
2023-01-04 10:29:34,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:34,483 INFO:     Epoch: 59
2023-01-04 10:29:36,051 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41166356404622395, 'Total loss': 0.41166356404622395} | train loss {'Reaction outcome loss': 0.304726789531472, 'Total loss': 0.304726789531472}
2023-01-04 10:29:36,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:36,051 INFO:     Epoch: 60
2023-01-04 10:29:37,616 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3993172287940979, 'Total loss': 0.3993172287940979} | train loss {'Reaction outcome loss': 0.3058010010942544, 'Total loss': 0.3058010010942544}
2023-01-04 10:29:37,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:37,616 INFO:     Epoch: 61
2023-01-04 10:29:39,099 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4421772619088491, 'Total loss': 0.4421772619088491} | train loss {'Reaction outcome loss': 0.3019766243713679, 'Total loss': 0.3019766243713679}
2023-01-04 10:29:39,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:39,099 INFO:     Epoch: 62
2023-01-04 10:29:40,657 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4150023698806763, 'Total loss': 0.4150023698806763} | train loss {'Reaction outcome loss': 0.30668777006340553, 'Total loss': 0.30668777006340553}
2023-01-04 10:29:40,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:40,658 INFO:     Epoch: 63
2023-01-04 10:29:42,204 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4225381165742874, 'Total loss': 0.4225381165742874} | train loss {'Reaction outcome loss': 0.30570030482588234, 'Total loss': 0.30570030482588234}
2023-01-04 10:29:42,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:42,205 INFO:     Epoch: 64
2023-01-04 10:29:43,763 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4271529098351797, 'Total loss': 0.4271529098351797} | train loss {'Reaction outcome loss': 0.30083138640328644, 'Total loss': 0.30083138640328644}
2023-01-04 10:29:43,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:43,763 INFO:     Epoch: 65
2023-01-04 10:29:45,330 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4329712003469467, 'Total loss': 0.4329712003469467} | train loss {'Reaction outcome loss': 0.30164212738965457, 'Total loss': 0.30164212738965457}
2023-01-04 10:29:45,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:45,330 INFO:     Epoch: 66
2023-01-04 10:29:46,863 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.400677016377449, 'Total loss': 0.400677016377449} | train loss {'Reaction outcome loss': 0.29551116071450406, 'Total loss': 0.29551116071450406}
2023-01-04 10:29:46,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:46,864 INFO:     Epoch: 67
2023-01-04 10:29:48,374 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3992199758688609, 'Total loss': 0.3992199758688609} | train loss {'Reaction outcome loss': 0.29485716285941366, 'Total loss': 0.29485716285941366}
2023-01-04 10:29:48,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:48,375 INFO:     Epoch: 68
2023-01-04 10:29:49,927 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4091329952081045, 'Total loss': 0.4091329952081045} | train loss {'Reaction outcome loss': 0.2956283057019824, 'Total loss': 0.2956283057019824}
2023-01-04 10:29:49,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:49,927 INFO:     Epoch: 69
2023-01-04 10:29:51,482 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4398747901121775, 'Total loss': 0.4398747901121775} | train loss {'Reaction outcome loss': 0.2947830815182064, 'Total loss': 0.2947830815182064}
2023-01-04 10:29:51,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:51,482 INFO:     Epoch: 70
2023-01-04 10:29:53,037 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43394214709599815, 'Total loss': 0.43394214709599815} | train loss {'Reaction outcome loss': 0.29670929674045504, 'Total loss': 0.29670929674045504}
2023-01-04 10:29:53,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:53,037 INFO:     Epoch: 71
2023-01-04 10:29:54,592 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4226351340611776, 'Total loss': 0.4226351340611776} | train loss {'Reaction outcome loss': 0.29182888581093414, 'Total loss': 0.29182888581093414}
2023-01-04 10:29:54,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:54,593 INFO:     Epoch: 72
2023-01-04 10:29:56,106 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44404831528663635, 'Total loss': 0.44404831528663635} | train loss {'Reaction outcome loss': 0.28851876635745766, 'Total loss': 0.28851876635745766}
2023-01-04 10:29:56,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:56,107 INFO:     Epoch: 73
2023-01-04 10:29:57,625 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40625013212362926, 'Total loss': 0.40625013212362926} | train loss {'Reaction outcome loss': 0.288838376164873, 'Total loss': 0.288838376164873}
2023-01-04 10:29:57,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:57,625 INFO:     Epoch: 74
2023-01-04 10:29:59,195 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3909955307841301, 'Total loss': 0.3909955307841301} | train loss {'Reaction outcome loss': 0.2866772300744559, 'Total loss': 0.2866772300744559}
2023-01-04 10:29:59,196 INFO:     Found new best model at epoch 74
2023-01-04 10:29:59,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:29:59,196 INFO:     Epoch: 75
2023-01-04 10:30:00,761 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42369463890790937, 'Total loss': 0.42369463890790937} | train loss {'Reaction outcome loss': 0.2833088231938226, 'Total loss': 0.2833088231938226}
2023-01-04 10:30:00,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:00,762 INFO:     Epoch: 76
2023-01-04 10:30:02,319 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4501967300971349, 'Total loss': 0.4501967300971349} | train loss {'Reaction outcome loss': 0.28331788970437244, 'Total loss': 0.28331788970437244}
2023-01-04 10:30:02,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:02,320 INFO:     Epoch: 77
2023-01-04 10:30:03,864 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41800412933031716, 'Total loss': 0.41800412933031716} | train loss {'Reaction outcome loss': 0.2827874940339026, 'Total loss': 0.2827874940339026}
2023-01-04 10:30:03,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:03,864 INFO:     Epoch: 78
2023-01-04 10:30:05,369 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4004128997524579, 'Total loss': 0.4004128997524579} | train loss {'Reaction outcome loss': 0.2798417669622016, 'Total loss': 0.2798417669622016}
2023-01-04 10:30:05,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:05,369 INFO:     Epoch: 79
2023-01-04 10:30:06,877 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4272185464700063, 'Total loss': 0.4272185464700063} | train loss {'Reaction outcome loss': 0.27805236354470253, 'Total loss': 0.27805236354470253}
2023-01-04 10:30:06,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:06,877 INFO:     Epoch: 80
2023-01-04 10:30:08,419 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4319341629743576, 'Total loss': 0.4319341629743576} | train loss {'Reaction outcome loss': 0.2790623960382008, 'Total loss': 0.2790623960382008}
2023-01-04 10:30:08,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:08,420 INFO:     Epoch: 81
2023-01-04 10:30:09,959 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4091483513514201, 'Total loss': 0.4091483513514201} | train loss {'Reaction outcome loss': 0.2757149577932262, 'Total loss': 0.2757149577932262}
2023-01-04 10:30:09,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:09,959 INFO:     Epoch: 82
2023-01-04 10:30:11,504 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3963105464975039, 'Total loss': 0.3963105464975039} | train loss {'Reaction outcome loss': 0.2779586811587487, 'Total loss': 0.2779586811587487}
2023-01-04 10:30:11,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:11,504 INFO:     Epoch: 83
2023-01-04 10:30:13,043 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4289751927057902, 'Total loss': 0.4289751927057902} | train loss {'Reaction outcome loss': 0.27664255545962424, 'Total loss': 0.27664255545962424}
2023-01-04 10:30:13,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:13,044 INFO:     Epoch: 84
2023-01-04 10:30:14,567 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43704548974831897, 'Total loss': 0.43704548974831897} | train loss {'Reaction outcome loss': 0.2725124111187545, 'Total loss': 0.2725124111187545}
2023-01-04 10:30:14,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:14,567 INFO:     Epoch: 85
2023-01-04 10:30:16,074 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4187060326337814, 'Total loss': 0.4187060326337814} | train loss {'Reaction outcome loss': 0.27668738760900147, 'Total loss': 0.27668738760900147}
2023-01-04 10:30:16,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:16,074 INFO:     Epoch: 86
2023-01-04 10:30:17,638 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44068378806114195, 'Total loss': 0.44068378806114195} | train loss {'Reaction outcome loss': 0.2723001469295103, 'Total loss': 0.2723001469295103}
2023-01-04 10:30:17,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:17,638 INFO:     Epoch: 87
2023-01-04 10:30:19,210 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4349630792935689, 'Total loss': 0.4349630792935689} | train loss {'Reaction outcome loss': 0.26854481676340974, 'Total loss': 0.26854481676340974}
2023-01-04 10:30:19,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:19,210 INFO:     Epoch: 88
2023-01-04 10:30:20,799 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4143359283606211, 'Total loss': 0.4143359283606211} | train loss {'Reaction outcome loss': 0.269467064622967, 'Total loss': 0.269467064622967}
2023-01-04 10:30:20,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:20,799 INFO:     Epoch: 89
2023-01-04 10:30:22,387 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4199477811654409, 'Total loss': 0.4199477811654409} | train loss {'Reaction outcome loss': 0.26587402263840476, 'Total loss': 0.26587402263840476}
2023-01-04 10:30:22,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:22,387 INFO:     Epoch: 90
2023-01-04 10:30:23,925 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4244200358788172, 'Total loss': 0.4244200358788172} | train loss {'Reaction outcome loss': 0.2697779369769079, 'Total loss': 0.2697779369769079}
2023-01-04 10:30:23,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:23,926 INFO:     Epoch: 91
2023-01-04 10:30:25,459 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4211767087380091, 'Total loss': 0.4211767087380091} | train loss {'Reaction outcome loss': 0.2693659950852831, 'Total loss': 0.2693659950852831}
2023-01-04 10:30:25,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:25,459 INFO:     Epoch: 92
2023-01-04 10:30:27,039 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4537786960601807, 'Total loss': 0.4537786960601807} | train loss {'Reaction outcome loss': 0.26849719922948667, 'Total loss': 0.26849719922948667}
2023-01-04 10:30:27,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:27,040 INFO:     Epoch: 93
2023-01-04 10:30:28,602 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38764564990997313, 'Total loss': 0.38764564990997313} | train loss {'Reaction outcome loss': 0.2661970410455059, 'Total loss': 0.2661970410455059}
2023-01-04 10:30:28,602 INFO:     Found new best model at epoch 93
2023-01-04 10:30:28,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:28,603 INFO:     Epoch: 94
2023-01-04 10:30:30,150 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4232248018185298, 'Total loss': 0.4232248018185298} | train loss {'Reaction outcome loss': 0.26526792007651956, 'Total loss': 0.26526792007651956}
2023-01-04 10:30:30,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:30,151 INFO:     Epoch: 95
2023-01-04 10:30:31,720 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41969204545021055, 'Total loss': 0.41969204545021055} | train loss {'Reaction outcome loss': 0.2657299152005723, 'Total loss': 0.2657299152005723}
2023-01-04 10:30:31,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:31,720 INFO:     Epoch: 96
2023-01-04 10:30:33,244 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4189012298981349, 'Total loss': 0.4189012298981349} | train loss {'Reaction outcome loss': 0.26335604791785333, 'Total loss': 0.26335604791785333}
2023-01-04 10:30:33,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:33,245 INFO:     Epoch: 97
2023-01-04 10:30:34,750 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42263744374116263, 'Total loss': 0.42263744374116263} | train loss {'Reaction outcome loss': 0.26679548842238854, 'Total loss': 0.26679548842238854}
2023-01-04 10:30:34,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:34,750 INFO:     Epoch: 98
2023-01-04 10:30:36,306 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3865789214769999, 'Total loss': 0.3865789214769999} | train loss {'Reaction outcome loss': 0.2652564507810187, 'Total loss': 0.2652564507810187}
2023-01-04 10:30:36,306 INFO:     Found new best model at epoch 98
2023-01-04 10:30:36,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:36,307 INFO:     Epoch: 99
2023-01-04 10:30:37,861 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4227757622798284, 'Total loss': 0.4227757622798284} | train loss {'Reaction outcome loss': 0.2629546917729325, 'Total loss': 0.2629546917729325}
2023-01-04 10:30:37,861 INFO:     Best model found after epoch 99 of 100.
2023-01-04 10:30:37,861 INFO:   Done with stage: TRAINING
2023-01-04 10:30:37,861 INFO:   Starting stage: EVALUATION
2023-01-04 10:30:38,001 INFO:   Done with stage: EVALUATION
2023-01-04 10:30:38,001 INFO:   Leaving out SEQ value Fold_3
2023-01-04 10:30:38,014 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 10:30:38,014 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:30:38,658 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:30:38,658 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:30:38,727 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:30:38,727 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:30:38,727 INFO:     No hyperparam tuning for this model
2023-01-04 10:30:38,727 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:30:38,727 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:30:38,728 INFO:     None feature selector for col prot
2023-01-04 10:30:38,728 INFO:     None feature selector for col prot
2023-01-04 10:30:38,728 INFO:     None feature selector for col prot
2023-01-04 10:30:38,728 INFO:     None feature selector for col chem
2023-01-04 10:30:38,729 INFO:     None feature selector for col chem
2023-01-04 10:30:38,729 INFO:     None feature selector for col chem
2023-01-04 10:30:38,729 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:30:38,729 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:30:38,730 INFO:     Number of params in model 70111
2023-01-04 10:30:38,733 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:30:38,733 INFO:   Starting stage: TRAINING
2023-01-04 10:30:38,777 INFO:     Val loss before train {'Reaction outcome loss': 1.0732630411783854, 'Total loss': 1.0732630411783854}
2023-01-04 10:30:38,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:38,777 INFO:     Epoch: 0
2023-01-04 10:30:40,328 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7508505483468374, 'Total loss': 0.7508505483468374} | train loss {'Reaction outcome loss': 0.8433714646559495, 'Total loss': 0.8433714646559495}
2023-01-04 10:30:40,328 INFO:     Found new best model at epoch 0
2023-01-04 10:30:40,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:40,329 INFO:     Epoch: 1
2023-01-04 10:30:41,828 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6208296914895376, 'Total loss': 0.6208296914895376} | train loss {'Reaction outcome loss': 0.6820464172424414, 'Total loss': 0.6820464172424414}
2023-01-04 10:30:41,828 INFO:     Found new best model at epoch 1
2023-01-04 10:30:41,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:41,829 INFO:     Epoch: 2
2023-01-04 10:30:43,347 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5725153843561809, 'Total loss': 0.5725153843561809} | train loss {'Reaction outcome loss': 0.591173400754457, 'Total loss': 0.591173400754457}
2023-01-04 10:30:43,347 INFO:     Found new best model at epoch 2
2023-01-04 10:30:43,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:43,348 INFO:     Epoch: 3
2023-01-04 10:30:44,896 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5620647231737773, 'Total loss': 0.5620647231737773} | train loss {'Reaction outcome loss': 0.5455350734484501, 'Total loss': 0.5455350734484501}
2023-01-04 10:30:44,896 INFO:     Found new best model at epoch 3
2023-01-04 10:30:44,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:44,897 INFO:     Epoch: 4
2023-01-04 10:30:46,446 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5154343863328298, 'Total loss': 0.5154343863328298} | train loss {'Reaction outcome loss': 0.5204342330222601, 'Total loss': 0.5204342330222601}
2023-01-04 10:30:46,447 INFO:     Found new best model at epoch 4
2023-01-04 10:30:46,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:46,447 INFO:     Epoch: 5
2023-01-04 10:30:47,996 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5187515119711558, 'Total loss': 0.5187515119711558} | train loss {'Reaction outcome loss': 0.5003029330200328, 'Total loss': 0.5003029330200328}
2023-01-04 10:30:47,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:47,996 INFO:     Epoch: 6
2023-01-04 10:30:49,550 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5238920350869497, 'Total loss': 0.5238920350869497} | train loss {'Reaction outcome loss': 0.4917439739236902, 'Total loss': 0.4917439739236902}
2023-01-04 10:30:49,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:49,551 INFO:     Epoch: 7
2023-01-04 10:30:51,094 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49752883315086366, 'Total loss': 0.49752883315086366} | train loss {'Reaction outcome loss': 0.4816479585764609, 'Total loss': 0.4816479585764609}
2023-01-04 10:30:51,094 INFO:     Found new best model at epoch 7
2023-01-04 10:30:51,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:51,095 INFO:     Epoch: 8
2023-01-04 10:30:52,638 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49464233915011085, 'Total loss': 0.49464233915011085} | train loss {'Reaction outcome loss': 0.4722633730251711, 'Total loss': 0.4722633730251711}
2023-01-04 10:30:52,638 INFO:     Found new best model at epoch 8
2023-01-04 10:30:52,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:52,639 INFO:     Epoch: 9
2023-01-04 10:30:54,232 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4686896891643604, 'Total loss': 0.4686896891643604} | train loss {'Reaction outcome loss': 0.4641878079254549, 'Total loss': 0.4641878079254549}
2023-01-04 10:30:54,232 INFO:     Found new best model at epoch 9
2023-01-04 10:30:54,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:54,233 INFO:     Epoch: 10
2023-01-04 10:30:55,827 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47880323727925617, 'Total loss': 0.47880323727925617} | train loss {'Reaction outcome loss': 0.45462766679979505, 'Total loss': 0.45462766679979505}
2023-01-04 10:30:55,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:55,828 INFO:     Epoch: 11
2023-01-04 10:30:57,398 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48680856029192604, 'Total loss': 0.48680856029192604} | train loss {'Reaction outcome loss': 0.4510709377544703, 'Total loss': 0.4510709377544703}
2023-01-04 10:30:57,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:57,398 INFO:     Epoch: 12
2023-01-04 10:30:58,946 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4863896826903025, 'Total loss': 0.4863896826903025} | train loss {'Reaction outcome loss': 0.44636695076039423, 'Total loss': 0.44636695076039423}
2023-01-04 10:30:58,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:30:58,947 INFO:     Epoch: 13
2023-01-04 10:31:00,432 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46423611119389535, 'Total loss': 0.46423611119389535} | train loss {'Reaction outcome loss': 0.44180938544181675, 'Total loss': 0.44180938544181675}
2023-01-04 10:31:00,433 INFO:     Found new best model at epoch 13
2023-01-04 10:31:00,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:00,434 INFO:     Epoch: 14
2023-01-04 10:31:01,992 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49710711439450583, 'Total loss': 0.49710711439450583} | train loss {'Reaction outcome loss': 0.4407977957974423, 'Total loss': 0.4407977957974423}
2023-01-04 10:31:01,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:01,992 INFO:     Epoch: 15
2023-01-04 10:31:03,591 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46964231729507444, 'Total loss': 0.46964231729507444} | train loss {'Reaction outcome loss': 0.4326751798036553, 'Total loss': 0.4326751798036553}
2023-01-04 10:31:03,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:03,591 INFO:     Epoch: 16
2023-01-04 10:31:05,176 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48733075459798175, 'Total loss': 0.48733075459798175} | train loss {'Reaction outcome loss': 0.4292377960005086, 'Total loss': 0.4292377960005086}
2023-01-04 10:31:05,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:05,176 INFO:     Epoch: 17
2023-01-04 10:31:06,758 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45812056263287865, 'Total loss': 0.45812056263287865} | train loss {'Reaction outcome loss': 0.4245511446516592, 'Total loss': 0.4245511446516592}
2023-01-04 10:31:06,759 INFO:     Found new best model at epoch 17
2023-01-04 10:31:06,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:06,760 INFO:     Epoch: 18
2023-01-04 10:31:08,289 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44438540041446684, 'Total loss': 0.44438540041446684} | train loss {'Reaction outcome loss': 0.42229529925973425, 'Total loss': 0.42229529925973425}
2023-01-04 10:31:08,290 INFO:     Found new best model at epoch 18
2023-01-04 10:31:08,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:08,290 INFO:     Epoch: 19
2023-01-04 10:31:09,822 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4633542577425639, 'Total loss': 0.4633542577425639} | train loss {'Reaction outcome loss': 0.4148551834262771, 'Total loss': 0.4148551834262771}
2023-01-04 10:31:09,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:09,822 INFO:     Epoch: 20
2023-01-04 10:31:11,383 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4579979181289673, 'Total loss': 0.4579979181289673} | train loss {'Reaction outcome loss': 0.41688866231031035, 'Total loss': 0.41688866231031035}
2023-01-04 10:31:11,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:11,383 INFO:     Epoch: 21
2023-01-04 10:31:12,945 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46438585023085277, 'Total loss': 0.46438585023085277} | train loss {'Reaction outcome loss': 0.4092261309261287, 'Total loss': 0.4092261309261287}
2023-01-04 10:31:12,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:12,945 INFO:     Epoch: 22
2023-01-04 10:31:14,513 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4338821331659953, 'Total loss': 0.4338821331659953} | train loss {'Reaction outcome loss': 0.40711808352025003, 'Total loss': 0.40711808352025003}
2023-01-04 10:31:14,513 INFO:     Found new best model at epoch 22
2023-01-04 10:31:14,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:14,514 INFO:     Epoch: 23
2023-01-04 10:31:16,075 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4455627779165904, 'Total loss': 0.4455627779165904} | train loss {'Reaction outcome loss': 0.40308525915438437, 'Total loss': 0.40308525915438437}
2023-01-04 10:31:16,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:16,075 INFO:     Epoch: 24
2023-01-04 10:31:17,612 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.444517982006073, 'Total loss': 0.444517982006073} | train loss {'Reaction outcome loss': 0.40088584077554745, 'Total loss': 0.40088584077554745}
2023-01-04 10:31:17,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:17,612 INFO:     Epoch: 25
2023-01-04 10:31:19,155 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4585777699947357, 'Total loss': 0.4585777699947357} | train loss {'Reaction outcome loss': 0.3928990764168156, 'Total loss': 0.3928990764168156}
2023-01-04 10:31:19,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:19,155 INFO:     Epoch: 26
2023-01-04 10:31:20,746 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4435630838076274, 'Total loss': 0.4435630838076274} | train loss {'Reaction outcome loss': 0.3941711872379422, 'Total loss': 0.3941711872379422}
2023-01-04 10:31:20,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:20,747 INFO:     Epoch: 27
2023-01-04 10:31:22,322 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.442017145951589, 'Total loss': 0.442017145951589} | train loss {'Reaction outcome loss': 0.3889246953330634, 'Total loss': 0.3889246953330634}
2023-01-04 10:31:22,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:22,322 INFO:     Epoch: 28
2023-01-04 10:31:23,901 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42920459310213727, 'Total loss': 0.42920459310213727} | train loss {'Reaction outcome loss': 0.384139117986073, 'Total loss': 0.384139117986073}
2023-01-04 10:31:23,901 INFO:     Found new best model at epoch 28
2023-01-04 10:31:23,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:23,902 INFO:     Epoch: 29
2023-01-04 10:31:25,477 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42686980168024696, 'Total loss': 0.42686980168024696} | train loss {'Reaction outcome loss': 0.380644197326713, 'Total loss': 0.380644197326713}
2023-01-04 10:31:25,477 INFO:     Found new best model at epoch 29
2023-01-04 10:31:25,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:25,478 INFO:     Epoch: 30
2023-01-04 10:31:27,015 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45597490966320037, 'Total loss': 0.45597490966320037} | train loss {'Reaction outcome loss': 0.38712832907508143, 'Total loss': 0.38712832907508143}
2023-01-04 10:31:27,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:27,016 INFO:     Epoch: 31
2023-01-04 10:31:28,541 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4280142903327942, 'Total loss': 0.4280142903327942} | train loss {'Reaction outcome loss': 0.3762617338544283, 'Total loss': 0.3762617338544283}
2023-01-04 10:31:28,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:28,541 INFO:     Epoch: 32
2023-01-04 10:31:30,108 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4184732755025228, 'Total loss': 0.4184732755025228} | train loss {'Reaction outcome loss': 0.37326075106640877, 'Total loss': 0.37326075106640877}
2023-01-04 10:31:30,108 INFO:     Found new best model at epoch 32
2023-01-04 10:31:30,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:30,109 INFO:     Epoch: 33
2023-01-04 10:31:31,667 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45088358322779337, 'Total loss': 0.45088358322779337} | train loss {'Reaction outcome loss': 0.36817141316640073, 'Total loss': 0.36817141316640073}
2023-01-04 10:31:31,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:31,669 INFO:     Epoch: 34
2023-01-04 10:31:33,239 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42135908007621764, 'Total loss': 0.42135908007621764} | train loss {'Reaction outcome loss': 0.36371391405771064, 'Total loss': 0.36371391405771064}
2023-01-04 10:31:33,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:33,239 INFO:     Epoch: 35
2023-01-04 10:31:34,807 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4416118661562602, 'Total loss': 0.4416118661562602} | train loss {'Reaction outcome loss': 0.36933996656657136, 'Total loss': 0.36933996656657136}
2023-01-04 10:31:34,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:34,808 INFO:     Epoch: 36
2023-01-04 10:31:36,370 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4301435043414434, 'Total loss': 0.4301435043414434} | train loss {'Reaction outcome loss': 0.3597191567003945, 'Total loss': 0.3597191567003945}
2023-01-04 10:31:36,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:36,370 INFO:     Epoch: 37
2023-01-04 10:31:37,942 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44813057482242585, 'Total loss': 0.44813057482242585} | train loss {'Reaction outcome loss': 0.3584730351418803, 'Total loss': 0.3584730351418803}
2023-01-04 10:31:37,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:37,943 INFO:     Epoch: 38
2023-01-04 10:31:39,553 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4175714592138926, 'Total loss': 0.4175714592138926} | train loss {'Reaction outcome loss': 0.35046173382427664, 'Total loss': 0.35046173382427664}
2023-01-04 10:31:39,554 INFO:     Found new best model at epoch 38
2023-01-04 10:31:39,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:39,554 INFO:     Epoch: 39
2023-01-04 10:31:41,159 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4307165761788686, 'Total loss': 0.4307165761788686} | train loss {'Reaction outcome loss': 0.3489283786970617, 'Total loss': 0.3489283786970617}
2023-01-04 10:31:41,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:41,159 INFO:     Epoch: 40
2023-01-04 10:31:42,767 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45161296129226686, 'Total loss': 0.45161296129226686} | train loss {'Reaction outcome loss': 0.3497146717903815, 'Total loss': 0.3497146717903815}
2023-01-04 10:31:42,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:42,767 INFO:     Epoch: 41
2023-01-04 10:31:44,380 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43225916624069216, 'Total loss': 0.43225916624069216} | train loss {'Reaction outcome loss': 0.34589000373751255, 'Total loss': 0.34589000373751255}
2023-01-04 10:31:44,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:44,380 INFO:     Epoch: 42
2023-01-04 10:31:45,886 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42091686129570005, 'Total loss': 0.42091686129570005} | train loss {'Reaction outcome loss': 0.33956989310272445, 'Total loss': 0.33956989310272445}
2023-01-04 10:31:45,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:45,886 INFO:     Epoch: 43
2023-01-04 10:31:47,472 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43570262789726255, 'Total loss': 0.43570262789726255} | train loss {'Reaction outcome loss': 0.3370720460574269, 'Total loss': 0.3370720460574269}
2023-01-04 10:31:47,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:47,472 INFO:     Epoch: 44
2023-01-04 10:31:49,045 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41469565629959104, 'Total loss': 0.41469565629959104} | train loss {'Reaction outcome loss': 0.33576361193652554, 'Total loss': 0.33576361193652554}
2023-01-04 10:31:49,045 INFO:     Found new best model at epoch 44
2023-01-04 10:31:49,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:49,046 INFO:     Epoch: 45
2023-01-04 10:31:50,631 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42000588526328403, 'Total loss': 0.42000588526328403} | train loss {'Reaction outcome loss': 0.332081312033938, 'Total loss': 0.332081312033938}
2023-01-04 10:31:50,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:50,632 INFO:     Epoch: 46
2023-01-04 10:31:52,201 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44491915702819823, 'Total loss': 0.44491915702819823} | train loss {'Reaction outcome loss': 0.3310743739398626, 'Total loss': 0.3310743739398626}
2023-01-04 10:31:52,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:52,201 INFO:     Epoch: 47
2023-01-04 10:31:53,759 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4251403212547302, 'Total loss': 0.4251403212547302} | train loss {'Reaction outcome loss': 0.32455762601269905, 'Total loss': 0.32455762601269905}
2023-01-04 10:31:53,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:53,760 INFO:     Epoch: 48
2023-01-04 10:31:55,296 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43315394322077433, 'Total loss': 0.43315394322077433} | train loss {'Reaction outcome loss': 0.32345844895302595, 'Total loss': 0.32345844895302595}
2023-01-04 10:31:55,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:55,296 INFO:     Epoch: 49
2023-01-04 10:31:56,892 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4147769590218862, 'Total loss': 0.4147769590218862} | train loss {'Reaction outcome loss': 0.32046988442703916, 'Total loss': 0.32046988442703916}
2023-01-04 10:31:56,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:56,892 INFO:     Epoch: 50
2023-01-04 10:31:58,467 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43830624322096506, 'Total loss': 0.43830624322096506} | train loss {'Reaction outcome loss': 0.31473897080936714, 'Total loss': 0.31473897080936714}
2023-01-04 10:31:58,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:31:58,468 INFO:     Epoch: 51
2023-01-04 10:32:00,052 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42274571061134336, 'Total loss': 0.42274571061134336} | train loss {'Reaction outcome loss': 0.3169429774904426, 'Total loss': 0.3169429774904426}
2023-01-04 10:32:00,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:00,052 INFO:     Epoch: 52
2023-01-04 10:32:01,643 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43582897981007895, 'Total loss': 0.43582897981007895} | train loss {'Reaction outcome loss': 0.31433229055596795, 'Total loss': 0.31433229055596795}
2023-01-04 10:32:01,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:01,644 INFO:     Epoch: 53
2023-01-04 10:32:03,189 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42977615594863894, 'Total loss': 0.42977615594863894} | train loss {'Reaction outcome loss': 0.3126515340291973, 'Total loss': 0.3126515340291973}
2023-01-04 10:32:03,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:03,190 INFO:     Epoch: 54
2023-01-04 10:32:04,743 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.444951472679774, 'Total loss': 0.444951472679774} | train loss {'Reaction outcome loss': 0.30535573876998473, 'Total loss': 0.30535573876998473}
2023-01-04 10:32:04,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:04,743 INFO:     Epoch: 55
2023-01-04 10:32:06,340 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40908659597237906, 'Total loss': 0.40908659597237906} | train loss {'Reaction outcome loss': 0.3023888179998258, 'Total loss': 0.3023888179998258}
2023-01-04 10:32:06,340 INFO:     Found new best model at epoch 55
2023-01-04 10:32:06,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:06,341 INFO:     Epoch: 56
2023-01-04 10:32:07,936 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43017665843168895, 'Total loss': 0.43017665843168895} | train loss {'Reaction outcome loss': 0.30241942667699123, 'Total loss': 0.30241942667699123}
2023-01-04 10:32:07,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:07,936 INFO:     Epoch: 57
2023-01-04 10:32:09,546 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42084111471970875, 'Total loss': 0.42084111471970875} | train loss {'Reaction outcome loss': 0.3003008545482115, 'Total loss': 0.3003008545482115}
2023-01-04 10:32:09,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:09,547 INFO:     Epoch: 58
2023-01-04 10:32:11,150 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40325258175532025, 'Total loss': 0.40325258175532025} | train loss {'Reaction outcome loss': 0.30152826158555, 'Total loss': 0.30152826158555}
2023-01-04 10:32:11,150 INFO:     Found new best model at epoch 58
2023-01-04 10:32:11,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:11,151 INFO:     Epoch: 59
2023-01-04 10:32:12,709 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43582851986090343, 'Total loss': 0.43582851986090343} | train loss {'Reaction outcome loss': 0.2959688024752306, 'Total loss': 0.2959688024752306}
2023-01-04 10:32:12,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:12,709 INFO:     Epoch: 60
2023-01-04 10:32:14,263 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3791047066450119, 'Total loss': 0.3791047066450119} | train loss {'Reaction outcome loss': 0.2952036569491984, 'Total loss': 0.2952036569491984}
2023-01-04 10:32:14,264 INFO:     Found new best model at epoch 60
2023-01-04 10:32:14,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:14,264 INFO:     Epoch: 61
2023-01-04 10:32:15,829 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42654893596967064, 'Total loss': 0.42654893596967064} | train loss {'Reaction outcome loss': 0.2957671302415076, 'Total loss': 0.2957671302415076}
2023-01-04 10:32:15,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:15,830 INFO:     Epoch: 62
2023-01-04 10:32:17,399 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42671046455701195, 'Total loss': 0.42671046455701195} | train loss {'Reaction outcome loss': 0.2875889970105646, 'Total loss': 0.2875889970105646}
2023-01-04 10:32:17,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:17,399 INFO:     Epoch: 63
2023-01-04 10:32:18,969 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45460809071858727, 'Total loss': 0.45460809071858727} | train loss {'Reaction outcome loss': 0.2908681459151782, 'Total loss': 0.2908681459151782}
2023-01-04 10:32:18,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:18,969 INFO:     Epoch: 64
2023-01-04 10:32:20,542 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4441853920618693, 'Total loss': 0.4441853920618693} | train loss {'Reaction outcome loss': 0.2893765386153053, 'Total loss': 0.2893765386153053}
2023-01-04 10:32:20,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:20,543 INFO:     Epoch: 65
2023-01-04 10:32:22,070 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46240247686704, 'Total loss': 0.46240247686704} | train loss {'Reaction outcome loss': 0.2818041226584396, 'Total loss': 0.2818041226584396}
2023-01-04 10:32:22,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:22,071 INFO:     Epoch: 66
2023-01-04 10:32:23,598 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41758069569865863, 'Total loss': 0.41758069569865863} | train loss {'Reaction outcome loss': 0.28367030291712325, 'Total loss': 0.28367030291712325}
2023-01-04 10:32:23,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:23,598 INFO:     Epoch: 67
2023-01-04 10:32:25,175 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4378075102965037, 'Total loss': 0.4378075102965037} | train loss {'Reaction outcome loss': 0.2833888761071495, 'Total loss': 0.2833888761071495}
2023-01-04 10:32:25,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:25,175 INFO:     Epoch: 68
2023-01-04 10:32:26,743 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4069381058216095, 'Total loss': 0.4069381058216095} | train loss {'Reaction outcome loss': 0.2837975632822339, 'Total loss': 0.2837975632822339}
2023-01-04 10:32:26,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:26,744 INFO:     Epoch: 69
2023-01-04 10:32:28,320 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42189596891403197, 'Total loss': 0.42189596891403197} | train loss {'Reaction outcome loss': 0.2792634051497821, 'Total loss': 0.2792634051497821}
2023-01-04 10:32:28,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:28,320 INFO:     Epoch: 70
2023-01-04 10:32:29,892 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4228596796592077, 'Total loss': 0.4228596796592077} | train loss {'Reaction outcome loss': 0.27820181721077736, 'Total loss': 0.27820181721077736}
2023-01-04 10:32:29,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:29,893 INFO:     Epoch: 71
2023-01-04 10:32:31,404 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41667078832785287, 'Total loss': 0.41667078832785287} | train loss {'Reaction outcome loss': 0.27370839514138495, 'Total loss': 0.27370839514138495}
2023-01-04 10:32:31,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:31,404 INFO:     Epoch: 72
2023-01-04 10:32:32,971 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39664144118626915, 'Total loss': 0.39664144118626915} | train loss {'Reaction outcome loss': 0.2745099666327129, 'Total loss': 0.2745099666327129}
2023-01-04 10:32:32,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:32,971 INFO:     Epoch: 73
2023-01-04 10:32:34,512 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4214460730552673, 'Total loss': 0.4214460730552673} | train loss {'Reaction outcome loss': 0.2717699182574593, 'Total loss': 0.2717699182574593}
2023-01-04 10:32:34,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:34,512 INFO:     Epoch: 74
2023-01-04 10:32:36,085 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39949908753236135, 'Total loss': 0.39949908753236135} | train loss {'Reaction outcome loss': 0.27261386817191546, 'Total loss': 0.27261386817191546}
2023-01-04 10:32:36,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:36,085 INFO:     Epoch: 75
2023-01-04 10:32:37,653 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4415943890810013, 'Total loss': 0.4415943890810013} | train loss {'Reaction outcome loss': 0.27460675604041024, 'Total loss': 0.27460675604041024}
2023-01-04 10:32:37,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:37,654 INFO:     Epoch: 76
2023-01-04 10:32:39,201 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41388939023017884, 'Total loss': 0.41388939023017884} | train loss {'Reaction outcome loss': 0.2662081209731189, 'Total loss': 0.2662081209731189}
2023-01-04 10:32:39,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:39,201 INFO:     Epoch: 77
2023-01-04 10:32:40,714 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4113147964080175, 'Total loss': 0.4113147964080175} | train loss {'Reaction outcome loss': 0.27306304015082755, 'Total loss': 0.27306304015082755}
2023-01-04 10:32:40,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:40,714 INFO:     Epoch: 78
2023-01-04 10:32:42,300 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3888801465431849, 'Total loss': 0.3888801465431849} | train loss {'Reaction outcome loss': 0.2693769455829383, 'Total loss': 0.2693769455829383}
2023-01-04 10:32:42,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:42,300 INFO:     Epoch: 79
2023-01-04 10:32:43,870 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4556004449725151, 'Total loss': 0.4556004449725151} | train loss {'Reaction outcome loss': 0.26095634112100463, 'Total loss': 0.26095634112100463}
2023-01-04 10:32:43,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:43,871 INFO:     Epoch: 80
2023-01-04 10:32:45,441 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42212825218836464, 'Total loss': 0.42212825218836464} | train loss {'Reaction outcome loss': 0.26516010874247814, 'Total loss': 0.26516010874247814}
2023-01-04 10:32:45,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:45,441 INFO:     Epoch: 81
2023-01-04 10:32:47,024 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42276179492473603, 'Total loss': 0.42276179492473603} | train loss {'Reaction outcome loss': 0.2638038315847789, 'Total loss': 0.2638038315847789}
2023-01-04 10:32:47,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:47,025 INFO:     Epoch: 82
2023-01-04 10:32:48,563 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42761503756046293, 'Total loss': 0.42761503756046293} | train loss {'Reaction outcome loss': 0.25991327906429984, 'Total loss': 0.25991327906429984}
2023-01-04 10:32:48,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:48,563 INFO:     Epoch: 83
2023-01-04 10:32:50,097 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40014204184214275, 'Total loss': 0.40014204184214275} | train loss {'Reaction outcome loss': 0.2655746924244004, 'Total loss': 0.2655746924244004}
2023-01-04 10:32:50,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:50,097 INFO:     Epoch: 84
2023-01-04 10:32:51,655 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.39914149542649585, 'Total loss': 0.39914149542649585} | train loss {'Reaction outcome loss': 0.2597753812146165, 'Total loss': 0.2597753812146165}
2023-01-04 10:32:51,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:51,656 INFO:     Epoch: 85
2023-01-04 10:32:53,225 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4374841978152593, 'Total loss': 0.4374841978152593} | train loss {'Reaction outcome loss': 0.2560720337152263, 'Total loss': 0.2560720337152263}
2023-01-04 10:32:53,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:53,225 INFO:     Epoch: 86
2023-01-04 10:32:54,804 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4520790070295334, 'Total loss': 0.4520790070295334} | train loss {'Reaction outcome loss': 0.2597656669470417, 'Total loss': 0.2597656669470417}
2023-01-04 10:32:54,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:54,805 INFO:     Epoch: 87
2023-01-04 10:32:56,396 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44611233174800874, 'Total loss': 0.44611233174800874} | train loss {'Reaction outcome loss': 0.2558534507513483, 'Total loss': 0.2558534507513483}
2023-01-04 10:32:56,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:56,397 INFO:     Epoch: 88
2023-01-04 10:32:57,940 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.406655781964461, 'Total loss': 0.406655781964461} | train loss {'Reaction outcome loss': 0.2562310115703733, 'Total loss': 0.2562310115703733}
2023-01-04 10:32:57,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:57,941 INFO:     Epoch: 89
2023-01-04 10:32:59,482 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42230586608250936, 'Total loss': 0.42230586608250936} | train loss {'Reaction outcome loss': 0.25742287553109966, 'Total loss': 0.25742287553109966}
2023-01-04 10:32:59,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:32:59,482 INFO:     Epoch: 90
2023-01-04 10:33:01,044 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43168558478355407, 'Total loss': 0.43168558478355407} | train loss {'Reaction outcome loss': 0.25803120327847345, 'Total loss': 0.25803120327847345}
2023-01-04 10:33:01,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:01,044 INFO:     Epoch: 91
2023-01-04 10:33:02,616 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4187512626250585, 'Total loss': 0.4187512626250585} | train loss {'Reaction outcome loss': 0.25262313402486425, 'Total loss': 0.25262313402486425}
2023-01-04 10:33:02,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:02,616 INFO:     Epoch: 92
2023-01-04 10:33:04,178 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4308725168307622, 'Total loss': 0.4308725168307622} | train loss {'Reaction outcome loss': 0.25391829675643435, 'Total loss': 0.25391829675643435}
2023-01-04 10:33:04,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:04,179 INFO:     Epoch: 93
2023-01-04 10:33:05,751 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3976394683122635, 'Total loss': 0.3976394683122635} | train loss {'Reaction outcome loss': 0.25019424517840255, 'Total loss': 0.25019424517840255}
2023-01-04 10:33:05,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:05,751 INFO:     Epoch: 94
2023-01-04 10:33:07,305 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4017782280842463, 'Total loss': 0.4017782280842463} | train loss {'Reaction outcome loss': 0.24641261298905362, 'Total loss': 0.24641261298905362}
2023-01-04 10:33:07,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:07,305 INFO:     Epoch: 95
2023-01-04 10:33:08,863 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40049138764540354, 'Total loss': 0.40049138764540354} | train loss {'Reaction outcome loss': 0.2547103501105811, 'Total loss': 0.2547103501105811}
2023-01-04 10:33:08,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:08,863 INFO:     Epoch: 96
2023-01-04 10:33:10,437 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4202004045248032, 'Total loss': 0.4202004045248032} | train loss {'Reaction outcome loss': 0.24682722420810344, 'Total loss': 0.24682722420810344}
2023-01-04 10:33:10,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:10,438 INFO:     Epoch: 97
2023-01-04 10:33:12,021 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4314914604028066, 'Total loss': 0.4314914604028066} | train loss {'Reaction outcome loss': 0.2455765020798196, 'Total loss': 0.2455765020798196}
2023-01-04 10:33:12,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:12,022 INFO:     Epoch: 98
2023-01-04 10:33:13,629 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42999715109666187, 'Total loss': 0.42999715109666187} | train loss {'Reaction outcome loss': 0.24592242606031972, 'Total loss': 0.24592242606031972}
2023-01-04 10:33:13,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:13,631 INFO:     Epoch: 99
2023-01-04 10:33:15,223 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43731722235679626, 'Total loss': 0.43731722235679626} | train loss {'Reaction outcome loss': 0.24601419340996517, 'Total loss': 0.24601419340996517}
2023-01-04 10:33:15,223 INFO:     Best model found after epoch 61 of 100.
2023-01-04 10:33:15,224 INFO:   Done with stage: TRAINING
2023-01-04 10:33:15,224 INFO:   Starting stage: EVALUATION
2023-01-04 10:33:15,365 INFO:   Done with stage: EVALUATION
2023-01-04 10:33:15,365 INFO:   Leaving out SEQ value Fold_4
2023-01-04 10:33:15,377 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 10:33:15,378 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:33:16,025 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:33:16,025 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:33:16,094 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:33:16,094 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:33:16,094 INFO:     No hyperparam tuning for this model
2023-01-04 10:33:16,094 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:33:16,094 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:33:16,095 INFO:     None feature selector for col prot
2023-01-04 10:33:16,095 INFO:     None feature selector for col prot
2023-01-04 10:33:16,095 INFO:     None feature selector for col prot
2023-01-04 10:33:16,096 INFO:     None feature selector for col chem
2023-01-04 10:33:16,096 INFO:     None feature selector for col chem
2023-01-04 10:33:16,096 INFO:     None feature selector for col chem
2023-01-04 10:33:16,096 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:33:16,096 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:33:16,097 INFO:     Number of params in model 70111
2023-01-04 10:33:16,100 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:33:16,100 INFO:   Starting stage: TRAINING
2023-01-04 10:33:16,143 INFO:     Val loss before train {'Reaction outcome loss': 0.9472291231155395, 'Total loss': 0.9472291231155395}
2023-01-04 10:33:16,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:16,143 INFO:     Epoch: 0
2023-01-04 10:33:17,706 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7504212101300557, 'Total loss': 0.7504212101300557} | train loss {'Reaction outcome loss': 0.8319323980721874, 'Total loss': 0.8319323980721874}
2023-01-04 10:33:17,707 INFO:     Found new best model at epoch 0
2023-01-04 10:33:17,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:17,707 INFO:     Epoch: 1
2023-01-04 10:33:19,307 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6619202136993408, 'Total loss': 0.6619202136993408} | train loss {'Reaction outcome loss': 0.6688980482842611, 'Total loss': 0.6688980482842611}
2023-01-04 10:33:19,307 INFO:     Found new best model at epoch 1
2023-01-04 10:33:19,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:19,308 INFO:     Epoch: 2
2023-01-04 10:33:20,896 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6183742741743724, 'Total loss': 0.6183742741743724} | train loss {'Reaction outcome loss': 0.5686817455014376, 'Total loss': 0.5686817455014376}
2023-01-04 10:33:20,897 INFO:     Found new best model at epoch 2
2023-01-04 10:33:20,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:20,898 INFO:     Epoch: 3
2023-01-04 10:33:22,502 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.629513128598531, 'Total loss': 0.629513128598531} | train loss {'Reaction outcome loss': 0.5279281052585313, 'Total loss': 0.5279281052585313}
2023-01-04 10:33:22,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:22,502 INFO:     Epoch: 4
2023-01-04 10:33:24,098 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6051461478074391, 'Total loss': 0.6051461478074391} | train loss {'Reaction outcome loss': 0.5059820531557003, 'Total loss': 0.5059820531557003}
2023-01-04 10:33:24,098 INFO:     Found new best model at epoch 4
2023-01-04 10:33:24,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:24,099 INFO:     Epoch: 5
2023-01-04 10:33:25,636 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.607591160138448, 'Total loss': 0.607591160138448} | train loss {'Reaction outcome loss': 0.492603068391833, 'Total loss': 0.492603068391833}
2023-01-04 10:33:25,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:25,637 INFO:     Epoch: 6
2023-01-04 10:33:27,230 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5847153504689534, 'Total loss': 0.5847153504689534} | train loss {'Reaction outcome loss': 0.4837791776066086, 'Total loss': 0.4837791776066086}
2023-01-04 10:33:27,230 INFO:     Found new best model at epoch 6
2023-01-04 10:33:27,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:27,231 INFO:     Epoch: 7
2023-01-04 10:33:28,827 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5723954757054647, 'Total loss': 0.5723954757054647} | train loss {'Reaction outcome loss': 0.47479448040974315, 'Total loss': 0.47479448040974315}
2023-01-04 10:33:28,827 INFO:     Found new best model at epoch 7
2023-01-04 10:33:28,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:28,828 INFO:     Epoch: 8
2023-01-04 10:33:30,399 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5795819779237111, 'Total loss': 0.5795819779237111} | train loss {'Reaction outcome loss': 0.4637045770802576, 'Total loss': 0.4637045770802576}
2023-01-04 10:33:30,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:30,399 INFO:     Epoch: 9
2023-01-04 10:33:31,958 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5740872452656428, 'Total loss': 0.5740872452656428} | train loss {'Reaction outcome loss': 0.4557177485169276, 'Total loss': 0.4557177485169276}
2023-01-04 10:33:31,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:31,958 INFO:     Epoch: 10
2023-01-04 10:33:33,492 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5835497577985128, 'Total loss': 0.5835497577985128} | train loss {'Reaction outcome loss': 0.4525877582921606, 'Total loss': 0.4525877582921606}
2023-01-04 10:33:33,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:33,493 INFO:     Epoch: 11
2023-01-04 10:33:35,004 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5363756497701009, 'Total loss': 0.5363756497701009} | train loss {'Reaction outcome loss': 0.4462797883189405, 'Total loss': 0.4462797883189405}
2023-01-04 10:33:35,004 INFO:     Found new best model at epoch 11
2023-01-04 10:33:35,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:35,005 INFO:     Epoch: 12
2023-01-04 10:33:36,583 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5654213309288025, 'Total loss': 0.5654213309288025} | train loss {'Reaction outcome loss': 0.44002782340175, 'Total loss': 0.44002782340175}
2023-01-04 10:33:36,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:36,583 INFO:     Epoch: 13
2023-01-04 10:33:38,161 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5792047619819641, 'Total loss': 0.5792047619819641} | train loss {'Reaction outcome loss': 0.4411850277422185, 'Total loss': 0.4411850277422185}
2023-01-04 10:33:38,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:38,162 INFO:     Epoch: 14
2023-01-04 10:33:39,748 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5482386887073517, 'Total loss': 0.5482386887073517} | train loss {'Reaction outcome loss': 0.42909037713990617, 'Total loss': 0.42909037713990617}
2023-01-04 10:33:39,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:39,748 INFO:     Epoch: 15
2023-01-04 10:33:41,338 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5341908901929855, 'Total loss': 0.5341908901929855} | train loss {'Reaction outcome loss': 0.42535414411753847, 'Total loss': 0.42535414411753847}
2023-01-04 10:33:41,338 INFO:     Found new best model at epoch 15
2023-01-04 10:33:41,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:41,339 INFO:     Epoch: 16
2023-01-04 10:33:42,887 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5570405105749766, 'Total loss': 0.5570405105749766} | train loss {'Reaction outcome loss': 0.42493476450951106, 'Total loss': 0.42493476450951106}
2023-01-04 10:33:42,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:42,887 INFO:     Epoch: 17
2023-01-04 10:33:44,446 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5226593752702077, 'Total loss': 0.5226593752702077} | train loss {'Reaction outcome loss': 0.4179582373284232, 'Total loss': 0.4179582373284232}
2023-01-04 10:33:44,447 INFO:     Found new best model at epoch 17
2023-01-04 10:33:44,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:44,448 INFO:     Epoch: 18
2023-01-04 10:33:46,039 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5561472555001576, 'Total loss': 0.5561472555001576} | train loss {'Reaction outcome loss': 0.4131802223990604, 'Total loss': 0.4131802223990604}
2023-01-04 10:33:46,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:46,039 INFO:     Epoch: 19
2023-01-04 10:33:47,640 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5649455587069193, 'Total loss': 0.5649455587069193} | train loss {'Reaction outcome loss': 0.4069600848757756, 'Total loss': 0.4069600848757756}
2023-01-04 10:33:47,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:47,640 INFO:     Epoch: 20
2023-01-04 10:33:49,221 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5391185442606609, 'Total loss': 0.5391185442606609} | train loss {'Reaction outcome loss': 0.40617930868208624, 'Total loss': 0.40617930868208624}
2023-01-04 10:33:49,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:49,221 INFO:     Epoch: 21
2023-01-04 10:33:50,799 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5543713251749675, 'Total loss': 0.5543713251749675} | train loss {'Reaction outcome loss': 0.39982593057177745, 'Total loss': 0.39982593057177745}
2023-01-04 10:33:50,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:50,800 INFO:     Epoch: 22
2023-01-04 10:33:52,341 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.526000972588857, 'Total loss': 0.526000972588857} | train loss {'Reaction outcome loss': 0.39685950376155815, 'Total loss': 0.39685950376155815}
2023-01-04 10:33:52,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:52,341 INFO:     Epoch: 23
2023-01-04 10:33:53,888 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.523370643456777, 'Total loss': 0.523370643456777} | train loss {'Reaction outcome loss': 0.3959428944449494, 'Total loss': 0.3959428944449494}
2023-01-04 10:33:53,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:53,889 INFO:     Epoch: 24
2023-01-04 10:33:55,445 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5267482936382294, 'Total loss': 0.5267482936382294} | train loss {'Reaction outcome loss': 0.3970731262023142, 'Total loss': 0.3970731262023142}
2023-01-04 10:33:55,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:55,446 INFO:     Epoch: 25
2023-01-04 10:33:57,013 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.509318059682846, 'Total loss': 0.509318059682846} | train loss {'Reaction outcome loss': 0.3867145275825338, 'Total loss': 0.3867145275825338}
2023-01-04 10:33:57,013 INFO:     Found new best model at epoch 25
2023-01-04 10:33:57,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:57,013 INFO:     Epoch: 26
2023-01-04 10:33:58,588 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5073838452498118, 'Total loss': 0.5073838452498118} | train loss {'Reaction outcome loss': 0.381174631165408, 'Total loss': 0.381174631165408}
2023-01-04 10:33:58,588 INFO:     Found new best model at epoch 26
2023-01-04 10:33:58,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:33:58,589 INFO:     Epoch: 27
2023-01-04 10:34:00,159 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5098866681257884, 'Total loss': 0.5098866681257884} | train loss {'Reaction outcome loss': 0.3807348791945159, 'Total loss': 0.3807348791945159}
2023-01-04 10:34:00,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:00,159 INFO:     Epoch: 28
2023-01-04 10:34:01,699 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5843159725268682, 'Total loss': 0.5843159725268682} | train loss {'Reaction outcome loss': 0.3786773132700203, 'Total loss': 0.3786773132700203}
2023-01-04 10:34:01,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:01,700 INFO:     Epoch: 29
2023-01-04 10:34:03,230 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5245262145996094, 'Total loss': 0.5245262145996094} | train loss {'Reaction outcome loss': 0.37570005961005454, 'Total loss': 0.37570005961005454}
2023-01-04 10:34:03,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:03,231 INFO:     Epoch: 30
2023-01-04 10:34:04,802 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5345062504212061, 'Total loss': 0.5345062504212061} | train loss {'Reaction outcome loss': 0.3739163614809513, 'Total loss': 0.3739163614809513}
2023-01-04 10:34:04,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:04,802 INFO:     Epoch: 31
2023-01-04 10:34:06,400 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5025634904702504, 'Total loss': 0.5025634904702504} | train loss {'Reaction outcome loss': 0.378187982365489, 'Total loss': 0.378187982365489}
2023-01-04 10:34:06,401 INFO:     Found new best model at epoch 31
2023-01-04 10:34:06,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:06,401 INFO:     Epoch: 32
2023-01-04 10:34:07,981 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5102640589078268, 'Total loss': 0.5102640589078268} | train loss {'Reaction outcome loss': 0.37625431911884877, 'Total loss': 0.37625431911884877}
2023-01-04 10:34:07,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:07,981 INFO:     Epoch: 33
2023-01-04 10:34:09,561 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49418137868245443, 'Total loss': 0.49418137868245443} | train loss {'Reaction outcome loss': 0.36783287123493524, 'Total loss': 0.36783287123493524}
2023-01-04 10:34:09,561 INFO:     Found new best model at epoch 33
2023-01-04 10:34:09,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:09,562 INFO:     Epoch: 34
2023-01-04 10:34:11,087 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5173628747463226, 'Total loss': 0.5173628747463226} | train loss {'Reaction outcome loss': 0.3599056289379444, 'Total loss': 0.3599056289379444}
2023-01-04 10:34:11,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:11,087 INFO:     Epoch: 35
2023-01-04 10:34:12,654 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.530700969696045, 'Total loss': 0.530700969696045} | train loss {'Reaction outcome loss': 0.3547179678706121, 'Total loss': 0.3547179678706121}
2023-01-04 10:34:12,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:12,654 INFO:     Epoch: 36
2023-01-04 10:34:14,220 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5211665987968445, 'Total loss': 0.5211665987968445} | train loss {'Reaction outcome loss': 0.3558285788875883, 'Total loss': 0.3558285788875883}
2023-01-04 10:34:14,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:14,220 INFO:     Epoch: 37
2023-01-04 10:34:15,798 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5108331819375356, 'Total loss': 0.5108331819375356} | train loss {'Reaction outcome loss': 0.34969418636941607, 'Total loss': 0.34969418636941607}
2023-01-04 10:34:15,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:15,799 INFO:     Epoch: 38
2023-01-04 10:34:17,368 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4995816687742869, 'Total loss': 0.4995816687742869} | train loss {'Reaction outcome loss': 0.34810252417472826, 'Total loss': 0.34810252417472826}
2023-01-04 10:34:17,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:17,368 INFO:     Epoch: 39
2023-01-04 10:34:18,925 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5328558365503947, 'Total loss': 0.5328558365503947} | train loss {'Reaction outcome loss': 0.3505557412146658, 'Total loss': 0.3505557412146658}
2023-01-04 10:34:18,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:18,926 INFO:     Epoch: 40
2023-01-04 10:34:20,468 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5360472699006399, 'Total loss': 0.5360472699006399} | train loss {'Reaction outcome loss': 0.3462904937863957, 'Total loss': 0.3462904937863957}
2023-01-04 10:34:20,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:20,468 INFO:     Epoch: 41
2023-01-04 10:34:22,040 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5332340260346731, 'Total loss': 0.5332340260346731} | train loss {'Reaction outcome loss': 0.34234434511998424, 'Total loss': 0.34234434511998424}
2023-01-04 10:34:22,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:22,041 INFO:     Epoch: 42
2023-01-04 10:34:23,601 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5597871343294779, 'Total loss': 0.5597871343294779} | train loss {'Reaction outcome loss': 0.35979069763983507, 'Total loss': 0.35979069763983507}
2023-01-04 10:34:23,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:23,601 INFO:     Epoch: 43
2023-01-04 10:34:25,145 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5105668465296428, 'Total loss': 0.5105668465296428} | train loss {'Reaction outcome loss': 0.3598055718601614, 'Total loss': 0.3598055718601614}
2023-01-04 10:34:25,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:25,145 INFO:     Epoch: 44
2023-01-04 10:34:26,723 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5167415996392568, 'Total loss': 0.5167415996392568} | train loss {'Reaction outcome loss': 0.33669802371034585, 'Total loss': 0.33669802371034585}
2023-01-04 10:34:26,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:26,724 INFO:     Epoch: 45
2023-01-04 10:34:28,252 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5197128196557362, 'Total loss': 0.5197128196557362} | train loss {'Reaction outcome loss': 0.3323746224514384, 'Total loss': 0.3323746224514384}
2023-01-04 10:34:28,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:28,253 INFO:     Epoch: 46
2023-01-04 10:34:29,761 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5069932500521342, 'Total loss': 0.5069932500521342} | train loss {'Reaction outcome loss': 0.33502876998829667, 'Total loss': 0.33502876998829667}
2023-01-04 10:34:29,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:29,762 INFO:     Epoch: 47
2023-01-04 10:34:31,313 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5127058506011963, 'Total loss': 0.5127058506011963} | train loss {'Reaction outcome loss': 0.3440803499669646, 'Total loss': 0.3440803499669646}
2023-01-04 10:34:31,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:31,313 INFO:     Epoch: 48
2023-01-04 10:34:32,871 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5011448035637538, 'Total loss': 0.5011448035637538} | train loss {'Reaction outcome loss': 0.3275564038127229, 'Total loss': 0.3275564038127229}
2023-01-04 10:34:32,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:32,871 INFO:     Epoch: 49
2023-01-04 10:34:34,422 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5099510908126831, 'Total loss': 0.5099510908126831} | train loss {'Reaction outcome loss': 0.3365725630057463, 'Total loss': 0.3365725630057463}
2023-01-04 10:34:34,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:34,423 INFO:     Epoch: 50
2023-01-04 10:34:35,987 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5018027643362681, 'Total loss': 0.5018027643362681} | train loss {'Reaction outcome loss': 0.33268642641495966, 'Total loss': 0.33268642641495966}
2023-01-04 10:34:35,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:35,987 INFO:     Epoch: 51
2023-01-04 10:34:37,551 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4905111382404963, 'Total loss': 0.4905111382404963} | train loss {'Reaction outcome loss': 0.32227465489616053, 'Total loss': 0.32227465489616053}
2023-01-04 10:34:37,552 INFO:     Found new best model at epoch 51
2023-01-04 10:34:37,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:37,552 INFO:     Epoch: 52
2023-01-04 10:34:39,125 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5111099163691203, 'Total loss': 0.5111099163691203} | train loss {'Reaction outcome loss': 0.3201095063671254, 'Total loss': 0.3201095063671254}
2023-01-04 10:34:39,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:39,125 INFO:     Epoch: 53
2023-01-04 10:34:40,749 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5187292834122975, 'Total loss': 0.5187292834122975} | train loss {'Reaction outcome loss': 0.3170324094539535, 'Total loss': 0.3170324094539535}
2023-01-04 10:34:40,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:40,750 INFO:     Epoch: 54
2023-01-04 10:34:42,369 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5026066641012827, 'Total loss': 0.5026066641012827} | train loss {'Reaction outcome loss': 0.3193171601202609, 'Total loss': 0.3193171601202609}
2023-01-04 10:34:42,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:42,369 INFO:     Epoch: 55
2023-01-04 10:34:43,983 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5175230165322622, 'Total loss': 0.5175230165322622} | train loss {'Reaction outcome loss': 0.3235516714107623, 'Total loss': 0.3235516714107623}
2023-01-04 10:34:43,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:43,983 INFO:     Epoch: 56
2023-01-04 10:34:45,574 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4867057869831721, 'Total loss': 0.4867057869831721} | train loss {'Reaction outcome loss': 0.3144545478349307, 'Total loss': 0.3144545478349307}
2023-01-04 10:34:45,574 INFO:     Found new best model at epoch 56
2023-01-04 10:34:45,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:45,575 INFO:     Epoch: 57
2023-01-04 10:34:47,135 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5422550002733867, 'Total loss': 0.5422550002733867} | train loss {'Reaction outcome loss': 0.3093252753663272, 'Total loss': 0.3093252753663272}
2023-01-04 10:34:47,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:47,135 INFO:     Epoch: 58
2023-01-04 10:34:48,694 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5487434148788453, 'Total loss': 0.5487434148788453} | train loss {'Reaction outcome loss': 0.31380172998246236, 'Total loss': 0.31380172998246236}
2023-01-04 10:34:48,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:48,694 INFO:     Epoch: 59
2023-01-04 10:34:50,326 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.50972700715065, 'Total loss': 0.50972700715065} | train loss {'Reaction outcome loss': 0.30696688985209103, 'Total loss': 0.30696688985209103}
2023-01-04 10:34:50,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:50,326 INFO:     Epoch: 60
2023-01-04 10:34:51,940 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5298984189828236, 'Total loss': 0.5298984189828236} | train loss {'Reaction outcome loss': 0.3045350276676101, 'Total loss': 0.3045350276676101}
2023-01-04 10:34:51,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:51,941 INFO:     Epoch: 61
2023-01-04 10:34:53,552 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49141700367132823, 'Total loss': 0.49141700367132823} | train loss {'Reaction outcome loss': 0.29982356469865434, 'Total loss': 0.29982356469865434}
2023-01-04 10:34:53,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:53,552 INFO:     Epoch: 62
2023-01-04 10:34:55,156 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5118904173374176, 'Total loss': 0.5118904173374176} | train loss {'Reaction outcome loss': 0.3017836648808873, 'Total loss': 0.3017836648808873}
2023-01-04 10:34:55,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:55,156 INFO:     Epoch: 63
2023-01-04 10:34:56,694 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4990438103675842, 'Total loss': 0.4990438103675842} | train loss {'Reaction outcome loss': 0.3099842589834462, 'Total loss': 0.3099842589834462}
2023-01-04 10:34:56,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:56,694 INFO:     Epoch: 64
2023-01-04 10:34:58,269 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.521986985206604, 'Total loss': 0.521986985206604} | train loss {'Reaction outcome loss': 0.3048650093808554, 'Total loss': 0.3048650093808554}
2023-01-04 10:34:58,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:58,270 INFO:     Epoch: 65
2023-01-04 10:34:59,840 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5730867505073547, 'Total loss': 0.5730867505073547} | train loss {'Reaction outcome loss': 0.323115976959251, 'Total loss': 0.323115976959251}
2023-01-04 10:34:59,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:34:59,840 INFO:     Epoch: 66
2023-01-04 10:35:01,399 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5109564363956451, 'Total loss': 0.5109564363956451} | train loss {'Reaction outcome loss': 0.3276752158375187, 'Total loss': 0.3276752158375187}
2023-01-04 10:35:01,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:01,399 INFO:     Epoch: 67
2023-01-04 10:35:02,944 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5242924571037293, 'Total loss': 0.5242924571037293} | train loss {'Reaction outcome loss': 0.31079802494766057, 'Total loss': 0.31079802494766057}
2023-01-04 10:35:02,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:02,944 INFO:     Epoch: 68
2023-01-04 10:35:04,469 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5526984751224517, 'Total loss': 0.5526984751224517} | train loss {'Reaction outcome loss': 0.30217497126347775, 'Total loss': 0.30217497126347775}
2023-01-04 10:35:04,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:04,469 INFO:     Epoch: 69
2023-01-04 10:35:06,005 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5079926788806916, 'Total loss': 0.5079926788806916} | train loss {'Reaction outcome loss': 0.29402839676797576, 'Total loss': 0.29402839676797576}
2023-01-04 10:35:06,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:06,006 INFO:     Epoch: 70
2023-01-04 10:35:07,584 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5106325427691142, 'Total loss': 0.5106325427691142} | train loss {'Reaction outcome loss': 0.28893622952602815, 'Total loss': 0.28893622952602815}
2023-01-04 10:35:07,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:07,584 INFO:     Epoch: 71
2023-01-04 10:35:09,169 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5254663407802582, 'Total loss': 0.5254663407802582} | train loss {'Reaction outcome loss': 0.2935345977868723, 'Total loss': 0.2935345977868723}
2023-01-04 10:35:09,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:09,170 INFO:     Epoch: 72
2023-01-04 10:35:10,756 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49635134637355804, 'Total loss': 0.49635134637355804} | train loss {'Reaction outcome loss': 0.3068881416828304, 'Total loss': 0.3068881416828304}
2023-01-04 10:35:10,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:10,757 INFO:     Epoch: 73
2023-01-04 10:35:12,314 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4998698800802231, 'Total loss': 0.4998698800802231} | train loss {'Reaction outcome loss': 0.3078597023732204, 'Total loss': 0.3078597023732204}
2023-01-04 10:35:12,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:12,315 INFO:     Epoch: 74
2023-01-04 10:35:13,856 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49961881736914315, 'Total loss': 0.49961881736914315} | train loss {'Reaction outcome loss': 0.2872038691075168, 'Total loss': 0.2872038691075168}
2023-01-04 10:35:13,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:13,857 INFO:     Epoch: 75
2023-01-04 10:35:15,405 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4884139875570933, 'Total loss': 0.4884139875570933} | train loss {'Reaction outcome loss': 0.2857506686511139, 'Total loss': 0.2857506686511139}
2023-01-04 10:35:15,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:15,405 INFO:     Epoch: 76
2023-01-04 10:35:16,980 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5134045720100403, 'Total loss': 0.5134045720100403} | train loss {'Reaction outcome loss': 0.28243465747927193, 'Total loss': 0.28243465747927193}
2023-01-04 10:35:16,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:16,980 INFO:     Epoch: 77
2023-01-04 10:35:18,551 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5123484611511231, 'Total loss': 0.5123484611511231} | train loss {'Reaction outcome loss': 0.28503723755019944, 'Total loss': 0.28503723755019944}
2023-01-04 10:35:18,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:18,551 INFO:     Epoch: 78
2023-01-04 10:35:20,116 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4816200822591782, 'Total loss': 0.4816200822591782} | train loss {'Reaction outcome loss': 0.2816459236690181, 'Total loss': 0.2816459236690181}
2023-01-04 10:35:20,116 INFO:     Found new best model at epoch 78
2023-01-04 10:35:20,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:20,116 INFO:     Epoch: 79
2023-01-04 10:35:21,695 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5107062518596649, 'Total loss': 0.5107062518596649} | train loss {'Reaction outcome loss': 0.2809662759958672, 'Total loss': 0.2809662759958672}
2023-01-04 10:35:21,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:21,695 INFO:     Epoch: 80
2023-01-04 10:35:23,246 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5013658086458842, 'Total loss': 0.5013658086458842} | train loss {'Reaction outcome loss': 0.28743397849409474, 'Total loss': 0.28743397849409474}
2023-01-04 10:35:23,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:23,247 INFO:     Epoch: 81
2023-01-04 10:35:24,803 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5099481701850891, 'Total loss': 0.5099481701850891} | train loss {'Reaction outcome loss': 0.32205019410753594, 'Total loss': 0.32205019410753594}
2023-01-04 10:35:24,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:24,803 INFO:     Epoch: 82
2023-01-04 10:35:26,388 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49540401697158815, 'Total loss': 0.49540401697158815} | train loss {'Reaction outcome loss': 0.3189532852637163, 'Total loss': 0.3189532852637163}
2023-01-04 10:35:26,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:26,389 INFO:     Epoch: 83
2023-01-04 10:35:27,985 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49316441814104717, 'Total loss': 0.49316441814104717} | train loss {'Reaction outcome loss': 0.31909611788612735, 'Total loss': 0.31909611788612735}
2023-01-04 10:35:27,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:27,986 INFO:     Epoch: 84
2023-01-04 10:35:29,551 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5229216585556666, 'Total loss': 0.5229216585556666} | train loss {'Reaction outcome loss': 0.2947254873174445, 'Total loss': 0.2947254873174445}
2023-01-04 10:35:29,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:29,551 INFO:     Epoch: 85
2023-01-04 10:35:31,137 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.511370321114858, 'Total loss': 0.511370321114858} | train loss {'Reaction outcome loss': 0.2893164296955468, 'Total loss': 0.2893164296955468}
2023-01-04 10:35:31,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:31,137 INFO:     Epoch: 86
2023-01-04 10:35:32,669 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5185848216215769, 'Total loss': 0.5185848216215769} | train loss {'Reaction outcome loss': 0.2881768727227978, 'Total loss': 0.2881768727227978}
2023-01-04 10:35:32,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:32,669 INFO:     Epoch: 87
2023-01-04 10:35:34,177 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5085830350716909, 'Total loss': 0.5085830350716909} | train loss {'Reaction outcome loss': 0.2868655576114205, 'Total loss': 0.2868655576114205}
2023-01-04 10:35:34,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:34,178 INFO:     Epoch: 88
2023-01-04 10:35:35,739 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.523056815067927, 'Total loss': 0.523056815067927} | train loss {'Reaction outcome loss': 0.2870472223308963, 'Total loss': 0.2870472223308963}
2023-01-04 10:35:35,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:35,739 INFO:     Epoch: 89
2023-01-04 10:35:37,307 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5035117149353028, 'Total loss': 0.5035117149353028} | train loss {'Reaction outcome loss': 0.28056919587222673, 'Total loss': 0.28056919587222673}
2023-01-04 10:35:37,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:37,307 INFO:     Epoch: 90
2023-01-04 10:35:38,870 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5025559802850087, 'Total loss': 0.5025559802850087} | train loss {'Reaction outcome loss': 0.28213984039029205, 'Total loss': 0.28213984039029205}
2023-01-04 10:35:38,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:38,870 INFO:     Epoch: 91
2023-01-04 10:35:40,433 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4997596601645152, 'Total loss': 0.4997596601645152} | train loss {'Reaction outcome loss': 0.27741649372699717, 'Total loss': 0.27741649372699717}
2023-01-04 10:35:40,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:40,433 INFO:     Epoch: 92
2023-01-04 10:35:41,960 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5040148963530858, 'Total loss': 0.5040148963530858} | train loss {'Reaction outcome loss': 0.28498342656193004, 'Total loss': 0.28498342656193004}
2023-01-04 10:35:41,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:41,960 INFO:     Epoch: 93
2023-01-04 10:35:43,518 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5524280240138372, 'Total loss': 0.5524280240138372} | train loss {'Reaction outcome loss': 0.316042334003293, 'Total loss': 0.316042334003293}
2023-01-04 10:35:43,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:43,519 INFO:     Epoch: 94
2023-01-04 10:35:45,062 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5105337460835775, 'Total loss': 0.5105337460835775} | train loss {'Reaction outcome loss': 0.2808395721342253, 'Total loss': 0.2808395721342253}
2023-01-04 10:35:45,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:45,062 INFO:     Epoch: 95
2023-01-04 10:35:46,632 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5018829862276714, 'Total loss': 0.5018829862276714} | train loss {'Reaction outcome loss': 0.2749095604471538, 'Total loss': 0.2749095604471538}
2023-01-04 10:35:46,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:46,632 INFO:     Epoch: 96
2023-01-04 10:35:48,199 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5006162007649739, 'Total loss': 0.5006162007649739} | train loss {'Reaction outcome loss': 0.27984300861135125, 'Total loss': 0.27984300861135125}
2023-01-04 10:35:48,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:48,199 INFO:     Epoch: 97
2023-01-04 10:35:49,723 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5010876029729843, 'Total loss': 0.5010876029729843} | train loss {'Reaction outcome loss': 0.2710673124031704, 'Total loss': 0.2710673124031704}
2023-01-04 10:35:49,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:49,723 INFO:     Epoch: 98
2023-01-04 10:35:51,261 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5013092597325642, 'Total loss': 0.5013092597325642} | train loss {'Reaction outcome loss': 0.2708452905838688, 'Total loss': 0.2708452905838688}
2023-01-04 10:35:51,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:51,261 INFO:     Epoch: 99
2023-01-04 10:35:52,830 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49816548228263857, 'Total loss': 0.49816548228263857} | train loss {'Reaction outcome loss': 0.27884487904932187, 'Total loss': 0.27884487904932187}
2023-01-04 10:35:52,830 INFO:     Best model found after epoch 79 of 100.
2023-01-04 10:35:52,830 INFO:   Done with stage: TRAINING
2023-01-04 10:35:52,830 INFO:   Starting stage: EVALUATION
2023-01-04 10:35:52,958 INFO:   Done with stage: EVALUATION
2023-01-04 10:35:52,958 INFO:   Leaving out SEQ value Fold_5
2023-01-04 10:35:52,970 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 10:35:52,970 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:35:53,621 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:35:53,621 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:35:53,688 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:35:53,688 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:35:53,688 INFO:     No hyperparam tuning for this model
2023-01-04 10:35:53,688 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:35:53,688 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:35:53,689 INFO:     None feature selector for col prot
2023-01-04 10:35:53,689 INFO:     None feature selector for col prot
2023-01-04 10:35:53,689 INFO:     None feature selector for col prot
2023-01-04 10:35:53,690 INFO:     None feature selector for col chem
2023-01-04 10:35:53,690 INFO:     None feature selector for col chem
2023-01-04 10:35:53,690 INFO:     None feature selector for col chem
2023-01-04 10:35:53,690 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:35:53,690 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:35:53,691 INFO:     Number of params in model 70111
2023-01-04 10:35:53,694 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:35:53,694 INFO:   Starting stage: TRAINING
2023-01-04 10:35:53,737 INFO:     Val loss before train {'Reaction outcome loss': 1.0406042297681173, 'Total loss': 1.0406042297681173}
2023-01-04 10:35:53,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:53,737 INFO:     Epoch: 0
2023-01-04 10:35:55,305 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7084710041681925, 'Total loss': 0.7084710041681925} | train loss {'Reaction outcome loss': 0.8368996051342591, 'Total loss': 0.8368996051342591}
2023-01-04 10:35:55,305 INFO:     Found new best model at epoch 0
2023-01-04 10:35:55,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:55,306 INFO:     Epoch: 1
2023-01-04 10:35:56,877 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5653232594331106, 'Total loss': 0.5653232594331106} | train loss {'Reaction outcome loss': 0.6841711566608021, 'Total loss': 0.6841711566608021}
2023-01-04 10:35:56,878 INFO:     Found new best model at epoch 1
2023-01-04 10:35:56,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:56,878 INFO:     Epoch: 2
2023-01-04 10:35:58,416 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6169230779012044, 'Total loss': 0.6169230779012044} | train loss {'Reaction outcome loss': 0.580992250446824, 'Total loss': 0.580992250446824}
2023-01-04 10:35:58,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:58,416 INFO:     Epoch: 3
2023-01-04 10:35:59,975 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5572898864746094, 'Total loss': 0.5572898864746094} | train loss {'Reaction outcome loss': 0.543066729777965, 'Total loss': 0.543066729777965}
2023-01-04 10:35:59,975 INFO:     Found new best model at epoch 3
2023-01-04 10:35:59,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:35:59,976 INFO:     Epoch: 4
2023-01-04 10:36:01,544 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5235136806964874, 'Total loss': 0.5235136806964874} | train loss {'Reaction outcome loss': 0.5138106486773577, 'Total loss': 0.5138106486773577}
2023-01-04 10:36:01,544 INFO:     Found new best model at epoch 4
2023-01-04 10:36:01,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:01,545 INFO:     Epoch: 5
2023-01-04 10:36:03,108 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4800017019112905, 'Total loss': 0.4800017019112905} | train loss {'Reaction outcome loss': 0.5038142785753893, 'Total loss': 0.5038142785753893}
2023-01-04 10:36:03,109 INFO:     Found new best model at epoch 5
2023-01-04 10:36:03,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:03,110 INFO:     Epoch: 6
2023-01-04 10:36:04,695 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4998632629712423, 'Total loss': 0.4998632629712423} | train loss {'Reaction outcome loss': 0.49481565563052055, 'Total loss': 0.49481565563052055}
2023-01-04 10:36:04,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:04,695 INFO:     Epoch: 7
2023-01-04 10:36:06,269 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4739069183667501, 'Total loss': 0.4739069183667501} | train loss {'Reaction outcome loss': 0.496580440281094, 'Total loss': 0.496580440281094}
2023-01-04 10:36:06,269 INFO:     Found new best model at epoch 7
2023-01-04 10:36:06,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:06,269 INFO:     Epoch: 8
2023-01-04 10:36:07,810 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45938503245512646, 'Total loss': 0.45938503245512646} | train loss {'Reaction outcome loss': 0.48496998995002627, 'Total loss': 0.48496998995002627}
2023-01-04 10:36:07,810 INFO:     Found new best model at epoch 8
2023-01-04 10:36:07,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:07,811 INFO:     Epoch: 9
2023-01-04 10:36:09,336 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45294780532519024, 'Total loss': 0.45294780532519024} | train loss {'Reaction outcome loss': 0.468374360460734, 'Total loss': 0.468374360460734}
2023-01-04 10:36:09,337 INFO:     Found new best model at epoch 9
2023-01-04 10:36:09,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:09,338 INFO:     Epoch: 10
2023-01-04 10:36:10,912 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4342606763044993, 'Total loss': 0.4342606763044993} | train loss {'Reaction outcome loss': 0.461421327888538, 'Total loss': 0.461421327888538}
2023-01-04 10:36:10,912 INFO:     Found new best model at epoch 10
2023-01-04 10:36:10,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:10,913 INFO:     Epoch: 11
2023-01-04 10:36:12,488 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49318478504816693, 'Total loss': 0.49318478504816693} | train loss {'Reaction outcome loss': 0.455302099764779, 'Total loss': 0.455302099764779}
2023-01-04 10:36:12,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:12,488 INFO:     Epoch: 12
2023-01-04 10:36:14,046 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4410258571306864, 'Total loss': 0.4410258571306864} | train loss {'Reaction outcome loss': 0.4551285742953938, 'Total loss': 0.4551285742953938}
2023-01-04 10:36:14,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:14,046 INFO:     Epoch: 13
2023-01-04 10:36:15,624 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42926015655199684, 'Total loss': 0.42926015655199684} | train loss {'Reaction outcome loss': 0.44290010976618616, 'Total loss': 0.44290010976618616}
2023-01-04 10:36:15,624 INFO:     Found new best model at epoch 13
2023-01-04 10:36:15,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:15,625 INFO:     Epoch: 14
2023-01-04 10:36:17,164 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47705304821332295, 'Total loss': 0.47705304821332295} | train loss {'Reaction outcome loss': 0.4430116934539831, 'Total loss': 0.4430116934539831}
2023-01-04 10:36:17,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:17,165 INFO:     Epoch: 15
2023-01-04 10:36:18,690 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4212481101353963, 'Total loss': 0.4212481101353963} | train loss {'Reaction outcome loss': 0.43107154904662265, 'Total loss': 0.43107154904662265}
2023-01-04 10:36:18,690 INFO:     Found new best model at epoch 15
2023-01-04 10:36:18,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:18,691 INFO:     Epoch: 16
2023-01-04 10:36:20,297 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4320851723353068, 'Total loss': 0.4320851723353068} | train loss {'Reaction outcome loss': 0.4257426191985175, 'Total loss': 0.4257426191985175}
2023-01-04 10:36:20,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:20,297 INFO:     Epoch: 17
2023-01-04 10:36:21,875 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43985874752203624, 'Total loss': 0.43985874752203624} | train loss {'Reaction outcome loss': 0.4280435174249747, 'Total loss': 0.4280435174249747}
2023-01-04 10:36:21,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:21,876 INFO:     Epoch: 18
2023-01-04 10:36:23,482 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4627537171045939, 'Total loss': 0.4627537171045939} | train loss {'Reaction outcome loss': 0.43559384389200073, 'Total loss': 0.43559384389200073}
2023-01-04 10:36:23,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:23,482 INFO:     Epoch: 19
2023-01-04 10:36:25,079 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4312421182791392, 'Total loss': 0.4312421182791392} | train loss {'Reaction outcome loss': 0.43830602639354765, 'Total loss': 0.43830602639354765}
2023-01-04 10:36:25,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:25,080 INFO:     Epoch: 20
2023-01-04 10:36:26,626 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4357757886250814, 'Total loss': 0.4357757886250814} | train loss {'Reaction outcome loss': 0.4130617918284691, 'Total loss': 0.4130617918284691}
2023-01-04 10:36:26,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:26,626 INFO:     Epoch: 21
2023-01-04 10:36:28,170 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4104314347108205, 'Total loss': 0.4104314347108205} | train loss {'Reaction outcome loss': 0.4098524374590404, 'Total loss': 0.4098524374590404}
2023-01-04 10:36:28,170 INFO:     Found new best model at epoch 21
2023-01-04 10:36:28,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:28,171 INFO:     Epoch: 22
2023-01-04 10:36:29,748 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4174593468507131, 'Total loss': 0.4174593468507131} | train loss {'Reaction outcome loss': 0.4043616008796338, 'Total loss': 0.4043616008796338}
2023-01-04 10:36:29,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:29,748 INFO:     Epoch: 23
2023-01-04 10:36:31,314 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4251392751932144, 'Total loss': 0.4251392751932144} | train loss {'Reaction outcome loss': 0.400761223020221, 'Total loss': 0.400761223020221}
2023-01-04 10:36:31,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:31,314 INFO:     Epoch: 24
2023-01-04 10:36:32,884 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4041458696126938, 'Total loss': 0.4041458696126938} | train loss {'Reaction outcome loss': 0.3943340388074791, 'Total loss': 0.3943340388074791}
2023-01-04 10:36:32,885 INFO:     Found new best model at epoch 24
2023-01-04 10:36:32,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:32,885 INFO:     Epoch: 25
2023-01-04 10:36:34,430 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40498128632704417, 'Total loss': 0.40498128632704417} | train loss {'Reaction outcome loss': 0.4090601031439028, 'Total loss': 0.4090601031439028}
2023-01-04 10:36:34,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:34,431 INFO:     Epoch: 26
2023-01-04 10:36:35,975 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44034596582253777, 'Total loss': 0.44034596582253777} | train loss {'Reaction outcome loss': 0.3876753089315953, 'Total loss': 0.3876753089315953}
2023-01-04 10:36:35,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:35,975 INFO:     Epoch: 27
2023-01-04 10:36:37,521 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4696027060349782, 'Total loss': 0.4696027060349782} | train loss {'Reaction outcome loss': 0.39160694190017553, 'Total loss': 0.39160694190017553}
2023-01-04 10:36:37,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:37,522 INFO:     Epoch: 28
2023-01-04 10:36:39,097 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38815066317717234, 'Total loss': 0.38815066317717234} | train loss {'Reaction outcome loss': 0.398943784326126, 'Total loss': 0.398943784326126}
2023-01-04 10:36:39,098 INFO:     Found new best model at epoch 28
2023-01-04 10:36:39,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:39,098 INFO:     Epoch: 29
2023-01-04 10:36:40,681 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40542397399743396, 'Total loss': 0.40542397399743396} | train loss {'Reaction outcome loss': 0.37882820469246287, 'Total loss': 0.37882820469246287}
2023-01-04 10:36:40,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:40,682 INFO:     Epoch: 30
2023-01-04 10:36:42,254 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4020366072654724, 'Total loss': 0.4020366072654724} | train loss {'Reaction outcome loss': 0.37929558500215627, 'Total loss': 0.37929558500215627}
2023-01-04 10:36:42,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:42,255 INFO:     Epoch: 31
2023-01-04 10:36:43,790 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38469925622145335, 'Total loss': 0.38469925622145335} | train loss {'Reaction outcome loss': 0.3784345239721428, 'Total loss': 0.3784345239721428}
2023-01-04 10:36:43,790 INFO:     Found new best model at epoch 31
2023-01-04 10:36:43,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:43,791 INFO:     Epoch: 32
2023-01-04 10:36:45,329 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4033838212490082, 'Total loss': 0.4033838212490082} | train loss {'Reaction outcome loss': 0.37015642916810687, 'Total loss': 0.37015642916810687}
2023-01-04 10:36:45,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:45,329 INFO:     Epoch: 33
2023-01-04 10:36:46,934 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4024774859348933, 'Total loss': 0.4024774859348933} | train loss {'Reaction outcome loss': 0.3648607450118963, 'Total loss': 0.3648607450118963}
2023-01-04 10:36:46,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:46,934 INFO:     Epoch: 34
2023-01-04 10:36:48,537 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3920228292544683, 'Total loss': 0.3920228292544683} | train loss {'Reaction outcome loss': 0.3644448536299709, 'Total loss': 0.3644448536299709}
2023-01-04 10:36:48,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:48,537 INFO:     Epoch: 35
2023-01-04 10:36:50,141 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40666851301987966, 'Total loss': 0.40666851301987966} | train loss {'Reaction outcome loss': 0.38329957435379963, 'Total loss': 0.38329957435379963}
2023-01-04 10:36:50,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:50,141 INFO:     Epoch: 36
2023-01-04 10:36:51,738 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38317510634660723, 'Total loss': 0.38317510634660723} | train loss {'Reaction outcome loss': 0.3621694929357888, 'Total loss': 0.3621694929357888}
2023-01-04 10:36:51,738 INFO:     Found new best model at epoch 36
2023-01-04 10:36:51,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:51,739 INFO:     Epoch: 37
2023-01-04 10:36:53,287 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38679608702659607, 'Total loss': 0.38679608702659607} | train loss {'Reaction outcome loss': 0.3636297298514325, 'Total loss': 0.3636297298514325}
2023-01-04 10:36:53,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:53,288 INFO:     Epoch: 38
2023-01-04 10:36:54,842 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39260516663392386, 'Total loss': 0.39260516663392386} | train loss {'Reaction outcome loss': 0.3562368151978117, 'Total loss': 0.3562368151978117}
2023-01-04 10:36:54,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:54,843 INFO:     Epoch: 39
2023-01-04 10:36:56,432 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3818619738022486, 'Total loss': 0.3818619738022486} | train loss {'Reaction outcome loss': 0.34829324043855286, 'Total loss': 0.34829324043855286}
2023-01-04 10:36:56,432 INFO:     Found new best model at epoch 39
2023-01-04 10:36:56,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:56,433 INFO:     Epoch: 40
2023-01-04 10:36:58,026 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38464589913686115, 'Total loss': 0.38464589913686115} | train loss {'Reaction outcome loss': 0.35001754787737044, 'Total loss': 0.35001754787737044}
2023-01-04 10:36:58,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:58,027 INFO:     Epoch: 41
2023-01-04 10:36:59,622 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3701224664847056, 'Total loss': 0.3701224664847056} | train loss {'Reaction outcome loss': 0.3589008788728371, 'Total loss': 0.3589008788728371}
2023-01-04 10:36:59,622 INFO:     Found new best model at epoch 41
2023-01-04 10:36:59,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:36:59,623 INFO:     Epoch: 42
2023-01-04 10:37:01,201 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39895916879177096, 'Total loss': 0.39895916879177096} | train loss {'Reaction outcome loss': 0.33802665852641256, 'Total loss': 0.33802665852641256}
2023-01-04 10:37:01,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:01,201 INFO:     Epoch: 43
2023-01-04 10:37:02,747 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4137988378604253, 'Total loss': 0.4137988378604253} | train loss {'Reaction outcome loss': 0.3374220578647826, 'Total loss': 0.3374220578647826}
2023-01-04 10:37:02,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:02,747 INFO:     Epoch: 44
2023-01-04 10:37:04,311 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39845617512861886, 'Total loss': 0.39845617512861886} | train loss {'Reaction outcome loss': 0.33491328540106263, 'Total loss': 0.33491328540106263}
2023-01-04 10:37:04,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:04,311 INFO:     Epoch: 45
2023-01-04 10:37:05,891 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4100855191548665, 'Total loss': 0.4100855191548665} | train loss {'Reaction outcome loss': 0.3369651758449449, 'Total loss': 0.3369651758449449}
2023-01-04 10:37:05,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:05,891 INFO:     Epoch: 46
2023-01-04 10:37:07,471 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4048015296459198, 'Total loss': 0.4048015296459198} | train loss {'Reaction outcome loss': 0.34199637134788907, 'Total loss': 0.34199637134788907}
2023-01-04 10:37:07,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:07,472 INFO:     Epoch: 47
2023-01-04 10:37:09,059 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38560596605141956, 'Total loss': 0.38560596605141956} | train loss {'Reaction outcome loss': 0.33094339219826285, 'Total loss': 0.33094339219826285}
2023-01-04 10:37:09,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:09,060 INFO:     Epoch: 48
2023-01-04 10:37:10,653 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4059247821569443, 'Total loss': 0.4059247821569443} | train loss {'Reaction outcome loss': 0.32937966273638647, 'Total loss': 0.32937966273638647}
2023-01-04 10:37:10,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:10,653 INFO:     Epoch: 49
2023-01-04 10:37:12,195 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4022557606299718, 'Total loss': 0.4022557606299718} | train loss {'Reaction outcome loss': 0.3498153130834301, 'Total loss': 0.3498153130834301}
2023-01-04 10:37:12,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:12,195 INFO:     Epoch: 50
2023-01-04 10:37:13,730 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3809732099374135, 'Total loss': 0.3809732099374135} | train loss {'Reaction outcome loss': 0.3228959266696989, 'Total loss': 0.3228959266696989}
2023-01-04 10:37:13,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:13,730 INFO:     Epoch: 51
2023-01-04 10:37:15,314 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41875486075878143, 'Total loss': 0.41875486075878143} | train loss {'Reaction outcome loss': 0.3256642898760628, 'Total loss': 0.3256642898760628}
2023-01-04 10:37:15,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:15,314 INFO:     Epoch: 52
2023-01-04 10:37:16,929 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3721356434126695, 'Total loss': 0.3721356434126695} | train loss {'Reaction outcome loss': 0.34595723388095695, 'Total loss': 0.34595723388095695}
2023-01-04 10:37:16,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:16,930 INFO:     Epoch: 53
2023-01-04 10:37:18,541 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38496810545523963, 'Total loss': 0.38496810545523963} | train loss {'Reaction outcome loss': 0.31829115696777793, 'Total loss': 0.31829115696777793}
2023-01-04 10:37:18,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:18,541 INFO:     Epoch: 54
2023-01-04 10:37:20,120 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3995942920446396, 'Total loss': 0.3995942920446396} | train loss {'Reaction outcome loss': 0.3154156548467733, 'Total loss': 0.3154156548467733}
2023-01-04 10:37:20,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:20,120 INFO:     Epoch: 55
2023-01-04 10:37:21,663 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3581342761715253, 'Total loss': 0.3581342761715253} | train loss {'Reaction outcome loss': 0.3106176373430703, 'Total loss': 0.3106176373430703}
2023-01-04 10:37:21,663 INFO:     Found new best model at epoch 55
2023-01-04 10:37:21,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:21,664 INFO:     Epoch: 56
2023-01-04 10:37:23,236 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3686152954896291, 'Total loss': 0.3686152954896291} | train loss {'Reaction outcome loss': 0.3076835176147195, 'Total loss': 0.3076835176147195}
2023-01-04 10:37:23,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:23,236 INFO:     Epoch: 57
2023-01-04 10:37:24,798 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37988652984301247, 'Total loss': 0.37988652984301247} | train loss {'Reaction outcome loss': 0.3051575661731371, 'Total loss': 0.3051575661731371}
2023-01-04 10:37:24,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:24,799 INFO:     Epoch: 58
2023-01-04 10:37:26,372 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3782323936621348, 'Total loss': 0.3782323936621348} | train loss {'Reaction outcome loss': 0.2979488964116646, 'Total loss': 0.2979488964116646}
2023-01-04 10:37:26,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:26,372 INFO:     Epoch: 59
2023-01-04 10:37:27,953 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.34331365128358204, 'Total loss': 0.34331365128358204} | train loss {'Reaction outcome loss': 0.2994081059704236, 'Total loss': 0.2994081059704236}
2023-01-04 10:37:27,953 INFO:     Found new best model at epoch 59
2023-01-04 10:37:27,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:27,954 INFO:     Epoch: 60
2023-01-04 10:37:29,497 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3681415140628815, 'Total loss': 0.3681415140628815} | train loss {'Reaction outcome loss': 0.3007423881337171, 'Total loss': 0.3007423881337171}
2023-01-04 10:37:29,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:29,497 INFO:     Epoch: 61
2023-01-04 10:37:31,051 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.401581405599912, 'Total loss': 0.401581405599912} | train loss {'Reaction outcome loss': 0.2963824749492325, 'Total loss': 0.2963824749492325}
2023-01-04 10:37:31,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:31,051 INFO:     Epoch: 62
2023-01-04 10:37:32,627 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37446054617563884, 'Total loss': 0.37446054617563884} | train loss {'Reaction outcome loss': 0.2985620248951304, 'Total loss': 0.2985620248951304}
2023-01-04 10:37:32,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:32,628 INFO:     Epoch: 63
2023-01-04 10:37:34,195 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3587795406579971, 'Total loss': 0.3587795406579971} | train loss {'Reaction outcome loss': 0.2937868873186876, 'Total loss': 0.2937868873186876}
2023-01-04 10:37:34,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:34,195 INFO:     Epoch: 64
2023-01-04 10:37:35,763 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3657589226961136, 'Total loss': 0.3657589226961136} | train loss {'Reaction outcome loss': 0.2940275715604978, 'Total loss': 0.2940275715604978}
2023-01-04 10:37:35,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:35,763 INFO:     Epoch: 65
2023-01-04 10:37:37,324 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.364900075395902, 'Total loss': 0.364900075395902} | train loss {'Reaction outcome loss': 0.29341387524829665, 'Total loss': 0.29341387524829665}
2023-01-04 10:37:37,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:37,325 INFO:     Epoch: 66
2023-01-04 10:37:38,873 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3688158690929413, 'Total loss': 0.3688158690929413} | train loss {'Reaction outcome loss': 0.2894693811024156, 'Total loss': 0.2894693811024156}
2023-01-04 10:37:38,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:38,874 INFO:     Epoch: 67
2023-01-04 10:37:40,156 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3481543848911921, 'Total loss': 0.3481543848911921} | train loss {'Reaction outcome loss': 0.28588885768777283, 'Total loss': 0.28588885768777283}
2023-01-04 10:37:40,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:40,156 INFO:     Epoch: 68
2023-01-04 10:37:41,184 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3849631011486053, 'Total loss': 0.3849631011486053} | train loss {'Reaction outcome loss': 0.28723722057129897, 'Total loss': 0.28723722057129897}
2023-01-04 10:37:41,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:41,184 INFO:     Epoch: 69
2023-01-04 10:37:42,201 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38464958369731905, 'Total loss': 0.38464958369731905} | train loss {'Reaction outcome loss': 0.29623767846952315, 'Total loss': 0.29623767846952315}
2023-01-04 10:37:42,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:42,201 INFO:     Epoch: 70
2023-01-04 10:37:43,221 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39651950101057687, 'Total loss': 0.39651950101057687} | train loss {'Reaction outcome loss': 0.3300716463962327, 'Total loss': 0.3300716463962327}
2023-01-04 10:37:43,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:43,222 INFO:     Epoch: 71
2023-01-04 10:37:44,271 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38900955418745675, 'Total loss': 0.38900955418745675} | train loss {'Reaction outcome loss': 0.3665071284884344, 'Total loss': 0.3665071284884344}
2023-01-04 10:37:44,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:44,272 INFO:     Epoch: 72
2023-01-04 10:37:45,764 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.363729660709699, 'Total loss': 0.363729660709699} | train loss {'Reaction outcome loss': 0.2968213755496212, 'Total loss': 0.2968213755496212}
2023-01-04 10:37:45,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:45,766 INFO:     Epoch: 73
2023-01-04 10:37:47,353 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3772417674462, 'Total loss': 0.3772417674462} | train loss {'Reaction outcome loss': 0.2861262904513843, 'Total loss': 0.2861262904513843}
2023-01-04 10:37:47,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:47,353 INFO:     Epoch: 74
2023-01-04 10:37:48,936 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3701686322689056, 'Total loss': 0.3701686322689056} | train loss {'Reaction outcome loss': 0.28227747085591126, 'Total loss': 0.28227747085591126}
2023-01-04 10:37:48,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:48,936 INFO:     Epoch: 75
2023-01-04 10:37:50,543 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3706358551979065, 'Total loss': 0.3706358551979065} | train loss {'Reaction outcome loss': 0.2817984737685301, 'Total loss': 0.2817984737685301}
2023-01-04 10:37:50,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:50,543 INFO:     Epoch: 76
2023-01-04 10:37:52,113 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3884073744217555, 'Total loss': 0.3884073744217555} | train loss {'Reaction outcome loss': 0.30176023366874544, 'Total loss': 0.30176023366874544}
2023-01-04 10:37:52,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:52,114 INFO:     Epoch: 77
2023-01-04 10:37:53,595 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37057014207045236, 'Total loss': 0.37057014207045236} | train loss {'Reaction outcome loss': 0.28172333440254105, 'Total loss': 0.28172333440254105}
2023-01-04 10:37:53,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:53,596 INFO:     Epoch: 78
2023-01-04 10:37:55,157 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.36403057525555294, 'Total loss': 0.36403057525555294} | train loss {'Reaction outcome loss': 0.2757498984279084, 'Total loss': 0.2757498984279084}
2023-01-04 10:37:55,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:55,158 INFO:     Epoch: 79
2023-01-04 10:37:56,746 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42033346990744275, 'Total loss': 0.42033346990744275} | train loss {'Reaction outcome loss': 0.277235284164224, 'Total loss': 0.277235284164224}
2023-01-04 10:37:56,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:56,746 INFO:     Epoch: 80
2023-01-04 10:37:58,362 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3784883985916773, 'Total loss': 0.3784883985916773} | train loss {'Reaction outcome loss': 0.3169225349860347, 'Total loss': 0.3169225349860347}
2023-01-04 10:37:58,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:58,362 INFO:     Epoch: 81
2023-01-04 10:37:59,974 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3651335875193278, 'Total loss': 0.3651335875193278} | train loss {'Reaction outcome loss': 0.2814521817657496, 'Total loss': 0.2814521817657496}
2023-01-04 10:37:59,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:37:59,974 INFO:     Epoch: 82
2023-01-04 10:38:01,588 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3829994628826777, 'Total loss': 0.3829994628826777} | train loss {'Reaction outcome loss': 0.27248709401169763, 'Total loss': 0.27248709401169763}
2023-01-04 10:38:01,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:01,589 INFO:     Epoch: 83
2023-01-04 10:38:03,090 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.362971293926239, 'Total loss': 0.362971293926239} | train loss {'Reaction outcome loss': 0.26786698117528274, 'Total loss': 0.26786698117528274}
2023-01-04 10:38:03,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:03,091 INFO:     Epoch: 84
2023-01-04 10:38:04,707 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38364898165067035, 'Total loss': 0.38364898165067035} | train loss {'Reaction outcome loss': 0.26990288334682655, 'Total loss': 0.26990288334682655}
2023-01-04 10:38:04,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:04,708 INFO:     Epoch: 85
2023-01-04 10:38:06,310 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.36835734993219377, 'Total loss': 0.36835734993219377} | train loss {'Reaction outcome loss': 0.2651489120030749, 'Total loss': 0.2651489120030749}
2023-01-04 10:38:06,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:06,310 INFO:     Epoch: 86
2023-01-04 10:38:07,921 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4051592687765757, 'Total loss': 0.4051592687765757} | train loss {'Reaction outcome loss': 0.2770409313286992, 'Total loss': 0.2770409313286992}
2023-01-04 10:38:07,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:07,921 INFO:     Epoch: 87
2023-01-04 10:38:09,517 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.36881367762883505, 'Total loss': 0.36881367762883505} | train loss {'Reaction outcome loss': 0.29009537385317724, 'Total loss': 0.29009537385317724}
2023-01-04 10:38:09,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:09,517 INFO:     Epoch: 88
2023-01-04 10:38:11,125 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3646203766266505, 'Total loss': 0.3646203766266505} | train loss {'Reaction outcome loss': 0.2973014859995548, 'Total loss': 0.2973014859995548}
2023-01-04 10:38:11,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:11,125 INFO:     Epoch: 89
2023-01-04 10:38:12,613 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3615292062362035, 'Total loss': 0.3615292062362035} | train loss {'Reaction outcome loss': 0.27020155286231456, 'Total loss': 0.27020155286231456}
2023-01-04 10:38:12,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:12,613 INFO:     Epoch: 90
2023-01-04 10:38:14,219 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4277747864524523, 'Total loss': 0.4277747864524523} | train loss {'Reaction outcome loss': 0.2649971415386603, 'Total loss': 0.2649971415386603}
2023-01-04 10:38:14,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:14,220 INFO:     Epoch: 91
2023-01-04 10:38:15,831 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3728886033097903, 'Total loss': 0.3728886033097903} | train loss {'Reaction outcome loss': 0.2627103842888092, 'Total loss': 0.2627103842888092}
2023-01-04 10:38:15,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:15,832 INFO:     Epoch: 92
2023-01-04 10:38:17,449 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.38752727111180624, 'Total loss': 0.38752727111180624} | train loss {'Reaction outcome loss': 0.2619509103006103, 'Total loss': 0.2619509103006103}
2023-01-04 10:38:17,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:17,449 INFO:     Epoch: 93
2023-01-04 10:38:19,067 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3857828696568807, 'Total loss': 0.3857828696568807} | train loss {'Reaction outcome loss': 0.26169141535849677, 'Total loss': 0.26169141535849677}
2023-01-04 10:38:19,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:19,067 INFO:     Epoch: 94
2023-01-04 10:38:20,671 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.36685479482014977, 'Total loss': 0.36685479482014977} | train loss {'Reaction outcome loss': 0.26982280873841996, 'Total loss': 0.26982280873841996}
2023-01-04 10:38:20,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:20,672 INFO:     Epoch: 95
2023-01-04 10:38:22,158 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3719250996907552, 'Total loss': 0.3719250996907552} | train loss {'Reaction outcome loss': 0.2775864413790945, 'Total loss': 0.2775864413790945}
2023-01-04 10:38:22,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:22,159 INFO:     Epoch: 96
2023-01-04 10:38:23,755 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3716008499264717, 'Total loss': 0.3716008499264717} | train loss {'Reaction outcome loss': 0.25498660161595227, 'Total loss': 0.25498660161595227}
2023-01-04 10:38:23,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:23,755 INFO:     Epoch: 97
2023-01-04 10:38:25,341 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.364562134941419, 'Total loss': 0.364562134941419} | train loss {'Reaction outcome loss': 0.25416144063195173, 'Total loss': 0.25416144063195173}
2023-01-04 10:38:25,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:25,341 INFO:     Epoch: 98
2023-01-04 10:38:26,935 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3884060323238373, 'Total loss': 0.3884060323238373} | train loss {'Reaction outcome loss': 0.25508429293868307, 'Total loss': 0.25508429293868307}
2023-01-04 10:38:26,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:26,936 INFO:     Epoch: 99
2023-01-04 10:38:28,547 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3705059866110484, 'Total loss': 0.3705059866110484} | train loss {'Reaction outcome loss': 0.25204790163474355, 'Total loss': 0.25204790163474355}
2023-01-04 10:38:28,547 INFO:     Best model found after epoch 60 of 100.
2023-01-04 10:38:28,547 INFO:   Done with stage: TRAINING
2023-01-04 10:38:28,547 INFO:   Starting stage: EVALUATION
2023-01-04 10:38:28,677 INFO:   Done with stage: EVALUATION
2023-01-04 10:38:28,677 INFO:   Leaving out SEQ value Fold_6
2023-01-04 10:38:28,690 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 10:38:28,690 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:38:29,351 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:38:29,351 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:38:29,419 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:38:29,419 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:38:29,419 INFO:     No hyperparam tuning for this model
2023-01-04 10:38:29,420 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:38:29,420 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:38:29,420 INFO:     None feature selector for col prot
2023-01-04 10:38:29,420 INFO:     None feature selector for col prot
2023-01-04 10:38:29,421 INFO:     None feature selector for col prot
2023-01-04 10:38:29,421 INFO:     None feature selector for col chem
2023-01-04 10:38:29,421 INFO:     None feature selector for col chem
2023-01-04 10:38:29,421 INFO:     None feature selector for col chem
2023-01-04 10:38:29,421 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:38:29,421 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:38:29,422 INFO:     Number of params in model 70111
2023-01-04 10:38:29,426 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:38:29,426 INFO:   Starting stage: TRAINING
2023-01-04 10:38:29,469 INFO:     Val loss before train {'Reaction outcome loss': 1.0655101219813028, 'Total loss': 1.0655101219813028}
2023-01-04 10:38:29,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:29,469 INFO:     Epoch: 0
2023-01-04 10:38:31,046 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7414851148923238, 'Total loss': 0.7414851148923238} | train loss {'Reaction outcome loss': 0.8308296268167048, 'Total loss': 0.8308296268167048}
2023-01-04 10:38:31,046 INFO:     Found new best model at epoch 0
2023-01-04 10:38:31,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:31,047 INFO:     Epoch: 1
2023-01-04 10:38:32,671 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6316167831420898, 'Total loss': 0.6316167831420898} | train loss {'Reaction outcome loss': 0.6672809873892512, 'Total loss': 0.6672809873892512}
2023-01-04 10:38:32,671 INFO:     Found new best model at epoch 1
2023-01-04 10:38:32,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:32,672 INFO:     Epoch: 2
2023-01-04 10:38:34,292 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5884443044662475, 'Total loss': 0.5884443044662475} | train loss {'Reaction outcome loss': 0.58868631419292, 'Total loss': 0.58868631419292}
2023-01-04 10:38:34,293 INFO:     Found new best model at epoch 2
2023-01-04 10:38:34,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:34,294 INFO:     Epoch: 3
2023-01-04 10:38:35,907 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5576412796974182, 'Total loss': 0.5576412796974182} | train loss {'Reaction outcome loss': 0.5492198372575781, 'Total loss': 0.5492198372575781}
2023-01-04 10:38:35,907 INFO:     Found new best model at epoch 3
2023-01-04 10:38:35,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:35,908 INFO:     Epoch: 4
2023-01-04 10:38:37,520 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.557242731253306, 'Total loss': 0.557242731253306} | train loss {'Reaction outcome loss': 0.5253382300426813, 'Total loss': 0.5253382300426813}
2023-01-04 10:38:37,520 INFO:     Found new best model at epoch 4
2023-01-04 10:38:37,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:37,521 INFO:     Epoch: 5
2023-01-04 10:38:39,022 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5618486007054647, 'Total loss': 0.5618486007054647} | train loss {'Reaction outcome loss': 0.5112992619779566, 'Total loss': 0.5112992619779566}
2023-01-04 10:38:39,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:39,023 INFO:     Epoch: 6
2023-01-04 10:38:40,631 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5449987947940826, 'Total loss': 0.5449987947940826} | train loss {'Reaction outcome loss': 0.5027477878956158, 'Total loss': 0.5027477878956158}
2023-01-04 10:38:40,631 INFO:     Found new best model at epoch 6
2023-01-04 10:38:40,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:40,632 INFO:     Epoch: 7
2023-01-04 10:38:42,236 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5158990244070689, 'Total loss': 0.5158990244070689} | train loss {'Reaction outcome loss': 0.4920066103930938, 'Total loss': 0.4920066103930938}
2023-01-04 10:38:42,236 INFO:     Found new best model at epoch 7
2023-01-04 10:38:42,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:42,237 INFO:     Epoch: 8
2023-01-04 10:38:43,844 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5243378599484761, 'Total loss': 0.5243378599484761} | train loss {'Reaction outcome loss': 0.48156403693696653, 'Total loss': 0.48156403693696653}
2023-01-04 10:38:43,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:43,844 INFO:     Epoch: 9
2023-01-04 10:38:45,447 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5147787094116211, 'Total loss': 0.5147787094116211} | train loss {'Reaction outcome loss': 0.4781599289566171, 'Total loss': 0.4781599289566171}
2023-01-04 10:38:45,447 INFO:     Found new best model at epoch 9
2023-01-04 10:38:45,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:45,448 INFO:     Epoch: 10
2023-01-04 10:38:47,041 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49698697924613955, 'Total loss': 0.49698697924613955} | train loss {'Reaction outcome loss': 0.47199517402407926, 'Total loss': 0.47199517402407926}
2023-01-04 10:38:47,042 INFO:     Found new best model at epoch 10
2023-01-04 10:38:47,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:47,043 INFO:     Epoch: 11
2023-01-04 10:38:48,522 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5068625609079996, 'Total loss': 0.5068625609079996} | train loss {'Reaction outcome loss': 0.4651826771803281, 'Total loss': 0.4651826771803281}
2023-01-04 10:38:48,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:48,522 INFO:     Epoch: 12
2023-01-04 10:38:50,098 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5031974852085114, 'Total loss': 0.5031974852085114} | train loss {'Reaction outcome loss': 0.45694182678680556, 'Total loss': 0.45694182678680556}
2023-01-04 10:38:50,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:50,098 INFO:     Epoch: 13
2023-01-04 10:38:51,708 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4826747715473175, 'Total loss': 0.4826747715473175} | train loss {'Reaction outcome loss': 0.4500633834824235, 'Total loss': 0.4500633834824235}
2023-01-04 10:38:51,708 INFO:     Found new best model at epoch 13
2023-01-04 10:38:51,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:51,709 INFO:     Epoch: 14
2023-01-04 10:38:53,330 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4865253418684006, 'Total loss': 0.4865253418684006} | train loss {'Reaction outcome loss': 0.4522483718416751, 'Total loss': 0.4522483718416751}
2023-01-04 10:38:53,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:53,331 INFO:     Epoch: 15
2023-01-04 10:38:54,928 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5070443391799927, 'Total loss': 0.5070443391799927} | train loss {'Reaction outcome loss': 0.44283243615704754, 'Total loss': 0.44283243615704754}
2023-01-04 10:38:54,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:54,929 INFO:     Epoch: 16
2023-01-04 10:38:56,546 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4881621281305949, 'Total loss': 0.4881621281305949} | train loss {'Reaction outcome loss': 0.4399653672096101, 'Total loss': 0.4399653672096101}
2023-01-04 10:38:56,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:56,547 INFO:     Epoch: 17
2023-01-04 10:38:58,019 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46388948361078897, 'Total loss': 0.46388948361078897} | train loss {'Reaction outcome loss': 0.4361158219377917, 'Total loss': 0.4361158219377917}
2023-01-04 10:38:58,019 INFO:     Found new best model at epoch 17
2023-01-04 10:38:58,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:58,020 INFO:     Epoch: 18
2023-01-04 10:38:59,633 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47135853668053945, 'Total loss': 0.47135853668053945} | train loss {'Reaction outcome loss': 0.4311963448348028, 'Total loss': 0.4311963448348028}
2023-01-04 10:38:59,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:38:59,633 INFO:     Epoch: 19
2023-01-04 10:39:01,240 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4764068404833476, 'Total loss': 0.4764068404833476} | train loss {'Reaction outcome loss': 0.42537673016747846, 'Total loss': 0.42537673016747846}
2023-01-04 10:39:01,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:01,240 INFO:     Epoch: 20
2023-01-04 10:39:02,836 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4698003927866618, 'Total loss': 0.4698003927866618} | train loss {'Reaction outcome loss': 0.4253450574534895, 'Total loss': 0.4253450574534895}
2023-01-04 10:39:02,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:02,836 INFO:     Epoch: 21
2023-01-04 10:39:04,431 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4722462107737859, 'Total loss': 0.4722462107737859} | train loss {'Reaction outcome loss': 0.42152899686610223, 'Total loss': 0.42152899686610223}
2023-01-04 10:39:04,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:04,432 INFO:     Epoch: 22
2023-01-04 10:39:05,963 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4928936501344045, 'Total loss': 0.4928936501344045} | train loss {'Reaction outcome loss': 0.4158172075929194, 'Total loss': 0.4158172075929194}
2023-01-04 10:39:05,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:05,964 INFO:     Epoch: 23
2023-01-04 10:39:07,570 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4726035535335541, 'Total loss': 0.4726035535335541} | train loss {'Reaction outcome loss': 0.41401873071701517, 'Total loss': 0.41401873071701517}
2023-01-04 10:39:07,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:07,571 INFO:     Epoch: 24
2023-01-04 10:39:09,201 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4525310387214025, 'Total loss': 0.4525310387214025} | train loss {'Reaction outcome loss': 0.4080721924236105, 'Total loss': 0.4080721924236105}
2023-01-04 10:39:09,201 INFO:     Found new best model at epoch 24
2023-01-04 10:39:09,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:09,202 INFO:     Epoch: 25
2023-01-04 10:39:10,825 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4611972808837891, 'Total loss': 0.4611972808837891} | train loss {'Reaction outcome loss': 0.40399523359128287, 'Total loss': 0.40399523359128287}
2023-01-04 10:39:10,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:10,825 INFO:     Epoch: 26
2023-01-04 10:39:12,429 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4725389500459035, 'Total loss': 0.4725389500459035} | train loss {'Reaction outcome loss': 0.4036572473359022, 'Total loss': 0.4036572473359022}
2023-01-04 10:39:12,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:12,429 INFO:     Epoch: 27
2023-01-04 10:39:14,028 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4495467046896617, 'Total loss': 0.4495467046896617} | train loss {'Reaction outcome loss': 0.40111784104405757, 'Total loss': 0.40111784104405757}
2023-01-04 10:39:14,028 INFO:     Found new best model at epoch 27
2023-01-04 10:39:14,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:14,029 INFO:     Epoch: 28
2023-01-04 10:39:15,495 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44019092520078024, 'Total loss': 0.44019092520078024} | train loss {'Reaction outcome loss': 0.39430602828195377, 'Total loss': 0.39430602828195377}
2023-01-04 10:39:15,495 INFO:     Found new best model at epoch 28
2023-01-04 10:39:15,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:15,496 INFO:     Epoch: 29
2023-01-04 10:39:17,077 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4331250707308451, 'Total loss': 0.4331250707308451} | train loss {'Reaction outcome loss': 0.3910486716709843, 'Total loss': 0.3910486716709843}
2023-01-04 10:39:17,078 INFO:     Found new best model at epoch 29
2023-01-04 10:39:17,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:17,079 INFO:     Epoch: 30
2023-01-04 10:39:18,654 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43604594469070435, 'Total loss': 0.43604594469070435} | train loss {'Reaction outcome loss': 0.3854497203112509, 'Total loss': 0.3854497203112509}
2023-01-04 10:39:18,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:18,655 INFO:     Epoch: 31
2023-01-04 10:39:20,240 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42414801915486655, 'Total loss': 0.42414801915486655} | train loss {'Reaction outcome loss': 0.3824755986782618, 'Total loss': 0.3824755986782618}
2023-01-04 10:39:20,240 INFO:     Found new best model at epoch 31
2023-01-04 10:39:20,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:20,241 INFO:     Epoch: 32
2023-01-04 10:39:21,828 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45826236804326376, 'Total loss': 0.45826236804326376} | train loss {'Reaction outcome loss': 0.37821915823737634, 'Total loss': 0.37821915823737634}
2023-01-04 10:39:21,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:21,829 INFO:     Epoch: 33
2023-01-04 10:39:23,402 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4365163614352544, 'Total loss': 0.4365163614352544} | train loss {'Reaction outcome loss': 0.3794335435121068, 'Total loss': 0.3794335435121068}
2023-01-04 10:39:23,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:23,402 INFO:     Epoch: 34
2023-01-04 10:39:24,867 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4487863560517629, 'Total loss': 0.4487863560517629} | train loss {'Reaction outcome loss': 0.3695563099175584, 'Total loss': 0.3695563099175584}
2023-01-04 10:39:24,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:24,867 INFO:     Epoch: 35
2023-01-04 10:39:26,442 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42285785675048826, 'Total loss': 0.42285785675048826} | train loss {'Reaction outcome loss': 0.3678578348689131, 'Total loss': 0.3678578348689131}
2023-01-04 10:39:26,442 INFO:     Found new best model at epoch 35
2023-01-04 10:39:26,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:26,443 INFO:     Epoch: 36
2023-01-04 10:39:28,025 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4080847382545471, 'Total loss': 0.4080847382545471} | train loss {'Reaction outcome loss': 0.3632324633561747, 'Total loss': 0.3632324633561747}
2023-01-04 10:39:28,025 INFO:     Found new best model at epoch 36
2023-01-04 10:39:28,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:28,026 INFO:     Epoch: 37
2023-01-04 10:39:29,595 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4219856341679891, 'Total loss': 0.4219856341679891} | train loss {'Reaction outcome loss': 0.36346611474718, 'Total loss': 0.36346611474718}
2023-01-04 10:39:29,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:29,595 INFO:     Epoch: 38
2023-01-04 10:39:31,151 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39397946099440256, 'Total loss': 0.39397946099440256} | train loss {'Reaction outcome loss': 0.36117210653391985, 'Total loss': 0.36117210653391985}
2023-01-04 10:39:31,151 INFO:     Found new best model at epoch 38
2023-01-04 10:39:31,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:31,152 INFO:     Epoch: 39
2023-01-04 10:39:32,734 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4190611739953359, 'Total loss': 0.4190611739953359} | train loss {'Reaction outcome loss': 0.353953177613687, 'Total loss': 0.353953177613687}
2023-01-04 10:39:32,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:32,735 INFO:     Epoch: 40
2023-01-04 10:39:34,185 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4057062913974126, 'Total loss': 0.4057062913974126} | train loss {'Reaction outcome loss': 0.35278710007452363, 'Total loss': 0.35278710007452363}
2023-01-04 10:39:34,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:34,185 INFO:     Epoch: 41
2023-01-04 10:39:35,761 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.421589524547259, 'Total loss': 0.421589524547259} | train loss {'Reaction outcome loss': 0.3477951452566398, 'Total loss': 0.3477951452566398}
2023-01-04 10:39:35,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:35,762 INFO:     Epoch: 42
2023-01-04 10:39:37,354 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43116047581036887, 'Total loss': 0.43116047581036887} | train loss {'Reaction outcome loss': 0.34686840785539536, 'Total loss': 0.34686840785539536}
2023-01-04 10:39:37,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:37,354 INFO:     Epoch: 43
2023-01-04 10:39:38,959 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4205219030380249, 'Total loss': 0.4205219030380249} | train loss {'Reaction outcome loss': 0.34283788556011147, 'Total loss': 0.34283788556011147}
2023-01-04 10:39:38,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:38,959 INFO:     Epoch: 44
2023-01-04 10:39:40,534 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4476478934288025, 'Total loss': 0.4476478934288025} | train loss {'Reaction outcome loss': 0.33743596773608064, 'Total loss': 0.33743596773608064}
2023-01-04 10:39:40,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:40,534 INFO:     Epoch: 45
2023-01-04 10:39:42,141 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4291748742262522, 'Total loss': 0.4291748742262522} | train loss {'Reaction outcome loss': 0.33596232922122365, 'Total loss': 0.33596232922122365}
2023-01-04 10:39:42,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:42,142 INFO:     Epoch: 46
2023-01-04 10:39:43,642 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4134610782066981, 'Total loss': 0.4134610782066981} | train loss {'Reaction outcome loss': 0.32950120857691506, 'Total loss': 0.32950120857691506}
2023-01-04 10:39:43,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:43,642 INFO:     Epoch: 47
2023-01-04 10:39:45,258 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43053849041461945, 'Total loss': 0.43053849041461945} | train loss {'Reaction outcome loss': 0.3324633069363312, 'Total loss': 0.3324633069363312}
2023-01-04 10:39:45,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:45,259 INFO:     Epoch: 48
2023-01-04 10:39:46,872 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39041547576586405, 'Total loss': 0.39041547576586405} | train loss {'Reaction outcome loss': 0.3276480876904532, 'Total loss': 0.3276480876904532}
2023-01-04 10:39:46,872 INFO:     Found new best model at epoch 48
2023-01-04 10:39:46,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:46,873 INFO:     Epoch: 49
2023-01-04 10:39:48,489 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4682723561922709, 'Total loss': 0.4682723561922709} | train loss {'Reaction outcome loss': 0.3228650177267484, 'Total loss': 0.3228650177267484}
2023-01-04 10:39:48,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:48,490 INFO:     Epoch: 50
2023-01-04 10:39:50,095 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43226403295993804, 'Total loss': 0.43226403295993804} | train loss {'Reaction outcome loss': 0.3224332780183868, 'Total loss': 0.3224332780183868}
2023-01-04 10:39:50,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:50,095 INFO:     Epoch: 51
2023-01-04 10:39:51,635 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42498077154159547, 'Total loss': 0.42498077154159547} | train loss {'Reaction outcome loss': 0.3233656648425419, 'Total loss': 0.3233656648425419}
2023-01-04 10:39:51,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:51,636 INFO:     Epoch: 52
2023-01-04 10:39:53,242 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41189152002334595, 'Total loss': 0.41189152002334595} | train loss {'Reaction outcome loss': 0.3234148178827892, 'Total loss': 0.3234148178827892}
2023-01-04 10:39:53,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:53,242 INFO:     Epoch: 53
2023-01-04 10:39:54,859 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4109477619330088, 'Total loss': 0.4109477619330088} | train loss {'Reaction outcome loss': 0.3173295723993856, 'Total loss': 0.3173295723993856}
2023-01-04 10:39:54,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:54,860 INFO:     Epoch: 54
2023-01-04 10:39:56,481 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3994177500406901, 'Total loss': 0.3994177500406901} | train loss {'Reaction outcome loss': 0.3123470579243739, 'Total loss': 0.3123470579243739}
2023-01-04 10:39:56,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:56,481 INFO:     Epoch: 55
2023-01-04 10:39:58,103 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4009634147087733, 'Total loss': 0.4009634147087733} | train loss {'Reaction outcome loss': 0.3115755836294446, 'Total loss': 0.3115755836294446}
2023-01-04 10:39:58,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:58,103 INFO:     Epoch: 56
2023-01-04 10:39:59,704 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4226278096437454, 'Total loss': 0.4226278096437454} | train loss {'Reaction outcome loss': 0.3071176178672684, 'Total loss': 0.3071176178672684}
2023-01-04 10:39:59,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:39:59,704 INFO:     Epoch: 57
2023-01-04 10:40:01,214 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43654265503088635, 'Total loss': 0.43654265503088635} | train loss {'Reaction outcome loss': 0.3074512817100067, 'Total loss': 0.3074512817100067}
2023-01-04 10:40:01,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:01,214 INFO:     Epoch: 58
2023-01-04 10:40:02,817 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42183720171451566, 'Total loss': 0.42183720171451566} | train loss {'Reaction outcome loss': 0.3075981204421512, 'Total loss': 0.3075981204421512}
2023-01-04 10:40:02,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:02,818 INFO:     Epoch: 59
2023-01-04 10:40:04,444 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4217165211836497, 'Total loss': 0.4217165211836497} | train loss {'Reaction outcome loss': 0.3028345822427247, 'Total loss': 0.3028345822427247}
2023-01-04 10:40:04,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:04,444 INFO:     Epoch: 60
2023-01-04 10:40:06,069 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4266350269317627, 'Total loss': 0.4266350269317627} | train loss {'Reaction outcome loss': 0.301309711114917, 'Total loss': 0.301309711114917}
2023-01-04 10:40:06,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:06,070 INFO:     Epoch: 61
2023-01-04 10:40:07,691 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43047755857308706, 'Total loss': 0.43047755857308706} | train loss {'Reaction outcome loss': 0.29970797000701677, 'Total loss': 0.29970797000701677}
2023-01-04 10:40:07,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:07,692 INFO:     Epoch: 62
2023-01-04 10:40:09,316 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4015888452529907, 'Total loss': 0.4015888452529907} | train loss {'Reaction outcome loss': 0.29700183521431706, 'Total loss': 0.29700183521431706}
2023-01-04 10:40:09,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:09,317 INFO:     Epoch: 63
2023-01-04 10:40:10,830 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4222223480542501, 'Total loss': 0.4222223480542501} | train loss {'Reaction outcome loss': 0.29225961643435894, 'Total loss': 0.29225961643435894}
2023-01-04 10:40:10,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:10,831 INFO:     Epoch: 64
2023-01-04 10:40:12,448 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4235793670018514, 'Total loss': 0.4235793670018514} | train loss {'Reaction outcome loss': 0.2983761332956032, 'Total loss': 0.2983761332956032}
2023-01-04 10:40:12,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:12,448 INFO:     Epoch: 65
2023-01-04 10:40:14,051 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3910075177748998, 'Total loss': 0.3910075177748998} | train loss {'Reaction outcome loss': 0.29701188082944613, 'Total loss': 0.29701188082944613}
2023-01-04 10:40:14,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:14,052 INFO:     Epoch: 66
2023-01-04 10:40:15,669 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40564366976420085, 'Total loss': 0.40564366976420085} | train loss {'Reaction outcome loss': 0.28978635045272777, 'Total loss': 0.28978635045272777}
2023-01-04 10:40:15,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:15,670 INFO:     Epoch: 67
2023-01-04 10:40:17,280 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4123506595691045, 'Total loss': 0.4123506595691045} | train loss {'Reaction outcome loss': 0.2891891286960578, 'Total loss': 0.2891891286960578}
2023-01-04 10:40:17,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:17,280 INFO:     Epoch: 68
2023-01-04 10:40:18,851 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41355115473270415, 'Total loss': 0.41355115473270415} | train loss {'Reaction outcome loss': 0.29232949416559956, 'Total loss': 0.29232949416559956}
2023-01-04 10:40:18,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:18,852 INFO:     Epoch: 69
2023-01-04 10:40:20,438 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4068641940752665, 'Total loss': 0.4068641940752665} | train loss {'Reaction outcome loss': 0.2827514929273283, 'Total loss': 0.2827514929273283}
2023-01-04 10:40:20,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:20,438 INFO:     Epoch: 70
2023-01-04 10:40:22,043 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4090971584121386, 'Total loss': 0.4090971584121386} | train loss {'Reaction outcome loss': 0.28700035015652325, 'Total loss': 0.28700035015652325}
2023-01-04 10:40:22,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:22,043 INFO:     Epoch: 71
2023-01-04 10:40:23,650 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42072912951310476, 'Total loss': 0.42072912951310476} | train loss {'Reaction outcome loss': 0.28387696903857945, 'Total loss': 0.28387696903857945}
2023-01-04 10:40:23,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:23,650 INFO:     Epoch: 72
2023-01-04 10:40:25,272 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3884965399901072, 'Total loss': 0.3884965399901072} | train loss {'Reaction outcome loss': 0.2823458105218109, 'Total loss': 0.2823458105218109}
2023-01-04 10:40:25,273 INFO:     Found new best model at epoch 72
2023-01-04 10:40:25,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:25,274 INFO:     Epoch: 73
2023-01-04 10:40:26,866 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38803635239601136, 'Total loss': 0.38803635239601136} | train loss {'Reaction outcome loss': 0.2812084330225679, 'Total loss': 0.2812084330225679}
2023-01-04 10:40:26,866 INFO:     Found new best model at epoch 73
2023-01-04 10:40:26,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:26,867 INFO:     Epoch: 74
2023-01-04 10:40:28,370 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3988760928312937, 'Total loss': 0.3988760928312937} | train loss {'Reaction outcome loss': 0.2829319595591256, 'Total loss': 0.2829319595591256}
2023-01-04 10:40:28,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:28,370 INFO:     Epoch: 75
2023-01-04 10:40:29,974 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43325472076733906, 'Total loss': 0.43325472076733906} | train loss {'Reaction outcome loss': 0.27564463982298054, 'Total loss': 0.27564463982298054}
2023-01-04 10:40:29,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:29,974 INFO:     Epoch: 76
2023-01-04 10:40:31,563 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40345163345336915, 'Total loss': 0.40345163345336915} | train loss {'Reaction outcome loss': 0.2798538511948465, 'Total loss': 0.2798538511948465}
2023-01-04 10:40:31,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:31,564 INFO:     Epoch: 77
2023-01-04 10:40:33,156 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4354511151711146, 'Total loss': 0.4354511151711146} | train loss {'Reaction outcome loss': 0.2724574128912244, 'Total loss': 0.2724574128912244}
2023-01-04 10:40:33,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:33,156 INFO:     Epoch: 78
2023-01-04 10:40:34,762 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39511972963809966, 'Total loss': 0.39511972963809966} | train loss {'Reaction outcome loss': 0.279253392255048, 'Total loss': 0.279253392255048}
2023-01-04 10:40:34,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:34,763 INFO:     Epoch: 79
2023-01-04 10:40:36,359 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39042144616444907, 'Total loss': 0.39042144616444907} | train loss {'Reaction outcome loss': 0.2701683206624933, 'Total loss': 0.2701683206624933}
2023-01-04 10:40:36,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:36,360 INFO:     Epoch: 80
2023-01-04 10:40:37,845 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4146973391373952, 'Total loss': 0.4146973391373952} | train loss {'Reaction outcome loss': 0.27162278724652766, 'Total loss': 0.27162278724652766}
2023-01-04 10:40:37,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:37,846 INFO:     Epoch: 81
2023-01-04 10:40:39,446 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4264712403217951, 'Total loss': 0.4264712403217951} | train loss {'Reaction outcome loss': 0.269497912605747, 'Total loss': 0.269497912605747}
2023-01-04 10:40:39,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:39,447 INFO:     Epoch: 82
2023-01-04 10:40:41,045 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4126845419406891, 'Total loss': 0.4126845419406891} | train loss {'Reaction outcome loss': 0.2719658202347127, 'Total loss': 0.2719658202347127}
2023-01-04 10:40:41,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:41,045 INFO:     Epoch: 83
2023-01-04 10:40:42,628 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40663748780886333, 'Total loss': 0.40663748780886333} | train loss {'Reaction outcome loss': 0.2728482698651858, 'Total loss': 0.2728482698651858}
2023-01-04 10:40:42,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:42,628 INFO:     Epoch: 84
2023-01-04 10:40:44,221 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4155052165190379, 'Total loss': 0.4155052165190379} | train loss {'Reaction outcome loss': 0.2690333098119347, 'Total loss': 0.2690333098119347}
2023-01-04 10:40:44,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:44,221 INFO:     Epoch: 85
2023-01-04 10:40:45,800 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39740753372510274, 'Total loss': 0.39740753372510274} | train loss {'Reaction outcome loss': 0.26755072429292037, 'Total loss': 0.26755072429292037}
2023-01-04 10:40:45,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:45,800 INFO:     Epoch: 86
2023-01-04 10:40:47,292 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4061297784248988, 'Total loss': 0.4061297784248988} | train loss {'Reaction outcome loss': 0.26953210719333226, 'Total loss': 0.26953210719333226}
2023-01-04 10:40:47,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:47,293 INFO:     Epoch: 87
2023-01-04 10:40:48,896 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40143309632937113, 'Total loss': 0.40143309632937113} | train loss {'Reaction outcome loss': 0.2683810694445772, 'Total loss': 0.2683810694445772}
2023-01-04 10:40:48,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:48,897 INFO:     Epoch: 88
2023-01-04 10:40:50,485 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40980953176816304, 'Total loss': 0.40980953176816304} | train loss {'Reaction outcome loss': 0.26419181188413815, 'Total loss': 0.26419181188413815}
2023-01-04 10:40:50,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:50,486 INFO:     Epoch: 89
2023-01-04 10:40:52,069 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40522005160649616, 'Total loss': 0.40522005160649616} | train loss {'Reaction outcome loss': 0.26293408032842924, 'Total loss': 0.26293408032842924}
2023-01-04 10:40:52,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:52,069 INFO:     Epoch: 90
2023-01-04 10:40:53,680 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4082986185948054, 'Total loss': 0.4082986185948054} | train loss {'Reaction outcome loss': 0.26239435205283146, 'Total loss': 0.26239435205283146}
2023-01-04 10:40:53,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:53,680 INFO:     Epoch: 91
2023-01-04 10:40:55,255 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38846195936203004, 'Total loss': 0.38846195936203004} | train loss {'Reaction outcome loss': 0.2632093978541422, 'Total loss': 0.2632093978541422}
2023-01-04 10:40:55,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:55,256 INFO:     Epoch: 92
2023-01-04 10:40:56,799 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44742160439491274, 'Total loss': 0.44742160439491274} | train loss {'Reaction outcome loss': 0.2594174851364177, 'Total loss': 0.2594174851364177}
2023-01-04 10:40:56,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:56,800 INFO:     Epoch: 93
2023-01-04 10:40:58,406 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4152160227298737, 'Total loss': 0.4152160227298737} | train loss {'Reaction outcome loss': 0.26618510015335756, 'Total loss': 0.26618510015335756}
2023-01-04 10:40:58,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:40:58,406 INFO:     Epoch: 94
2023-01-04 10:41:00,021 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4141843428214391, 'Total loss': 0.4141843428214391} | train loss {'Reaction outcome loss': 0.25566732471923104, 'Total loss': 0.25566732471923104}
2023-01-04 10:41:00,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:00,022 INFO:     Epoch: 95
2023-01-04 10:41:01,619 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40148097574710845, 'Total loss': 0.40148097574710845} | train loss {'Reaction outcome loss': 0.25575663020249306, 'Total loss': 0.25575663020249306}
2023-01-04 10:41:01,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:01,620 INFO:     Epoch: 96
2023-01-04 10:41:03,218 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3881132816274961, 'Total loss': 0.3881132816274961} | train loss {'Reaction outcome loss': 0.2569883122287072, 'Total loss': 0.2569883122287072}
2023-01-04 10:41:03,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:03,218 INFO:     Epoch: 97
2023-01-04 10:41:04,718 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3836408078670502, 'Total loss': 0.3836408078670502} | train loss {'Reaction outcome loss': 0.25986704081027945, 'Total loss': 0.25986704081027945}
2023-01-04 10:41:04,718 INFO:     Found new best model at epoch 97
2023-01-04 10:41:04,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:04,719 INFO:     Epoch: 98
2023-01-04 10:41:06,343 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.38510317305723823, 'Total loss': 0.38510317305723823} | train loss {'Reaction outcome loss': 0.2561206046747387, 'Total loss': 0.2561206046747387}
2023-01-04 10:41:06,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:06,343 INFO:     Epoch: 99
2023-01-04 10:41:07,925 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3883483688036601, 'Total loss': 0.3883483688036601} | train loss {'Reaction outcome loss': 0.25493865924137593, 'Total loss': 0.25493865924137593}
2023-01-04 10:41:07,926 INFO:     Best model found after epoch 98 of 100.
2023-01-04 10:41:07,926 INFO:   Done with stage: TRAINING
2023-01-04 10:41:07,926 INFO:   Starting stage: EVALUATION
2023-01-04 10:41:08,049 INFO:   Done with stage: EVALUATION
2023-01-04 10:41:08,049 INFO:   Leaving out SEQ value Fold_7
2023-01-04 10:41:08,062 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 10:41:08,062 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:41:08,720 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:41:08,720 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:41:08,789 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:41:08,789 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:41:08,789 INFO:     No hyperparam tuning for this model
2023-01-04 10:41:08,789 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:41:08,789 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:41:08,790 INFO:     None feature selector for col prot
2023-01-04 10:41:08,790 INFO:     None feature selector for col prot
2023-01-04 10:41:08,790 INFO:     None feature selector for col prot
2023-01-04 10:41:08,791 INFO:     None feature selector for col chem
2023-01-04 10:41:08,791 INFO:     None feature selector for col chem
2023-01-04 10:41:08,791 INFO:     None feature selector for col chem
2023-01-04 10:41:08,791 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:41:08,791 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:41:08,792 INFO:     Number of params in model 70111
2023-01-04 10:41:08,796 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:41:08,796 INFO:   Starting stage: TRAINING
2023-01-04 10:41:08,839 INFO:     Val loss before train {'Reaction outcome loss': 1.0198275844256084, 'Total loss': 1.0198275844256084}
2023-01-04 10:41:08,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:08,840 INFO:     Epoch: 0
2023-01-04 10:41:10,460 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8126765807469686, 'Total loss': 0.8126765807469686} | train loss {'Reaction outcome loss': 0.829794939782215, 'Total loss': 0.829794939782215}
2023-01-04 10:41:10,460 INFO:     Found new best model at epoch 0
2023-01-04 10:41:10,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:10,461 INFO:     Epoch: 1
2023-01-04 10:41:12,055 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6894214729468028, 'Total loss': 0.6894214729468028} | train loss {'Reaction outcome loss': 0.6682357962381108, 'Total loss': 0.6682357962381108}
2023-01-04 10:41:12,055 INFO:     Found new best model at epoch 1
2023-01-04 10:41:12,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:12,056 INFO:     Epoch: 2
2023-01-04 10:41:13,553 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6639310419559479, 'Total loss': 0.6639310419559479} | train loss {'Reaction outcome loss': 0.5761263092932718, 'Total loss': 0.5761263092932718}
2023-01-04 10:41:13,553 INFO:     Found new best model at epoch 2
2023-01-04 10:41:13,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:13,554 INFO:     Epoch: 3
2023-01-04 10:41:15,164 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6362943251927694, 'Total loss': 0.6362943251927694} | train loss {'Reaction outcome loss': 0.5362726920133033, 'Total loss': 0.5362726920133033}
2023-01-04 10:41:15,164 INFO:     Found new best model at epoch 3
2023-01-04 10:41:15,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:15,165 INFO:     Epoch: 4
2023-01-04 10:41:16,757 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6039077421029408, 'Total loss': 0.6039077421029408} | train loss {'Reaction outcome loss': 0.5152568569682565, 'Total loss': 0.5152568569682565}
2023-01-04 10:41:16,758 INFO:     Found new best model at epoch 4
2023-01-04 10:41:16,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:16,758 INFO:     Epoch: 5
2023-01-04 10:41:18,375 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.594987674554189, 'Total loss': 0.594987674554189} | train loss {'Reaction outcome loss': 0.4972933779877446, 'Total loss': 0.4972933779877446}
2023-01-04 10:41:18,376 INFO:     Found new best model at epoch 5
2023-01-04 10:41:18,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:18,376 INFO:     Epoch: 6
2023-01-04 10:41:19,977 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5716328173875809, 'Total loss': 0.5716328173875809} | train loss {'Reaction outcome loss': 0.4891685041387159, 'Total loss': 0.4891685041387159}
2023-01-04 10:41:19,977 INFO:     Found new best model at epoch 6
2023-01-04 10:41:19,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:19,978 INFO:     Epoch: 7
2023-01-04 10:41:21,569 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5769673844178518, 'Total loss': 0.5769673844178518} | train loss {'Reaction outcome loss': 0.4803956815374457, 'Total loss': 0.4803956815374457}
2023-01-04 10:41:21,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:21,569 INFO:     Epoch: 8
2023-01-04 10:41:23,053 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5848930915196736, 'Total loss': 0.5848930915196736} | train loss {'Reaction outcome loss': 0.4709412196267813, 'Total loss': 0.4709412196267813}
2023-01-04 10:41:23,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:23,053 INFO:     Epoch: 9
2023-01-04 10:41:24,644 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5871911307175954, 'Total loss': 0.5871911307175954} | train loss {'Reaction outcome loss': 0.46508071294545267, 'Total loss': 0.46508071294545267}
2023-01-04 10:41:24,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:24,644 INFO:     Epoch: 10
2023-01-04 10:41:26,248 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5855191330115, 'Total loss': 0.5855191330115} | train loss {'Reaction outcome loss': 0.46170623842559566, 'Total loss': 0.46170623842559566}
2023-01-04 10:41:26,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:26,250 INFO:     Epoch: 11
2023-01-04 10:41:27,850 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5635559678077697, 'Total loss': 0.5635559678077697} | train loss {'Reaction outcome loss': 0.453131123462739, 'Total loss': 0.453131123462739}
2023-01-04 10:41:27,851 INFO:     Found new best model at epoch 11
2023-01-04 10:41:27,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:27,851 INFO:     Epoch: 12
2023-01-04 10:41:29,456 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5436662554740905, 'Total loss': 0.5436662554740905} | train loss {'Reaction outcome loss': 0.4479468770943824, 'Total loss': 0.4479468770943824}
2023-01-04 10:41:29,456 INFO:     Found new best model at epoch 12
2023-01-04 10:41:29,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:29,457 INFO:     Epoch: 13
2023-01-04 10:41:31,064 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5474404752254486, 'Total loss': 0.5474404752254486} | train loss {'Reaction outcome loss': 0.4471433289913925, 'Total loss': 0.4471433289913925}
2023-01-04 10:41:31,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:31,064 INFO:     Epoch: 14
2023-01-04 10:41:32,561 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5424274543921153, 'Total loss': 0.5424274543921153} | train loss {'Reaction outcome loss': 0.4427681321594259, 'Total loss': 0.4427681321594259}
2023-01-04 10:41:32,562 INFO:     Found new best model at epoch 14
2023-01-04 10:41:32,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:32,563 INFO:     Epoch: 15
2023-01-04 10:41:34,174 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5280893156925838, 'Total loss': 0.5280893156925838} | train loss {'Reaction outcome loss': 0.4336225934837699, 'Total loss': 0.4336225934837699}
2023-01-04 10:41:34,174 INFO:     Found new best model at epoch 15
2023-01-04 10:41:34,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:34,175 INFO:     Epoch: 16
2023-01-04 10:41:35,777 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5319106837113698, 'Total loss': 0.5319106837113698} | train loss {'Reaction outcome loss': 0.4326592102808212, 'Total loss': 0.4326592102808212}
2023-01-04 10:41:35,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:35,778 INFO:     Epoch: 17
2023-01-04 10:41:37,387 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5622596263885498, 'Total loss': 0.5622596263885498} | train loss {'Reaction outcome loss': 0.42737110018299806, 'Total loss': 0.42737110018299806}
2023-01-04 10:41:37,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:37,387 INFO:     Epoch: 18
2023-01-04 10:41:38,980 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5466991285483043, 'Total loss': 0.5466991285483043} | train loss {'Reaction outcome loss': 0.4253677376394668, 'Total loss': 0.4253677376394668}
2023-01-04 10:41:38,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:38,980 INFO:     Epoch: 19
2023-01-04 10:41:40,495 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5210040807723999, 'Total loss': 0.5210040807723999} | train loss {'Reaction outcome loss': 0.4184887566560012, 'Total loss': 0.4184887566560012}
2023-01-04 10:41:40,495 INFO:     Found new best model at epoch 19
2023-01-04 10:41:40,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:40,496 INFO:     Epoch: 20
2023-01-04 10:41:42,097 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5417780041694641, 'Total loss': 0.5417780041694641} | train loss {'Reaction outcome loss': 0.41667510230188337, 'Total loss': 0.41667510230188337}
2023-01-04 10:41:42,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:42,097 INFO:     Epoch: 21
2023-01-04 10:41:43,693 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5076521694660187, 'Total loss': 0.5076521694660187} | train loss {'Reaction outcome loss': 0.41338392166884796, 'Total loss': 0.41338392166884796}
2023-01-04 10:41:43,693 INFO:     Found new best model at epoch 21
2023-01-04 10:41:43,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:43,694 INFO:     Epoch: 22
2023-01-04 10:41:45,276 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.521083261569341, 'Total loss': 0.521083261569341} | train loss {'Reaction outcome loss': 0.4084025400855481, 'Total loss': 0.4084025400855481}
2023-01-04 10:41:45,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:45,277 INFO:     Epoch: 23
2023-01-04 10:41:46,893 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.514638998111089, 'Total loss': 0.514638998111089} | train loss {'Reaction outcome loss': 0.4016571869058299, 'Total loss': 0.4016571869058299}
2023-01-04 10:41:46,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:46,894 INFO:     Epoch: 24
2023-01-04 10:41:48,516 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5177056610584259, 'Total loss': 0.5177056610584259} | train loss {'Reaction outcome loss': 0.40121486648540633, 'Total loss': 0.40121486648540633}
2023-01-04 10:41:48,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:48,516 INFO:     Epoch: 25
2023-01-04 10:41:50,018 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49348655293385185, 'Total loss': 0.49348655293385185} | train loss {'Reaction outcome loss': 0.3972912528669791, 'Total loss': 0.3972912528669791}
2023-01-04 10:41:50,018 INFO:     Found new best model at epoch 25
2023-01-04 10:41:50,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:50,019 INFO:     Epoch: 26
2023-01-04 10:41:51,615 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5299152831236521, 'Total loss': 0.5299152831236521} | train loss {'Reaction outcome loss': 0.3923697823436682, 'Total loss': 0.3923697823436682}
2023-01-04 10:41:51,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:51,615 INFO:     Epoch: 27
2023-01-04 10:41:53,214 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5024506290753682, 'Total loss': 0.5024506290753682} | train loss {'Reaction outcome loss': 0.3899231665239868, 'Total loss': 0.3899231665239868}
2023-01-04 10:41:53,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:53,214 INFO:     Epoch: 28
2023-01-04 10:41:54,828 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48924920757611595, 'Total loss': 0.48924920757611595} | train loss {'Reaction outcome loss': 0.39116215560625606, 'Total loss': 0.39116215560625606}
2023-01-04 10:41:54,828 INFO:     Found new best model at epoch 28
2023-01-04 10:41:54,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:54,829 INFO:     Epoch: 29
2023-01-04 10:41:56,417 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5282206197579702, 'Total loss': 0.5282206197579702} | train loss {'Reaction outcome loss': 0.3858068652908294, 'Total loss': 0.3858068652908294}
2023-01-04 10:41:56,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:56,417 INFO:     Epoch: 30
2023-01-04 10:41:58,002 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.523888639609019, 'Total loss': 0.523888639609019} | train loss {'Reaction outcome loss': 0.3807779203575871, 'Total loss': 0.3807779203575871}
2023-01-04 10:41:58,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:58,002 INFO:     Epoch: 31
2023-01-04 10:41:59,501 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5019807716210684, 'Total loss': 0.5019807716210684} | train loss {'Reaction outcome loss': 0.38025329011872355, 'Total loss': 0.38025329011872355}
2023-01-04 10:41:59,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:41:59,501 INFO:     Epoch: 32
2023-01-04 10:42:01,113 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5266396482785543, 'Total loss': 0.5266396482785543} | train loss {'Reaction outcome loss': 0.37519660169789937, 'Total loss': 0.37519660169789937}
2023-01-04 10:42:01,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:01,115 INFO:     Epoch: 33
2023-01-04 10:42:02,732 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5202291150887807, 'Total loss': 0.5202291150887807} | train loss {'Reaction outcome loss': 0.3718426338655854, 'Total loss': 0.3718426338655854}
2023-01-04 10:42:02,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:02,732 INFO:     Epoch: 34
2023-01-04 10:42:04,341 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5053315142790477, 'Total loss': 0.5053315142790477} | train loss {'Reaction outcome loss': 0.36826410300572426, 'Total loss': 0.36826410300572426}
2023-01-04 10:42:04,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:04,341 INFO:     Epoch: 35
2023-01-04 10:42:05,953 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47548022369543713, 'Total loss': 0.47548022369543713} | train loss {'Reaction outcome loss': 0.3662765491417599, 'Total loss': 0.3662765491417599}
2023-01-04 10:42:05,953 INFO:     Found new best model at epoch 35
2023-01-04 10:42:05,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:05,954 INFO:     Epoch: 36
2023-01-04 10:42:07,577 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4694812953472137, 'Total loss': 0.4694812953472137} | train loss {'Reaction outcome loss': 0.36235589122514, 'Total loss': 0.36235589122514}
2023-01-04 10:42:07,577 INFO:     Found new best model at epoch 36
2023-01-04 10:42:07,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:07,578 INFO:     Epoch: 37
2023-01-04 10:42:09,070 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49292428493499757, 'Total loss': 0.49292428493499757} | train loss {'Reaction outcome loss': 0.35901388603965295, 'Total loss': 0.35901388603965295}
2023-01-04 10:42:09,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:09,071 INFO:     Epoch: 38
2023-01-04 10:42:10,638 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4611853301525116, 'Total loss': 0.4611853301525116} | train loss {'Reaction outcome loss': 0.35273380313969693, 'Total loss': 0.35273380313969693}
2023-01-04 10:42:10,638 INFO:     Found new best model at epoch 38
2023-01-04 10:42:10,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:10,639 INFO:     Epoch: 39
2023-01-04 10:42:12,224 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5314915676911672, 'Total loss': 0.5314915676911672} | train loss {'Reaction outcome loss': 0.3506572572548037, 'Total loss': 0.3506572572548037}
2023-01-04 10:42:12,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:12,225 INFO:     Epoch: 40
2023-01-04 10:42:13,816 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5094380597273509, 'Total loss': 0.5094380597273509} | train loss {'Reaction outcome loss': 0.3546456416483821, 'Total loss': 0.3546456416483821}
2023-01-04 10:42:13,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:13,816 INFO:     Epoch: 41
2023-01-04 10:42:15,401 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5504197140534719, 'Total loss': 0.5504197140534719} | train loss {'Reaction outcome loss': 0.34804793995963107, 'Total loss': 0.34804793995963107}
2023-01-04 10:42:15,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:15,401 INFO:     Epoch: 42
2023-01-04 10:42:16,916 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4517780105272929, 'Total loss': 0.4517780105272929} | train loss {'Reaction outcome loss': 0.34594882631990453, 'Total loss': 0.34594882631990453}
2023-01-04 10:42:16,916 INFO:     Found new best model at epoch 42
2023-01-04 10:42:16,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:16,917 INFO:     Epoch: 43
2023-01-04 10:42:18,497 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4633852541446686, 'Total loss': 0.4633852541446686} | train loss {'Reaction outcome loss': 0.34603169563122177, 'Total loss': 0.34603169563122177}
2023-01-04 10:42:18,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:18,498 INFO:     Epoch: 44
2023-01-04 10:42:20,114 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.477481476465861, 'Total loss': 0.477481476465861} | train loss {'Reaction outcome loss': 0.3376210984447803, 'Total loss': 0.3376210984447803}
2023-01-04 10:42:20,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:20,115 INFO:     Epoch: 45
2023-01-04 10:42:21,713 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46951490739981333, 'Total loss': 0.46951490739981333} | train loss {'Reaction outcome loss': 0.3374969218773532, 'Total loss': 0.3374969218773532}
2023-01-04 10:42:21,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:21,713 INFO:     Epoch: 46
2023-01-04 10:42:23,300 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.495307848850886, 'Total loss': 0.495307848850886} | train loss {'Reaction outcome loss': 0.3355828697796548, 'Total loss': 0.3355828697796548}
2023-01-04 10:42:23,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:23,300 INFO:     Epoch: 47
2023-01-04 10:42:24,894 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4813548515240351, 'Total loss': 0.4813548515240351} | train loss {'Reaction outcome loss': 0.33703990944994056, 'Total loss': 0.33703990944994056}
2023-01-04 10:42:24,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:24,895 INFO:     Epoch: 48
2023-01-04 10:42:26,332 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45904768705368043, 'Total loss': 0.45904768705368043} | train loss {'Reaction outcome loss': 0.33213742983793093, 'Total loss': 0.33213742983793093}
2023-01-04 10:42:26,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:26,333 INFO:     Epoch: 49
2023-01-04 10:42:27,928 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46309678455193837, 'Total loss': 0.46309678455193837} | train loss {'Reaction outcome loss': 0.3294298529947708, 'Total loss': 0.3294298529947708}
2023-01-04 10:42:27,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:27,928 INFO:     Epoch: 50
2023-01-04 10:42:29,507 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48349332213401797, 'Total loss': 0.48349332213401797} | train loss {'Reaction outcome loss': 0.3270156073118375, 'Total loss': 0.3270156073118375}
2023-01-04 10:42:29,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:29,507 INFO:     Epoch: 51
2023-01-04 10:42:31,137 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46299433906873066, 'Total loss': 0.46299433906873066} | train loss {'Reaction outcome loss': 0.3231580409924046, 'Total loss': 0.3231580409924046}
2023-01-04 10:42:31,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:31,138 INFO:     Epoch: 52
2023-01-04 10:42:32,751 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4526523510615031, 'Total loss': 0.4526523510615031} | train loss {'Reaction outcome loss': 0.32288627353385896, 'Total loss': 0.32288627353385896}
2023-01-04 10:42:32,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:32,751 INFO:     Epoch: 53
2023-01-04 10:42:34,365 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45643025636672974, 'Total loss': 0.45643025636672974} | train loss {'Reaction outcome loss': 0.3207569990831592, 'Total loss': 0.3207569990831592}
2023-01-04 10:42:34,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:34,365 INFO:     Epoch: 54
2023-01-04 10:42:35,855 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.461025196313858, 'Total loss': 0.461025196313858} | train loss {'Reaction outcome loss': 0.3171565028358022, 'Total loss': 0.3171565028358022}
2023-01-04 10:42:35,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:35,855 INFO:     Epoch: 55
2023-01-04 10:42:37,472 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4422432899475098, 'Total loss': 0.4422432899475098} | train loss {'Reaction outcome loss': 0.3175906720251813, 'Total loss': 0.3175906720251813}
2023-01-04 10:42:37,473 INFO:     Found new best model at epoch 55
2023-01-04 10:42:37,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:37,474 INFO:     Epoch: 56
2023-01-04 10:42:39,066 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48444147904713947, 'Total loss': 0.48444147904713947} | train loss {'Reaction outcome loss': 0.30940225779579866, 'Total loss': 0.30940225779579866}
2023-01-04 10:42:39,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:39,067 INFO:     Epoch: 57
2023-01-04 10:42:40,666 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4617379456758499, 'Total loss': 0.4617379456758499} | train loss {'Reaction outcome loss': 0.3110138451956239, 'Total loss': 0.3110138451956239}
2023-01-04 10:42:40,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:40,667 INFO:     Epoch: 58
2023-01-04 10:42:42,277 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4682743072509766, 'Total loss': 0.4682743072509766} | train loss {'Reaction outcome loss': 0.31403532290716896, 'Total loss': 0.31403532290716896}
2023-01-04 10:42:42,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:42,278 INFO:     Epoch: 59
2023-01-04 10:42:43,894 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46108139753341676, 'Total loss': 0.46108139753341676} | train loss {'Reaction outcome loss': 0.3079404513812237, 'Total loss': 0.3079404513812237}
2023-01-04 10:42:43,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:43,895 INFO:     Epoch: 60
2023-01-04 10:42:45,391 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44275522927443184, 'Total loss': 0.44275522927443184} | train loss {'Reaction outcome loss': 0.3037141817436967, 'Total loss': 0.3037141817436967}
2023-01-04 10:42:45,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:45,392 INFO:     Epoch: 61
2023-01-04 10:42:47,000 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4535416861375173, 'Total loss': 0.4535416861375173} | train loss {'Reaction outcome loss': 0.3014780857233795, 'Total loss': 0.3014780857233795}
2023-01-04 10:42:47,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:47,000 INFO:     Epoch: 62
2023-01-04 10:42:48,624 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47268682916959126, 'Total loss': 0.47268682916959126} | train loss {'Reaction outcome loss': 0.30103778232574896, 'Total loss': 0.30103778232574896}
2023-01-04 10:42:48,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:48,624 INFO:     Epoch: 63
2023-01-04 10:42:50,237 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4424678315718969, 'Total loss': 0.4424678315718969} | train loss {'Reaction outcome loss': 0.30400089136852687, 'Total loss': 0.30400089136852687}
2023-01-04 10:42:50,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:50,237 INFO:     Epoch: 64
2023-01-04 10:42:51,798 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4099234720071157, 'Total loss': 0.4099234720071157} | train loss {'Reaction outcome loss': 0.3021771480675639, 'Total loss': 0.3021771480675639}
2023-01-04 10:42:51,799 INFO:     Found new best model at epoch 64
2023-01-04 10:42:51,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:51,799 INFO:     Epoch: 65
2023-01-04 10:42:53,308 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4399612675110499, 'Total loss': 0.4399612675110499} | train loss {'Reaction outcome loss': 0.2934434769762552, 'Total loss': 0.2934434769762552}
2023-01-04 10:42:53,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:53,308 INFO:     Epoch: 66
2023-01-04 10:42:54,338 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48800663352012635, 'Total loss': 0.48800663352012635} | train loss {'Reaction outcome loss': 0.2978222207956366, 'Total loss': 0.2978222207956366}
2023-01-04 10:42:54,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:54,339 INFO:     Epoch: 67
2023-01-04 10:42:55,368 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46849918365478516, 'Total loss': 0.46849918365478516} | train loss {'Reaction outcome loss': 0.2925661461232802, 'Total loss': 0.2925661461232802}
2023-01-04 10:42:55,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:55,368 INFO:     Epoch: 68
2023-01-04 10:42:56,397 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4354008972644806, 'Total loss': 0.4354008972644806} | train loss {'Reaction outcome loss': 0.29072668400697327, 'Total loss': 0.29072668400697327}
2023-01-04 10:42:56,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:56,398 INFO:     Epoch: 69
2023-01-04 10:42:57,424 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.469013108809789, 'Total loss': 0.469013108809789} | train loss {'Reaction outcome loss': 0.2927756383746109, 'Total loss': 0.2927756383746109}
2023-01-04 10:42:57,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:57,425 INFO:     Epoch: 70
2023-01-04 10:42:58,972 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4442604680856069, 'Total loss': 0.4442604680856069} | train loss {'Reaction outcome loss': 0.290487312264606, 'Total loss': 0.290487312264606}
2023-01-04 10:42:58,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:42:58,972 INFO:     Epoch: 71
2023-01-04 10:43:00,519 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4604000081618627, 'Total loss': 0.4604000081618627} | train loss {'Reaction outcome loss': 0.2893399844746297, 'Total loss': 0.2893399844746297}
2023-01-04 10:43:00,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:00,519 INFO:     Epoch: 72
2023-01-04 10:43:02,126 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45547447899977367, 'Total loss': 0.45547447899977367} | train loss {'Reaction outcome loss': 0.2853359157481779, 'Total loss': 0.2853359157481779}
2023-01-04 10:43:02,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:02,127 INFO:     Epoch: 73
2023-01-04 10:43:03,725 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4386522928873698, 'Total loss': 0.4386522928873698} | train loss {'Reaction outcome loss': 0.28185331383013984, 'Total loss': 0.28185331383013984}
2023-01-04 10:43:03,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:03,725 INFO:     Epoch: 74
2023-01-04 10:43:05,333 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49745838940143583, 'Total loss': 0.49745838940143583} | train loss {'Reaction outcome loss': 0.2800193554604097, 'Total loss': 0.2800193554604097}
2023-01-04 10:43:05,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:05,333 INFO:     Epoch: 75
2023-01-04 10:43:06,883 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4257577409346898, 'Total loss': 0.4257577409346898} | train loss {'Reaction outcome loss': 0.2849914904159329, 'Total loss': 0.2849914904159329}
2023-01-04 10:43:06,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:06,883 INFO:     Epoch: 76
2023-01-04 10:43:08,478 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44295921524365744, 'Total loss': 0.44295921524365744} | train loss {'Reaction outcome loss': 0.2802103940222668, 'Total loss': 0.2802103940222668}
2023-01-04 10:43:08,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:08,478 INFO:     Epoch: 77
2023-01-04 10:43:10,023 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4543653607368469, 'Total loss': 0.4543653607368469} | train loss {'Reaction outcome loss': 0.2827360523387198, 'Total loss': 0.2827360523387198}
2023-01-04 10:43:10,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:10,024 INFO:     Epoch: 78
2023-01-04 10:43:11,576 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5137865593036016, 'Total loss': 0.5137865593036016} | train loss {'Reaction outcome loss': 0.2756727896227303, 'Total loss': 0.2756727896227303}
2023-01-04 10:43:11,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:11,576 INFO:     Epoch: 79
2023-01-04 10:43:13,149 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46953725119431816, 'Total loss': 0.46953725119431816} | train loss {'Reaction outcome loss': 0.2770125854235909, 'Total loss': 0.2770125854235909}
2023-01-04 10:43:13,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:13,149 INFO:     Epoch: 80
2023-01-04 10:43:14,714 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45102895696957906, 'Total loss': 0.45102895696957906} | train loss {'Reaction outcome loss': 0.27611485911728245, 'Total loss': 0.27611485911728245}
2023-01-04 10:43:14,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:14,714 INFO:     Epoch: 81
2023-01-04 10:43:16,235 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4240056057771047, 'Total loss': 0.4240056057771047} | train loss {'Reaction outcome loss': 0.2761097886071739, 'Total loss': 0.2761097886071739}
2023-01-04 10:43:16,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:16,235 INFO:     Epoch: 82
2023-01-04 10:43:17,846 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4338380962610245, 'Total loss': 0.4338380962610245} | train loss {'Reaction outcome loss': 0.2692255858829521, 'Total loss': 0.2692255858829521}
2023-01-04 10:43:17,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:17,847 INFO:     Epoch: 83
2023-01-04 10:43:19,389 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4230365703503291, 'Total loss': 0.4230365703503291} | train loss {'Reaction outcome loss': 0.2756390506771497, 'Total loss': 0.2756390506771497}
2023-01-04 10:43:19,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:19,389 INFO:     Epoch: 84
2023-01-04 10:43:21,013 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4472658733526866, 'Total loss': 0.4472658733526866} | train loss {'Reaction outcome loss': 0.2715111016581635, 'Total loss': 0.2715111016581635}
2023-01-04 10:43:21,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:21,013 INFO:     Epoch: 85
2023-01-04 10:43:22,593 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.447669126590093, 'Total loss': 0.447669126590093} | train loss {'Reaction outcome loss': 0.2706757674686315, 'Total loss': 0.2706757674686315}
2023-01-04 10:43:22,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:22,593 INFO:     Epoch: 86
2023-01-04 10:43:24,188 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46181912819544474, 'Total loss': 0.46181912819544474} | train loss {'Reaction outcome loss': 0.27031628665134366, 'Total loss': 0.27031628665134366}
2023-01-04 10:43:24,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:24,188 INFO:     Epoch: 87
2023-01-04 10:43:25,750 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4233307848374049, 'Total loss': 0.4233307848374049} | train loss {'Reaction outcome loss': 0.26937871886289505, 'Total loss': 0.26937871886289505}
2023-01-04 10:43:25,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:25,750 INFO:     Epoch: 88
2023-01-04 10:43:27,314 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4391491740942001, 'Total loss': 0.4391491740942001} | train loss {'Reaction outcome loss': 0.266706534725234, 'Total loss': 0.266706534725234}
2023-01-04 10:43:27,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:27,314 INFO:     Epoch: 89
2023-01-04 10:43:28,888 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4452773183584213, 'Total loss': 0.4452773183584213} | train loss {'Reaction outcome loss': 0.2684578989709758, 'Total loss': 0.2684578989709758}
2023-01-04 10:43:28,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:28,889 INFO:     Epoch: 90
2023-01-04 10:43:30,484 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4604203353325526, 'Total loss': 0.4604203353325526} | train loss {'Reaction outcome loss': 0.26692224887034954, 'Total loss': 0.26692224887034954}
2023-01-04 10:43:30,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:30,484 INFO:     Epoch: 91
2023-01-04 10:43:32,059 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45762230157852174, 'Total loss': 0.45762230157852174} | train loss {'Reaction outcome loss': 0.26394119616665135, 'Total loss': 0.26394119616665135}
2023-01-04 10:43:32,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:32,059 INFO:     Epoch: 92
2023-01-04 10:43:33,644 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4175672471523285, 'Total loss': 0.4175672471523285} | train loss {'Reaction outcome loss': 0.26688159231621006, 'Total loss': 0.26688159231621006}
2023-01-04 10:43:33,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:33,644 INFO:     Epoch: 93
2023-01-04 10:43:35,213 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4485425700743993, 'Total loss': 0.4485425700743993} | train loss {'Reaction outcome loss': 0.2644331886127107, 'Total loss': 0.2644331886127107}
2023-01-04 10:43:35,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:35,213 INFO:     Epoch: 94
2023-01-04 10:43:36,798 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44512889881928763, 'Total loss': 0.44512889881928763} | train loss {'Reaction outcome loss': 0.26303900529492635, 'Total loss': 0.26303900529492635}
2023-01-04 10:43:36,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:36,798 INFO:     Epoch: 95
2023-01-04 10:43:38,411 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42763522565364837, 'Total loss': 0.42763522565364837} | train loss {'Reaction outcome loss': 0.2619109350905522, 'Total loss': 0.2619109350905522}
2023-01-04 10:43:38,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:38,411 INFO:     Epoch: 96
2023-01-04 10:43:40,009 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4342775175968806, 'Total loss': 0.4342775175968806} | train loss {'Reaction outcome loss': 0.26099734220801707, 'Total loss': 0.26099734220801707}
2023-01-04 10:43:40,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:40,009 INFO:     Epoch: 97
2023-01-04 10:43:41,617 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42210892339547473, 'Total loss': 0.42210892339547473} | train loss {'Reaction outcome loss': 0.2610227440211532, 'Total loss': 0.2610227440211532}
2023-01-04 10:43:41,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:41,618 INFO:     Epoch: 98
2023-01-04 10:43:43,199 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4278684298197428, 'Total loss': 0.4278684298197428} | train loss {'Reaction outcome loss': 0.26398679124534347, 'Total loss': 0.26398679124534347}
2023-01-04 10:43:43,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:43,199 INFO:     Epoch: 99
2023-01-04 10:43:44,777 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42906803290049234, 'Total loss': 0.42906803290049234} | train loss {'Reaction outcome loss': 0.2610796603108571, 'Total loss': 0.2610796603108571}
2023-01-04 10:43:44,777 INFO:     Best model found after epoch 65 of 100.
2023-01-04 10:43:44,777 INFO:   Done with stage: TRAINING
2023-01-04 10:43:44,777 INFO:   Starting stage: EVALUATION
2023-01-04 10:43:44,900 INFO:   Done with stage: EVALUATION
2023-01-04 10:43:44,900 INFO:   Leaving out SEQ value Fold_8
2023-01-04 10:43:44,913 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 10:43:44,913 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:43:45,577 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:43:45,578 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:43:45,646 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:43:45,647 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:43:45,647 INFO:     No hyperparam tuning for this model
2023-01-04 10:43:45,647 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:43:45,647 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:43:45,647 INFO:     None feature selector for col prot
2023-01-04 10:43:45,648 INFO:     None feature selector for col prot
2023-01-04 10:43:45,648 INFO:     None feature selector for col prot
2023-01-04 10:43:45,648 INFO:     None feature selector for col chem
2023-01-04 10:43:45,648 INFO:     None feature selector for col chem
2023-01-04 10:43:45,648 INFO:     None feature selector for col chem
2023-01-04 10:43:45,648 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:43:45,648 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:43:45,649 INFO:     Number of params in model 70111
2023-01-04 10:43:45,653 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:43:45,653 INFO:   Starting stage: TRAINING
2023-01-04 10:43:45,696 INFO:     Val loss before train {'Reaction outcome loss': 0.9469320972760519, 'Total loss': 0.9469320972760519}
2023-01-04 10:43:45,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:45,696 INFO:     Epoch: 0
2023-01-04 10:43:47,278 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7047605752944947, 'Total loss': 0.7047605752944947} | train loss {'Reaction outcome loss': 0.8314596132199833, 'Total loss': 0.8314596132199833}
2023-01-04 10:43:47,279 INFO:     Found new best model at epoch 0
2023-01-04 10:43:47,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:47,279 INFO:     Epoch: 1
2023-01-04 10:43:48,854 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.595890098810196, 'Total loss': 0.595890098810196} | train loss {'Reaction outcome loss': 0.6790922844809466, 'Total loss': 0.6790922844809466}
2023-01-04 10:43:48,855 INFO:     Found new best model at epoch 1
2023-01-04 10:43:48,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:48,855 INFO:     Epoch: 2
2023-01-04 10:43:50,430 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5634000460306804, 'Total loss': 0.5634000460306804} | train loss {'Reaction outcome loss': 0.5787824615296246, 'Total loss': 0.5787824615296246}
2023-01-04 10:43:50,430 INFO:     Found new best model at epoch 2
2023-01-04 10:43:50,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:50,431 INFO:     Epoch: 3
2023-01-04 10:43:51,987 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5385364949703216, 'Total loss': 0.5385364949703216} | train loss {'Reaction outcome loss': 0.5436163080343301, 'Total loss': 0.5436163080343301}
2023-01-04 10:43:51,987 INFO:     Found new best model at epoch 3
2023-01-04 10:43:51,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:51,988 INFO:     Epoch: 4
2023-01-04 10:43:53,572 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5473708629608154, 'Total loss': 0.5473708629608154} | train loss {'Reaction outcome loss': 0.5242253426408422, 'Total loss': 0.5242253426408422}
2023-01-04 10:43:53,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:53,572 INFO:     Epoch: 5
2023-01-04 10:43:55,110 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5019587218761444, 'Total loss': 0.5019587218761444} | train loss {'Reaction outcome loss': 0.49689590596012684, 'Total loss': 0.49689590596012684}
2023-01-04 10:43:55,110 INFO:     Found new best model at epoch 5
2023-01-04 10:43:55,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:55,111 INFO:     Epoch: 6
2023-01-04 10:43:56,679 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5051482180754344, 'Total loss': 0.5051482180754344} | train loss {'Reaction outcome loss': 0.5024525153896083, 'Total loss': 0.5024525153896083}
2023-01-04 10:43:56,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:56,679 INFO:     Epoch: 7
2023-01-04 10:43:58,246 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4948622117439906, 'Total loss': 0.4948622117439906} | train loss {'Reaction outcome loss': 0.5408309161649558, 'Total loss': 0.5408309161649558}
2023-01-04 10:43:58,247 INFO:     Found new best model at epoch 7
2023-01-04 10:43:58,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:58,247 INFO:     Epoch: 8
2023-01-04 10:43:59,830 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49654159347216287, 'Total loss': 0.49654159347216287} | train loss {'Reaction outcome loss': 0.4808901825894861, 'Total loss': 0.4808901825894861}
2023-01-04 10:43:59,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:43:59,831 INFO:     Epoch: 9
2023-01-04 10:44:01,379 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4698806683222453, 'Total loss': 0.4698806683222453} | train loss {'Reaction outcome loss': 0.4680876101087104, 'Total loss': 0.4680876101087104}
2023-01-04 10:44:01,380 INFO:     Found new best model at epoch 9
2023-01-04 10:44:01,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:01,380 INFO:     Epoch: 10
2023-01-04 10:44:02,977 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47223320802052815, 'Total loss': 0.47223320802052815} | train loss {'Reaction outcome loss': 0.462204394136569, 'Total loss': 0.462204394136569}
2023-01-04 10:44:02,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:02,977 INFO:     Epoch: 11
2023-01-04 10:44:04,536 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4795528054237366, 'Total loss': 0.4795528054237366} | train loss {'Reaction outcome loss': 0.4690888835306185, 'Total loss': 0.4690888835306185}
2023-01-04 10:44:04,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:04,536 INFO:     Epoch: 12
2023-01-04 10:44:06,146 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4776047726472219, 'Total loss': 0.4776047726472219} | train loss {'Reaction outcome loss': 0.4736721397637376, 'Total loss': 0.4736721397637376}
2023-01-04 10:44:06,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:06,146 INFO:     Epoch: 13
2023-01-04 10:44:07,755 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.477073742945989, 'Total loss': 0.477073742945989} | train loss {'Reaction outcome loss': 0.4522101563819941, 'Total loss': 0.4522101563819941}
2023-01-04 10:44:07,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:07,755 INFO:     Epoch: 14
2023-01-04 10:44:09,360 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45478104054927826, 'Total loss': 0.45478104054927826} | train loss {'Reaction outcome loss': 0.44528404655324616, 'Total loss': 0.44528404655324616}
2023-01-04 10:44:09,360 INFO:     Found new best model at epoch 14
2023-01-04 10:44:09,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:09,361 INFO:     Epoch: 15
2023-01-04 10:44:10,909 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4718190332253774, 'Total loss': 0.4718190332253774} | train loss {'Reaction outcome loss': 0.4370122966559037, 'Total loss': 0.4370122966559037}
2023-01-04 10:44:10,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:10,910 INFO:     Epoch: 16
2023-01-04 10:44:12,490 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4498748371998469, 'Total loss': 0.4498748371998469} | train loss {'Reaction outcome loss': 0.4367039042467629, 'Total loss': 0.4367039042467629}
2023-01-04 10:44:12,490 INFO:     Found new best model at epoch 16
2023-01-04 10:44:12,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:12,491 INFO:     Epoch: 17
2023-01-04 10:44:14,079 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45739262700080874, 'Total loss': 0.45739262700080874} | train loss {'Reaction outcome loss': 0.4322931877155181, 'Total loss': 0.4322931877155181}
2023-01-04 10:44:14,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:14,080 INFO:     Epoch: 18
2023-01-04 10:44:15,690 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44286032517751056, 'Total loss': 0.44286032517751056} | train loss {'Reaction outcome loss': 0.43064523858787573, 'Total loss': 0.43064523858787573}
2023-01-04 10:44:15,690 INFO:     Found new best model at epoch 18
2023-01-04 10:44:15,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:15,691 INFO:     Epoch: 19
2023-01-04 10:44:17,291 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44661664962768555, 'Total loss': 0.44661664962768555} | train loss {'Reaction outcome loss': 0.4243371463988138, 'Total loss': 0.4243371463988138}
2023-01-04 10:44:17,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:17,293 INFO:     Epoch: 20
2023-01-04 10:44:18,900 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4418908874193827, 'Total loss': 0.4418908874193827} | train loss {'Reaction outcome loss': 0.4290259588877603, 'Total loss': 0.4290259588877603}
2023-01-04 10:44:18,900 INFO:     Found new best model at epoch 20
2023-01-04 10:44:18,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:18,901 INFO:     Epoch: 21
2023-01-04 10:44:20,460 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45713356137275696, 'Total loss': 0.45713356137275696} | train loss {'Reaction outcome loss': 0.41522850395185873, 'Total loss': 0.41522850395185873}
2023-01-04 10:44:20,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:20,461 INFO:     Epoch: 22
2023-01-04 10:44:22,009 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4611718773841858, 'Total loss': 0.4611718773841858} | train loss {'Reaction outcome loss': 0.4142857773087757, 'Total loss': 0.4142857773087757}
2023-01-04 10:44:22,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:22,009 INFO:     Epoch: 23
2023-01-04 10:44:23,604 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4461136301358541, 'Total loss': 0.4461136301358541} | train loss {'Reaction outcome loss': 0.40981342960151157, 'Total loss': 0.40981342960151157}
2023-01-04 10:44:23,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:23,605 INFO:     Epoch: 24
2023-01-04 10:44:25,191 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4312178701162338, 'Total loss': 0.4312178701162338} | train loss {'Reaction outcome loss': 0.40828992566768674, 'Total loss': 0.40828992566768674}
2023-01-04 10:44:25,192 INFO:     Found new best model at epoch 24
2023-01-04 10:44:25,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:25,192 INFO:     Epoch: 25
2023-01-04 10:44:26,789 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44644790689150493, 'Total loss': 0.44644790689150493} | train loss {'Reaction outcome loss': 0.40612555222342844, 'Total loss': 0.40612555222342844}
2023-01-04 10:44:26,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:26,790 INFO:     Epoch: 26
2023-01-04 10:44:28,349 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4337389379739761, 'Total loss': 0.4337389379739761} | train loss {'Reaction outcome loss': 0.4022740520320941, 'Total loss': 0.4022740520320941}
2023-01-04 10:44:28,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:28,349 INFO:     Epoch: 27
2023-01-04 10:44:29,932 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4649219989776611, 'Total loss': 0.4649219989776611} | train loss {'Reaction outcome loss': 0.40970285899727943, 'Total loss': 0.40970285899727943}
2023-01-04 10:44:29,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:29,932 INFO:     Epoch: 28
2023-01-04 10:44:31,489 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42861169477303823, 'Total loss': 0.42861169477303823} | train loss {'Reaction outcome loss': 0.398587326223935, 'Total loss': 0.398587326223935}
2023-01-04 10:44:31,489 INFO:     Found new best model at epoch 28
2023-01-04 10:44:31,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:31,490 INFO:     Epoch: 29
2023-01-04 10:44:33,062 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43495270013809206, 'Total loss': 0.43495270013809206} | train loss {'Reaction outcome loss': 0.3917700798534181, 'Total loss': 0.3917700798534181}
2023-01-04 10:44:33,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:33,062 INFO:     Epoch: 30
2023-01-04 10:44:34,629 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4380020995934804, 'Total loss': 0.4380020995934804} | train loss {'Reaction outcome loss': 0.38982935596520646, 'Total loss': 0.38982935596520646}
2023-01-04 10:44:34,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:34,629 INFO:     Epoch: 31
2023-01-04 10:44:36,196 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4271656413873037, 'Total loss': 0.4271656413873037} | train loss {'Reaction outcome loss': 0.38845589019267895, 'Total loss': 0.38845589019267895}
2023-01-04 10:44:36,197 INFO:     Found new best model at epoch 31
2023-01-04 10:44:36,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:36,198 INFO:     Epoch: 32
2023-01-04 10:44:37,739 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41903560360272724, 'Total loss': 0.41903560360272724} | train loss {'Reaction outcome loss': 0.38472966891371785, 'Total loss': 0.38472966891371785}
2023-01-04 10:44:37,739 INFO:     Found new best model at epoch 32
2023-01-04 10:44:37,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:37,740 INFO:     Epoch: 33
2023-01-04 10:44:39,314 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44145564834276835, 'Total loss': 0.44145564834276835} | train loss {'Reaction outcome loss': 0.3823757960420588, 'Total loss': 0.3823757960420588}
2023-01-04 10:44:39,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:39,315 INFO:     Epoch: 34
2023-01-04 10:44:40,848 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43578640222549436, 'Total loss': 0.43578640222549436} | train loss {'Reaction outcome loss': 0.3914000758820254, 'Total loss': 0.3914000758820254}
2023-01-04 10:44:40,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:40,848 INFO:     Epoch: 35
2023-01-04 10:44:42,427 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4334964632987976, 'Total loss': 0.4334964632987976} | train loss {'Reaction outcome loss': 0.37528373554780864, 'Total loss': 0.37528373554780864}
2023-01-04 10:44:42,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:42,427 INFO:     Epoch: 36
2023-01-04 10:44:44,020 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4074518462022146, 'Total loss': 0.4074518462022146} | train loss {'Reaction outcome loss': 0.3741941212851932, 'Total loss': 0.3741941212851932}
2023-01-04 10:44:44,021 INFO:     Found new best model at epoch 36
2023-01-04 10:44:44,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:44,021 INFO:     Epoch: 37
2023-01-04 10:44:45,608 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4302162051200867, 'Total loss': 0.4302162051200867} | train loss {'Reaction outcome loss': 0.3655423923127524, 'Total loss': 0.3655423923127524}
2023-01-04 10:44:45,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:45,609 INFO:     Epoch: 38
2023-01-04 10:44:47,144 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4419595867395401, 'Total loss': 0.4419595867395401} | train loss {'Reaction outcome loss': 0.3836129580934842, 'Total loss': 0.3836129580934842}
2023-01-04 10:44:47,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:47,144 INFO:     Epoch: 39
2023-01-04 10:44:48,717 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4242307682832082, 'Total loss': 0.4242307682832082} | train loss {'Reaction outcome loss': 0.41232915301942197, 'Total loss': 0.41232915301942197}
2023-01-04 10:44:48,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:48,717 INFO:     Epoch: 40
2023-01-04 10:44:50,261 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40031809608141583, 'Total loss': 0.40031809608141583} | train loss {'Reaction outcome loss': 0.3612004921390284, 'Total loss': 0.3612004921390284}
2023-01-04 10:44:50,262 INFO:     Found new best model at epoch 40
2023-01-04 10:44:50,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:50,262 INFO:     Epoch: 41
2023-01-04 10:44:51,867 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.427084078391393, 'Total loss': 0.427084078391393} | train loss {'Reaction outcome loss': 0.37374072894454, 'Total loss': 0.37374072894454}
2023-01-04 10:44:51,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:51,867 INFO:     Epoch: 42
2023-01-04 10:44:53,467 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4111873616774877, 'Total loss': 0.4111873616774877} | train loss {'Reaction outcome loss': 0.37403784935346607, 'Total loss': 0.37403784935346607}
2023-01-04 10:44:53,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:53,468 INFO:     Epoch: 43
2023-01-04 10:44:55,065 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4016255100568136, 'Total loss': 0.4016255100568136} | train loss {'Reaction outcome loss': 0.35464865822628466, 'Total loss': 0.35464865822628466}
2023-01-04 10:44:55,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:55,066 INFO:     Epoch: 44
2023-01-04 10:44:56,646 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42738576928774513, 'Total loss': 0.42738576928774513} | train loss {'Reaction outcome loss': 0.353645671914885, 'Total loss': 0.353645671914885}
2023-01-04 10:44:56,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:56,646 INFO:     Epoch: 45
2023-01-04 10:44:58,209 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38664506872495014, 'Total loss': 0.38664506872495014} | train loss {'Reaction outcome loss': 0.3513663517635154, 'Total loss': 0.3513663517635154}
2023-01-04 10:44:58,209 INFO:     Found new best model at epoch 45
2023-01-04 10:44:58,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:58,210 INFO:     Epoch: 46
2023-01-04 10:44:59,823 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3997957110404968, 'Total loss': 0.3997957110404968} | train loss {'Reaction outcome loss': 0.34641415859653574, 'Total loss': 0.34641415859653574}
2023-01-04 10:44:59,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:44:59,824 INFO:     Epoch: 47
2023-01-04 10:45:01,423 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39237651924292244, 'Total loss': 0.39237651924292244} | train loss {'Reaction outcome loss': 0.3393368240297381, 'Total loss': 0.3393368240297381}
2023-01-04 10:45:01,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:01,423 INFO:     Epoch: 48
2023-01-04 10:45:02,999 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40681955416997273, 'Total loss': 0.40681955416997273} | train loss {'Reaction outcome loss': 0.3390867555753557, 'Total loss': 0.3390867555753557}
2023-01-04 10:45:03,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:03,000 INFO:     Epoch: 49
2023-01-04 10:45:04,564 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4212687263886134, 'Total loss': 0.4212687263886134} | train loss {'Reaction outcome loss': 0.335152109873994, 'Total loss': 0.335152109873994}
2023-01-04 10:45:04,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:04,564 INFO:     Epoch: 50
2023-01-04 10:45:06,112 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40320435365041096, 'Total loss': 0.40320435365041096} | train loss {'Reaction outcome loss': 0.3408715208946808, 'Total loss': 0.3408715208946808}
2023-01-04 10:45:06,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:06,112 INFO:     Epoch: 51
2023-01-04 10:45:07,660 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42258034149805707, 'Total loss': 0.42258034149805707} | train loss {'Reaction outcome loss': 0.33566059550081473, 'Total loss': 0.33566059550081473}
2023-01-04 10:45:07,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:07,661 INFO:     Epoch: 52
2023-01-04 10:45:09,231 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4107237994670868, 'Total loss': 0.4107237994670868} | train loss {'Reaction outcome loss': 0.33608074758819345, 'Total loss': 0.33608074758819345}
2023-01-04 10:45:09,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:09,231 INFO:     Epoch: 53
2023-01-04 10:45:10,802 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39858823219935097, 'Total loss': 0.39858823219935097} | train loss {'Reaction outcome loss': 0.33110301802841696, 'Total loss': 0.33110301802841696}
2023-01-04 10:45:10,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:10,803 INFO:     Epoch: 54
2023-01-04 10:45:12,373 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4183746337890625, 'Total loss': 0.4183746337890625} | train loss {'Reaction outcome loss': 0.33110190691271174, 'Total loss': 0.33110190691271174}
2023-01-04 10:45:12,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:12,373 INFO:     Epoch: 55
2023-01-04 10:45:13,920 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41180821855862937, 'Total loss': 0.41180821855862937} | train loss {'Reaction outcome loss': 0.32772982683651947, 'Total loss': 0.32772982683651947}
2023-01-04 10:45:13,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:13,921 INFO:     Epoch: 56
2023-01-04 10:45:15,498 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4110839794079463, 'Total loss': 0.4110839794079463} | train loss {'Reaction outcome loss': 0.326935272402319, 'Total loss': 0.326935272402319}
2023-01-04 10:45:15,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:15,498 INFO:     Epoch: 57
2023-01-04 10:45:17,018 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41019492944081626, 'Total loss': 0.41019492944081626} | train loss {'Reaction outcome loss': 0.3270169908342802, 'Total loss': 0.3270169908342802}
2023-01-04 10:45:17,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:17,018 INFO:     Epoch: 58
2023-01-04 10:45:18,595 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41169532338778175, 'Total loss': 0.41169532338778175} | train loss {'Reaction outcome loss': 0.32488722994036134, 'Total loss': 0.32488722994036134}
2023-01-04 10:45:18,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:18,595 INFO:     Epoch: 59
2023-01-04 10:45:20,165 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3774612843990326, 'Total loss': 0.3774612843990326} | train loss {'Reaction outcome loss': 0.3249816345995751, 'Total loss': 0.3249816345995751}
2023-01-04 10:45:20,165 INFO:     Found new best model at epoch 59
2023-01-04 10:45:20,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:20,166 INFO:     Epoch: 60
2023-01-04 10:45:21,724 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39815963904062907, 'Total loss': 0.39815963904062907} | train loss {'Reaction outcome loss': 0.3375070243232651, 'Total loss': 0.3375070243232651}
2023-01-04 10:45:21,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:21,725 INFO:     Epoch: 61
2023-01-04 10:45:23,254 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39666147232055665, 'Total loss': 0.39666147232055665} | train loss {'Reaction outcome loss': 0.3205913121042692, 'Total loss': 0.3205913121042692}
2023-01-04 10:45:23,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:23,254 INFO:     Epoch: 62
2023-01-04 10:45:24,825 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42638997932275136, 'Total loss': 0.42638997932275136} | train loss {'Reaction outcome loss': 0.31785048821241263, 'Total loss': 0.31785048821241263}
2023-01-04 10:45:24,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:24,825 INFO:     Epoch: 63
2023-01-04 10:45:26,345 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4241987039645513, 'Total loss': 0.4241987039645513} | train loss {'Reaction outcome loss': 0.31614621476109134, 'Total loss': 0.31614621476109134}
2023-01-04 10:45:26,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:26,345 INFO:     Epoch: 64
2023-01-04 10:45:27,917 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.390779247879982, 'Total loss': 0.390779247879982} | train loss {'Reaction outcome loss': 0.31330999595229514, 'Total loss': 0.31330999595229514}
2023-01-04 10:45:27,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:27,918 INFO:     Epoch: 65
2023-01-04 10:45:29,490 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3980329026778539, 'Total loss': 0.3980329026778539} | train loss {'Reaction outcome loss': 0.30853706609417236, 'Total loss': 0.30853706609417236}
2023-01-04 10:45:29,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:29,491 INFO:     Epoch: 66
2023-01-04 10:45:31,070 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42274401982625326, 'Total loss': 0.42274401982625326} | train loss {'Reaction outcome loss': 0.3102982025703186, 'Total loss': 0.3102982025703186}
2023-01-04 10:45:31,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:31,070 INFO:     Epoch: 67
2023-01-04 10:45:32,610 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4002358873685201, 'Total loss': 0.4002358873685201} | train loss {'Reaction outcome loss': 0.3081497026040502, 'Total loss': 0.3081497026040502}
2023-01-04 10:45:32,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:32,610 INFO:     Epoch: 68
2023-01-04 10:45:34,209 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4284189283847809, 'Total loss': 0.4284189283847809} | train loss {'Reaction outcome loss': 0.315032996898652, 'Total loss': 0.315032996898652}
2023-01-04 10:45:34,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:34,210 INFO:     Epoch: 69
2023-01-04 10:45:35,754 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4167404234409332, 'Total loss': 0.4167404234409332} | train loss {'Reaction outcome loss': 0.32197852297753526, 'Total loss': 0.32197852297753526}
2023-01-04 10:45:35,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:35,754 INFO:     Epoch: 70
2023-01-04 10:45:37,335 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42586513559023537, 'Total loss': 0.42586513559023537} | train loss {'Reaction outcome loss': 0.3101124830014221, 'Total loss': 0.3101124830014221}
2023-01-04 10:45:37,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:37,335 INFO:     Epoch: 71
2023-01-04 10:45:38,920 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4125650942325592, 'Total loss': 0.4125650942325592} | train loss {'Reaction outcome loss': 0.3043621085361456, 'Total loss': 0.3043621085361456}
2023-01-04 10:45:38,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:38,920 INFO:     Epoch: 72
2023-01-04 10:45:40,521 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39231064220269524, 'Total loss': 0.39231064220269524} | train loss {'Reaction outcome loss': 0.30023046087244176, 'Total loss': 0.30023046087244176}
2023-01-04 10:45:40,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:40,521 INFO:     Epoch: 73
2023-01-04 10:45:42,096 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3729169537623723, 'Total loss': 0.3729169537623723} | train loss {'Reaction outcome loss': 0.297182944505408, 'Total loss': 0.297182944505408}
2023-01-04 10:45:42,096 INFO:     Found new best model at epoch 73
2023-01-04 10:45:42,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:42,097 INFO:     Epoch: 74
2023-01-04 10:45:43,663 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37141359895467757, 'Total loss': 0.37141359895467757} | train loss {'Reaction outcome loss': 0.2976111032885324, 'Total loss': 0.2976111032885324}
2023-01-04 10:45:43,664 INFO:     Found new best model at epoch 74
2023-01-04 10:45:43,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:43,664 INFO:     Epoch: 75
2023-01-04 10:45:45,224 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41677635808785757, 'Total loss': 0.41677635808785757} | train loss {'Reaction outcome loss': 0.29778907303630875, 'Total loss': 0.29778907303630875}
2023-01-04 10:45:45,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:45,224 INFO:     Epoch: 76
2023-01-04 10:45:46,830 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41543713708718616, 'Total loss': 0.41543713708718616} | train loss {'Reaction outcome loss': 0.2988868581495531, 'Total loss': 0.2988868581495531}
2023-01-04 10:45:46,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:46,831 INFO:     Epoch: 77
2023-01-04 10:45:48,421 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40558286805947624, 'Total loss': 0.40558286805947624} | train loss {'Reaction outcome loss': 0.2993970246364673, 'Total loss': 0.2993970246364673}
2023-01-04 10:45:48,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:48,422 INFO:     Epoch: 78
2023-01-04 10:45:50,010 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38841845790545143, 'Total loss': 0.38841845790545143} | train loss {'Reaction outcome loss': 0.32057230856161617, 'Total loss': 0.32057230856161617}
2023-01-04 10:45:50,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:50,011 INFO:     Epoch: 79
2023-01-04 10:45:51,534 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44900452295939125, 'Total loss': 0.44900452295939125} | train loss {'Reaction outcome loss': 0.3062377009216858, 'Total loss': 0.3062377009216858}
2023-01-04 10:45:51,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:51,534 INFO:     Epoch: 80
2023-01-04 10:45:53,081 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4155796845753988, 'Total loss': 0.4155796845753988} | train loss {'Reaction outcome loss': 0.30514069222996454, 'Total loss': 0.30514069222996454}
2023-01-04 10:45:53,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:53,081 INFO:     Epoch: 81
2023-01-04 10:45:54,647 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3943620731433233, 'Total loss': 0.3943620731433233} | train loss {'Reaction outcome loss': 0.28882099122510874, 'Total loss': 0.28882099122510874}
2023-01-04 10:45:54,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:54,648 INFO:     Epoch: 82
2023-01-04 10:45:56,233 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4257872372865677, 'Total loss': 0.4257872372865677} | train loss {'Reaction outcome loss': 0.2968693878883444, 'Total loss': 0.2968693878883444}
2023-01-04 10:45:56,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:56,233 INFO:     Epoch: 83
2023-01-04 10:45:57,837 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4019818325837453, 'Total loss': 0.4019818325837453} | train loss {'Reaction outcome loss': 0.2882602872369993, 'Total loss': 0.2882602872369993}
2023-01-04 10:45:57,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:57,837 INFO:     Epoch: 84
2023-01-04 10:45:59,400 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38711922069390614, 'Total loss': 0.38711922069390614} | train loss {'Reaction outcome loss': 0.2912721529306061, 'Total loss': 0.2912721529306061}
2023-01-04 10:45:59,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:45:59,400 INFO:     Epoch: 85
2023-01-04 10:46:00,970 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39312498370806376, 'Total loss': 0.39312498370806376} | train loss {'Reaction outcome loss': 0.3505841101371292, 'Total loss': 0.3505841101371292}
2023-01-04 10:46:00,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:00,971 INFO:     Epoch: 86
2023-01-04 10:46:02,509 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4133966346581777, 'Total loss': 0.4133966346581777} | train loss {'Reaction outcome loss': 0.2972790912011777, 'Total loss': 0.2972790912011777}
2023-01-04 10:46:02,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:02,510 INFO:     Epoch: 87
2023-01-04 10:46:04,080 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3867926796277364, 'Total loss': 0.3867926796277364} | train loss {'Reaction outcome loss': 0.28905187976425106, 'Total loss': 0.28905187976425106}
2023-01-04 10:46:04,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:04,081 INFO:     Epoch: 88
2023-01-04 10:46:05,669 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4057006945212682, 'Total loss': 0.4057006945212682} | train loss {'Reaction outcome loss': 0.2869647230663627, 'Total loss': 0.2869647230663627}
2023-01-04 10:46:05,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:05,669 INFO:     Epoch: 89
2023-01-04 10:46:07,245 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3929606060187022, 'Total loss': 0.3929606060187022} | train loss {'Reaction outcome loss': 0.2872964979108909, 'Total loss': 0.2872964979108909}
2023-01-04 10:46:07,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:07,246 INFO:     Epoch: 90
2023-01-04 10:46:08,774 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3971628874540329, 'Total loss': 0.3971628874540329} | train loss {'Reaction outcome loss': 0.28340275593749853, 'Total loss': 0.28340275593749853}
2023-01-04 10:46:08,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:08,775 INFO:     Epoch: 91
2023-01-04 10:46:10,355 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42055419981479647, 'Total loss': 0.42055419981479647} | train loss {'Reaction outcome loss': 0.3001731086819284, 'Total loss': 0.3001731086819284}
2023-01-04 10:46:10,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:10,356 INFO:     Epoch: 92
2023-01-04 10:46:11,895 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.38207788864771525, 'Total loss': 0.38207788864771525} | train loss {'Reaction outcome loss': 0.3053269228742768, 'Total loss': 0.3053269228742768}
2023-01-04 10:46:11,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:11,895 INFO:     Epoch: 93
2023-01-04 10:46:13,483 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3966809878746668, 'Total loss': 0.3966809878746668} | train loss {'Reaction outcome loss': 0.2817693465267834, 'Total loss': 0.2817693465267834}
2023-01-04 10:46:13,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:13,484 INFO:     Epoch: 94
2023-01-04 10:46:15,071 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41692253748575847, 'Total loss': 0.41692253748575847} | train loss {'Reaction outcome loss': 0.2760460243182446, 'Total loss': 0.2760460243182446}
2023-01-04 10:46:15,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:15,071 INFO:     Epoch: 95
2023-01-04 10:46:16,649 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40349644323190054, 'Total loss': 0.40349644323190054} | train loss {'Reaction outcome loss': 0.27529306758989824, 'Total loss': 0.27529306758989824}
2023-01-04 10:46:16,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:16,649 INFO:     Epoch: 96
2023-01-04 10:46:18,192 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44346134265263876, 'Total loss': 0.44346134265263876} | train loss {'Reaction outcome loss': 0.2825127424395127, 'Total loss': 0.2825127424395127}
2023-01-04 10:46:18,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:18,193 INFO:     Epoch: 97
2023-01-04 10:46:19,759 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3954024414221446, 'Total loss': 0.3954024414221446} | train loss {'Reaction outcome loss': 0.27457108974804345, 'Total loss': 0.27457108974804345}
2023-01-04 10:46:19,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:19,759 INFO:     Epoch: 98
2023-01-04 10:46:21,293 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3765082468589147, 'Total loss': 0.3765082468589147} | train loss {'Reaction outcome loss': 0.2750594388297928, 'Total loss': 0.2750594388297928}
2023-01-04 10:46:21,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:21,294 INFO:     Epoch: 99
2023-01-04 10:46:22,857 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3976265788078308, 'Total loss': 0.3976265788078308} | train loss {'Reaction outcome loss': 0.2720750523541305, 'Total loss': 0.2720750523541305}
2023-01-04 10:46:22,858 INFO:     Best model found after epoch 75 of 100.
2023-01-04 10:46:22,858 INFO:   Done with stage: TRAINING
2023-01-04 10:46:22,858 INFO:   Starting stage: EVALUATION
2023-01-04 10:46:22,985 INFO:   Done with stage: EVALUATION
2023-01-04 10:46:22,985 INFO:   Leaving out SEQ value Fold_9
2023-01-04 10:46:22,998 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 10:46:22,998 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:46:23,643 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:46:23,643 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:46:23,711 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:46:23,711 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:46:23,711 INFO:     No hyperparam tuning for this model
2023-01-04 10:46:23,711 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:46:23,711 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:46:23,712 INFO:     None feature selector for col prot
2023-01-04 10:46:23,712 INFO:     None feature selector for col prot
2023-01-04 10:46:23,712 INFO:     None feature selector for col prot
2023-01-04 10:46:23,713 INFO:     None feature selector for col chem
2023-01-04 10:46:23,713 INFO:     None feature selector for col chem
2023-01-04 10:46:23,713 INFO:     None feature selector for col chem
2023-01-04 10:46:23,713 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:46:23,713 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:46:23,714 INFO:     Number of params in model 70111
2023-01-04 10:46:23,717 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:46:23,717 INFO:   Starting stage: TRAINING
2023-01-04 10:46:23,760 INFO:     Val loss before train {'Reaction outcome loss': 0.9612818737824758, 'Total loss': 0.9612818737824758}
2023-01-04 10:46:23,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:23,760 INFO:     Epoch: 0
2023-01-04 10:46:25,324 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7348611116409302, 'Total loss': 0.7348611116409302} | train loss {'Reaction outcome loss': 0.8492470689727428, 'Total loss': 0.8492470689727428}
2023-01-04 10:46:25,324 INFO:     Found new best model at epoch 0
2023-01-04 10:46:25,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:25,325 INFO:     Epoch: 1
2023-01-04 10:46:26,854 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6085535963376363, 'Total loss': 0.6085535963376363} | train loss {'Reaction outcome loss': 0.6864849216653965, 'Total loss': 0.6864849216653965}
2023-01-04 10:46:26,854 INFO:     Found new best model at epoch 1
2023-01-04 10:46:26,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:26,855 INFO:     Epoch: 2
2023-01-04 10:46:28,434 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5377643287181855, 'Total loss': 0.5377643287181855} | train loss {'Reaction outcome loss': 0.5887734527274481, 'Total loss': 0.5887734527274481}
2023-01-04 10:46:28,434 INFO:     Found new best model at epoch 2
2023-01-04 10:46:28,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:28,435 INFO:     Epoch: 3
2023-01-04 10:46:29,981 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5118093490600586, 'Total loss': 0.5118093490600586} | train loss {'Reaction outcome loss': 0.5485414815476111, 'Total loss': 0.5485414815476111}
2023-01-04 10:46:29,981 INFO:     Found new best model at epoch 3
2023-01-04 10:46:29,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:29,982 INFO:     Epoch: 4
2023-01-04 10:46:31,554 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4754927635192871, 'Total loss': 0.4754927635192871} | train loss {'Reaction outcome loss': 0.5335269929922145, 'Total loss': 0.5335269929922145}
2023-01-04 10:46:31,554 INFO:     Found new best model at epoch 4
2023-01-04 10:46:31,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:31,555 INFO:     Epoch: 5
2023-01-04 10:46:33,154 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49141457974910735, 'Total loss': 0.49141457974910735} | train loss {'Reaction outcome loss': 0.5232554500301679, 'Total loss': 0.5232554500301679}
2023-01-04 10:46:33,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:33,154 INFO:     Epoch: 6
2023-01-04 10:46:34,739 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4607263684272766, 'Total loss': 0.4607263684272766} | train loss {'Reaction outcome loss': 0.5210654612468637, 'Total loss': 0.5210654612468637}
2023-01-04 10:46:34,740 INFO:     Found new best model at epoch 6
2023-01-04 10:46:34,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:34,741 INFO:     Epoch: 7
2023-01-04 10:46:36,271 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46441973249117535, 'Total loss': 0.46441973249117535} | train loss {'Reaction outcome loss': 0.4971693793884934, 'Total loss': 0.4971693793884934}
2023-01-04 10:46:36,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:36,271 INFO:     Epoch: 8
2023-01-04 10:46:37,839 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4657968064149221, 'Total loss': 0.4657968064149221} | train loss {'Reaction outcome loss': 0.4904297710720288, 'Total loss': 0.4904297710720288}
2023-01-04 10:46:37,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:37,839 INFO:     Epoch: 9
2023-01-04 10:46:39,406 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4572011172771454, 'Total loss': 0.4572011172771454} | train loss {'Reaction outcome loss': 0.4841243568042547, 'Total loss': 0.4841243568042547}
2023-01-04 10:46:39,406 INFO:     Found new best model at epoch 9
2023-01-04 10:46:39,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:39,407 INFO:     Epoch: 10
2023-01-04 10:46:40,990 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43842796683311464, 'Total loss': 0.43842796683311464} | train loss {'Reaction outcome loss': 0.4760494430657422, 'Total loss': 0.4760494430657422}
2023-01-04 10:46:40,991 INFO:     Found new best model at epoch 10
2023-01-04 10:46:40,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:40,992 INFO:     Epoch: 11
2023-01-04 10:46:42,586 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44033558865388234, 'Total loss': 0.44033558865388234} | train loss {'Reaction outcome loss': 0.4701264637211959, 'Total loss': 0.4701264637211959}
2023-01-04 10:46:42,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:42,587 INFO:     Epoch: 12
2023-01-04 10:46:44,182 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42987683912118274, 'Total loss': 0.42987683912118274} | train loss {'Reaction outcome loss': 0.4641369773965815, 'Total loss': 0.4641369773965815}
2023-01-04 10:46:44,182 INFO:     Found new best model at epoch 12
2023-01-04 10:46:44,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:44,183 INFO:     Epoch: 13
2023-01-04 10:46:45,729 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4208290308713913, 'Total loss': 0.4208290308713913} | train loss {'Reaction outcome loss': 0.4568831531754425, 'Total loss': 0.4568831531754425}
2023-01-04 10:46:45,729 INFO:     Found new best model at epoch 13
2023-01-04 10:46:45,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:45,730 INFO:     Epoch: 14
2023-01-04 10:46:47,251 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43597366909186047, 'Total loss': 0.43597366909186047} | train loss {'Reaction outcome loss': 0.45794249147824617, 'Total loss': 0.45794249147824617}
2023-01-04 10:46:47,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:47,251 INFO:     Epoch: 15
2023-01-04 10:46:48,818 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4325847844282786, 'Total loss': 0.4325847844282786} | train loss {'Reaction outcome loss': 0.46986295440085774, 'Total loss': 0.46986295440085774}
2023-01-04 10:46:48,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:48,819 INFO:     Epoch: 16
2023-01-04 10:46:50,404 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41591355999310814, 'Total loss': 0.41591355999310814} | train loss {'Reaction outcome loss': 0.4494423050738355, 'Total loss': 0.4494423050738355}
2023-01-04 10:46:50,404 INFO:     Found new best model at epoch 16
2023-01-04 10:46:50,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:50,404 INFO:     Epoch: 17
2023-01-04 10:46:51,989 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4242079496383667, 'Total loss': 0.4242079496383667} | train loss {'Reaction outcome loss': 0.44547421138301707, 'Total loss': 0.44547421138301707}
2023-01-04 10:46:51,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:51,989 INFO:     Epoch: 18
2023-01-04 10:46:53,527 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4136720597743988, 'Total loss': 0.4136720597743988} | train loss {'Reaction outcome loss': 0.43671529242040025, 'Total loss': 0.43671529242040025}
2023-01-04 10:46:53,528 INFO:     Found new best model at epoch 18
2023-01-04 10:46:53,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:53,529 INFO:     Epoch: 19
2023-01-04 10:46:55,100 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42160924275716144, 'Total loss': 0.42160924275716144} | train loss {'Reaction outcome loss': 0.43699032950984396, 'Total loss': 0.43699032950984396}
2023-01-04 10:46:55,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:55,100 INFO:     Epoch: 20
2023-01-04 10:46:56,643 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4111111561457316, 'Total loss': 0.4111111561457316} | train loss {'Reaction outcome loss': 0.42829711819482275, 'Total loss': 0.42829711819482275}
2023-01-04 10:46:56,643 INFO:     Found new best model at epoch 20
2023-01-04 10:46:56,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:56,644 INFO:     Epoch: 21
2023-01-04 10:46:58,215 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4270501891771952, 'Total loss': 0.4270501891771952} | train loss {'Reaction outcome loss': 0.4365121837219466, 'Total loss': 0.4365121837219466}
2023-01-04 10:46:58,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:58,215 INFO:     Epoch: 22
2023-01-04 10:46:59,790 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4271889497836431, 'Total loss': 0.4271889497836431} | train loss {'Reaction outcome loss': 0.4401144309718486, 'Total loss': 0.4401144309718486}
2023-01-04 10:46:59,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:46:59,790 INFO:     Epoch: 23
2023-01-04 10:47:01,342 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42648426493008934, 'Total loss': 0.42648426493008934} | train loss {'Reaction outcome loss': 0.42167713957420294, 'Total loss': 0.42167713957420294}
2023-01-04 10:47:01,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:01,342 INFO:     Epoch: 24
2023-01-04 10:47:02,876 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42508126199245455, 'Total loss': 0.42508126199245455} | train loss {'Reaction outcome loss': 0.4165025952042661, 'Total loss': 0.4165025952042661}
2023-01-04 10:47:02,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:02,876 INFO:     Epoch: 25
2023-01-04 10:47:04,445 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41909131904443103, 'Total loss': 0.41909131904443103} | train loss {'Reaction outcome loss': 0.40809047029799095, 'Total loss': 0.40809047029799095}
2023-01-04 10:47:04,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:04,445 INFO:     Epoch: 26
2023-01-04 10:47:06,007 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3979088544845581, 'Total loss': 0.3979088544845581} | train loss {'Reaction outcome loss': 0.4051629344365843, 'Total loss': 0.4051629344365843}
2023-01-04 10:47:06,009 INFO:     Found new best model at epoch 26
2023-01-04 10:47:06,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:06,009 INFO:     Epoch: 27
2023-01-04 10:47:07,584 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40403659343719484, 'Total loss': 0.40403659343719484} | train loss {'Reaction outcome loss': 0.4018486774124988, 'Total loss': 0.4018486774124988}
2023-01-04 10:47:07,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:07,584 INFO:     Epoch: 28
2023-01-04 10:47:09,167 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41582768857479097, 'Total loss': 0.41582768857479097} | train loss {'Reaction outcome loss': 0.39923947255896486, 'Total loss': 0.39923947255896486}
2023-01-04 10:47:09,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:09,168 INFO:     Epoch: 29
2023-01-04 10:47:10,755 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4001855492591858, 'Total loss': 0.4001855492591858} | train loss {'Reaction outcome loss': 0.4342270408743534, 'Total loss': 0.4342270408743534}
2023-01-04 10:47:10,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:10,755 INFO:     Epoch: 30
2023-01-04 10:47:12,304 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3973447839419047, 'Total loss': 0.3973447839419047} | train loss {'Reaction outcome loss': 0.40987530483634793, 'Total loss': 0.40987530483634793}
2023-01-04 10:47:12,305 INFO:     Found new best model at epoch 30
2023-01-04 10:47:12,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:12,306 INFO:     Epoch: 31
2023-01-04 10:47:13,866 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38762193818887075, 'Total loss': 0.38762193818887075} | train loss {'Reaction outcome loss': 0.3884379079222065, 'Total loss': 0.3884379079222065}
2023-01-04 10:47:13,866 INFO:     Found new best model at epoch 31
2023-01-04 10:47:13,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:13,867 INFO:     Epoch: 32
2023-01-04 10:47:15,403 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43202279806137084, 'Total loss': 0.43202279806137084} | train loss {'Reaction outcome loss': 0.3870903361264778, 'Total loss': 0.3870903361264778}
2023-01-04 10:47:15,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:15,404 INFO:     Epoch: 33
2023-01-04 10:47:16,965 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40325396656990053, 'Total loss': 0.40325396656990053} | train loss {'Reaction outcome loss': 0.38457475308382855, 'Total loss': 0.38457475308382855}
2023-01-04 10:47:16,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:16,965 INFO:     Epoch: 34
2023-01-04 10:47:18,529 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39155255556106566, 'Total loss': 0.39155255556106566} | train loss {'Reaction outcome loss': 0.38215292508054216, 'Total loss': 0.38215292508054216}
2023-01-04 10:47:18,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:18,530 INFO:     Epoch: 35
2023-01-04 10:47:20,096 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3779239555199941, 'Total loss': 0.3779239555199941} | train loss {'Reaction outcome loss': 0.3750372674667101, 'Total loss': 0.3750372674667101}
2023-01-04 10:47:20,096 INFO:     Found new best model at epoch 35
2023-01-04 10:47:20,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:20,096 INFO:     Epoch: 36
2023-01-04 10:47:21,622 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38393684128920236, 'Total loss': 0.38393684128920236} | train loss {'Reaction outcome loss': 0.3871948763296224, 'Total loss': 0.3871948763296224}
2023-01-04 10:47:21,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:21,623 INFO:     Epoch: 37
2023-01-04 10:47:23,174 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40308695236841835, 'Total loss': 0.40308695236841835} | train loss {'Reaction outcome loss': 0.3906180034050983, 'Total loss': 0.3906180034050983}
2023-01-04 10:47:23,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:23,174 INFO:     Epoch: 38
2023-01-04 10:47:24,733 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4117040524880091, 'Total loss': 0.4117040524880091} | train loss {'Reaction outcome loss': 0.3805945574481418, 'Total loss': 0.3805945574481418}
2023-01-04 10:47:24,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:24,734 INFO:     Epoch: 39
2023-01-04 10:47:26,318 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3913066446781158, 'Total loss': 0.3913066446781158} | train loss {'Reaction outcome loss': 0.39512715609084426, 'Total loss': 0.39512715609084426}
2023-01-04 10:47:26,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:26,318 INFO:     Epoch: 40
2023-01-04 10:47:27,916 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38161509931087495, 'Total loss': 0.38161509931087495} | train loss {'Reaction outcome loss': 0.36363953128465504, 'Total loss': 0.36363953128465504}
2023-01-04 10:47:27,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:27,917 INFO:     Epoch: 41
2023-01-04 10:47:29,509 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41985043783982595, 'Total loss': 0.41985043783982595} | train loss {'Reaction outcome loss': 0.3603833437028843, 'Total loss': 0.3603833437028843}
2023-01-04 10:47:29,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:29,510 INFO:     Epoch: 42
2023-01-04 10:47:31,057 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38963066538174945, 'Total loss': 0.38963066538174945} | train loss {'Reaction outcome loss': 0.37844848476242327, 'Total loss': 0.37844848476242327}
2023-01-04 10:47:31,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:31,057 INFO:     Epoch: 43
2023-01-04 10:47:32,618 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3944448739290237, 'Total loss': 0.3944448739290237} | train loss {'Reaction outcome loss': 0.38178806539381976, 'Total loss': 0.38178806539381976}
2023-01-04 10:47:32,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:32,618 INFO:     Epoch: 44
2023-01-04 10:47:34,196 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3775623420874278, 'Total loss': 0.3775623420874278} | train loss {'Reaction outcome loss': 0.3558080971521069, 'Total loss': 0.3558080971521069}
2023-01-04 10:47:34,196 INFO:     Found new best model at epoch 44
2023-01-04 10:47:34,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:34,197 INFO:     Epoch: 45
2023-01-04 10:47:35,779 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3963655869166056, 'Total loss': 0.3963655869166056} | train loss {'Reaction outcome loss': 0.3527633158787005, 'Total loss': 0.3527633158787005}
2023-01-04 10:47:35,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:35,779 INFO:     Epoch: 46
2023-01-04 10:47:37,323 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37588318685690564, 'Total loss': 0.37588318685690564} | train loss {'Reaction outcome loss': 0.3555664934987283, 'Total loss': 0.3555664934987283}
2023-01-04 10:47:37,324 INFO:     Found new best model at epoch 46
2023-01-04 10:47:37,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:37,325 INFO:     Epoch: 47
2023-01-04 10:47:38,840 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40716583530108136, 'Total loss': 0.40716583530108136} | train loss {'Reaction outcome loss': 0.3473443199435006, 'Total loss': 0.3473443199435006}
2023-01-04 10:47:38,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:38,841 INFO:     Epoch: 48
2023-01-04 10:47:40,354 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3902791639169057, 'Total loss': 0.3902791639169057} | train loss {'Reaction outcome loss': 0.36127757545614586, 'Total loss': 0.36127757545614586}
2023-01-04 10:47:40,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:40,354 INFO:     Epoch: 49
2023-01-04 10:47:41,847 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.36906355023384096, 'Total loss': 0.36906355023384096} | train loss {'Reaction outcome loss': 0.35272375613019086, 'Total loss': 0.35272375613019086}
2023-01-04 10:47:41,847 INFO:     Found new best model at epoch 49
2023-01-04 10:47:41,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:41,848 INFO:     Epoch: 50
2023-01-04 10:47:43,377 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3822147925694784, 'Total loss': 0.3822147925694784} | train loss {'Reaction outcome loss': 0.3753779644983402, 'Total loss': 0.3753779644983402}
2023-01-04 10:47:43,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:43,378 INFO:     Epoch: 51
2023-01-04 10:47:44,896 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3832422137260437, 'Total loss': 0.3832422137260437} | train loss {'Reaction outcome loss': 0.33849976542304555, 'Total loss': 0.33849976542304555}
2023-01-04 10:47:44,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:44,896 INFO:     Epoch: 52
2023-01-04 10:47:46,419 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.35993433396021524, 'Total loss': 0.35993433396021524} | train loss {'Reaction outcome loss': 0.3382249106315599, 'Total loss': 0.3382249106315599}
2023-01-04 10:47:46,419 INFO:     Found new best model at epoch 52
2023-01-04 10:47:46,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:46,420 INFO:     Epoch: 53
2023-01-04 10:47:47,969 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3726841022570928, 'Total loss': 0.3726841022570928} | train loss {'Reaction outcome loss': 0.3359065891068051, 'Total loss': 0.3359065891068051}
2023-01-04 10:47:47,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:47,970 INFO:     Epoch: 54
2023-01-04 10:47:49,516 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.36928454240163167, 'Total loss': 0.36928454240163167} | train loss {'Reaction outcome loss': 0.33866557214355125, 'Total loss': 0.33866557214355125}
2023-01-04 10:47:49,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:49,517 INFO:     Epoch: 55
2023-01-04 10:47:51,110 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38130243321259816, 'Total loss': 0.38130243321259816} | train loss {'Reaction outcome loss': 0.33174517604967824, 'Total loss': 0.33174517604967824}
2023-01-04 10:47:51,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:51,110 INFO:     Epoch: 56
2023-01-04 10:47:52,718 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3911179333925247, 'Total loss': 0.3911179333925247} | train loss {'Reaction outcome loss': 0.34342048400878045, 'Total loss': 0.34342048400878045}
2023-01-04 10:47:52,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:52,718 INFO:     Epoch: 57
2023-01-04 10:47:54,301 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4151408910751343, 'Total loss': 0.4151408910751343} | train loss {'Reaction outcome loss': 0.3657803341053638, 'Total loss': 0.3657803341053638}
2023-01-04 10:47:54,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:54,301 INFO:     Epoch: 58
2023-01-04 10:47:55,886 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.37112038433551786, 'Total loss': 0.37112038433551786} | train loss {'Reaction outcome loss': 0.3313939635898324, 'Total loss': 0.3313939635898324}
2023-01-04 10:47:55,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:55,887 INFO:     Epoch: 59
2023-01-04 10:47:57,469 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3737624943256378, 'Total loss': 0.3737624943256378} | train loss {'Reaction outcome loss': 0.3262582041793064, 'Total loss': 0.3262582041793064}
2023-01-04 10:47:57,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:57,469 INFO:     Epoch: 60
2023-01-04 10:47:59,052 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3822203854719798, 'Total loss': 0.3822203854719798} | train loss {'Reaction outcome loss': 0.3147046979199555, 'Total loss': 0.3147046979199555}
2023-01-04 10:47:59,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:47:59,052 INFO:     Epoch: 61
2023-01-04 10:48:00,604 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3611579298973083, 'Total loss': 0.3611579298973083} | train loss {'Reaction outcome loss': 0.3229419101810798, 'Total loss': 0.3229419101810798}
2023-01-04 10:48:00,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:00,604 INFO:     Epoch: 62
2023-01-04 10:48:02,190 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3846540182828903, 'Total loss': 0.3846540182828903} | train loss {'Reaction outcome loss': 0.3131723860393401, 'Total loss': 0.3131723860393401}
2023-01-04 10:48:02,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:02,190 INFO:     Epoch: 63
2023-01-04 10:48:03,784 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.35547760625680286, 'Total loss': 0.35547760625680286} | train loss {'Reaction outcome loss': 0.3140773589181228, 'Total loss': 0.3140773589181228}
2023-01-04 10:48:03,784 INFO:     Found new best model at epoch 63
2023-01-04 10:48:03,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:03,785 INFO:     Epoch: 64
2023-01-04 10:48:05,381 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3621164659659068, 'Total loss': 0.3621164659659068} | train loss {'Reaction outcome loss': 0.3139952209900609, 'Total loss': 0.3139952209900609}
2023-01-04 10:48:05,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:05,381 INFO:     Epoch: 65
2023-01-04 10:48:06,926 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3572980841000875, 'Total loss': 0.3572980841000875} | train loss {'Reaction outcome loss': 0.30888497748452687, 'Total loss': 0.30888497748452687}
2023-01-04 10:48:06,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:06,927 INFO:     Epoch: 66
2023-01-04 10:48:08,542 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3670820285876592, 'Total loss': 0.3670820285876592} | train loss {'Reaction outcome loss': 0.3127013491416026, 'Total loss': 0.3127013491416026}
2023-01-04 10:48:08,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:08,542 INFO:     Epoch: 67
2023-01-04 10:48:10,121 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4093930800755819, 'Total loss': 0.4093930800755819} | train loss {'Reaction outcome loss': 0.3102657264119615, 'Total loss': 0.3102657264119615}
2023-01-04 10:48:10,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:10,122 INFO:     Epoch: 68
2023-01-04 10:48:11,752 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3387839138507843, 'Total loss': 0.3387839138507843} | train loss {'Reaction outcome loss': 0.31038356356430746, 'Total loss': 0.31038356356430746}
2023-01-04 10:48:11,753 INFO:     Found new best model at epoch 68
2023-01-04 10:48:11,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:11,754 INFO:     Epoch: 69
2023-01-04 10:48:13,375 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.36500943303108213, 'Total loss': 0.36500943303108213} | train loss {'Reaction outcome loss': 0.3129514949531227, 'Total loss': 0.3129514949531227}
2023-01-04 10:48:13,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:13,375 INFO:     Epoch: 70
2023-01-04 10:48:15,006 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3717520703872045, 'Total loss': 0.3717520703872045} | train loss {'Reaction outcome loss': 0.32176996787092177, 'Total loss': 0.32176996787092177}
2023-01-04 10:48:15,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:15,006 INFO:     Epoch: 71
2023-01-04 10:48:16,579 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.36116615136464436, 'Total loss': 0.36116615136464436} | train loss {'Reaction outcome loss': 0.3138667380950157, 'Total loss': 0.3138667380950157}
2023-01-04 10:48:16,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:16,579 INFO:     Epoch: 72
2023-01-04 10:48:18,179 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3636263370513916, 'Total loss': 0.3636263370513916} | train loss {'Reaction outcome loss': 0.3199217977690632, 'Total loss': 0.3199217977690632}
2023-01-04 10:48:18,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:18,180 INFO:     Epoch: 73
2023-01-04 10:48:19,728 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3580127000808716, 'Total loss': 0.3580127000808716} | train loss {'Reaction outcome loss': 0.30413466197026445, 'Total loss': 0.30413466197026445}
2023-01-04 10:48:19,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:19,729 INFO:     Epoch: 74
2023-01-04 10:48:21,312 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.36505730748176574, 'Total loss': 0.36505730748176574} | train loss {'Reaction outcome loss': 0.30074238648597634, 'Total loss': 0.30074238648597634}
2023-01-04 10:48:21,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:21,312 INFO:     Epoch: 75
2023-01-04 10:48:22,872 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3624120463927587, 'Total loss': 0.3624120463927587} | train loss {'Reaction outcome loss': 0.30112258433971717, 'Total loss': 0.30112258433971717}
2023-01-04 10:48:22,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:22,872 INFO:     Epoch: 76
2023-01-04 10:48:24,420 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.36652600367863974, 'Total loss': 0.36652600367863974} | train loss {'Reaction outcome loss': 0.29554745641307556, 'Total loss': 0.29554745641307556}
2023-01-04 10:48:24,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:24,421 INFO:     Epoch: 77
2023-01-04 10:48:25,957 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3782911558945974, 'Total loss': 0.3782911558945974} | train loss {'Reaction outcome loss': 0.296787202467807, 'Total loss': 0.296787202467807}
2023-01-04 10:48:25,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:25,957 INFO:     Epoch: 78
2023-01-04 10:48:27,483 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.35116179088751476, 'Total loss': 0.35116179088751476} | train loss {'Reaction outcome loss': 0.294833197214968, 'Total loss': 0.294833197214968}
2023-01-04 10:48:27,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:27,484 INFO:     Epoch: 79
2023-01-04 10:48:29,099 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3480125268300374, 'Total loss': 0.3480125268300374} | train loss {'Reaction outcome loss': 0.29374900143791793, 'Total loss': 0.29374900143791793}
2023-01-04 10:48:29,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:29,099 INFO:     Epoch: 80
2023-01-04 10:48:30,715 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.35362703700860343, 'Total loss': 0.35362703700860343} | train loss {'Reaction outcome loss': 0.29199351370334625, 'Total loss': 0.29199351370334625}
2023-01-04 10:48:30,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:30,716 INFO:     Epoch: 81
2023-01-04 10:48:32,327 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3559515615304311, 'Total loss': 0.3559515615304311} | train loss {'Reaction outcome loss': 0.29944695516125014, 'Total loss': 0.29944695516125014}
2023-01-04 10:48:32,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:32,327 INFO:     Epoch: 82
2023-01-04 10:48:33,933 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3836282163858414, 'Total loss': 0.3836282163858414} | train loss {'Reaction outcome loss': 0.28798103710025735, 'Total loss': 0.28798103710025735}
2023-01-04 10:48:33,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:33,933 INFO:     Epoch: 83
2023-01-04 10:48:35,498 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.34053292175134026, 'Total loss': 0.34053292175134026} | train loss {'Reaction outcome loss': 0.292480965040024, 'Total loss': 0.292480965040024}
2023-01-04 10:48:35,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:35,498 INFO:     Epoch: 84
2023-01-04 10:48:37,065 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.35097921440998714, 'Total loss': 0.35097921440998714} | train loss {'Reaction outcome loss': 0.2867453329389969, 'Total loss': 0.2867453329389969}
2023-01-04 10:48:37,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:37,065 INFO:     Epoch: 85
2023-01-04 10:48:38,681 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.35587384800116223, 'Total loss': 0.35587384800116223} | train loss {'Reaction outcome loss': 0.2894760450159294, 'Total loss': 0.2894760450159294}
2023-01-04 10:48:38,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:38,681 INFO:     Epoch: 86
2023-01-04 10:48:40,290 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3840541104475657, 'Total loss': 0.3840541104475657} | train loss {'Reaction outcome loss': 0.31044820717964455, 'Total loss': 0.31044820717964455}
2023-01-04 10:48:40,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:40,290 INFO:     Epoch: 87
2023-01-04 10:48:41,896 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3356925765673319, 'Total loss': 0.3356925765673319} | train loss {'Reaction outcome loss': 0.2914968477950121, 'Total loss': 0.2914968477950121}
2023-01-04 10:48:41,897 INFO:     Found new best model at epoch 87
2023-01-04 10:48:41,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:41,897 INFO:     Epoch: 88
2023-01-04 10:48:43,496 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.357844074567159, 'Total loss': 0.357844074567159} | train loss {'Reaction outcome loss': 0.28592819535591896, 'Total loss': 0.28592819535591896}
2023-01-04 10:48:43,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:43,497 INFO:     Epoch: 89
2023-01-04 10:48:45,065 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.35982603977123895, 'Total loss': 0.35982603977123895} | train loss {'Reaction outcome loss': 0.2834435201302199, 'Total loss': 0.2834435201302199}
2023-01-04 10:48:45,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:45,066 INFO:     Epoch: 90
2023-01-04 10:48:46,635 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3644365777571996, 'Total loss': 0.3644365777571996} | train loss {'Reaction outcome loss': 0.28111241139719123, 'Total loss': 0.28111241139719123}
2023-01-04 10:48:46,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:46,636 INFO:     Epoch: 91
2023-01-04 10:48:48,261 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3760844727357229, 'Total loss': 0.3760844727357229} | train loss {'Reaction outcome loss': 0.2826682245628773, 'Total loss': 0.2826682245628773}
2023-01-04 10:48:48,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:48,263 INFO:     Epoch: 92
2023-01-04 10:48:49,818 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37039207816123965, 'Total loss': 0.37039207816123965} | train loss {'Reaction outcome loss': 0.30190705222001113, 'Total loss': 0.30190705222001113}
2023-01-04 10:48:49,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:49,818 INFO:     Epoch: 93
2023-01-04 10:48:51,384 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41238200664520264, 'Total loss': 0.41238200664520264} | train loss {'Reaction outcome loss': 0.28152991608152184, 'Total loss': 0.28152991608152184}
2023-01-04 10:48:51,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:51,384 INFO:     Epoch: 94
2023-01-04 10:48:52,944 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3647716815272967, 'Total loss': 0.3647716815272967} | train loss {'Reaction outcome loss': 0.27783754686622514, 'Total loss': 0.27783754686622514}
2023-01-04 10:48:52,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:52,944 INFO:     Epoch: 95
2023-01-04 10:48:54,519 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3640982796748479, 'Total loss': 0.3640982796748479} | train loss {'Reaction outcome loss': 0.2769720210627133, 'Total loss': 0.2769720210627133}
2023-01-04 10:48:54,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:54,520 INFO:     Epoch: 96
2023-01-04 10:48:56,084 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.34190745949745177, 'Total loss': 0.34190745949745177} | train loss {'Reaction outcome loss': 0.27353954307408707, 'Total loss': 0.27353954307408707}
2023-01-04 10:48:56,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:56,085 INFO:     Epoch: 97
2023-01-04 10:48:57,677 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3565993130207062, 'Total loss': 0.3565993130207062} | train loss {'Reaction outcome loss': 0.27393292854337586, 'Total loss': 0.27393292854337586}
2023-01-04 10:48:57,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:57,677 INFO:     Epoch: 98
2023-01-04 10:48:59,254 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3915222187836965, 'Total loss': 0.3915222187836965} | train loss {'Reaction outcome loss': 0.2749375911780458, 'Total loss': 0.2749375911780458}
2023-01-04 10:48:59,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:48:59,254 INFO:     Epoch: 99
2023-01-04 10:49:00,846 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3410022308429082, 'Total loss': 0.3410022308429082} | train loss {'Reaction outcome loss': 0.29140576863479195, 'Total loss': 0.29140576863479195}
2023-01-04 10:49:00,846 INFO:     Best model found after epoch 88 of 100.
2023-01-04 10:49:00,846 INFO:   Done with stage: TRAINING
2023-01-04 10:49:00,846 INFO:   Starting stage: EVALUATION
2023-01-04 10:49:00,975 INFO:   Done with stage: EVALUATION
2023-01-04 10:49:00,984 INFO:   Leaving out SEQ value Fold_0
2023-01-04 10:49:00,996 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 10:49:00,996 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:49:01,635 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:49:01,635 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:49:01,703 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:49:01,703 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:49:01,703 INFO:     No hyperparam tuning for this model
2023-01-04 10:49:01,703 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:49:01,703 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:49:01,704 INFO:     None feature selector for col prot
2023-01-04 10:49:01,704 INFO:     None feature selector for col prot
2023-01-04 10:49:01,704 INFO:     None feature selector for col prot
2023-01-04 10:49:01,705 INFO:     None feature selector for col chem
2023-01-04 10:49:01,705 INFO:     None feature selector for col chem
2023-01-04 10:49:01,705 INFO:     None feature selector for col chem
2023-01-04 10:49:01,705 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:49:01,705 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:49:01,706 INFO:     Number of params in model 70111
2023-01-04 10:49:01,709 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:49:01,709 INFO:   Starting stage: TRAINING
2023-01-04 10:49:01,745 INFO:     Val loss before train {'Reaction outcome loss': 1.0151295423507691, 'Total loss': 1.0151295423507691}
2023-01-04 10:49:01,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:01,745 INFO:     Epoch: 0
2023-01-04 10:49:03,332 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7294021824995677, 'Total loss': 0.7294021824995677} | train loss {'Reaction outcome loss': 0.8396157785488741, 'Total loss': 0.8396157785488741}
2023-01-04 10:49:03,332 INFO:     Found new best model at epoch 0
2023-01-04 10:49:03,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:03,333 INFO:     Epoch: 1
2023-01-04 10:49:04,939 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6128531754016876, 'Total loss': 0.6128531754016876} | train loss {'Reaction outcome loss': 0.6640171596821207, 'Total loss': 0.6640171596821207}
2023-01-04 10:49:04,939 INFO:     Found new best model at epoch 1
2023-01-04 10:49:04,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:04,940 INFO:     Epoch: 2
2023-01-04 10:49:06,549 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.58433096408844, 'Total loss': 0.58433096408844} | train loss {'Reaction outcome loss': 0.5744799466898841, 'Total loss': 0.5744799466898841}
2023-01-04 10:49:06,550 INFO:     Found new best model at epoch 2
2023-01-04 10:49:06,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:06,550 INFO:     Epoch: 3
2023-01-04 10:49:08,157 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.549857747554779, 'Total loss': 0.549857747554779} | train loss {'Reaction outcome loss': 0.5434734931174856, 'Total loss': 0.5434734931174856}
2023-01-04 10:49:08,157 INFO:     Found new best model at epoch 3
2023-01-04 10:49:08,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:08,158 INFO:     Epoch: 4
2023-01-04 10:49:09,767 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5578594545523325, 'Total loss': 0.5578594545523325} | train loss {'Reaction outcome loss': 0.5188305795627789, 'Total loss': 0.5188305795627789}
2023-01-04 10:49:09,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:09,767 INFO:     Epoch: 5
2023-01-04 10:49:11,321 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49984795053799946, 'Total loss': 0.49984795053799946} | train loss {'Reaction outcome loss': 0.5054233471189973, 'Total loss': 0.5054233471189973}
2023-01-04 10:49:11,321 INFO:     Found new best model at epoch 5
2023-01-04 10:49:11,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:11,322 INFO:     Epoch: 6
2023-01-04 10:49:12,890 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47456305027008056, 'Total loss': 0.47456305027008056} | train loss {'Reaction outcome loss': 0.4948941638869961, 'Total loss': 0.4948941638869961}
2023-01-04 10:49:12,890 INFO:     Found new best model at epoch 6
2023-01-04 10:49:12,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:12,891 INFO:     Epoch: 7
2023-01-04 10:49:14,502 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5044554819663366, 'Total loss': 0.5044554819663366} | train loss {'Reaction outcome loss': 0.48343468490090685, 'Total loss': 0.48343468490090685}
2023-01-04 10:49:14,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:14,503 INFO:     Epoch: 8
2023-01-04 10:49:16,118 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46280094186464943, 'Total loss': 0.46280094186464943} | train loss {'Reaction outcome loss': 0.48077017232014313, 'Total loss': 0.48077017232014313}
2023-01-04 10:49:16,118 INFO:     Found new best model at epoch 8
2023-01-04 10:49:16,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:16,119 INFO:     Epoch: 9
2023-01-04 10:49:17,727 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4860520382722219, 'Total loss': 0.4860520382722219} | train loss {'Reaction outcome loss': 0.4695431465541359, 'Total loss': 0.4695431465541359}
2023-01-04 10:49:17,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:17,727 INFO:     Epoch: 10
2023-01-04 10:49:19,332 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4615765273571014, 'Total loss': 0.4615765273571014} | train loss {'Reaction outcome loss': 0.46557231125061527, 'Total loss': 0.46557231125061527}
2023-01-04 10:49:19,333 INFO:     Found new best model at epoch 10
2023-01-04 10:49:19,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:19,334 INFO:     Epoch: 11
2023-01-04 10:49:20,884 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48820165594418846, 'Total loss': 0.48820165594418846} | train loss {'Reaction outcome loss': 0.45883911385805937, 'Total loss': 0.45883911385805937}
2023-01-04 10:49:20,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:20,884 INFO:     Epoch: 12
2023-01-04 10:49:22,443 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4622478683789571, 'Total loss': 0.4622478683789571} | train loss {'Reaction outcome loss': 0.4513811231964696, 'Total loss': 0.4513811231964696}
2023-01-04 10:49:22,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:22,443 INFO:     Epoch: 13
2023-01-04 10:49:24,043 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49180739720662436, 'Total loss': 0.49180739720662436} | train loss {'Reaction outcome loss': 0.448747702677102, 'Total loss': 0.448747702677102}
2023-01-04 10:49:24,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:24,043 INFO:     Epoch: 14
2023-01-04 10:49:25,630 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.436547115445137, 'Total loss': 0.436547115445137} | train loss {'Reaction outcome loss': 0.4416549559818567, 'Total loss': 0.4416549559818567}
2023-01-04 10:49:25,630 INFO:     Found new best model at epoch 14
2023-01-04 10:49:25,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:25,631 INFO:     Epoch: 15
2023-01-04 10:49:27,242 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44598207076390584, 'Total loss': 0.44598207076390584} | train loss {'Reaction outcome loss': 0.4384755480245952, 'Total loss': 0.4384755480245952}
2023-01-04 10:49:27,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:27,242 INFO:     Epoch: 16
2023-01-04 10:49:28,848 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4776915768782298, 'Total loss': 0.4776915768782298} | train loss {'Reaction outcome loss': 0.43084901299354805, 'Total loss': 0.43084901299354805}
2023-01-04 10:49:28,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:28,848 INFO:     Epoch: 17
2023-01-04 10:49:30,417 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.444788138071696, 'Total loss': 0.444788138071696} | train loss {'Reaction outcome loss': 0.4293425541071996, 'Total loss': 0.4293425541071996}
2023-01-04 10:49:30,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:30,417 INFO:     Epoch: 18
2023-01-04 10:49:31,975 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43343858122825624, 'Total loss': 0.43343858122825624} | train loss {'Reaction outcome loss': 0.4272740644531964, 'Total loss': 0.4272740644531964}
2023-01-04 10:49:31,975 INFO:     Found new best model at epoch 18
2023-01-04 10:49:31,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:31,975 INFO:     Epoch: 19
2023-01-04 10:49:33,593 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44136387507120767, 'Total loss': 0.44136387507120767} | train loss {'Reaction outcome loss': 0.41842623783724153, 'Total loss': 0.41842623783724153}
2023-01-04 10:49:33,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:33,593 INFO:     Epoch: 20
2023-01-04 10:49:35,196 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.410993891954422, 'Total loss': 0.410993891954422} | train loss {'Reaction outcome loss': 0.41278912469635914, 'Total loss': 0.41278912469635914}
2023-01-04 10:49:35,196 INFO:     Found new best model at epoch 20
2023-01-04 10:49:35,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:35,197 INFO:     Epoch: 21
2023-01-04 10:49:36,813 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4431759476661682, 'Total loss': 0.4431759476661682} | train loss {'Reaction outcome loss': 0.40983671776569675, 'Total loss': 0.40983671776569675}
2023-01-04 10:49:36,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:36,814 INFO:     Epoch: 22
2023-01-04 10:49:38,389 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43838173349698384, 'Total loss': 0.43838173349698384} | train loss {'Reaction outcome loss': 0.4065957123780773, 'Total loss': 0.4065957123780773}
2023-01-04 10:49:38,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:38,390 INFO:     Epoch: 23
2023-01-04 10:49:39,947 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4401706099510193, 'Total loss': 0.4401706099510193} | train loss {'Reaction outcome loss': 0.4013674639328553, 'Total loss': 0.4013674639328553}
2023-01-04 10:49:39,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:39,947 INFO:     Epoch: 24
2023-01-04 10:49:41,558 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41702181895573937, 'Total loss': 0.41702181895573937} | train loss {'Reaction outcome loss': 0.39821438219425453, 'Total loss': 0.39821438219425453}
2023-01-04 10:49:41,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:41,558 INFO:     Epoch: 25
2023-01-04 10:49:43,181 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4024873370925585, 'Total loss': 0.4024873370925585} | train loss {'Reaction outcome loss': 0.3960631841073071, 'Total loss': 0.3960631841073071}
2023-01-04 10:49:43,181 INFO:     Found new best model at epoch 25
2023-01-04 10:49:43,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:43,181 INFO:     Epoch: 26
2023-01-04 10:49:44,787 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.444302033384641, 'Total loss': 0.444302033384641} | train loss {'Reaction outcome loss': 0.3897672031265106, 'Total loss': 0.3897672031265106}
2023-01-04 10:49:44,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:44,787 INFO:     Epoch: 27
2023-01-04 10:49:46,370 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42189465314149854, 'Total loss': 0.42189465314149854} | train loss {'Reaction outcome loss': 0.3890916158574341, 'Total loss': 0.3890916158574341}
2023-01-04 10:49:46,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:46,370 INFO:     Epoch: 28
2023-01-04 10:49:47,927 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4188501407702764, 'Total loss': 0.4188501407702764} | train loss {'Reaction outcome loss': 0.38271630979584953, 'Total loss': 0.38271630979584953}
2023-01-04 10:49:47,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:47,927 INFO:     Epoch: 29
2023-01-04 10:49:49,479 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4076404814918836, 'Total loss': 0.4076404814918836} | train loss {'Reaction outcome loss': 0.37851055600021005, 'Total loss': 0.37851055600021005}
2023-01-04 10:49:49,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:49,479 INFO:     Epoch: 30
2023-01-04 10:49:51,085 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4313383370637894, 'Total loss': 0.4313383370637894} | train loss {'Reaction outcome loss': 0.37696301454447045, 'Total loss': 0.37696301454447045}
2023-01-04 10:49:51,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:51,085 INFO:     Epoch: 31
2023-01-04 10:49:52,693 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44811994830767315, 'Total loss': 0.44811994830767315} | train loss {'Reaction outcome loss': 0.37291302931678555, 'Total loss': 0.37291302931678555}
2023-01-04 10:49:52,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:52,694 INFO:     Epoch: 32
2023-01-04 10:49:54,295 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41217745939890543, 'Total loss': 0.41217745939890543} | train loss {'Reaction outcome loss': 0.3710130655689396, 'Total loss': 0.3710130655689396}
2023-01-04 10:49:54,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:54,296 INFO:     Epoch: 33
2023-01-04 10:49:55,905 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40623817443847654, 'Total loss': 0.40623817443847654} | train loss {'Reaction outcome loss': 0.36691804007239587, 'Total loss': 0.36691804007239587}
2023-01-04 10:49:55,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:55,905 INFO:     Epoch: 34
2023-01-04 10:49:57,465 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41929995715618135, 'Total loss': 0.41929995715618135} | train loss {'Reaction outcome loss': 0.36349237881546476, 'Total loss': 0.36349237881546476}
2023-01-04 10:49:57,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:57,466 INFO:     Epoch: 35
2023-01-04 10:49:59,007 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4266200840473175, 'Total loss': 0.4266200840473175} | train loss {'Reaction outcome loss': 0.358524593748968, 'Total loss': 0.358524593748968}
2023-01-04 10:49:59,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:49:59,008 INFO:     Epoch: 36
2023-01-04 10:50:00,607 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43479712804158527, 'Total loss': 0.43479712804158527} | train loss {'Reaction outcome loss': 0.3551878820642503, 'Total loss': 0.3551878820642503}
2023-01-04 10:50:00,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:00,608 INFO:     Epoch: 37
2023-01-04 10:50:02,206 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41414912343025206, 'Total loss': 0.41414912343025206} | train loss {'Reaction outcome loss': 0.3560047585272441, 'Total loss': 0.3560047585272441}
2023-01-04 10:50:02,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:02,206 INFO:     Epoch: 38
2023-01-04 10:50:03,809 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4249455471833547, 'Total loss': 0.4249455471833547} | train loss {'Reaction outcome loss': 0.35225727047472105, 'Total loss': 0.35225727047472105}
2023-01-04 10:50:03,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:03,810 INFO:     Epoch: 39
2023-01-04 10:50:05,423 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.385985071460406, 'Total loss': 0.385985071460406} | train loss {'Reaction outcome loss': 0.3481025913335981, 'Total loss': 0.3481025913335981}
2023-01-04 10:50:05,423 INFO:     Found new best model at epoch 39
2023-01-04 10:50:05,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:05,423 INFO:     Epoch: 40
2023-01-04 10:50:06,991 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4097368776798248, 'Total loss': 0.4097368776798248} | train loss {'Reaction outcome loss': 0.34213699974174044, 'Total loss': 0.34213699974174044}
2023-01-04 10:50:06,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:06,991 INFO:     Epoch: 41
2023-01-04 10:50:08,561 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42095716993014015, 'Total loss': 0.42095716993014015} | train loss {'Reaction outcome loss': 0.34070569298563214, 'Total loss': 0.34070569298563214}
2023-01-04 10:50:08,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:08,561 INFO:     Epoch: 42
2023-01-04 10:50:10,177 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38835637718439103, 'Total loss': 0.38835637718439103} | train loss {'Reaction outcome loss': 0.3386120828290055, 'Total loss': 0.3386120828290055}
2023-01-04 10:50:10,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:10,177 INFO:     Epoch: 43
2023-01-04 10:50:11,783 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4108407884836197, 'Total loss': 0.4108407884836197} | train loss {'Reaction outcome loss': 0.33619358994229864, 'Total loss': 0.33619358994229864}
2023-01-04 10:50:11,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:11,783 INFO:     Epoch: 44
2023-01-04 10:50:13,383 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4210490196943283, 'Total loss': 0.4210490196943283} | train loss {'Reaction outcome loss': 0.33458562331260555, 'Total loss': 0.33458562331260555}
2023-01-04 10:50:13,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:13,384 INFO:     Epoch: 45
2023-01-04 10:50:14,956 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43194859425226845, 'Total loss': 0.43194859425226845} | train loss {'Reaction outcome loss': 0.33146752555766246, 'Total loss': 0.33146752555766246}
2023-01-04 10:50:14,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:14,956 INFO:     Epoch: 46
2023-01-04 10:50:16,521 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40535638729731244, 'Total loss': 0.40535638729731244} | train loss {'Reaction outcome loss': 0.3274380411191361, 'Total loss': 0.3274380411191361}
2023-01-04 10:50:16,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:16,522 INFO:     Epoch: 47
2023-01-04 10:50:18,131 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4227006455262502, 'Total loss': 0.4227006455262502} | train loss {'Reaction outcome loss': 0.3276686336654816, 'Total loss': 0.3276686336654816}
2023-01-04 10:50:18,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:18,131 INFO:     Epoch: 48
2023-01-04 10:50:19,726 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4097245375315348, 'Total loss': 0.4097245375315348} | train loss {'Reaction outcome loss': 0.3232031335959034, 'Total loss': 0.3232031335959034}
2023-01-04 10:50:19,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:19,726 INFO:     Epoch: 49
2023-01-04 10:50:21,333 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39428490300973257, 'Total loss': 0.39428490300973257} | train loss {'Reaction outcome loss': 0.31877057197211434, 'Total loss': 0.31877057197211434}
2023-01-04 10:50:21,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:21,333 INFO:     Epoch: 50
2023-01-04 10:50:22,946 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3982417305310567, 'Total loss': 0.3982417305310567} | train loss {'Reaction outcome loss': 0.3176373174536402, 'Total loss': 0.3176373174536402}
2023-01-04 10:50:22,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:22,946 INFO:     Epoch: 51
2023-01-04 10:50:24,518 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3999302496512731, 'Total loss': 0.3999302496512731} | train loss {'Reaction outcome loss': 0.316661086450093, 'Total loss': 0.316661086450093}
2023-01-04 10:50:24,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:24,518 INFO:     Epoch: 52
2023-01-04 10:50:26,079 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38545380731423695, 'Total loss': 0.38545380731423695} | train loss {'Reaction outcome loss': 0.3155195791899723, 'Total loss': 0.3155195791899723}
2023-01-04 10:50:26,079 INFO:     Found new best model at epoch 52
2023-01-04 10:50:26,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:26,080 INFO:     Epoch: 53
2023-01-04 10:50:27,698 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38503773311773937, 'Total loss': 0.38503773311773937} | train loss {'Reaction outcome loss': 0.3124462132525705, 'Total loss': 0.3124462132525705}
2023-01-04 10:50:27,698 INFO:     Found new best model at epoch 53
2023-01-04 10:50:27,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:27,699 INFO:     Epoch: 54
2023-01-04 10:50:29,314 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40169492562611897, 'Total loss': 0.40169492562611897} | train loss {'Reaction outcome loss': 0.31158841533219295, 'Total loss': 0.31158841533219295}
2023-01-04 10:50:29,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:29,314 INFO:     Epoch: 55
2023-01-04 10:50:30,924 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38800494571526845, 'Total loss': 0.38800494571526845} | train loss {'Reaction outcome loss': 0.30735159866566203, 'Total loss': 0.30735159866566203}
2023-01-04 10:50:30,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:30,926 INFO:     Epoch: 56
2023-01-04 10:50:32,522 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37089050312836963, 'Total loss': 0.37089050312836963} | train loss {'Reaction outcome loss': 0.30416445716889234, 'Total loss': 0.30416445716889234}
2023-01-04 10:50:32,522 INFO:     Found new best model at epoch 56
2023-01-04 10:50:32,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:32,523 INFO:     Epoch: 57
2023-01-04 10:50:34,087 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3871860295534134, 'Total loss': 0.3871860295534134} | train loss {'Reaction outcome loss': 0.3013552224440296, 'Total loss': 0.3013552224440296}
2023-01-04 10:50:34,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:34,088 INFO:     Epoch: 58
2023-01-04 10:50:35,640 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3931708335876465, 'Total loss': 0.3931708335876465} | train loss {'Reaction outcome loss': 0.3008981834906731, 'Total loss': 0.3008981834906731}
2023-01-04 10:50:35,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:35,640 INFO:     Epoch: 59
2023-01-04 10:50:37,249 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3838722546895345, 'Total loss': 0.3838722546895345} | train loss {'Reaction outcome loss': 0.3006310754992666, 'Total loss': 0.3006310754992666}
2023-01-04 10:50:37,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:37,250 INFO:     Epoch: 60
2023-01-04 10:50:38,859 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40910965800285337, 'Total loss': 0.40910965800285337} | train loss {'Reaction outcome loss': 0.29977687671236747, 'Total loss': 0.29977687671236747}
2023-01-04 10:50:38,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:38,859 INFO:     Epoch: 61
2023-01-04 10:50:40,464 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.404743101199468, 'Total loss': 0.404743101199468} | train loss {'Reaction outcome loss': 0.30016720591344104, 'Total loss': 0.30016720591344104}
2023-01-04 10:50:40,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:40,465 INFO:     Epoch: 62
2023-01-04 10:50:42,040 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41086163421471916, 'Total loss': 0.41086163421471916} | train loss {'Reaction outcome loss': 0.2963845180551501, 'Total loss': 0.2963845180551501}
2023-01-04 10:50:42,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:42,040 INFO:     Epoch: 63
2023-01-04 10:50:43,626 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.389411915342013, 'Total loss': 0.389411915342013} | train loss {'Reaction outcome loss': 0.29643477507642585, 'Total loss': 0.29643477507642585}
2023-01-04 10:50:43,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:43,626 INFO:     Epoch: 64
2023-01-04 10:50:45,234 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3858650406201681, 'Total loss': 0.3858650406201681} | train loss {'Reaction outcome loss': 0.29203104929332313, 'Total loss': 0.29203104929332313}
2023-01-04 10:50:45,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:45,234 INFO:     Epoch: 65
2023-01-04 10:50:46,848 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39080190857251484, 'Total loss': 0.39080190857251484} | train loss {'Reaction outcome loss': 0.2920437800786356, 'Total loss': 0.2920437800786356}
2023-01-04 10:50:46,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:46,848 INFO:     Epoch: 66
2023-01-04 10:50:48,465 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.378594101468722, 'Total loss': 0.378594101468722} | train loss {'Reaction outcome loss': 0.2859395934255236, 'Total loss': 0.2859395934255236}
2023-01-04 10:50:48,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:48,465 INFO:     Epoch: 67
2023-01-04 10:50:50,081 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42196002701918284, 'Total loss': 0.42196002701918284} | train loss {'Reaction outcome loss': 0.29025663740008417, 'Total loss': 0.29025663740008417}
2023-01-04 10:50:50,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:50,082 INFO:     Epoch: 68
2023-01-04 10:50:51,650 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3779181589682897, 'Total loss': 0.3779181589682897} | train loss {'Reaction outcome loss': 0.2885854593648093, 'Total loss': 0.2885854593648093}
2023-01-04 10:50:51,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:51,650 INFO:     Epoch: 69
2023-01-04 10:50:53,195 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3913212686777115, 'Total loss': 0.3913212686777115} | train loss {'Reaction outcome loss': 0.2871802662818754, 'Total loss': 0.2871802662818754}
2023-01-04 10:50:53,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:53,196 INFO:     Epoch: 70
2023-01-04 10:50:54,791 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4038133919239044, 'Total loss': 0.4038133919239044} | train loss {'Reaction outcome loss': 0.27966142492028917, 'Total loss': 0.27966142492028917}
2023-01-04 10:50:54,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:54,791 INFO:     Epoch: 71
2023-01-04 10:50:56,399 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3827809770901998, 'Total loss': 0.3827809770901998} | train loss {'Reaction outcome loss': 0.2810178147153045, 'Total loss': 0.2810178147153045}
2023-01-04 10:50:56,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:56,399 INFO:     Epoch: 72
2023-01-04 10:50:57,995 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38540030817190807, 'Total loss': 0.38540030817190807} | train loss {'Reaction outcome loss': 0.2783512693632693, 'Total loss': 0.2783512693632693}
2023-01-04 10:50:57,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:57,995 INFO:     Epoch: 73
2023-01-04 10:50:59,559 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4196594645579656, 'Total loss': 0.4196594645579656} | train loss {'Reaction outcome loss': 0.278104356102591, 'Total loss': 0.278104356102591}
2023-01-04 10:50:59,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:50:59,559 INFO:     Epoch: 74
2023-01-04 10:51:01,106 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3951871852080027, 'Total loss': 0.3951871852080027} | train loss {'Reaction outcome loss': 0.2767989305629782, 'Total loss': 0.2767989305629782}
2023-01-04 10:51:01,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:01,107 INFO:     Epoch: 75
2023-01-04 10:51:02,632 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4033895899852117, 'Total loss': 0.4033895899852117} | train loss {'Reaction outcome loss': 0.27814146748533214, 'Total loss': 0.27814146748533214}
2023-01-04 10:51:02,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:02,632 INFO:     Epoch: 76
2023-01-04 10:51:04,216 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.409413422147433, 'Total loss': 0.409413422147433} | train loss {'Reaction outcome loss': 0.279441665939606, 'Total loss': 0.279441665939606}
2023-01-04 10:51:04,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:04,216 INFO:     Epoch: 77
2023-01-04 10:51:05,796 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3757549067338308, 'Total loss': 0.3757549067338308} | train loss {'Reaction outcome loss': 0.2744317411234344, 'Total loss': 0.2744317411234344}
2023-01-04 10:51:05,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:05,797 INFO:     Epoch: 78
2023-01-04 10:51:07,405 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38921055346727373, 'Total loss': 0.38921055346727373} | train loss {'Reaction outcome loss': 0.27354306094076514, 'Total loss': 0.27354306094076514}
2023-01-04 10:51:07,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:07,406 INFO:     Epoch: 79
2023-01-04 10:51:09,015 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3825468291838964, 'Total loss': 0.3825468291838964} | train loss {'Reaction outcome loss': 0.2707655092660528, 'Total loss': 0.2707655092660528}
2023-01-04 10:51:09,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:09,015 INFO:     Epoch: 80
2023-01-04 10:51:10,556 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38965360124905907, 'Total loss': 0.38965360124905907} | train loss {'Reaction outcome loss': 0.27348659878229575, 'Total loss': 0.27348659878229575}
2023-01-04 10:51:10,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:10,556 INFO:     Epoch: 81
2023-01-04 10:51:12,094 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3982531398534775, 'Total loss': 0.3982531398534775} | train loss {'Reaction outcome loss': 0.27315727992486344, 'Total loss': 0.27315727992486344}
2023-01-04 10:51:12,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:12,094 INFO:     Epoch: 82
2023-01-04 10:51:13,693 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3927447497844696, 'Total loss': 0.3927447497844696} | train loss {'Reaction outcome loss': 0.2683202406513865, 'Total loss': 0.2683202406513865}
2023-01-04 10:51:13,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:13,694 INFO:     Epoch: 83
2023-01-04 10:51:15,260 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40250523189703624, 'Total loss': 0.40250523189703624} | train loss {'Reaction outcome loss': 0.26854121418547455, 'Total loss': 0.26854121418547455}
2023-01-04 10:51:15,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:15,260 INFO:     Epoch: 84
2023-01-04 10:51:16,837 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3829225718975067, 'Total loss': 0.3829225718975067} | train loss {'Reaction outcome loss': 0.2699888031793772, 'Total loss': 0.2699888031793772}
2023-01-04 10:51:16,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:16,837 INFO:     Epoch: 85
2023-01-04 10:51:18,409 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38664818306763965, 'Total loss': 0.38664818306763965} | train loss {'Reaction outcome loss': 0.26569878312684325, 'Total loss': 0.26569878312684325}
2023-01-04 10:51:18,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:18,410 INFO:     Epoch: 86
2023-01-04 10:51:19,963 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3936724543571472, 'Total loss': 0.3936724543571472} | train loss {'Reaction outcome loss': 0.26303137270529775, 'Total loss': 0.26303137270529775}
2023-01-04 10:51:19,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:19,963 INFO:     Epoch: 87
2023-01-04 10:51:21,530 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38357087473074597, 'Total loss': 0.38357087473074597} | train loss {'Reaction outcome loss': 0.26727532008051, 'Total loss': 0.26727532008051}
2023-01-04 10:51:21,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:21,530 INFO:     Epoch: 88
2023-01-04 10:51:23,111 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37823115984598793, 'Total loss': 0.37823115984598793} | train loss {'Reaction outcome loss': 0.2608206372735274, 'Total loss': 0.2608206372735274}
2023-01-04 10:51:23,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:23,111 INFO:     Epoch: 89
2023-01-04 10:51:24,699 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38734440902868905, 'Total loss': 0.38734440902868905} | train loss {'Reaction outcome loss': 0.2617349884044515, 'Total loss': 0.2617349884044515}
2023-01-04 10:51:24,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:24,699 INFO:     Epoch: 90
2023-01-04 10:51:26,282 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.398162849744161, 'Total loss': 0.398162849744161} | train loss {'Reaction outcome loss': 0.25747261113439596, 'Total loss': 0.25747261113439596}
2023-01-04 10:51:26,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:26,283 INFO:     Epoch: 91
2023-01-04 10:51:27,841 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4272222280502319, 'Total loss': 0.4272222280502319} | train loss {'Reaction outcome loss': 0.25665443483060296, 'Total loss': 0.25665443483060296}
2023-01-04 10:51:27,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:27,841 INFO:     Epoch: 92
2023-01-04 10:51:29,394 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.369917294383049, 'Total loss': 0.369917294383049} | train loss {'Reaction outcome loss': 0.26099490042585527, 'Total loss': 0.26099490042585527}
2023-01-04 10:51:29,395 INFO:     Found new best model at epoch 92
2023-01-04 10:51:29,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:29,395 INFO:     Epoch: 93
2023-01-04 10:51:30,990 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.377187176545461, 'Total loss': 0.377187176545461} | train loss {'Reaction outcome loss': 0.261523273603542, 'Total loss': 0.261523273603542}
2023-01-04 10:51:30,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:30,990 INFO:     Epoch: 94
2023-01-04 10:51:32,566 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38140505850315093, 'Total loss': 0.38140505850315093} | train loss {'Reaction outcome loss': 0.25804421952823653, 'Total loss': 0.25804421952823653}
2023-01-04 10:51:32,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:32,566 INFO:     Epoch: 95
2023-01-04 10:51:34,156 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3797521725296974, 'Total loss': 0.3797521725296974} | train loss {'Reaction outcome loss': 0.25189961517488, 'Total loss': 0.25189961517488}
2023-01-04 10:51:34,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:34,156 INFO:     Epoch: 96
2023-01-04 10:51:35,748 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3794456998507182, 'Total loss': 0.3794456998507182} | train loss {'Reaction outcome loss': 0.25579455698819925, 'Total loss': 0.25579455698819925}
2023-01-04 10:51:35,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:35,748 INFO:     Epoch: 97
2023-01-04 10:51:37,292 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40309842030207316, 'Total loss': 0.40309842030207316} | train loss {'Reaction outcome loss': 0.2529723769475291, 'Total loss': 0.2529723769475291}
2023-01-04 10:51:37,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:37,292 INFO:     Epoch: 98
2023-01-04 10:51:38,838 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39387338956197104, 'Total loss': 0.39387338956197104} | train loss {'Reaction outcome loss': 0.2511295758758801, 'Total loss': 0.2511295758758801}
2023-01-04 10:51:38,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:38,838 INFO:     Epoch: 99
2023-01-04 10:51:40,376 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37078525523344674, 'Total loss': 0.37078525523344674} | train loss {'Reaction outcome loss': 0.2511755891253043, 'Total loss': 0.2511755891253043}
2023-01-04 10:51:40,376 INFO:     Best model found after epoch 93 of 100.
2023-01-04 10:51:40,376 INFO:   Done with stage: TRAINING
2023-01-04 10:51:40,376 INFO:   Starting stage: EVALUATION
2023-01-04 10:51:40,511 INFO:   Done with stage: EVALUATION
2023-01-04 10:51:40,511 INFO:   Leaving out SEQ value Fold_1
2023-01-04 10:51:40,523 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 10:51:40,523 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:51:41,159 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:51:41,159 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:51:41,226 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:51:41,226 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:51:41,226 INFO:     No hyperparam tuning for this model
2023-01-04 10:51:41,226 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:51:41,226 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:51:41,227 INFO:     None feature selector for col prot
2023-01-04 10:51:41,227 INFO:     None feature selector for col prot
2023-01-04 10:51:41,227 INFO:     None feature selector for col prot
2023-01-04 10:51:41,228 INFO:     None feature selector for col chem
2023-01-04 10:51:41,228 INFO:     None feature selector for col chem
2023-01-04 10:51:41,228 INFO:     None feature selector for col chem
2023-01-04 10:51:41,228 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:51:41,228 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:51:41,229 INFO:     Number of params in model 70111
2023-01-04 10:51:41,232 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:51:41,232 INFO:   Starting stage: TRAINING
2023-01-04 10:51:41,275 INFO:     Val loss before train {'Reaction outcome loss': 0.9405062516530355, 'Total loss': 0.9405062516530355}
2023-01-04 10:51:41,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:41,275 INFO:     Epoch: 0
2023-01-04 10:51:42,795 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6838044961293538, 'Total loss': 0.6838044961293538} | train loss {'Reaction outcome loss': 0.8552552310975043, 'Total loss': 0.8552552310975043}
2023-01-04 10:51:42,796 INFO:     Found new best model at epoch 0
2023-01-04 10:51:42,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:42,797 INFO:     Epoch: 1
2023-01-04 10:51:44,327 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.59322749376297, 'Total loss': 0.59322749376297} | train loss {'Reaction outcome loss': 0.7130399283035335, 'Total loss': 0.7130399283035335}
2023-01-04 10:51:44,328 INFO:     Found new best model at epoch 1
2023-01-04 10:51:44,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:44,328 INFO:     Epoch: 2
2023-01-04 10:51:45,814 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5129941999912262, 'Total loss': 0.5129941999912262} | train loss {'Reaction outcome loss': 0.6233564247360159, 'Total loss': 0.6233564247360159}
2023-01-04 10:51:45,814 INFO:     Found new best model at epoch 2
2023-01-04 10:51:45,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:45,815 INFO:     Epoch: 3
2023-01-04 10:51:47,322 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5043160438537597, 'Total loss': 0.5043160438537597} | train loss {'Reaction outcome loss': 0.5730447749515156, 'Total loss': 0.5730447749515156}
2023-01-04 10:51:47,322 INFO:     Found new best model at epoch 3
2023-01-04 10:51:47,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:47,323 INFO:     Epoch: 4
2023-01-04 10:51:48,856 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4874971608320872, 'Total loss': 0.4874971608320872} | train loss {'Reaction outcome loss': 0.5441452804065886, 'Total loss': 0.5441452804065886}
2023-01-04 10:51:48,857 INFO:     Found new best model at epoch 4
2023-01-04 10:51:48,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:48,857 INFO:     Epoch: 5
2023-01-04 10:51:50,388 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45540293455123904, 'Total loss': 0.45540293455123904} | train loss {'Reaction outcome loss': 0.5246185481875807, 'Total loss': 0.5246185481875807}
2023-01-04 10:51:50,389 INFO:     Found new best model at epoch 5
2023-01-04 10:51:50,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:50,389 INFO:     Epoch: 6
2023-01-04 10:51:51,933 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42738973498344424, 'Total loss': 0.42738973498344424} | train loss {'Reaction outcome loss': 0.516820001351091, 'Total loss': 0.516820001351091}
2023-01-04 10:51:51,933 INFO:     Found new best model at epoch 6
2023-01-04 10:51:51,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:51,934 INFO:     Epoch: 7
2023-01-04 10:51:53,486 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43520774841308596, 'Total loss': 0.43520774841308596} | train loss {'Reaction outcome loss': 0.5042843586686767, 'Total loss': 0.5042843586686767}
2023-01-04 10:51:53,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:53,486 INFO:     Epoch: 8
2023-01-04 10:51:54,982 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4129858881235123, 'Total loss': 0.4129858881235123} | train loss {'Reaction outcome loss': 0.4958596895465921, 'Total loss': 0.4958596895465921}
2023-01-04 10:51:54,982 INFO:     Found new best model at epoch 8
2023-01-04 10:51:54,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:54,983 INFO:     Epoch: 9
2023-01-04 10:51:56,494 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43841147323449453, 'Total loss': 0.43841147323449453} | train loss {'Reaction outcome loss': 0.48953544018251116, 'Total loss': 0.48953544018251116}
2023-01-04 10:51:56,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:56,494 INFO:     Epoch: 10
2023-01-04 10:51:58,031 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4228510955969493, 'Total loss': 0.4228510955969493} | train loss {'Reaction outcome loss': 0.4851330714675533, 'Total loss': 0.4851330714675533}
2023-01-04 10:51:58,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:58,031 INFO:     Epoch: 11
2023-01-04 10:51:59,620 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41239402890205384, 'Total loss': 0.41239402890205384} | train loss {'Reaction outcome loss': 0.4754066186182665, 'Total loss': 0.4754066186182665}
2023-01-04 10:51:59,620 INFO:     Found new best model at epoch 11
2023-01-04 10:51:59,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:51:59,621 INFO:     Epoch: 12
2023-01-04 10:52:01,203 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39789448380470277, 'Total loss': 0.39789448380470277} | train loss {'Reaction outcome loss': 0.4716282149046769, 'Total loss': 0.4716282149046769}
2023-01-04 10:52:01,204 INFO:     Found new best model at epoch 12
2023-01-04 10:52:01,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:01,205 INFO:     Epoch: 13
2023-01-04 10:52:02,786 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3959118296702703, 'Total loss': 0.3959118296702703} | train loss {'Reaction outcome loss': 0.46610559566772025, 'Total loss': 0.46610559566772025}
2023-01-04 10:52:02,787 INFO:     Found new best model at epoch 13
2023-01-04 10:52:02,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:02,788 INFO:     Epoch: 14
2023-01-04 10:52:04,327 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4091700216134389, 'Total loss': 0.4091700216134389} | train loss {'Reaction outcome loss': 0.46241234493997946, 'Total loss': 0.46241234493997946}
2023-01-04 10:52:04,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:04,327 INFO:     Epoch: 15
2023-01-04 10:52:05,874 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3964908013741175, 'Total loss': 0.3964908013741175} | train loss {'Reaction outcome loss': 0.4542329446190879, 'Total loss': 0.4542329446190879}
2023-01-04 10:52:05,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:05,874 INFO:     Epoch: 16
2023-01-04 10:52:07,463 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3834721972544988, 'Total loss': 0.3834721972544988} | train loss {'Reaction outcome loss': 0.4554187839393651, 'Total loss': 0.4554187839393651}
2023-01-04 10:52:07,464 INFO:     Found new best model at epoch 16
2023-01-04 10:52:07,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:07,465 INFO:     Epoch: 17
2023-01-04 10:52:08,981 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39723780850569407, 'Total loss': 0.39723780850569407} | train loss {'Reaction outcome loss': 0.4494739643165043, 'Total loss': 0.4494739643165043}
2023-01-04 10:52:08,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:08,981 INFO:     Epoch: 18
2023-01-04 10:52:10,489 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40314712723096213, 'Total loss': 0.40314712723096213} | train loss {'Reaction outcome loss': 0.44511484114569183, 'Total loss': 0.44511484114569183}
2023-01-04 10:52:10,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:10,489 INFO:     Epoch: 19
2023-01-04 10:52:12,028 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38183409969011944, 'Total loss': 0.38183409969011944} | train loss {'Reaction outcome loss': 0.43669700909119386, 'Total loss': 0.43669700909119386}
2023-01-04 10:52:12,028 INFO:     Found new best model at epoch 19
2023-01-04 10:52:12,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:12,029 INFO:     Epoch: 20
2023-01-04 10:52:13,528 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4169071306784948, 'Total loss': 0.4169071306784948} | train loss {'Reaction outcome loss': 0.4382864367285054, 'Total loss': 0.4382864367285054}
2023-01-04 10:52:13,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:13,529 INFO:     Epoch: 21
2023-01-04 10:52:15,021 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41277591586112977, 'Total loss': 0.41277591586112977} | train loss {'Reaction outcome loss': 0.42802120526850007, 'Total loss': 0.42802120526850007}
2023-01-04 10:52:15,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:15,022 INFO:     Epoch: 22
2023-01-04 10:52:16,542 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4029596547285716, 'Total loss': 0.4029596547285716} | train loss {'Reaction outcome loss': 0.4274712339207366, 'Total loss': 0.4274712339207366}
2023-01-04 10:52:16,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:16,542 INFO:     Epoch: 23
2023-01-04 10:52:18,093 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4089208076397578, 'Total loss': 0.4089208076397578} | train loss {'Reaction outcome loss': 0.4229381664113684, 'Total loss': 0.4229381664113684}
2023-01-04 10:52:18,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:18,093 INFO:     Epoch: 24
2023-01-04 10:52:19,642 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3746501564979553, 'Total loss': 0.3746501564979553} | train loss {'Reaction outcome loss': 0.4223008930628553, 'Total loss': 0.4223008930628553}
2023-01-04 10:52:19,643 INFO:     Found new best model at epoch 24
2023-01-04 10:52:19,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:19,644 INFO:     Epoch: 25
2023-01-04 10:52:21,233 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39434560934702556, 'Total loss': 0.39434560934702556} | train loss {'Reaction outcome loss': 0.4151490549028138, 'Total loss': 0.4151490549028138}
2023-01-04 10:52:21,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:21,233 INFO:     Epoch: 26
2023-01-04 10:52:22,789 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3739496757586797, 'Total loss': 0.3739496757586797} | train loss {'Reaction outcome loss': 0.4147275332020316, 'Total loss': 0.4147275332020316}
2023-01-04 10:52:22,789 INFO:     Found new best model at epoch 26
2023-01-04 10:52:22,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:22,790 INFO:     Epoch: 27
2023-01-04 10:52:24,330 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42846294343471525, 'Total loss': 0.42846294343471525} | train loss {'Reaction outcome loss': 0.40969269370639716, 'Total loss': 0.40969269370639716}
2023-01-04 10:52:24,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:24,330 INFO:     Epoch: 28
2023-01-04 10:52:25,942 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.37712133725484215, 'Total loss': 0.37712133725484215} | train loss {'Reaction outcome loss': 0.4013338681214895, 'Total loss': 0.4013338681214895}
2023-01-04 10:52:25,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:25,942 INFO:     Epoch: 29
2023-01-04 10:52:27,550 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.36787574291229247, 'Total loss': 0.36787574291229247} | train loss {'Reaction outcome loss': 0.39887607637997513, 'Total loss': 0.39887607637997513}
2023-01-04 10:52:27,550 INFO:     Found new best model at epoch 29
2023-01-04 10:52:27,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:27,551 INFO:     Epoch: 30
2023-01-04 10:52:29,156 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.391327315568924, 'Total loss': 0.391327315568924} | train loss {'Reaction outcome loss': 0.3960080879839349, 'Total loss': 0.3960080879839349}
2023-01-04 10:52:29,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:29,156 INFO:     Epoch: 31
2023-01-04 10:52:30,769 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39610896905263265, 'Total loss': 0.39610896905263265} | train loss {'Reaction outcome loss': 0.3955944467185836, 'Total loss': 0.3955944467185836}
2023-01-04 10:52:30,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:30,769 INFO:     Epoch: 32
2023-01-04 10:52:32,288 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3688205897808075, 'Total loss': 0.3688205897808075} | train loss {'Reaction outcome loss': 0.38950058337532995, 'Total loss': 0.38950058337532995}
2023-01-04 10:52:32,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:32,289 INFO:     Epoch: 33
2023-01-04 10:52:33,899 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.37013652821381887, 'Total loss': 0.37013652821381887} | train loss {'Reaction outcome loss': 0.3878500087377735, 'Total loss': 0.3878500087377735}
2023-01-04 10:52:33,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:33,900 INFO:     Epoch: 34
2023-01-04 10:52:35,505 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3555111358563105, 'Total loss': 0.3555111358563105} | train loss {'Reaction outcome loss': 0.38803046971777855, 'Total loss': 0.38803046971777855}
2023-01-04 10:52:35,505 INFO:     Found new best model at epoch 34
2023-01-04 10:52:35,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:35,506 INFO:     Epoch: 35
2023-01-04 10:52:37,106 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3683571368455887, 'Total loss': 0.3683571368455887} | train loss {'Reaction outcome loss': 0.3819593554669684, 'Total loss': 0.3819593554669684}
2023-01-04 10:52:37,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:37,107 INFO:     Epoch: 36
2023-01-04 10:52:38,718 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39328005313873293, 'Total loss': 0.39328005313873293} | train loss {'Reaction outcome loss': 0.37607345773732703, 'Total loss': 0.37607345773732703}
2023-01-04 10:52:38,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:38,719 INFO:     Epoch: 37
2023-01-04 10:52:40,295 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3618143012126287, 'Total loss': 0.3618143012126287} | train loss {'Reaction outcome loss': 0.3778065513996851, 'Total loss': 0.3778065513996851}
2023-01-04 10:52:40,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:40,295 INFO:     Epoch: 38
2023-01-04 10:52:41,775 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3298263559117913, 'Total loss': 0.3298263559117913} | train loss {'Reaction outcome loss': 0.37278852041387733, 'Total loss': 0.37278852041387733}
2023-01-04 10:52:41,776 INFO:     Found new best model at epoch 38
2023-01-04 10:52:41,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:41,776 INFO:     Epoch: 39
2023-01-04 10:52:43,313 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3565090835094452, 'Total loss': 0.3565090835094452} | train loss {'Reaction outcome loss': 0.3692247581569266, 'Total loss': 0.3692247581569266}
2023-01-04 10:52:43,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:43,314 INFO:     Epoch: 40
2023-01-04 10:52:44,848 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3635487159093221, 'Total loss': 0.3635487159093221} | train loss {'Reaction outcome loss': 0.36854031485515637, 'Total loss': 0.36854031485515637}
2023-01-04 10:52:44,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:44,849 INFO:     Epoch: 41
2023-01-04 10:52:46,393 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3700937767823537, 'Total loss': 0.3700937767823537} | train loss {'Reaction outcome loss': 0.3677805632680327, 'Total loss': 0.3677805632680327}
2023-01-04 10:52:46,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:46,393 INFO:     Epoch: 42
2023-01-04 10:52:47,951 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.35809095998605095, 'Total loss': 0.35809095998605095} | train loss {'Reaction outcome loss': 0.3656449475131192, 'Total loss': 0.3656449475131192}
2023-01-04 10:52:47,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:47,952 INFO:     Epoch: 43
2023-01-04 10:52:49,500 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3867843508720398, 'Total loss': 0.3867843508720398} | train loss {'Reaction outcome loss': 0.3556192957492538, 'Total loss': 0.3556192957492538}
2023-01-04 10:52:49,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:49,501 INFO:     Epoch: 44
2023-01-04 10:52:50,836 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3622004255652428, 'Total loss': 0.3622004255652428} | train loss {'Reaction outcome loss': 0.3528521224692628, 'Total loss': 0.3528521224692628}
2023-01-04 10:52:50,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:50,836 INFO:     Epoch: 45
2023-01-04 10:52:51,852 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3666612635056178, 'Total loss': 0.3666612635056178} | train loss {'Reaction outcome loss': 0.35341536381960786, 'Total loss': 0.35341536381960786}
2023-01-04 10:52:51,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:51,853 INFO:     Epoch: 46
2023-01-04 10:52:52,864 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3799543797969818, 'Total loss': 0.3799543797969818} | train loss {'Reaction outcome loss': 0.35118065275006244, 'Total loss': 0.35118065275006244}
2023-01-04 10:52:52,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:52,864 INFO:     Epoch: 47
2023-01-04 10:52:53,883 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3756955961386363, 'Total loss': 0.3756955961386363} | train loss {'Reaction outcome loss': 0.3468266290513587, 'Total loss': 0.3468266290513587}
2023-01-04 10:52:53,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:53,883 INFO:     Epoch: 48
2023-01-04 10:52:54,899 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3394532869259516, 'Total loss': 0.3394532869259516} | train loss {'Reaction outcome loss': 0.34387038069548626, 'Total loss': 0.34387038069548626}
2023-01-04 10:52:54,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:54,899 INFO:     Epoch: 49
2023-01-04 10:52:56,360 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3456824784477552, 'Total loss': 0.3456824784477552} | train loss {'Reaction outcome loss': 0.3433359633489843, 'Total loss': 0.3433359633489843}
2023-01-04 10:52:56,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:56,361 INFO:     Epoch: 50
2023-01-04 10:52:57,908 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3654976586500804, 'Total loss': 0.3654976586500804} | train loss {'Reaction outcome loss': 0.3403574250392861, 'Total loss': 0.3403574250392861}
2023-01-04 10:52:57,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:57,908 INFO:     Epoch: 51
2023-01-04 10:52:59,450 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.34220973153909046, 'Total loss': 0.34220973153909046} | train loss {'Reaction outcome loss': 0.3368227653778516, 'Total loss': 0.3368227653778516}
2023-01-04 10:52:59,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:52:59,450 INFO:     Epoch: 52
2023-01-04 10:53:01,006 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3458121970295906, 'Total loss': 0.3458121970295906} | train loss {'Reaction outcome loss': 0.33270448732834595, 'Total loss': 0.33270448732834595}
2023-01-04 10:53:01,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:01,006 INFO:     Epoch: 53
2023-01-04 10:53:02,587 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3178810983896255, 'Total loss': 0.3178810983896255} | train loss {'Reaction outcome loss': 0.3300101168098904, 'Total loss': 0.3300101168098904}
2023-01-04 10:53:02,587 INFO:     Found new best model at epoch 53
2023-01-04 10:53:02,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:02,588 INFO:     Epoch: 54
2023-01-04 10:53:04,144 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.32811733533938725, 'Total loss': 0.32811733533938725} | train loss {'Reaction outcome loss': 0.32924811733074677, 'Total loss': 0.32924811733074677}
2023-01-04 10:53:04,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:04,145 INFO:     Epoch: 55
2023-01-04 10:53:05,647 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3571053832769394, 'Total loss': 0.3571053832769394} | train loss {'Reaction outcome loss': 0.3292469389927693, 'Total loss': 0.3292469389927693}
2023-01-04 10:53:05,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:05,647 INFO:     Epoch: 56
2023-01-04 10:53:07,200 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.32594630171855293, 'Total loss': 0.32594630171855293} | train loss {'Reaction outcome loss': 0.3321326039595045, 'Total loss': 0.3321326039595045}
2023-01-04 10:53:07,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:07,200 INFO:     Epoch: 57
2023-01-04 10:53:08,738 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3712124283115069, 'Total loss': 0.3712124283115069} | train loss {'Reaction outcome loss': 0.322493919359022, 'Total loss': 0.322493919359022}
2023-01-04 10:53:08,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:08,738 INFO:     Epoch: 58
2023-01-04 10:53:10,286 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.33535968959331514, 'Total loss': 0.33535968959331514} | train loss {'Reaction outcome loss': 0.3213361812271041, 'Total loss': 0.3213361812271041}
2023-01-04 10:53:10,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:10,286 INFO:     Epoch: 59
2023-01-04 10:53:11,843 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.356719313065211, 'Total loss': 0.356719313065211} | train loss {'Reaction outcome loss': 0.31651451801642394, 'Total loss': 0.31651451801642394}
2023-01-04 10:53:11,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:11,845 INFO:     Epoch: 60
2023-01-04 10:53:13,384 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3313452661037445, 'Total loss': 0.3313452661037445} | train loss {'Reaction outcome loss': 0.3177761977790913, 'Total loss': 0.3177761977790913}
2023-01-04 10:53:13,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:13,384 INFO:     Epoch: 61
2023-01-04 10:53:14,901 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3849534898996353, 'Total loss': 0.3849534898996353} | train loss {'Reaction outcome loss': 0.31410852399392003, 'Total loss': 0.31410852399392003}
2023-01-04 10:53:14,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:14,903 INFO:     Epoch: 62
2023-01-04 10:53:16,445 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3748442759116491, 'Total loss': 0.3748442759116491} | train loss {'Reaction outcome loss': 0.32661976244969243, 'Total loss': 0.32661976244969243}
2023-01-04 10:53:16,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:16,445 INFO:     Epoch: 63
2023-01-04 10:53:18,000 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.34119391242663066, 'Total loss': 0.34119391242663066} | train loss {'Reaction outcome loss': 0.31484599032135674, 'Total loss': 0.31484599032135674}
2023-01-04 10:53:18,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:18,000 INFO:     Epoch: 64
2023-01-04 10:53:19,553 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3435875654220581, 'Total loss': 0.3435875654220581} | train loss {'Reaction outcome loss': 0.3144728980767421, 'Total loss': 0.3144728980767421}
2023-01-04 10:53:19,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:19,554 INFO:     Epoch: 65
2023-01-04 10:53:21,105 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3267789423465729, 'Total loss': 0.3267789423465729} | train loss {'Reaction outcome loss': 0.3091465020518163, 'Total loss': 0.3091465020518163}
2023-01-04 10:53:21,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:21,106 INFO:     Epoch: 66
2023-01-04 10:53:22,621 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.33789355456829073, 'Total loss': 0.33789355456829073} | train loss {'Reaction outcome loss': 0.31112271831149146, 'Total loss': 0.31112271831149146}
2023-01-04 10:53:22,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:22,622 INFO:     Epoch: 67
2023-01-04 10:53:24,132 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3262597362200419, 'Total loss': 0.3262597362200419} | train loss {'Reaction outcome loss': 0.3088214999480999, 'Total loss': 0.3088214999480999}
2023-01-04 10:53:24,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:24,132 INFO:     Epoch: 68
2023-01-04 10:53:25,660 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3202390345434348, 'Total loss': 0.3202390345434348} | train loss {'Reaction outcome loss': 0.3054590608119528, 'Total loss': 0.3054590608119528}
2023-01-04 10:53:25,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:25,660 INFO:     Epoch: 69
2023-01-04 10:53:27,238 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.32521581451098125, 'Total loss': 0.32521581451098125} | train loss {'Reaction outcome loss': 0.29990962401523696, 'Total loss': 0.29990962401523696}
2023-01-04 10:53:27,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:27,238 INFO:     Epoch: 70
2023-01-04 10:53:28,830 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3183185795942942, 'Total loss': 0.3183185795942942} | train loss {'Reaction outcome loss': 0.30449824641039086, 'Total loss': 0.30449824641039086}
2023-01-04 10:53:28,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:28,830 INFO:     Epoch: 71
2023-01-04 10:53:30,432 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.339108282327652, 'Total loss': 0.339108282327652} | train loss {'Reaction outcome loss': 0.3012457250620856, 'Total loss': 0.3012457250620856}
2023-01-04 10:53:30,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:30,432 INFO:     Epoch: 72
2023-01-04 10:53:31,980 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3689260005950928, 'Total loss': 0.3689260005950928} | train loss {'Reaction outcome loss': 0.29542832728816476, 'Total loss': 0.29542832728816476}
2023-01-04 10:53:31,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:31,981 INFO:     Epoch: 73
2023-01-04 10:53:33,553 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.344581459959348, 'Total loss': 0.344581459959348} | train loss {'Reaction outcome loss': 0.3039810159158357, 'Total loss': 0.3039810159158357}
2023-01-04 10:53:33,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:33,554 INFO:     Epoch: 74
2023-01-04 10:53:35,107 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.329860453804334, 'Total loss': 0.329860453804334} | train loss {'Reaction outcome loss': 0.2978872441492238, 'Total loss': 0.2978872441492238}
2023-01-04 10:53:35,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:35,108 INFO:     Epoch: 75
2023-01-04 10:53:36,671 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.31827625383933383, 'Total loss': 0.31827625383933383} | train loss {'Reaction outcome loss': 0.2946605139817947, 'Total loss': 0.2946605139817947}
2023-01-04 10:53:36,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:36,671 INFO:     Epoch: 76
2023-01-04 10:53:38,237 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.317559988796711, 'Total loss': 0.317559988796711} | train loss {'Reaction outcome loss': 0.29982735424033014, 'Total loss': 0.29982735424033014}
2023-01-04 10:53:38,237 INFO:     Found new best model at epoch 76
2023-01-04 10:53:38,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:38,238 INFO:     Epoch: 77
2023-01-04 10:53:39,812 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3234413869678974, 'Total loss': 0.3234413869678974} | train loss {'Reaction outcome loss': 0.2966102150442836, 'Total loss': 0.2966102150442836}
2023-01-04 10:53:39,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:39,812 INFO:     Epoch: 78
2023-01-04 10:53:41,353 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3668519993623098, 'Total loss': 0.3668519993623098} | train loss {'Reaction outcome loss': 0.29316438664938066, 'Total loss': 0.29316438664938066}
2023-01-04 10:53:41,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:41,354 INFO:     Epoch: 79
2023-01-04 10:53:42,918 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.31882694860299426, 'Total loss': 0.31882694860299426} | train loss {'Reaction outcome loss': 0.28801195549986736, 'Total loss': 0.28801195549986736}
2023-01-04 10:53:42,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:42,918 INFO:     Epoch: 80
2023-01-04 10:53:44,497 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.33750096360842385, 'Total loss': 0.33750096360842385} | train loss {'Reaction outcome loss': 0.2909589204596076, 'Total loss': 0.2909589204596076}
2023-01-04 10:53:44,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:44,497 INFO:     Epoch: 81
2023-01-04 10:53:46,080 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3185903191566467, 'Total loss': 0.3185903191566467} | train loss {'Reaction outcome loss': 0.2873108963662888, 'Total loss': 0.2873108963662888}
2023-01-04 10:53:46,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:46,081 INFO:     Epoch: 82
2023-01-04 10:53:47,661 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.348090398311615, 'Total loss': 0.348090398311615} | train loss {'Reaction outcome loss': 0.284052935534672, 'Total loss': 0.284052935534672}
2023-01-04 10:53:47,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:47,661 INFO:     Epoch: 83
2023-01-04 10:53:49,238 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.31366980373859404, 'Total loss': 0.31366980373859404} | train loss {'Reaction outcome loss': 0.29350970898355755, 'Total loss': 0.29350970898355755}
2023-01-04 10:53:49,238 INFO:     Found new best model at epoch 83
2023-01-04 10:53:49,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:49,239 INFO:     Epoch: 84
2023-01-04 10:53:50,736 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.31478847165902457, 'Total loss': 0.31478847165902457} | train loss {'Reaction outcome loss': 0.2848799648820917, 'Total loss': 0.2848799648820917}
2023-01-04 10:53:50,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:50,736 INFO:     Epoch: 85
2023-01-04 10:53:52,315 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.31684773315986, 'Total loss': 0.31684773315986} | train loss {'Reaction outcome loss': 0.2843320293031333, 'Total loss': 0.2843320293031333}
2023-01-04 10:53:52,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:52,316 INFO:     Epoch: 86
2023-01-04 10:53:53,894 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.33319503962993624, 'Total loss': 0.33319503962993624} | train loss {'Reaction outcome loss': 0.2835359207931019, 'Total loss': 0.2835359207931019}
2023-01-04 10:53:53,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:53,894 INFO:     Epoch: 87
2023-01-04 10:53:55,460 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.34882379571596783, 'Total loss': 0.34882379571596783} | train loss {'Reaction outcome loss': 0.2776650074364502, 'Total loss': 0.2776650074364502}
2023-01-04 10:53:55,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:55,460 INFO:     Epoch: 88
2023-01-04 10:53:57,064 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3209294557571411, 'Total loss': 0.3209294557571411} | train loss {'Reaction outcome loss': 0.280925933135189, 'Total loss': 0.280925933135189}
2023-01-04 10:53:57,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:57,065 INFO:     Epoch: 89
2023-01-04 10:53:58,668 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.34528616766134895, 'Total loss': 0.34528616766134895} | train loss {'Reaction outcome loss': 0.27786882650175376, 'Total loss': 0.27786882650175376}
2023-01-04 10:53:58,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:53:58,668 INFO:     Epoch: 90
2023-01-04 10:54:00,178 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3436528921127319, 'Total loss': 0.3436528921127319} | train loss {'Reaction outcome loss': 0.27663890867333707, 'Total loss': 0.27663890867333707}
2023-01-04 10:54:00,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:00,178 INFO:     Epoch: 91
2023-01-04 10:54:01,746 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.33465758959452313, 'Total loss': 0.33465758959452313} | train loss {'Reaction outcome loss': 0.2805180027262195, 'Total loss': 0.2805180027262195}
2023-01-04 10:54:01,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:01,746 INFO:     Epoch: 92
2023-01-04 10:54:03,301 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3361008067925771, 'Total loss': 0.3361008067925771} | train loss {'Reaction outcome loss': 0.2779300371082602, 'Total loss': 0.2779300371082602}
2023-01-04 10:54:03,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:03,301 INFO:     Epoch: 93
2023-01-04 10:54:04,870 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.35331635077794393, 'Total loss': 0.35331635077794393} | train loss {'Reaction outcome loss': 0.27506557699197376, 'Total loss': 0.27506557699197376}
2023-01-04 10:54:04,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:04,871 INFO:     Epoch: 94
2023-01-04 10:54:06,428 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.31896627495686214, 'Total loss': 0.31896627495686214} | train loss {'Reaction outcome loss': 0.27605700322286986, 'Total loss': 0.27605700322286986}
2023-01-04 10:54:06,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:06,428 INFO:     Epoch: 95
2023-01-04 10:54:08,003 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3280459860960642, 'Total loss': 0.3280459860960642} | train loss {'Reaction outcome loss': 0.2741262125390353, 'Total loss': 0.2741262125390353}
2023-01-04 10:54:08,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:08,003 INFO:     Epoch: 96
2023-01-04 10:54:09,569 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3182176689306895, 'Total loss': 0.3182176689306895} | train loss {'Reaction outcome loss': 0.2730671892781834, 'Total loss': 0.2730671892781834}
2023-01-04 10:54:09,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:09,569 INFO:     Epoch: 97
2023-01-04 10:54:11,153 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3484992374976476, 'Total loss': 0.3484992374976476} | train loss {'Reaction outcome loss': 0.2744734886583391, 'Total loss': 0.2744734886583391}
2023-01-04 10:54:11,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:11,153 INFO:     Epoch: 98
2023-01-04 10:54:12,744 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.32753393749396004, 'Total loss': 0.32753393749396004} | train loss {'Reaction outcome loss': 0.2733535939083868, 'Total loss': 0.2733535939083868}
2023-01-04 10:54:12,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:12,745 INFO:     Epoch: 99
2023-01-04 10:54:14,329 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3523536374171575, 'Total loss': 0.3523536374171575} | train loss {'Reaction outcome loss': 0.27014095595468096, 'Total loss': 0.27014095595468096}
2023-01-04 10:54:14,329 INFO:     Best model found after epoch 84 of 100.
2023-01-04 10:54:14,329 INFO:   Done with stage: TRAINING
2023-01-04 10:54:14,329 INFO:   Starting stage: EVALUATION
2023-01-04 10:54:14,468 INFO:   Done with stage: EVALUATION
2023-01-04 10:54:14,468 INFO:   Leaving out SEQ value Fold_2
2023-01-04 10:54:14,481 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-04 10:54:14,481 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:54:15,129 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:54:15,129 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:54:15,197 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:54:15,197 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:54:15,197 INFO:     No hyperparam tuning for this model
2023-01-04 10:54:15,197 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:54:15,197 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:54:15,198 INFO:     None feature selector for col prot
2023-01-04 10:54:15,198 INFO:     None feature selector for col prot
2023-01-04 10:54:15,198 INFO:     None feature selector for col prot
2023-01-04 10:54:15,199 INFO:     None feature selector for col chem
2023-01-04 10:54:15,199 INFO:     None feature selector for col chem
2023-01-04 10:54:15,199 INFO:     None feature selector for col chem
2023-01-04 10:54:15,199 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:54:15,199 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:54:15,200 INFO:     Number of params in model 70111
2023-01-04 10:54:15,203 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:54:15,203 INFO:   Starting stage: TRAINING
2023-01-04 10:54:15,246 INFO:     Val loss before train {'Reaction outcome loss': 1.033661417166392, 'Total loss': 1.033661417166392}
2023-01-04 10:54:15,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:15,246 INFO:     Epoch: 0
2023-01-04 10:54:16,783 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7159407128890355, 'Total loss': 0.7159407128890355} | train loss {'Reaction outcome loss': 0.841149780473146, 'Total loss': 0.841149780473146}
2023-01-04 10:54:16,784 INFO:     Found new best model at epoch 0
2023-01-04 10:54:16,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:16,785 INFO:     Epoch: 1
2023-01-04 10:54:18,328 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6002154846986135, 'Total loss': 0.6002154846986135} | train loss {'Reaction outcome loss': 0.6788735371014288, 'Total loss': 0.6788735371014288}
2023-01-04 10:54:18,328 INFO:     Found new best model at epoch 1
2023-01-04 10:54:18,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:18,329 INFO:     Epoch: 2
2023-01-04 10:54:19,912 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5616363088289896, 'Total loss': 0.5616363088289896} | train loss {'Reaction outcome loss': 0.5953265881626368, 'Total loss': 0.5953265881626368}
2023-01-04 10:54:19,912 INFO:     Found new best model at epoch 2
2023-01-04 10:54:19,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:19,913 INFO:     Epoch: 3
2023-01-04 10:54:21,498 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5455584645271301, 'Total loss': 0.5455584645271301} | train loss {'Reaction outcome loss': 0.5546689207263539, 'Total loss': 0.5546689207263539}
2023-01-04 10:54:21,499 INFO:     Found new best model at epoch 3
2023-01-04 10:54:21,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:21,499 INFO:     Epoch: 4
2023-01-04 10:54:23,061 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.578349859515826, 'Total loss': 0.578349859515826} | train loss {'Reaction outcome loss': 0.5261767976728312, 'Total loss': 0.5261767976728312}
2023-01-04 10:54:23,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:23,062 INFO:     Epoch: 5
2023-01-04 10:54:24,633 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5133036990960439, 'Total loss': 0.5133036990960439} | train loss {'Reaction outcome loss': 0.5138287937399206, 'Total loss': 0.5138287937399206}
2023-01-04 10:54:24,633 INFO:     Found new best model at epoch 5
2023-01-04 10:54:24,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:24,634 INFO:     Epoch: 6
2023-01-04 10:54:26,130 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5282862563927968, 'Total loss': 0.5282862563927968} | train loss {'Reaction outcome loss': 0.4948442016085575, 'Total loss': 0.4948442016085575}
2023-01-04 10:54:26,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:26,130 INFO:     Epoch: 7
2023-01-04 10:54:27,650 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4847599198420843, 'Total loss': 0.4847599198420843} | train loss {'Reaction outcome loss': 0.4854894468485209, 'Total loss': 0.4854894468485209}
2023-01-04 10:54:27,650 INFO:     Found new best model at epoch 7
2023-01-04 10:54:27,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:27,651 INFO:     Epoch: 8
2023-01-04 10:54:29,199 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4935512900352478, 'Total loss': 0.4935512900352478} | train loss {'Reaction outcome loss': 0.4793758489658912, 'Total loss': 0.4793758489658912}
2023-01-04 10:54:29,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:29,199 INFO:     Epoch: 9
2023-01-04 10:54:30,755 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4655699332555135, 'Total loss': 0.4655699332555135} | train loss {'Reaction outcome loss': 0.46469551979175794, 'Total loss': 0.46469551979175794}
2023-01-04 10:54:30,755 INFO:     Found new best model at epoch 9
2023-01-04 10:54:30,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:30,756 INFO:     Epoch: 10
2023-01-04 10:54:32,286 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4464573264122009, 'Total loss': 0.4464573264122009} | train loss {'Reaction outcome loss': 0.4634568435569531, 'Total loss': 0.4634568435569531}
2023-01-04 10:54:32,286 INFO:     Found new best model at epoch 10
2023-01-04 10:54:32,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:32,286 INFO:     Epoch: 11
2023-01-04 10:54:33,826 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48874558409055074, 'Total loss': 0.48874558409055074} | train loss {'Reaction outcome loss': 0.45284454024145965, 'Total loss': 0.45284454024145965}
2023-01-04 10:54:33,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:33,827 INFO:     Epoch: 12
2023-01-04 10:54:35,348 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4501613140106201, 'Total loss': 0.4501613140106201} | train loss {'Reaction outcome loss': 0.4484013303069611, 'Total loss': 0.4484013303069611}
2023-01-04 10:54:35,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:35,348 INFO:     Epoch: 13
2023-01-04 10:54:36,857 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4633942385514577, 'Total loss': 0.4633942385514577} | train loss {'Reaction outcome loss': 0.4440997770241706, 'Total loss': 0.4440997770241706}
2023-01-04 10:54:36,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:36,857 INFO:     Epoch: 14
2023-01-04 10:54:38,413 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4566989918549856, 'Total loss': 0.4566989918549856} | train loss {'Reaction outcome loss': 0.43708321485132307, 'Total loss': 0.43708321485132307}
2023-01-04 10:54:38,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:38,413 INFO:     Epoch: 15
2023-01-04 10:54:39,976 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.445379701256752, 'Total loss': 0.445379701256752} | train loss {'Reaction outcome loss': 0.43069979790391955, 'Total loss': 0.43069979790391955}
2023-01-04 10:54:39,976 INFO:     Found new best model at epoch 15
2023-01-04 10:54:39,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:39,977 INFO:     Epoch: 16
2023-01-04 10:54:41,518 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4321640332539876, 'Total loss': 0.4321640332539876} | train loss {'Reaction outcome loss': 0.42883769469507504, 'Total loss': 0.42883769469507504}
2023-01-04 10:54:41,518 INFO:     Found new best model at epoch 16
2023-01-04 10:54:41,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:41,519 INFO:     Epoch: 17
2023-01-04 10:54:43,057 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41063323815663655, 'Total loss': 0.41063323815663655} | train loss {'Reaction outcome loss': 0.42794275316804975, 'Total loss': 0.42794275316804975}
2023-01-04 10:54:43,058 INFO:     Found new best model at epoch 17
2023-01-04 10:54:43,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:43,058 INFO:     Epoch: 18
2023-01-04 10:54:44,559 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42909175356229146, 'Total loss': 0.42909175356229146} | train loss {'Reaction outcome loss': 0.4238221057556652, 'Total loss': 0.4238221057556652}
2023-01-04 10:54:44,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:44,559 INFO:     Epoch: 19
2023-01-04 10:54:46,065 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4183722456296285, 'Total loss': 0.4183722456296285} | train loss {'Reaction outcome loss': 0.41665028981397073, 'Total loss': 0.41665028981397073}
2023-01-04 10:54:46,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:46,065 INFO:     Epoch: 20
2023-01-04 10:54:47,628 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4517866303523382, 'Total loss': 0.4517866303523382} | train loss {'Reaction outcome loss': 0.4093073296096052, 'Total loss': 0.4093073296096052}
2023-01-04 10:54:47,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:47,628 INFO:     Epoch: 21
2023-01-04 10:54:49,173 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4514922151962916, 'Total loss': 0.4514922151962916} | train loss {'Reaction outcome loss': 0.4061994842937512, 'Total loss': 0.4061994842937512}
2023-01-04 10:54:49,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:49,173 INFO:     Epoch: 22
2023-01-04 10:54:50,723 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41683992743492126, 'Total loss': 0.41683992743492126} | train loss {'Reaction outcome loss': 0.4038018047039799, 'Total loss': 0.4038018047039799}
2023-01-04 10:54:50,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:50,723 INFO:     Epoch: 23
2023-01-04 10:54:52,251 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41920493642489115, 'Total loss': 0.41920493642489115} | train loss {'Reaction outcome loss': 0.3984939821091965, 'Total loss': 0.3984939821091965}
2023-01-04 10:54:52,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:52,252 INFO:     Epoch: 24
2023-01-04 10:54:53,779 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41839652856191, 'Total loss': 0.41839652856191} | train loss {'Reaction outcome loss': 0.39617821766661543, 'Total loss': 0.39617821766661543}
2023-01-04 10:54:53,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:53,779 INFO:     Epoch: 25
2023-01-04 10:54:55,323 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3999847133954366, 'Total loss': 0.3999847133954366} | train loss {'Reaction outcome loss': 0.3903869856767549, 'Total loss': 0.3903869856767549}
2023-01-04 10:54:55,323 INFO:     Found new best model at epoch 25
2023-01-04 10:54:55,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:55,324 INFO:     Epoch: 26
2023-01-04 10:54:56,910 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47770166595776875, 'Total loss': 0.47770166595776875} | train loss {'Reaction outcome loss': 0.3905331713741996, 'Total loss': 0.3905331713741996}
2023-01-04 10:54:56,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:56,911 INFO:     Epoch: 27
2023-01-04 10:54:58,491 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4203862061103185, 'Total loss': 0.4203862061103185} | train loss {'Reaction outcome loss': 0.3869360233914808, 'Total loss': 0.3869360233914808}
2023-01-04 10:54:58,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:54:58,492 INFO:     Epoch: 28
2023-01-04 10:55:00,068 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40287094910939536, 'Total loss': 0.40287094910939536} | train loss {'Reaction outcome loss': 0.3816234570862622, 'Total loss': 0.3816234570862622}
2023-01-04 10:55:00,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:00,068 INFO:     Epoch: 29
2023-01-04 10:55:01,623 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4011105532447497, 'Total loss': 0.4011105532447497} | train loss {'Reaction outcome loss': 0.3769413452196825, 'Total loss': 0.3769413452196825}
2023-01-04 10:55:01,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:01,624 INFO:     Epoch: 30
2023-01-04 10:55:03,120 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4485408713420232, 'Total loss': 0.4485408713420232} | train loss {'Reaction outcome loss': 0.37210894881909184, 'Total loss': 0.37210894881909184}
2023-01-04 10:55:03,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:03,120 INFO:     Epoch: 31
2023-01-04 10:55:04,684 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4457776228586833, 'Total loss': 0.4457776228586833} | train loss {'Reaction outcome loss': 0.36920956002610195, 'Total loss': 0.36920956002610195}
2023-01-04 10:55:04,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:04,684 INFO:     Epoch: 32
2023-01-04 10:55:06,253 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4012280166149139, 'Total loss': 0.4012280166149139} | train loss {'Reaction outcome loss': 0.3660343300372472, 'Total loss': 0.3660343300372472}
2023-01-04 10:55:06,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:06,253 INFO:     Epoch: 33
2023-01-04 10:55:07,831 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39742854436238606, 'Total loss': 0.39742854436238606} | train loss {'Reaction outcome loss': 0.3650961091872511, 'Total loss': 0.3650961091872511}
2023-01-04 10:55:07,831 INFO:     Found new best model at epoch 33
2023-01-04 10:55:07,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:07,832 INFO:     Epoch: 34
2023-01-04 10:55:09,408 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4009536325931549, 'Total loss': 0.4009536325931549} | train loss {'Reaction outcome loss': 0.3587735012118667, 'Total loss': 0.3587735012118667}
2023-01-04 10:55:09,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:09,408 INFO:     Epoch: 35
2023-01-04 10:55:10,972 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38913016418615975, 'Total loss': 0.38913016418615975} | train loss {'Reaction outcome loss': 0.36057668272749527, 'Total loss': 0.36057668272749527}
2023-01-04 10:55:10,973 INFO:     Found new best model at epoch 35
2023-01-04 10:55:10,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:10,974 INFO:     Epoch: 36
2023-01-04 10:55:12,469 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38734671572844187, 'Total loss': 0.38734671572844187} | train loss {'Reaction outcome loss': 0.3566368183196691, 'Total loss': 0.3566368183196691}
2023-01-04 10:55:12,469 INFO:     Found new best model at epoch 36
2023-01-04 10:55:12,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:12,470 INFO:     Epoch: 37
2023-01-04 10:55:14,047 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3909257446726163, 'Total loss': 0.3909257446726163} | train loss {'Reaction outcome loss': 0.35715437933417704, 'Total loss': 0.35715437933417704}
2023-01-04 10:55:14,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:14,047 INFO:     Epoch: 38
2023-01-04 10:55:15,614 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41156518359978994, 'Total loss': 0.41156518359978994} | train loss {'Reaction outcome loss': 0.34664804645130115, 'Total loss': 0.34664804645130115}
2023-01-04 10:55:15,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:15,614 INFO:     Epoch: 39
2023-01-04 10:55:17,180 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3983538329601288, 'Total loss': 0.3983538329601288} | train loss {'Reaction outcome loss': 0.34554098037886005, 'Total loss': 0.34554098037886005}
2023-01-04 10:55:17,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:17,180 INFO:     Epoch: 40
2023-01-04 10:55:18,751 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3803615886718035, 'Total loss': 0.3803615886718035} | train loss {'Reaction outcome loss': 0.34707239000779677, 'Total loss': 0.34707239000779677}
2023-01-04 10:55:18,752 INFO:     Found new best model at epoch 40
2023-01-04 10:55:18,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:18,752 INFO:     Epoch: 41
2023-01-04 10:55:20,317 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.395962647596995, 'Total loss': 0.395962647596995} | train loss {'Reaction outcome loss': 0.34347505427594555, 'Total loss': 0.34347505427594555}
2023-01-04 10:55:20,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:20,318 INFO:     Epoch: 42
2023-01-04 10:55:21,797 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39603811303774517, 'Total loss': 0.39603811303774517} | train loss {'Reaction outcome loss': 0.3367451606971311, 'Total loss': 0.3367451606971311}
2023-01-04 10:55:21,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:21,798 INFO:     Epoch: 43
2023-01-04 10:55:23,346 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38914347688357037, 'Total loss': 0.38914347688357037} | train loss {'Reaction outcome loss': 0.34110922811765954, 'Total loss': 0.34110922811765954}
2023-01-04 10:55:23,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:23,347 INFO:     Epoch: 44
2023-01-04 10:55:24,885 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42018877069155375, 'Total loss': 0.42018877069155375} | train loss {'Reaction outcome loss': 0.3326856755132605, 'Total loss': 0.3326856755132605}
2023-01-04 10:55:24,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:24,885 INFO:     Epoch: 45
2023-01-04 10:55:26,431 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.37134162411093713, 'Total loss': 0.37134162411093713} | train loss {'Reaction outcome loss': 0.3308927741217877, 'Total loss': 0.3308927741217877}
2023-01-04 10:55:26,431 INFO:     Found new best model at epoch 45
2023-01-04 10:55:26,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:26,432 INFO:     Epoch: 46
2023-01-04 10:55:27,999 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3980225443840027, 'Total loss': 0.3980225443840027} | train loss {'Reaction outcome loss': 0.3314592150414562, 'Total loss': 0.3314592150414562}
2023-01-04 10:55:27,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:27,999 INFO:     Epoch: 47
2023-01-04 10:55:29,524 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.394892214735349, 'Total loss': 0.394892214735349} | train loss {'Reaction outcome loss': 0.3282865657027797, 'Total loss': 0.3282865657027797}
2023-01-04 10:55:29,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:29,525 INFO:     Epoch: 48
2023-01-04 10:55:31,029 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3904453923304876, 'Total loss': 0.3904453923304876} | train loss {'Reaction outcome loss': 0.3218653376911839, 'Total loss': 0.3218653376911839}
2023-01-04 10:55:31,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:31,030 INFO:     Epoch: 49
2023-01-04 10:55:32,579 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39702439109484355, 'Total loss': 0.39702439109484355} | train loss {'Reaction outcome loss': 0.3185188853872658, 'Total loss': 0.3185188853872658}
2023-01-04 10:55:32,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:32,579 INFO:     Epoch: 50
2023-01-04 10:55:34,131 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39549401799837747, 'Total loss': 0.39549401799837747} | train loss {'Reaction outcome loss': 0.3197329200226882, 'Total loss': 0.3197329200226882}
2023-01-04 10:55:34,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:34,131 INFO:     Epoch: 51
2023-01-04 10:55:35,691 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.396088108420372, 'Total loss': 0.396088108420372} | train loss {'Reaction outcome loss': 0.3165438990366415, 'Total loss': 0.3165438990366415}
2023-01-04 10:55:35,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:35,692 INFO:     Epoch: 52
2023-01-04 10:55:37,248 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3885551696022352, 'Total loss': 0.3885551696022352} | train loss {'Reaction outcome loss': 0.31452882815001193, 'Total loss': 0.31452882815001193}
2023-01-04 10:55:37,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:37,248 INFO:     Epoch: 53
2023-01-04 10:55:38,758 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3900622268517812, 'Total loss': 0.3900622268517812} | train loss {'Reaction outcome loss': 0.3129888915652719, 'Total loss': 0.3129888915652719}
2023-01-04 10:55:38,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:38,758 INFO:     Epoch: 54
2023-01-04 10:55:40,281 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4057681848605474, 'Total loss': 0.4057681848605474} | train loss {'Reaction outcome loss': 0.3099320960743181, 'Total loss': 0.3099320960743181}
2023-01-04 10:55:40,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:40,281 INFO:     Epoch: 55
2023-01-04 10:55:41,842 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43314910928408307, 'Total loss': 0.43314910928408307} | train loss {'Reaction outcome loss': 0.3076956706238409, 'Total loss': 0.3076956706238409}
2023-01-04 10:55:41,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:41,843 INFO:     Epoch: 56
2023-01-04 10:55:43,415 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4044037600358327, 'Total loss': 0.4044037600358327} | train loss {'Reaction outcome loss': 0.3113053834333851, 'Total loss': 0.3113053834333851}
2023-01-04 10:55:43,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:43,415 INFO:     Epoch: 57
2023-01-04 10:55:44,971 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38847410678863525, 'Total loss': 0.38847410678863525} | train loss {'Reaction outcome loss': 0.30624034747866247, 'Total loss': 0.30624034747866247}
2023-01-04 10:55:44,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:44,971 INFO:     Epoch: 58
2023-01-04 10:55:46,514 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3684100988010565, 'Total loss': 0.3684100988010565} | train loss {'Reaction outcome loss': 0.3090313801136404, 'Total loss': 0.3090313801136404}
2023-01-04 10:55:46,514 INFO:     Found new best model at epoch 58
2023-01-04 10:55:46,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:46,515 INFO:     Epoch: 59
2023-01-04 10:55:48,033 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38513177037239077, 'Total loss': 0.38513177037239077} | train loss {'Reaction outcome loss': 0.3010407047573051, 'Total loss': 0.3010407047573051}
2023-01-04 10:55:48,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:48,033 INFO:     Epoch: 60
2023-01-04 10:55:49,565 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3897774934768677, 'Total loss': 0.3897774934768677} | train loss {'Reaction outcome loss': 0.30202410455339507, 'Total loss': 0.30202410455339507}
2023-01-04 10:55:49,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:49,565 INFO:     Epoch: 61
2023-01-04 10:55:51,144 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38723760545253755, 'Total loss': 0.38723760545253755} | train loss {'Reaction outcome loss': 0.29632303685059846, 'Total loss': 0.29632303685059846}
2023-01-04 10:55:51,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:51,144 INFO:     Epoch: 62
2023-01-04 10:55:52,713 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3858621199925741, 'Total loss': 0.3858621199925741} | train loss {'Reaction outcome loss': 0.2986366667018385, 'Total loss': 0.2986366667018385}
2023-01-04 10:55:52,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:52,713 INFO:     Epoch: 63
2023-01-04 10:55:54,288 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38483282675345737, 'Total loss': 0.38483282675345737} | train loss {'Reaction outcome loss': 0.299481058775059, 'Total loss': 0.299481058775059}
2023-01-04 10:55:54,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:54,290 INFO:     Epoch: 64
2023-01-04 10:55:55,854 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3946183909972509, 'Total loss': 0.3946183909972509} | train loss {'Reaction outcome loss': 0.29768610206807233, 'Total loss': 0.29768610206807233}
2023-01-04 10:55:55,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:55,854 INFO:     Epoch: 65
2023-01-04 10:55:57,382 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3874425490697225, 'Total loss': 0.3874425490697225} | train loss {'Reaction outcome loss': 0.2929486084413265, 'Total loss': 0.2929486084413265}
2023-01-04 10:55:57,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:57,383 INFO:     Epoch: 66
2023-01-04 10:55:58,921 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4244372268517812, 'Total loss': 0.4244372268517812} | train loss {'Reaction outcome loss': 0.29202769369546777, 'Total loss': 0.29202769369546777}
2023-01-04 10:55:58,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:55:58,921 INFO:     Epoch: 67
2023-01-04 10:56:00,487 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4037354071935018, 'Total loss': 0.4037354071935018} | train loss {'Reaction outcome loss': 0.2873674525820901, 'Total loss': 0.2873674525820901}
2023-01-04 10:56:00,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:00,487 INFO:     Epoch: 68
2023-01-04 10:56:02,063 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39565898180007936, 'Total loss': 0.39565898180007936} | train loss {'Reaction outcome loss': 0.2908562040609407, 'Total loss': 0.2908562040609407}
2023-01-04 10:56:02,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:02,064 INFO:     Epoch: 69
2023-01-04 10:56:03,650 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40327983647584914, 'Total loss': 0.40327983647584914} | train loss {'Reaction outcome loss': 0.2859589751411188, 'Total loss': 0.2859589751411188}
2023-01-04 10:56:03,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:03,650 INFO:     Epoch: 70
2023-01-04 10:56:05,229 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37376905779043834, 'Total loss': 0.37376905779043834} | train loss {'Reaction outcome loss': 0.2826692180714924, 'Total loss': 0.2826692180714924}
2023-01-04 10:56:05,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:05,229 INFO:     Epoch: 71
2023-01-04 10:56:06,751 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3907721251249313, 'Total loss': 0.3907721251249313} | train loss {'Reaction outcome loss': 0.2850492898498514, 'Total loss': 0.2850492898498514}
2023-01-04 10:56:06,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:06,751 INFO:     Epoch: 72
2023-01-04 10:56:08,319 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37528790533542633, 'Total loss': 0.37528790533542633} | train loss {'Reaction outcome loss': 0.28308818390338625, 'Total loss': 0.28308818390338625}
2023-01-04 10:56:08,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:08,319 INFO:     Epoch: 73
2023-01-04 10:56:09,904 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40235309501489, 'Total loss': 0.40235309501489} | train loss {'Reaction outcome loss': 0.28034644949205245, 'Total loss': 0.28034644949205245}
2023-01-04 10:56:09,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:09,904 INFO:     Epoch: 74
2023-01-04 10:56:11,487 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.36969564904769264, 'Total loss': 0.36969564904769264} | train loss {'Reaction outcome loss': 0.2801824155713799, 'Total loss': 0.2801824155713799}
2023-01-04 10:56:11,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:11,487 INFO:     Epoch: 75
2023-01-04 10:56:13,048 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39838707000017165, 'Total loss': 0.39838707000017165} | train loss {'Reaction outcome loss': 0.27849811916256745, 'Total loss': 0.27849811916256745}
2023-01-04 10:56:13,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:13,049 INFO:     Epoch: 76
2023-01-04 10:56:14,599 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38719568252563474, 'Total loss': 0.38719568252563474} | train loss {'Reaction outcome loss': 0.27313861406212364, 'Total loss': 0.27313861406212364}
2023-01-04 10:56:14,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:14,599 INFO:     Epoch: 77
2023-01-04 10:56:16,098 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3482778869569302, 'Total loss': 0.3482778869569302} | train loss {'Reaction outcome loss': 0.27745834283008347, 'Total loss': 0.27745834283008347}
2023-01-04 10:56:16,098 INFO:     Found new best model at epoch 77
2023-01-04 10:56:16,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:16,099 INFO:     Epoch: 78
2023-01-04 10:56:17,681 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43949202398459114, 'Total loss': 0.43949202398459114} | train loss {'Reaction outcome loss': 0.2707823041510318, 'Total loss': 0.2707823041510318}
2023-01-04 10:56:17,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:17,681 INFO:     Epoch: 79
2023-01-04 10:56:19,263 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43643621106942493, 'Total loss': 0.43643621106942493} | train loss {'Reaction outcome loss': 0.2758617613368369, 'Total loss': 0.2758617613368369}
2023-01-04 10:56:19,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:19,263 INFO:     Epoch: 80
2023-01-04 10:56:20,855 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37106900215148925, 'Total loss': 0.37106900215148925} | train loss {'Reaction outcome loss': 0.2745998117701594, 'Total loss': 0.2745998117701594}
2023-01-04 10:56:20,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:20,855 INFO:     Epoch: 81
2023-01-04 10:56:22,445 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.425294425090154, 'Total loss': 0.425294425090154} | train loss {'Reaction outcome loss': 0.2686605367713309, 'Total loss': 0.2686605367713309}
2023-01-04 10:56:22,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:22,445 INFO:     Epoch: 82
2023-01-04 10:56:24,021 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36187775333722433, 'Total loss': 0.36187775333722433} | train loss {'Reaction outcome loss': 0.2716023871379585, 'Total loss': 0.2716023871379585}
2023-01-04 10:56:24,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:24,021 INFO:     Epoch: 83
2023-01-04 10:56:25,531 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39617368777592976, 'Total loss': 0.39617368777592976} | train loss {'Reaction outcome loss': 0.26959144953652064, 'Total loss': 0.26959144953652064}
2023-01-04 10:56:25,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:25,533 INFO:     Epoch: 84
2023-01-04 10:56:27,128 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3787627826134364, 'Total loss': 0.3787627826134364} | train loss {'Reaction outcome loss': 0.2660109340127324, 'Total loss': 0.2660109340127324}
2023-01-04 10:56:27,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:27,128 INFO:     Epoch: 85
2023-01-04 10:56:28,722 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3872709800799688, 'Total loss': 0.3872709800799688} | train loss {'Reaction outcome loss': 0.2641234608209001, 'Total loss': 0.2641234608209001}
2023-01-04 10:56:28,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:28,722 INFO:     Epoch: 86
2023-01-04 10:56:30,308 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3866902073224386, 'Total loss': 0.3866902073224386} | train loss {'Reaction outcome loss': 0.26949788915935036, 'Total loss': 0.26949788915935036}
2023-01-04 10:56:30,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:30,308 INFO:     Epoch: 87
2023-01-04 10:56:31,897 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3785320480664571, 'Total loss': 0.3785320480664571} | train loss {'Reaction outcome loss': 0.2632711596402075, 'Total loss': 0.2632711596402075}
2023-01-04 10:56:31,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:31,898 INFO:     Epoch: 88
2023-01-04 10:56:33,436 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37027250428994496, 'Total loss': 0.37027250428994496} | train loss {'Reaction outcome loss': 0.2631101411427079, 'Total loss': 0.2631101411427079}
2023-01-04 10:56:33,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:33,436 INFO:     Epoch: 89
2023-01-04 10:56:34,984 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37683675984541576, 'Total loss': 0.37683675984541576} | train loss {'Reaction outcome loss': 0.2711457433075922, 'Total loss': 0.2711457433075922}
2023-01-04 10:56:34,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:34,984 INFO:     Epoch: 90
2023-01-04 10:56:36,563 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3704455941915512, 'Total loss': 0.3704455941915512} | train loss {'Reaction outcome loss': 0.26005609069583163, 'Total loss': 0.26005609069583163}
2023-01-04 10:56:36,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:36,563 INFO:     Epoch: 91
2023-01-04 10:56:38,157 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4017444312572479, 'Total loss': 0.4017444312572479} | train loss {'Reaction outcome loss': 0.25646317618249526, 'Total loss': 0.25646317618249526}
2023-01-04 10:56:38,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:38,157 INFO:     Epoch: 92
2023-01-04 10:56:39,742 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3894222304224968, 'Total loss': 0.3894222304224968} | train loss {'Reaction outcome loss': 0.2602985041332861, 'Total loss': 0.2602985041332861}
2023-01-04 10:56:39,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:39,742 INFO:     Epoch: 93
2023-01-04 10:56:41,269 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39059233864148457, 'Total loss': 0.39059233864148457} | train loss {'Reaction outcome loss': 0.2610585616963376, 'Total loss': 0.2610585616963376}
2023-01-04 10:56:41,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:41,269 INFO:     Epoch: 94
2023-01-04 10:56:42,769 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4376091460386912, 'Total loss': 0.4376091460386912} | train loss {'Reaction outcome loss': 0.25942715427862323, 'Total loss': 0.25942715427862323}
2023-01-04 10:56:42,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:42,770 INFO:     Epoch: 95
2023-01-04 10:56:44,296 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3886664301156998, 'Total loss': 0.3886664301156998} | train loss {'Reaction outcome loss': 0.2581455707824978, 'Total loss': 0.2581455707824978}
2023-01-04 10:56:44,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:44,297 INFO:     Epoch: 96
2023-01-04 10:56:45,895 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37836803992589313, 'Total loss': 0.37836803992589313} | train loss {'Reaction outcome loss': 0.2543571416522304, 'Total loss': 0.2543571416522304}
2023-01-04 10:56:45,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:45,896 INFO:     Epoch: 97
2023-01-04 10:56:47,480 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4121299852927526, 'Total loss': 0.4121299852927526} | train loss {'Reaction outcome loss': 0.25691254324248797, 'Total loss': 0.25691254324248797}
2023-01-04 10:56:47,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:47,480 INFO:     Epoch: 98
2023-01-04 10:56:49,074 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.36378627518812817, 'Total loss': 0.36378627518812817} | train loss {'Reaction outcome loss': 0.2570866007371582, 'Total loss': 0.2570866007371582}
2023-01-04 10:56:49,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:49,074 INFO:     Epoch: 99
2023-01-04 10:56:50,642 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3903050323327382, 'Total loss': 0.3903050323327382} | train loss {'Reaction outcome loss': 0.2553564646449696, 'Total loss': 0.2553564646449696}
2023-01-04 10:56:50,642 INFO:     Best model found after epoch 78 of 100.
2023-01-04 10:56:50,642 INFO:   Done with stage: TRAINING
2023-01-04 10:56:50,642 INFO:   Starting stage: EVALUATION
2023-01-04 10:56:50,787 INFO:   Done with stage: EVALUATION
2023-01-04 10:56:50,787 INFO:   Leaving out SEQ value Fold_3
2023-01-04 10:56:50,800 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 10:56:50,800 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:56:51,439 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:56:51,439 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:56:51,507 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:56:51,507 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:56:51,507 INFO:     No hyperparam tuning for this model
2023-01-04 10:56:51,507 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:56:51,507 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:56:51,508 INFO:     None feature selector for col prot
2023-01-04 10:56:51,508 INFO:     None feature selector for col prot
2023-01-04 10:56:51,508 INFO:     None feature selector for col prot
2023-01-04 10:56:51,509 INFO:     None feature selector for col chem
2023-01-04 10:56:51,509 INFO:     None feature selector for col chem
2023-01-04 10:56:51,509 INFO:     None feature selector for col chem
2023-01-04 10:56:51,509 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:56:51,509 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:56:51,510 INFO:     Number of params in model 70111
2023-01-04 10:56:51,513 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:56:51,513 INFO:   Starting stage: TRAINING
2023-01-04 10:56:51,559 INFO:     Val loss before train {'Reaction outcome loss': 1.0119530498981475, 'Total loss': 1.0119530498981475}
2023-01-04 10:56:51,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:51,559 INFO:     Epoch: 0
2023-01-04 10:56:53,092 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7929588198661804, 'Total loss': 0.7929588198661804} | train loss {'Reaction outcome loss': 0.8460316565567559, 'Total loss': 0.8460316565567559}
2023-01-04 10:56:53,092 INFO:     Found new best model at epoch 0
2023-01-04 10:56:53,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:53,093 INFO:     Epoch: 1
2023-01-04 10:56:54,674 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6187094847361246, 'Total loss': 0.6187094847361246} | train loss {'Reaction outcome loss': 0.6841393226254595, 'Total loss': 0.6841393226254595}
2023-01-04 10:56:54,674 INFO:     Found new best model at epoch 1
2023-01-04 10:56:54,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:54,675 INFO:     Epoch: 2
2023-01-04 10:56:56,264 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5530935009320577, 'Total loss': 0.5530935009320577} | train loss {'Reaction outcome loss': 0.5738185501120386, 'Total loss': 0.5738185501120386}
2023-01-04 10:56:56,264 INFO:     Found new best model at epoch 2
2023-01-04 10:56:56,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:56,265 INFO:     Epoch: 3
2023-01-04 10:56:57,832 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5775282343228658, 'Total loss': 0.5775282343228658} | train loss {'Reaction outcome loss': 0.5319174250764568, 'Total loss': 0.5319174250764568}
2023-01-04 10:56:57,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:57,833 INFO:     Epoch: 4
2023-01-04 10:56:59,425 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5196354428927104, 'Total loss': 0.5196354428927104} | train loss {'Reaction outcome loss': 0.512314249673029, 'Total loss': 0.512314249673029}
2023-01-04 10:56:59,425 INFO:     Found new best model at epoch 4
2023-01-04 10:56:59,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:56:59,425 INFO:     Epoch: 5
2023-01-04 10:57:00,946 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5172141710917155, 'Total loss': 0.5172141710917155} | train loss {'Reaction outcome loss': 0.4976388209220702, 'Total loss': 0.4976388209220702}
2023-01-04 10:57:00,946 INFO:     Found new best model at epoch 5
2023-01-04 10:57:00,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:00,947 INFO:     Epoch: 6
2023-01-04 10:57:02,483 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49123340447743735, 'Total loss': 0.49123340447743735} | train loss {'Reaction outcome loss': 0.48812728609046796, 'Total loss': 0.48812728609046796}
2023-01-04 10:57:02,483 INFO:     Found new best model at epoch 6
2023-01-04 10:57:02,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:02,484 INFO:     Epoch: 7
2023-01-04 10:57:04,052 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4863682528336843, 'Total loss': 0.4863682528336843} | train loss {'Reaction outcome loss': 0.47701067950603737, 'Total loss': 0.47701067950603737}
2023-01-04 10:57:04,053 INFO:     Found new best model at epoch 7
2023-01-04 10:57:04,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:04,054 INFO:     Epoch: 8
2023-01-04 10:57:05,624 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49576781888802846, 'Total loss': 0.49576781888802846} | train loss {'Reaction outcome loss': 0.46939363102190684, 'Total loss': 0.46939363102190684}
2023-01-04 10:57:05,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:05,625 INFO:     Epoch: 9
2023-01-04 10:57:07,202 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5143901765346527, 'Total loss': 0.5143901765346527} | train loss {'Reaction outcome loss': 0.465819454160485, 'Total loss': 0.465819454160485}
2023-01-04 10:57:07,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:07,203 INFO:     Epoch: 10
2023-01-04 10:57:08,790 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4732720593611399, 'Total loss': 0.4732720593611399} | train loss {'Reaction outcome loss': 0.4574475819720839, 'Total loss': 0.4574475819720839}
2023-01-04 10:57:08,790 INFO:     Found new best model at epoch 10
2023-01-04 10:57:08,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:08,790 INFO:     Epoch: 11
2023-01-04 10:57:10,298 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48163660168647765, 'Total loss': 0.48163660168647765} | train loss {'Reaction outcome loss': 0.45072536238462385, 'Total loss': 0.45072536238462385}
2023-01-04 10:57:10,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:10,299 INFO:     Epoch: 12
2023-01-04 10:57:11,859 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48280603289604185, 'Total loss': 0.48280603289604185} | train loss {'Reaction outcome loss': 0.4437102656403597, 'Total loss': 0.4437102656403597}
2023-01-04 10:57:11,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:11,859 INFO:     Epoch: 13
2023-01-04 10:57:13,426 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47937586506207785, 'Total loss': 0.47937586506207785} | train loss {'Reaction outcome loss': 0.44065195224145903, 'Total loss': 0.44065195224145903}
2023-01-04 10:57:13,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:13,427 INFO:     Epoch: 14
2023-01-04 10:57:14,994 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4436677575111389, 'Total loss': 0.4436677575111389} | train loss {'Reaction outcome loss': 0.43769075574666044, 'Total loss': 0.43769075574666044}
2023-01-04 10:57:14,994 INFO:     Found new best model at epoch 14
2023-01-04 10:57:14,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:14,995 INFO:     Epoch: 15
2023-01-04 10:57:16,571 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4700055489937464, 'Total loss': 0.4700055489937464} | train loss {'Reaction outcome loss': 0.4273432755339755, 'Total loss': 0.4273432755339755}
2023-01-04 10:57:16,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:16,572 INFO:     Epoch: 16
2023-01-04 10:57:18,134 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46506661276022593, 'Total loss': 0.46506661276022593} | train loss {'Reaction outcome loss': 0.42687441778444024, 'Total loss': 0.42687441778444024}
2023-01-04 10:57:18,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:18,134 INFO:     Epoch: 17
2023-01-04 10:57:19,619 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4466607799132665, 'Total loss': 0.4466607799132665} | train loss {'Reaction outcome loss': 0.42079128591466125, 'Total loss': 0.42079128591466125}
2023-01-04 10:57:19,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:19,620 INFO:     Epoch: 18
2023-01-04 10:57:21,165 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4584059834480286, 'Total loss': 0.4584059834480286} | train loss {'Reaction outcome loss': 0.4170276251533171, 'Total loss': 0.4170276251533171}
2023-01-04 10:57:21,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:21,165 INFO:     Epoch: 19
2023-01-04 10:57:22,722 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4432729721069336, 'Total loss': 0.4432729721069336} | train loss {'Reaction outcome loss': 0.4137786996625636, 'Total loss': 0.4137786996625636}
2023-01-04 10:57:22,722 INFO:     Found new best model at epoch 19
2023-01-04 10:57:22,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:22,723 INFO:     Epoch: 20
2023-01-04 10:57:24,279 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48506778478622437, 'Total loss': 0.48506778478622437} | train loss {'Reaction outcome loss': 0.4103074489827574, 'Total loss': 0.4103074489827574}
2023-01-04 10:57:24,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:24,280 INFO:     Epoch: 21
2023-01-04 10:57:25,842 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44910206496715543, 'Total loss': 0.44910206496715543} | train loss {'Reaction outcome loss': 0.40496330343893844, 'Total loss': 0.40496330343893844}
2023-01-04 10:57:25,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:25,843 INFO:     Epoch: 22
2023-01-04 10:57:27,428 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47860260009765626, 'Total loss': 0.47860260009765626} | train loss {'Reaction outcome loss': 0.400349701979082, 'Total loss': 0.400349701979082}
2023-01-04 10:57:27,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:27,428 INFO:     Epoch: 23
2023-01-04 10:57:28,925 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46580905516942345, 'Total loss': 0.46580905516942345} | train loss {'Reaction outcome loss': 0.3963928143527821, 'Total loss': 0.3963928143527821}
2023-01-04 10:57:28,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:28,925 INFO:     Epoch: 24
2023-01-04 10:57:30,502 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44343660871187845, 'Total loss': 0.44343660871187845} | train loss {'Reaction outcome loss': 0.39432693125992796, 'Total loss': 0.39432693125992796}
2023-01-04 10:57:30,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:30,503 INFO:     Epoch: 25
2023-01-04 10:57:32,074 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46245406369368236, 'Total loss': 0.46245406369368236} | train loss {'Reaction outcome loss': 0.39056996160941404, 'Total loss': 0.39056996160941404}
2023-01-04 10:57:32,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:32,074 INFO:     Epoch: 26
2023-01-04 10:57:33,648 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4443068544069926, 'Total loss': 0.4443068544069926} | train loss {'Reaction outcome loss': 0.38612816134726047, 'Total loss': 0.38612816134726047}
2023-01-04 10:57:33,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:33,649 INFO:     Epoch: 27
2023-01-04 10:57:35,213 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4374023377895355, 'Total loss': 0.4374023377895355} | train loss {'Reaction outcome loss': 0.3783199151937109, 'Total loss': 0.3783199151937109}
2023-01-04 10:57:35,213 INFO:     Found new best model at epoch 27
2023-01-04 10:57:35,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:35,214 INFO:     Epoch: 28
2023-01-04 10:57:36,767 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4553139090538025, 'Total loss': 0.4553139090538025} | train loss {'Reaction outcome loss': 0.3823721832765715, 'Total loss': 0.3823721832765715}
2023-01-04 10:57:36,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:36,768 INFO:     Epoch: 29
2023-01-04 10:57:38,290 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4807466427485148, 'Total loss': 0.4807466427485148} | train loss {'Reaction outcome loss': 0.3740655829055901, 'Total loss': 0.3740655829055901}
2023-01-04 10:57:38,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:38,290 INFO:     Epoch: 30
2023-01-04 10:57:39,894 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43233769039312997, 'Total loss': 0.43233769039312997} | train loss {'Reaction outcome loss': 0.3723001484725162, 'Total loss': 0.3723001484725162}
2023-01-04 10:57:39,895 INFO:     Found new best model at epoch 30
2023-01-04 10:57:39,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:39,896 INFO:     Epoch: 31
2023-01-04 10:57:41,492 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4121492952108383, 'Total loss': 0.4121492952108383} | train loss {'Reaction outcome loss': 0.368198003701485, 'Total loss': 0.368198003701485}
2023-01-04 10:57:41,492 INFO:     Found new best model at epoch 31
2023-01-04 10:57:41,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:41,493 INFO:     Epoch: 32
2023-01-04 10:57:43,085 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45375554462273915, 'Total loss': 0.45375554462273915} | train loss {'Reaction outcome loss': 0.3683515826552889, 'Total loss': 0.3683515826552889}
2023-01-04 10:57:43,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:43,086 INFO:     Epoch: 33
2023-01-04 10:57:44,677 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43134729663530985, 'Total loss': 0.43134729663530985} | train loss {'Reaction outcome loss': 0.36446260247569884, 'Total loss': 0.36446260247569884}
2023-01-04 10:57:44,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:44,678 INFO:     Epoch: 34
2023-01-04 10:57:46,229 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4223513603210449, 'Total loss': 0.4223513603210449} | train loss {'Reaction outcome loss': 0.36026158833699506, 'Total loss': 0.36026158833699506}
2023-01-04 10:57:46,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:46,229 INFO:     Epoch: 35
2023-01-04 10:57:47,779 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4434540788332621, 'Total loss': 0.4434540788332621} | train loss {'Reaction outcome loss': 0.35734431865713456, 'Total loss': 0.35734431865713456}
2023-01-04 10:57:47,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:47,779 INFO:     Epoch: 36
2023-01-04 10:57:49,357 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4223488102356593, 'Total loss': 0.4223488102356593} | train loss {'Reaction outcome loss': 0.35721248573195324, 'Total loss': 0.35721248573195324}
2023-01-04 10:57:49,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:49,357 INFO:     Epoch: 37
2023-01-04 10:57:50,957 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42772530714670814, 'Total loss': 0.42772530714670814} | train loss {'Reaction outcome loss': 0.3486517788774341, 'Total loss': 0.3486517788774341}
2023-01-04 10:57:50,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:50,957 INFO:     Epoch: 38
2023-01-04 10:57:52,548 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41094758212566374, 'Total loss': 0.41094758212566374} | train loss {'Reaction outcome loss': 0.3490738837986532, 'Total loss': 0.3490738837986532}
2023-01-04 10:57:52,549 INFO:     Found new best model at epoch 38
2023-01-04 10:57:52,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:52,550 INFO:     Epoch: 39
2023-01-04 10:57:54,136 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.435056604941686, 'Total loss': 0.435056604941686} | train loss {'Reaction outcome loss': 0.34471142406228683, 'Total loss': 0.34471142406228683}
2023-01-04 10:57:54,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:54,136 INFO:     Epoch: 40
2023-01-04 10:57:55,679 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3929942707220713, 'Total loss': 0.3929942707220713} | train loss {'Reaction outcome loss': 0.3444758747452802, 'Total loss': 0.3444758747452802}
2023-01-04 10:57:55,679 INFO:     Found new best model at epoch 40
2023-01-04 10:57:55,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:55,680 INFO:     Epoch: 41
2023-01-04 10:57:57,254 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41037020087242126, 'Total loss': 0.41037020087242126} | train loss {'Reaction outcome loss': 0.3420952985702205, 'Total loss': 0.3420952985702205}
2023-01-04 10:57:57,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:57,255 INFO:     Epoch: 42
2023-01-04 10:57:58,851 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.404112783074379, 'Total loss': 0.404112783074379} | train loss {'Reaction outcome loss': 0.3367142677579048, 'Total loss': 0.3367142677579048}
2023-01-04 10:57:58,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:57:58,851 INFO:     Epoch: 43
2023-01-04 10:58:00,453 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4305339733759562, 'Total loss': 0.4305339733759562} | train loss {'Reaction outcome loss': 0.333700747195169, 'Total loss': 0.333700747195169}
2023-01-04 10:58:00,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:00,453 INFO:     Epoch: 44
2023-01-04 10:58:02,055 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4054202934106191, 'Total loss': 0.4054202934106191} | train loss {'Reaction outcome loss': 0.3362666868271619, 'Total loss': 0.3362666868271619}
2023-01-04 10:58:02,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:02,055 INFO:     Epoch: 45
2023-01-04 10:58:03,663 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41496386577685673, 'Total loss': 0.41496386577685673} | train loss {'Reaction outcome loss': 0.3349998504684789, 'Total loss': 0.3349998504684789}
2023-01-04 10:58:03,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:03,663 INFO:     Epoch: 46
2023-01-04 10:58:05,119 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4303930997848511, 'Total loss': 0.4303930997848511} | train loss {'Reaction outcome loss': 0.327866940575577, 'Total loss': 0.327866940575577}
2023-01-04 10:58:05,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:05,119 INFO:     Epoch: 47
2023-01-04 10:58:06,151 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42122039596239724, 'Total loss': 0.42122039596239724} | train loss {'Reaction outcome loss': 0.3268236001260089, 'Total loss': 0.3268236001260089}
2023-01-04 10:58:06,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:06,151 INFO:     Epoch: 48
2023-01-04 10:58:07,177 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4066654473543167, 'Total loss': 0.4066654473543167} | train loss {'Reaction outcome loss': 0.3242761848263279, 'Total loss': 0.3242761848263279}
2023-01-04 10:58:07,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:07,177 INFO:     Epoch: 49
2023-01-04 10:58:08,202 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41515469749768574, 'Total loss': 0.41515469749768574} | train loss {'Reaction outcome loss': 0.32087211694269285, 'Total loss': 0.32087211694269285}
2023-01-04 10:58:08,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:08,204 INFO:     Epoch: 50
2023-01-04 10:58:09,264 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41559718549251556, 'Total loss': 0.41559718549251556} | train loss {'Reaction outcome loss': 0.31698214213778503, 'Total loss': 0.31698214213778503}
2023-01-04 10:58:09,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:09,264 INFO:     Epoch: 51
2023-01-04 10:58:10,819 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4249813437461853, 'Total loss': 0.4249813437461853} | train loss {'Reaction outcome loss': 0.31511051262164635, 'Total loss': 0.31511051262164635}
2023-01-04 10:58:10,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:10,819 INFO:     Epoch: 52
2023-01-04 10:58:12,413 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41812635163466133, 'Total loss': 0.41812635163466133} | train loss {'Reaction outcome loss': 0.31600038745324976, 'Total loss': 0.31600038745324976}
2023-01-04 10:58:12,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:12,413 INFO:     Epoch: 53
2023-01-04 10:58:14,006 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41054756740729015, 'Total loss': 0.41054756740729015} | train loss {'Reaction outcome loss': 0.31473789965040494, 'Total loss': 0.31473789965040494}
2023-01-04 10:58:14,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:14,006 INFO:     Epoch: 54
2023-01-04 10:58:15,604 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4106460362672806, 'Total loss': 0.4106460362672806} | train loss {'Reaction outcome loss': 0.31620930002009784, 'Total loss': 0.31620930002009784}
2023-01-04 10:58:15,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:15,605 INFO:     Epoch: 55
2023-01-04 10:58:17,208 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.403128907084465, 'Total loss': 0.403128907084465} | train loss {'Reaction outcome loss': 0.30951060338394487, 'Total loss': 0.30951060338394487}
2023-01-04 10:58:17,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:17,209 INFO:     Epoch: 56
2023-01-04 10:58:18,769 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3874344448248545, 'Total loss': 0.3874344448248545} | train loss {'Reaction outcome loss': 0.3054392478653114, 'Total loss': 0.3054392478653114}
2023-01-04 10:58:18,769 INFO:     Found new best model at epoch 56
2023-01-04 10:58:18,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:18,770 INFO:     Epoch: 57
2023-01-04 10:58:20,322 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4163862446943919, 'Total loss': 0.4163862446943919} | train loss {'Reaction outcome loss': 0.30721747094806096, 'Total loss': 0.30721747094806096}
2023-01-04 10:58:20,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:20,322 INFO:     Epoch: 58
2023-01-04 10:58:21,912 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43388140996297203, 'Total loss': 0.43388140996297203} | train loss {'Reaction outcome loss': 0.30115918178845497, 'Total loss': 0.30115918178845497}
2023-01-04 10:58:21,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:21,912 INFO:     Epoch: 59
2023-01-04 10:58:23,483 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38118528127670287, 'Total loss': 0.38118528127670287} | train loss {'Reaction outcome loss': 0.30119439130173115, 'Total loss': 0.30119439130173115}
2023-01-04 10:58:23,483 INFO:     Found new best model at epoch 59
2023-01-04 10:58:23,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:23,484 INFO:     Epoch: 60
2023-01-04 10:58:25,040 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.435801237821579, 'Total loss': 0.435801237821579} | train loss {'Reaction outcome loss': 0.3034139996136192, 'Total loss': 0.3034139996136192}
2023-01-04 10:58:25,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:25,040 INFO:     Epoch: 61
2023-01-04 10:58:26,591 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4160075734059016, 'Total loss': 0.4160075734059016} | train loss {'Reaction outcome loss': 0.2993202726390675, 'Total loss': 0.2993202726390675}
2023-01-04 10:58:26,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:26,591 INFO:     Epoch: 62
2023-01-04 10:58:28,125 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4074467301368713, 'Total loss': 0.4074467301368713} | train loss {'Reaction outcome loss': 0.2957448804628675, 'Total loss': 0.2957448804628675}
2023-01-04 10:58:28,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:28,126 INFO:     Epoch: 63
2023-01-04 10:58:29,688 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40619054238001506, 'Total loss': 0.40619054238001506} | train loss {'Reaction outcome loss': 0.29692720349905266, 'Total loss': 0.29692720349905266}
2023-01-04 10:58:29,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:29,688 INFO:     Epoch: 64
2023-01-04 10:58:31,300 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4337130675713221, 'Total loss': 0.4337130675713221} | train loss {'Reaction outcome loss': 0.2928194975222114, 'Total loss': 0.2928194975222114}
2023-01-04 10:58:31,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:31,300 INFO:     Epoch: 65
2023-01-04 10:58:32,914 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4223231812318166, 'Total loss': 0.4223231812318166} | train loss {'Reaction outcome loss': 0.2945399219374152, 'Total loss': 0.2945399219374152}
2023-01-04 10:58:32,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:32,915 INFO:     Epoch: 66
2023-01-04 10:58:34,517 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4099095602830251, 'Total loss': 0.4099095602830251} | train loss {'Reaction outcome loss': 0.29151326918253934, 'Total loss': 0.29151326918253934}
2023-01-04 10:58:34,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:34,517 INFO:     Epoch: 67
2023-01-04 10:58:36,132 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38699047863483427, 'Total loss': 0.38699047863483427} | train loss {'Reaction outcome loss': 0.28963661479362607, 'Total loss': 0.28963661479362607}
2023-01-04 10:58:36,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:36,132 INFO:     Epoch: 68
2023-01-04 10:58:37,705 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38150440404812497, 'Total loss': 0.38150440404812497} | train loss {'Reaction outcome loss': 0.2860655863327484, 'Total loss': 0.2860655863327484}
2023-01-04 10:58:37,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:37,705 INFO:     Epoch: 69
2023-01-04 10:58:39,278 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3879581666241089, 'Total loss': 0.3879581666241089} | train loss {'Reaction outcome loss': 0.28643177047263096, 'Total loss': 0.28643177047263096}
2023-01-04 10:58:39,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:39,279 INFO:     Epoch: 70
2023-01-04 10:58:40,885 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37834835300842923, 'Total loss': 0.37834835300842923} | train loss {'Reaction outcome loss': 0.2839149446056707, 'Total loss': 0.2839149446056707}
2023-01-04 10:58:40,885 INFO:     Found new best model at epoch 70
2023-01-04 10:58:40,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:40,886 INFO:     Epoch: 71
2023-01-04 10:58:42,496 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40454673568407695, 'Total loss': 0.40454673568407695} | train loss {'Reaction outcome loss': 0.28323643907469553, 'Total loss': 0.28323643907469553}
2023-01-04 10:58:42,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:42,496 INFO:     Epoch: 72
2023-01-04 10:58:44,112 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38333677252133685, 'Total loss': 0.38333677252133685} | train loss {'Reaction outcome loss': 0.28234488987465844, 'Total loss': 0.28234488987465844}
2023-01-04 10:58:44,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:44,112 INFO:     Epoch: 73
2023-01-04 10:58:45,718 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3765442798535029, 'Total loss': 0.3765442798535029} | train loss {'Reaction outcome loss': 0.28245858646874883, 'Total loss': 0.28245858646874883}
2023-01-04 10:58:45,719 INFO:     Found new best model at epoch 73
2023-01-04 10:58:45,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:45,719 INFO:     Epoch: 74
2023-01-04 10:58:47,209 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38530014803012214, 'Total loss': 0.38530014803012214} | train loss {'Reaction outcome loss': 0.2803760904845965, 'Total loss': 0.2803760904845965}
2023-01-04 10:58:47,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:47,209 INFO:     Epoch: 75
2023-01-04 10:58:48,817 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41580118983983994, 'Total loss': 0.41580118983983994} | train loss {'Reaction outcome loss': 0.27823518309062417, 'Total loss': 0.27823518309062417}
2023-01-04 10:58:48,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:48,817 INFO:     Epoch: 76
2023-01-04 10:58:50,420 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.400984658797582, 'Total loss': 0.400984658797582} | train loss {'Reaction outcome loss': 0.27902035018170834, 'Total loss': 0.27902035018170834}
2023-01-04 10:58:50,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:50,420 INFO:     Epoch: 77
2023-01-04 10:58:52,022 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40624953905741373, 'Total loss': 0.40624953905741373} | train loss {'Reaction outcome loss': 0.27403894917917077, 'Total loss': 0.27403894917917077}
2023-01-04 10:58:52,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:52,022 INFO:     Epoch: 78
2023-01-04 10:58:53,607 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3702251891295115, 'Total loss': 0.3702251891295115} | train loss {'Reaction outcome loss': 0.27533149047598354, 'Total loss': 0.27533149047598354}
2023-01-04 10:58:53,608 INFO:     Found new best model at epoch 78
2023-01-04 10:58:53,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:53,608 INFO:     Epoch: 79
2023-01-04 10:58:55,154 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39368208050727843, 'Total loss': 0.39368208050727843} | train loss {'Reaction outcome loss': 0.27716619418050253, 'Total loss': 0.27716619418050253}
2023-01-04 10:58:55,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:55,154 INFO:     Epoch: 80
2023-01-04 10:58:56,706 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3730023284753164, 'Total loss': 0.3730023284753164} | train loss {'Reaction outcome loss': 0.27529508778213585, 'Total loss': 0.27529508778213585}
2023-01-04 10:58:56,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:56,707 INFO:     Epoch: 81
2023-01-04 10:58:58,297 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.415444552898407, 'Total loss': 0.415444552898407} | train loss {'Reaction outcome loss': 0.2739934883875786, 'Total loss': 0.2739934883875786}
2023-01-04 10:58:58,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:58,298 INFO:     Epoch: 82
2023-01-04 10:58:59,903 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.412682318687439, 'Total loss': 0.412682318687439} | train loss {'Reaction outcome loss': 0.27072564942123245, 'Total loss': 0.27072564942123245}
2023-01-04 10:58:59,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:58:59,903 INFO:     Epoch: 83
2023-01-04 10:59:01,515 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37530750731627144, 'Total loss': 0.37530750731627144} | train loss {'Reaction outcome loss': 0.26859117465188903, 'Total loss': 0.26859117465188903}
2023-01-04 10:59:01,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:01,516 INFO:     Epoch: 84
2023-01-04 10:59:03,107 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.393779722849528, 'Total loss': 0.393779722849528} | train loss {'Reaction outcome loss': 0.26985248077633606, 'Total loss': 0.26985248077633606}
2023-01-04 10:59:03,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:03,107 INFO:     Epoch: 85
2023-01-04 10:59:04,673 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41980821986993155, 'Total loss': 0.41980821986993155} | train loss {'Reaction outcome loss': 0.2727563827142228, 'Total loss': 0.2727563827142228}
2023-01-04 10:59:04,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:04,673 INFO:     Epoch: 86
2023-01-04 10:59:06,238 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3696887920300166, 'Total loss': 0.3696887920300166} | train loss {'Reaction outcome loss': 0.26654309073095994, 'Total loss': 0.26654309073095994}
2023-01-04 10:59:06,238 INFO:     Found new best model at epoch 86
2023-01-04 10:59:06,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:06,239 INFO:     Epoch: 87
2023-01-04 10:59:07,848 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3836103280385335, 'Total loss': 0.3836103280385335} | train loss {'Reaction outcome loss': 0.2658625652972799, 'Total loss': 0.2658625652972799}
2023-01-04 10:59:07,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:07,849 INFO:     Epoch: 88
2023-01-04 10:59:09,413 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40014336407184603, 'Total loss': 0.40014336407184603} | train loss {'Reaction outcome loss': 0.26649627154760985, 'Total loss': 0.26649627154760985}
2023-01-04 10:59:09,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:09,415 INFO:     Epoch: 89
2023-01-04 10:59:10,989 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38353750904401146, 'Total loss': 0.38353750904401146} | train loss {'Reaction outcome loss': 0.26501416535980077, 'Total loss': 0.26501416535980077}
2023-01-04 10:59:10,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:10,989 INFO:     Epoch: 90
2023-01-04 10:59:12,543 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40150694251060487, 'Total loss': 0.40150694251060487} | train loss {'Reaction outcome loss': 0.2615272328257561, 'Total loss': 0.2615272328257561}
2023-01-04 10:59:12,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:12,543 INFO:     Epoch: 91
2023-01-04 10:59:14,056 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.359647477666537, 'Total loss': 0.359647477666537} | train loss {'Reaction outcome loss': 0.26063301979842846, 'Total loss': 0.26063301979842846}
2023-01-04 10:59:14,056 INFO:     Found new best model at epoch 91
2023-01-04 10:59:14,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:14,057 INFO:     Epoch: 92
2023-01-04 10:59:15,581 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41749610702196754, 'Total loss': 0.41749610702196754} | train loss {'Reaction outcome loss': 0.26218623183939577, 'Total loss': 0.26218623183939577}
2023-01-04 10:59:15,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:15,582 INFO:     Epoch: 93
2023-01-04 10:59:17,143 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40310335755348203, 'Total loss': 0.40310335755348203} | train loss {'Reaction outcome loss': 0.2646288568031614, 'Total loss': 0.2646288568031614}
2023-01-04 10:59:17,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:17,144 INFO:     Epoch: 94
2023-01-04 10:59:18,738 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3767837444941203, 'Total loss': 0.3767837444941203} | train loss {'Reaction outcome loss': 0.2633816770611018, 'Total loss': 0.2633816770611018}
2023-01-04 10:59:18,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:18,739 INFO:     Epoch: 95
2023-01-04 10:59:20,329 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39924767762422564, 'Total loss': 0.39924767762422564} | train loss {'Reaction outcome loss': 0.25917278136378225, 'Total loss': 0.25917278136378225}
2023-01-04 10:59:20,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:20,329 INFO:     Epoch: 96
2023-01-04 10:59:21,933 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3760668555895487, 'Total loss': 0.3760668555895487} | train loss {'Reaction outcome loss': 0.25817769034391774, 'Total loss': 0.25817769034391774}
2023-01-04 10:59:21,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:21,933 INFO:     Epoch: 97
2023-01-04 10:59:23,468 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3890329748392105, 'Total loss': 0.3890329748392105} | train loss {'Reaction outcome loss': 0.256643610401419, 'Total loss': 0.256643610401419}
2023-01-04 10:59:23,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:23,468 INFO:     Epoch: 98
2023-01-04 10:59:25,059 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.398514524102211, 'Total loss': 0.398514524102211} | train loss {'Reaction outcome loss': 0.2605646385600532, 'Total loss': 0.2605646385600532}
2023-01-04 10:59:25,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:25,060 INFO:     Epoch: 99
2023-01-04 10:59:26,669 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3973666369915009, 'Total loss': 0.3973666369915009} | train loss {'Reaction outcome loss': 0.256455730565273, 'Total loss': 0.256455730565273}
2023-01-04 10:59:26,670 INFO:     Best model found after epoch 92 of 100.
2023-01-04 10:59:26,670 INFO:   Done with stage: TRAINING
2023-01-04 10:59:26,670 INFO:   Starting stage: EVALUATION
2023-01-04 10:59:26,802 INFO:   Done with stage: EVALUATION
2023-01-04 10:59:26,802 INFO:   Leaving out SEQ value Fold_4
2023-01-04 10:59:26,815 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 10:59:26,815 INFO:   Starting stage: FEATURE SCALING
2023-01-04 10:59:27,465 INFO:   Done with stage: FEATURE SCALING
2023-01-04 10:59:27,465 INFO:   Starting stage: SCALING TARGETS
2023-01-04 10:59:27,533 INFO:   Done with stage: SCALING TARGETS
2023-01-04 10:59:27,533 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:59:27,533 INFO:     No hyperparam tuning for this model
2023-01-04 10:59:27,533 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 10:59:27,533 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 10:59:27,534 INFO:     None feature selector for col prot
2023-01-04 10:59:27,534 INFO:     None feature selector for col prot
2023-01-04 10:59:27,534 INFO:     None feature selector for col prot
2023-01-04 10:59:27,534 INFO:     None feature selector for col chem
2023-01-04 10:59:27,535 INFO:     None feature selector for col chem
2023-01-04 10:59:27,535 INFO:     None feature selector for col chem
2023-01-04 10:59:27,535 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 10:59:27,535 INFO:   Starting stage: BUILD MODEL
2023-01-04 10:59:27,536 INFO:     Number of params in model 70111
2023-01-04 10:59:27,539 INFO:   Done with stage: BUILD MODEL
2023-01-04 10:59:27,539 INFO:   Starting stage: TRAINING
2023-01-04 10:59:27,581 INFO:     Val loss before train {'Reaction outcome loss': 1.0071788549423217, 'Total loss': 1.0071788549423217}
2023-01-04 10:59:27,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:27,582 INFO:     Epoch: 0
2023-01-04 10:59:29,208 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7372149427731832, 'Total loss': 0.7372149427731832} | train loss {'Reaction outcome loss': 0.8312750339292877, 'Total loss': 0.8312750339292877}
2023-01-04 10:59:29,208 INFO:     Found new best model at epoch 0
2023-01-04 10:59:29,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:29,209 INFO:     Epoch: 1
2023-01-04 10:59:30,833 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6206934829552968, 'Total loss': 0.6206934829552968} | train loss {'Reaction outcome loss': 0.6583425712499378, 'Total loss': 0.6583425712499378}
2023-01-04 10:59:30,833 INFO:     Found new best model at epoch 1
2023-01-04 10:59:30,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:30,834 INFO:     Epoch: 2
2023-01-04 10:59:32,346 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6052093744277954, 'Total loss': 0.6052093744277954} | train loss {'Reaction outcome loss': 0.5756052980461706, 'Total loss': 0.5756052980461706}
2023-01-04 10:59:32,347 INFO:     Found new best model at epoch 2
2023-01-04 10:59:32,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:32,347 INFO:     Epoch: 3
2023-01-04 10:59:33,978 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.575800629456838, 'Total loss': 0.575800629456838} | train loss {'Reaction outcome loss': 0.5357007105643138, 'Total loss': 0.5357007105643138}
2023-01-04 10:59:33,978 INFO:     Found new best model at epoch 3
2023-01-04 10:59:33,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:33,979 INFO:     Epoch: 4
2023-01-04 10:59:35,585 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5601412733395894, 'Total loss': 0.5601412733395894} | train loss {'Reaction outcome loss': 0.5243926563633048, 'Total loss': 0.5243926563633048}
2023-01-04 10:59:35,585 INFO:     Found new best model at epoch 4
2023-01-04 10:59:35,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:35,586 INFO:     Epoch: 5
2023-01-04 10:59:37,196 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.543631237745285, 'Total loss': 0.543631237745285} | train loss {'Reaction outcome loss': 0.5046226809386312, 'Total loss': 0.5046226809386312}
2023-01-04 10:59:37,196 INFO:     Found new best model at epoch 5
2023-01-04 10:59:37,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:37,197 INFO:     Epoch: 6
2023-01-04 10:59:38,814 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5515605489412944, 'Total loss': 0.5515605489412944} | train loss {'Reaction outcome loss': 0.49406122262942664, 'Total loss': 0.49406122262942664}
2023-01-04 10:59:38,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:38,814 INFO:     Epoch: 7
2023-01-04 10:59:40,400 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5578981220722199, 'Total loss': 0.5578981220722199} | train loss {'Reaction outcome loss': 0.4865905561279304, 'Total loss': 0.4865905561279304}
2023-01-04 10:59:40,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:40,400 INFO:     Epoch: 8
2023-01-04 10:59:41,980 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5845557391643524, 'Total loss': 0.5845557391643524} | train loss {'Reaction outcome loss': 0.4753787010800537, 'Total loss': 0.4753787010800537}
2023-01-04 10:59:41,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:41,981 INFO:     Epoch: 9
2023-01-04 10:59:43,608 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5517533441384633, 'Total loss': 0.5517533441384633} | train loss {'Reaction outcome loss': 0.47078456043766725, 'Total loss': 0.47078456043766725}
2023-01-04 10:59:43,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:43,608 INFO:     Epoch: 10
2023-01-04 10:59:45,229 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5346754868825276, 'Total loss': 0.5346754868825276} | train loss {'Reaction outcome loss': 0.4671799755698937, 'Total loss': 0.4671799755698937}
2023-01-04 10:59:45,229 INFO:     Found new best model at epoch 10
2023-01-04 10:59:45,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:45,230 INFO:     Epoch: 11
2023-01-04 10:59:46,852 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.531280920902888, 'Total loss': 0.531280920902888} | train loss {'Reaction outcome loss': 0.45831033329240684, 'Total loss': 0.45831033329240684}
2023-01-04 10:59:46,853 INFO:     Found new best model at epoch 11
2023-01-04 10:59:46,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:46,854 INFO:     Epoch: 12
2023-01-04 10:59:48,484 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5255767474571864, 'Total loss': 0.5255767474571864} | train loss {'Reaction outcome loss': 0.451229927503245, 'Total loss': 0.451229927503245}
2023-01-04 10:59:48,484 INFO:     Found new best model at epoch 12
2023-01-04 10:59:48,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:48,485 INFO:     Epoch: 13
2023-01-04 10:59:50,054 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5537221272786458, 'Total loss': 0.5537221272786458} | train loss {'Reaction outcome loss': 0.4483973308590775, 'Total loss': 0.4483973308590775}
2023-01-04 10:59:50,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:50,054 INFO:     Epoch: 14
2023-01-04 10:59:51,639 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5640064924955368, 'Total loss': 0.5640064924955368} | train loss {'Reaction outcome loss': 0.4431587088086545, 'Total loss': 0.4431587088086545}
2023-01-04 10:59:51,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:51,640 INFO:     Epoch: 15
2023-01-04 10:59:53,260 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5240446945031484, 'Total loss': 0.5240446945031484} | train loss {'Reaction outcome loss': 0.43682044825183786, 'Total loss': 0.43682044825183786}
2023-01-04 10:59:53,261 INFO:     Found new best model at epoch 15
2023-01-04 10:59:53,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:53,261 INFO:     Epoch: 16
2023-01-04 10:59:54,885 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5261768579483033, 'Total loss': 0.5261768579483033} | train loss {'Reaction outcome loss': 0.43315824355244203, 'Total loss': 0.43315824355244203}
2023-01-04 10:59:54,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:54,886 INFO:     Epoch: 17
2023-01-04 10:59:56,513 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5159589747587839, 'Total loss': 0.5159589747587839} | train loss {'Reaction outcome loss': 0.4280251101035934, 'Total loss': 0.4280251101035934}
2023-01-04 10:59:56,513 INFO:     Found new best model at epoch 17
2023-01-04 10:59:56,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:56,514 INFO:     Epoch: 18
2023-01-04 10:59:58,126 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5185304701328277, 'Total loss': 0.5185304701328277} | train loss {'Reaction outcome loss': 0.4229890769784631, 'Total loss': 0.4229890769784631}
2023-01-04 10:59:58,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:58,127 INFO:     Epoch: 19
2023-01-04 10:59:59,662 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5223930259545644, 'Total loss': 0.5223930259545644} | train loss {'Reaction outcome loss': 0.4234273178697923, 'Total loss': 0.4234273178697923}
2023-01-04 10:59:59,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 10:59:59,662 INFO:     Epoch: 20
2023-01-04 11:00:01,264 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5060269157091777, 'Total loss': 0.5060269157091777} | train loss {'Reaction outcome loss': 0.4162559904400192, 'Total loss': 0.4162559904400192}
2023-01-04 11:00:01,264 INFO:     Found new best model at epoch 20
2023-01-04 11:00:01,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:01,265 INFO:     Epoch: 21
2023-01-04 11:00:02,851 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5504881342252096, 'Total loss': 0.5504881342252096} | train loss {'Reaction outcome loss': 0.4130687857793126, 'Total loss': 0.4130687857793126}
2023-01-04 11:00:02,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:02,851 INFO:     Epoch: 22
2023-01-04 11:00:04,448 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5318693737188975, 'Total loss': 0.5318693737188975} | train loss {'Reaction outcome loss': 0.4098926078165051, 'Total loss': 0.4098926078165051}
2023-01-04 11:00:04,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:04,448 INFO:     Epoch: 23
2023-01-04 11:00:06,035 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5208045532306035, 'Total loss': 0.5208045532306035} | train loss {'Reaction outcome loss': 0.4036984034555053, 'Total loss': 0.4036984034555053}
2023-01-04 11:00:06,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:06,036 INFO:     Epoch: 24
2023-01-04 11:00:07,594 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5167424480120341, 'Total loss': 0.5167424480120341} | train loss {'Reaction outcome loss': 0.39774062207459543, 'Total loss': 0.39774062207459543}
2023-01-04 11:00:07,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:07,595 INFO:     Epoch: 25
2023-01-04 11:00:09,135 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5019335021575292, 'Total loss': 0.5019335021575292} | train loss {'Reaction outcome loss': 0.3943847249453679, 'Total loss': 0.3943847249453679}
2023-01-04 11:00:09,135 INFO:     Found new best model at epoch 25
2023-01-04 11:00:09,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:09,136 INFO:     Epoch: 26
2023-01-04 11:00:10,723 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5090152124563853, 'Total loss': 0.5090152124563853} | train loss {'Reaction outcome loss': 0.3925230686522563, 'Total loss': 0.3925230686522563}
2023-01-04 11:00:10,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:10,723 INFO:     Epoch: 27
2023-01-04 11:00:12,305 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5420845607916515, 'Total loss': 0.5420845607916515} | train loss {'Reaction outcome loss': 0.3897295106296505, 'Total loss': 0.3897295106296505}
2023-01-04 11:00:12,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:12,305 INFO:     Epoch: 28
2023-01-04 11:00:13,893 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5041915496190389, 'Total loss': 0.5041915496190389} | train loss {'Reaction outcome loss': 0.3873314983093782, 'Total loss': 0.3873314983093782}
2023-01-04 11:00:13,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:13,893 INFO:     Epoch: 29
2023-01-04 11:00:15,468 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5286897917588552, 'Total loss': 0.5286897917588552} | train loss {'Reaction outcome loss': 0.380349921835889, 'Total loss': 0.380349921835889}
2023-01-04 11:00:15,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:15,468 INFO:     Epoch: 30
2023-01-04 11:00:17,026 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5172222673892974, 'Total loss': 0.5172222673892974} | train loss {'Reaction outcome loss': 0.3784370784940272, 'Total loss': 0.3784370784940272}
2023-01-04 11:00:17,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:17,026 INFO:     Epoch: 31
2023-01-04 11:00:18,566 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5074816594521204, 'Total loss': 0.5074816594521204} | train loss {'Reaction outcome loss': 0.3737857410623709, 'Total loss': 0.3737857410623709}
2023-01-04 11:00:18,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:18,566 INFO:     Epoch: 32
2023-01-04 11:00:20,147 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5360506574312845, 'Total loss': 0.5360506574312845} | train loss {'Reaction outcome loss': 0.37302648843625824, 'Total loss': 0.37302648843625824}
2023-01-04 11:00:20,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:20,148 INFO:     Epoch: 33
2023-01-04 11:00:21,719 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5232017338275909, 'Total loss': 0.5232017338275909} | train loss {'Reaction outcome loss': 0.36700347135858846, 'Total loss': 0.36700347135858846}
2023-01-04 11:00:21,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:21,720 INFO:     Epoch: 34
2023-01-04 11:00:23,277 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5269314587116242, 'Total loss': 0.5269314587116242} | train loss {'Reaction outcome loss': 0.365326369040064, 'Total loss': 0.365326369040064}
2023-01-04 11:00:23,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:23,277 INFO:     Epoch: 35
2023-01-04 11:00:24,872 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5072842518488566, 'Total loss': 0.5072842518488566} | train loss {'Reaction outcome loss': 0.362179284895155, 'Total loss': 0.362179284895155}
2023-01-04 11:00:24,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:24,872 INFO:     Epoch: 36
2023-01-04 11:00:26,431 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47858372529347737, 'Total loss': 0.47858372529347737} | train loss {'Reaction outcome loss': 0.3564354272202895, 'Total loss': 0.3564354272202895}
2023-01-04 11:00:26,431 INFO:     Found new best model at epoch 36
2023-01-04 11:00:26,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:26,432 INFO:     Epoch: 37
2023-01-04 11:00:27,986 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49724911550680795, 'Total loss': 0.49724911550680795} | train loss {'Reaction outcome loss': 0.35592261013248766, 'Total loss': 0.35592261013248766}
2023-01-04 11:00:27,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:27,987 INFO:     Epoch: 38
2023-01-04 11:00:29,587 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4888909141222636, 'Total loss': 0.4888909141222636} | train loss {'Reaction outcome loss': 0.35136880997285946, 'Total loss': 0.35136880997285946}
2023-01-04 11:00:29,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:29,587 INFO:     Epoch: 39
2023-01-04 11:00:31,161 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4709923048814138, 'Total loss': 0.4709923048814138} | train loss {'Reaction outcome loss': 0.34925954544156895, 'Total loss': 0.34925954544156895}
2023-01-04 11:00:31,161 INFO:     Found new best model at epoch 39
2023-01-04 11:00:31,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:31,162 INFO:     Epoch: 40
2023-01-04 11:00:32,737 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4816687315702438, 'Total loss': 0.4816687315702438} | train loss {'Reaction outcome loss': 0.3415812408881067, 'Total loss': 0.3415812408881067}
2023-01-04 11:00:32,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:32,738 INFO:     Epoch: 41
2023-01-04 11:00:34,328 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4894774834314982, 'Total loss': 0.4894774834314982} | train loss {'Reaction outcome loss': 0.3445958734257987, 'Total loss': 0.3445958734257987}
2023-01-04 11:00:34,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:34,328 INFO:     Epoch: 42
2023-01-04 11:00:35,868 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.507940802971522, 'Total loss': 0.507940802971522} | train loss {'Reaction outcome loss': 0.33854335212965736, 'Total loss': 0.33854335212965736}
2023-01-04 11:00:35,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:35,868 INFO:     Epoch: 43
2023-01-04 11:00:37,448 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.49773989121119183, 'Total loss': 0.49773989121119183} | train loss {'Reaction outcome loss': 0.3377651730115233, 'Total loss': 0.3377651730115233}
2023-01-04 11:00:37,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:37,448 INFO:     Epoch: 44
2023-01-04 11:00:39,048 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4393531938393911, 'Total loss': 0.4393531938393911} | train loss {'Reaction outcome loss': 0.3354681957822414, 'Total loss': 0.3354681957822414}
2023-01-04 11:00:39,048 INFO:     Found new best model at epoch 44
2023-01-04 11:00:39,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:39,049 INFO:     Epoch: 45
2023-01-04 11:00:40,653 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5094737271467845, 'Total loss': 0.5094737271467845} | train loss {'Reaction outcome loss': 0.33098238050292117, 'Total loss': 0.33098238050292117}
2023-01-04 11:00:40,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:40,654 INFO:     Epoch: 46
2023-01-04 11:00:42,278 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5011477311452229, 'Total loss': 0.5011477311452229} | train loss {'Reaction outcome loss': 0.3290858228929637, 'Total loss': 0.3290858228929637}
2023-01-04 11:00:42,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:42,278 INFO:     Epoch: 47
2023-01-04 11:00:43,832 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4862090408802032, 'Total loss': 0.4862090408802032} | train loss {'Reaction outcome loss': 0.3252314365727807, 'Total loss': 0.3252314365727807}
2023-01-04 11:00:43,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:43,832 INFO:     Epoch: 48
2023-01-04 11:00:45,380 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4864378829797109, 'Total loss': 0.4864378829797109} | train loss {'Reaction outcome loss': 0.322576178298315, 'Total loss': 0.322576178298315}
2023-01-04 11:00:45,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:45,380 INFO:     Epoch: 49
2023-01-04 11:00:46,966 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5076066931088765, 'Total loss': 0.5076066931088765} | train loss {'Reaction outcome loss': 0.31896446833541675, 'Total loss': 0.31896446833541675}
2023-01-04 11:00:46,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:46,966 INFO:     Epoch: 50
2023-01-04 11:00:48,537 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4542990456024806, 'Total loss': 0.4542990456024806} | train loss {'Reaction outcome loss': 0.32172748968274156, 'Total loss': 0.32172748968274156}
2023-01-04 11:00:48,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:48,537 INFO:     Epoch: 51
2023-01-04 11:00:50,127 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4725557198127111, 'Total loss': 0.4725557198127111} | train loss {'Reaction outcome loss': 0.316772974812382, 'Total loss': 0.316772974812382}
2023-01-04 11:00:50,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:50,127 INFO:     Epoch: 52
2023-01-04 11:00:51,715 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4553064694007238, 'Total loss': 0.4553064694007238} | train loss {'Reaction outcome loss': 0.31555988943533775, 'Total loss': 0.31555988943533775}
2023-01-04 11:00:51,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:51,716 INFO:     Epoch: 53
2023-01-04 11:00:53,278 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4593159933884939, 'Total loss': 0.4593159933884939} | train loss {'Reaction outcome loss': 0.31254426618560555, 'Total loss': 0.31254426618560555}
2023-01-04 11:00:53,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:53,280 INFO:     Epoch: 54
2023-01-04 11:00:54,812 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4561991721391678, 'Total loss': 0.4561991721391678} | train loss {'Reaction outcome loss': 0.31240309054025245, 'Total loss': 0.31240309054025245}
2023-01-04 11:00:54,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:54,812 INFO:     Epoch: 55
2023-01-04 11:00:56,369 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48774894972642263, 'Total loss': 0.48774894972642263} | train loss {'Reaction outcome loss': 0.3101287843518309, 'Total loss': 0.3101287843518309}
2023-01-04 11:00:56,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:56,370 INFO:     Epoch: 56
2023-01-04 11:00:57,934 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4863285372654597, 'Total loss': 0.4863285372654597} | train loss {'Reaction outcome loss': 0.3054731476930935, 'Total loss': 0.3054731476930935}
2023-01-04 11:00:57,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:57,935 INFO:     Epoch: 57
2023-01-04 11:00:59,519 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4749319553375244, 'Total loss': 0.4749319553375244} | train loss {'Reaction outcome loss': 0.3125824981540549, 'Total loss': 0.3125824981540549}
2023-01-04 11:00:59,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:00:59,520 INFO:     Epoch: 58
2023-01-04 11:01:01,110 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4478411187728246, 'Total loss': 0.4478411187728246} | train loss {'Reaction outcome loss': 0.3085821242969389, 'Total loss': 0.3085821242969389}
2023-01-04 11:01:01,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:01,110 INFO:     Epoch: 59
2023-01-04 11:01:02,674 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47685877084732053, 'Total loss': 0.47685877084732053} | train loss {'Reaction outcome loss': 0.30270866084077297, 'Total loss': 0.30270866084077297}
2023-01-04 11:01:02,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:02,674 INFO:     Epoch: 60
2023-01-04 11:01:04,230 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4757242679595947, 'Total loss': 0.4757242679595947} | train loss {'Reaction outcome loss': 0.29841127367656584, 'Total loss': 0.29841127367656584}
2023-01-04 11:01:04,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:04,230 INFO:     Epoch: 61
2023-01-04 11:01:05,793 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45814088781674706, 'Total loss': 0.45814088781674706} | train loss {'Reaction outcome loss': 0.30143321889187025, 'Total loss': 0.30143321889187025}
2023-01-04 11:01:05,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:05,794 INFO:     Epoch: 62
2023-01-04 11:01:07,376 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47627296646436057, 'Total loss': 0.47627296646436057} | train loss {'Reaction outcome loss': 0.2967980374928416, 'Total loss': 0.2967980374928416}
2023-01-04 11:01:07,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:07,376 INFO:     Epoch: 63
2023-01-04 11:01:08,965 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45781151254971825, 'Total loss': 0.45781151254971825} | train loss {'Reaction outcome loss': 0.2980724509119557, 'Total loss': 0.2980724509119557}
2023-01-04 11:01:08,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:08,965 INFO:     Epoch: 64
2023-01-04 11:01:10,553 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48381181955337527, 'Total loss': 0.48381181955337527} | train loss {'Reaction outcome loss': 0.2934575893711097, 'Total loss': 0.2934575893711097}
2023-01-04 11:01:10,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:10,553 INFO:     Epoch: 65
2023-01-04 11:01:12,097 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5011942823727925, 'Total loss': 0.5011942823727925} | train loss {'Reaction outcome loss': 0.2907496496012925, 'Total loss': 0.2907496496012925}
2023-01-04 11:01:12,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:12,098 INFO:     Epoch: 66
2023-01-04 11:01:13,640 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4794028634826342, 'Total loss': 0.4794028634826342} | train loss {'Reaction outcome loss': 0.2898565439056834, 'Total loss': 0.2898565439056834}
2023-01-04 11:01:13,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:13,641 INFO:     Epoch: 67
2023-01-04 11:01:15,244 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4502253085374832, 'Total loss': 0.4502253085374832} | train loss {'Reaction outcome loss': 0.2862632666522845, 'Total loss': 0.2862632666522845}
2023-01-04 11:01:15,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:15,244 INFO:     Epoch: 68
2023-01-04 11:01:16,827 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4711165984471639, 'Total loss': 0.4711165984471639} | train loss {'Reaction outcome loss': 0.29136267083861767, 'Total loss': 0.29136267083861767}
2023-01-04 11:01:16,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:16,828 INFO:     Epoch: 69
2023-01-04 11:01:18,418 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5250136852264404, 'Total loss': 0.5250136852264404} | train loss {'Reaction outcome loss': 0.2898909640548892, 'Total loss': 0.2898909640548892}
2023-01-04 11:01:18,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:18,418 INFO:     Epoch: 70
2023-01-04 11:01:20,000 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45780058602492013, 'Total loss': 0.45780058602492013} | train loss {'Reaction outcome loss': 0.28151128722173213, 'Total loss': 0.28151128722173213}
2023-01-04 11:01:20,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:20,000 INFO:     Epoch: 71
2023-01-04 11:01:21,513 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43931228419144946, 'Total loss': 0.43931228419144946} | train loss {'Reaction outcome loss': 0.282959603203548, 'Total loss': 0.282959603203548}
2023-01-04 11:01:21,513 INFO:     Found new best model at epoch 71
2023-01-04 11:01:21,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:21,514 INFO:     Epoch: 72
2023-01-04 11:01:23,107 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45367990334828695, 'Total loss': 0.45367990334828695} | train loss {'Reaction outcome loss': 0.2832415387948928, 'Total loss': 0.2832415387948928}
2023-01-04 11:01:23,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:23,107 INFO:     Epoch: 73
2023-01-04 11:01:24,696 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46351775924364724, 'Total loss': 0.46351775924364724} | train loss {'Reaction outcome loss': 0.27687722320806246, 'Total loss': 0.27687722320806246}
2023-01-04 11:01:24,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:24,696 INFO:     Epoch: 74
2023-01-04 11:01:26,285 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4548924684524536, 'Total loss': 0.4548924684524536} | train loss {'Reaction outcome loss': 0.2779515726955789, 'Total loss': 0.2779515726955789}
2023-01-04 11:01:26,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:26,285 INFO:     Epoch: 75
2023-01-04 11:01:27,882 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4211455265680949, 'Total loss': 0.4211455265680949} | train loss {'Reaction outcome loss': 0.27902036448032846, 'Total loss': 0.27902036448032846}
2023-01-04 11:01:27,884 INFO:     Found new best model at epoch 75
2023-01-04 11:01:27,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:27,884 INFO:     Epoch: 76
2023-01-04 11:01:29,457 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44432040452957156, 'Total loss': 0.44432040452957156} | train loss {'Reaction outcome loss': 0.2804501835888904, 'Total loss': 0.2804501835888904}
2023-01-04 11:01:29,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:29,457 INFO:     Epoch: 77
2023-01-04 11:01:31,025 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4811870550115903, 'Total loss': 0.4811870550115903} | train loss {'Reaction outcome loss': 0.27501010025989275, 'Total loss': 0.27501010025989275}
2023-01-04 11:01:31,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:31,026 INFO:     Epoch: 78
2023-01-04 11:01:32,632 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4509409675995509, 'Total loss': 0.4509409675995509} | train loss {'Reaction outcome loss': 0.27428598938651033, 'Total loss': 0.27428598938651033}
2023-01-04 11:01:32,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:32,632 INFO:     Epoch: 79
2023-01-04 11:01:34,233 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45209650297959647, 'Total loss': 0.45209650297959647} | train loss {'Reaction outcome loss': 0.27355372217157686, 'Total loss': 0.27355372217157686}
2023-01-04 11:01:34,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:34,234 INFO:     Epoch: 80
2023-01-04 11:01:35,805 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4517085095246633, 'Total loss': 0.4517085095246633} | train loss {'Reaction outcome loss': 0.2716266106182057, 'Total loss': 0.2716266106182057}
2023-01-04 11:01:35,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:35,806 INFO:     Epoch: 81
2023-01-04 11:01:37,389 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4500723401705424, 'Total loss': 0.4500723401705424} | train loss {'Reaction outcome loss': 0.27169191388124164, 'Total loss': 0.27169191388124164}
2023-01-04 11:01:37,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:37,389 INFO:     Epoch: 82
2023-01-04 11:01:38,933 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4900726636250814, 'Total loss': 0.4900726636250814} | train loss {'Reaction outcome loss': 0.2681029438165551, 'Total loss': 0.2681029438165551}
2023-01-04 11:01:38,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:38,933 INFO:     Epoch: 83
2023-01-04 11:01:40,494 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46041000286738076, 'Total loss': 0.46041000286738076} | train loss {'Reaction outcome loss': 0.26899781031702186, 'Total loss': 0.26899781031702186}
2023-01-04 11:01:40,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:40,494 INFO:     Epoch: 84
2023-01-04 11:01:42,103 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45631513992945355, 'Total loss': 0.45631513992945355} | train loss {'Reaction outcome loss': 0.274471659011574, 'Total loss': 0.274471659011574}
2023-01-04 11:01:42,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:42,103 INFO:     Epoch: 85
2023-01-04 11:01:43,700 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4598306119441986, 'Total loss': 0.4598306119441986} | train loss {'Reaction outcome loss': 0.2682380141549162, 'Total loss': 0.2682380141549162}
2023-01-04 11:01:43,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:43,701 INFO:     Epoch: 86
2023-01-04 11:01:45,312 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45069604913393657, 'Total loss': 0.45069604913393657} | train loss {'Reaction outcome loss': 0.26354478779736407, 'Total loss': 0.26354478779736407}
2023-01-04 11:01:45,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:45,313 INFO:     Epoch: 87
2023-01-04 11:01:46,901 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46189146439234413, 'Total loss': 0.46189146439234413} | train loss {'Reaction outcome loss': 0.2626671379008448, 'Total loss': 0.2626671379008448}
2023-01-04 11:01:46,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:46,902 INFO:     Epoch: 88
2023-01-04 11:01:48,452 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4653436799844106, 'Total loss': 0.4653436799844106} | train loss {'Reaction outcome loss': 0.2626948008576025, 'Total loss': 0.2626948008576025}
2023-01-04 11:01:48,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:48,452 INFO:     Epoch: 89
2023-01-04 11:01:50,025 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45359180370966595, 'Total loss': 0.45359180370966595} | train loss {'Reaction outcome loss': 0.2637684360307907, 'Total loss': 0.2637684360307907}
2023-01-04 11:01:50,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:50,025 INFO:     Epoch: 90
2023-01-04 11:01:51,635 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4452595293521881, 'Total loss': 0.4452595293521881} | train loss {'Reaction outcome loss': 0.26101188340126824, 'Total loss': 0.26101188340126824}
2023-01-04 11:01:51,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:51,635 INFO:     Epoch: 91
2023-01-04 11:01:53,249 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49513018925984703, 'Total loss': 0.49513018925984703} | train loss {'Reaction outcome loss': 0.26518305216240107, 'Total loss': 0.26518305216240107}
2023-01-04 11:01:53,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:53,250 INFO:     Epoch: 92
2023-01-04 11:01:54,849 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.450630392630895, 'Total loss': 0.450630392630895} | train loss {'Reaction outcome loss': 0.26233361959995344, 'Total loss': 0.26233361959995344}
2023-01-04 11:01:54,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:54,849 INFO:     Epoch: 93
2023-01-04 11:01:56,410 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4488093018531799, 'Total loss': 0.4488093018531799} | train loss {'Reaction outcome loss': 0.2608145940981617, 'Total loss': 0.2608145940981617}
2023-01-04 11:01:56,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:56,411 INFO:     Epoch: 94
2023-01-04 11:01:57,959 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43921889464060465, 'Total loss': 0.43921889464060465} | train loss {'Reaction outcome loss': 0.2576676611973491, 'Total loss': 0.2576676611973491}
2023-01-04 11:01:57,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:57,959 INFO:     Epoch: 95
2023-01-04 11:01:59,545 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.429861722389857, 'Total loss': 0.429861722389857} | train loss {'Reaction outcome loss': 0.262360822248007, 'Total loss': 0.262360822248007}
2023-01-04 11:01:59,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:01:59,546 INFO:     Epoch: 96
2023-01-04 11:02:01,109 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4791760931412379, 'Total loss': 0.4791760931412379} | train loss {'Reaction outcome loss': 0.2566767845854217, 'Total loss': 0.2566767845854217}
2023-01-04 11:02:01,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:01,109 INFO:     Epoch: 97
2023-01-04 11:02:02,667 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4523103098074595, 'Total loss': 0.4523103098074595} | train loss {'Reaction outcome loss': 0.2540690765215171, 'Total loss': 0.2540690765215171}
2023-01-04 11:02:02,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:02,668 INFO:     Epoch: 98
2023-01-04 11:02:04,224 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5047106107076009, 'Total loss': 0.5047106107076009} | train loss {'Reaction outcome loss': 0.25015354475228363, 'Total loss': 0.25015354475228363}
2023-01-04 11:02:04,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:04,224 INFO:     Epoch: 99
2023-01-04 11:02:05,751 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45142075419425964, 'Total loss': 0.45142075419425964} | train loss {'Reaction outcome loss': 0.25174694426277056, 'Total loss': 0.25174694426277056}
2023-01-04 11:02:05,752 INFO:     Best model found after epoch 76 of 100.
2023-01-04 11:02:05,752 INFO:   Done with stage: TRAINING
2023-01-04 11:02:05,752 INFO:   Starting stage: EVALUATION
2023-01-04 11:02:05,873 INFO:   Done with stage: EVALUATION
2023-01-04 11:02:05,873 INFO:   Leaving out SEQ value Fold_5
2023-01-04 11:02:05,886 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 11:02:05,886 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:02:06,531 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:02:06,531 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:02:06,600 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:02:06,600 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:02:06,600 INFO:     No hyperparam tuning for this model
2023-01-04 11:02:06,600 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:02:06,600 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:02:06,601 INFO:     None feature selector for col prot
2023-01-04 11:02:06,601 INFO:     None feature selector for col prot
2023-01-04 11:02:06,601 INFO:     None feature selector for col prot
2023-01-04 11:02:06,601 INFO:     None feature selector for col chem
2023-01-04 11:02:06,601 INFO:     None feature selector for col chem
2023-01-04 11:02:06,602 INFO:     None feature selector for col chem
2023-01-04 11:02:06,602 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:02:06,602 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:02:06,603 INFO:     Number of params in model 70111
2023-01-04 11:02:06,606 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:02:06,606 INFO:   Starting stage: TRAINING
2023-01-04 11:02:06,650 INFO:     Val loss before train {'Reaction outcome loss': 0.9514154354731242, 'Total loss': 0.9514154354731242}
2023-01-04 11:02:06,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:06,650 INFO:     Epoch: 0
2023-01-04 11:02:08,210 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6722879787286122, 'Total loss': 0.6722879787286122} | train loss {'Reaction outcome loss': 0.8426214571679111, 'Total loss': 0.8426214571679111}
2023-01-04 11:02:08,210 INFO:     Found new best model at epoch 0
2023-01-04 11:02:08,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:08,211 INFO:     Epoch: 1
2023-01-04 11:02:09,763 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5731699585914611, 'Total loss': 0.5731699585914611} | train loss {'Reaction outcome loss': 0.6768003014666079, 'Total loss': 0.6768003014666079}
2023-01-04 11:02:09,763 INFO:     Found new best model at epoch 1
2023-01-04 11:02:09,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:09,763 INFO:     Epoch: 2
2023-01-04 11:02:11,312 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5230298797289531, 'Total loss': 0.5230298797289531} | train loss {'Reaction outcome loss': 0.5852714186863779, 'Total loss': 0.5852714186863779}
2023-01-04 11:02:11,312 INFO:     Found new best model at epoch 2
2023-01-04 11:02:11,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:11,313 INFO:     Epoch: 3
2023-01-04 11:02:12,856 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4976876745621363, 'Total loss': 0.4976876745621363} | train loss {'Reaction outcome loss': 0.5384450733446472, 'Total loss': 0.5384450733446472}
2023-01-04 11:02:12,856 INFO:     Found new best model at epoch 3
2023-01-04 11:02:12,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:12,857 INFO:     Epoch: 4
2023-01-04 11:02:14,376 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4975074758132299, 'Total loss': 0.4975074758132299} | train loss {'Reaction outcome loss': 0.5188483426394446, 'Total loss': 0.5188483426394446}
2023-01-04 11:02:14,376 INFO:     Found new best model at epoch 4
2023-01-04 11:02:14,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:14,377 INFO:     Epoch: 5
2023-01-04 11:02:15,900 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48440043330192567, 'Total loss': 0.48440043330192567} | train loss {'Reaction outcome loss': 0.5028453796886795, 'Total loss': 0.5028453796886795}
2023-01-04 11:02:15,900 INFO:     Found new best model at epoch 5
2023-01-04 11:02:15,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:15,901 INFO:     Epoch: 6
2023-01-04 11:02:17,472 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4801581015189489, 'Total loss': 0.4801581015189489} | train loss {'Reaction outcome loss': 0.49151525390922807, 'Total loss': 0.49151525390922807}
2023-01-04 11:02:17,472 INFO:     Found new best model at epoch 6
2023-01-04 11:02:17,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:17,473 INFO:     Epoch: 7
2023-01-04 11:02:19,014 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4891245782375336, 'Total loss': 0.4891245782375336} | train loss {'Reaction outcome loss': 0.47760485397779556, 'Total loss': 0.47760485397779556}
2023-01-04 11:02:19,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:19,015 INFO:     Epoch: 8
2023-01-04 11:02:20,560 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4705702841281891, 'Total loss': 0.4705702841281891} | train loss {'Reaction outcome loss': 0.4764330578087039, 'Total loss': 0.4764330578087039}
2023-01-04 11:02:20,560 INFO:     Found new best model at epoch 8
2023-01-04 11:02:20,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:20,561 INFO:     Epoch: 9
2023-01-04 11:02:22,112 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4871183693408966, 'Total loss': 0.4871183693408966} | train loss {'Reaction outcome loss': 0.46763203349569643, 'Total loss': 0.46763203349569643}
2023-01-04 11:02:22,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:22,113 INFO:     Epoch: 10
2023-01-04 11:02:23,627 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4588058481613795, 'Total loss': 0.4588058481613795} | train loss {'Reaction outcome loss': 0.4574185941731456, 'Total loss': 0.4574185941731456}
2023-01-04 11:02:23,628 INFO:     Found new best model at epoch 10
2023-01-04 11:02:23,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:23,628 INFO:     Epoch: 11
2023-01-04 11:02:25,144 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46293805340925853, 'Total loss': 0.46293805340925853} | train loss {'Reaction outcome loss': 0.4548359414300333, 'Total loss': 0.4548359414300333}
2023-01-04 11:02:25,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:25,144 INFO:     Epoch: 12
2023-01-04 11:02:26,697 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4803598016500473, 'Total loss': 0.4803598016500473} | train loss {'Reaction outcome loss': 0.4468911924409522, 'Total loss': 0.4468911924409522}
2023-01-04 11:02:26,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:26,697 INFO:     Epoch: 13
2023-01-04 11:02:28,256 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4466190020243327, 'Total loss': 0.4466190020243327} | train loss {'Reaction outcome loss': 0.4461044414432901, 'Total loss': 0.4461044414432901}
2023-01-04 11:02:28,256 INFO:     Found new best model at epoch 13
2023-01-04 11:02:28,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:28,257 INFO:     Epoch: 14
2023-01-04 11:02:29,809 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4458287616570791, 'Total loss': 0.4458287616570791} | train loss {'Reaction outcome loss': 0.43830930320579653, 'Total loss': 0.43830930320579653}
2023-01-04 11:02:29,809 INFO:     Found new best model at epoch 14
2023-01-04 11:02:29,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:29,810 INFO:     Epoch: 15
2023-01-04 11:02:31,359 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4278813287615776, 'Total loss': 0.4278813287615776} | train loss {'Reaction outcome loss': 0.4345437222654639, 'Total loss': 0.4345437222654639}
2023-01-04 11:02:31,359 INFO:     Found new best model at epoch 15
2023-01-04 11:02:31,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:31,360 INFO:     Epoch: 16
2023-01-04 11:02:32,880 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43965765635172527, 'Total loss': 0.43965765635172527} | train loss {'Reaction outcome loss': 0.4278930361090154, 'Total loss': 0.4278930361090154}
2023-01-04 11:02:32,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:32,880 INFO:     Epoch: 17
2023-01-04 11:02:34,399 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4624230404694875, 'Total loss': 0.4624230404694875} | train loss {'Reaction outcome loss': 0.42767447881427484, 'Total loss': 0.42767447881427484}
2023-01-04 11:02:34,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:34,401 INFO:     Epoch: 18
2023-01-04 11:02:35,987 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43953900535901386, 'Total loss': 0.43953900535901386} | train loss {'Reaction outcome loss': 0.4215132121252239, 'Total loss': 0.4215132121252239}
2023-01-04 11:02:35,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:35,987 INFO:     Epoch: 19
2023-01-04 11:02:37,554 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.459793813029925, 'Total loss': 0.459793813029925} | train loss {'Reaction outcome loss': 0.41765833637989813, 'Total loss': 0.41765833637989813}
2023-01-04 11:02:37,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:37,555 INFO:     Epoch: 20
2023-01-04 11:02:39,139 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4630688349405924, 'Total loss': 0.4630688349405924} | train loss {'Reaction outcome loss': 0.41356659774745846, 'Total loss': 0.41356659774745846}
2023-01-04 11:02:39,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:39,140 INFO:     Epoch: 21
2023-01-04 11:02:40,717 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45457645654678347, 'Total loss': 0.45457645654678347} | train loss {'Reaction outcome loss': 0.4095464969585088, 'Total loss': 0.4095464969585088}
2023-01-04 11:02:40,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:40,718 INFO:     Epoch: 22
2023-01-04 11:02:42,233 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44811879793802895, 'Total loss': 0.44811879793802895} | train loss {'Reaction outcome loss': 0.4057060859909126, 'Total loss': 0.4057060859909126}
2023-01-04 11:02:42,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:42,233 INFO:     Epoch: 23
2023-01-04 11:02:43,761 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4521992355585098, 'Total loss': 0.4521992355585098} | train loss {'Reaction outcome loss': 0.4009076834854666, 'Total loss': 0.4009076834854666}
2023-01-04 11:02:43,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:43,761 INFO:     Epoch: 24
2023-01-04 11:02:45,332 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4065627634525299, 'Total loss': 0.4065627634525299} | train loss {'Reaction outcome loss': 0.39690818844719483, 'Total loss': 0.39690818844719483}
2023-01-04 11:02:45,332 INFO:     Found new best model at epoch 24
2023-01-04 11:02:45,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:45,333 INFO:     Epoch: 25
2023-01-04 11:02:46,883 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4371797184149424, 'Total loss': 0.4371797184149424} | train loss {'Reaction outcome loss': 0.39611917533760466, 'Total loss': 0.39611917533760466}
2023-01-04 11:02:46,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:46,883 INFO:     Epoch: 26
2023-01-04 11:02:48,437 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42599973976612093, 'Total loss': 0.42599973976612093} | train loss {'Reaction outcome loss': 0.39236416027541626, 'Total loss': 0.39236416027541626}
2023-01-04 11:02:48,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:48,438 INFO:     Epoch: 27
2023-01-04 11:02:50,012 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40751693248748777, 'Total loss': 0.40751693248748777} | train loss {'Reaction outcome loss': 0.38972186824367366, 'Total loss': 0.38972186824367366}
2023-01-04 11:02:50,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:50,012 INFO:     Epoch: 28
2023-01-04 11:02:51,535 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42587737143039706, 'Total loss': 0.42587737143039706} | train loss {'Reaction outcome loss': 0.38419413087815585, 'Total loss': 0.38419413087815585}
2023-01-04 11:02:51,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:51,535 INFO:     Epoch: 29
2023-01-04 11:02:53,072 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4039038171370824, 'Total loss': 0.4039038171370824} | train loss {'Reaction outcome loss': 0.3797082245242294, 'Total loss': 0.3797082245242294}
2023-01-04 11:02:53,072 INFO:     Found new best model at epoch 29
2023-01-04 11:02:53,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:53,073 INFO:     Epoch: 30
2023-01-04 11:02:54,632 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42229865392049154, 'Total loss': 0.42229865392049154} | train loss {'Reaction outcome loss': 0.37666428444187566, 'Total loss': 0.37666428444187566}
2023-01-04 11:02:54,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:54,633 INFO:     Epoch: 31
2023-01-04 11:02:56,197 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47513627310593926, 'Total loss': 0.47513627310593926} | train loss {'Reaction outcome loss': 0.3744346938946617, 'Total loss': 0.3744346938946617}
2023-01-04 11:02:56,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:56,197 INFO:     Epoch: 32
2023-01-04 11:02:57,775 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44125181436538696, 'Total loss': 0.44125181436538696} | train loss {'Reaction outcome loss': 0.3711362066359296, 'Total loss': 0.3711362066359296}
2023-01-04 11:02:57,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:57,776 INFO:     Epoch: 33
2023-01-04 11:02:59,358 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41650782922903695, 'Total loss': 0.41650782922903695} | train loss {'Reaction outcome loss': 0.3667198023103204, 'Total loss': 0.3667198023103204}
2023-01-04 11:02:59,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:02:59,358 INFO:     Epoch: 34
2023-01-04 11:03:00,876 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.436175803343455, 'Total loss': 0.436175803343455} | train loss {'Reaction outcome loss': 0.36431403810474416, 'Total loss': 0.36431403810474416}
2023-01-04 11:03:00,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:00,877 INFO:     Epoch: 35
2023-01-04 11:03:02,437 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39086115956306455, 'Total loss': 0.39086115956306455} | train loss {'Reaction outcome loss': 0.35516707244117335, 'Total loss': 0.35516707244117335}
2023-01-04 11:03:02,437 INFO:     Found new best model at epoch 35
2023-01-04 11:03:02,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:02,438 INFO:     Epoch: 36
2023-01-04 11:03:04,006 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41781481305758156, 'Total loss': 0.41781481305758156} | train loss {'Reaction outcome loss': 0.3601630231910234, 'Total loss': 0.3601630231910234}
2023-01-04 11:03:04,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:04,007 INFO:     Epoch: 37
2023-01-04 11:03:05,591 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4123927156130473, 'Total loss': 0.4123927156130473} | train loss {'Reaction outcome loss': 0.3538369645872271, 'Total loss': 0.3538369645872271}
2023-01-04 11:03:05,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:05,593 INFO:     Epoch: 38
2023-01-04 11:03:07,150 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38004336655139925, 'Total loss': 0.38004336655139925} | train loss {'Reaction outcome loss': 0.34972725259913434, 'Total loss': 0.34972725259913434}
2023-01-04 11:03:07,150 INFO:     Found new best model at epoch 38
2023-01-04 11:03:07,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:07,151 INFO:     Epoch: 39
2023-01-04 11:03:08,700 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39332974354426065, 'Total loss': 0.39332974354426065} | train loss {'Reaction outcome loss': 0.3515197714044299, 'Total loss': 0.3515197714044299}
2023-01-04 11:03:08,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:08,701 INFO:     Epoch: 40
2023-01-04 11:03:10,208 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4031886508067449, 'Total loss': 0.4031886508067449} | train loss {'Reaction outcome loss': 0.34529684930501864, 'Total loss': 0.34529684930501864}
2023-01-04 11:03:10,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:10,209 INFO:     Epoch: 41
2023-01-04 11:03:11,764 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41875744263331094, 'Total loss': 0.41875744263331094} | train loss {'Reaction outcome loss': 0.3406610166122767, 'Total loss': 0.3406610166122767}
2023-01-04 11:03:11,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:11,765 INFO:     Epoch: 42
2023-01-04 11:03:13,337 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4071532269318899, 'Total loss': 0.4071532269318899} | train loss {'Reaction outcome loss': 0.33623136372880386, 'Total loss': 0.33623136372880386}
2023-01-04 11:03:13,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:13,337 INFO:     Epoch: 43
2023-01-04 11:03:14,906 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4104089428981145, 'Total loss': 0.4104089428981145} | train loss {'Reaction outcome loss': 0.3378022763918453, 'Total loss': 0.3378022763918453}
2023-01-04 11:03:14,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:14,906 INFO:     Epoch: 44
2023-01-04 11:03:16,472 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4084239313999812, 'Total loss': 0.4084239313999812} | train loss {'Reaction outcome loss': 0.3352282568543396, 'Total loss': 0.3352282568543396}
2023-01-04 11:03:16,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:16,473 INFO:     Epoch: 45
2023-01-04 11:03:18,015 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3943416078885396, 'Total loss': 0.3943416078885396} | train loss {'Reaction outcome loss': 0.33292263439631203, 'Total loss': 0.33292263439631203}
2023-01-04 11:03:18,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:18,015 INFO:     Epoch: 46
2023-01-04 11:03:19,542 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3796935021877289, 'Total loss': 0.3796935021877289} | train loss {'Reaction outcome loss': 0.33250355397751186, 'Total loss': 0.33250355397751186}
2023-01-04 11:03:19,542 INFO:     Found new best model at epoch 46
2023-01-04 11:03:19,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:19,543 INFO:     Epoch: 47
2023-01-04 11:03:21,091 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42047801812489827, 'Total loss': 0.42047801812489827} | train loss {'Reaction outcome loss': 0.33117542324406146, 'Total loss': 0.33117542324406146}
2023-01-04 11:03:21,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:21,091 INFO:     Epoch: 48
2023-01-04 11:03:22,655 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39442067543665565, 'Total loss': 0.39442067543665565} | train loss {'Reaction outcome loss': 0.3258992835126199, 'Total loss': 0.3258992835126199}
2023-01-04 11:03:22,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:22,656 INFO:     Epoch: 49
2023-01-04 11:03:24,224 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3878333124021689, 'Total loss': 0.3878333124021689} | train loss {'Reaction outcome loss': 0.3246152569079227, 'Total loss': 0.3246152569079227}
2023-01-04 11:03:24,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:24,225 INFO:     Epoch: 50
2023-01-04 11:03:25,774 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40865703821182253, 'Total loss': 0.40865703821182253} | train loss {'Reaction outcome loss': 0.32599283316397926, 'Total loss': 0.32599283316397926}
2023-01-04 11:03:25,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:25,774 INFO:     Epoch: 51
2023-01-04 11:03:27,280 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4051229019959768, 'Total loss': 0.4051229019959768} | train loss {'Reaction outcome loss': 0.31930028207411837, 'Total loss': 0.31930028207411837}
2023-01-04 11:03:27,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:27,280 INFO:     Epoch: 52
2023-01-04 11:03:28,791 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38247599005699157, 'Total loss': 0.38247599005699157} | train loss {'Reaction outcome loss': 0.315915122628212, 'Total loss': 0.315915122628212}
2023-01-04 11:03:28,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:28,792 INFO:     Epoch: 53
2023-01-04 11:03:30,339 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38633725643157957, 'Total loss': 0.38633725643157957} | train loss {'Reaction outcome loss': 0.31134976110411033, 'Total loss': 0.31134976110411033}
2023-01-04 11:03:30,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:30,340 INFO:     Epoch: 54
2023-01-04 11:03:31,887 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38535297016302744, 'Total loss': 0.38535297016302744} | train loss {'Reaction outcome loss': 0.3112391856388064, 'Total loss': 0.3112391856388064}
2023-01-04 11:03:31,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:31,887 INFO:     Epoch: 55
2023-01-04 11:03:33,439 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4002588431040446, 'Total loss': 0.4002588431040446} | train loss {'Reaction outcome loss': 0.3118737417168996, 'Total loss': 0.3118737417168996}
2023-01-04 11:03:33,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:33,439 INFO:     Epoch: 56
2023-01-04 11:03:34,990 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40971891283988954, 'Total loss': 0.40971891283988954} | train loss {'Reaction outcome loss': 0.3083567912774396, 'Total loss': 0.3083567912774396}
2023-01-04 11:03:34,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:34,990 INFO:     Epoch: 57
2023-01-04 11:03:36,504 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39558901091416676, 'Total loss': 0.39558901091416676} | train loss {'Reaction outcome loss': 0.3045368726879681, 'Total loss': 0.3045368726879681}
2023-01-04 11:03:36,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:36,505 INFO:     Epoch: 58
2023-01-04 11:03:38,024 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4310498207807541, 'Total loss': 0.4310498207807541} | train loss {'Reaction outcome loss': 0.305227928805007, 'Total loss': 0.305227928805007}
2023-01-04 11:03:38,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:38,025 INFO:     Epoch: 59
2023-01-04 11:03:39,598 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3699083685874939, 'Total loss': 0.3699083685874939} | train loss {'Reaction outcome loss': 0.30440866301636405, 'Total loss': 0.30440866301636405}
2023-01-04 11:03:39,598 INFO:     Found new best model at epoch 59
2023-01-04 11:03:39,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:39,599 INFO:     Epoch: 60
2023-01-04 11:03:41,166 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3851958304643631, 'Total loss': 0.3851958304643631} | train loss {'Reaction outcome loss': 0.2983613666752185, 'Total loss': 0.2983613666752185}
2023-01-04 11:03:41,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:41,166 INFO:     Epoch: 61
2023-01-04 11:03:42,734 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3897662967443466, 'Total loss': 0.3897662967443466} | train loss {'Reaction outcome loss': 0.3014162911458566, 'Total loss': 0.3014162911458566}
2023-01-04 11:03:42,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:42,735 INFO:     Epoch: 62
2023-01-04 11:03:44,302 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40364495615164436, 'Total loss': 0.40364495615164436} | train loss {'Reaction outcome loss': 0.2985026088647464, 'Total loss': 0.2985026088647464}
2023-01-04 11:03:44,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:44,302 INFO:     Epoch: 63
2023-01-04 11:03:45,826 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3808628886938095, 'Total loss': 0.3808628886938095} | train loss {'Reaction outcome loss': 0.29715470819051515, 'Total loss': 0.29715470819051515}
2023-01-04 11:03:45,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:45,826 INFO:     Epoch: 64
2023-01-04 11:03:47,350 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41209160586198174, 'Total loss': 0.41209160586198174} | train loss {'Reaction outcome loss': 0.29634389345826656, 'Total loss': 0.29634389345826656}
2023-01-04 11:03:47,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:47,351 INFO:     Epoch: 65
2023-01-04 11:03:48,905 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3958367536465327, 'Total loss': 0.3958367536465327} | train loss {'Reaction outcome loss': 0.2926080660215354, 'Total loss': 0.2926080660215354}
2023-01-04 11:03:48,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:48,905 INFO:     Epoch: 66
2023-01-04 11:03:50,464 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39499400158723197, 'Total loss': 0.39499400158723197} | train loss {'Reaction outcome loss': 0.288849638122729, 'Total loss': 0.288849638122729}
2023-01-04 11:03:50,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:50,465 INFO:     Epoch: 67
2023-01-04 11:03:52,024 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3965101530154546, 'Total loss': 0.3965101530154546} | train loss {'Reaction outcome loss': 0.2936089759968248, 'Total loss': 0.2936089759968248}
2023-01-04 11:03:52,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:52,025 INFO:     Epoch: 68
2023-01-04 11:03:53,600 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38689775864283243, 'Total loss': 0.38689775864283243} | train loss {'Reaction outcome loss': 0.29175706250788075, 'Total loss': 0.29175706250788075}
2023-01-04 11:03:53,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:53,600 INFO:     Epoch: 69
2023-01-04 11:03:55,136 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.374602880080541, 'Total loss': 0.374602880080541} | train loss {'Reaction outcome loss': 0.2880904277793337, 'Total loss': 0.2880904277793337}
2023-01-04 11:03:55,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:55,137 INFO:     Epoch: 70
2023-01-04 11:03:56,656 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38113103111584984, 'Total loss': 0.38113103111584984} | train loss {'Reaction outcome loss': 0.2844532665524242, 'Total loss': 0.2844532665524242}
2023-01-04 11:03:56,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:56,656 INFO:     Epoch: 71
2023-01-04 11:03:58,206 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40073410272598264, 'Total loss': 0.40073410272598264} | train loss {'Reaction outcome loss': 0.2843567354315455, 'Total loss': 0.2843567354315455}
2023-01-04 11:03:58,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:58,206 INFO:     Epoch: 72
2023-01-04 11:03:59,756 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37045815885066985, 'Total loss': 0.37045815885066985} | train loss {'Reaction outcome loss': 0.28474471270231133, 'Total loss': 0.28474471270231133}
2023-01-04 11:03:59,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:03:59,756 INFO:     Epoch: 73
2023-01-04 11:04:01,327 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.35828842520713805, 'Total loss': 0.35828842520713805} | train loss {'Reaction outcome loss': 0.2816666806190668, 'Total loss': 0.2816666806190668}
2023-01-04 11:04:01,327 INFO:     Found new best model at epoch 73
2023-01-04 11:04:01,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:01,328 INFO:     Epoch: 74
2023-01-04 11:04:02,869 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3800665805737177, 'Total loss': 0.3800665805737177} | train loss {'Reaction outcome loss': 0.2820588055500485, 'Total loss': 0.2820588055500485}
2023-01-04 11:04:02,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:02,869 INFO:     Epoch: 75
2023-01-04 11:04:04,385 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4342675119638443, 'Total loss': 0.4342675119638443} | train loss {'Reaction outcome loss': 0.2779433975796407, 'Total loss': 0.2779433975796407}
2023-01-04 11:04:04,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:04,385 INFO:     Epoch: 76
2023-01-04 11:04:05,959 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4215044577916463, 'Total loss': 0.4215044577916463} | train loss {'Reaction outcome loss': 0.2825281838432546, 'Total loss': 0.2825281838432546}
2023-01-04 11:04:05,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:05,959 INFO:     Epoch: 77
2023-01-04 11:04:07,526 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42483140031496686, 'Total loss': 0.42483140031496686} | train loss {'Reaction outcome loss': 0.2790625145934549, 'Total loss': 0.2790625145934549}
2023-01-04 11:04:07,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:07,527 INFO:     Epoch: 78
2023-01-04 11:04:09,089 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4047763635714849, 'Total loss': 0.4047763635714849} | train loss {'Reaction outcome loss': 0.27533915612026244, 'Total loss': 0.27533915612026244}
2023-01-04 11:04:09,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:09,089 INFO:     Epoch: 79
2023-01-04 11:04:10,650 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39353953997294105, 'Total loss': 0.39353953997294105} | train loss {'Reaction outcome loss': 0.2729426219198678, 'Total loss': 0.2729426219198678}
2023-01-04 11:04:10,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:10,650 INFO:     Epoch: 80
2023-01-04 11:04:12,193 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4115244150161743, 'Total loss': 0.4115244150161743} | train loss {'Reaction outcome loss': 0.2776188432686165, 'Total loss': 0.2776188432686165}
2023-01-04 11:04:12,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:12,195 INFO:     Epoch: 81
2023-01-04 11:04:13,704 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3587634195884069, 'Total loss': 0.3587634195884069} | train loss {'Reaction outcome loss': 0.2772952221898826, 'Total loss': 0.2772952221898826}
2023-01-04 11:04:13,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:13,705 INFO:     Epoch: 82
2023-01-04 11:04:15,253 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3914713501930237, 'Total loss': 0.3914713501930237} | train loss {'Reaction outcome loss': 0.27107271553430745, 'Total loss': 0.27107271553430745}
2023-01-04 11:04:15,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:15,253 INFO:     Epoch: 83
2023-01-04 11:04:16,799 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.36391396125157677, 'Total loss': 0.36391396125157677} | train loss {'Reaction outcome loss': 0.2686506289491154, 'Total loss': 0.2686506289491154}
2023-01-04 11:04:16,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:16,799 INFO:     Epoch: 84
2023-01-04 11:04:18,344 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3804571613669395, 'Total loss': 0.3804571613669395} | train loss {'Reaction outcome loss': 0.2672896929461818, 'Total loss': 0.2672896929461818}
2023-01-04 11:04:18,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:18,345 INFO:     Epoch: 85
2023-01-04 11:04:19,899 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37798411746819816, 'Total loss': 0.37798411746819816} | train loss {'Reaction outcome loss': 0.2646435590776941, 'Total loss': 0.2646435590776941}
2023-01-04 11:04:19,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:19,899 INFO:     Epoch: 86
2023-01-04 11:04:21,411 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38960546950499214, 'Total loss': 0.38960546950499214} | train loss {'Reaction outcome loss': 0.26988110884970273, 'Total loss': 0.26988110884970273}
2023-01-04 11:04:21,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:21,412 INFO:     Epoch: 87
2023-01-04 11:04:22,939 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3766058549284935, 'Total loss': 0.3766058549284935} | train loss {'Reaction outcome loss': 0.26292039225355385, 'Total loss': 0.26292039225355385}
2023-01-04 11:04:22,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:22,940 INFO:     Epoch: 88
2023-01-04 11:04:24,537 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4106007546186447, 'Total loss': 0.4106007546186447} | train loss {'Reaction outcome loss': 0.26623128799701423, 'Total loss': 0.26623128799701423}
2023-01-04 11:04:24,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:24,537 INFO:     Epoch: 89
2023-01-04 11:04:26,168 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39156368176142375, 'Total loss': 0.39156368176142375} | train loss {'Reaction outcome loss': 0.26397166323145377, 'Total loss': 0.26397166323145377}
2023-01-04 11:04:26,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:26,168 INFO:     Epoch: 90
2023-01-04 11:04:27,804 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38008052905400597, 'Total loss': 0.38008052905400597} | train loss {'Reaction outcome loss': 0.2630295716629562, 'Total loss': 0.2630295716629562}
2023-01-04 11:04:27,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:27,805 INFO:     Epoch: 91
2023-01-04 11:04:29,422 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.36396830081939696, 'Total loss': 0.36396830081939696} | train loss {'Reaction outcome loss': 0.27060082775375904, 'Total loss': 0.27060082775375904}
2023-01-04 11:04:29,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:29,423 INFO:     Epoch: 92
2023-01-04 11:04:30,971 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3681114325920741, 'Total loss': 0.3681114325920741} | train loss {'Reaction outcome loss': 0.26332497155623313, 'Total loss': 0.26332497155623313}
2023-01-04 11:04:30,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:30,972 INFO:     Epoch: 93
2023-01-04 11:04:32,501 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3937661677598953, 'Total loss': 0.3937661677598953} | train loss {'Reaction outcome loss': 0.25791618693283747, 'Total loss': 0.25791618693283747}
2023-01-04 11:04:32,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:32,501 INFO:     Epoch: 94
2023-01-04 11:04:34,068 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38510473171869913, 'Total loss': 0.38510473171869913} | train loss {'Reaction outcome loss': 0.2604306344655662, 'Total loss': 0.2604306344655662}
2023-01-04 11:04:34,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:34,068 INFO:     Epoch: 95
2023-01-04 11:04:35,642 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3781757195790609, 'Total loss': 0.3781757195790609} | train loss {'Reaction outcome loss': 0.26174572181454203, 'Total loss': 0.26174572181454203}
2023-01-04 11:04:35,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:35,642 INFO:     Epoch: 96
2023-01-04 11:04:37,200 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37114109595616657, 'Total loss': 0.37114109595616657} | train loss {'Reaction outcome loss': 0.25533178639648624, 'Total loss': 0.25533178639648624}
2023-01-04 11:04:37,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:37,200 INFO:     Epoch: 97
2023-01-04 11:04:38,771 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3653886417547862, 'Total loss': 0.3653886417547862} | train loss {'Reaction outcome loss': 0.26006810126375635, 'Total loss': 0.26006810126375635}
2023-01-04 11:04:38,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:38,771 INFO:     Epoch: 98
2023-01-04 11:04:40,304 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3792746881643931, 'Total loss': 0.3792746881643931} | train loss {'Reaction outcome loss': 0.25440008728512786, 'Total loss': 0.25440008728512786}
2023-01-04 11:04:40,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:40,305 INFO:     Epoch: 99
2023-01-04 11:04:41,857 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40253971914450326, 'Total loss': 0.40253971914450326} | train loss {'Reaction outcome loss': 0.25766220542901475, 'Total loss': 0.25766220542901475}
2023-01-04 11:04:41,857 INFO:     Best model found after epoch 74 of 100.
2023-01-04 11:04:41,857 INFO:   Done with stage: TRAINING
2023-01-04 11:04:41,857 INFO:   Starting stage: EVALUATION
2023-01-04 11:04:41,977 INFO:   Done with stage: EVALUATION
2023-01-04 11:04:41,977 INFO:   Leaving out SEQ value Fold_6
2023-01-04 11:04:41,990 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 11:04:41,990 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:04:42,633 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:04:42,634 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:04:42,703 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:04:42,703 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:04:42,703 INFO:     No hyperparam tuning for this model
2023-01-04 11:04:42,703 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:04:42,703 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:04:42,704 INFO:     None feature selector for col prot
2023-01-04 11:04:42,704 INFO:     None feature selector for col prot
2023-01-04 11:04:42,704 INFO:     None feature selector for col prot
2023-01-04 11:04:42,705 INFO:     None feature selector for col chem
2023-01-04 11:04:42,705 INFO:     None feature selector for col chem
2023-01-04 11:04:42,705 INFO:     None feature selector for col chem
2023-01-04 11:04:42,705 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:04:42,705 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:04:42,707 INFO:     Number of params in model 70111
2023-01-04 11:04:42,710 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:04:42,710 INFO:   Starting stage: TRAINING
2023-01-04 11:04:42,753 INFO:     Val loss before train {'Reaction outcome loss': 0.9358291705449422, 'Total loss': 0.9358291705449422}
2023-01-04 11:04:42,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:42,753 INFO:     Epoch: 0
2023-01-04 11:04:44,324 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.654784615834554, 'Total loss': 0.654784615834554} | train loss {'Reaction outcome loss': 0.8395580121110923, 'Total loss': 0.8395580121110923}
2023-01-04 11:04:44,324 INFO:     Found new best model at epoch 0
2023-01-04 11:04:44,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:44,325 INFO:     Epoch: 1
2023-01-04 11:04:45,885 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5525383293628693, 'Total loss': 0.5525383293628693} | train loss {'Reaction outcome loss': 0.6779802330779685, 'Total loss': 0.6779802330779685}
2023-01-04 11:04:45,886 INFO:     Found new best model at epoch 1
2023-01-04 11:04:45,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:45,886 INFO:     Epoch: 2
2023-01-04 11:04:47,478 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5214814245700836, 'Total loss': 0.5214814245700836} | train loss {'Reaction outcome loss': 0.5841979820160229, 'Total loss': 0.5841979820160229}
2023-01-04 11:04:47,478 INFO:     Found new best model at epoch 2
2023-01-04 11:04:47,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:47,479 INFO:     Epoch: 3
2023-01-04 11:04:49,037 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48890691498915356, 'Total loss': 0.48890691498915356} | train loss {'Reaction outcome loss': 0.5368136562380119, 'Total loss': 0.5368136562380119}
2023-01-04 11:04:49,038 INFO:     Found new best model at epoch 3
2023-01-04 11:04:49,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:49,038 INFO:     Epoch: 4
2023-01-04 11:04:50,603 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47512495120366416, 'Total loss': 0.47512495120366416} | train loss {'Reaction outcome loss': 0.5187059874353857, 'Total loss': 0.5187059874353857}
2023-01-04 11:04:50,603 INFO:     Found new best model at epoch 4
2023-01-04 11:04:50,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:50,604 INFO:     Epoch: 5
2023-01-04 11:04:52,205 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46728380719820656, 'Total loss': 0.46728380719820656} | train loss {'Reaction outcome loss': 0.500248651158078, 'Total loss': 0.500248651158078}
2023-01-04 11:04:52,206 INFO:     Found new best model at epoch 5
2023-01-04 11:04:52,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:52,206 INFO:     Epoch: 6
2023-01-04 11:04:53,812 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46026723384857177, 'Total loss': 0.46026723384857177} | train loss {'Reaction outcome loss': 0.4934286460119034, 'Total loss': 0.4934286460119034}
2023-01-04 11:04:53,812 INFO:     Found new best model at epoch 6
2023-01-04 11:04:53,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:53,812 INFO:     Epoch: 7
2023-01-04 11:04:55,418 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46351852019627887, 'Total loss': 0.46351852019627887} | train loss {'Reaction outcome loss': 0.4801984088300368, 'Total loss': 0.4801984088300368}
2023-01-04 11:04:55,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:55,418 INFO:     Epoch: 8
2023-01-04 11:04:57,025 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43970563064018886, 'Total loss': 0.43970563064018886} | train loss {'Reaction outcome loss': 0.4704337523517195, 'Total loss': 0.4704337523517195}
2023-01-04 11:04:57,026 INFO:     Found new best model at epoch 8
2023-01-04 11:04:57,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:57,026 INFO:     Epoch: 9
2023-01-04 11:04:58,579 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46411463419596355, 'Total loss': 0.46411463419596355} | train loss {'Reaction outcome loss': 0.4652847465840488, 'Total loss': 0.4652847465840488}
2023-01-04 11:04:58,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:04:58,579 INFO:     Epoch: 10
2023-01-04 11:05:00,187 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44312450488408406, 'Total loss': 0.44312450488408406} | train loss {'Reaction outcome loss': 0.45391741421894044, 'Total loss': 0.45391741421894044}
2023-01-04 11:05:00,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:00,187 INFO:     Epoch: 11
2023-01-04 11:05:01,790 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4791904369990031, 'Total loss': 0.4791904369990031} | train loss {'Reaction outcome loss': 0.45522454929696093, 'Total loss': 0.45522454929696093}
2023-01-04 11:05:01,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:01,792 INFO:     Epoch: 12
2023-01-04 11:05:03,400 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42063840428988136, 'Total loss': 0.42063840428988136} | train loss {'Reaction outcome loss': 0.44936861581965903, 'Total loss': 0.44936861581965903}
2023-01-04 11:05:03,400 INFO:     Found new best model at epoch 12
2023-01-04 11:05:03,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:03,401 INFO:     Epoch: 13
2023-01-04 11:05:05,004 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42374193569024404, 'Total loss': 0.42374193569024404} | train loss {'Reaction outcome loss': 0.4390130048947214, 'Total loss': 0.4390130048947214}
2023-01-04 11:05:05,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:05,004 INFO:     Epoch: 14
2023-01-04 11:05:06,610 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42812345226605736, 'Total loss': 0.42812345226605736} | train loss {'Reaction outcome loss': 0.44063537635097433, 'Total loss': 0.44063537635097433}
2023-01-04 11:05:06,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:06,610 INFO:     Epoch: 15
2023-01-04 11:05:08,152 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4178289194901784, 'Total loss': 0.4178289194901784} | train loss {'Reaction outcome loss': 0.4354560561881599, 'Total loss': 0.4354560561881599}
2023-01-04 11:05:08,152 INFO:     Found new best model at epoch 15
2023-01-04 11:05:08,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:08,152 INFO:     Epoch: 16
2023-01-04 11:05:09,730 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4460387567679087, 'Total loss': 0.4460387567679087} | train loss {'Reaction outcome loss': 0.4308801827286555, 'Total loss': 0.4308801827286555}
2023-01-04 11:05:09,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:09,730 INFO:     Epoch: 17
2023-01-04 11:05:11,314 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42660848299662274, 'Total loss': 0.42660848299662274} | train loss {'Reaction outcome loss': 0.42912389405260015, 'Total loss': 0.42912389405260015}
2023-01-04 11:05:11,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:11,314 INFO:     Epoch: 18
2023-01-04 11:05:12,881 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41454452872276304, 'Total loss': 0.41454452872276304} | train loss {'Reaction outcome loss': 0.42439076229123, 'Total loss': 0.42439076229123}
2023-01-04 11:05:12,881 INFO:     Found new best model at epoch 18
2023-01-04 11:05:12,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:12,882 INFO:     Epoch: 19
2023-01-04 11:05:14,455 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4494342724482218, 'Total loss': 0.4494342724482218} | train loss {'Reaction outcome loss': 0.420894647279371, 'Total loss': 0.420894647279371}
2023-01-04 11:05:14,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:14,456 INFO:     Epoch: 20
2023-01-04 11:05:16,027 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43210032979647317, 'Total loss': 0.43210032979647317} | train loss {'Reaction outcome loss': 0.41386381079466333, 'Total loss': 0.41386381079466333}
2023-01-04 11:05:16,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:16,027 INFO:     Epoch: 21
2023-01-04 11:05:17,565 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4221136530240377, 'Total loss': 0.4221136530240377} | train loss {'Reaction outcome loss': 0.41240872324373745, 'Total loss': 0.41240872324373745}
2023-01-04 11:05:17,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:17,565 INFO:     Epoch: 22
2023-01-04 11:05:19,185 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40647914906342825, 'Total loss': 0.40647914906342825} | train loss {'Reaction outcome loss': 0.40964304255019024, 'Total loss': 0.40964304255019024}
2023-01-04 11:05:19,186 INFO:     Found new best model at epoch 22
2023-01-04 11:05:19,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:19,187 INFO:     Epoch: 23
2023-01-04 11:05:20,811 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3911434094111125, 'Total loss': 0.3911434094111125} | train loss {'Reaction outcome loss': 0.4044146963835623, 'Total loss': 0.4044146963835623}
2023-01-04 11:05:20,812 INFO:     Found new best model at epoch 23
2023-01-04 11:05:20,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:20,812 INFO:     Epoch: 24
2023-01-04 11:05:22,430 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40227024157842, 'Total loss': 0.40227024157842} | train loss {'Reaction outcome loss': 0.40252432135683536, 'Total loss': 0.40252432135683536}
2023-01-04 11:05:22,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:22,431 INFO:     Epoch: 25
2023-01-04 11:05:24,046 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4192113767067591, 'Total loss': 0.4192113767067591} | train loss {'Reaction outcome loss': 0.39823388553053035, 'Total loss': 0.39823388553053035}
2023-01-04 11:05:24,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:24,046 INFO:     Epoch: 26
2023-01-04 11:05:25,603 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41366418202718097, 'Total loss': 0.41366418202718097} | train loss {'Reaction outcome loss': 0.39508907556103456, 'Total loss': 0.39508907556103456}
2023-01-04 11:05:25,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:25,604 INFO:     Epoch: 27
2023-01-04 11:05:27,229 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38158395836750664, 'Total loss': 0.38158395836750664} | train loss {'Reaction outcome loss': 0.39212365335505794, 'Total loss': 0.39212365335505794}
2023-01-04 11:05:27,229 INFO:     Found new best model at epoch 27
2023-01-04 11:05:27,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:27,230 INFO:     Epoch: 28
2023-01-04 11:05:28,854 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.390534383058548, 'Total loss': 0.390534383058548} | train loss {'Reaction outcome loss': 0.3865766789401051, 'Total loss': 0.3865766789401051}
2023-01-04 11:05:28,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:28,854 INFO:     Epoch: 29
2023-01-04 11:05:30,483 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40148628304402034, 'Total loss': 0.40148628304402034} | train loss {'Reaction outcome loss': 0.3875283846086974, 'Total loss': 0.3875283846086974}
2023-01-04 11:05:30,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:30,484 INFO:     Epoch: 30
2023-01-04 11:05:32,101 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38788148760795593, 'Total loss': 0.38788148760795593} | train loss {'Reaction outcome loss': 0.3782416445199763, 'Total loss': 0.3782416445199763}
2023-01-04 11:05:32,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:32,101 INFO:     Epoch: 31
2023-01-04 11:05:33,693 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40215457876523336, 'Total loss': 0.40215457876523336} | train loss {'Reaction outcome loss': 0.37889988171710004, 'Total loss': 0.37889988171710004}
2023-01-04 11:05:33,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:33,694 INFO:     Epoch: 32
2023-01-04 11:05:35,197 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3860125114520391, 'Total loss': 0.3860125114520391} | train loss {'Reaction outcome loss': 0.37710327711561525, 'Total loss': 0.37710327711561525}
2023-01-04 11:05:35,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:35,197 INFO:     Epoch: 33
2023-01-04 11:05:36,762 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3826454430818558, 'Total loss': 0.3826454430818558} | train loss {'Reaction outcome loss': 0.3749686161103231, 'Total loss': 0.3749686161103231}
2023-01-04 11:05:36,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:36,763 INFO:     Epoch: 34
2023-01-04 11:05:38,326 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3878313064575195, 'Total loss': 0.3878313064575195} | train loss {'Reaction outcome loss': 0.37058536194614555, 'Total loss': 0.37058536194614555}
2023-01-04 11:05:38,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:38,327 INFO:     Epoch: 35
2023-01-04 11:05:39,904 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3843973696231842, 'Total loss': 0.3843973696231842} | train loss {'Reaction outcome loss': 0.37126670385095617, 'Total loss': 0.37126670385095617}
2023-01-04 11:05:39,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:39,904 INFO:     Epoch: 36
2023-01-04 11:05:41,474 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3866777410109838, 'Total loss': 0.3866777410109838} | train loss {'Reaction outcome loss': 0.3660970739616814, 'Total loss': 0.3660970739616814}
2023-01-04 11:05:41,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:41,475 INFO:     Epoch: 37
2023-01-04 11:05:43,048 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4077569742997487, 'Total loss': 0.4077569742997487} | train loss {'Reaction outcome loss': 0.363729632691571, 'Total loss': 0.363729632691571}
2023-01-04 11:05:43,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:43,048 INFO:     Epoch: 38
2023-01-04 11:05:44,546 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3453825742006302, 'Total loss': 0.3453825742006302} | train loss {'Reaction outcome loss': 0.3598200580649858, 'Total loss': 0.3598200580649858}
2023-01-04 11:05:44,546 INFO:     Found new best model at epoch 38
2023-01-04 11:05:44,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:44,547 INFO:     Epoch: 39
2023-01-04 11:05:46,105 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3602194373806318, 'Total loss': 0.3602194373806318} | train loss {'Reaction outcome loss': 0.3556508585434098, 'Total loss': 0.3556508585434098}
2023-01-04 11:05:46,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:46,105 INFO:     Epoch: 40
2023-01-04 11:05:47,656 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3628437489271164, 'Total loss': 0.3628437489271164} | train loss {'Reaction outcome loss': 0.35505241386942055, 'Total loss': 0.35505241386942055}
2023-01-04 11:05:47,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:47,656 INFO:     Epoch: 41
2023-01-04 11:05:49,226 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3543224443991979, 'Total loss': 0.3543224443991979} | train loss {'Reaction outcome loss': 0.3549431355582678, 'Total loss': 0.3549431355582678}
2023-01-04 11:05:49,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:49,226 INFO:     Epoch: 42
2023-01-04 11:05:50,781 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3640208433071772, 'Total loss': 0.3640208433071772} | train loss {'Reaction outcome loss': 0.34917390669295933, 'Total loss': 0.34917390669295933}
2023-01-04 11:05:50,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:50,781 INFO:     Epoch: 43
2023-01-04 11:05:52,361 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.35689775546391805, 'Total loss': 0.35689775546391805} | train loss {'Reaction outcome loss': 0.3493907173779467, 'Total loss': 0.3493907173779467}
2023-01-04 11:05:52,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:52,361 INFO:     Epoch: 44
2023-01-04 11:05:53,861 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3615690420071284, 'Total loss': 0.3615690420071284} | train loss {'Reaction outcome loss': 0.3470362315647008, 'Total loss': 0.3470362315647008}
2023-01-04 11:05:53,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:53,861 INFO:     Epoch: 45
2023-01-04 11:05:55,441 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3643131117026011, 'Total loss': 0.3643131117026011} | train loss {'Reaction outcome loss': 0.3401617808301096, 'Total loss': 0.3401617808301096}
2023-01-04 11:05:55,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:55,442 INFO:     Epoch: 46
2023-01-04 11:05:57,002 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.36622442603111266, 'Total loss': 0.36622442603111266} | train loss {'Reaction outcome loss': 0.34025274978325254, 'Total loss': 0.34025274978325254}
2023-01-04 11:05:57,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:57,002 INFO:     Epoch: 47
2023-01-04 11:05:58,584 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3552174399296443, 'Total loss': 0.3552174399296443} | train loss {'Reaction outcome loss': 0.34280503073216345, 'Total loss': 0.34280503073216345}
2023-01-04 11:05:58,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:05:58,585 INFO:     Epoch: 48
2023-01-04 11:06:00,163 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3589415113131205, 'Total loss': 0.3589415113131205} | train loss {'Reaction outcome loss': 0.3389005968448057, 'Total loss': 0.3389005968448057}
2023-01-04 11:06:00,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:00,163 INFO:     Epoch: 49
2023-01-04 11:06:01,703 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4039931893348694, 'Total loss': 0.4039931893348694} | train loss {'Reaction outcome loss': 0.33245518020882076, 'Total loss': 0.33245518020882076}
2023-01-04 11:06:01,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:01,704 INFO:     Epoch: 50
2023-01-04 11:06:03,217 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3549505611260732, 'Total loss': 0.3549505611260732} | train loss {'Reaction outcome loss': 0.335240371417698, 'Total loss': 0.335240371417698}
2023-01-04 11:06:03,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:03,217 INFO:     Epoch: 51
2023-01-04 11:06:04,778 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3501794397830963, 'Total loss': 0.3501794397830963} | train loss {'Reaction outcome loss': 0.3333004747487147, 'Total loss': 0.3333004747487147}
2023-01-04 11:06:04,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:04,779 INFO:     Epoch: 52
2023-01-04 11:06:06,344 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.34706339438756306, 'Total loss': 0.34706339438756306} | train loss {'Reaction outcome loss': 0.3313521240915202, 'Total loss': 0.3313521240915202}
2023-01-04 11:06:06,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:06,345 INFO:     Epoch: 53
2023-01-04 11:06:07,901 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36592910687128705, 'Total loss': 0.36592910687128705} | train loss {'Reaction outcome loss': 0.3270613603051819, 'Total loss': 0.3270613603051819}
2023-01-04 11:06:07,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:07,901 INFO:     Epoch: 54
2023-01-04 11:06:09,480 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37406067649523417, 'Total loss': 0.37406067649523417} | train loss {'Reaction outcome loss': 0.3252323878532282, 'Total loss': 0.3252323878532282}
2023-01-04 11:06:09,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:09,481 INFO:     Epoch: 55
2023-01-04 11:06:10,993 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.35742170313994087, 'Total loss': 0.35742170313994087} | train loss {'Reaction outcome loss': 0.3206589898155054, 'Total loss': 0.3206589898155054}
2023-01-04 11:06:10,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:10,994 INFO:     Epoch: 56
2023-01-04 11:06:12,552 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36104883551597594, 'Total loss': 0.36104883551597594} | train loss {'Reaction outcome loss': 0.32319302152210194, 'Total loss': 0.32319302152210194}
2023-01-04 11:06:12,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:12,552 INFO:     Epoch: 57
2023-01-04 11:06:14,179 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.35343363086382545, 'Total loss': 0.35343363086382545} | train loss {'Reaction outcome loss': 0.3208762280347115, 'Total loss': 0.3208762280347115}
2023-01-04 11:06:14,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:14,180 INFO:     Epoch: 58
2023-01-04 11:06:15,736 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.34252886672814686, 'Total loss': 0.34252886672814686} | train loss {'Reaction outcome loss': 0.31874752496554104, 'Total loss': 0.31874752496554104}
2023-01-04 11:06:15,736 INFO:     Found new best model at epoch 58
2023-01-04 11:06:15,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:15,737 INFO:     Epoch: 59
2023-01-04 11:06:17,302 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3523303200801214, 'Total loss': 0.3523303200801214} | train loss {'Reaction outcome loss': 0.32017525816706116, 'Total loss': 0.32017525816706116}
2023-01-04 11:06:17,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:17,303 INFO:     Epoch: 60
2023-01-04 11:06:18,858 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3500647693872452, 'Total loss': 0.3500647693872452} | train loss {'Reaction outcome loss': 0.3151758386339952, 'Total loss': 0.3151758386339952}
2023-01-04 11:06:18,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:18,858 INFO:     Epoch: 61
2023-01-04 11:06:20,362 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37059046030044557, 'Total loss': 0.37059046030044557} | train loss {'Reaction outcome loss': 0.31280413551074504, 'Total loss': 0.31280413551074504}
2023-01-04 11:06:20,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:20,362 INFO:     Epoch: 62
2023-01-04 11:06:21,923 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3474851588408152, 'Total loss': 0.3474851588408152} | train loss {'Reaction outcome loss': 0.3105780490361396, 'Total loss': 0.3105780490361396}
2023-01-04 11:06:21,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:21,924 INFO:     Epoch: 63
2023-01-04 11:06:23,477 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36923411389191946, 'Total loss': 0.36923411389191946} | train loss {'Reaction outcome loss': 0.31249538833268714, 'Total loss': 0.31249538833268714}
2023-01-04 11:06:23,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:23,477 INFO:     Epoch: 64
2023-01-04 11:06:25,047 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.32672099471092225, 'Total loss': 0.32672099471092225} | train loss {'Reaction outcome loss': 0.3074410201356299, 'Total loss': 0.3074410201356299}
2023-01-04 11:06:25,047 INFO:     Found new best model at epoch 64
2023-01-04 11:06:25,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:25,048 INFO:     Epoch: 65
2023-01-04 11:06:26,673 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3528448224067688, 'Total loss': 0.3528448224067688} | train loss {'Reaction outcome loss': 0.31045010462672273, 'Total loss': 0.31045010462672273}
2023-01-04 11:06:26,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:26,673 INFO:     Epoch: 66
2023-01-04 11:06:28,305 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3444937258958817, 'Total loss': 0.3444937258958817} | train loss {'Reaction outcome loss': 0.30326497675817365, 'Total loss': 0.30326497675817365}
2023-01-04 11:06:28,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:28,305 INFO:     Epoch: 67
2023-01-04 11:06:29,797 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.33000788738330206, 'Total loss': 0.33000788738330206} | train loss {'Reaction outcome loss': 0.31033650207390423, 'Total loss': 0.31033650207390423}
2023-01-04 11:06:29,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:29,798 INFO:     Epoch: 68
2023-01-04 11:06:31,425 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.34450465937455493, 'Total loss': 0.34450465937455493} | train loss {'Reaction outcome loss': 0.30378475989675696, 'Total loss': 0.30378475989675696}
2023-01-04 11:06:31,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:31,426 INFO:     Epoch: 69
2023-01-04 11:06:33,058 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3279338484009107, 'Total loss': 0.3279338484009107} | train loss {'Reaction outcome loss': 0.30166407895109715, 'Total loss': 0.30166407895109715}
2023-01-04 11:06:33,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:33,058 INFO:     Epoch: 70
2023-01-04 11:06:34,693 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3563110649585724, 'Total loss': 0.3563110649585724} | train loss {'Reaction outcome loss': 0.30100586448227884, 'Total loss': 0.30100586448227884}
2023-01-04 11:06:34,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:34,694 INFO:     Epoch: 71
2023-01-04 11:06:36,330 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3405598560969035, 'Total loss': 0.3405598560969035} | train loss {'Reaction outcome loss': 0.2990800653607837, 'Total loss': 0.2990800653607837}
2023-01-04 11:06:36,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:36,331 INFO:     Epoch: 72
2023-01-04 11:06:37,933 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.35851159592469534, 'Total loss': 0.35851159592469534} | train loss {'Reaction outcome loss': 0.29690321615564264, 'Total loss': 0.29690321615564264}
2023-01-04 11:06:37,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:37,933 INFO:     Epoch: 73
2023-01-04 11:06:39,428 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.33544822633266447, 'Total loss': 0.33544822633266447} | train loss {'Reaction outcome loss': 0.29852504117770745, 'Total loss': 0.29852504117770745}
2023-01-04 11:06:39,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:39,429 INFO:     Epoch: 74
2023-01-04 11:06:41,040 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3332461645205816, 'Total loss': 0.3332461645205816} | train loss {'Reaction outcome loss': 0.294874214738715, 'Total loss': 0.294874214738715}
2023-01-04 11:06:41,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:41,041 INFO:     Epoch: 75
2023-01-04 11:06:42,586 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3552183945973714, 'Total loss': 0.3552183945973714} | train loss {'Reaction outcome loss': 0.29542311197583854, 'Total loss': 0.29542311197583854}
2023-01-04 11:06:42,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:42,586 INFO:     Epoch: 76
2023-01-04 11:06:44,151 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.348905211687088, 'Total loss': 0.348905211687088} | train loss {'Reaction outcome loss': 0.2908379034229995, 'Total loss': 0.2908379034229995}
2023-01-04 11:06:44,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:44,152 INFO:     Epoch: 77
2023-01-04 11:06:45,728 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3337448587020238, 'Total loss': 0.3337448587020238} | train loss {'Reaction outcome loss': 0.2944526275088641, 'Total loss': 0.2944526275088641}
2023-01-04 11:06:45,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:45,728 INFO:     Epoch: 78
2023-01-04 11:06:47,286 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.34003240962823233, 'Total loss': 0.34003240962823233} | train loss {'Reaction outcome loss': 0.2886647117132529, 'Total loss': 0.2886647117132529}
2023-01-04 11:06:47,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:47,286 INFO:     Epoch: 79
2023-01-04 11:06:48,735 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.32958450516064963, 'Total loss': 0.32958450516064963} | train loss {'Reaction outcome loss': 0.2885532988107592, 'Total loss': 0.2885532988107592}
2023-01-04 11:06:48,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:48,736 INFO:     Epoch: 80
2023-01-04 11:06:50,316 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3569087296724319, 'Total loss': 0.3569087296724319} | train loss {'Reaction outcome loss': 0.28608777637623706, 'Total loss': 0.28608777637623706}
2023-01-04 11:06:50,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:50,316 INFO:     Epoch: 81
2023-01-04 11:06:51,897 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.37048562467098234, 'Total loss': 0.37048562467098234} | train loss {'Reaction outcome loss': 0.28725827719330355, 'Total loss': 0.28725827719330355}
2023-01-04 11:06:51,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:51,897 INFO:     Epoch: 82
2023-01-04 11:06:53,457 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.35035769939422606, 'Total loss': 0.35035769939422606} | train loss {'Reaction outcome loss': 0.28186065944362204, 'Total loss': 0.28186065944362204}
2023-01-04 11:06:53,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:53,457 INFO:     Epoch: 83
2023-01-04 11:06:55,037 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3492061773935954, 'Total loss': 0.3492061773935954} | train loss {'Reaction outcome loss': 0.2867320392159779, 'Total loss': 0.2867320392159779}
2023-01-04 11:06:55,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:55,038 INFO:     Epoch: 84
2023-01-04 11:06:56,560 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3581821918487549, 'Total loss': 0.3581821918487549} | train loss {'Reaction outcome loss': 0.28281269092045536, 'Total loss': 0.28281269092045536}
2023-01-04 11:06:56,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:56,560 INFO:     Epoch: 85
2023-01-04 11:06:58,093 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.326948477824529, 'Total loss': 0.326948477824529} | train loss {'Reaction outcome loss': 0.28130946293580833, 'Total loss': 0.28130946293580833}
2023-01-04 11:06:58,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:58,093 INFO:     Epoch: 86
2023-01-04 11:06:59,652 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3494221995274226, 'Total loss': 0.3494221995274226} | train loss {'Reaction outcome loss': 0.2754954505267987, 'Total loss': 0.2754954505267987}
2023-01-04 11:06:59,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:06:59,652 INFO:     Epoch: 87
2023-01-04 11:07:01,239 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.34550542533397677, 'Total loss': 0.34550542533397677} | train loss {'Reaction outcome loss': 0.28205730821197644, 'Total loss': 0.28205730821197644}
2023-01-04 11:07:01,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:01,239 INFO:     Epoch: 88
2023-01-04 11:07:02,826 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3428244690100352, 'Total loss': 0.3428244690100352} | train loss {'Reaction outcome loss': 0.28021833736328444, 'Total loss': 0.28021833736328444}
2023-01-04 11:07:02,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:02,826 INFO:     Epoch: 89
2023-01-04 11:07:04,410 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3463665803273519, 'Total loss': 0.3463665803273519} | train loss {'Reaction outcome loss': 0.2741549174008817, 'Total loss': 0.2741549174008817}
2023-01-04 11:07:04,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:04,410 INFO:     Epoch: 90
2023-01-04 11:07:05,883 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.35459332416454953, 'Total loss': 0.35459332416454953} | train loss {'Reaction outcome loss': 0.2794254774005835, 'Total loss': 0.2794254774005835}
2023-01-04 11:07:05,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:05,884 INFO:     Epoch: 91
2023-01-04 11:07:07,443 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3500703990459442, 'Total loss': 0.3500703990459442} | train loss {'Reaction outcome loss': 0.27653410336816353, 'Total loss': 0.27653410336816353}
2023-01-04 11:07:07,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:07,443 INFO:     Epoch: 92
2023-01-04 11:07:09,012 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3300879418849945, 'Total loss': 0.3300879418849945} | train loss {'Reaction outcome loss': 0.2796590646950777, 'Total loss': 0.2796590646950777}
2023-01-04 11:07:09,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:09,012 INFO:     Epoch: 93
2023-01-04 11:07:10,592 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36610945959885915, 'Total loss': 0.36610945959885915} | train loss {'Reaction outcome loss': 0.27471881211879884, 'Total loss': 0.27471881211879884}
2023-01-04 11:07:10,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:10,592 INFO:     Epoch: 94
2023-01-04 11:07:12,155 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.33484781881173453, 'Total loss': 0.33484781881173453} | train loss {'Reaction outcome loss': 0.275076044501488, 'Total loss': 0.275076044501488}
2023-01-04 11:07:12,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:12,156 INFO:     Epoch: 95
2023-01-04 11:07:13,726 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35451023777325946, 'Total loss': 0.35451023777325946} | train loss {'Reaction outcome loss': 0.26870011984764025, 'Total loss': 0.26870011984764025}
2023-01-04 11:07:13,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:13,726 INFO:     Epoch: 96
2023-01-04 11:07:15,191 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.34187452246745426, 'Total loss': 0.34187452246745426} | train loss {'Reaction outcome loss': 0.27401555184315257, 'Total loss': 0.27401555184315257}
2023-01-04 11:07:15,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:15,191 INFO:     Epoch: 97
2023-01-04 11:07:16,767 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.33259076277414956, 'Total loss': 0.33259076277414956} | train loss {'Reaction outcome loss': 0.2696286812693634, 'Total loss': 0.2696286812693634}
2023-01-04 11:07:16,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:16,768 INFO:     Epoch: 98
2023-01-04 11:07:18,376 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.34197714428106946, 'Total loss': 0.34197714428106946} | train loss {'Reaction outcome loss': 0.26996802250831137, 'Total loss': 0.26996802250831137}
2023-01-04 11:07:18,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:18,376 INFO:     Epoch: 99
2023-01-04 11:07:20,011 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.338661856452624, 'Total loss': 0.338661856452624} | train loss {'Reaction outcome loss': 0.2658623323409351, 'Total loss': 0.2658623323409351}
2023-01-04 11:07:20,011 INFO:     Best model found after epoch 65 of 100.
2023-01-04 11:07:20,011 INFO:   Done with stage: TRAINING
2023-01-04 11:07:20,011 INFO:   Starting stage: EVALUATION
2023-01-04 11:07:20,133 INFO:   Done with stage: EVALUATION
2023-01-04 11:07:20,133 INFO:   Leaving out SEQ value Fold_7
2023-01-04 11:07:20,146 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 11:07:20,146 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:07:20,788 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:07:20,788 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:07:20,856 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:07:20,856 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:07:20,856 INFO:     No hyperparam tuning for this model
2023-01-04 11:07:20,856 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:07:20,856 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:07:20,857 INFO:     None feature selector for col prot
2023-01-04 11:07:20,857 INFO:     None feature selector for col prot
2023-01-04 11:07:20,857 INFO:     None feature selector for col prot
2023-01-04 11:07:20,857 INFO:     None feature selector for col chem
2023-01-04 11:07:20,857 INFO:     None feature selector for col chem
2023-01-04 11:07:20,858 INFO:     None feature selector for col chem
2023-01-04 11:07:20,858 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:07:20,858 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:07:20,859 INFO:     Number of params in model 70111
2023-01-04 11:07:20,862 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:07:20,862 INFO:   Starting stage: TRAINING
2023-01-04 11:07:20,905 INFO:     Val loss before train {'Reaction outcome loss': 0.9751787702242534, 'Total loss': 0.9751787702242534}
2023-01-04 11:07:20,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:20,906 INFO:     Epoch: 0
2023-01-04 11:07:22,483 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7118749260902405, 'Total loss': 0.7118749260902405} | train loss {'Reaction outcome loss': 0.8453097797472985, 'Total loss': 0.8453097797472985}
2023-01-04 11:07:22,483 INFO:     Found new best model at epoch 0
2023-01-04 11:07:22,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:22,484 INFO:     Epoch: 1
2023-01-04 11:07:23,948 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5815963943799337, 'Total loss': 0.5815963943799337} | train loss {'Reaction outcome loss': 0.6686080247701721, 'Total loss': 0.6686080247701721}
2023-01-04 11:07:23,948 INFO:     Found new best model at epoch 1
2023-01-04 11:07:23,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:23,949 INFO:     Epoch: 2
2023-01-04 11:07:25,532 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5499203185240428, 'Total loss': 0.5499203185240428} | train loss {'Reaction outcome loss': 0.5651775656624392, 'Total loss': 0.5651775656624392}
2023-01-04 11:07:25,533 INFO:     Found new best model at epoch 2
2023-01-04 11:07:25,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:25,533 INFO:     Epoch: 3
2023-01-04 11:07:27,119 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5016561011473338, 'Total loss': 0.5016561011473338} | train loss {'Reaction outcome loss': 0.5314298980072517, 'Total loss': 0.5314298980072517}
2023-01-04 11:07:27,119 INFO:     Found new best model at epoch 3
2023-01-04 11:07:27,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:27,120 INFO:     Epoch: 4
2023-01-04 11:07:28,764 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5121733903884887, 'Total loss': 0.5121733903884887} | train loss {'Reaction outcome loss': 0.5132437042273339, 'Total loss': 0.5132437042273339}
2023-01-04 11:07:28,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:28,764 INFO:     Epoch: 5
2023-01-04 11:07:30,407 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4927112966775894, 'Total loss': 0.4927112966775894} | train loss {'Reaction outcome loss': 0.4955274292708304, 'Total loss': 0.4955274292708304}
2023-01-04 11:07:30,407 INFO:     Found new best model at epoch 5
2023-01-04 11:07:30,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:30,408 INFO:     Epoch: 6
2023-01-04 11:07:32,052 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4971928497155507, 'Total loss': 0.4971928497155507} | train loss {'Reaction outcome loss': 0.48482027622982055, 'Total loss': 0.48482027622982055}
2023-01-04 11:07:32,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:32,053 INFO:     Epoch: 7
2023-01-04 11:07:33,592 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5159996052583059, 'Total loss': 0.5159996052583059} | train loss {'Reaction outcome loss': 0.4810996620448488, 'Total loss': 0.4810996620448488}
2023-01-04 11:07:33,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:33,592 INFO:     Epoch: 8
2023-01-04 11:07:35,226 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49993592997392017, 'Total loss': 0.49993592997392017} | train loss {'Reaction outcome loss': 0.47310398987053964, 'Total loss': 0.47310398987053964}
2023-01-04 11:07:35,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:35,226 INFO:     Epoch: 9
2023-01-04 11:07:36,862 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4703087548414866, 'Total loss': 0.4703087548414866} | train loss {'Reaction outcome loss': 0.46424338732600645, 'Total loss': 0.46424338732600645}
2023-01-04 11:07:36,863 INFO:     Found new best model at epoch 9
2023-01-04 11:07:36,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:36,864 INFO:     Epoch: 10
2023-01-04 11:07:38,485 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4599886993567149, 'Total loss': 0.4599886993567149} | train loss {'Reaction outcome loss': 0.460036679214734, 'Total loss': 0.460036679214734}
2023-01-04 11:07:38,485 INFO:     Found new best model at epoch 10
2023-01-04 11:07:38,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:38,486 INFO:     Epoch: 11
2023-01-04 11:07:40,122 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48449506958325705, 'Total loss': 0.48449506958325705} | train loss {'Reaction outcome loss': 0.45256422379386985, 'Total loss': 0.45256422379386985}
2023-01-04 11:07:40,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:40,122 INFO:     Epoch: 12
2023-01-04 11:07:41,725 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47275637288888295, 'Total loss': 0.47275637288888295} | train loss {'Reaction outcome loss': 0.44974866729996266, 'Total loss': 0.44974866729996266}
2023-01-04 11:07:41,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:41,725 INFO:     Epoch: 13
2023-01-04 11:07:43,308 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4571995774904887, 'Total loss': 0.4571995774904887} | train loss {'Reaction outcome loss': 0.441467227004065, 'Total loss': 0.441467227004065}
2023-01-04 11:07:43,308 INFO:     Found new best model at epoch 13
2023-01-04 11:07:43,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:43,309 INFO:     Epoch: 14
2023-01-04 11:07:44,950 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4911853432655334, 'Total loss': 0.4911853432655334} | train loss {'Reaction outcome loss': 0.4397420482945356, 'Total loss': 0.4397420482945356}
2023-01-04 11:07:44,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:44,951 INFO:     Epoch: 15
2023-01-04 11:07:46,592 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4757895807425181, 'Total loss': 0.4757895807425181} | train loss {'Reaction outcome loss': 0.4354717701888687, 'Total loss': 0.4354717701888687}
2023-01-04 11:07:46,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:46,592 INFO:     Epoch: 16
2023-01-04 11:07:48,208 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43497208654880526, 'Total loss': 0.43497208654880526} | train loss {'Reaction outcome loss': 0.42886511806654154, 'Total loss': 0.42886511806654154}
2023-01-04 11:07:48,208 INFO:     Found new best model at epoch 16
2023-01-04 11:07:48,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:48,209 INFO:     Epoch: 17
2023-01-04 11:07:49,839 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4627320071061452, 'Total loss': 0.4627320071061452} | train loss {'Reaction outcome loss': 0.4273447646937646, 'Total loss': 0.4273447646937646}
2023-01-04 11:07:49,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:49,840 INFO:     Epoch: 18
2023-01-04 11:07:51,388 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4523092309633891, 'Total loss': 0.4523092309633891} | train loss {'Reaction outcome loss': 0.42174509447404196, 'Total loss': 0.42174509447404196}
2023-01-04 11:07:51,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:51,388 INFO:     Epoch: 19
2023-01-04 11:07:53,029 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44453136722246805, 'Total loss': 0.44453136722246805} | train loss {'Reaction outcome loss': 0.41478940537905434, 'Total loss': 0.41478940537905434}
2023-01-04 11:07:53,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:53,029 INFO:     Epoch: 20
2023-01-04 11:07:54,659 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4869577328364054, 'Total loss': 0.4869577328364054} | train loss {'Reaction outcome loss': 0.4134958509611309, 'Total loss': 0.4134958509611309}
2023-01-04 11:07:54,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:54,659 INFO:     Epoch: 21
2023-01-04 11:07:56,277 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4374758114417394, 'Total loss': 0.4374758114417394} | train loss {'Reaction outcome loss': 0.40677367355203803, 'Total loss': 0.40677367355203803}
2023-01-04 11:07:56,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:56,278 INFO:     Epoch: 22
2023-01-04 11:07:57,908 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4449717789888382, 'Total loss': 0.4449717789888382} | train loss {'Reaction outcome loss': 0.4001081111951856, 'Total loss': 0.4001081111951856}
2023-01-04 11:07:57,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:57,908 INFO:     Epoch: 23
2023-01-04 11:07:59,543 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44126055041948953, 'Total loss': 0.44126055041948953} | train loss {'Reaction outcome loss': 0.4020963211943957, 'Total loss': 0.4020963211943957}
2023-01-04 11:07:59,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:07:59,543 INFO:     Epoch: 24
2023-01-04 11:08:00,739 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46453220446904503, 'Total loss': 0.46453220446904503} | train loss {'Reaction outcome loss': 0.3926378415379714, 'Total loss': 0.3926378415379714}
2023-01-04 11:08:00,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:00,739 INFO:     Epoch: 25
2023-01-04 11:08:01,789 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4527520418167114, 'Total loss': 0.4527520418167114} | train loss {'Reaction outcome loss': 0.39189940583404653, 'Total loss': 0.39189940583404653}
2023-01-04 11:08:01,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:01,789 INFO:     Epoch: 26
2023-01-04 11:08:02,836 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4680283556381861, 'Total loss': 0.4680283556381861} | train loss {'Reaction outcome loss': 0.3828153018755603, 'Total loss': 0.3828153018755603}
2023-01-04 11:08:02,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:02,836 INFO:     Epoch: 27
2023-01-04 11:08:03,885 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4519631673892339, 'Total loss': 0.4519631673892339} | train loss {'Reaction outcome loss': 0.38088044669438786, 'Total loss': 0.38088044669438786}
2023-01-04 11:08:03,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:03,885 INFO:     Epoch: 28
2023-01-04 11:08:05,100 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4818344434102376, 'Total loss': 0.4818344434102376} | train loss {'Reaction outcome loss': 0.38274344863766796, 'Total loss': 0.38274344863766796}
2023-01-04 11:08:05,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:05,100 INFO:     Epoch: 29
2023-01-04 11:08:06,692 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46597772439320884, 'Total loss': 0.46597772439320884} | train loss {'Reaction outcome loss': 0.37438424426510875, 'Total loss': 0.37438424426510875}
2023-01-04 11:08:06,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:06,692 INFO:     Epoch: 30
2023-01-04 11:08:08,258 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4343546390533447, 'Total loss': 0.4343546390533447} | train loss {'Reaction outcome loss': 0.3720237092528533, 'Total loss': 0.3720237092528533}
2023-01-04 11:08:08,259 INFO:     Found new best model at epoch 30
2023-01-04 11:08:08,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:08,260 INFO:     Epoch: 31
2023-01-04 11:08:09,846 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4280333399772644, 'Total loss': 0.4280333399772644} | train loss {'Reaction outcome loss': 0.36779029271985647, 'Total loss': 0.36779029271985647}
2023-01-04 11:08:09,846 INFO:     Found new best model at epoch 31
2023-01-04 11:08:09,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:09,847 INFO:     Epoch: 32
2023-01-04 11:08:11,429 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4665619174639384, 'Total loss': 0.4665619174639384} | train loss {'Reaction outcome loss': 0.3626730328809053, 'Total loss': 0.3626730328809053}
2023-01-04 11:08:11,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:11,429 INFO:     Epoch: 33
2023-01-04 11:08:13,015 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4481860319773356, 'Total loss': 0.4481860319773356} | train loss {'Reaction outcome loss': 0.3653183700752172, 'Total loss': 0.3653183700752172}
2023-01-04 11:08:13,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:13,015 INFO:     Epoch: 34
2023-01-04 11:08:14,577 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4480011532704035, 'Total loss': 0.4480011532704035} | train loss {'Reaction outcome loss': 0.3579795749770605, 'Total loss': 0.3579795749770605}
2023-01-04 11:08:14,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:14,578 INFO:     Epoch: 35
2023-01-04 11:08:16,146 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.447550763686498, 'Total loss': 0.447550763686498} | train loss {'Reaction outcome loss': 0.35751676505653435, 'Total loss': 0.35751676505653435}
2023-01-04 11:08:16,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:16,146 INFO:     Epoch: 36
2023-01-04 11:08:17,771 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4279411256313324, 'Total loss': 0.4279411256313324} | train loss {'Reaction outcome loss': 0.3513885911164086, 'Total loss': 0.3513885911164086}
2023-01-04 11:08:17,771 INFO:     Found new best model at epoch 36
2023-01-04 11:08:17,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:17,772 INFO:     Epoch: 37
2023-01-04 11:08:19,390 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4549880544344584, 'Total loss': 0.4549880544344584} | train loss {'Reaction outcome loss': 0.3514719074760103, 'Total loss': 0.3514719074760103}
2023-01-04 11:08:19,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:19,391 INFO:     Epoch: 38
2023-01-04 11:08:20,983 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45050615469614663, 'Total loss': 0.45050615469614663} | train loss {'Reaction outcome loss': 0.34878978001404326, 'Total loss': 0.34878978001404326}
2023-01-04 11:08:20,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:20,983 INFO:     Epoch: 39
2023-01-04 11:08:22,587 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4159992595513662, 'Total loss': 0.4159992595513662} | train loss {'Reaction outcome loss': 0.34660435623963387, 'Total loss': 0.34660435623963387}
2023-01-04 11:08:22,587 INFO:     Found new best model at epoch 39
2023-01-04 11:08:22,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:22,588 INFO:     Epoch: 40
2023-01-04 11:08:24,167 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42704785863558453, 'Total loss': 0.42704785863558453} | train loss {'Reaction outcome loss': 0.33813187913021026, 'Total loss': 0.33813187913021026}
2023-01-04 11:08:24,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:24,167 INFO:     Epoch: 41
2023-01-04 11:08:25,723 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4233891228834788, 'Total loss': 0.4233891228834788} | train loss {'Reaction outcome loss': 0.33640593451713396, 'Total loss': 0.33640593451713396}
2023-01-04 11:08:25,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:25,723 INFO:     Epoch: 42
2023-01-04 11:08:27,289 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44477800726890565, 'Total loss': 0.44477800726890565} | train loss {'Reaction outcome loss': 0.3399527996294335, 'Total loss': 0.3399527996294335}
2023-01-04 11:08:27,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:27,290 INFO:     Epoch: 43
2023-01-04 11:08:28,862 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45239987671375276, 'Total loss': 0.45239987671375276} | train loss {'Reaction outcome loss': 0.3316391159911448, 'Total loss': 0.3316391159911448}
2023-01-04 11:08:28,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:28,862 INFO:     Epoch: 44
2023-01-04 11:08:30,438 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47193520863850913, 'Total loss': 0.47193520863850913} | train loss {'Reaction outcome loss': 0.3355511381738022, 'Total loss': 0.3355511381738022}
2023-01-04 11:08:30,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:30,438 INFO:     Epoch: 45
2023-01-04 11:08:31,994 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4110127369562785, 'Total loss': 0.4110127369562785} | train loss {'Reaction outcome loss': 0.33177880778747343, 'Total loss': 0.33177880778747343}
2023-01-04 11:08:31,995 INFO:     Found new best model at epoch 45
2023-01-04 11:08:31,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:31,995 INFO:     Epoch: 46
2023-01-04 11:08:33,565 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.443060091137886, 'Total loss': 0.443060091137886} | train loss {'Reaction outcome loss': 0.32510925853618217, 'Total loss': 0.32510925853618217}
2023-01-04 11:08:33,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:33,566 INFO:     Epoch: 47
2023-01-04 11:08:35,127 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4138290782769521, 'Total loss': 0.4138290782769521} | train loss {'Reaction outcome loss': 0.3242971170895366, 'Total loss': 0.3242971170895366}
2023-01-04 11:08:35,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:35,127 INFO:     Epoch: 48
2023-01-04 11:08:36,728 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40173066755135856, 'Total loss': 0.40173066755135856} | train loss {'Reaction outcome loss': 0.3242070356162016, 'Total loss': 0.3242070356162016}
2023-01-04 11:08:36,728 INFO:     Found new best model at epoch 48
2023-01-04 11:08:36,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:36,729 INFO:     Epoch: 49
2023-01-04 11:08:38,303 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4144756068785985, 'Total loss': 0.4144756068785985} | train loss {'Reaction outcome loss': 0.32073027788516845, 'Total loss': 0.32073027788516845}
2023-01-04 11:08:38,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:38,303 INFO:     Epoch: 50
2023-01-04 11:08:39,874 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4069653997818629, 'Total loss': 0.4069653997818629} | train loss {'Reaction outcome loss': 0.31631377336673355, 'Total loss': 0.31631377336673355}
2023-01-04 11:08:39,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:39,874 INFO:     Epoch: 51
2023-01-04 11:08:41,424 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4165353169043859, 'Total loss': 0.4165353169043859} | train loss {'Reaction outcome loss': 0.31648531940762314, 'Total loss': 0.31648531940762314}
2023-01-04 11:08:41,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:41,424 INFO:     Epoch: 52
2023-01-04 11:08:43,014 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40593964358170825, 'Total loss': 0.40593964358170825} | train loss {'Reaction outcome loss': 0.30773003071223787, 'Total loss': 0.30773003071223787}
2023-01-04 11:08:43,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:43,016 INFO:     Epoch: 53
2023-01-04 11:08:44,567 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4274188985427221, 'Total loss': 0.4274188985427221} | train loss {'Reaction outcome loss': 0.3098448779608799, 'Total loss': 0.3098448779608799}
2023-01-04 11:08:44,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:44,567 INFO:     Epoch: 54
2023-01-04 11:08:46,168 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4201802949110667, 'Total loss': 0.4201802949110667} | train loss {'Reaction outcome loss': 0.31086932953837115, 'Total loss': 0.31086932953837115}
2023-01-04 11:08:46,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:46,169 INFO:     Epoch: 55
2023-01-04 11:08:47,746 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.425182514389356, 'Total loss': 0.425182514389356} | train loss {'Reaction outcome loss': 0.30586217830650214, 'Total loss': 0.30586217830650214}
2023-01-04 11:08:47,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:47,746 INFO:     Epoch: 56
2023-01-04 11:08:49,336 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4293509046236674, 'Total loss': 0.4293509046236674} | train loss {'Reaction outcome loss': 0.3073841039669643, 'Total loss': 0.3073841039669643}
2023-01-04 11:08:49,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:49,337 INFO:     Epoch: 57
2023-01-04 11:08:50,878 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41590539515018465, 'Total loss': 0.41590539515018465} | train loss {'Reaction outcome loss': 0.3019715346369072, 'Total loss': 0.3019715346369072}
2023-01-04 11:08:50,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:50,879 INFO:     Epoch: 58
2023-01-04 11:08:52,441 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4163965404033661, 'Total loss': 0.4163965404033661} | train loss {'Reaction outcome loss': 0.30338258659366235, 'Total loss': 0.30338258659366235}
2023-01-04 11:08:52,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:52,441 INFO:     Epoch: 59
2023-01-04 11:08:54,015 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40994609942038857, 'Total loss': 0.40994609942038857} | train loss {'Reaction outcome loss': 0.30001330929757886, 'Total loss': 0.30001330929757886}
2023-01-04 11:08:54,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:54,015 INFO:     Epoch: 60
2023-01-04 11:08:55,595 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4058761388063431, 'Total loss': 0.4058761388063431} | train loss {'Reaction outcome loss': 0.29853729995149136, 'Total loss': 0.29853729995149136}
2023-01-04 11:08:55,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:55,596 INFO:     Epoch: 61
2023-01-04 11:08:57,164 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4061290363470713, 'Total loss': 0.4061290363470713} | train loss {'Reaction outcome loss': 0.29489751511155915, 'Total loss': 0.29489751511155915}
2023-01-04 11:08:57,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:57,165 INFO:     Epoch: 62
2023-01-04 11:08:58,763 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4070697863896688, 'Total loss': 0.4070697863896688} | train loss {'Reaction outcome loss': 0.2952638875276173, 'Total loss': 0.2952638875276173}
2023-01-04 11:08:58,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:08:58,763 INFO:     Epoch: 63
2023-01-04 11:09:00,336 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40830237865448, 'Total loss': 0.40830237865448} | train loss {'Reaction outcome loss': 0.2920053191348534, 'Total loss': 0.2920053191348534}
2023-01-04 11:09:00,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:00,336 INFO:     Epoch: 64
2023-01-04 11:09:01,885 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4072162002325058, 'Total loss': 0.4072162002325058} | train loss {'Reaction outcome loss': 0.2896493628674896, 'Total loss': 0.2896493628674896}
2023-01-04 11:09:01,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:01,886 INFO:     Epoch: 65
2023-01-04 11:09:03,480 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40612474679946897, 'Total loss': 0.40612474679946897} | train loss {'Reaction outcome loss': 0.29055854986129254, 'Total loss': 0.29055854986129254}
2023-01-04 11:09:03,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:03,480 INFO:     Epoch: 66
2023-01-04 11:09:05,064 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4452043652534485, 'Total loss': 0.4452043652534485} | train loss {'Reaction outcome loss': 0.2926463445493891, 'Total loss': 0.2926463445493891}
2023-01-04 11:09:05,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:05,065 INFO:     Epoch: 67
2023-01-04 11:09:06,651 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4085707555214564, 'Total loss': 0.4085707555214564} | train loss {'Reaction outcome loss': 0.286247823992576, 'Total loss': 0.286247823992576}
2023-01-04 11:09:06,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:06,651 INFO:     Epoch: 68
2023-01-04 11:09:08,249 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.435106227795283, 'Total loss': 0.435106227795283} | train loss {'Reaction outcome loss': 0.28385404865879443, 'Total loss': 0.28385404865879443}
2023-01-04 11:09:08,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:08,249 INFO:     Epoch: 69
2023-01-04 11:09:09,821 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4161946912606557, 'Total loss': 0.4161946912606557} | train loss {'Reaction outcome loss': 0.2845748513668022, 'Total loss': 0.2845748513668022}
2023-01-04 11:09:09,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:09,822 INFO:     Epoch: 70
2023-01-04 11:09:11,380 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4357603430747986, 'Total loss': 0.4357603430747986} | train loss {'Reaction outcome loss': 0.2812885982303843, 'Total loss': 0.2812885982303843}
2023-01-04 11:09:11,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:11,381 INFO:     Epoch: 71
2023-01-04 11:09:12,985 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4253202776114146, 'Total loss': 0.4253202776114146} | train loss {'Reaction outcome loss': 0.2812247145046826, 'Total loss': 0.2812247145046826}
2023-01-04 11:09:12,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:12,985 INFO:     Epoch: 72
2023-01-04 11:09:14,577 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4218182404836019, 'Total loss': 0.4218182404836019} | train loss {'Reaction outcome loss': 0.2753911977263995, 'Total loss': 0.2753911977263995}
2023-01-04 11:09:14,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:14,578 INFO:     Epoch: 73
2023-01-04 11:09:16,200 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4058787832657496, 'Total loss': 0.4058787832657496} | train loss {'Reaction outcome loss': 0.28119161878359444, 'Total loss': 0.28119161878359444}
2023-01-04 11:09:16,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:16,200 INFO:     Epoch: 74
2023-01-04 11:09:17,779 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44983453353246056, 'Total loss': 0.44983453353246056} | train loss {'Reaction outcome loss': 0.2721952678171736, 'Total loss': 0.2721952678171736}
2023-01-04 11:09:17,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:17,779 INFO:     Epoch: 75
2023-01-04 11:09:19,391 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4521234174569448, 'Total loss': 0.4521234174569448} | train loss {'Reaction outcome loss': 0.2756617144557113, 'Total loss': 0.2756617144557113}
2023-01-04 11:09:19,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:19,392 INFO:     Epoch: 76
2023-01-04 11:09:20,963 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4174195885658264, 'Total loss': 0.4174195885658264} | train loss {'Reaction outcome loss': 0.27558315782017656, 'Total loss': 0.27558315782017656}
2023-01-04 11:09:20,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:20,964 INFO:     Epoch: 77
2023-01-04 11:09:22,554 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4215753694375356, 'Total loss': 0.4215753694375356} | train loss {'Reaction outcome loss': 0.2741803572738429, 'Total loss': 0.2741803572738429}
2023-01-04 11:09:22,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:22,554 INFO:     Epoch: 78
2023-01-04 11:09:24,166 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4149719605843226, 'Total loss': 0.4149719605843226} | train loss {'Reaction outcome loss': 0.27828887356478815, 'Total loss': 0.27828887356478815}
2023-01-04 11:09:24,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:24,166 INFO:     Epoch: 79
2023-01-04 11:09:25,773 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4350403110186259, 'Total loss': 0.4350403110186259} | train loss {'Reaction outcome loss': 0.2645219738733037, 'Total loss': 0.2645219738733037}
2023-01-04 11:09:25,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:25,774 INFO:     Epoch: 80
2023-01-04 11:09:27,360 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4104984958966573, 'Total loss': 0.4104984958966573} | train loss {'Reaction outcome loss': 0.27059079795430285, 'Total loss': 0.27059079795430285}
2023-01-04 11:09:27,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:27,360 INFO:     Epoch: 81
2023-01-04 11:09:28,938 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3781863123178482, 'Total loss': 0.3781863123178482} | train loss {'Reaction outcome loss': 0.26544044063248357, 'Total loss': 0.26544044063248357}
2023-01-04 11:09:28,938 INFO:     Found new best model at epoch 81
2023-01-04 11:09:28,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:28,939 INFO:     Epoch: 82
2023-01-04 11:09:30,522 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39834015965461733, 'Total loss': 0.39834015965461733} | train loss {'Reaction outcome loss': 0.26390509596195355, 'Total loss': 0.26390509596195355}
2023-01-04 11:09:30,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:30,522 INFO:     Epoch: 83
2023-01-04 11:09:32,100 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43431610067685444, 'Total loss': 0.43431610067685444} | train loss {'Reaction outcome loss': 0.26028866689342883, 'Total loss': 0.26028866689342883}
2023-01-04 11:09:32,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:32,100 INFO:     Epoch: 84
2023-01-04 11:09:33,691 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4164211541414261, 'Total loss': 0.4164211541414261} | train loss {'Reaction outcome loss': 0.26767644933710677, 'Total loss': 0.26767644933710677}
2023-01-04 11:09:33,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:33,692 INFO:     Epoch: 85
2023-01-04 11:09:35,274 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4378991574048996, 'Total loss': 0.4378991574048996} | train loss {'Reaction outcome loss': 0.26158049120315574, 'Total loss': 0.26158049120315574}
2023-01-04 11:09:35,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:35,274 INFO:     Epoch: 86
2023-01-04 11:09:36,810 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4278773923714956, 'Total loss': 0.4278773923714956} | train loss {'Reaction outcome loss': 0.2615218070547503, 'Total loss': 0.2615218070547503}
2023-01-04 11:09:36,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:36,810 INFO:     Epoch: 87
2023-01-04 11:09:38,358 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43971393009026843, 'Total loss': 0.43971393009026843} | train loss {'Reaction outcome loss': 0.26081280899822495, 'Total loss': 0.26081280899822495}
2023-01-04 11:09:38,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:38,358 INFO:     Epoch: 88
2023-01-04 11:09:39,940 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4608702043692271, 'Total loss': 0.4608702043692271} | train loss {'Reaction outcome loss': 0.2585150083990949, 'Total loss': 0.2585150083990949}
2023-01-04 11:09:39,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:39,940 INFO:     Epoch: 89
2023-01-04 11:09:41,514 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44059471487998964, 'Total loss': 0.44059471487998964} | train loss {'Reaction outcome loss': 0.262500116325888, 'Total loss': 0.262500116325888}
2023-01-04 11:09:41,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:41,514 INFO:     Epoch: 90
2023-01-04 11:09:43,083 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41225788195927937, 'Total loss': 0.41225788195927937} | train loss {'Reaction outcome loss': 0.259889295896253, 'Total loss': 0.259889295896253}
2023-01-04 11:09:43,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:43,083 INFO:     Epoch: 91
2023-01-04 11:09:44,648 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43300859530766805, 'Total loss': 0.43300859530766805} | train loss {'Reaction outcome loss': 0.2559088901868796, 'Total loss': 0.2559088901868796}
2023-01-04 11:09:44,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:44,649 INFO:     Epoch: 92
2023-01-04 11:09:46,182 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4258988459904989, 'Total loss': 0.4258988459904989} | train loss {'Reaction outcome loss': 0.2565301461178904, 'Total loss': 0.2565301461178904}
2023-01-04 11:09:46,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:46,182 INFO:     Epoch: 93
2023-01-04 11:09:47,721 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4224195788304011, 'Total loss': 0.4224195788304011} | train loss {'Reaction outcome loss': 0.25190428469585596, 'Total loss': 0.25190428469585596}
2023-01-04 11:09:47,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:47,721 INFO:     Epoch: 94
2023-01-04 11:09:49,291 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.433827044069767, 'Total loss': 0.433827044069767} | train loss {'Reaction outcome loss': 0.25651507516684086, 'Total loss': 0.25651507516684086}
2023-01-04 11:09:49,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:49,291 INFO:     Epoch: 95
2023-01-04 11:09:50,887 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43681628902753195, 'Total loss': 0.43681628902753195} | train loss {'Reaction outcome loss': 0.24897725424235048, 'Total loss': 0.24897725424235048}
2023-01-04 11:09:50,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:50,888 INFO:     Epoch: 96
2023-01-04 11:09:52,458 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.418460613489151, 'Total loss': 0.418460613489151} | train loss {'Reaction outcome loss': 0.24726139895268295, 'Total loss': 0.24726139895268295}
2023-01-04 11:09:52,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:52,458 INFO:     Epoch: 97
2023-01-04 11:09:54,003 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4063594157497088, 'Total loss': 0.4063594157497088} | train loss {'Reaction outcome loss': 0.25077558198560446, 'Total loss': 0.25077558198560446}
2023-01-04 11:09:54,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:54,003 INFO:     Epoch: 98
2023-01-04 11:09:55,600 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3988699624935786, 'Total loss': 0.3988699624935786} | train loss {'Reaction outcome loss': 0.2479675183953576, 'Total loss': 0.2479675183953576}
2023-01-04 11:09:55,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:55,600 INFO:     Epoch: 99
2023-01-04 11:09:57,140 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4159626225630442, 'Total loss': 0.4159626225630442} | train loss {'Reaction outcome loss': 0.2492170101737718, 'Total loss': 0.2492170101737718}
2023-01-04 11:09:57,141 INFO:     Best model found after epoch 82 of 100.
2023-01-04 11:09:57,141 INFO:   Done with stage: TRAINING
2023-01-04 11:09:57,141 INFO:   Starting stage: EVALUATION
2023-01-04 11:09:57,263 INFO:   Done with stage: EVALUATION
2023-01-04 11:09:57,263 INFO:   Leaving out SEQ value Fold_8
2023-01-04 11:09:57,275 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 11:09:57,275 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:09:57,913 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:09:57,913 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:09:57,980 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:09:57,980 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:09:57,980 INFO:     No hyperparam tuning for this model
2023-01-04 11:09:57,980 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:09:57,980 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:09:57,981 INFO:     None feature selector for col prot
2023-01-04 11:09:57,981 INFO:     None feature selector for col prot
2023-01-04 11:09:57,981 INFO:     None feature selector for col prot
2023-01-04 11:09:57,981 INFO:     None feature selector for col chem
2023-01-04 11:09:57,981 INFO:     None feature selector for col chem
2023-01-04 11:09:57,982 INFO:     None feature selector for col chem
2023-01-04 11:09:57,982 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:09:57,982 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:09:57,983 INFO:     Number of params in model 70111
2023-01-04 11:09:57,986 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:09:57,986 INFO:   Starting stage: TRAINING
2023-01-04 11:09:58,027 INFO:     Val loss before train {'Reaction outcome loss': 1.1000585039456685, 'Total loss': 1.1000585039456685}
2023-01-04 11:09:58,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:58,028 INFO:     Epoch: 0
2023-01-04 11:09:59,598 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8025147994359334, 'Total loss': 0.8025147994359334} | train loss {'Reaction outcome loss': 0.8429524982280104, 'Total loss': 0.8429524982280104}
2023-01-04 11:09:59,598 INFO:     Found new best model at epoch 0
2023-01-04 11:09:59,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:09:59,599 INFO:     Epoch: 1
2023-01-04 11:10:01,148 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6735560516516368, 'Total loss': 0.6735560516516368} | train loss {'Reaction outcome loss': 0.6826632112047099, 'Total loss': 0.6826632112047099}
2023-01-04 11:10:01,148 INFO:     Found new best model at epoch 1
2023-01-04 11:10:01,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:01,149 INFO:     Epoch: 2
2023-01-04 11:10:02,681 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5911437749862671, 'Total loss': 0.5911437749862671} | train loss {'Reaction outcome loss': 0.5824775742570849, 'Total loss': 0.5824775742570849}
2023-01-04 11:10:02,681 INFO:     Found new best model at epoch 2
2023-01-04 11:10:02,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:02,682 INFO:     Epoch: 3
2023-01-04 11:10:04,232 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5436187903086345, 'Total loss': 0.5436187903086345} | train loss {'Reaction outcome loss': 0.5348231067513898, 'Total loss': 0.5348231067513898}
2023-01-04 11:10:04,232 INFO:     Found new best model at epoch 3
2023-01-04 11:10:04,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:04,233 INFO:     Epoch: 4
2023-01-04 11:10:05,805 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5379312396049499, 'Total loss': 0.5379312396049499} | train loss {'Reaction outcome loss': 0.5127871500423354, 'Total loss': 0.5127871500423354}
2023-01-04 11:10:05,806 INFO:     Found new best model at epoch 4
2023-01-04 11:10:05,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:05,806 INFO:     Epoch: 5
2023-01-04 11:10:07,423 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5419959902763367, 'Total loss': 0.5419959902763367} | train loss {'Reaction outcome loss': 0.4982653926976406, 'Total loss': 0.4982653926976406}
2023-01-04 11:10:07,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:07,423 INFO:     Epoch: 6
2023-01-04 11:10:09,036 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5301449557145437, 'Total loss': 0.5301449557145437} | train loss {'Reaction outcome loss': 0.49092836792234085, 'Total loss': 0.49092836792234085}
2023-01-04 11:10:09,037 INFO:     Found new best model at epoch 6
2023-01-04 11:10:09,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:09,037 INFO:     Epoch: 7
2023-01-04 11:10:10,655 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5452622016270955, 'Total loss': 0.5452622016270955} | train loss {'Reaction outcome loss': 0.47986167712803307, 'Total loss': 0.47986167712803307}
2023-01-04 11:10:10,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:10,656 INFO:     Epoch: 8
2023-01-04 11:10:12,198 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5037943740685781, 'Total loss': 0.5037943740685781} | train loss {'Reaction outcome loss': 0.4769345817230914, 'Total loss': 0.4769345817230914}
2023-01-04 11:10:12,199 INFO:     Found new best model at epoch 8
2023-01-04 11:10:12,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:12,199 INFO:     Epoch: 9
2023-01-04 11:10:13,727 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4910531431436539, 'Total loss': 0.4910531431436539} | train loss {'Reaction outcome loss': 0.46859752104012636, 'Total loss': 0.46859752104012636}
2023-01-04 11:10:13,727 INFO:     Found new best model at epoch 9
2023-01-04 11:10:13,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:13,728 INFO:     Epoch: 10
2023-01-04 11:10:15,272 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49211793740590415, 'Total loss': 0.49211793740590415} | train loss {'Reaction outcome loss': 0.46261634025042947, 'Total loss': 0.46261634025042947}
2023-01-04 11:10:15,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:15,272 INFO:     Epoch: 11
2023-01-04 11:10:16,833 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4977447728315989, 'Total loss': 0.4977447728315989} | train loss {'Reaction outcome loss': 0.46050461501318174, 'Total loss': 0.46050461501318174}
2023-01-04 11:10:16,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:16,834 INFO:     Epoch: 12
2023-01-04 11:10:18,397 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4992591142654419, 'Total loss': 0.4992591142654419} | train loss {'Reaction outcome loss': 0.45324794823018305, 'Total loss': 0.45324794823018305}
2023-01-04 11:10:18,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:18,397 INFO:     Epoch: 13
2023-01-04 11:10:19,951 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4877342124780019, 'Total loss': 0.4877342124780019} | train loss {'Reaction outcome loss': 0.4451843510470251, 'Total loss': 0.4451843510470251}
2023-01-04 11:10:19,951 INFO:     Found new best model at epoch 13
2023-01-04 11:10:19,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:19,952 INFO:     Epoch: 14
2023-01-04 11:10:21,465 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48146401047706605, 'Total loss': 0.48146401047706605} | train loss {'Reaction outcome loss': 0.44803714980609227, 'Total loss': 0.44803714980609227}
2023-01-04 11:10:21,466 INFO:     Found new best model at epoch 14
2023-01-04 11:10:21,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:21,466 INFO:     Epoch: 15
2023-01-04 11:10:22,984 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46140251457691195, 'Total loss': 0.46140251457691195} | train loss {'Reaction outcome loss': 0.440847699442049, 'Total loss': 0.440847699442049}
2023-01-04 11:10:22,984 INFO:     Found new best model at epoch 15
2023-01-04 11:10:22,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:22,984 INFO:     Epoch: 16
2023-01-04 11:10:24,546 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47201007008552553, 'Total loss': 0.47201007008552553} | train loss {'Reaction outcome loss': 0.4389387344139336, 'Total loss': 0.4389387344139336}
2023-01-04 11:10:24,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:24,546 INFO:     Epoch: 17
2023-01-04 11:10:26,123 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.474021178483963, 'Total loss': 0.474021178483963} | train loss {'Reaction outcome loss': 0.4320100023798699, 'Total loss': 0.4320100023798699}
2023-01-04 11:10:26,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:26,124 INFO:     Epoch: 18
2023-01-04 11:10:27,697 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4779133955637614, 'Total loss': 0.4779133955637614} | train loss {'Reaction outcome loss': 0.43185841759843546, 'Total loss': 0.43185841759843546}
2023-01-04 11:10:27,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:27,698 INFO:     Epoch: 19
2023-01-04 11:10:29,270 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4859056989351908, 'Total loss': 0.4859056989351908} | train loss {'Reaction outcome loss': 0.4275479231872698, 'Total loss': 0.4275479231872698}
2023-01-04 11:10:29,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:29,270 INFO:     Epoch: 20
2023-01-04 11:10:30,799 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4632402122020721, 'Total loss': 0.4632402122020721} | train loss {'Reaction outcome loss': 0.4240978898031868, 'Total loss': 0.4240978898031868}
2023-01-04 11:10:30,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:30,799 INFO:     Epoch: 21
2023-01-04 11:10:32,338 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46771396497885387, 'Total loss': 0.46771396497885387} | train loss {'Reaction outcome loss': 0.4211496028260593, 'Total loss': 0.4211496028260593}
2023-01-04 11:10:32,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:32,339 INFO:     Epoch: 22
2023-01-04 11:10:33,899 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45534332990646365, 'Total loss': 0.45534332990646365} | train loss {'Reaction outcome loss': 0.4192866510609641, 'Total loss': 0.4192866510609641}
2023-01-04 11:10:33,899 INFO:     Found new best model at epoch 22
2023-01-04 11:10:33,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:33,900 INFO:     Epoch: 23
2023-01-04 11:10:35,473 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47091408967971804, 'Total loss': 0.47091408967971804} | train loss {'Reaction outcome loss': 0.4154990347523759, 'Total loss': 0.4154990347523759}
2023-01-04 11:10:35,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:35,473 INFO:     Epoch: 24
2023-01-04 11:10:37,039 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4591700494289398, 'Total loss': 0.4591700494289398} | train loss {'Reaction outcome loss': 0.41084256023168564, 'Total loss': 0.41084256023168564}
2023-01-04 11:10:37,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:37,040 INFO:     Epoch: 25
2023-01-04 11:10:38,604 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4707939366499583, 'Total loss': 0.4707939366499583} | train loss {'Reaction outcome loss': 0.4107082306686109, 'Total loss': 0.4107082306686109}
2023-01-04 11:10:38,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:38,604 INFO:     Epoch: 26
2023-01-04 11:10:40,132 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47494740088780724, 'Total loss': 0.47494740088780724} | train loss {'Reaction outcome loss': 0.40540385300660653, 'Total loss': 0.40540385300660653}
2023-01-04 11:10:40,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:40,132 INFO:     Epoch: 27
2023-01-04 11:10:41,662 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46397658785184226, 'Total loss': 0.46397658785184226} | train loss {'Reaction outcome loss': 0.4007785301247652, 'Total loss': 0.4007785301247652}
2023-01-04 11:10:41,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:41,662 INFO:     Epoch: 28
2023-01-04 11:10:43,241 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46208691596984863, 'Total loss': 0.46208691596984863} | train loss {'Reaction outcome loss': 0.40194271148665106, 'Total loss': 0.40194271148665106}
2023-01-04 11:10:43,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:43,241 INFO:     Epoch: 29
2023-01-04 11:10:44,841 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4464603215456009, 'Total loss': 0.4464603215456009} | train loss {'Reaction outcome loss': 0.3972785738262817, 'Total loss': 0.3972785738262817}
2023-01-04 11:10:44,841 INFO:     Found new best model at epoch 29
2023-01-04 11:10:44,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:44,842 INFO:     Epoch: 30
2023-01-04 11:10:46,423 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4460051986078421, 'Total loss': 0.4460051986078421} | train loss {'Reaction outcome loss': 0.39515235226084716, 'Total loss': 0.39515235226084716}
2023-01-04 11:10:46,423 INFO:     Found new best model at epoch 30
2023-01-04 11:10:46,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:46,424 INFO:     Epoch: 31
2023-01-04 11:10:47,983 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.439588463306427, 'Total loss': 0.439588463306427} | train loss {'Reaction outcome loss': 0.3924400054299048, 'Total loss': 0.3924400054299048}
2023-01-04 11:10:47,983 INFO:     Found new best model at epoch 31
2023-01-04 11:10:47,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:47,983 INFO:     Epoch: 32
2023-01-04 11:10:49,561 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4682280739148458, 'Total loss': 0.4682280739148458} | train loss {'Reaction outcome loss': 0.3849702482349681, 'Total loss': 0.3849702482349681}
2023-01-04 11:10:49,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:49,561 INFO:     Epoch: 33
2023-01-04 11:10:51,104 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45509141782919565, 'Total loss': 0.45509141782919565} | train loss {'Reaction outcome loss': 0.3811350649181944, 'Total loss': 0.3811350649181944}
2023-01-04 11:10:51,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:51,104 INFO:     Epoch: 34
2023-01-04 11:10:52,669 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4606080671151479, 'Total loss': 0.4606080671151479} | train loss {'Reaction outcome loss': 0.38294828859885244, 'Total loss': 0.38294828859885244}
2023-01-04 11:10:52,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:52,670 INFO:     Epoch: 35
2023-01-04 11:10:54,270 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44613959987958274, 'Total loss': 0.44613959987958274} | train loss {'Reaction outcome loss': 0.3805324142377307, 'Total loss': 0.3805324142377307}
2023-01-04 11:10:54,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:54,270 INFO:     Epoch: 36
2023-01-04 11:10:55,847 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4475242018699646, 'Total loss': 0.4475242018699646} | train loss {'Reaction outcome loss': 0.3765815750145129, 'Total loss': 0.3765815750145129}
2023-01-04 11:10:55,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:55,847 INFO:     Epoch: 37
2023-01-04 11:10:57,369 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4162690281867981, 'Total loss': 0.4162690281867981} | train loss {'Reaction outcome loss': 0.37275853796596947, 'Total loss': 0.37275853796596947}
2023-01-04 11:10:57,370 INFO:     Found new best model at epoch 37
2023-01-04 11:10:57,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:57,370 INFO:     Epoch: 38
2023-01-04 11:10:58,941 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43749722838401794, 'Total loss': 0.43749722838401794} | train loss {'Reaction outcome loss': 0.3698800462468045, 'Total loss': 0.3698800462468045}
2023-01-04 11:10:58,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:10:58,942 INFO:     Epoch: 39
2023-01-04 11:11:00,468 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47437398235003153, 'Total loss': 0.47437398235003153} | train loss {'Reaction outcome loss': 0.36695439036745225, 'Total loss': 0.36695439036745225}
2023-01-04 11:11:00,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:00,469 INFO:     Epoch: 40
2023-01-04 11:11:02,044 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4568824032942454, 'Total loss': 0.4568824032942454} | train loss {'Reaction outcome loss': 0.3643644018928065, 'Total loss': 0.3643644018928065}
2023-01-04 11:11:02,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:02,046 INFO:     Epoch: 41
2023-01-04 11:11:03,620 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42322209974129993, 'Total loss': 0.42322209974129993} | train loss {'Reaction outcome loss': 0.36197396367788315, 'Total loss': 0.36197396367788315}
2023-01-04 11:11:03,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:03,620 INFO:     Epoch: 42
2023-01-04 11:11:05,179 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41332213481267294, 'Total loss': 0.41332213481267294} | train loss {'Reaction outcome loss': 0.3594900729393002, 'Total loss': 0.3594900729393002}
2023-01-04 11:11:05,179 INFO:     Found new best model at epoch 42
2023-01-04 11:11:05,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:05,180 INFO:     Epoch: 43
2023-01-04 11:11:06,697 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43313139577706655, 'Total loss': 0.43313139577706655} | train loss {'Reaction outcome loss': 0.3568093054757936, 'Total loss': 0.3568093054757936}
2023-01-04 11:11:06,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:06,697 INFO:     Epoch: 44
2023-01-04 11:11:08,253 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4348368108272552, 'Total loss': 0.4348368108272552} | train loss {'Reaction outcome loss': 0.35251256219879556, 'Total loss': 0.35251256219879556}
2023-01-04 11:11:08,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:08,253 INFO:     Epoch: 45
2023-01-04 11:11:09,808 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4148942659298579, 'Total loss': 0.4148942659298579} | train loss {'Reaction outcome loss': 0.3531799224225709, 'Total loss': 0.3531799224225709}
2023-01-04 11:11:09,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:09,808 INFO:     Epoch: 46
2023-01-04 11:11:11,367 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4476808488368988, 'Total loss': 0.4476808488368988} | train loss {'Reaction outcome loss': 0.34613522654739176, 'Total loss': 0.34613522654739176}
2023-01-04 11:11:11,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:11,367 INFO:     Epoch: 47
2023-01-04 11:11:12,918 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44007296562194825, 'Total loss': 0.44007296562194825} | train loss {'Reaction outcome loss': 0.34437819577100937, 'Total loss': 0.34437819577100937}
2023-01-04 11:11:12,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:12,918 INFO:     Epoch: 48
2023-01-04 11:11:14,485 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4224116921424866, 'Total loss': 0.4224116921424866} | train loss {'Reaction outcome loss': 0.3478978985961336, 'Total loss': 0.3478978985961336}
2023-01-04 11:11:14,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:14,485 INFO:     Epoch: 49
2023-01-04 11:11:16,009 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42125688095887504, 'Total loss': 0.42125688095887504} | train loss {'Reaction outcome loss': 0.34300989184501396, 'Total loss': 0.34300989184501396}
2023-01-04 11:11:16,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:16,009 INFO:     Epoch: 50
2023-01-04 11:11:17,527 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4254650861024857, 'Total loss': 0.4254650861024857} | train loss {'Reaction outcome loss': 0.3408424850607658, 'Total loss': 0.3408424850607658}
2023-01-04 11:11:17,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:17,528 INFO:     Epoch: 51
2023-01-04 11:11:19,095 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4338026056687037, 'Total loss': 0.4338026056687037} | train loss {'Reaction outcome loss': 0.34272486379329303, 'Total loss': 0.34272486379329303}
2023-01-04 11:11:19,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:19,095 INFO:     Epoch: 52
2023-01-04 11:11:20,662 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.423075004418691, 'Total loss': 0.423075004418691} | train loss {'Reaction outcome loss': 0.3334859600086717, 'Total loss': 0.3334859600086717}
2023-01-04 11:11:20,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:20,662 INFO:     Epoch: 53
2023-01-04 11:11:22,220 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42408546010653175, 'Total loss': 0.42408546010653175} | train loss {'Reaction outcome loss': 0.33329779418171757, 'Total loss': 0.33329779418171757}
2023-01-04 11:11:22,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:22,220 INFO:     Epoch: 54
2023-01-04 11:11:23,792 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4262509783109029, 'Total loss': 0.4262509783109029} | train loss {'Reaction outcome loss': 0.3367457771605819, 'Total loss': 0.3367457771605819}
2023-01-04 11:11:23,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:23,792 INFO:     Epoch: 55
2023-01-04 11:11:25,329 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4688522477944692, 'Total loss': 0.4688522477944692} | train loss {'Reaction outcome loss': 0.32973000113546413, 'Total loss': 0.32973000113546413}
2023-01-04 11:11:25,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:25,330 INFO:     Epoch: 56
2023-01-04 11:11:26,874 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44615665475527444, 'Total loss': 0.44615665475527444} | train loss {'Reaction outcome loss': 0.329648625758225, 'Total loss': 0.329648625758225}
2023-01-04 11:11:26,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:26,874 INFO:     Epoch: 57
2023-01-04 11:11:28,479 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42235022485256196, 'Total loss': 0.42235022485256196} | train loss {'Reaction outcome loss': 0.32525457137257513, 'Total loss': 0.32525457137257513}
2023-01-04 11:11:28,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:28,479 INFO:     Epoch: 58
2023-01-04 11:11:30,063 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4295328120390574, 'Total loss': 0.4295328120390574} | train loss {'Reaction outcome loss': 0.3229795876536926, 'Total loss': 0.3229795876536926}
2023-01-04 11:11:30,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:30,064 INFO:     Epoch: 59
2023-01-04 11:11:31,663 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43119956701993944, 'Total loss': 0.43119956701993944} | train loss {'Reaction outcome loss': 0.3266371589453116, 'Total loss': 0.3266371589453116}
2023-01-04 11:11:31,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:31,664 INFO:     Epoch: 60
2023-01-04 11:11:33,250 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4324166158835093, 'Total loss': 0.4324166158835093} | train loss {'Reaction outcome loss': 0.3218398886277293, 'Total loss': 0.3218398886277293}
2023-01-04 11:11:33,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:33,251 INFO:     Epoch: 61
2023-01-04 11:11:34,824 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4463503817717234, 'Total loss': 0.4463503817717234} | train loss {'Reaction outcome loss': 0.32107916534164527, 'Total loss': 0.32107916534164527}
2023-01-04 11:11:34,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:34,824 INFO:     Epoch: 62
2023-01-04 11:11:36,382 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43282168408234917, 'Total loss': 0.43282168408234917} | train loss {'Reaction outcome loss': 0.31719403988579764, 'Total loss': 0.31719403988579764}
2023-01-04 11:11:36,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:36,382 INFO:     Epoch: 63
2023-01-04 11:11:37,936 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4411192317803701, 'Total loss': 0.4411192317803701} | train loss {'Reaction outcome loss': 0.31447909716652694, 'Total loss': 0.31447909716652694}
2023-01-04 11:11:37,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:37,938 INFO:     Epoch: 64
2023-01-04 11:11:39,455 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42278326451778414, 'Total loss': 0.42278326451778414} | train loss {'Reaction outcome loss': 0.31388907591356846, 'Total loss': 0.31388907591356846}
2023-01-04 11:11:39,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:39,455 INFO:     Epoch: 65
2023-01-04 11:11:40,960 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44626445571581524, 'Total loss': 0.44626445571581524} | train loss {'Reaction outcome loss': 0.3135912856426987, 'Total loss': 0.3135912856426987}
2023-01-04 11:11:40,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:40,961 INFO:     Epoch: 66
2023-01-04 11:11:42,482 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4535448342561722, 'Total loss': 0.4535448342561722} | train loss {'Reaction outcome loss': 0.3093993594856375, 'Total loss': 0.3093993594856375}
2023-01-04 11:11:42,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:42,482 INFO:     Epoch: 67
2023-01-04 11:11:43,951 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4290486415227254, 'Total loss': 0.4290486415227254} | train loss {'Reaction outcome loss': 0.3137190177982306, 'Total loss': 0.3137190177982306}
2023-01-04 11:11:43,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:43,952 INFO:     Epoch: 68
2023-01-04 11:11:45,430 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4191251561045647, 'Total loss': 0.4191251561045647} | train loss {'Reaction outcome loss': 0.3079020312722147, 'Total loss': 0.3079020312722147}
2023-01-04 11:11:45,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:45,430 INFO:     Epoch: 69
2023-01-04 11:11:46,964 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43302967051664987, 'Total loss': 0.43302967051664987} | train loss {'Reaction outcome loss': 0.3067086603574074, 'Total loss': 0.3067086603574074}
2023-01-04 11:11:46,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:46,964 INFO:     Epoch: 70
2023-01-04 11:11:48,525 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45589276353518166, 'Total loss': 0.45589276353518166} | train loss {'Reaction outcome loss': 0.30530506119567113, 'Total loss': 0.30530506119567113}
2023-01-04 11:11:48,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:48,526 INFO:     Epoch: 71
2023-01-04 11:11:50,098 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43671429554621377, 'Total loss': 0.43671429554621377} | train loss {'Reaction outcome loss': 0.30329320538979376, 'Total loss': 0.30329320538979376}
2023-01-04 11:11:50,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:50,099 INFO:     Epoch: 72
2023-01-04 11:11:51,653 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40846065481503807, 'Total loss': 0.40846065481503807} | train loss {'Reaction outcome loss': 0.30009840227609136, 'Total loss': 0.30009840227609136}
2023-01-04 11:11:51,654 INFO:     Found new best model at epoch 72
2023-01-04 11:11:51,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:51,654 INFO:     Epoch: 73
2023-01-04 11:11:53,173 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42261228362719216, 'Total loss': 0.42261228362719216} | train loss {'Reaction outcome loss': 0.29882633264591224, 'Total loss': 0.29882633264591224}
2023-01-04 11:11:53,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:53,174 INFO:     Epoch: 74
2023-01-04 11:11:54,716 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4336189925670624, 'Total loss': 0.4336189925670624} | train loss {'Reaction outcome loss': 0.30073518297859353, 'Total loss': 0.30073518297859353}
2023-01-04 11:11:54,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:54,716 INFO:     Epoch: 75
2023-01-04 11:11:56,312 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44167693157990773, 'Total loss': 0.44167693157990773} | train loss {'Reaction outcome loss': 0.29595144723888733, 'Total loss': 0.29595144723888733}
2023-01-04 11:11:56,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:56,313 INFO:     Epoch: 76
2023-01-04 11:11:57,917 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42531144320964814, 'Total loss': 0.42531144320964814} | train loss {'Reaction outcome loss': 0.29606376697112174, 'Total loss': 0.29606376697112174}
2023-01-04 11:11:57,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:57,917 INFO:     Epoch: 77
2023-01-04 11:11:59,521 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4472916305065155, 'Total loss': 0.4472916305065155} | train loss {'Reaction outcome loss': 0.2946044146253245, 'Total loss': 0.2946044146253245}
2023-01-04 11:11:59,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:11:59,521 INFO:     Epoch: 78
2023-01-04 11:12:01,093 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46281417409578957, 'Total loss': 0.46281417409578957} | train loss {'Reaction outcome loss': 0.297243291960798, 'Total loss': 0.297243291960798}
2023-01-04 11:12:01,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:01,093 INFO:     Epoch: 79
2023-01-04 11:12:02,680 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4082884122927984, 'Total loss': 0.4082884122927984} | train loss {'Reaction outcome loss': 0.29031065408221995, 'Total loss': 0.29031065408221995}
2023-01-04 11:12:02,680 INFO:     Found new best model at epoch 79
2023-01-04 11:12:02,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:02,681 INFO:     Epoch: 80
2023-01-04 11:12:04,248 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3926621158917745, 'Total loss': 0.3926621158917745} | train loss {'Reaction outcome loss': 0.2922276411287106, 'Total loss': 0.2922276411287106}
2023-01-04 11:12:04,248 INFO:     Found new best model at epoch 80
2023-01-04 11:12:04,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:04,249 INFO:     Epoch: 81
2023-01-04 11:12:05,855 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4380566755930583, 'Total loss': 0.4380566755930583} | train loss {'Reaction outcome loss': 0.28946406460863394, 'Total loss': 0.28946406460863394}
2023-01-04 11:12:05,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:05,855 INFO:     Epoch: 82
2023-01-04 11:12:07,445 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4345240900913874, 'Total loss': 0.4345240900913874} | train loss {'Reaction outcome loss': 0.28931151953165546, 'Total loss': 0.28931151953165546}
2023-01-04 11:12:07,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:07,445 INFO:     Epoch: 83
2023-01-04 11:12:09,060 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4546858201424281, 'Total loss': 0.4546858201424281} | train loss {'Reaction outcome loss': 0.28799098171293736, 'Total loss': 0.28799098171293736}
2023-01-04 11:12:09,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:09,060 INFO:     Epoch: 84
2023-01-04 11:12:10,621 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4347238490978877, 'Total loss': 0.4347238490978877} | train loss {'Reaction outcome loss': 0.28704745890776606, 'Total loss': 0.28704745890776606}
2023-01-04 11:12:10,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:10,621 INFO:     Epoch: 85
2023-01-04 11:12:12,187 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4283450881640116, 'Total loss': 0.4283450881640116} | train loss {'Reaction outcome loss': 0.2838655580786893, 'Total loss': 0.2838655580786893}
2023-01-04 11:12:12,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:12,187 INFO:     Epoch: 86
2023-01-04 11:12:13,755 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4532401571671168, 'Total loss': 0.4532401571671168} | train loss {'Reaction outcome loss': 0.28532551114794114, 'Total loss': 0.28532551114794114}
2023-01-04 11:12:13,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:13,757 INFO:     Epoch: 87
2023-01-04 11:12:15,366 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43270054658253987, 'Total loss': 0.43270054658253987} | train loss {'Reaction outcome loss': 0.282973567119045, 'Total loss': 0.282973567119045}
2023-01-04 11:12:15,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:15,366 INFO:     Epoch: 88
2023-01-04 11:12:16,971 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4183356742064158, 'Total loss': 0.4183356742064158} | train loss {'Reaction outcome loss': 0.2867964397381692, 'Total loss': 0.2867964397381692}
2023-01-04 11:12:16,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:16,971 INFO:     Epoch: 89
2023-01-04 11:12:18,534 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41696102966864906, 'Total loss': 0.41696102966864906} | train loss {'Reaction outcome loss': 0.28443071735601355, 'Total loss': 0.28443071735601355}
2023-01-04 11:12:18,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:18,534 INFO:     Epoch: 90
2023-01-04 11:12:20,106 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4213088889916738, 'Total loss': 0.4213088889916738} | train loss {'Reaction outcome loss': 0.2797968388963355, 'Total loss': 0.2797968388963355}
2023-01-04 11:12:20,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:20,107 INFO:     Epoch: 91
2023-01-04 11:12:21,681 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4735794226328532, 'Total loss': 0.4735794226328532} | train loss {'Reaction outcome loss': 0.2809409368647276, 'Total loss': 0.2809409368647276}
2023-01-04 11:12:21,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:21,681 INFO:     Epoch: 92
2023-01-04 11:12:23,299 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4075535277525584, 'Total loss': 0.4075535277525584} | train loss {'Reaction outcome loss': 0.28076588419558357, 'Total loss': 0.28076588419558357}
2023-01-04 11:12:23,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:23,299 INFO:     Epoch: 93
2023-01-04 11:12:24,918 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44023856123288474, 'Total loss': 0.44023856123288474} | train loss {'Reaction outcome loss': 0.2764076553964919, 'Total loss': 0.2764076553964919}
2023-01-04 11:12:24,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:24,919 INFO:     Epoch: 94
2023-01-04 11:12:26,538 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41325562745332717, 'Total loss': 0.41325562745332717} | train loss {'Reaction outcome loss': 0.2812030412746172, 'Total loss': 0.2812030412746172}
2023-01-04 11:12:26,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:26,538 INFO:     Epoch: 95
2023-01-04 11:12:28,150 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4154051939646403, 'Total loss': 0.4154051939646403} | train loss {'Reaction outcome loss': 0.2737520200737419, 'Total loss': 0.2737520200737419}
2023-01-04 11:12:28,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:28,150 INFO:     Epoch: 96
2023-01-04 11:12:29,689 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4101170609394709, 'Total loss': 0.4101170609394709} | train loss {'Reaction outcome loss': 0.27684180158441957, 'Total loss': 0.27684180158441957}
2023-01-04 11:12:29,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:29,690 INFO:     Epoch: 97
2023-01-04 11:12:31,217 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3989488144715627, 'Total loss': 0.3989488144715627} | train loss {'Reaction outcome loss': 0.2775827419067169, 'Total loss': 0.2775827419067169}
2023-01-04 11:12:31,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:31,217 INFO:     Epoch: 98
2023-01-04 11:12:32,763 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40693421959877013, 'Total loss': 0.40693421959877013} | train loss {'Reaction outcome loss': 0.26994298144250456, 'Total loss': 0.26994298144250456}
2023-01-04 11:12:32,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:32,764 INFO:     Epoch: 99
2023-01-04 11:12:34,320 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4113359565536181, 'Total loss': 0.4113359565536181} | train loss {'Reaction outcome loss': 0.2723276433093052, 'Total loss': 0.2723276433093052}
2023-01-04 11:12:34,320 INFO:     Best model found after epoch 81 of 100.
2023-01-04 11:12:34,320 INFO:   Done with stage: TRAINING
2023-01-04 11:12:34,320 INFO:   Starting stage: EVALUATION
2023-01-04 11:12:34,454 INFO:   Done with stage: EVALUATION
2023-01-04 11:12:34,454 INFO:   Leaving out SEQ value Fold_9
2023-01-04 11:12:34,467 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 11:12:34,467 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:12:35,113 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:12:35,113 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:12:35,181 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:12:35,181 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:12:35,181 INFO:     No hyperparam tuning for this model
2023-01-04 11:12:35,181 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:12:35,181 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:12:35,182 INFO:     None feature selector for col prot
2023-01-04 11:12:35,182 INFO:     None feature selector for col prot
2023-01-04 11:12:35,182 INFO:     None feature selector for col prot
2023-01-04 11:12:35,183 INFO:     None feature selector for col chem
2023-01-04 11:12:35,183 INFO:     None feature selector for col chem
2023-01-04 11:12:35,183 INFO:     None feature selector for col chem
2023-01-04 11:12:35,183 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:12:35,183 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:12:35,184 INFO:     Number of params in model 70111
2023-01-04 11:12:35,187 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:12:35,187 INFO:   Starting stage: TRAINING
2023-01-04 11:12:35,230 INFO:     Val loss before train {'Reaction outcome loss': 1.0623085141181945, 'Total loss': 1.0623085141181945}
2023-01-04 11:12:35,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:35,230 INFO:     Epoch: 0
2023-01-04 11:12:36,801 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7549967209498087, 'Total loss': 0.7549967209498087} | train loss {'Reaction outcome loss': 0.8391451773544153, 'Total loss': 0.8391451773544153}
2023-01-04 11:12:36,801 INFO:     Found new best model at epoch 0
2023-01-04 11:12:36,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:36,802 INFO:     Epoch: 1
2023-01-04 11:12:38,350 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6248488227526346, 'Total loss': 0.6248488227526346} | train loss {'Reaction outcome loss': 0.6642186720518098, 'Total loss': 0.6642186720518098}
2023-01-04 11:12:38,350 INFO:     Found new best model at epoch 1
2023-01-04 11:12:38,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:38,351 INFO:     Epoch: 2
2023-01-04 11:12:39,885 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.582656729221344, 'Total loss': 0.582656729221344} | train loss {'Reaction outcome loss': 0.5671915807693765, 'Total loss': 0.5671915807693765}
2023-01-04 11:12:39,885 INFO:     Found new best model at epoch 2
2023-01-04 11:12:39,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:39,886 INFO:     Epoch: 3
2023-01-04 11:12:41,465 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5393435994784037, 'Total loss': 0.5393435994784037} | train loss {'Reaction outcome loss': 0.5253542287230801, 'Total loss': 0.5253542287230801}
2023-01-04 11:12:41,465 INFO:     Found new best model at epoch 3
2023-01-04 11:12:41,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:41,466 INFO:     Epoch: 4
2023-01-04 11:12:43,046 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5604115744431813, 'Total loss': 0.5604115744431813} | train loss {'Reaction outcome loss': 0.5079181901165757, 'Total loss': 0.5079181901165757}
2023-01-04 11:12:43,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:43,046 INFO:     Epoch: 5
2023-01-04 11:12:44,624 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5509986033042272, 'Total loss': 0.5509986033042272} | train loss {'Reaction outcome loss': 0.4938120791229649, 'Total loss': 0.4938120791229649}
2023-01-04 11:12:44,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:44,624 INFO:     Epoch: 6
2023-01-04 11:12:46,164 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5420262296994527, 'Total loss': 0.5420262296994527} | train loss {'Reaction outcome loss': 0.49161256042619544, 'Total loss': 0.49161256042619544}
2023-01-04 11:12:46,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:46,164 INFO:     Epoch: 7
2023-01-04 11:12:47,751 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5578172067801158, 'Total loss': 0.5578172067801158} | train loss {'Reaction outcome loss': 0.4745705234615699, 'Total loss': 0.4745705234615699}
2023-01-04 11:12:47,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:47,751 INFO:     Epoch: 8
2023-01-04 11:12:49,301 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5283383905887604, 'Total loss': 0.5283383905887604} | train loss {'Reaction outcome loss': 0.47095337131506076, 'Total loss': 0.47095337131506076}
2023-01-04 11:12:49,302 INFO:     Found new best model at epoch 8
2023-01-04 11:12:49,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:49,303 INFO:     Epoch: 9
2023-01-04 11:12:50,903 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4956201195716858, 'Total loss': 0.4956201195716858} | train loss {'Reaction outcome loss': 0.45988605816281686, 'Total loss': 0.45988605816281686}
2023-01-04 11:12:50,903 INFO:     Found new best model at epoch 9
2023-01-04 11:12:50,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:50,904 INFO:     Epoch: 10
2023-01-04 11:12:52,510 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5132397641738256, 'Total loss': 0.5132397641738256} | train loss {'Reaction outcome loss': 0.4559658782202623, 'Total loss': 0.4559658782202623}
2023-01-04 11:12:52,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:52,510 INFO:     Epoch: 11
2023-01-04 11:12:54,082 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49880178868770597, 'Total loss': 0.49880178868770597} | train loss {'Reaction outcome loss': 0.4515979866888644, 'Total loss': 0.4515979866888644}
2023-01-04 11:12:54,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:54,083 INFO:     Epoch: 12
2023-01-04 11:12:55,627 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5166439294815064, 'Total loss': 0.5166439294815064} | train loss {'Reaction outcome loss': 0.4562876431298429, 'Total loss': 0.4562876431298429}
2023-01-04 11:12:55,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:55,628 INFO:     Epoch: 13
2023-01-04 11:12:57,229 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48316232562065126, 'Total loss': 0.48316232562065126} | train loss {'Reaction outcome loss': 0.44741020182930474, 'Total loss': 0.44741020182930474}
2023-01-04 11:12:57,229 INFO:     Found new best model at epoch 13
2023-01-04 11:12:57,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:57,230 INFO:     Epoch: 14
2023-01-04 11:12:58,804 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4873503863811493, 'Total loss': 0.4873503863811493} | train loss {'Reaction outcome loss': 0.44035583923138893, 'Total loss': 0.44035583923138893}
2023-01-04 11:12:58,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:12:58,804 INFO:     Epoch: 15
2023-01-04 11:13:00,386 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4893308222293854, 'Total loss': 0.4893308222293854} | train loss {'Reaction outcome loss': 0.4334917012062194, 'Total loss': 0.4334917012062194}
2023-01-04 11:13:00,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:00,386 INFO:     Epoch: 16
2023-01-04 11:13:01,983 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5142530163129171, 'Total loss': 0.5142530163129171} | train loss {'Reaction outcome loss': 0.4296957286930157, 'Total loss': 0.4296957286930157}
2023-01-04 11:13:01,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:01,983 INFO:     Epoch: 17
2023-01-04 11:13:03,567 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4905566612879435, 'Total loss': 0.4905566612879435} | train loss {'Reaction outcome loss': 0.4234034399218533, 'Total loss': 0.4234034399218533}
2023-01-04 11:13:03,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:03,567 INFO:     Epoch: 18
2023-01-04 11:13:05,115 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5010683019955953, 'Total loss': 0.5010683019955953} | train loss {'Reaction outcome loss': 0.42111906015138695, 'Total loss': 0.42111906015138695}
2023-01-04 11:13:05,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:05,115 INFO:     Epoch: 19
2023-01-04 11:13:06,658 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5021427969137827, 'Total loss': 0.5021427969137827} | train loss {'Reaction outcome loss': 0.4249769657634307, 'Total loss': 0.4249769657634307}
2023-01-04 11:13:06,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:06,658 INFO:     Epoch: 20
2023-01-04 11:13:08,245 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4946882685025533, 'Total loss': 0.4946882685025533} | train loss {'Reaction outcome loss': 0.41301299354096915, 'Total loss': 0.41301299354096915}
2023-01-04 11:13:08,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:08,246 INFO:     Epoch: 21
2023-01-04 11:13:09,828 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4984408636887868, 'Total loss': 0.4984408636887868} | train loss {'Reaction outcome loss': 0.40551858737497876, 'Total loss': 0.40551858737497876}
2023-01-04 11:13:09,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:09,828 INFO:     Epoch: 22
2023-01-04 11:13:11,428 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4639388879140218, 'Total loss': 0.4639388879140218} | train loss {'Reaction outcome loss': 0.4039222122224021, 'Total loss': 0.4039222122224021}
2023-01-04 11:13:11,428 INFO:     Found new best model at epoch 22
2023-01-04 11:13:11,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:11,429 INFO:     Epoch: 23
2023-01-04 11:13:13,008 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5045596837997437, 'Total loss': 0.5045596837997437} | train loss {'Reaction outcome loss': 0.39705608751408866, 'Total loss': 0.39705608751408866}
2023-01-04 11:13:13,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:13,008 INFO:     Epoch: 24
2023-01-04 11:13:14,559 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.49888219833374026, 'Total loss': 0.49888219833374026} | train loss {'Reaction outcome loss': 0.3984430118099503, 'Total loss': 0.3984430118099503}
2023-01-04 11:13:14,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:14,559 INFO:     Epoch: 25
2023-01-04 11:13:15,977 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4624489506085714, 'Total loss': 0.4624489506085714} | train loss {'Reaction outcome loss': 0.40183611659576063, 'Total loss': 0.40183611659576063}
2023-01-04 11:13:15,978 INFO:     Found new best model at epoch 25
2023-01-04 11:13:15,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:15,978 INFO:     Epoch: 26
2023-01-04 11:13:16,995 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47592995564142865, 'Total loss': 0.47592995564142865} | train loss {'Reaction outcome loss': 0.40716855392615864, 'Total loss': 0.40716855392615864}
2023-01-04 11:13:16,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:16,996 INFO:     Epoch: 27
2023-01-04 11:13:18,008 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.473679780960083, 'Total loss': 0.473679780960083} | train loss {'Reaction outcome loss': 0.39522645206458645, 'Total loss': 0.39522645206458645}
2023-01-04 11:13:18,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:18,008 INFO:     Epoch: 28
2023-01-04 11:13:19,025 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4511291652917862, 'Total loss': 0.4511291652917862} | train loss {'Reaction outcome loss': 0.3779823634827483, 'Total loss': 0.3779823634827483}
2023-01-04 11:13:19,025 INFO:     Found new best model at epoch 28
2023-01-04 11:13:19,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:19,026 INFO:     Epoch: 29
2023-01-04 11:13:20,044 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49196888903776803, 'Total loss': 0.49196888903776803} | train loss {'Reaction outcome loss': 0.3746057856414141, 'Total loss': 0.3746057856414141}
2023-01-04 11:13:20,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:20,045 INFO:     Epoch: 30
2023-01-04 11:13:21,656 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46333917876084646, 'Total loss': 0.46333917876084646} | train loss {'Reaction outcome loss': 0.37312744498468825, 'Total loss': 0.37312744498468825}
2023-01-04 11:13:21,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:21,656 INFO:     Epoch: 31
2023-01-04 11:13:23,271 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47804628908634184, 'Total loss': 0.47804628908634184} | train loss {'Reaction outcome loss': 0.3700786191376223, 'Total loss': 0.3700786191376223}
2023-01-04 11:13:23,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:23,271 INFO:     Epoch: 32
2023-01-04 11:13:24,868 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45570232371489205, 'Total loss': 0.45570232371489205} | train loss {'Reaction outcome loss': 0.3839581201419882, 'Total loss': 0.3839581201419882}
2023-01-04 11:13:24,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:24,868 INFO:     Epoch: 33
2023-01-04 11:13:26,485 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4541377305984497, 'Total loss': 0.4541377305984497} | train loss {'Reaction outcome loss': 0.38455663456757, 'Total loss': 0.38455663456757}
2023-01-04 11:13:26,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:26,486 INFO:     Epoch: 34
2023-01-04 11:13:28,071 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4472690323988597, 'Total loss': 0.4472690323988597} | train loss {'Reaction outcome loss': 0.3665693271365287, 'Total loss': 0.3665693271365287}
2023-01-04 11:13:28,071 INFO:     Found new best model at epoch 34
2023-01-04 11:13:28,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:28,072 INFO:     Epoch: 35
2023-01-04 11:13:29,566 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45444869498411816, 'Total loss': 0.45444869498411816} | train loss {'Reaction outcome loss': 0.36997132643085456, 'Total loss': 0.36997132643085456}
2023-01-04 11:13:29,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:29,566 INFO:     Epoch: 36
2023-01-04 11:13:31,197 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4400017241636912, 'Total loss': 0.4400017241636912} | train loss {'Reaction outcome loss': 0.3577866993196633, 'Total loss': 0.3577866993196633}
2023-01-04 11:13:31,197 INFO:     Found new best model at epoch 36
2023-01-04 11:13:31,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:31,198 INFO:     Epoch: 37
2023-01-04 11:13:32,818 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4713786467909813, 'Total loss': 0.4713786467909813} | train loss {'Reaction outcome loss': 0.36186929157449177, 'Total loss': 0.36186929157449177}
2023-01-04 11:13:32,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:32,818 INFO:     Epoch: 38
2023-01-04 11:13:34,451 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5273838798205058, 'Total loss': 0.5273838798205058} | train loss {'Reaction outcome loss': 0.35872589404006366, 'Total loss': 0.35872589404006366}
2023-01-04 11:13:34,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:34,451 INFO:     Epoch: 39
2023-01-04 11:13:36,065 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4559564491113027, 'Total loss': 0.4559564491113027} | train loss {'Reaction outcome loss': 0.3752718155434274, 'Total loss': 0.3752718155434274}
2023-01-04 11:13:36,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:36,065 INFO:     Epoch: 40
2023-01-04 11:13:37,691 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4416954775651296, 'Total loss': 0.4416954775651296} | train loss {'Reaction outcome loss': 0.34457333509445837, 'Total loss': 0.34457333509445837}
2023-01-04 11:13:37,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:37,691 INFO:     Epoch: 41
2023-01-04 11:13:39,186 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4249299267927806, 'Total loss': 0.4249299267927806} | train loss {'Reaction outcome loss': 0.3465370660026868, 'Total loss': 0.3465370660026868}
2023-01-04 11:13:39,187 INFO:     Found new best model at epoch 41
2023-01-04 11:13:39,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:39,188 INFO:     Epoch: 42
2023-01-04 11:13:40,816 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45750927925109863, 'Total loss': 0.45750927925109863} | train loss {'Reaction outcome loss': 0.342591338458579, 'Total loss': 0.342591338458579}
2023-01-04 11:13:40,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:40,816 INFO:     Epoch: 43
2023-01-04 11:13:42,456 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4463176856438319, 'Total loss': 0.4463176856438319} | train loss {'Reaction outcome loss': 0.3398032780926413, 'Total loss': 0.3398032780926413}
2023-01-04 11:13:42,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:42,456 INFO:     Epoch: 44
2023-01-04 11:13:44,094 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4192329585552216, 'Total loss': 0.4192329585552216} | train loss {'Reaction outcome loss': 0.33328951279079355, 'Total loss': 0.33328951279079355}
2023-01-04 11:13:44,094 INFO:     Found new best model at epoch 44
2023-01-04 11:13:44,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:44,095 INFO:     Epoch: 45
2023-01-04 11:13:45,725 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45893207291762034, 'Total loss': 0.45893207291762034} | train loss {'Reaction outcome loss': 0.3380367295897525, 'Total loss': 0.3380367295897525}
2023-01-04 11:13:45,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:45,725 INFO:     Epoch: 46
2023-01-04 11:13:47,303 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4475714286168416, 'Total loss': 0.4475714286168416} | train loss {'Reaction outcome loss': 0.35546086996918597, 'Total loss': 0.35546086996918597}
2023-01-04 11:13:47,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:47,303 INFO:     Epoch: 47
2023-01-04 11:13:48,891 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46197775105635325, 'Total loss': 0.46197775105635325} | train loss {'Reaction outcome loss': 0.336501136854075, 'Total loss': 0.336501136854075}
2023-01-04 11:13:48,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:48,891 INFO:     Epoch: 48
2023-01-04 11:13:50,524 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4393012285232544, 'Total loss': 0.4393012285232544} | train loss {'Reaction outcome loss': 0.3469121773976941, 'Total loss': 0.3469121773976941}
2023-01-04 11:13:50,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:50,525 INFO:     Epoch: 49
2023-01-04 11:13:52,158 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4446075399716695, 'Total loss': 0.4446075399716695} | train loss {'Reaction outcome loss': 0.3302303872443598, 'Total loss': 0.3302303872443598}
2023-01-04 11:13:52,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:52,159 INFO:     Epoch: 50
2023-01-04 11:13:53,794 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44412281513214114, 'Total loss': 0.44412281513214114} | train loss {'Reaction outcome loss': 0.3257368607868346, 'Total loss': 0.3257368607868346}
2023-01-04 11:13:53,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:53,794 INFO:     Epoch: 51
2023-01-04 11:13:55,430 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42627669374148053, 'Total loss': 0.42627669374148053} | train loss {'Reaction outcome loss': 0.32053934605927137, 'Total loss': 0.32053934605927137}
2023-01-04 11:13:55,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:55,431 INFO:     Epoch: 52
2023-01-04 11:13:56,939 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4232557058334351, 'Total loss': 0.4232557058334351} | train loss {'Reaction outcome loss': 0.32168034493815206, 'Total loss': 0.32168034493815206}
2023-01-04 11:13:56,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:56,939 INFO:     Epoch: 53
2023-01-04 11:13:58,574 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4457515199979146, 'Total loss': 0.4457515199979146} | train loss {'Reaction outcome loss': 0.3273892494285921, 'Total loss': 0.3273892494285921}
2023-01-04 11:13:58,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:13:58,574 INFO:     Epoch: 54
2023-01-04 11:14:00,210 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4556799590587616, 'Total loss': 0.4556799590587616} | train loss {'Reaction outcome loss': 0.31879684263907804, 'Total loss': 0.31879684263907804}
2023-01-04 11:14:00,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:00,210 INFO:     Epoch: 55
2023-01-04 11:14:01,848 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40610445936520895, 'Total loss': 0.40610445936520895} | train loss {'Reaction outcome loss': 0.3174637201494909, 'Total loss': 0.3174637201494909}
2023-01-04 11:14:01,848 INFO:     Found new best model at epoch 55
2023-01-04 11:14:01,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:01,848 INFO:     Epoch: 56
2023-01-04 11:14:03,478 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44701365927855174, 'Total loss': 0.44701365927855174} | train loss {'Reaction outcome loss': 0.31054631852801295, 'Total loss': 0.31054631852801295}
2023-01-04 11:14:03,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:03,478 INFO:     Epoch: 57
2023-01-04 11:14:05,115 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4474687337875366, 'Total loss': 0.4474687337875366} | train loss {'Reaction outcome loss': 0.30726127350277715, 'Total loss': 0.30726127350277715}
2023-01-04 11:14:05,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:05,115 INFO:     Epoch: 58
2023-01-04 11:14:06,623 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41462156772613523, 'Total loss': 0.41462156772613523} | train loss {'Reaction outcome loss': 0.3093599298280542, 'Total loss': 0.3093599298280542}
2023-01-04 11:14:06,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:06,624 INFO:     Epoch: 59
2023-01-04 11:14:08,253 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45780374805132545, 'Total loss': 0.45780374805132545} | train loss {'Reaction outcome loss': 0.3105813696764518, 'Total loss': 0.3105813696764518}
2023-01-04 11:14:08,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:08,254 INFO:     Epoch: 60
2023-01-04 11:14:09,892 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46291350622971855, 'Total loss': 0.46291350622971855} | train loss {'Reaction outcome loss': 0.3294882207587564, 'Total loss': 0.3294882207587564}
2023-01-04 11:14:09,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:09,893 INFO:     Epoch: 61
2023-01-04 11:14:11,530 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43098587493101753, 'Total loss': 0.43098587493101753} | train loss {'Reaction outcome loss': 0.30812689132796117, 'Total loss': 0.30812689132796117}
2023-01-04 11:14:11,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:11,531 INFO:     Epoch: 62
2023-01-04 11:14:13,171 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40908235907554624, 'Total loss': 0.40908235907554624} | train loss {'Reaction outcome loss': 0.3030810735544419, 'Total loss': 0.3030810735544419}
2023-01-04 11:14:13,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:13,171 INFO:     Epoch: 63
2023-01-04 11:14:14,775 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4586494147777557, 'Total loss': 0.4586494147777557} | train loss {'Reaction outcome loss': 0.3002069718896182, 'Total loss': 0.3002069718896182}
2023-01-04 11:14:14,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:14,775 INFO:     Epoch: 64
2023-01-04 11:14:16,336 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4309925059477488, 'Total loss': 0.4309925059477488} | train loss {'Reaction outcome loss': 0.2984880833900061, 'Total loss': 0.2984880833900061}
2023-01-04 11:14:16,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:16,336 INFO:     Epoch: 65
2023-01-04 11:14:17,974 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4275270024935404, 'Total loss': 0.4275270024935404} | train loss {'Reaction outcome loss': 0.3014807904015112, 'Total loss': 0.3014807904015112}
2023-01-04 11:14:17,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:17,974 INFO:     Epoch: 66
2023-01-04 11:14:19,614 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4467572251955668, 'Total loss': 0.4467572251955668} | train loss {'Reaction outcome loss': 0.3060250422120958, 'Total loss': 0.3060250422120958}
2023-01-04 11:14:19,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:19,614 INFO:     Epoch: 67
2023-01-04 11:14:21,252 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4383505662282308, 'Total loss': 0.4383505662282308} | train loss {'Reaction outcome loss': 0.3248407790526761, 'Total loss': 0.3248407790526761}
2023-01-04 11:14:21,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:21,253 INFO:     Epoch: 68
2023-01-04 11:14:22,876 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44918359319369, 'Total loss': 0.44918359319369} | train loss {'Reaction outcome loss': 0.29796773978117586, 'Total loss': 0.29796773978117586}
2023-01-04 11:14:22,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:22,876 INFO:     Epoch: 69
2023-01-04 11:14:24,384 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44698748687903084, 'Total loss': 0.44698748687903084} | train loss {'Reaction outcome loss': 0.29872039793248195, 'Total loss': 0.29872039793248195}
2023-01-04 11:14:24,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:24,384 INFO:     Epoch: 70
2023-01-04 11:14:26,021 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5032004654407501, 'Total loss': 0.5032004654407501} | train loss {'Reaction outcome loss': 0.29188965024260816, 'Total loss': 0.29188965024260816}
2023-01-04 11:14:26,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:26,021 INFO:     Epoch: 71
2023-01-04 11:14:27,655 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41118916173775993, 'Total loss': 0.41118916173775993} | train loss {'Reaction outcome loss': 0.2888091028654489, 'Total loss': 0.2888091028654489}
2023-01-04 11:14:27,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:27,656 INFO:     Epoch: 72
2023-01-04 11:14:29,247 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4829246749480565, 'Total loss': 0.4829246749480565} | train loss {'Reaction outcome loss': 0.28876886461638723, 'Total loss': 0.28876886461638723}
2023-01-04 11:14:29,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:29,247 INFO:     Epoch: 73
2023-01-04 11:14:30,815 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39455530842145287, 'Total loss': 0.39455530842145287} | train loss {'Reaction outcome loss': 0.2959014820339887, 'Total loss': 0.2959014820339887}
2023-01-04 11:14:30,816 INFO:     Found new best model at epoch 73
2023-01-04 11:14:30,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:30,816 INFO:     Epoch: 74
2023-01-04 11:14:32,364 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4367884824673335, 'Total loss': 0.4367884824673335} | train loss {'Reaction outcome loss': 0.32203176645966974, 'Total loss': 0.32203176645966974}
2023-01-04 11:14:32,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:32,365 INFO:     Epoch: 75
2023-01-04 11:14:33,773 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47594617307186127, 'Total loss': 0.47594617307186127} | train loss {'Reaction outcome loss': 0.29084222026395384, 'Total loss': 0.29084222026395384}
2023-01-04 11:14:33,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:33,773 INFO:     Epoch: 76
2023-01-04 11:14:35,326 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43232549031575523, 'Total loss': 0.43232549031575523} | train loss {'Reaction outcome loss': 0.28402485132244404, 'Total loss': 0.28402485132244404}
2023-01-04 11:14:35,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:35,326 INFO:     Epoch: 77
2023-01-04 11:14:36,900 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41156430592139565, 'Total loss': 0.41156430592139565} | train loss {'Reaction outcome loss': 0.28251382318136375, 'Total loss': 0.28251382318136375}
2023-01-04 11:14:36,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:36,900 INFO:     Epoch: 78
2023-01-04 11:14:38,451 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4266022741794586, 'Total loss': 0.4266022741794586} | train loss {'Reaction outcome loss': 0.2828828725791739, 'Total loss': 0.2828828725791739}
2023-01-04 11:14:38,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:38,451 INFO:     Epoch: 79
2023-01-04 11:14:40,009 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46955862243970237, 'Total loss': 0.46955862243970237} | train loss {'Reaction outcome loss': 0.27659870285804017, 'Total loss': 0.27659870285804017}
2023-01-04 11:14:40,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:40,010 INFO:     Epoch: 80
2023-01-04 11:14:41,585 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4775870422522227, 'Total loss': 0.4775870422522227} | train loss {'Reaction outcome loss': 0.28547338650062465, 'Total loss': 0.28547338650062465}
2023-01-04 11:14:41,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:41,586 INFO:     Epoch: 81
2023-01-04 11:14:43,027 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43479214211304984, 'Total loss': 0.43479214211304984} | train loss {'Reaction outcome loss': 0.3060693131840747, 'Total loss': 0.3060693131840747}
2023-01-04 11:14:43,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:43,028 INFO:     Epoch: 82
2023-01-04 11:14:44,592 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40362981557846067, 'Total loss': 0.40362981557846067} | train loss {'Reaction outcome loss': 0.27742584517218877, 'Total loss': 0.27742584517218877}
2023-01-04 11:14:44,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:44,592 INFO:     Epoch: 83
2023-01-04 11:14:46,169 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42314388950665793, 'Total loss': 0.42314388950665793} | train loss {'Reaction outcome loss': 0.2735224262392823, 'Total loss': 0.2735224262392823}
2023-01-04 11:14:46,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:46,169 INFO:     Epoch: 84
2023-01-04 11:14:47,760 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4570465405782064, 'Total loss': 0.4570465405782064} | train loss {'Reaction outcome loss': 0.2763297511500887, 'Total loss': 0.2763297511500887}
2023-01-04 11:14:47,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:47,761 INFO:     Epoch: 85
2023-01-04 11:14:49,330 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4409266630808512, 'Total loss': 0.4409266630808512} | train loss {'Reaction outcome loss': 0.2750371419487224, 'Total loss': 0.2750371419487224}
2023-01-04 11:14:49,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:49,331 INFO:     Epoch: 86
2023-01-04 11:14:50,904 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4053436994552612, 'Total loss': 0.4053436994552612} | train loss {'Reaction outcome loss': 0.3000275290240466, 'Total loss': 0.3000275290240466}
2023-01-04 11:14:50,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:50,904 INFO:     Epoch: 87
2023-01-04 11:14:52,356 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3828674534956614, 'Total loss': 0.3828674534956614} | train loss {'Reaction outcome loss': 0.27194169911348104, 'Total loss': 0.27194169911348104}
2023-01-04 11:14:52,357 INFO:     Found new best model at epoch 87
2023-01-04 11:14:52,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:52,358 INFO:     Epoch: 88
2023-01-04 11:14:53,924 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42077438831329345, 'Total loss': 0.42077438831329345} | train loss {'Reaction outcome loss': 0.27036050720599253, 'Total loss': 0.27036050720599253}
2023-01-04 11:14:53,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:53,924 INFO:     Epoch: 89
2023-01-04 11:14:55,487 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38721486926078796, 'Total loss': 0.38721486926078796} | train loss {'Reaction outcome loss': 0.26776033549369616, 'Total loss': 0.26776033549369616}
2023-01-04 11:14:55,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:55,487 INFO:     Epoch: 90
2023-01-04 11:14:57,054 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4076311349868774, 'Total loss': 0.4076311349868774} | train loss {'Reaction outcome loss': 0.2633257101937804, 'Total loss': 0.2633257101937804}
2023-01-04 11:14:57,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:57,054 INFO:     Epoch: 91
2023-01-04 11:14:58,607 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44932183623313904, 'Total loss': 0.44932183623313904} | train loss {'Reaction outcome loss': 0.26605148797186656, 'Total loss': 0.26605148797186656}
2023-01-04 11:14:58,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:14:58,608 INFO:     Epoch: 92
2023-01-04 11:15:00,184 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42622055212656657, 'Total loss': 0.42622055212656657} | train loss {'Reaction outcome loss': 0.26284673052488366, 'Total loss': 0.26284673052488366}
2023-01-04 11:15:00,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:00,184 INFO:     Epoch: 93
2023-01-04 11:15:01,638 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3999423737327258, 'Total loss': 0.3999423737327258} | train loss {'Reaction outcome loss': 0.26124093903100415, 'Total loss': 0.26124093903100415}
2023-01-04 11:15:01,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:01,638 INFO:     Epoch: 94
2023-01-04 11:15:03,234 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42039608558019004, 'Total loss': 0.42039608558019004} | train loss {'Reaction outcome loss': 0.2636055562680944, 'Total loss': 0.2636055562680944}
2023-01-04 11:15:03,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:03,234 INFO:     Epoch: 95
2023-01-04 11:15:04,822 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41094241937001547, 'Total loss': 0.41094241937001547} | train loss {'Reaction outcome loss': 0.26464158197536497, 'Total loss': 0.26464158197536497}
2023-01-04 11:15:04,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:04,822 INFO:     Epoch: 96
2023-01-04 11:15:06,389 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40317140420277914, 'Total loss': 0.40317140420277914} | train loss {'Reaction outcome loss': 0.26339848660163756, 'Total loss': 0.26339848660163756}
2023-01-04 11:15:06,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:06,389 INFO:     Epoch: 97
2023-01-04 11:15:07,950 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42708753546079, 'Total loss': 0.42708753546079} | train loss {'Reaction outcome loss': 0.2573891311784383, 'Total loss': 0.2573891311784383}
2023-01-04 11:15:07,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:07,950 INFO:     Epoch: 98
2023-01-04 11:15:09,499 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4190818816423416, 'Total loss': 0.4190818816423416} | train loss {'Reaction outcome loss': 0.25703907810637483, 'Total loss': 0.25703907810637483}
2023-01-04 11:15:09,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:09,499 INFO:     Epoch: 99
2023-01-04 11:15:10,991 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4128526568412781, 'Total loss': 0.4128526568412781} | train loss {'Reaction outcome loss': 0.25386902378122084, 'Total loss': 0.25386902378122084}
2023-01-04 11:15:10,992 INFO:     Best model found after epoch 88 of 100.
2023-01-04 11:15:10,992 INFO:   Done with stage: TRAINING
2023-01-04 11:15:10,992 INFO:   Starting stage: EVALUATION
2023-01-04 11:15:11,120 INFO:   Done with stage: EVALUATION
2023-01-04 11:15:11,128 INFO:   Leaving out SEQ value Fold_0
2023-01-04 11:15:11,141 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-04 11:15:11,141 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:15:11,774 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:15:11,774 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:15:11,840 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:15:11,840 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:15:11,841 INFO:     No hyperparam tuning for this model
2023-01-04 11:15:11,841 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:15:11,841 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:15:11,841 INFO:     None feature selector for col prot
2023-01-04 11:15:11,841 INFO:     None feature selector for col prot
2023-01-04 11:15:11,842 INFO:     None feature selector for col prot
2023-01-04 11:15:11,842 INFO:     None feature selector for col chem
2023-01-04 11:15:11,842 INFO:     None feature selector for col chem
2023-01-04 11:15:11,842 INFO:     None feature selector for col chem
2023-01-04 11:15:11,842 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:15:11,842 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:15:11,843 INFO:     Number of params in model 70111
2023-01-04 11:15:11,846 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:15:11,847 INFO:   Starting stage: TRAINING
2023-01-04 11:15:11,889 INFO:     Val loss before train {'Reaction outcome loss': 0.9570222059885661, 'Total loss': 0.9570222059885661}
2023-01-04 11:15:11,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:11,889 INFO:     Epoch: 0
2023-01-04 11:15:13,408 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7046243588129679, 'Total loss': 0.7046243588129679} | train loss {'Reaction outcome loss': 0.8479622544177784, 'Total loss': 0.8479622544177784}
2023-01-04 11:15:13,408 INFO:     Found new best model at epoch 0
2023-01-04 11:15:13,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:13,409 INFO:     Epoch: 1
2023-01-04 11:15:14,946 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5842608690261841, 'Total loss': 0.5842608690261841} | train loss {'Reaction outcome loss': 0.6937495699887786, 'Total loss': 0.6937495699887786}
2023-01-04 11:15:14,946 INFO:     Found new best model at epoch 1
2023-01-04 11:15:14,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:14,947 INFO:     Epoch: 2
2023-01-04 11:15:16,487 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5077238569657008, 'Total loss': 0.5077238569657008} | train loss {'Reaction outcome loss': 0.5967843311519201, 'Total loss': 0.5967843311519201}
2023-01-04 11:15:16,487 INFO:     Found new best model at epoch 2
2023-01-04 11:15:16,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:16,488 INFO:     Epoch: 3
2023-01-04 11:15:18,039 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49254343112309773, 'Total loss': 0.49254343112309773} | train loss {'Reaction outcome loss': 0.5427400978398939, 'Total loss': 0.5427400978398939}
2023-01-04 11:15:18,039 INFO:     Found new best model at epoch 3
2023-01-04 11:15:18,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:18,040 INFO:     Epoch: 4
2023-01-04 11:15:19,452 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4929822047551473, 'Total loss': 0.4929822047551473} | train loss {'Reaction outcome loss': 0.5157100900292837, 'Total loss': 0.5157100900292837}
2023-01-04 11:15:19,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:19,453 INFO:     Epoch: 5
2023-01-04 11:15:20,983 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4782456795374552, 'Total loss': 0.4782456795374552} | train loss {'Reaction outcome loss': 0.5031585489361928, 'Total loss': 0.5031585489361928}
2023-01-04 11:15:20,984 INFO:     Found new best model at epoch 5
2023-01-04 11:15:20,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:20,984 INFO:     Epoch: 6
2023-01-04 11:15:22,524 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.493218324581782, 'Total loss': 0.493218324581782} | train loss {'Reaction outcome loss': 0.4886726280090114, 'Total loss': 0.4886726280090114}
2023-01-04 11:15:22,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:22,524 INFO:     Epoch: 7
2023-01-04 11:15:24,071 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4626079981525739, 'Total loss': 0.4626079981525739} | train loss {'Reaction outcome loss': 0.4737561080893467, 'Total loss': 0.4737561080893467}
2023-01-04 11:15:24,071 INFO:     Found new best model at epoch 7
2023-01-04 11:15:24,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:24,072 INFO:     Epoch: 8
2023-01-04 11:15:25,606 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4498191197713216, 'Total loss': 0.4498191197713216} | train loss {'Reaction outcome loss': 0.46905690167662845, 'Total loss': 0.46905690167662845}
2023-01-04 11:15:25,607 INFO:     Found new best model at epoch 8
2023-01-04 11:15:25,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:25,607 INFO:     Epoch: 9
2023-01-04 11:15:27,146 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44475638270378115, 'Total loss': 0.44475638270378115} | train loss {'Reaction outcome loss': 0.45812832187462554, 'Total loss': 0.45812832187462554}
2023-01-04 11:15:27,146 INFO:     Found new best model at epoch 9
2023-01-04 11:15:27,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:27,147 INFO:     Epoch: 10
2023-01-04 11:15:28,556 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43942524989446, 'Total loss': 0.43942524989446} | train loss {'Reaction outcome loss': 0.45782541574367297, 'Total loss': 0.45782541574367297}
2023-01-04 11:15:28,558 INFO:     Found new best model at epoch 10
2023-01-04 11:15:28,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:28,559 INFO:     Epoch: 11
2023-01-04 11:15:30,092 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4307725727558136, 'Total loss': 0.4307725727558136} | train loss {'Reaction outcome loss': 0.4451230004484803, 'Total loss': 0.4451230004484803}
2023-01-04 11:15:30,092 INFO:     Found new best model at epoch 11
2023-01-04 11:15:30,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:30,093 INFO:     Epoch: 12
2023-01-04 11:15:31,616 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4540513475735982, 'Total loss': 0.4540513475735982} | train loss {'Reaction outcome loss': 0.4395546190083247, 'Total loss': 0.4395546190083247}
2023-01-04 11:15:31,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:31,617 INFO:     Epoch: 13
2023-01-04 11:15:33,149 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4031359295050303, 'Total loss': 0.4031359295050303} | train loss {'Reaction outcome loss': 0.4390281559246493, 'Total loss': 0.4390281559246493}
2023-01-04 11:15:33,149 INFO:     Found new best model at epoch 13
2023-01-04 11:15:33,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:33,150 INFO:     Epoch: 14
2023-01-04 11:15:34,686 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43070375323295595, 'Total loss': 0.43070375323295595} | train loss {'Reaction outcome loss': 0.43256849039524686, 'Total loss': 0.43256849039524686}
2023-01-04 11:15:34,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:34,687 INFO:     Epoch: 15
2023-01-04 11:15:36,210 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42432299156983694, 'Total loss': 0.42432299156983694} | train loss {'Reaction outcome loss': 0.4242117117361829, 'Total loss': 0.4242117117361829}
2023-01-04 11:15:36,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:36,210 INFO:     Epoch: 16
2023-01-04 11:15:37,628 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44371813734372456, 'Total loss': 0.44371813734372456} | train loss {'Reaction outcome loss': 0.421117669679362, 'Total loss': 0.421117669679362}
2023-01-04 11:15:37,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:37,628 INFO:     Epoch: 17
2023-01-04 11:15:39,155 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4150872011979421, 'Total loss': 0.4150872011979421} | train loss {'Reaction outcome loss': 0.4202867898114053, 'Total loss': 0.4202867898114053}
2023-01-04 11:15:39,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:39,155 INFO:     Epoch: 18
2023-01-04 11:15:40,684 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41699216862519584, 'Total loss': 0.41699216862519584} | train loss {'Reaction outcome loss': 0.41737480005215016, 'Total loss': 0.41737480005215016}
2023-01-04 11:15:40,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:40,684 INFO:     Epoch: 19
2023-01-04 11:15:42,219 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39840784867604573, 'Total loss': 0.39840784867604573} | train loss {'Reaction outcome loss': 0.4106105983917124, 'Total loss': 0.4106105983917124}
2023-01-04 11:15:42,219 INFO:     Found new best model at epoch 19
2023-01-04 11:15:42,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:42,220 INFO:     Epoch: 20
2023-01-04 11:15:43,760 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40153056184450786, 'Total loss': 0.40153056184450786} | train loss {'Reaction outcome loss': 0.4041678374873756, 'Total loss': 0.4041678374873756}
2023-01-04 11:15:43,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:43,760 INFO:     Epoch: 21
2023-01-04 11:15:45,287 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4067644993464152, 'Total loss': 0.4067644993464152} | train loss {'Reaction outcome loss': 0.40160721614681927, 'Total loss': 0.40160721614681927}
2023-01-04 11:15:45,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:45,287 INFO:     Epoch: 22
2023-01-04 11:15:46,721 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4221473276615143, 'Total loss': 0.4221473276615143} | train loss {'Reaction outcome loss': 0.3977206944319595, 'Total loss': 0.3977206944319595}
2023-01-04 11:15:46,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:46,722 INFO:     Epoch: 23
2023-01-04 11:15:48,274 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40052452782789866, 'Total loss': 0.40052452782789866} | train loss {'Reaction outcome loss': 0.3929731006771876, 'Total loss': 0.3929731006771876}
2023-01-04 11:15:48,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:48,274 INFO:     Epoch: 24
2023-01-04 11:15:49,817 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38475773433844246, 'Total loss': 0.38475773433844246} | train loss {'Reaction outcome loss': 0.3886762194857826, 'Total loss': 0.3886762194857826}
2023-01-04 11:15:49,817 INFO:     Found new best model at epoch 24
2023-01-04 11:15:49,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:49,818 INFO:     Epoch: 25
2023-01-04 11:15:51,337 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4070797254641851, 'Total loss': 0.4070797254641851} | train loss {'Reaction outcome loss': 0.3882216704919989, 'Total loss': 0.3882216704919989}
2023-01-04 11:15:51,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:51,337 INFO:     Epoch: 26
2023-01-04 11:15:52,883 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40165260930856067, 'Total loss': 0.40165260930856067} | train loss {'Reaction outcome loss': 0.37882023497151274, 'Total loss': 0.37882023497151274}
2023-01-04 11:15:52,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:52,884 INFO:     Epoch: 27
2023-01-04 11:15:54,402 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3888744751612345, 'Total loss': 0.3888744751612345} | train loss {'Reaction outcome loss': 0.3799963199234537, 'Total loss': 0.3799963199234537}
2023-01-04 11:15:54,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:54,402 INFO:     Epoch: 28
2023-01-04 11:15:55,812 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38843207359313964, 'Total loss': 0.38843207359313964} | train loss {'Reaction outcome loss': 0.37497745938186716, 'Total loss': 0.37497745938186716}
2023-01-04 11:15:55,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:55,812 INFO:     Epoch: 29
2023-01-04 11:15:57,368 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3672922117014726, 'Total loss': 0.3672922117014726} | train loss {'Reaction outcome loss': 0.37106217276236225, 'Total loss': 0.37106217276236225}
2023-01-04 11:15:57,368 INFO:     Found new best model at epoch 29
2023-01-04 11:15:57,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:57,369 INFO:     Epoch: 30
2023-01-04 11:15:58,917 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3898900439341863, 'Total loss': 0.3898900439341863} | train loss {'Reaction outcome loss': 0.36814584602289097, 'Total loss': 0.36814584602289097}
2023-01-04 11:15:58,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:15:58,917 INFO:     Epoch: 31
2023-01-04 11:16:00,454 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39857273995876313, 'Total loss': 0.39857273995876313} | train loss {'Reaction outcome loss': 0.3666138080708215, 'Total loss': 0.3666138080708215}
2023-01-04 11:16:00,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:00,454 INFO:     Epoch: 32
2023-01-04 11:16:02,001 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41589481035868325, 'Total loss': 0.41589481035868325} | train loss {'Reaction outcome loss': 0.3626925419342474, 'Total loss': 0.3626925419342474}
2023-01-04 11:16:02,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:02,001 INFO:     Epoch: 33
2023-01-04 11:16:03,554 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43199596206347146, 'Total loss': 0.43199596206347146} | train loss {'Reaction outcome loss': 0.3578571725045623, 'Total loss': 0.3578571725045623}
2023-01-04 11:16:03,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:03,556 INFO:     Epoch: 34
2023-01-04 11:16:05,021 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40466340680917107, 'Total loss': 0.40466340680917107} | train loss {'Reaction outcome loss': 0.3529802317493956, 'Total loss': 0.3529802317493956}
2023-01-04 11:16:05,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:05,021 INFO:     Epoch: 35
2023-01-04 11:16:06,562 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40865294138590497, 'Total loss': 0.40865294138590497} | train loss {'Reaction outcome loss': 0.3527922027115452, 'Total loss': 0.3527922027115452}
2023-01-04 11:16:06,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:06,562 INFO:     Epoch: 36
2023-01-04 11:16:08,124 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3740224689245224, 'Total loss': 0.3740224689245224} | train loss {'Reaction outcome loss': 0.35239622156338496, 'Total loss': 0.35239622156338496}
2023-01-04 11:16:08,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:08,124 INFO:     Epoch: 37
2023-01-04 11:16:09,694 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39653511842091876, 'Total loss': 0.39653511842091876} | train loss {'Reaction outcome loss': 0.34486132634741795, 'Total loss': 0.34486132634741795}
2023-01-04 11:16:09,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:09,695 INFO:     Epoch: 38
2023-01-04 11:16:11,267 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39004283050696054, 'Total loss': 0.39004283050696054} | train loss {'Reaction outcome loss': 0.3404649387756397, 'Total loss': 0.3404649387756397}
2023-01-04 11:16:11,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:11,268 INFO:     Epoch: 39
2023-01-04 11:16:12,766 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.37378010352452595, 'Total loss': 0.37378010352452595} | train loss {'Reaction outcome loss': 0.3440339524862511, 'Total loss': 0.3440339524862511}
2023-01-04 11:16:12,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:12,767 INFO:     Epoch: 40
2023-01-04 11:16:14,256 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38998483022054037, 'Total loss': 0.38998483022054037} | train loss {'Reaction outcome loss': 0.33721062824185044, 'Total loss': 0.33721062824185044}
2023-01-04 11:16:14,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:14,257 INFO:     Epoch: 41
2023-01-04 11:16:15,835 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39026795625686644, 'Total loss': 0.39026795625686644} | train loss {'Reaction outcome loss': 0.33346292623954504, 'Total loss': 0.33346292623954504}
2023-01-04 11:16:15,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:15,836 INFO:     Epoch: 42
2023-01-04 11:16:17,384 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3956407328446706, 'Total loss': 0.3956407328446706} | train loss {'Reaction outcome loss': 0.32874111597498407, 'Total loss': 0.32874111597498407}
2023-01-04 11:16:17,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:17,384 INFO:     Epoch: 43
2023-01-04 11:16:18,936 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3990371098121007, 'Total loss': 0.3990371098121007} | train loss {'Reaction outcome loss': 0.3338029784085126, 'Total loss': 0.3338029784085126}
2023-01-04 11:16:18,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:18,937 INFO:     Epoch: 44
2023-01-04 11:16:20,492 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3649262378613154, 'Total loss': 0.3649262378613154} | train loss {'Reaction outcome loss': 0.3275332349967693, 'Total loss': 0.3275332349967693}
2023-01-04 11:16:20,493 INFO:     Found new best model at epoch 44
2023-01-04 11:16:20,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:20,493 INFO:     Epoch: 45
2023-01-04 11:16:21,950 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3815160751342773, 'Total loss': 0.3815160751342773} | train loss {'Reaction outcome loss': 0.3263472790702683, 'Total loss': 0.3263472790702683}
2023-01-04 11:16:21,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:21,951 INFO:     Epoch: 46
2023-01-04 11:16:23,484 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4168542812267939, 'Total loss': 0.4168542812267939} | train loss {'Reaction outcome loss': 0.3234183754208343, 'Total loss': 0.3234183754208343}
2023-01-04 11:16:23,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:23,485 INFO:     Epoch: 47
2023-01-04 11:16:25,033 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41364811758200326, 'Total loss': 0.41364811758200326} | train loss {'Reaction outcome loss': 0.32071503735666346, 'Total loss': 0.32071503735666346}
2023-01-04 11:16:25,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:25,033 INFO:     Epoch: 48
2023-01-04 11:16:26,599 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.36643695731957754, 'Total loss': 0.36643695731957754} | train loss {'Reaction outcome loss': 0.3168821186102184, 'Total loss': 0.3168821186102184}
2023-01-04 11:16:26,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:26,600 INFO:     Epoch: 49
2023-01-04 11:16:28,153 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3776867260535558, 'Total loss': 0.3776867260535558} | train loss {'Reaction outcome loss': 0.32071577062026163, 'Total loss': 0.32071577062026163}
2023-01-04 11:16:28,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:28,153 INFO:     Epoch: 50
2023-01-04 11:16:29,717 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.34979250145455204, 'Total loss': 0.34979250145455204} | train loss {'Reaction outcome loss': 0.3160850332561894, 'Total loss': 0.3160850332561894}
2023-01-04 11:16:29,717 INFO:     Found new best model at epoch 50
2023-01-04 11:16:29,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:29,717 INFO:     Epoch: 51
2023-01-04 11:16:31,139 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3636066774527232, 'Total loss': 0.3636066774527232} | train loss {'Reaction outcome loss': 0.3142438921321362, 'Total loss': 0.3142438921321362}
2023-01-04 11:16:31,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:31,140 INFO:     Epoch: 52
2023-01-04 11:16:32,671 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36169034739335376, 'Total loss': 0.36169034739335376} | train loss {'Reaction outcome loss': 0.30745440584047257, 'Total loss': 0.30745440584047257}
2023-01-04 11:16:32,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:32,671 INFO:     Epoch: 53
2023-01-04 11:16:34,222 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4201429327329, 'Total loss': 0.4201429327329} | train loss {'Reaction outcome loss': 0.30678271680960356, 'Total loss': 0.30678271680960356}
2023-01-04 11:16:34,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:34,223 INFO:     Epoch: 54
2023-01-04 11:16:35,759 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.35107439110676447, 'Total loss': 0.35107439110676447} | train loss {'Reaction outcome loss': 0.3036014212783412, 'Total loss': 0.3036014212783412}
2023-01-04 11:16:35,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:35,759 INFO:     Epoch: 55
2023-01-04 11:16:37,292 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.35128316978613533, 'Total loss': 0.35128316978613533} | train loss {'Reaction outcome loss': 0.30123861635798016, 'Total loss': 0.30123861635798016}
2023-01-04 11:16:37,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:37,292 INFO:     Epoch: 56
2023-01-04 11:16:38,816 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38124773403008777, 'Total loss': 0.38124773403008777} | train loss {'Reaction outcome loss': 0.30717008525155126, 'Total loss': 0.30717008525155126}
2023-01-04 11:16:38,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:38,816 INFO:     Epoch: 57
2023-01-04 11:16:40,219 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39586859246095024, 'Total loss': 0.39586859246095024} | train loss {'Reaction outcome loss': 0.29667314650607723, 'Total loss': 0.29667314650607723}
2023-01-04 11:16:40,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:40,220 INFO:     Epoch: 58
2023-01-04 11:16:41,774 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3925151954094569, 'Total loss': 0.3925151954094569} | train loss {'Reaction outcome loss': 0.30134296222036616, 'Total loss': 0.30134296222036616}
2023-01-04 11:16:41,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:41,775 INFO:     Epoch: 59
2023-01-04 11:16:43,332 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37927752832571665, 'Total loss': 0.37927752832571665} | train loss {'Reaction outcome loss': 0.29985721544036126, 'Total loss': 0.29985721544036126}
2023-01-04 11:16:43,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:43,332 INFO:     Epoch: 60
2023-01-04 11:16:44,882 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39664002855618796, 'Total loss': 0.39664002855618796} | train loss {'Reaction outcome loss': 0.29727926000787763, 'Total loss': 0.29727926000787763}
2023-01-04 11:16:44,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:44,882 INFO:     Epoch: 61
2023-01-04 11:16:46,426 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38146632512410483, 'Total loss': 0.38146632512410483} | train loss {'Reaction outcome loss': 0.29651478026405914, 'Total loss': 0.29651478026405914}
2023-01-04 11:16:46,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:46,426 INFO:     Epoch: 62
2023-01-04 11:16:47,976 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37306639601786934, 'Total loss': 0.37306639601786934} | train loss {'Reaction outcome loss': 0.29697236437969105, 'Total loss': 0.29697236437969105}
2023-01-04 11:16:47,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:47,977 INFO:     Epoch: 63
2023-01-04 11:16:49,420 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3839263657728831, 'Total loss': 0.3839263657728831} | train loss {'Reaction outcome loss': 0.2949972585036086, 'Total loss': 0.2949972585036086}
2023-01-04 11:16:49,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:49,420 INFO:     Epoch: 64
2023-01-04 11:16:50,957 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38897318840026857, 'Total loss': 0.38897318840026857} | train loss {'Reaction outcome loss': 0.2876690550126493, 'Total loss': 0.2876690550126493}
2023-01-04 11:16:50,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:50,957 INFO:     Epoch: 65
2023-01-04 11:16:52,538 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.36114621460437774, 'Total loss': 0.36114621460437774} | train loss {'Reaction outcome loss': 0.2875735782141835, 'Total loss': 0.2875735782141835}
2023-01-04 11:16:52,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:52,538 INFO:     Epoch: 66
2023-01-04 11:16:54,089 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4026544362306595, 'Total loss': 0.4026544362306595} | train loss {'Reaction outcome loss': 0.28356646874239083, 'Total loss': 0.28356646874239083}
2023-01-04 11:16:54,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:54,089 INFO:     Epoch: 67
2023-01-04 11:16:55,684 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4087361792723338, 'Total loss': 0.4087361792723338} | train loss {'Reaction outcome loss': 0.2863513972486517, 'Total loss': 0.2863513972486517}
2023-01-04 11:16:55,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:55,684 INFO:     Epoch: 68
2023-01-04 11:16:57,265 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3487274235735337, 'Total loss': 0.3487274235735337} | train loss {'Reaction outcome loss': 0.28185466520240826, 'Total loss': 0.28185466520240826}
2023-01-04 11:16:57,265 INFO:     Found new best model at epoch 68
2023-01-04 11:16:57,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:57,266 INFO:     Epoch: 69
2023-01-04 11:16:58,713 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3794249633948008, 'Total loss': 0.3794249633948008} | train loss {'Reaction outcome loss': 0.2853788283423304, 'Total loss': 0.2853788283423304}
2023-01-04 11:16:58,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:16:58,714 INFO:     Epoch: 70
2023-01-04 11:17:00,260 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3884734312693278, 'Total loss': 0.3884734312693278} | train loss {'Reaction outcome loss': 0.278591283339306, 'Total loss': 0.278591283339306}
2023-01-04 11:17:00,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:00,261 INFO:     Epoch: 71
2023-01-04 11:17:01,803 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.34832763274510703, 'Total loss': 0.34832763274510703} | train loss {'Reaction outcome loss': 0.2807097533972061, 'Total loss': 0.2807097533972061}
2023-01-04 11:17:01,803 INFO:     Found new best model at epoch 71
2023-01-04 11:17:01,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:01,804 INFO:     Epoch: 72
2023-01-04 11:17:03,384 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39057277540365853, 'Total loss': 0.39057277540365853} | train loss {'Reaction outcome loss': 0.2757471338106917, 'Total loss': 0.2757471338106917}
2023-01-04 11:17:03,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:03,384 INFO:     Epoch: 73
2023-01-04 11:17:04,943 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3949861407279968, 'Total loss': 0.3949861407279968} | train loss {'Reaction outcome loss': 0.27713619789789085, 'Total loss': 0.27713619789789085}
2023-01-04 11:17:04,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:04,944 INFO:     Epoch: 74
2023-01-04 11:17:06,506 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4078755736351013, 'Total loss': 0.4078755736351013} | train loss {'Reaction outcome loss': 0.27637643677722046, 'Total loss': 0.27637643677722046}
2023-01-04 11:17:06,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:06,506 INFO:     Epoch: 75
2023-01-04 11:17:07,931 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3772851099570592, 'Total loss': 0.3772851099570592} | train loss {'Reaction outcome loss': 0.2733528983961392, 'Total loss': 0.2733528983961392}
2023-01-04 11:17:07,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:07,931 INFO:     Epoch: 76
2023-01-04 11:17:09,469 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.348858568072319, 'Total loss': 0.348858568072319} | train loss {'Reaction outcome loss': 0.2747160684028675, 'Total loss': 0.2747160684028675}
2023-01-04 11:17:09,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:09,469 INFO:     Epoch: 77
2023-01-04 11:17:11,020 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3473973758518696, 'Total loss': 0.3473973758518696} | train loss {'Reaction outcome loss': 0.2687037847386295, 'Total loss': 0.2687037847386295}
2023-01-04 11:17:11,021 INFO:     Found new best model at epoch 77
2023-01-04 11:17:11,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:11,022 INFO:     Epoch: 78
2023-01-04 11:17:12,562 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3715936248501142, 'Total loss': 0.3715936248501142} | train loss {'Reaction outcome loss': 0.2717732019255082, 'Total loss': 0.2717732019255082}
2023-01-04 11:17:12,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:12,563 INFO:     Epoch: 79
2023-01-04 11:17:14,106 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38445563316345216, 'Total loss': 0.38445563316345216} | train loss {'Reaction outcome loss': 0.2670766417748154, 'Total loss': 0.2670766417748154}
2023-01-04 11:17:14,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:14,106 INFO:     Epoch: 80
2023-01-04 11:17:15,650 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38376376827557884, 'Total loss': 0.38376376827557884} | train loss {'Reaction outcome loss': 0.2681592302981118, 'Total loss': 0.2681592302981118}
2023-01-04 11:17:15,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:15,650 INFO:     Epoch: 81
2023-01-04 11:17:17,054 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.35807775557041166, 'Total loss': 0.35807775557041166} | train loss {'Reaction outcome loss': 0.27248009901864945, 'Total loss': 0.27248009901864945}
2023-01-04 11:17:17,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:17,055 INFO:     Epoch: 82
2023-01-04 11:17:18,610 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41462357540925343, 'Total loss': 0.41462357540925343} | train loss {'Reaction outcome loss': 0.2677148142588974, 'Total loss': 0.2677148142588974}
2023-01-04 11:17:18,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:18,610 INFO:     Epoch: 83
2023-01-04 11:17:20,164 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.34954747607310616, 'Total loss': 0.34954747607310616} | train loss {'Reaction outcome loss': 0.2706232508610095, 'Total loss': 0.2706232508610095}
2023-01-04 11:17:20,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:20,164 INFO:     Epoch: 84
2023-01-04 11:17:21,716 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40417927304903667, 'Total loss': 0.40417927304903667} | train loss {'Reaction outcome loss': 0.26416905173461375, 'Total loss': 0.26416905173461375}
2023-01-04 11:17:21,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:21,716 INFO:     Epoch: 85
2023-01-04 11:17:23,279 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.394493168592453, 'Total loss': 0.394493168592453} | train loss {'Reaction outcome loss': 0.26501444848151223, 'Total loss': 0.26501444848151223}
2023-01-04 11:17:23,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:23,280 INFO:     Epoch: 86
2023-01-04 11:17:24,830 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3707027663787206, 'Total loss': 0.3707027663787206} | train loss {'Reaction outcome loss': 0.26111609800770275, 'Total loss': 0.26111609800770275}
2023-01-04 11:17:24,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:24,830 INFO:     Epoch: 87
2023-01-04 11:17:26,244 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3741157134373983, 'Total loss': 0.3741157134373983} | train loss {'Reaction outcome loss': 0.261625435299539, 'Total loss': 0.261625435299539}
2023-01-04 11:17:26,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:26,245 INFO:     Epoch: 88
2023-01-04 11:17:27,810 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3687593837579091, 'Total loss': 0.3687593837579091} | train loss {'Reaction outcome loss': 0.2622794334353996, 'Total loss': 0.2622794334353996}
2023-01-04 11:17:27,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:27,811 INFO:     Epoch: 89
2023-01-04 11:17:29,368 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37506943196058273, 'Total loss': 0.37506943196058273} | train loss {'Reaction outcome loss': 0.26114901630860854, 'Total loss': 0.26114901630860854}
2023-01-04 11:17:29,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:29,368 INFO:     Epoch: 90
2023-01-04 11:17:30,920 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39435758789380393, 'Total loss': 0.39435758789380393} | train loss {'Reaction outcome loss': 0.2589734150612266, 'Total loss': 0.2589734150612266}
2023-01-04 11:17:30,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:30,920 INFO:     Epoch: 91
2023-01-04 11:17:32,485 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3938751190900803, 'Total loss': 0.3938751190900803} | train loss {'Reaction outcome loss': 0.26073171367449516, 'Total loss': 0.26073171367449516}
2023-01-04 11:17:32,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:32,485 INFO:     Epoch: 92
2023-01-04 11:17:34,043 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3795117060343424, 'Total loss': 0.3795117060343424} | train loss {'Reaction outcome loss': 0.26194307395013056, 'Total loss': 0.26194307395013056}
2023-01-04 11:17:34,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:34,043 INFO:     Epoch: 93
2023-01-04 11:17:35,446 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40660594701766967, 'Total loss': 0.40660594701766967} | train loss {'Reaction outcome loss': 0.2560404666812877, 'Total loss': 0.2560404666812877}
2023-01-04 11:17:35,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:35,447 INFO:     Epoch: 94
2023-01-04 11:17:37,016 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3881913721561432, 'Total loss': 0.3881913721561432} | train loss {'Reaction outcome loss': 0.25635062441284806, 'Total loss': 0.25635062441284806}
2023-01-04 11:17:37,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:37,017 INFO:     Epoch: 95
2023-01-04 11:17:38,575 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40650409907102586, 'Total loss': 0.40650409907102586} | train loss {'Reaction outcome loss': 0.2555443464170083, 'Total loss': 0.2555443464170083}
2023-01-04 11:17:38,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:38,575 INFO:     Epoch: 96
2023-01-04 11:17:40,137 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.36534900069236753, 'Total loss': 0.36534900069236753} | train loss {'Reaction outcome loss': 0.26337092024758735, 'Total loss': 0.26337092024758735}
2023-01-04 11:17:40,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:40,138 INFO:     Epoch: 97
2023-01-04 11:17:41,676 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3766310145457586, 'Total loss': 0.3766310145457586} | train loss {'Reaction outcome loss': 0.2505642807599143, 'Total loss': 0.2505642807599143}
2023-01-04 11:17:41,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:41,677 INFO:     Epoch: 98
2023-01-04 11:17:43,239 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.36688853005568184, 'Total loss': 0.36688853005568184} | train loss {'Reaction outcome loss': 0.26017972345831647, 'Total loss': 0.26017972345831647}
2023-01-04 11:17:43,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:43,239 INFO:     Epoch: 99
2023-01-04 11:17:44,638 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3666332503159841, 'Total loss': 0.3666332503159841} | train loss {'Reaction outcome loss': 0.24774719271602666, 'Total loss': 0.24774719271602666}
2023-01-04 11:17:44,638 INFO:     Best model found after epoch 78 of 100.
2023-01-04 11:17:44,638 INFO:   Done with stage: TRAINING
2023-01-04 11:17:44,638 INFO:   Starting stage: EVALUATION
2023-01-04 11:17:44,783 INFO:   Done with stage: EVALUATION
2023-01-04 11:17:44,784 INFO:   Leaving out SEQ value Fold_1
2023-01-04 11:17:44,797 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 11:17:44,797 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:17:45,444 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:17:45,444 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:17:45,512 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:17:45,512 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:17:45,512 INFO:     No hyperparam tuning for this model
2023-01-04 11:17:45,512 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:17:45,512 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:17:45,513 INFO:     None feature selector for col prot
2023-01-04 11:17:45,513 INFO:     None feature selector for col prot
2023-01-04 11:17:45,513 INFO:     None feature selector for col prot
2023-01-04 11:17:45,514 INFO:     None feature selector for col chem
2023-01-04 11:17:45,514 INFO:     None feature selector for col chem
2023-01-04 11:17:45,514 INFO:     None feature selector for col chem
2023-01-04 11:17:45,514 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:17:45,514 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:17:45,515 INFO:     Number of params in model 70111
2023-01-04 11:17:45,518 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:17:45,518 INFO:   Starting stage: TRAINING
2023-01-04 11:17:45,561 INFO:     Val loss before train {'Reaction outcome loss': 0.9127707878748575, 'Total loss': 0.9127707878748575}
2023-01-04 11:17:45,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:45,561 INFO:     Epoch: 0
2023-01-04 11:17:47,119 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6518941243489583, 'Total loss': 0.6518941243489583} | train loss {'Reaction outcome loss': 0.852542941261382, 'Total loss': 0.852542941261382}
2023-01-04 11:17:47,119 INFO:     Found new best model at epoch 0
2023-01-04 11:17:47,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:47,120 INFO:     Epoch: 1
2023-01-04 11:17:48,671 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5195348878701528, 'Total loss': 0.5195348878701528} | train loss {'Reaction outcome loss': 0.6945307823645808, 'Total loss': 0.6945307823645808}
2023-01-04 11:17:48,671 INFO:     Found new best model at epoch 1
2023-01-04 11:17:48,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:48,672 INFO:     Epoch: 2
2023-01-04 11:17:50,230 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4566096226374308, 'Total loss': 0.4566096226374308} | train loss {'Reaction outcome loss': 0.5907973810269015, 'Total loss': 0.5907973810269015}
2023-01-04 11:17:50,230 INFO:     Found new best model at epoch 2
2023-01-04 11:17:50,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:50,231 INFO:     Epoch: 3
2023-01-04 11:17:51,788 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4196702311436335, 'Total loss': 0.4196702311436335} | train loss {'Reaction outcome loss': 0.5476079394456244, 'Total loss': 0.5476079394456244}
2023-01-04 11:17:51,788 INFO:     Found new best model at epoch 3
2023-01-04 11:17:51,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:51,789 INFO:     Epoch: 4
2023-01-04 11:17:53,217 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.425599996248881, 'Total loss': 0.425599996248881} | train loss {'Reaction outcome loss': 0.527015184453369, 'Total loss': 0.527015184453369}
2023-01-04 11:17:53,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:53,217 INFO:     Epoch: 5
2023-01-04 11:17:54,801 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4178826630115509, 'Total loss': 0.4178826630115509} | train loss {'Reaction outcome loss': 0.5125972843953293, 'Total loss': 0.5125972843953293}
2023-01-04 11:17:54,802 INFO:     Found new best model at epoch 5
2023-01-04 11:17:54,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:54,803 INFO:     Epoch: 6
2023-01-04 11:17:56,373 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3894859552383423, 'Total loss': 0.3894859552383423} | train loss {'Reaction outcome loss': 0.5017347286326171, 'Total loss': 0.5017347286326171}
2023-01-04 11:17:56,373 INFO:     Found new best model at epoch 6
2023-01-04 11:17:56,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:56,374 INFO:     Epoch: 7
2023-01-04 11:17:57,973 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3720957636833191, 'Total loss': 0.3720957636833191} | train loss {'Reaction outcome loss': 0.4948220076787211, 'Total loss': 0.4948220076787211}
2023-01-04 11:17:57,974 INFO:     Found new best model at epoch 7
2023-01-04 11:17:57,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:57,974 INFO:     Epoch: 8
2023-01-04 11:17:59,550 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.363063175479571, 'Total loss': 0.363063175479571} | train loss {'Reaction outcome loss': 0.4849795415236132, 'Total loss': 0.4849795415236132}
2023-01-04 11:17:59,551 INFO:     Found new best model at epoch 8
2023-01-04 11:17:59,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:17:59,551 INFO:     Epoch: 9
2023-01-04 11:18:01,127 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3875395725170771, 'Total loss': 0.3875395725170771} | train loss {'Reaction outcome loss': 0.48177281647485537, 'Total loss': 0.48177281647485537}
2023-01-04 11:18:01,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:01,128 INFO:     Epoch: 10
2023-01-04 11:18:02,570 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3853418956200282, 'Total loss': 0.3853418956200282} | train loss {'Reaction outcome loss': 0.4735289318826947, 'Total loss': 0.4735289318826947}
2023-01-04 11:18:02,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:02,571 INFO:     Epoch: 11
2023-01-04 11:18:04,155 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3624375522136688, 'Total loss': 0.3624375522136688} | train loss {'Reaction outcome loss': 0.46940289617237385, 'Total loss': 0.46940289617237385}
2023-01-04 11:18:04,155 INFO:     Found new best model at epoch 11
2023-01-04 11:18:04,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:04,156 INFO:     Epoch: 12
2023-01-04 11:18:05,727 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3546374082565308, 'Total loss': 0.3546374082565308} | train loss {'Reaction outcome loss': 0.46583908344924885, 'Total loss': 0.46583908344924885}
2023-01-04 11:18:05,728 INFO:     Found new best model at epoch 12
2023-01-04 11:18:05,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:05,728 INFO:     Epoch: 13
2023-01-04 11:18:07,302 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.34431684066851936, 'Total loss': 0.34431684066851936} | train loss {'Reaction outcome loss': 0.46032116562128067, 'Total loss': 0.46032116562128067}
2023-01-04 11:18:07,303 INFO:     Found new best model at epoch 13
2023-01-04 11:18:07,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:07,304 INFO:     Epoch: 14
2023-01-04 11:18:08,885 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3683109919230143, 'Total loss': 0.3683109919230143} | train loss {'Reaction outcome loss': 0.45127962181602954, 'Total loss': 0.45127962181602954}
2023-01-04 11:18:08,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:08,886 INFO:     Epoch: 15
2023-01-04 11:18:10,459 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.35413020153840385, 'Total loss': 0.35413020153840385} | train loss {'Reaction outcome loss': 0.4510274713818174, 'Total loss': 0.4510274713818174}
2023-01-04 11:18:10,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:10,460 INFO:     Epoch: 16
2023-01-04 11:18:11,920 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3699601352214813, 'Total loss': 0.3699601352214813} | train loss {'Reaction outcome loss': 0.4434283953839845, 'Total loss': 0.4434283953839845}
2023-01-04 11:18:11,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:11,920 INFO:     Epoch: 17
2023-01-04 11:18:13,517 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.35385661323865253, 'Total loss': 0.35385661323865253} | train loss {'Reaction outcome loss': 0.4402343296874179, 'Total loss': 0.4402343296874179}
2023-01-04 11:18:13,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:13,518 INFO:     Epoch: 18
2023-01-04 11:18:15,132 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.36934526165326437, 'Total loss': 0.36934526165326437} | train loss {'Reaction outcome loss': 0.43851423432139586, 'Total loss': 0.43851423432139586}
2023-01-04 11:18:15,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:15,132 INFO:     Epoch: 19
2023-01-04 11:18:16,727 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3545883963505427, 'Total loss': 0.3545883963505427} | train loss {'Reaction outcome loss': 0.4324435242553697, 'Total loss': 0.4324435242553697}
2023-01-04 11:18:16,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:16,727 INFO:     Epoch: 20
2023-01-04 11:18:18,293 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3849987268447876, 'Total loss': 0.3849987268447876} | train loss {'Reaction outcome loss': 0.42613840788385293, 'Total loss': 0.42613840788385293}
2023-01-04 11:18:18,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:18,294 INFO:     Epoch: 21
2023-01-04 11:18:19,872 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3563374072313309, 'Total loss': 0.3563374072313309} | train loss {'Reaction outcome loss': 0.4212074037505327, 'Total loss': 0.4212074037505327}
2023-01-04 11:18:19,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:19,872 INFO:     Epoch: 22
2023-01-04 11:18:21,307 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.35379084646701814, 'Total loss': 0.35379084646701814} | train loss {'Reaction outcome loss': 0.41907893866300583, 'Total loss': 0.41907893866300583}
2023-01-04 11:18:21,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:21,307 INFO:     Epoch: 23
2023-01-04 11:18:22,890 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3536516467730204, 'Total loss': 0.3536516467730204} | train loss {'Reaction outcome loss': 0.4123459698183693, 'Total loss': 0.4123459698183693}
2023-01-04 11:18:22,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:22,891 INFO:     Epoch: 24
2023-01-04 11:18:24,449 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3489483912785848, 'Total loss': 0.3489483912785848} | train loss {'Reaction outcome loss': 0.4136454523914922, 'Total loss': 0.4136454523914922}
2023-01-04 11:18:24,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:24,449 INFO:     Epoch: 25
2023-01-04 11:18:26,030 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3605318784713745, 'Total loss': 0.3605318784713745} | train loss {'Reaction outcome loss': 0.4092161666846623, 'Total loss': 0.4092161666846623}
2023-01-04 11:18:26,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:26,031 INFO:     Epoch: 26
2023-01-04 11:18:27,625 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3542455385128657, 'Total loss': 0.3542455385128657} | train loss {'Reaction outcome loss': 0.40519841972493775, 'Total loss': 0.40519841972493775}
2023-01-04 11:18:27,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:27,625 INFO:     Epoch: 27
2023-01-04 11:18:29,183 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3427172581354777, 'Total loss': 0.3427172581354777} | train loss {'Reaction outcome loss': 0.4002239744648011, 'Total loss': 0.4002239744648011}
2023-01-04 11:18:29,183 INFO:     Found new best model at epoch 27
2023-01-04 11:18:29,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:29,184 INFO:     Epoch: 28
2023-01-04 11:18:30,652 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3126789833108584, 'Total loss': 0.3126789833108584} | train loss {'Reaction outcome loss': 0.393726287749562, 'Total loss': 0.393726287749562}
2023-01-04 11:18:30,652 INFO:     Found new best model at epoch 28
2023-01-04 11:18:30,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:30,653 INFO:     Epoch: 29
2023-01-04 11:18:32,234 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3306629796822866, 'Total loss': 0.3306629796822866} | train loss {'Reaction outcome loss': 0.393400150167681, 'Total loss': 0.393400150167681}
2023-01-04 11:18:32,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:32,234 INFO:     Epoch: 30
2023-01-04 11:18:33,827 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.34665730396906536, 'Total loss': 0.34665730396906536} | train loss {'Reaction outcome loss': 0.3873700285806273, 'Total loss': 0.3873700285806273}
2023-01-04 11:18:33,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:33,827 INFO:     Epoch: 31
2023-01-04 11:18:35,405 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3525097111860911, 'Total loss': 0.3525097111860911} | train loss {'Reaction outcome loss': 0.38285235329157247, 'Total loss': 0.38285235329157247}
2023-01-04 11:18:35,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:35,405 INFO:     Epoch: 32
2023-01-04 11:18:36,976 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3517517079909643, 'Total loss': 0.3517517079909643} | train loss {'Reaction outcome loss': 0.38349240947596347, 'Total loss': 0.38349240947596347}
2023-01-04 11:18:36,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:36,977 INFO:     Epoch: 33
2023-01-04 11:18:38,453 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3081987569729487, 'Total loss': 0.3081987569729487} | train loss {'Reaction outcome loss': 0.3754953358893412, 'Total loss': 0.3754953358893412}
2023-01-04 11:18:38,453 INFO:     Found new best model at epoch 33
2023-01-04 11:18:38,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:38,454 INFO:     Epoch: 34
2023-01-04 11:18:40,010 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3414912750323614, 'Total loss': 0.3414912750323614} | train loss {'Reaction outcome loss': 0.3729475912549635, 'Total loss': 0.3729475912549635}
2023-01-04 11:18:40,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:40,010 INFO:     Epoch: 35
2023-01-04 11:18:41,574 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.34493849575519564, 'Total loss': 0.34493849575519564} | train loss {'Reaction outcome loss': 0.36844835892645983, 'Total loss': 0.36844835892645983}
2023-01-04 11:18:41,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:41,574 INFO:     Epoch: 36
2023-01-04 11:18:43,142 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.33283986449241637, 'Total loss': 0.33283986449241637} | train loss {'Reaction outcome loss': 0.36968543065072845, 'Total loss': 0.36968543065072845}
2023-01-04 11:18:43,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:43,143 INFO:     Epoch: 37
2023-01-04 11:18:44,688 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3402287095785141, 'Total loss': 0.3402287095785141} | train loss {'Reaction outcome loss': 0.36148254630448173, 'Total loss': 0.36148254630448173}
2023-01-04 11:18:44,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:44,688 INFO:     Epoch: 38
2023-01-04 11:18:46,243 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.32191146314144137, 'Total loss': 0.32191146314144137} | train loss {'Reaction outcome loss': 0.3597165030175752, 'Total loss': 0.3597165030175752}
2023-01-04 11:18:46,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:46,243 INFO:     Epoch: 39
2023-01-04 11:18:47,637 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.34320488572120667, 'Total loss': 0.34320488572120667} | train loss {'Reaction outcome loss': 0.35875236615538597, 'Total loss': 0.35875236615538597}
2023-01-04 11:18:47,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:47,637 INFO:     Epoch: 40
2023-01-04 11:18:49,187 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3243173559506734, 'Total loss': 0.3243173559506734} | train loss {'Reaction outcome loss': 0.355724768889864, 'Total loss': 0.355724768889864}
2023-01-04 11:18:49,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:49,187 INFO:     Epoch: 41
2023-01-04 11:18:50,735 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3067255184054375, 'Total loss': 0.3067255184054375} | train loss {'Reaction outcome loss': 0.3473317599753394, 'Total loss': 0.3473317599753394}
2023-01-04 11:18:50,736 INFO:     Found new best model at epoch 41
2023-01-04 11:18:50,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:50,736 INFO:     Epoch: 42
2023-01-04 11:18:52,288 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.31651075681050617, 'Total loss': 0.31651075681050617} | train loss {'Reaction outcome loss': 0.35165900568457414, 'Total loss': 0.35165900568457414}
2023-01-04 11:18:52,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:52,288 INFO:     Epoch: 43
2023-01-04 11:18:53,852 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.33163081904252373, 'Total loss': 0.33163081904252373} | train loss {'Reaction outcome loss': 0.34420645769930236, 'Total loss': 0.34420645769930236}
2023-01-04 11:18:53,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:53,852 INFO:     Epoch: 44
2023-01-04 11:18:55,393 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.32153170704841616, 'Total loss': 0.32153170704841616} | train loss {'Reaction outcome loss': 0.34217758975705526, 'Total loss': 0.34217758975705526}
2023-01-04 11:18:55,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:55,393 INFO:     Epoch: 45
2023-01-04 11:18:56,804 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.33143676618734996, 'Total loss': 0.33143676618734996} | train loss {'Reaction outcome loss': 0.34105078731901456, 'Total loss': 0.34105078731901456}
2023-01-04 11:18:56,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:56,805 INFO:     Epoch: 46
2023-01-04 11:18:58,388 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3129789367318153, 'Total loss': 0.3129789367318153} | train loss {'Reaction outcome loss': 0.34031619077181297, 'Total loss': 0.34031619077181297}
2023-01-04 11:18:58,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:58,388 INFO:     Epoch: 47
2023-01-04 11:18:59,954 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.330253932873408, 'Total loss': 0.330253932873408} | train loss {'Reaction outcome loss': 0.33888228088073485, 'Total loss': 0.33888228088073485}
2023-01-04 11:18:59,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:18:59,955 INFO:     Epoch: 48
2023-01-04 11:19:01,509 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3135700300335884, 'Total loss': 0.3135700300335884} | train loss {'Reaction outcome loss': 0.3333676699413, 'Total loss': 0.3333676699413}
2023-01-04 11:19:01,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:01,510 INFO:     Epoch: 49
2023-01-04 11:19:03,091 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3356834717094898, 'Total loss': 0.3356834717094898} | train loss {'Reaction outcome loss': 0.3298032447478197, 'Total loss': 0.3298032447478197}
2023-01-04 11:19:03,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:03,092 INFO:     Epoch: 50
2023-01-04 11:19:04,673 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3083814869324366, 'Total loss': 0.3083814869324366} | train loss {'Reaction outcome loss': 0.3292717794432257, 'Total loss': 0.3292717794432257}
2023-01-04 11:19:04,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:04,673 INFO:     Epoch: 51
2023-01-04 11:19:06,080 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3622860456506411, 'Total loss': 0.3622860456506411} | train loss {'Reaction outcome loss': 0.3258148311045918, 'Total loss': 0.3258148311045918}
2023-01-04 11:19:06,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:06,080 INFO:     Epoch: 52
2023-01-04 11:19:07,664 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3224687397480011, 'Total loss': 0.3224687397480011} | train loss {'Reaction outcome loss': 0.32696683299693746, 'Total loss': 0.32696683299693746}
2023-01-04 11:19:07,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:07,664 INFO:     Epoch: 53
2023-01-04 11:19:09,241 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3216649363438288, 'Total loss': 0.3216649363438288} | train loss {'Reaction outcome loss': 0.32000939262500644, 'Total loss': 0.32000939262500644}
2023-01-04 11:19:09,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:09,241 INFO:     Epoch: 54
2023-01-04 11:19:10,808 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.30029005110263823, 'Total loss': 0.30029005110263823} | train loss {'Reaction outcome loss': 0.31991114804561993, 'Total loss': 0.31991114804561993}
2023-01-04 11:19:10,808 INFO:     Found new best model at epoch 54
2023-01-04 11:19:10,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:10,809 INFO:     Epoch: 55
2023-01-04 11:19:12,368 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3038201202948888, 'Total loss': 0.3038201202948888} | train loss {'Reaction outcome loss': 0.32183416533100345, 'Total loss': 0.32183416533100345}
2023-01-04 11:19:12,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:12,369 INFO:     Epoch: 56
2023-01-04 11:19:13,987 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3136927992105484, 'Total loss': 0.3136927992105484} | train loss {'Reaction outcome loss': 0.31710750982165337, 'Total loss': 0.31710750982165337}
2023-01-04 11:19:13,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:13,987 INFO:     Epoch: 57
2023-01-04 11:19:15,452 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.33618103762467705, 'Total loss': 0.33618103762467705} | train loss {'Reaction outcome loss': 0.3163526443642204, 'Total loss': 0.3163526443642204}
2023-01-04 11:19:15,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:15,452 INFO:     Epoch: 58
2023-01-04 11:19:17,062 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3016719937324524, 'Total loss': 0.3016719937324524} | train loss {'Reaction outcome loss': 0.31057198865026453, 'Total loss': 0.31057198865026453}
2023-01-04 11:19:17,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:17,062 INFO:     Epoch: 59
2023-01-04 11:19:18,668 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3039915720621745, 'Total loss': 0.3039915720621745} | train loss {'Reaction outcome loss': 0.31416058037294087, 'Total loss': 0.31416058037294087}
2023-01-04 11:19:18,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:18,669 INFO:     Epoch: 60
2023-01-04 11:19:20,251 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3177150706450144, 'Total loss': 0.3177150706450144} | train loss {'Reaction outcome loss': 0.3141665749632529, 'Total loss': 0.3141665749632529}
2023-01-04 11:19:20,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:20,251 INFO:     Epoch: 61
2023-01-04 11:19:21,836 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.30639421542485556, 'Total loss': 0.30639421542485556} | train loss {'Reaction outcome loss': 0.30465005648179644, 'Total loss': 0.30465005648179644}
2023-01-04 11:19:21,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:21,836 INFO:     Epoch: 62
2023-01-04 11:19:23,403 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.32433009992043177, 'Total loss': 0.32433009992043177} | train loss {'Reaction outcome loss': 0.3126419158312526, 'Total loss': 0.3126419158312526}
2023-01-04 11:19:23,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:23,403 INFO:     Epoch: 63
2023-01-04 11:19:24,854 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.2973403066396713, 'Total loss': 0.2973403066396713} | train loss {'Reaction outcome loss': 0.3058870866840338, 'Total loss': 0.3058870866840338}
2023-01-04 11:19:24,855 INFO:     Found new best model at epoch 63
2023-01-04 11:19:24,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:24,856 INFO:     Epoch: 64
2023-01-04 11:19:26,462 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.35380077362060547, 'Total loss': 0.35380077362060547} | train loss {'Reaction outcome loss': 0.3073534740910043, 'Total loss': 0.3073534740910043}
2023-01-04 11:19:26,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:26,463 INFO:     Epoch: 65
2023-01-04 11:19:28,049 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.31399461229642234, 'Total loss': 0.31399461229642234} | train loss {'Reaction outcome loss': 0.30218468682609334, 'Total loss': 0.30218468682609334}
2023-01-04 11:19:28,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:28,050 INFO:     Epoch: 66
2023-01-04 11:19:29,637 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3154095262289047, 'Total loss': 0.3154095262289047} | train loss {'Reaction outcome loss': 0.29944264081163996, 'Total loss': 0.29944264081163996}
2023-01-04 11:19:29,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:29,637 INFO:     Epoch: 67
2023-01-04 11:19:31,226 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.32980513870716094, 'Total loss': 0.32980513870716094} | train loss {'Reaction outcome loss': 0.2954930577998179, 'Total loss': 0.2954930577998179}
2023-01-04 11:19:31,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:31,226 INFO:     Epoch: 68
2023-01-04 11:19:32,811 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.33772124846776325, 'Total loss': 0.33772124846776325} | train loss {'Reaction outcome loss': 0.298959221201439, 'Total loss': 0.298959221201439}
2023-01-04 11:19:32,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:32,811 INFO:     Epoch: 69
2023-01-04 11:19:34,232 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.29277033507823946, 'Total loss': 0.29277033507823946} | train loss {'Reaction outcome loss': 0.29762356350347946, 'Total loss': 0.29762356350347946}
2023-01-04 11:19:34,232 INFO:     Found new best model at epoch 69
2023-01-04 11:19:34,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:34,233 INFO:     Epoch: 70
2023-01-04 11:19:35,803 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.313601150115331, 'Total loss': 0.313601150115331} | train loss {'Reaction outcome loss': 0.29282768622693356, 'Total loss': 0.29282768622693356}
2023-01-04 11:19:35,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:35,803 INFO:     Epoch: 71
2023-01-04 11:19:37,368 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.345044141014417, 'Total loss': 0.345044141014417} | train loss {'Reaction outcome loss': 0.2940318182545857, 'Total loss': 0.2940318182545857}
2023-01-04 11:19:37,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:37,369 INFO:     Epoch: 72
2023-01-04 11:19:38,931 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.2951972131927808, 'Total loss': 0.2951972131927808} | train loss {'Reaction outcome loss': 0.2942839776621248, 'Total loss': 0.2942839776621248}
2023-01-04 11:19:38,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:38,931 INFO:     Epoch: 73
2023-01-04 11:19:40,512 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.32484320451815923, 'Total loss': 0.32484320451815923} | train loss {'Reaction outcome loss': 0.28878552393212803, 'Total loss': 0.28878552393212803}
2023-01-04 11:19:40,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:40,512 INFO:     Epoch: 74
2023-01-04 11:19:42,073 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3303681174914042, 'Total loss': 0.3303681174914042} | train loss {'Reaction outcome loss': 0.29365897662665724, 'Total loss': 0.29365897662665724}
2023-01-04 11:19:42,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:42,074 INFO:     Epoch: 75
2023-01-04 11:19:43,544 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.33136871258417766, 'Total loss': 0.33136871258417766} | train loss {'Reaction outcome loss': 0.28651482989862015, 'Total loss': 0.28651482989862015}
2023-01-04 11:19:43,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:43,544 INFO:     Epoch: 76
2023-01-04 11:19:45,107 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3025693158308665, 'Total loss': 0.3025693158308665} | train loss {'Reaction outcome loss': 0.2854538187112686, 'Total loss': 0.2854538187112686}
2023-01-04 11:19:45,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:45,108 INFO:     Epoch: 77
2023-01-04 11:19:46,673 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.31600030784805616, 'Total loss': 0.31600030784805616} | train loss {'Reaction outcome loss': 0.285609379601087, 'Total loss': 0.285609379601087}
2023-01-04 11:19:46,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:46,673 INFO:     Epoch: 78
2023-01-04 11:19:48,232 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.343416232864062, 'Total loss': 0.343416232864062} | train loss {'Reaction outcome loss': 0.2853491163275538, 'Total loss': 0.2853491163275538}
2023-01-04 11:19:48,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:48,233 INFO:     Epoch: 79
2023-01-04 11:19:49,801 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3065439114967982, 'Total loss': 0.3065439114967982} | train loss {'Reaction outcome loss': 0.2854264139802787, 'Total loss': 0.2854264139802787}
2023-01-04 11:19:49,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:49,801 INFO:     Epoch: 80
2023-01-04 11:19:51,281 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3220789353052775, 'Total loss': 0.3220789353052775} | train loss {'Reaction outcome loss': 0.283159539375427, 'Total loss': 0.283159539375427}
2023-01-04 11:19:51,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:51,282 INFO:     Epoch: 81
2023-01-04 11:19:52,800 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3043094808856646, 'Total loss': 0.3043094808856646} | train loss {'Reaction outcome loss': 0.28121301306098917, 'Total loss': 0.28121301306098917}
2023-01-04 11:19:52,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:52,800 INFO:     Epoch: 82
2023-01-04 11:19:54,343 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.34627590229113897, 'Total loss': 0.34627590229113897} | train loss {'Reaction outcome loss': 0.28388849061227195, 'Total loss': 0.28388849061227195}
2023-01-04 11:19:54,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:54,345 INFO:     Epoch: 83
2023-01-04 11:19:55,880 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3157941073179245, 'Total loss': 0.3157941073179245} | train loss {'Reaction outcome loss': 0.27623723768187264, 'Total loss': 0.27623723768187264}
2023-01-04 11:19:55,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:55,880 INFO:     Epoch: 84
2023-01-04 11:19:57,421 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.33425753116607665, 'Total loss': 0.33425753116607665} | train loss {'Reaction outcome loss': 0.2780974373819619, 'Total loss': 0.2780974373819619}
2023-01-04 11:19:57,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:57,422 INFO:     Epoch: 85
2023-01-04 11:19:58,965 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.30411740044752755, 'Total loss': 0.30411740044752755} | train loss {'Reaction outcome loss': 0.2765285250098601, 'Total loss': 0.2765285250098601}
2023-01-04 11:19:58,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:19:58,965 INFO:     Epoch: 86
2023-01-04 11:20:00,392 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.34395322302977244, 'Total loss': 0.34395322302977244} | train loss {'Reaction outcome loss': 0.2777797103363232, 'Total loss': 0.2777797103363232}
2023-01-04 11:20:00,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:00,393 INFO:     Epoch: 87
2023-01-04 11:20:01,941 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.348868394891421, 'Total loss': 0.348868394891421} | train loss {'Reaction outcome loss': 0.27267153765054514, 'Total loss': 0.27267153765054514}
2023-01-04 11:20:01,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:01,941 INFO:     Epoch: 88
2023-01-04 11:20:03,529 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.31958085000514985, 'Total loss': 0.31958085000514985} | train loss {'Reaction outcome loss': 0.2751969513177437, 'Total loss': 0.2751969513177437}
2023-01-04 11:20:03,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:03,530 INFO:     Epoch: 89
2023-01-04 11:20:05,082 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3237057457367579, 'Total loss': 0.3237057457367579} | train loss {'Reaction outcome loss': 0.27360147807448015, 'Total loss': 0.27360147807448015}
2023-01-04 11:20:05,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:05,082 INFO:     Epoch: 90
2023-01-04 11:20:06,640 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.31721110213547943, 'Total loss': 0.31721110213547943} | train loss {'Reaction outcome loss': 0.27333056991987853, 'Total loss': 0.27333056991987853}
2023-01-04 11:20:06,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:06,640 INFO:     Epoch: 91
2023-01-04 11:20:08,215 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.31555460939804714, 'Total loss': 0.31555460939804714} | train loss {'Reaction outcome loss': 0.27073682633901597, 'Total loss': 0.27073682633901597}
2023-01-04 11:20:08,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:08,215 INFO:     Epoch: 92
2023-01-04 11:20:09,645 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.33152438898881276, 'Total loss': 0.33152438898881276} | train loss {'Reaction outcome loss': 0.2710425822186644, 'Total loss': 0.2710425822186644}
2023-01-04 11:20:09,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:09,645 INFO:     Epoch: 93
2023-01-04 11:20:11,191 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.2975421828528245, 'Total loss': 0.2975421828528245} | train loss {'Reaction outcome loss': 0.26385726630143874, 'Total loss': 0.26385726630143874}
2023-01-04 11:20:11,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:11,191 INFO:     Epoch: 94
2023-01-04 11:20:12,748 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.33475277821222943, 'Total loss': 0.33475277821222943} | train loss {'Reaction outcome loss': 0.27162840157529733, 'Total loss': 0.27162840157529733}
2023-01-04 11:20:12,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:12,749 INFO:     Epoch: 95
2023-01-04 11:20:14,296 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35161685744921367, 'Total loss': 0.35161685744921367} | train loss {'Reaction outcome loss': 0.2674814964352298, 'Total loss': 0.2674814964352298}
2023-01-04 11:20:14,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:14,297 INFO:     Epoch: 96
2023-01-04 11:20:15,847 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.2942964181303978, 'Total loss': 0.2942964181303978} | train loss {'Reaction outcome loss': 0.26986583295094707, 'Total loss': 0.26986583295094707}
2023-01-04 11:20:15,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:15,847 INFO:     Epoch: 97
2023-01-04 11:20:17,400 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3326323057214419, 'Total loss': 0.3326323057214419} | train loss {'Reaction outcome loss': 0.26659371391156295, 'Total loss': 0.26659371391156295}
2023-01-04 11:20:17,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:17,400 INFO:     Epoch: 98
2023-01-04 11:20:18,808 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3094213177760442, 'Total loss': 0.3094213177760442} | train loss {'Reaction outcome loss': 0.2682027940223687, 'Total loss': 0.2682027940223687}
2023-01-04 11:20:18,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:18,808 INFO:     Epoch: 99
2023-01-04 11:20:20,354 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3192833105723063, 'Total loss': 0.3192833105723063} | train loss {'Reaction outcome loss': 0.2613328815757358, 'Total loss': 0.2613328815757358}
2023-01-04 11:20:20,354 INFO:     Best model found after epoch 70 of 100.
2023-01-04 11:20:20,354 INFO:   Done with stage: TRAINING
2023-01-04 11:20:20,354 INFO:   Starting stage: EVALUATION
2023-01-04 11:20:20,487 INFO:   Done with stage: EVALUATION
2023-01-04 11:20:20,487 INFO:   Leaving out SEQ value Fold_2
2023-01-04 11:20:20,500 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 11:20:20,500 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:20:21,141 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:20:21,142 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:20:21,209 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:20:21,209 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:20:21,209 INFO:     No hyperparam tuning for this model
2023-01-04 11:20:21,209 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:20:21,209 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:20:21,210 INFO:     None feature selector for col prot
2023-01-04 11:20:21,210 INFO:     None feature selector for col prot
2023-01-04 11:20:21,210 INFO:     None feature selector for col prot
2023-01-04 11:20:21,211 INFO:     None feature selector for col chem
2023-01-04 11:20:21,211 INFO:     None feature selector for col chem
2023-01-04 11:20:21,211 INFO:     None feature selector for col chem
2023-01-04 11:20:21,211 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:20:21,211 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:20:21,212 INFO:     Number of params in model 70111
2023-01-04 11:20:21,215 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:20:21,215 INFO:   Starting stage: TRAINING
2023-01-04 11:20:21,258 INFO:     Val loss before train {'Reaction outcome loss': 1.0346460978190104, 'Total loss': 1.0346460978190104}
2023-01-04 11:20:21,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:21,259 INFO:     Epoch: 0
2023-01-04 11:20:22,818 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.767269907395045, 'Total loss': 0.767269907395045} | train loss {'Reaction outcome loss': 0.8430161526210714, 'Total loss': 0.8430161526210714}
2023-01-04 11:20:22,818 INFO:     Found new best model at epoch 0
2023-01-04 11:20:22,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:22,819 INFO:     Epoch: 1
2023-01-04 11:20:24,374 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5900319536526998, 'Total loss': 0.5900319536526998} | train loss {'Reaction outcome loss': 0.6865168324928137, 'Total loss': 0.6865168324928137}
2023-01-04 11:20:24,375 INFO:     Found new best model at epoch 1
2023-01-04 11:20:24,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:24,376 INFO:     Epoch: 2
2023-01-04 11:20:25,930 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5682647466659546, 'Total loss': 0.5682647466659546} | train loss {'Reaction outcome loss': 0.5931719510775545, 'Total loss': 0.5931719510775545}
2023-01-04 11:20:25,930 INFO:     Found new best model at epoch 2
2023-01-04 11:20:25,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:25,931 INFO:     Epoch: 3
2023-01-04 11:20:27,370 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5369818349679311, 'Total loss': 0.5369818349679311} | train loss {'Reaction outcome loss': 0.55079929260672, 'Total loss': 0.55079929260672}
2023-01-04 11:20:27,370 INFO:     Found new best model at epoch 3
2023-01-04 11:20:27,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:27,371 INFO:     Epoch: 4
2023-01-04 11:20:28,967 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5079292078812917, 'Total loss': 0.5079292078812917} | train loss {'Reaction outcome loss': 0.5308378733647312, 'Total loss': 0.5308378733647312}
2023-01-04 11:20:28,967 INFO:     Found new best model at epoch 4
2023-01-04 11:20:28,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:28,968 INFO:     Epoch: 5
2023-01-04 11:20:30,551 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5031634251276652, 'Total loss': 0.5031634251276652} | train loss {'Reaction outcome loss': 0.5025401302533757, 'Total loss': 0.5025401302533757}
2023-01-04 11:20:30,552 INFO:     Found new best model at epoch 5
2023-01-04 11:20:30,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:30,553 INFO:     Epoch: 6
2023-01-04 11:20:32,144 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.52136832177639, 'Total loss': 0.52136832177639} | train loss {'Reaction outcome loss': 0.49081940361487586, 'Total loss': 0.49081940361487586}
2023-01-04 11:20:32,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:32,144 INFO:     Epoch: 7
2023-01-04 11:20:33,723 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46909435192743937, 'Total loss': 0.46909435192743937} | train loss {'Reaction outcome loss': 0.47997203000240785, 'Total loss': 0.47997203000240785}
2023-01-04 11:20:33,723 INFO:     Found new best model at epoch 7
2023-01-04 11:20:33,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:33,724 INFO:     Epoch: 8
2023-01-04 11:20:35,296 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.502301017443339, 'Total loss': 0.502301017443339} | train loss {'Reaction outcome loss': 0.48235786949162895, 'Total loss': 0.48235786949162895}
2023-01-04 11:20:35,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:35,297 INFO:     Epoch: 9
2023-01-04 11:20:36,748 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4962586541970571, 'Total loss': 0.4962586541970571} | train loss {'Reaction outcome loss': 0.49429008569838345, 'Total loss': 0.49429008569838345}
2023-01-04 11:20:36,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:36,748 INFO:     Epoch: 10
2023-01-04 11:20:38,337 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4717467377583186, 'Total loss': 0.4717467377583186} | train loss {'Reaction outcome loss': 0.4882823064238081, 'Total loss': 0.4882823064238081}
2023-01-04 11:20:38,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:38,337 INFO:     Epoch: 11
2023-01-04 11:20:39,916 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4425889531771342, 'Total loss': 0.4425889531771342} | train loss {'Reaction outcome loss': 0.45811861451796215, 'Total loss': 0.45811861451796215}
2023-01-04 11:20:39,916 INFO:     Found new best model at epoch 11
2023-01-04 11:20:39,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:39,917 INFO:     Epoch: 12
2023-01-04 11:20:41,483 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47525849839051565, 'Total loss': 0.47525849839051565} | train loss {'Reaction outcome loss': 0.4492879447027825, 'Total loss': 0.4492879447027825}
2023-01-04 11:20:41,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:41,483 INFO:     Epoch: 13
2023-01-04 11:20:43,074 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4609009156624476, 'Total loss': 0.4609009156624476} | train loss {'Reaction outcome loss': 0.444708073316007, 'Total loss': 0.444708073316007}
2023-01-04 11:20:43,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:43,075 INFO:     Epoch: 14
2023-01-04 11:20:44,677 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4581081847349803, 'Total loss': 0.4581081847349803} | train loss {'Reaction outcome loss': 0.4406383810375068, 'Total loss': 0.4406383810375068}
2023-01-04 11:20:44,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:44,678 INFO:     Epoch: 15
2023-01-04 11:20:46,149 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44323986073335014, 'Total loss': 0.44323986073335014} | train loss {'Reaction outcome loss': 0.44001426460686227, 'Total loss': 0.44001426460686227}
2023-01-04 11:20:46,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:46,150 INFO:     Epoch: 16
2023-01-04 11:20:47,734 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4463595678408941, 'Total loss': 0.4463595678408941} | train loss {'Reaction outcome loss': 0.43290495532362355, 'Total loss': 0.43290495532362355}
2023-01-04 11:20:47,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:47,735 INFO:     Epoch: 17
2023-01-04 11:20:49,309 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4483335892359416, 'Total loss': 0.4483335892359416} | train loss {'Reaction outcome loss': 0.43106301890119264, 'Total loss': 0.43106301890119264}
2023-01-04 11:20:49,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:49,309 INFO:     Epoch: 18
2023-01-04 11:20:50,888 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4901625692844391, 'Total loss': 0.4901625692844391} | train loss {'Reaction outcome loss': 0.4319349174266276, 'Total loss': 0.4319349174266276}
2023-01-04 11:20:50,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:50,888 INFO:     Epoch: 19
2023-01-04 11:20:52,457 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4460749626159668, 'Total loss': 0.4460749626159668} | train loss {'Reaction outcome loss': 0.4455895868190767, 'Total loss': 0.4455895868190767}
2023-01-04 11:20:52,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:52,458 INFO:     Epoch: 20
2023-01-04 11:20:54,033 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4790305743614833, 'Total loss': 0.4790305743614833} | train loss {'Reaction outcome loss': 0.4202954422815811, 'Total loss': 0.4202954422815811}
2023-01-04 11:20:54,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:54,034 INFO:     Epoch: 21
2023-01-04 11:20:55,488 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43472868800163267, 'Total loss': 0.43472868800163267} | train loss {'Reaction outcome loss': 0.4169552842344063, 'Total loss': 0.4169552842344063}
2023-01-04 11:20:55,488 INFO:     Found new best model at epoch 21
2023-01-04 11:20:55,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:55,489 INFO:     Epoch: 22
2023-01-04 11:20:57,106 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4282367060581843, 'Total loss': 0.4282367060581843} | train loss {'Reaction outcome loss': 0.4140670200965057, 'Total loss': 0.4140670200965057}
2023-01-04 11:20:57,106 INFO:     Found new best model at epoch 22
2023-01-04 11:20:57,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:57,107 INFO:     Epoch: 23
2023-01-04 11:20:58,707 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43594317585229875, 'Total loss': 0.43594317585229875} | train loss {'Reaction outcome loss': 0.4092362059847168, 'Total loss': 0.4092362059847168}
2023-01-04 11:20:58,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:20:58,707 INFO:     Epoch: 24
2023-01-04 11:21:00,306 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4404914150635401, 'Total loss': 0.4404914150635401} | train loss {'Reaction outcome loss': 0.41705278182348265, 'Total loss': 0.41705278182348265}
2023-01-04 11:21:00,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:00,307 INFO:     Epoch: 25
2023-01-04 11:21:01,915 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41940940618515016, 'Total loss': 0.41940940618515016} | train loss {'Reaction outcome loss': 0.40465745119296986, 'Total loss': 0.40465745119296986}
2023-01-04 11:21:01,915 INFO:     Found new best model at epoch 25
2023-01-04 11:21:01,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:01,916 INFO:     Epoch: 26
2023-01-04 11:21:03,511 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3969434529542923, 'Total loss': 0.3969434529542923} | train loss {'Reaction outcome loss': 0.3975424105799217, 'Total loss': 0.3975424105799217}
2023-01-04 11:21:03,511 INFO:     Found new best model at epoch 26
2023-01-04 11:21:03,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:03,512 INFO:     Epoch: 27
2023-01-04 11:21:04,977 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41788339912891387, 'Total loss': 0.41788339912891387} | train loss {'Reaction outcome loss': 0.39624594519103784, 'Total loss': 0.39624594519103784}
2023-01-04 11:21:04,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:04,977 INFO:     Epoch: 28
2023-01-04 11:21:06,592 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41886247793833414, 'Total loss': 0.41886247793833414} | train loss {'Reaction outcome loss': 0.3893702230378277, 'Total loss': 0.3893702230378277}
2023-01-04 11:21:06,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:06,593 INFO:     Epoch: 29
2023-01-04 11:21:08,192 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41892500122388204, 'Total loss': 0.41892500122388204} | train loss {'Reaction outcome loss': 0.3906593750352445, 'Total loss': 0.3906593750352445}
2023-01-04 11:21:08,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:08,192 INFO:     Epoch: 30
2023-01-04 11:21:09,776 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4082755943139394, 'Total loss': 0.4082755943139394} | train loss {'Reaction outcome loss': 0.41716537563521683, 'Total loss': 0.41716537563521683}
2023-01-04 11:21:09,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:09,776 INFO:     Epoch: 31
2023-01-04 11:21:11,380 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4161896288394928, 'Total loss': 0.4161896288394928} | train loss {'Reaction outcome loss': 0.3839342634875219, 'Total loss': 0.3839342634875219}
2023-01-04 11:21:11,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:11,380 INFO:     Epoch: 32
2023-01-04 11:21:12,881 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4076829135417938, 'Total loss': 0.4076829135417938} | train loss {'Reaction outcome loss': 0.37875699050778494, 'Total loss': 0.37875699050778494}
2023-01-04 11:21:12,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:12,882 INFO:     Epoch: 33
2023-01-04 11:21:14,439 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4030652314424515, 'Total loss': 0.4030652314424515} | train loss {'Reaction outcome loss': 0.3750350406592496, 'Total loss': 0.3750350406592496}
2023-01-04 11:21:14,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:14,439 INFO:     Epoch: 34
2023-01-04 11:21:16,026 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39546726246674857, 'Total loss': 0.39546726246674857} | train loss {'Reaction outcome loss': 0.37329606247552927, 'Total loss': 0.37329606247552927}
2023-01-04 11:21:16,026 INFO:     Found new best model at epoch 34
2023-01-04 11:21:16,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:16,027 INFO:     Epoch: 35
2023-01-04 11:21:17,598 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42650223076343535, 'Total loss': 0.42650223076343535} | train loss {'Reaction outcome loss': 0.38042407898583275, 'Total loss': 0.38042407898583275}
2023-01-04 11:21:17,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:17,598 INFO:     Epoch: 36
2023-01-04 11:21:19,169 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41053413450717924, 'Total loss': 0.41053413450717924} | train loss {'Reaction outcome loss': 0.3698501606793244, 'Total loss': 0.3698501606793244}
2023-01-04 11:21:19,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:19,170 INFO:     Epoch: 37
2023-01-04 11:21:20,764 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4112152894337972, 'Total loss': 0.4112152894337972} | train loss {'Reaction outcome loss': 0.3655176568958584, 'Total loss': 0.3655176568958584}
2023-01-04 11:21:20,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:20,764 INFO:     Epoch: 38
2023-01-04 11:21:22,203 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4193493982156118, 'Total loss': 0.4193493982156118} | train loss {'Reaction outcome loss': 0.36049157482963323, 'Total loss': 0.36049157482963323}
2023-01-04 11:21:22,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:22,203 INFO:     Epoch: 39
2023-01-04 11:21:23,789 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4316610336303711, 'Total loss': 0.4316610336303711} | train loss {'Reaction outcome loss': 0.3579936181127593, 'Total loss': 0.3579936181127593}
2023-01-04 11:21:23,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:23,789 INFO:     Epoch: 40
2023-01-04 11:21:25,364 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3970130781332652, 'Total loss': 0.3970130781332652} | train loss {'Reaction outcome loss': 0.3591907766383099, 'Total loss': 0.3591907766383099}
2023-01-04 11:21:25,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:25,364 INFO:     Epoch: 41
2023-01-04 11:21:26,953 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.401068647702535, 'Total loss': 0.401068647702535} | train loss {'Reaction outcome loss': 0.3533988733559955, 'Total loss': 0.3533988733559955}
2023-01-04 11:21:26,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:26,953 INFO:     Epoch: 42
2023-01-04 11:21:28,524 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4214688370625178, 'Total loss': 0.4214688370625178} | train loss {'Reaction outcome loss': 0.3548110239477693, 'Total loss': 0.3548110239477693}
2023-01-04 11:21:28,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:28,524 INFO:     Epoch: 43
2023-01-04 11:21:30,103 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4462439517180125, 'Total loss': 0.4462439517180125} | train loss {'Reaction outcome loss': 0.34712068175671107, 'Total loss': 0.34712068175671107}
2023-01-04 11:21:30,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:30,103 INFO:     Epoch: 44
2023-01-04 11:21:31,546 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4065212647120158, 'Total loss': 0.4065212647120158} | train loss {'Reaction outcome loss': 0.3468633268894864, 'Total loss': 0.3468633268894864}
2023-01-04 11:21:31,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:31,546 INFO:     Epoch: 45
2023-01-04 11:21:33,124 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3930171012878418, 'Total loss': 0.3930171012878418} | train loss {'Reaction outcome loss': 0.34212783055272006, 'Total loss': 0.34212783055272006}
2023-01-04 11:21:33,124 INFO:     Found new best model at epoch 45
2023-01-04 11:21:33,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:33,125 INFO:     Epoch: 46
2023-01-04 11:21:34,703 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40410643617312114, 'Total loss': 0.40410643617312114} | train loss {'Reaction outcome loss': 0.3414378132860082, 'Total loss': 0.3414378132860082}
2023-01-04 11:21:34,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:34,703 INFO:     Epoch: 47
2023-01-04 11:21:36,286 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4122462451457977, 'Total loss': 0.4122462451457977} | train loss {'Reaction outcome loss': 0.33512479777098214, 'Total loss': 0.33512479777098214}
2023-01-04 11:21:36,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:36,288 INFO:     Epoch: 48
2023-01-04 11:21:37,857 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42245491842428845, 'Total loss': 0.42245491842428845} | train loss {'Reaction outcome loss': 0.3376659718308382, 'Total loss': 0.3376659718308382}
2023-01-04 11:21:37,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:37,857 INFO:     Epoch: 49
2023-01-04 11:21:39,426 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4166571875413259, 'Total loss': 0.4166571875413259} | train loss {'Reaction outcome loss': 0.3300560139460435, 'Total loss': 0.3300560139460435}
2023-01-04 11:21:39,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:39,426 INFO:     Epoch: 50
2023-01-04 11:21:40,883 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3903813898563385, 'Total loss': 0.3903813898563385} | train loss {'Reaction outcome loss': 0.3334140469846518, 'Total loss': 0.3334140469846518}
2023-01-04 11:21:40,883 INFO:     Found new best model at epoch 50
2023-01-04 11:21:40,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:40,884 INFO:     Epoch: 51
2023-01-04 11:21:42,465 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42341100573539736, 'Total loss': 0.42341100573539736} | train loss {'Reaction outcome loss': 0.33937493550500064, 'Total loss': 0.33937493550500064}
2023-01-04 11:21:42,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:42,466 INFO:     Epoch: 52
2023-01-04 11:21:44,036 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3993996818860372, 'Total loss': 0.3993996818860372} | train loss {'Reaction outcome loss': 0.32561082319032564, 'Total loss': 0.32561082319032564}
2023-01-04 11:21:44,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:44,036 INFO:     Epoch: 53
2023-01-04 11:21:45,611 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39832132558027905, 'Total loss': 0.39832132558027905} | train loss {'Reaction outcome loss': 0.31989312059907377, 'Total loss': 0.31989312059907377}
2023-01-04 11:21:45,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:45,612 INFO:     Epoch: 54
2023-01-04 11:21:47,201 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4002643893162409, 'Total loss': 0.4002643893162409} | train loss {'Reaction outcome loss': 0.3224430004899488, 'Total loss': 0.3224430004899488}
2023-01-04 11:21:47,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:47,201 INFO:     Epoch: 55
2023-01-04 11:21:48,770 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3923744986454646, 'Total loss': 0.3923744986454646} | train loss {'Reaction outcome loss': 0.32008901748960616, 'Total loss': 0.32008901748960616}
2023-01-04 11:21:48,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:48,770 INFO:     Epoch: 56
2023-01-04 11:21:50,230 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39423123200734456, 'Total loss': 0.39423123200734456} | train loss {'Reaction outcome loss': 0.3189320614244249, 'Total loss': 0.3189320614244249}
2023-01-04 11:21:50,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:50,230 INFO:     Epoch: 57
2023-01-04 11:21:51,823 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39080228805541994, 'Total loss': 0.39080228805541994} | train loss {'Reaction outcome loss': 0.31641488889421243, 'Total loss': 0.31641488889421243}
2023-01-04 11:21:51,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:51,823 INFO:     Epoch: 58
2023-01-04 11:21:53,433 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4131637295087179, 'Total loss': 0.4131637295087179} | train loss {'Reaction outcome loss': 0.31410104980813747, 'Total loss': 0.31410104980813747}
2023-01-04 11:21:53,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:53,433 INFO:     Epoch: 59
2023-01-04 11:21:55,012 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42317517499128976, 'Total loss': 0.42317517499128976} | train loss {'Reaction outcome loss': 0.3091456673412366, 'Total loss': 0.3091456673412366}
2023-01-04 11:21:55,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:55,013 INFO:     Epoch: 60
2023-01-04 11:21:56,620 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39482619961102805, 'Total loss': 0.39482619961102805} | train loss {'Reaction outcome loss': 0.3063020796677017, 'Total loss': 0.3063020796677017}
2023-01-04 11:21:56,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:56,621 INFO:     Epoch: 61
2023-01-04 11:21:58,196 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3910880297422409, 'Total loss': 0.3910880297422409} | train loss {'Reaction outcome loss': 0.3073902506603981, 'Total loss': 0.3073902506603981}
2023-01-04 11:21:58,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:58,197 INFO:     Epoch: 62
2023-01-04 11:21:59,658 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40746626953283943, 'Total loss': 0.40746626953283943} | train loss {'Reaction outcome loss': 0.30081432070448133, 'Total loss': 0.30081432070448133}
2023-01-04 11:21:59,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:21:59,659 INFO:     Epoch: 63
2023-01-04 11:22:01,253 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41871535579363506, 'Total loss': 0.41871535579363506} | train loss {'Reaction outcome loss': 0.3042081410429724, 'Total loss': 0.3042081410429724}
2023-01-04 11:22:01,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:01,254 INFO:     Epoch: 64
2023-01-04 11:22:02,839 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40160688757896423, 'Total loss': 0.40160688757896423} | train loss {'Reaction outcome loss': 0.30393662674991967, 'Total loss': 0.30393662674991967}
2023-01-04 11:22:02,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:02,840 INFO:     Epoch: 65
2023-01-04 11:22:04,443 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4253448526064555, 'Total loss': 0.4253448526064555} | train loss {'Reaction outcome loss': 0.2979706181179516, 'Total loss': 0.2979706181179516}
2023-01-04 11:22:04,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:04,443 INFO:     Epoch: 66
2023-01-04 11:22:06,044 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.440680593252182, 'Total loss': 0.440680593252182} | train loss {'Reaction outcome loss': 0.29925297292462294, 'Total loss': 0.29925297292462294}
2023-01-04 11:22:06,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:06,045 INFO:     Epoch: 67
2023-01-04 11:22:07,509 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4191389818986257, 'Total loss': 0.4191389818986257} | train loss {'Reaction outcome loss': 0.3181851608813673, 'Total loss': 0.3181851608813673}
2023-01-04 11:22:07,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:07,510 INFO:     Epoch: 68
2023-01-04 11:22:09,084 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38991957406202954, 'Total loss': 0.38991957406202954} | train loss {'Reaction outcome loss': 0.3474637193527694, 'Total loss': 0.3474637193527694}
2023-01-04 11:22:09,084 INFO:     Found new best model at epoch 68
2023-01-04 11:22:09,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:09,084 INFO:     Epoch: 69
2023-01-04 11:22:10,657 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40930840571721394, 'Total loss': 0.40930840571721394} | train loss {'Reaction outcome loss': 0.2929713307623414, 'Total loss': 0.2929713307623414}
2023-01-04 11:22:10,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:10,658 INFO:     Epoch: 70
2023-01-04 11:22:12,240 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39614764948685965, 'Total loss': 0.39614764948685965} | train loss {'Reaction outcome loss': 0.2913890382809821, 'Total loss': 0.2913890382809821}
2023-01-04 11:22:12,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:12,241 INFO:     Epoch: 71
2023-01-04 11:22:13,824 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4211292972167333, 'Total loss': 0.4211292972167333} | train loss {'Reaction outcome loss': 0.2915956307982054, 'Total loss': 0.2915956307982054}
2023-01-04 11:22:13,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:13,825 INFO:     Epoch: 72
2023-01-04 11:22:15,443 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41542557179927825, 'Total loss': 0.41542557179927825} | train loss {'Reaction outcome loss': 0.2902761790378397, 'Total loss': 0.2902761790378397}
2023-01-04 11:22:15,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:15,443 INFO:     Epoch: 73
2023-01-04 11:22:16,906 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4077787041664124, 'Total loss': 0.4077787041664124} | train loss {'Reaction outcome loss': 0.29048742046174797, 'Total loss': 0.29048742046174797}
2023-01-04 11:22:16,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:16,906 INFO:     Epoch: 74
2023-01-04 11:22:18,476 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4263039410114288, 'Total loss': 0.4263039410114288} | train loss {'Reaction outcome loss': 0.29379163073051884, 'Total loss': 0.29379163073051884}
2023-01-04 11:22:18,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:18,477 INFO:     Epoch: 75
2023-01-04 11:22:20,047 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4087589353322983, 'Total loss': 0.4087589353322983} | train loss {'Reaction outcome loss': 0.2811153836329417, 'Total loss': 0.2811153836329417}
2023-01-04 11:22:20,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:20,048 INFO:     Epoch: 76
2023-01-04 11:22:21,631 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3948350081841151, 'Total loss': 0.3948350081841151} | train loss {'Reaction outcome loss': 0.28353936170342553, 'Total loss': 0.28353936170342553}
2023-01-04 11:22:21,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:21,631 INFO:     Epoch: 77
2023-01-04 11:22:23,205 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41932877401510876, 'Total loss': 0.41932877401510876} | train loss {'Reaction outcome loss': 0.2820928685326615, 'Total loss': 0.2820928685326615}
2023-01-04 11:22:23,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:23,205 INFO:     Epoch: 78
2023-01-04 11:22:24,794 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44237549702326456, 'Total loss': 0.44237549702326456} | train loss {'Reaction outcome loss': 0.2828426491224504, 'Total loss': 0.2828426491224504}
2023-01-04 11:22:24,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:24,794 INFO:     Epoch: 79
2023-01-04 11:22:26,301 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4138687511285146, 'Total loss': 0.4138687511285146} | train loss {'Reaction outcome loss': 0.2814214354839878, 'Total loss': 0.2814214354839878}
2023-01-04 11:22:26,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:26,302 INFO:     Epoch: 80
2023-01-04 11:22:27,879 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4006603350241979, 'Total loss': 0.4006603350241979} | train loss {'Reaction outcome loss': 0.28108466056890896, 'Total loss': 0.28108466056890896}
2023-01-04 11:22:27,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:27,880 INFO:     Epoch: 81
2023-01-04 11:22:29,443 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40092059373855593, 'Total loss': 0.40092059373855593} | train loss {'Reaction outcome loss': 0.2768169469715455, 'Total loss': 0.2768169469715455}
2023-01-04 11:22:29,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:29,443 INFO:     Epoch: 82
2023-01-04 11:22:31,005 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45788322389125824, 'Total loss': 0.45788322389125824} | train loss {'Reaction outcome loss': 0.27605776562004525, 'Total loss': 0.27605776562004525}
2023-01-04 11:22:31,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:31,006 INFO:     Epoch: 83
2023-01-04 11:22:32,570 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44167080720265706, 'Total loss': 0.44167080720265706} | train loss {'Reaction outcome loss': 0.27487166933175444, 'Total loss': 0.27487166933175444}
2023-01-04 11:22:32,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:32,570 INFO:     Epoch: 84
2023-01-04 11:22:34,144 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41868130415678023, 'Total loss': 0.41868130415678023} | train loss {'Reaction outcome loss': 0.2991581184492595, 'Total loss': 0.2991581184492595}
2023-01-04 11:22:34,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:34,144 INFO:     Epoch: 85
2023-01-04 11:22:35,613 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4048783411582311, 'Total loss': 0.4048783411582311} | train loss {'Reaction outcome loss': 0.27746032645412977, 'Total loss': 0.27746032645412977}
2023-01-04 11:22:35,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:35,613 INFO:     Epoch: 86
2023-01-04 11:22:37,198 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4262307162086169, 'Total loss': 0.4262307162086169} | train loss {'Reaction outcome loss': 0.2725759739245194, 'Total loss': 0.2725759739245194}
2023-01-04 11:22:37,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:37,198 INFO:     Epoch: 87
2023-01-04 11:22:38,770 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41669514377911887, 'Total loss': 0.41669514377911887} | train loss {'Reaction outcome loss': 0.26967726938048564, 'Total loss': 0.26967726938048564}
2023-01-04 11:22:38,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:38,770 INFO:     Epoch: 88
2023-01-04 11:22:40,352 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4520997683207194, 'Total loss': 0.4520997683207194} | train loss {'Reaction outcome loss': 0.28334016255710437, 'Total loss': 0.28334016255710437}
2023-01-04 11:22:40,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:40,352 INFO:     Epoch: 89
2023-01-04 11:22:41,934 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4318510264158249, 'Total loss': 0.4318510264158249} | train loss {'Reaction outcome loss': 0.2998129433641831, 'Total loss': 0.2998129433641831}
2023-01-04 11:22:41,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:41,935 INFO:     Epoch: 90
2023-01-04 11:22:43,525 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40557973384857177, 'Total loss': 0.40557973384857177} | train loss {'Reaction outcome loss': 0.28574633261145, 'Total loss': 0.28574633261145}
2023-01-04 11:22:43,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:43,526 INFO:     Epoch: 91
2023-01-04 11:22:45,019 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4197722151875496, 'Total loss': 0.4197722151875496} | train loss {'Reaction outcome loss': 0.27419492591311806, 'Total loss': 0.27419492591311806}
2023-01-04 11:22:45,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:45,019 INFO:     Epoch: 92
2023-01-04 11:22:46,588 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4317992726961772, 'Total loss': 0.4317992726961772} | train loss {'Reaction outcome loss': 0.26753823948219296, 'Total loss': 0.26753823948219296}
2023-01-04 11:22:46,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:46,589 INFO:     Epoch: 93
2023-01-04 11:22:48,164 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4110609581073125, 'Total loss': 0.4110609581073125} | train loss {'Reaction outcome loss': 0.2652298242011465, 'Total loss': 0.2652298242011465}
2023-01-04 11:22:48,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:48,164 INFO:     Epoch: 94
2023-01-04 11:22:49,750 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4045756936073303, 'Total loss': 0.4045756936073303} | train loss {'Reaction outcome loss': 0.2731418873088947, 'Total loss': 0.2731418873088947}
2023-01-04 11:22:49,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:49,751 INFO:     Epoch: 95
2023-01-04 11:22:51,318 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4018253336350123, 'Total loss': 0.4018253336350123} | train loss {'Reaction outcome loss': 0.29199601560021227, 'Total loss': 0.29199601560021227}
2023-01-04 11:22:51,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:51,318 INFO:     Epoch: 96
2023-01-04 11:22:52,869 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4242238680521647, 'Total loss': 0.4242238680521647} | train loss {'Reaction outcome loss': 0.2646300475634155, 'Total loss': 0.2646300475634155}
2023-01-04 11:22:52,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:52,869 INFO:     Epoch: 97
2023-01-04 11:22:54,367 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40972207188606263, 'Total loss': 0.40972207188606263} | train loss {'Reaction outcome loss': 0.2644039570662679, 'Total loss': 0.2644039570662679}
2023-01-04 11:22:54,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:54,367 INFO:     Epoch: 98
2023-01-04 11:22:55,943 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43998395403226215, 'Total loss': 0.43998395403226215} | train loss {'Reaction outcome loss': 0.2683921496559312, 'Total loss': 0.2683921496559312}
2023-01-04 11:22:55,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:55,943 INFO:     Epoch: 99
2023-01-04 11:22:57,512 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42985553443431856, 'Total loss': 0.42985553443431856} | train loss {'Reaction outcome loss': 0.28130082235440856, 'Total loss': 0.28130082235440856}
2023-01-04 11:22:57,513 INFO:     Best model found after epoch 69 of 100.
2023-01-04 11:22:57,513 INFO:   Done with stage: TRAINING
2023-01-04 11:22:57,513 INFO:   Starting stage: EVALUATION
2023-01-04 11:22:57,641 INFO:   Done with stage: EVALUATION
2023-01-04 11:22:57,641 INFO:   Leaving out SEQ value Fold_3
2023-01-04 11:22:57,653 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 11:22:57,654 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:22:58,305 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:22:58,305 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:22:58,373 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:22:58,374 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:22:58,374 INFO:     No hyperparam tuning for this model
2023-01-04 11:22:58,374 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:22:58,374 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:22:58,374 INFO:     None feature selector for col prot
2023-01-04 11:22:58,375 INFO:     None feature selector for col prot
2023-01-04 11:22:58,375 INFO:     None feature selector for col prot
2023-01-04 11:22:58,375 INFO:     None feature selector for col chem
2023-01-04 11:22:58,375 INFO:     None feature selector for col chem
2023-01-04 11:22:58,375 INFO:     None feature selector for col chem
2023-01-04 11:22:58,375 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:22:58,375 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:22:58,376 INFO:     Number of params in model 70111
2023-01-04 11:22:58,380 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:22:58,380 INFO:   Starting stage: TRAINING
2023-01-04 11:22:58,424 INFO:     Val loss before train {'Reaction outcome loss': 1.0930239359537761, 'Total loss': 1.0930239359537761}
2023-01-04 11:22:58,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:58,424 INFO:     Epoch: 0
2023-01-04 11:22:59,992 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7677752037843069, 'Total loss': 0.7677752037843069} | train loss {'Reaction outcome loss': 0.8336971115212941, 'Total loss': 0.8336971115212941}
2023-01-04 11:22:59,992 INFO:     Found new best model at epoch 0
2023-01-04 11:22:59,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:22:59,993 INFO:     Epoch: 1
2023-01-04 11:23:01,559 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6470013578732808, 'Total loss': 0.6470013578732808} | train loss {'Reaction outcome loss': 0.6625499273076707, 'Total loss': 0.6625499273076707}
2023-01-04 11:23:01,559 INFO:     Found new best model at epoch 1
2023-01-04 11:23:01,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:01,560 INFO:     Epoch: 2
2023-01-04 11:23:03,056 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5586456477642059, 'Total loss': 0.5586456477642059} | train loss {'Reaction outcome loss': 0.5750965908696146, 'Total loss': 0.5750965908696146}
2023-01-04 11:23:03,056 INFO:     Found new best model at epoch 2
2023-01-04 11:23:03,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:03,057 INFO:     Epoch: 3
2023-01-04 11:23:04,644 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5484118084112803, 'Total loss': 0.5484118084112803} | train loss {'Reaction outcome loss': 0.5370961669022623, 'Total loss': 0.5370961669022623}
2023-01-04 11:23:04,644 INFO:     Found new best model at epoch 3
2023-01-04 11:23:04,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:04,645 INFO:     Epoch: 4
2023-01-04 11:23:06,230 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5460255185763041, 'Total loss': 0.5460255185763041} | train loss {'Reaction outcome loss': 0.5357958208499611, 'Total loss': 0.5357958208499611}
2023-01-04 11:23:06,230 INFO:     Found new best model at epoch 4
2023-01-04 11:23:06,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:06,231 INFO:     Epoch: 5
2023-01-04 11:23:07,811 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5287476936976115, 'Total loss': 0.5287476936976115} | train loss {'Reaction outcome loss': 0.5200563353094934, 'Total loss': 0.5200563353094934}
2023-01-04 11:23:07,811 INFO:     Found new best model at epoch 5
2023-01-04 11:23:07,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:07,811 INFO:     Epoch: 6
2023-01-04 11:23:09,395 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5429456949234008, 'Total loss': 0.5429456949234008} | train loss {'Reaction outcome loss': 0.491781155897247, 'Total loss': 0.491781155897247}
2023-01-04 11:23:09,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:09,395 INFO:     Epoch: 7
2023-01-04 11:23:10,917 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5080039858818054, 'Total loss': 0.5080039858818054} | train loss {'Reaction outcome loss': 0.47982656264650647, 'Total loss': 0.47982656264650647}
2023-01-04 11:23:10,918 INFO:     Found new best model at epoch 7
2023-01-04 11:23:10,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:10,918 INFO:     Epoch: 8
2023-01-04 11:23:11,983 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5312342415253322, 'Total loss': 0.5312342415253322} | train loss {'Reaction outcome loss': 0.47593849468166416, 'Total loss': 0.47593849468166416}
2023-01-04 11:23:11,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:11,984 INFO:     Epoch: 9
2023-01-04 11:23:13,015 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5292573134104411, 'Total loss': 0.5292573134104411} | train loss {'Reaction outcome loss': 0.465876408069786, 'Total loss': 0.465876408069786}
2023-01-04 11:23:13,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:13,015 INFO:     Epoch: 10
2023-01-04 11:23:14,054 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5156309167544048, 'Total loss': 0.5156309167544048} | train loss {'Reaction outcome loss': 0.4635621583548145, 'Total loss': 0.4635621583548145}
2023-01-04 11:23:14,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:14,054 INFO:     Epoch: 11
2023-01-04 11:23:15,083 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5062895178794861, 'Total loss': 0.5062895178794861} | train loss {'Reaction outcome loss': 0.45870097958739253, 'Total loss': 0.45870097958739253}
2023-01-04 11:23:15,084 INFO:     Found new best model at epoch 11
2023-01-04 11:23:15,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:15,084 INFO:     Epoch: 12
2023-01-04 11:23:16,263 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5096964657306671, 'Total loss': 0.5096964657306671} | train loss {'Reaction outcome loss': 0.4640050657849381, 'Total loss': 0.4640050657849381}
2023-01-04 11:23:16,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:16,263 INFO:     Epoch: 13
2023-01-04 11:23:17,796 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5393164118131002, 'Total loss': 0.5393164118131002} | train loss {'Reaction outcome loss': 0.46784862654580583, 'Total loss': 0.46784862654580583}
2023-01-04 11:23:17,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:17,796 INFO:     Epoch: 14
2023-01-04 11:23:19,365 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5065361559391022, 'Total loss': 0.5065361559391022} | train loss {'Reaction outcome loss': 0.4606682910732385, 'Total loss': 0.4606682910732385}
2023-01-04 11:23:19,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:19,366 INFO:     Epoch: 15
2023-01-04 11:23:20,926 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5047941327095031, 'Total loss': 0.5047941327095031} | train loss {'Reaction outcome loss': 0.46515737649431266, 'Total loss': 0.46515737649431266}
2023-01-04 11:23:20,926 INFO:     Found new best model at epoch 15
2023-01-04 11:23:20,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:20,927 INFO:     Epoch: 16
2023-01-04 11:23:22,489 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49731361865997314, 'Total loss': 0.49731361865997314} | train loss {'Reaction outcome loss': 0.45711910288672947, 'Total loss': 0.45711910288672947}
2023-01-04 11:23:22,489 INFO:     Found new best model at epoch 16
2023-01-04 11:23:22,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:22,489 INFO:     Epoch: 17
2023-01-04 11:23:24,060 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4815530548493067, 'Total loss': 0.4815530548493067} | train loss {'Reaction outcome loss': 0.4405266212812368, 'Total loss': 0.4405266212812368}
2023-01-04 11:23:24,060 INFO:     Found new best model at epoch 17
2023-01-04 11:23:24,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:24,060 INFO:     Epoch: 18
2023-01-04 11:23:25,595 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48652596672376, 'Total loss': 0.48652596672376} | train loss {'Reaction outcome loss': 0.4402223090654698, 'Total loss': 0.4402223090654698}
2023-01-04 11:23:25,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:25,595 INFO:     Epoch: 19
2023-01-04 11:23:27,129 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5006264527638753, 'Total loss': 0.5006264527638753} | train loss {'Reaction outcome loss': 0.4363664268259553, 'Total loss': 0.4363664268259553}
2023-01-04 11:23:27,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:27,129 INFO:     Epoch: 20
2023-01-04 11:23:28,710 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5137645274400711, 'Total loss': 0.5137645274400711} | train loss {'Reaction outcome loss': 0.4441301835349936, 'Total loss': 0.4441301835349936}
2023-01-04 11:23:28,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:28,710 INFO:     Epoch: 21
2023-01-04 11:23:30,269 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4835483481486638, 'Total loss': 0.4835483481486638} | train loss {'Reaction outcome loss': 0.44326737810194533, 'Total loss': 0.44326737810194533}
2023-01-04 11:23:30,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:30,270 INFO:     Epoch: 22
2023-01-04 11:23:31,847 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47261798779169717, 'Total loss': 0.47261798779169717} | train loss {'Reaction outcome loss': 0.4208687206433303, 'Total loss': 0.4208687206433303}
2023-01-04 11:23:31,847 INFO:     Found new best model at epoch 22
2023-01-04 11:23:31,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:31,848 INFO:     Epoch: 23
2023-01-04 11:23:33,419 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4589551826318105, 'Total loss': 0.4589551826318105} | train loss {'Reaction outcome loss': 0.42217324749715085, 'Total loss': 0.42217324749715085}
2023-01-04 11:23:33,420 INFO:     Found new best model at epoch 23
2023-01-04 11:23:33,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:33,420 INFO:     Epoch: 24
2023-01-04 11:23:34,953 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47832224468390144, 'Total loss': 0.47832224468390144} | train loss {'Reaction outcome loss': 0.42729626041567087, 'Total loss': 0.42729626041567087}
2023-01-04 11:23:34,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:34,953 INFO:     Epoch: 25
2023-01-04 11:23:36,480 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49940133293469746, 'Total loss': 0.49940133293469746} | train loss {'Reaction outcome loss': 0.40909423474627343, 'Total loss': 0.40909423474627343}
2023-01-04 11:23:36,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:36,480 INFO:     Epoch: 26
2023-01-04 11:23:38,047 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47087228298187256, 'Total loss': 0.47087228298187256} | train loss {'Reaction outcome loss': 0.40824758995617283, 'Total loss': 0.40824758995617283}
2023-01-04 11:23:38,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:38,048 INFO:     Epoch: 27
2023-01-04 11:23:39,622 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4945923844973246, 'Total loss': 0.4945923844973246} | train loss {'Reaction outcome loss': 0.40128699911461363, 'Total loss': 0.40128699911461363}
2023-01-04 11:23:39,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:39,622 INFO:     Epoch: 28
2023-01-04 11:23:41,188 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48278905749320983, 'Total loss': 0.48278905749320983} | train loss {'Reaction outcome loss': 0.4011061696598873, 'Total loss': 0.4011061696598873}
2023-01-04 11:23:41,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:41,188 INFO:     Epoch: 29
2023-01-04 11:23:42,755 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4794135948022207, 'Total loss': 0.4794135948022207} | train loss {'Reaction outcome loss': 0.3941996666219801, 'Total loss': 0.3941996666219801}
2023-01-04 11:23:42,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:42,755 INFO:     Epoch: 30
2023-01-04 11:23:44,272 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.49745177030563353, 'Total loss': 0.49745177030563353} | train loss {'Reaction outcome loss': 0.3938795826330349, 'Total loss': 0.3938795826330349}
2023-01-04 11:23:44,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:44,272 INFO:     Epoch: 31
2023-01-04 11:23:45,811 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5049763441085815, 'Total loss': 0.5049763441085815} | train loss {'Reaction outcome loss': 0.38790694314419577, 'Total loss': 0.38790694314419577}
2023-01-04 11:23:45,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:45,811 INFO:     Epoch: 32
2023-01-04 11:23:47,401 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48579700191815695, 'Total loss': 0.48579700191815695} | train loss {'Reaction outcome loss': 0.38653966030392767, 'Total loss': 0.38653966030392767}
2023-01-04 11:23:47,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:47,402 INFO:     Epoch: 33
2023-01-04 11:23:48,985 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4688865880171458, 'Total loss': 0.4688865880171458} | train loss {'Reaction outcome loss': 0.38607778402544773, 'Total loss': 0.38607778402544773}
2023-01-04 11:23:48,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:48,985 INFO:     Epoch: 34
2023-01-04 11:23:50,560 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4687266518672307, 'Total loss': 0.4687266518672307} | train loss {'Reaction outcome loss': 0.37789524537407304, 'Total loss': 0.37789524537407304}
2023-01-04 11:23:50,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:50,560 INFO:     Epoch: 35
2023-01-04 11:23:52,118 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4680303980906804, 'Total loss': 0.4680303980906804} | train loss {'Reaction outcome loss': 0.3783205771238315, 'Total loss': 0.3783205771238315}
2023-01-04 11:23:52,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:52,118 INFO:     Epoch: 36
2023-01-04 11:23:53,638 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4670824666817983, 'Total loss': 0.4670824666817983} | train loss {'Reaction outcome loss': 0.3739968525832924, 'Total loss': 0.3739968525832924}
2023-01-04 11:23:53,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:53,639 INFO:     Epoch: 37
2023-01-04 11:23:55,197 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.471302874883016, 'Total loss': 0.471302874883016} | train loss {'Reaction outcome loss': 0.370608419195101, 'Total loss': 0.370608419195101}
2023-01-04 11:23:55,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:55,198 INFO:     Epoch: 38
2023-01-04 11:23:56,780 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46590297619501747, 'Total loss': 0.46590297619501747} | train loss {'Reaction outcome loss': 0.3715354690523953, 'Total loss': 0.3715354690523953}
2023-01-04 11:23:56,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:56,781 INFO:     Epoch: 39
2023-01-04 11:23:58,361 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4668702006340027, 'Total loss': 0.4668702006340027} | train loss {'Reaction outcome loss': 0.36474352181497693, 'Total loss': 0.36474352181497693}
2023-01-04 11:23:58,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:58,361 INFO:     Epoch: 40
2023-01-04 11:23:59,949 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.474282173315684, 'Total loss': 0.474282173315684} | train loss {'Reaction outcome loss': 0.36755569548805017, 'Total loss': 0.36755569548805017}
2023-01-04 11:23:59,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:23:59,949 INFO:     Epoch: 41
2023-01-04 11:24:01,526 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4557610770066579, 'Total loss': 0.4557610770066579} | train loss {'Reaction outcome loss': 0.36167853504952474, 'Total loss': 0.36167853504952474}
2023-01-04 11:24:01,527 INFO:     Found new best model at epoch 41
2023-01-04 11:24:01,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:01,528 INFO:     Epoch: 42
2023-01-04 11:24:03,082 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4625364621480306, 'Total loss': 0.4625364621480306} | train loss {'Reaction outcome loss': 0.36074753698852396, 'Total loss': 0.36074753698852396}
2023-01-04 11:24:03,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:03,083 INFO:     Epoch: 43
2023-01-04 11:24:04,673 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47104227940241494, 'Total loss': 0.47104227940241494} | train loss {'Reaction outcome loss': 0.3611474871581447, 'Total loss': 0.3611474871581447}
2023-01-04 11:24:04,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:04,673 INFO:     Epoch: 44
2023-01-04 11:24:06,286 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4697700957457224, 'Total loss': 0.4697700957457224} | train loss {'Reaction outcome loss': 0.3753285942248244, 'Total loss': 0.3753285942248244}
2023-01-04 11:24:06,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:06,286 INFO:     Epoch: 45
2023-01-04 11:24:07,881 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.456081368525823, 'Total loss': 0.456081368525823} | train loss {'Reaction outcome loss': 0.351698306309012, 'Total loss': 0.351698306309012}
2023-01-04 11:24:07,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:07,882 INFO:     Epoch: 46
2023-01-04 11:24:09,510 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4287488470474879, 'Total loss': 0.4287488470474879} | train loss {'Reaction outcome loss': 0.34690401854290476, 'Total loss': 0.34690401854290476}
2023-01-04 11:24:09,510 INFO:     Found new best model at epoch 46
2023-01-04 11:24:09,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:09,511 INFO:     Epoch: 47
2023-01-04 11:24:11,056 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4420376822352409, 'Total loss': 0.4420376822352409} | train loss {'Reaction outcome loss': 0.35406528345471167, 'Total loss': 0.35406528345471167}
2023-01-04 11:24:11,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:11,056 INFO:     Epoch: 48
2023-01-04 11:24:12,590 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48154415090878805, 'Total loss': 0.48154415090878805} | train loss {'Reaction outcome loss': 0.3440893539699955, 'Total loss': 0.3440893539699955}
2023-01-04 11:24:12,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:12,590 INFO:     Epoch: 49
2023-01-04 11:24:14,182 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4756366451581319, 'Total loss': 0.4756366451581319} | train loss {'Reaction outcome loss': 0.3490430445788239, 'Total loss': 0.3490430445788239}
2023-01-04 11:24:14,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:14,182 INFO:     Epoch: 50
2023-01-04 11:24:15,769 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4666906913121541, 'Total loss': 0.4666906913121541} | train loss {'Reaction outcome loss': 0.3355237184348854, 'Total loss': 0.3355237184348854}
2023-01-04 11:24:15,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:15,770 INFO:     Epoch: 51
2023-01-04 11:24:17,354 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4291073779265086, 'Total loss': 0.4291073779265086} | train loss {'Reaction outcome loss': 0.3316938113121991, 'Total loss': 0.3316938113121991}
2023-01-04 11:24:17,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:17,354 INFO:     Epoch: 52
2023-01-04 11:24:18,905 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.435576726992925, 'Total loss': 0.435576726992925} | train loss {'Reaction outcome loss': 0.329958670232425, 'Total loss': 0.329958670232425}
2023-01-04 11:24:18,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:18,905 INFO:     Epoch: 53
2023-01-04 11:24:20,430 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44697520434856414, 'Total loss': 0.44697520434856414} | train loss {'Reaction outcome loss': 0.3261670090808142, 'Total loss': 0.3261670090808142}
2023-01-04 11:24:20,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:20,430 INFO:     Epoch: 54
2023-01-04 11:24:21,949 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45488638083140054, 'Total loss': 0.45488638083140054} | train loss {'Reaction outcome loss': 0.32598963481090637, 'Total loss': 0.32598963481090637}
2023-01-04 11:24:21,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:21,949 INFO:     Epoch: 55
2023-01-04 11:24:23,501 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44750094215075176, 'Total loss': 0.44750094215075176} | train loss {'Reaction outcome loss': 0.3347516414385451, 'Total loss': 0.3347516414385451}
2023-01-04 11:24:23,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:23,501 INFO:     Epoch: 56
2023-01-04 11:24:25,060 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45231157839298247, 'Total loss': 0.45231157839298247} | train loss {'Reaction outcome loss': 0.3268154606601034, 'Total loss': 0.3268154606601034}
2023-01-04 11:24:25,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:25,060 INFO:     Epoch: 57
2023-01-04 11:24:26,617 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4578510691722234, 'Total loss': 0.4578510691722234} | train loss {'Reaction outcome loss': 0.339039286455153, 'Total loss': 0.339039286455153}
2023-01-04 11:24:26,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:26,617 INFO:     Epoch: 58
2023-01-04 11:24:28,192 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45177256464958193, 'Total loss': 0.45177256464958193} | train loss {'Reaction outcome loss': 0.31468398145575455, 'Total loss': 0.31468398145575455}
2023-01-04 11:24:28,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:28,192 INFO:     Epoch: 59
2023-01-04 11:24:29,729 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4312762002150218, 'Total loss': 0.4312762002150218} | train loss {'Reaction outcome loss': 0.32085931077059626, 'Total loss': 0.32085931077059626}
2023-01-04 11:24:29,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:29,729 INFO:     Epoch: 60
2023-01-04 11:24:31,284 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4358799656232198, 'Total loss': 0.4358799656232198} | train loss {'Reaction outcome loss': 0.31658731922262645, 'Total loss': 0.31658731922262645}
2023-01-04 11:24:31,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:31,285 INFO:     Epoch: 61
2023-01-04 11:24:32,892 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4378569265206655, 'Total loss': 0.4378569265206655} | train loss {'Reaction outcome loss': 0.31212668056052306, 'Total loss': 0.31212668056052306}
2023-01-04 11:24:32,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:32,892 INFO:     Epoch: 62
2023-01-04 11:24:34,487 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46856865882873533, 'Total loss': 0.46856865882873533} | train loss {'Reaction outcome loss': 0.3090747401820145, 'Total loss': 0.3090747401820145}
2023-01-04 11:24:34,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:34,488 INFO:     Epoch: 63
2023-01-04 11:24:36,079 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4313989440600077, 'Total loss': 0.4313989440600077} | train loss {'Reaction outcome loss': 0.3305679286960462, 'Total loss': 0.3305679286960462}
2023-01-04 11:24:36,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:36,079 INFO:     Epoch: 64
2023-01-04 11:24:37,687 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4342033843199412, 'Total loss': 0.4342033843199412} | train loss {'Reaction outcome loss': 0.30999434377873264, 'Total loss': 0.30999434377873264}
2023-01-04 11:24:37,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:37,688 INFO:     Epoch: 65
2023-01-04 11:24:39,194 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44254968762397767, 'Total loss': 0.44254968762397767} | train loss {'Reaction outcome loss': 0.30741881924694864, 'Total loss': 0.30741881924694864}
2023-01-04 11:24:39,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:39,194 INFO:     Epoch: 66
2023-01-04 11:24:40,786 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45812547504901885, 'Total loss': 0.45812547504901885} | train loss {'Reaction outcome loss': 0.30478987522909173, 'Total loss': 0.30478987522909173}
2023-01-04 11:24:40,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:40,786 INFO:     Epoch: 67
2023-01-04 11:24:42,402 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4485863943894704, 'Total loss': 0.4485863943894704} | train loss {'Reaction outcome loss': 0.29902433485256263, 'Total loss': 0.29902433485256263}
2023-01-04 11:24:42,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:42,402 INFO:     Epoch: 68
2023-01-04 11:24:43,992 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42641088912884395, 'Total loss': 0.42641088912884395} | train loss {'Reaction outcome loss': 0.2980848313656178, 'Total loss': 0.2980848313656178}
2023-01-04 11:24:43,992 INFO:     Found new best model at epoch 68
2023-01-04 11:24:43,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:43,993 INFO:     Epoch: 69
2023-01-04 11:24:45,587 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46155318021774294, 'Total loss': 0.46155318021774294} | train loss {'Reaction outcome loss': 0.29396903082986525, 'Total loss': 0.29396903082986525}
2023-01-04 11:24:45,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:45,587 INFO:     Epoch: 70
2023-01-04 11:24:47,166 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45410555104414624, 'Total loss': 0.45410555104414624} | train loss {'Reaction outcome loss': 0.29574975426194083, 'Total loss': 0.29574975426194083}
2023-01-04 11:24:47,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:47,166 INFO:     Epoch: 71
2023-01-04 11:24:48,690 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.451655783255895, 'Total loss': 0.451655783255895} | train loss {'Reaction outcome loss': 0.29462594329263503, 'Total loss': 0.29462594329263503}
2023-01-04 11:24:48,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:48,691 INFO:     Epoch: 72
2023-01-04 11:24:50,268 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4373618682225545, 'Total loss': 0.4373618682225545} | train loss {'Reaction outcome loss': 0.29547239207844855, 'Total loss': 0.29547239207844855}
2023-01-04 11:24:50,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:50,269 INFO:     Epoch: 73
2023-01-04 11:24:51,858 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4444196263949076, 'Total loss': 0.4444196263949076} | train loss {'Reaction outcome loss': 0.2905479878106195, 'Total loss': 0.2905479878106195}
2023-01-04 11:24:51,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:51,859 INFO:     Epoch: 74
2023-01-04 11:24:53,432 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4927091340223948, 'Total loss': 0.4927091340223948} | train loss {'Reaction outcome loss': 0.28692472551989817, 'Total loss': 0.28692472551989817}
2023-01-04 11:24:53,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:53,432 INFO:     Epoch: 75
2023-01-04 11:24:55,012 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4275963842868805, 'Total loss': 0.4275963842868805} | train loss {'Reaction outcome loss': 0.2883718638812475, 'Total loss': 0.2883718638812475}
2023-01-04 11:24:55,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:55,013 INFO:     Epoch: 76
2023-01-04 11:24:56,567 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4263152172168096, 'Total loss': 0.4263152172168096} | train loss {'Reaction outcome loss': 0.2849577986702755, 'Total loss': 0.2849577986702755}
2023-01-04 11:24:56,567 INFO:     Found new best model at epoch 76
2023-01-04 11:24:56,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:56,568 INFO:     Epoch: 77
2023-01-04 11:24:58,112 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4552225450674693, 'Total loss': 0.4552225450674693} | train loss {'Reaction outcome loss': 0.29095438647124433, 'Total loss': 0.29095438647124433}
2023-01-04 11:24:58,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:58,113 INFO:     Epoch: 78
2023-01-04 11:24:59,675 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4552336851755778, 'Total loss': 0.4552336851755778} | train loss {'Reaction outcome loss': 0.2826048096743551, 'Total loss': 0.2826048096743551}
2023-01-04 11:24:59,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:24:59,675 INFO:     Epoch: 79
2023-01-04 11:25:01,234 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48649616638819376, 'Total loss': 0.48649616638819376} | train loss {'Reaction outcome loss': 0.2873943095918799, 'Total loss': 0.2873943095918799}
2023-01-04 11:25:01,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:01,234 INFO:     Epoch: 80
2023-01-04 11:25:02,851 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4836950918038686, 'Total loss': 0.4836950918038686} | train loss {'Reaction outcome loss': 0.3270282758765962, 'Total loss': 0.3270282758765962}
2023-01-04 11:25:02,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:02,851 INFO:     Epoch: 81
2023-01-04 11:25:04,428 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4534078260262807, 'Total loss': 0.4534078260262807} | train loss {'Reaction outcome loss': 0.28460007671104826, 'Total loss': 0.28460007671104826}
2023-01-04 11:25:04,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:04,428 INFO:     Epoch: 82
2023-01-04 11:25:05,971 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44307777484258015, 'Total loss': 0.44307777484258015} | train loss {'Reaction outcome loss': 0.307874319499588, 'Total loss': 0.307874319499588}
2023-01-04 11:25:05,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:05,972 INFO:     Epoch: 83
2023-01-04 11:25:07,512 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42804909944534303, 'Total loss': 0.42804909944534303} | train loss {'Reaction outcome loss': 0.2803406285904888, 'Total loss': 0.2803406285904888}
2023-01-04 11:25:07,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:07,512 INFO:     Epoch: 84
2023-01-04 11:25:09,108 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4803443133831024, 'Total loss': 0.4803443133831024} | train loss {'Reaction outcome loss': 0.28538989535519393, 'Total loss': 0.28538989535519393}
2023-01-04 11:25:09,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:09,108 INFO:     Epoch: 85
2023-01-04 11:25:10,702 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46713358561197915, 'Total loss': 0.46713358561197915} | train loss {'Reaction outcome loss': 0.2784632828248584, 'Total loss': 0.2784632828248584}
2023-01-04 11:25:10,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:10,702 INFO:     Epoch: 86
2023-01-04 11:25:12,298 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43631747712691626, 'Total loss': 0.43631747712691626} | train loss {'Reaction outcome loss': 0.2909192459454167, 'Total loss': 0.2909192459454167}
2023-01-04 11:25:12,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:12,299 INFO:     Epoch: 87
2023-01-04 11:25:13,860 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4423232128222783, 'Total loss': 0.4423232128222783} | train loss {'Reaction outcome loss': 0.2736001732072496, 'Total loss': 0.2736001732072496}
2023-01-04 11:25:13,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:13,860 INFO:     Epoch: 88
2023-01-04 11:25:15,393 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44466774264971415, 'Total loss': 0.44466774264971415} | train loss {'Reaction outcome loss': 0.2962850434030744, 'Total loss': 0.2962850434030744}
2023-01-04 11:25:15,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:15,393 INFO:     Epoch: 89
2023-01-04 11:25:16,972 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4630819539229075, 'Total loss': 0.4630819539229075} | train loss {'Reaction outcome loss': 0.3131069227432211, 'Total loss': 0.3131069227432211}
2023-01-04 11:25:16,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:16,972 INFO:     Epoch: 90
2023-01-04 11:25:18,562 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4606336663166682, 'Total loss': 0.4606336663166682} | train loss {'Reaction outcome loss': 0.2772317297918641, 'Total loss': 0.2772317297918641}
2023-01-04 11:25:18,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:18,562 INFO:     Epoch: 91
2023-01-04 11:25:20,126 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44275413552920023, 'Total loss': 0.44275413552920023} | train loss {'Reaction outcome loss': 0.2833844397421184, 'Total loss': 0.2833844397421184}
2023-01-04 11:25:20,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:20,126 INFO:     Epoch: 92
2023-01-04 11:25:21,714 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46655484239260353, 'Total loss': 0.46655484239260353} | train loss {'Reaction outcome loss': 0.27158133395394124, 'Total loss': 0.27158133395394124}
2023-01-04 11:25:21,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:21,714 INFO:     Epoch: 93
2023-01-04 11:25:23,291 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5009235560894012, 'Total loss': 0.5009235560894012} | train loss {'Reaction outcome loss': 0.27048252262107597, 'Total loss': 0.27048252262107597}
2023-01-04 11:25:23,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:23,292 INFO:     Epoch: 94
2023-01-04 11:25:24,804 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48559705515702567, 'Total loss': 0.48559705515702567} | train loss {'Reaction outcome loss': 0.27445099497402925, 'Total loss': 0.27445099497402925}
2023-01-04 11:25:24,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:24,804 INFO:     Epoch: 95
2023-01-04 11:25:26,387 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45268789331118264, 'Total loss': 0.45268789331118264} | train loss {'Reaction outcome loss': 0.3262261132021313, 'Total loss': 0.3262261132021313}
2023-01-04 11:25:26,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:26,387 INFO:     Epoch: 96
2023-01-04 11:25:27,968 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4570696194966634, 'Total loss': 0.4570696194966634} | train loss {'Reaction outcome loss': 0.2914442121408934, 'Total loss': 0.2914442121408934}
2023-01-04 11:25:27,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:27,969 INFO:     Epoch: 97
2023-01-04 11:25:29,568 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4445253094037374, 'Total loss': 0.4445253094037374} | train loss {'Reaction outcome loss': 0.2698860981803644, 'Total loss': 0.2698860981803644}
2023-01-04 11:25:29,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:29,568 INFO:     Epoch: 98
2023-01-04 11:25:31,156 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4500989973545074, 'Total loss': 0.4500989973545074} | train loss {'Reaction outcome loss': 0.2658357932611408, 'Total loss': 0.2658357932611408}
2023-01-04 11:25:31,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:31,156 INFO:     Epoch: 99
2023-01-04 11:25:32,698 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4642662843068441, 'Total loss': 0.4642662843068441} | train loss {'Reaction outcome loss': 0.263990180671512, 'Total loss': 0.263990180671512}
2023-01-04 11:25:32,698 INFO:     Best model found after epoch 77 of 100.
2023-01-04 11:25:32,698 INFO:   Done with stage: TRAINING
2023-01-04 11:25:32,698 INFO:   Starting stage: EVALUATION
2023-01-04 11:25:32,826 INFO:   Done with stage: EVALUATION
2023-01-04 11:25:32,827 INFO:   Leaving out SEQ value Fold_4
2023-01-04 11:25:32,839 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 11:25:32,839 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:25:33,490 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:25:33,490 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:25:33,559 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:25:33,559 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:25:33,559 INFO:     No hyperparam tuning for this model
2023-01-04 11:25:33,559 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:25:33,559 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:25:33,560 INFO:     None feature selector for col prot
2023-01-04 11:25:33,560 INFO:     None feature selector for col prot
2023-01-04 11:25:33,560 INFO:     None feature selector for col prot
2023-01-04 11:25:33,561 INFO:     None feature selector for col chem
2023-01-04 11:25:33,561 INFO:     None feature selector for col chem
2023-01-04 11:25:33,561 INFO:     None feature selector for col chem
2023-01-04 11:25:33,561 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:25:33,561 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:25:33,562 INFO:     Number of params in model 70111
2023-01-04 11:25:33,565 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:25:33,565 INFO:   Starting stage: TRAINING
2023-01-04 11:25:33,608 INFO:     Val loss before train {'Reaction outcome loss': 1.0055320898691813, 'Total loss': 1.0055320898691813}
2023-01-04 11:25:33,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:33,608 INFO:     Epoch: 0
2023-01-04 11:25:35,157 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7122830847899119, 'Total loss': 0.7122830847899119} | train loss {'Reaction outcome loss': 0.8330017723116203, 'Total loss': 0.8330017723116203}
2023-01-04 11:25:35,157 INFO:     Found new best model at epoch 0
2023-01-04 11:25:35,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:35,158 INFO:     Epoch: 1
2023-01-04 11:25:36,707 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5843190550804138, 'Total loss': 0.5843190550804138} | train loss {'Reaction outcome loss': 0.6620815937484645, 'Total loss': 0.6620815937484645}
2023-01-04 11:25:36,707 INFO:     Found new best model at epoch 1
2023-01-04 11:25:36,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:36,708 INFO:     Epoch: 2
2023-01-04 11:25:38,251 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5433668931325276, 'Total loss': 0.5433668931325276} | train loss {'Reaction outcome loss': 0.5751512696166331, 'Total loss': 0.5751512696166331}
2023-01-04 11:25:38,251 INFO:     Found new best model at epoch 2
2023-01-04 11:25:38,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:38,252 INFO:     Epoch: 3
2023-01-04 11:25:39,830 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5481895506381989, 'Total loss': 0.5481895506381989} | train loss {'Reaction outcome loss': 0.5358547336465616, 'Total loss': 0.5358547336465616}
2023-01-04 11:25:39,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:39,830 INFO:     Epoch: 4
2023-01-04 11:25:41,379 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5359470049540201, 'Total loss': 0.5359470049540201} | train loss {'Reaction outcome loss': 0.5131660077976405, 'Total loss': 0.5131660077976405}
2023-01-04 11:25:41,380 INFO:     Found new best model at epoch 4
2023-01-04 11:25:41,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:41,380 INFO:     Epoch: 5
2023-01-04 11:25:42,904 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.514593184987704, 'Total loss': 0.514593184987704} | train loss {'Reaction outcome loss': 0.4988674361137707, 'Total loss': 0.4988674361137707}
2023-01-04 11:25:42,905 INFO:     Found new best model at epoch 5
2023-01-04 11:25:42,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:42,906 INFO:     Epoch: 6
2023-01-04 11:25:44,493 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5059366573890051, 'Total loss': 0.5059366573890051} | train loss {'Reaction outcome loss': 0.4932410753053018, 'Total loss': 0.4932410753053018}
2023-01-04 11:25:44,493 INFO:     Found new best model at epoch 6
2023-01-04 11:25:44,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:44,494 INFO:     Epoch: 7
2023-01-04 11:25:46,085 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4976817528406779, 'Total loss': 0.4976817528406779} | train loss {'Reaction outcome loss': 0.4765165377717586, 'Total loss': 0.4765165377717586}
2023-01-04 11:25:46,085 INFO:     Found new best model at epoch 7
2023-01-04 11:25:46,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:46,086 INFO:     Epoch: 8
2023-01-04 11:25:47,664 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5073401093482971, 'Total loss': 0.5073401093482971} | train loss {'Reaction outcome loss': 0.4685202748766875, 'Total loss': 0.4685202748766875}
2023-01-04 11:25:47,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:47,665 INFO:     Epoch: 9
2023-01-04 11:25:49,236 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5074940423170725, 'Total loss': 0.5074940423170725} | train loss {'Reaction outcome loss': 0.4639541270608076, 'Total loss': 0.4639541270608076}
2023-01-04 11:25:49,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:49,237 INFO:     Epoch: 10
2023-01-04 11:25:50,783 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48446978330612184, 'Total loss': 0.48446978330612184} | train loss {'Reaction outcome loss': 0.45766955396221004, 'Total loss': 0.45766955396221004}
2023-01-04 11:25:50,783 INFO:     Found new best model at epoch 10
2023-01-04 11:25:50,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:50,784 INFO:     Epoch: 11
2023-01-04 11:25:52,321 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49519464870293933, 'Total loss': 0.49519464870293933} | train loss {'Reaction outcome loss': 0.45141858147585007, 'Total loss': 0.45141858147585007}
2023-01-04 11:25:52,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:52,321 INFO:     Epoch: 12
2023-01-04 11:25:53,893 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49062873323758444, 'Total loss': 0.49062873323758444} | train loss {'Reaction outcome loss': 0.4445021823855514, 'Total loss': 0.4445021823855514}
2023-01-04 11:25:53,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:53,893 INFO:     Epoch: 13
2023-01-04 11:25:55,448 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46910549998283385, 'Total loss': 0.46910549998283385} | train loss {'Reaction outcome loss': 0.44075228053309856, 'Total loss': 0.44075228053309856}
2023-01-04 11:25:55,448 INFO:     Found new best model at epoch 13
2023-01-04 11:25:55,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:55,449 INFO:     Epoch: 14
2023-01-04 11:25:57,026 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5087351004282633, 'Total loss': 0.5087351004282633} | train loss {'Reaction outcome loss': 0.43123887264126043, 'Total loss': 0.43123887264126043}
2023-01-04 11:25:57,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:57,026 INFO:     Epoch: 15
2023-01-04 11:25:58,620 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4737593670686086, 'Total loss': 0.4737593670686086} | train loss {'Reaction outcome loss': 0.43057668779300867, 'Total loss': 0.43057668779300867}
2023-01-04 11:25:58,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:25:58,620 INFO:     Epoch: 16
2023-01-04 11:26:00,146 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45868241687615713, 'Total loss': 0.45868241687615713} | train loss {'Reaction outcome loss': 0.4282137081296005, 'Total loss': 0.4282137081296005}
2023-01-04 11:26:00,146 INFO:     Found new best model at epoch 16
2023-01-04 11:26:00,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:00,147 INFO:     Epoch: 17
2023-01-04 11:26:01,684 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45075023372968037, 'Total loss': 0.45075023372968037} | train loss {'Reaction outcome loss': 0.4201122409922982, 'Total loss': 0.4201122409922982}
2023-01-04 11:26:01,685 INFO:     Found new best model at epoch 17
2023-01-04 11:26:01,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:01,686 INFO:     Epoch: 18
2023-01-04 11:26:03,246 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46548356811205543, 'Total loss': 0.46548356811205543} | train loss {'Reaction outcome loss': 0.41490725452073646, 'Total loss': 0.41490725452073646}
2023-01-04 11:26:03,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:03,247 INFO:     Epoch: 19
2023-01-04 11:26:04,812 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4508542517820994, 'Total loss': 0.4508542517820994} | train loss {'Reaction outcome loss': 0.4103911568541819, 'Total loss': 0.4103911568541819}
2023-01-04 11:26:04,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:04,812 INFO:     Epoch: 20
2023-01-04 11:26:06,386 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4646111935377121, 'Total loss': 0.4646111935377121} | train loss {'Reaction outcome loss': 0.40977587354527484, 'Total loss': 0.40977587354527484}
2023-01-04 11:26:06,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:06,386 INFO:     Epoch: 21
2023-01-04 11:26:07,951 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4597927172978719, 'Total loss': 0.4597927172978719} | train loss {'Reaction outcome loss': 0.40473388482409695, 'Total loss': 0.40473388482409695}
2023-01-04 11:26:07,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:07,952 INFO:     Epoch: 22
2023-01-04 11:26:09,496 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4613888243834178, 'Total loss': 0.4613888243834178} | train loss {'Reaction outcome loss': 0.4007592731111747, 'Total loss': 0.4007592731111747}
2023-01-04 11:26:09,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:09,496 INFO:     Epoch: 23
2023-01-04 11:26:11,058 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4583696444829305, 'Total loss': 0.4583696444829305} | train loss {'Reaction outcome loss': 0.3938064493225477, 'Total loss': 0.3938064493225477}
2023-01-04 11:26:11,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:11,059 INFO:     Epoch: 24
2023-01-04 11:26:12,641 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4562282502651215, 'Total loss': 0.4562282502651215} | train loss {'Reaction outcome loss': 0.39137453281922463, 'Total loss': 0.39137453281922463}
2023-01-04 11:26:12,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:12,641 INFO:     Epoch: 25
2023-01-04 11:26:14,237 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48345727026462554, 'Total loss': 0.48345727026462554} | train loss {'Reaction outcome loss': 0.38822227442092416, 'Total loss': 0.38822227442092416}
2023-01-04 11:26:14,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:14,237 INFO:     Epoch: 26
2023-01-04 11:26:15,840 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4519606113433838, 'Total loss': 0.4519606113433838} | train loss {'Reaction outcome loss': 0.38653536649279646, 'Total loss': 0.38653536649279646}
2023-01-04 11:26:15,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:15,840 INFO:     Epoch: 27
2023-01-04 11:26:17,444 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4552932103474935, 'Total loss': 0.4552932103474935} | train loss {'Reaction outcome loss': 0.382893735132708, 'Total loss': 0.382893735132708}
2023-01-04 11:26:17,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:17,444 INFO:     Epoch: 28
2023-01-04 11:26:18,971 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4371209760506948, 'Total loss': 0.4371209760506948} | train loss {'Reaction outcome loss': 0.380039575701371, 'Total loss': 0.380039575701371}
2023-01-04 11:26:18,972 INFO:     Found new best model at epoch 28
2023-01-04 11:26:18,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:18,972 INFO:     Epoch: 29
2023-01-04 11:26:20,572 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4249114513397217, 'Total loss': 0.4249114513397217} | train loss {'Reaction outcome loss': 0.3764909530589727, 'Total loss': 0.3764909530589727}
2023-01-04 11:26:20,572 INFO:     Found new best model at epoch 29
2023-01-04 11:26:20,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:20,573 INFO:     Epoch: 30
2023-01-04 11:26:22,170 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.462091792623202, 'Total loss': 0.462091792623202} | train loss {'Reaction outcome loss': 0.37141452164856537, 'Total loss': 0.37141452164856537}
2023-01-04 11:26:22,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:22,170 INFO:     Epoch: 31
2023-01-04 11:26:23,767 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47144851088523865, 'Total loss': 0.47144851088523865} | train loss {'Reaction outcome loss': 0.37153307569048466, 'Total loss': 0.37153307569048466}
2023-01-04 11:26:23,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:23,767 INFO:     Epoch: 32
2023-01-04 11:26:25,369 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44593933820724485, 'Total loss': 0.44593933820724485} | train loss {'Reaction outcome loss': 0.3669644168406617, 'Total loss': 0.3669644168406617}
2023-01-04 11:26:25,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:25,370 INFO:     Epoch: 33
2023-01-04 11:26:26,942 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4394035875797272, 'Total loss': 0.4394035875797272} | train loss {'Reaction outcome loss': 0.36604179355857175, 'Total loss': 0.36604179355857175}
2023-01-04 11:26:26,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:26,943 INFO:     Epoch: 34
2023-01-04 11:26:28,524 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4384862373272578, 'Total loss': 0.4384862373272578} | train loss {'Reaction outcome loss': 0.35956980742594824, 'Total loss': 0.35956980742594824}
2023-01-04 11:26:28,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:28,524 INFO:     Epoch: 35
2023-01-04 11:26:30,124 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42373987634976706, 'Total loss': 0.42373987634976706} | train loss {'Reaction outcome loss': 0.35881750452389355, 'Total loss': 0.35881750452389355}
2023-01-04 11:26:30,124 INFO:     Found new best model at epoch 35
2023-01-04 11:26:30,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:30,125 INFO:     Epoch: 36
2023-01-04 11:26:31,733 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43741414149602253, 'Total loss': 0.43741414149602253} | train loss {'Reaction outcome loss': 0.3536219744798509, 'Total loss': 0.3536219744798509}
2023-01-04 11:26:31,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:31,733 INFO:     Epoch: 37
2023-01-04 11:26:33,329 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4595710615317027, 'Total loss': 0.4595710615317027} | train loss {'Reaction outcome loss': 0.35286406839152107, 'Total loss': 0.35286406839152107}
2023-01-04 11:26:33,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:33,329 INFO:     Epoch: 38
2023-01-04 11:26:34,935 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42536003986994425, 'Total loss': 0.42536003986994425} | train loss {'Reaction outcome loss': 0.35029295062652993, 'Total loss': 0.35029295062652993}
2023-01-04 11:26:34,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:34,935 INFO:     Epoch: 39
2023-01-04 11:26:36,484 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43965995907783506, 'Total loss': 0.43965995907783506} | train loss {'Reaction outcome loss': 0.3488139851751741, 'Total loss': 0.3488139851751741}
2023-01-04 11:26:36,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:36,484 INFO:     Epoch: 40
2023-01-04 11:26:38,008 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4457692970832189, 'Total loss': 0.4457692970832189} | train loss {'Reaction outcome loss': 0.34280474672248645, 'Total loss': 0.34280474672248645}
2023-01-04 11:26:38,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:38,009 INFO:     Epoch: 41
2023-01-04 11:26:39,561 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4382695734500885, 'Total loss': 0.4382695734500885} | train loss {'Reaction outcome loss': 0.33515127140369655, 'Total loss': 0.33515127140369655}
2023-01-04 11:26:39,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:39,561 INFO:     Epoch: 42
2023-01-04 11:26:41,117 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42908069491386414, 'Total loss': 0.42908069491386414} | train loss {'Reaction outcome loss': 0.3372081325049865, 'Total loss': 0.3372081325049865}
2023-01-04 11:26:41,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:41,117 INFO:     Epoch: 43
2023-01-04 11:26:42,662 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4059871107339859, 'Total loss': 0.4059871107339859} | train loss {'Reaction outcome loss': 0.3331738538798012, 'Total loss': 0.3331738538798012}
2023-01-04 11:26:42,663 INFO:     Found new best model at epoch 43
2023-01-04 11:26:42,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:42,663 INFO:     Epoch: 44
2023-01-04 11:26:44,239 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4311145762602488, 'Total loss': 0.4311145762602488} | train loss {'Reaction outcome loss': 0.330917729367418, 'Total loss': 0.330917729367418}
2023-01-04 11:26:44,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:44,240 INFO:     Epoch: 45
2023-01-04 11:26:45,774 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4191318382819494, 'Total loss': 0.4191318382819494} | train loss {'Reaction outcome loss': 0.33372196915562835, 'Total loss': 0.33372196915562835}
2023-01-04 11:26:45,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:45,774 INFO:     Epoch: 46
2023-01-04 11:26:47,287 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44299705028533937, 'Total loss': 0.44299705028533937} | train loss {'Reaction outcome loss': 0.3250448553140413, 'Total loss': 0.3250448553140413}
2023-01-04 11:26:47,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:47,287 INFO:     Epoch: 47
2023-01-04 11:26:48,834 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.427748100956281, 'Total loss': 0.427748100956281} | train loss {'Reaction outcome loss': 0.3269070361334064, 'Total loss': 0.3269070361334064}
2023-01-04 11:26:48,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:48,834 INFO:     Epoch: 48
2023-01-04 11:26:50,379 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4245601077874502, 'Total loss': 0.4245601077874502} | train loss {'Reaction outcome loss': 0.32459893927569855, 'Total loss': 0.32459893927569855}
2023-01-04 11:26:50,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:50,379 INFO:     Epoch: 49
2023-01-04 11:26:51,928 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4194752097129822, 'Total loss': 0.4194752097129822} | train loss {'Reaction outcome loss': 0.32810362842646745, 'Total loss': 0.32810362842646745}
2023-01-04 11:26:51,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:51,928 INFO:     Epoch: 50
2023-01-04 11:26:53,480 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42849968522787096, 'Total loss': 0.42849968522787096} | train loss {'Reaction outcome loss': 0.3211325450333017, 'Total loss': 0.3211325450333017}
2023-01-04 11:26:53,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:53,481 INFO:     Epoch: 51
2023-01-04 11:26:55,007 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4628586361805598, 'Total loss': 0.4628586361805598} | train loss {'Reaction outcome loss': 0.31831841641492364, 'Total loss': 0.31831841641492364}
2023-01-04 11:26:55,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:55,007 INFO:     Epoch: 52
2023-01-04 11:26:56,553 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4138833612203598, 'Total loss': 0.4138833612203598} | train loss {'Reaction outcome loss': 0.31666996529063596, 'Total loss': 0.31666996529063596}
2023-01-04 11:26:56,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:56,553 INFO:     Epoch: 53
2023-01-04 11:26:58,127 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40885052184263865, 'Total loss': 0.40885052184263865} | train loss {'Reaction outcome loss': 0.3144069279305341, 'Total loss': 0.3144069279305341}
2023-01-04 11:26:58,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:58,128 INFO:     Epoch: 54
2023-01-04 11:26:59,695 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4245560626188914, 'Total loss': 0.4245560626188914} | train loss {'Reaction outcome loss': 0.3152206274630361, 'Total loss': 0.3152206274630361}
2023-01-04 11:26:59,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:26:59,696 INFO:     Epoch: 55
2023-01-04 11:27:01,257 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41869824528694155, 'Total loss': 0.41869824528694155} | train loss {'Reaction outcome loss': 0.31193246509516714, 'Total loss': 0.31193246509516714}
2023-01-04 11:27:01,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:01,257 INFO:     Epoch: 56
2023-01-04 11:27:02,823 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4142254094282786, 'Total loss': 0.4142254094282786} | train loss {'Reaction outcome loss': 0.30569835165885384, 'Total loss': 0.30569835165885384}
2023-01-04 11:27:02,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:02,823 INFO:     Epoch: 57
2023-01-04 11:27:04,359 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4091446250677109, 'Total loss': 0.4091446250677109} | train loss {'Reaction outcome loss': 0.3063259166446834, 'Total loss': 0.3063259166446834}
2023-01-04 11:27:04,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:04,360 INFO:     Epoch: 58
2023-01-04 11:27:05,877 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4295552591482798, 'Total loss': 0.4295552591482798} | train loss {'Reaction outcome loss': 0.30762685415762, 'Total loss': 0.30762685415762}
2023-01-04 11:27:05,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:05,877 INFO:     Epoch: 59
2023-01-04 11:27:07,429 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4476257006327311, 'Total loss': 0.4476257006327311} | train loss {'Reaction outcome loss': 0.30497670517931774, 'Total loss': 0.30497670517931774}
2023-01-04 11:27:07,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:07,429 INFO:     Epoch: 60
2023-01-04 11:27:08,982 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4299160361289978, 'Total loss': 0.4299160361289978} | train loss {'Reaction outcome loss': 0.3036580351500735, 'Total loss': 0.3036580351500735}
2023-01-04 11:27:08,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:08,982 INFO:     Epoch: 61
2023-01-04 11:27:10,543 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45092965960502623, 'Total loss': 0.45092965960502623} | train loss {'Reaction outcome loss': 0.29998519357683856, 'Total loss': 0.29998519357683856}
2023-01-04 11:27:10,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:10,543 INFO:     Epoch: 62
2023-01-04 11:27:12,064 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41505139966805776, 'Total loss': 0.41505139966805776} | train loss {'Reaction outcome loss': 0.30166667145727344, 'Total loss': 0.30166667145727344}
2023-01-04 11:27:12,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:12,065 INFO:     Epoch: 63
2023-01-04 11:27:13,625 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4169106235106786, 'Total loss': 0.4169106235106786} | train loss {'Reaction outcome loss': 0.2948039754256875, 'Total loss': 0.2948039754256875}
2023-01-04 11:27:13,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:13,625 INFO:     Epoch: 64
2023-01-04 11:27:15,148 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44443284372488656, 'Total loss': 0.44443284372488656} | train loss {'Reaction outcome loss': 0.2948605976998806, 'Total loss': 0.2948605976998806}
2023-01-04 11:27:15,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:15,148 INFO:     Epoch: 65
2023-01-04 11:27:16,702 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42894983688990274, 'Total loss': 0.42894983688990274} | train loss {'Reaction outcome loss': 0.296723574991691, 'Total loss': 0.296723574991691}
2023-01-04 11:27:16,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:16,702 INFO:     Epoch: 66
2023-01-04 11:27:18,256 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4094372163216273, 'Total loss': 0.4094372163216273} | train loss {'Reaction outcome loss': 0.29208513826723564, 'Total loss': 0.29208513826723564}
2023-01-04 11:27:18,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:18,256 INFO:     Epoch: 67
2023-01-04 11:27:19,806 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4241428807377815, 'Total loss': 0.4241428807377815} | train loss {'Reaction outcome loss': 0.29325981908864496, 'Total loss': 0.29325981908864496}
2023-01-04 11:27:19,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:19,806 INFO:     Epoch: 68
2023-01-04 11:27:21,331 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41872413059075675, 'Total loss': 0.41872413059075675} | train loss {'Reaction outcome loss': 0.2876956915408911, 'Total loss': 0.2876956915408911}
2023-01-04 11:27:21,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:21,331 INFO:     Epoch: 69
2023-01-04 11:27:22,873 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43762413462003075, 'Total loss': 0.43762413462003075} | train loss {'Reaction outcome loss': 0.28840854255623766, 'Total loss': 0.28840854255623766}
2023-01-04 11:27:22,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:22,873 INFO:     Epoch: 70
2023-01-04 11:27:24,396 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42671084304650625, 'Total loss': 0.42671084304650625} | train loss {'Reaction outcome loss': 0.2899107187986374, 'Total loss': 0.2899107187986374}
2023-01-04 11:27:24,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:24,396 INFO:     Epoch: 71
2023-01-04 11:27:25,952 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4360753466685613, 'Total loss': 0.4360753466685613} | train loss {'Reaction outcome loss': 0.2891536210041614, 'Total loss': 0.2891536210041614}
2023-01-04 11:27:25,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:25,952 INFO:     Epoch: 72
2023-01-04 11:27:27,513 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40773391822973887, 'Total loss': 0.40773391822973887} | train loss {'Reaction outcome loss': 0.28794580415590576, 'Total loss': 0.28794580415590576}
2023-01-04 11:27:27,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:27,514 INFO:     Epoch: 73
2023-01-04 11:27:29,073 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40640703042348225, 'Total loss': 0.40640703042348225} | train loss {'Reaction outcome loss': 0.2839602168770473, 'Total loss': 0.2839602168770473}
2023-01-04 11:27:29,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:29,073 INFO:     Epoch: 74
2023-01-04 11:27:30,596 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4286951214075089, 'Total loss': 0.4286951214075089} | train loss {'Reaction outcome loss': 0.28497541243956837, 'Total loss': 0.28497541243956837}
2023-01-04 11:27:30,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:30,597 INFO:     Epoch: 75
2023-01-04 11:27:32,111 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42773827016353605, 'Total loss': 0.42773827016353605} | train loss {'Reaction outcome loss': 0.2824732694869007, 'Total loss': 0.2824732694869007}
2023-01-04 11:27:32,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:32,111 INFO:     Epoch: 76
2023-01-04 11:27:33,655 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41224684516588844, 'Total loss': 0.41224684516588844} | train loss {'Reaction outcome loss': 0.27891147029098623, 'Total loss': 0.27891147029098623}
2023-01-04 11:27:33,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:33,656 INFO:     Epoch: 77
2023-01-04 11:27:35,209 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41465704441070556, 'Total loss': 0.41465704441070556} | train loss {'Reaction outcome loss': 0.2803087165370745, 'Total loss': 0.2803087165370745}
2023-01-04 11:27:35,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:35,210 INFO:     Epoch: 78
2023-01-04 11:27:36,768 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42961182196935016, 'Total loss': 0.42961182196935016} | train loss {'Reaction outcome loss': 0.2811927019151109, 'Total loss': 0.2811927019151109}
2023-01-04 11:27:36,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:36,769 INFO:     Epoch: 79
2023-01-04 11:27:38,327 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4088446766138077, 'Total loss': 0.4088446766138077} | train loss {'Reaction outcome loss': 0.2762819893039521, 'Total loss': 0.2762819893039521}
2023-01-04 11:27:38,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:38,327 INFO:     Epoch: 80
2023-01-04 11:27:39,851 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41472382644812267, 'Total loss': 0.41472382644812267} | train loss {'Reaction outcome loss': 0.27402613941405224, 'Total loss': 0.27402613941405224}
2023-01-04 11:27:39,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:39,851 INFO:     Epoch: 81
2023-01-04 11:27:41,374 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4395032346248627, 'Total loss': 0.4395032346248627} | train loss {'Reaction outcome loss': 0.2749178720779367, 'Total loss': 0.2749178720779367}
2023-01-04 11:27:41,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:41,374 INFO:     Epoch: 82
2023-01-04 11:27:42,920 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42533694406350453, 'Total loss': 0.42533694406350453} | train loss {'Reaction outcome loss': 0.2743037631096392, 'Total loss': 0.2743037631096392}
2023-01-04 11:27:42,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:42,920 INFO:     Epoch: 83
2023-01-04 11:27:44,478 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4104700356721878, 'Total loss': 0.4104700356721878} | train loss {'Reaction outcome loss': 0.27410164599169035, 'Total loss': 0.27410164599169035}
2023-01-04 11:27:44,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:44,478 INFO:     Epoch: 84
2023-01-04 11:27:46,037 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43356286684672035, 'Total loss': 0.43356286684672035} | train loss {'Reaction outcome loss': 0.27851512853311716, 'Total loss': 0.27851512853311716}
2023-01-04 11:27:46,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:46,037 INFO:     Epoch: 85
2023-01-04 11:27:47,599 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43803552687168124, 'Total loss': 0.43803552687168124} | train loss {'Reaction outcome loss': 0.27097730620996185, 'Total loss': 0.27097730620996185}
2023-01-04 11:27:47,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:47,599 INFO:     Epoch: 86
2023-01-04 11:27:49,123 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4119003434975942, 'Total loss': 0.4119003434975942} | train loss {'Reaction outcome loss': 0.2707257649662908, 'Total loss': 0.2707257649662908}
2023-01-04 11:27:49,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:49,124 INFO:     Epoch: 87
2023-01-04 11:27:50,669 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4340435802936554, 'Total loss': 0.4340435802936554} | train loss {'Reaction outcome loss': 0.2718975244473249, 'Total loss': 0.2718975244473249}
2023-01-04 11:27:50,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:50,669 INFO:     Epoch: 88
2023-01-04 11:27:52,250 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4146656523148219, 'Total loss': 0.4146656523148219} | train loss {'Reaction outcome loss': 0.2709616797871968, 'Total loss': 0.2709616797871968}
2023-01-04 11:27:52,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:52,250 INFO:     Epoch: 89
2023-01-04 11:27:53,813 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.406038831671079, 'Total loss': 0.406038831671079} | train loss {'Reaction outcome loss': 0.26361274444884775, 'Total loss': 0.26361274444884775}
2023-01-04 11:27:53,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:53,813 INFO:     Epoch: 90
2023-01-04 11:27:55,383 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42467487255732217, 'Total loss': 0.42467487255732217} | train loss {'Reaction outcome loss': 0.2669090364491466, 'Total loss': 0.2669090364491466}
2023-01-04 11:27:55,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:55,383 INFO:     Epoch: 91
2023-01-04 11:27:56,945 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4029667466878891, 'Total loss': 0.4029667466878891} | train loss {'Reaction outcome loss': 0.26429347580951046, 'Total loss': 0.26429347580951046}
2023-01-04 11:27:56,946 INFO:     Found new best model at epoch 91
2023-01-04 11:27:56,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:56,946 INFO:     Epoch: 92
2023-01-04 11:27:58,468 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4184875438610713, 'Total loss': 0.4184875438610713} | train loss {'Reaction outcome loss': 0.2659086816900474, 'Total loss': 0.2659086816900474}
2023-01-04 11:27:58,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:58,468 INFO:     Epoch: 93
2023-01-04 11:27:59,996 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42434644798437754, 'Total loss': 0.42434644798437754} | train loss {'Reaction outcome loss': 0.2646357788559762, 'Total loss': 0.2646357788559762}
2023-01-04 11:27:59,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:27:59,996 INFO:     Epoch: 94
2023-01-04 11:28:01,564 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4254601180553436, 'Total loss': 0.4254601180553436} | train loss {'Reaction outcome loss': 0.26553161138339165, 'Total loss': 0.26553161138339165}
2023-01-04 11:28:01,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:01,565 INFO:     Epoch: 95
2023-01-04 11:28:03,139 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4349430799484253, 'Total loss': 0.4349430799484253} | train loss {'Reaction outcome loss': 0.2600829256597624, 'Total loss': 0.2600829256597624}
2023-01-04 11:28:03,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:03,140 INFO:     Epoch: 96
2023-01-04 11:28:04,708 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4463995575904846, 'Total loss': 0.4463995575904846} | train loss {'Reaction outcome loss': 0.2612261112900417, 'Total loss': 0.2612261112900417}
2023-01-04 11:28:04,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:04,708 INFO:     Epoch: 97
2023-01-04 11:28:06,279 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.427762907743454, 'Total loss': 0.427762907743454} | train loss {'Reaction outcome loss': 0.25372964626561434, 'Total loss': 0.25372964626561434}
2023-01-04 11:28:06,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:06,281 INFO:     Epoch: 98
2023-01-04 11:28:07,814 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41190027793248496, 'Total loss': 0.41190027793248496} | train loss {'Reaction outcome loss': 0.25934212202952656, 'Total loss': 0.25934212202952656}
2023-01-04 11:28:07,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:07,814 INFO:     Epoch: 99
2023-01-04 11:28:09,352 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41751625736554465, 'Total loss': 0.41751625736554465} | train loss {'Reaction outcome loss': 0.26125211911511337, 'Total loss': 0.26125211911511337}
2023-01-04 11:28:09,352 INFO:     Best model found after epoch 92 of 100.
2023-01-04 11:28:09,352 INFO:   Done with stage: TRAINING
2023-01-04 11:28:09,352 INFO:   Starting stage: EVALUATION
2023-01-04 11:28:09,473 INFO:   Done with stage: EVALUATION
2023-01-04 11:28:09,473 INFO:   Leaving out SEQ value Fold_5
2023-01-04 11:28:09,486 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 11:28:09,486 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:28:10,132 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:28:10,132 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:28:10,200 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:28:10,200 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:28:10,200 INFO:     No hyperparam tuning for this model
2023-01-04 11:28:10,200 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:28:10,200 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:28:10,201 INFO:     None feature selector for col prot
2023-01-04 11:28:10,201 INFO:     None feature selector for col prot
2023-01-04 11:28:10,201 INFO:     None feature selector for col prot
2023-01-04 11:28:10,201 INFO:     None feature selector for col chem
2023-01-04 11:28:10,202 INFO:     None feature selector for col chem
2023-01-04 11:28:10,202 INFO:     None feature selector for col chem
2023-01-04 11:28:10,202 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:28:10,202 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:28:10,203 INFO:     Number of params in model 70111
2023-01-04 11:28:10,206 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:28:10,206 INFO:   Starting stage: TRAINING
2023-01-04 11:28:10,249 INFO:     Val loss before train {'Reaction outcome loss': 0.9092432498931885, 'Total loss': 0.9092432498931885}
2023-01-04 11:28:10,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:10,249 INFO:     Epoch: 0
2023-01-04 11:28:11,787 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6756710767745971, 'Total loss': 0.6756710767745971} | train loss {'Reaction outcome loss': 0.84314174580313, 'Total loss': 0.84314174580313}
2023-01-04 11:28:11,787 INFO:     Found new best model at epoch 0
2023-01-04 11:28:11,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:11,788 INFO:     Epoch: 1
2023-01-04 11:28:13,345 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5440292656421661, 'Total loss': 0.5440292656421661} | train loss {'Reaction outcome loss': 0.6856160702279014, 'Total loss': 0.6856160702279014}
2023-01-04 11:28:13,346 INFO:     Found new best model at epoch 1
2023-01-04 11:28:13,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:13,347 INFO:     Epoch: 2
2023-01-04 11:28:14,889 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5113383829593658, 'Total loss': 0.5113383829593658} | train loss {'Reaction outcome loss': 0.5896614936799028, 'Total loss': 0.5896614936799028}
2023-01-04 11:28:14,889 INFO:     Found new best model at epoch 2
2023-01-04 11:28:14,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:14,890 INFO:     Epoch: 3
2023-01-04 11:28:16,420 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5159406860669454, 'Total loss': 0.5159406860669454} | train loss {'Reaction outcome loss': 0.5387078512215266, 'Total loss': 0.5387078512215266}
2023-01-04 11:28:16,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:16,420 INFO:     Epoch: 4
2023-01-04 11:28:17,931 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4955809563398361, 'Total loss': 0.4955809563398361} | train loss {'Reaction outcome loss': 0.5162070938487993, 'Total loss': 0.5162070938487993}
2023-01-04 11:28:17,931 INFO:     Found new best model at epoch 4
2023-01-04 11:28:17,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:17,932 INFO:     Epoch: 5
2023-01-04 11:28:19,494 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4701623757680257, 'Total loss': 0.4701623757680257} | train loss {'Reaction outcome loss': 0.4988245751409635, 'Total loss': 0.4988245751409635}
2023-01-04 11:28:19,494 INFO:     Found new best model at epoch 5
2023-01-04 11:28:19,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:19,495 INFO:     Epoch: 6
2023-01-04 11:28:21,064 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44196864366531374, 'Total loss': 0.44196864366531374} | train loss {'Reaction outcome loss': 0.4866342864332408, 'Total loss': 0.4866342864332408}
2023-01-04 11:28:21,064 INFO:     Found new best model at epoch 6
2023-01-04 11:28:21,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:21,065 INFO:     Epoch: 7
2023-01-04 11:28:22,633 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45516462723414103, 'Total loss': 0.45516462723414103} | train loss {'Reaction outcome loss': 0.47859397954749366, 'Total loss': 0.47859397954749366}
2023-01-04 11:28:22,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:22,633 INFO:     Epoch: 8
2023-01-04 11:28:24,159 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4518177310625712, 'Total loss': 0.4518177310625712} | train loss {'Reaction outcome loss': 0.4689274958341661, 'Total loss': 0.4689274958341661}
2023-01-04 11:28:24,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:24,160 INFO:     Epoch: 9
2023-01-04 11:28:25,711 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46443480054537456, 'Total loss': 0.46443480054537456} | train loss {'Reaction outcome loss': 0.46066460785639546, 'Total loss': 0.46066460785639546}
2023-01-04 11:28:25,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:25,712 INFO:     Epoch: 10
2023-01-04 11:28:26,842 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42707273761431375, 'Total loss': 0.42707273761431375} | train loss {'Reaction outcome loss': 0.4549236464565688, 'Total loss': 0.4549236464565688}
2023-01-04 11:28:26,842 INFO:     Found new best model at epoch 10
2023-01-04 11:28:26,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:26,843 INFO:     Epoch: 11
2023-01-04 11:28:27,860 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44527594645818075, 'Total loss': 0.44527594645818075} | train loss {'Reaction outcome loss': 0.4479039961295406, 'Total loss': 0.4479039961295406}
2023-01-04 11:28:27,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:27,860 INFO:     Epoch: 12
2023-01-04 11:28:28,872 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4495728413263957, 'Total loss': 0.4495728413263957} | train loss {'Reaction outcome loss': 0.44135715959280947, 'Total loss': 0.44135715959280947}
2023-01-04 11:28:28,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:28,872 INFO:     Epoch: 13
2023-01-04 11:28:29,888 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42178242405255634, 'Total loss': 0.42178242405255634} | train loss {'Reaction outcome loss': 0.43903632222735967, 'Total loss': 0.43903632222735967}
2023-01-04 11:28:29,888 INFO:     Found new best model at epoch 13
2023-01-04 11:28:29,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:29,889 INFO:     Epoch: 14
2023-01-04 11:28:31,209 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4425855100154877, 'Total loss': 0.4425855100154877} | train loss {'Reaction outcome loss': 0.43321382765569827, 'Total loss': 0.43321382765569827}
2023-01-04 11:28:31,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:31,210 INFO:     Epoch: 15
2023-01-04 11:28:32,747 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4337455968062083, 'Total loss': 0.4337455968062083} | train loss {'Reaction outcome loss': 0.42672040324359045, 'Total loss': 0.42672040324359045}
2023-01-04 11:28:32,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:32,747 INFO:     Epoch: 16
2023-01-04 11:28:34,302 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3986568585038185, 'Total loss': 0.3986568585038185} | train loss {'Reaction outcome loss': 0.42570726464699654, 'Total loss': 0.42570726464699654}
2023-01-04 11:28:34,302 INFO:     Found new best model at epoch 16
2023-01-04 11:28:34,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:34,303 INFO:     Epoch: 17
2023-01-04 11:28:35,837 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4193551997343699, 'Total loss': 0.4193551997343699} | train loss {'Reaction outcome loss': 0.4198833665654172, 'Total loss': 0.4198833665654172}
2023-01-04 11:28:35,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:35,837 INFO:     Epoch: 18
2023-01-04 11:28:37,387 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44115640223026276, 'Total loss': 0.44115640223026276} | train loss {'Reaction outcome loss': 0.4141421084475778, 'Total loss': 0.4141421084475778}
2023-01-04 11:28:37,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:37,387 INFO:     Epoch: 19
2023-01-04 11:28:38,937 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43878481288750965, 'Total loss': 0.43878481288750965} | train loss {'Reaction outcome loss': 0.4105949222660848, 'Total loss': 0.4105949222660848}
2023-01-04 11:28:38,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:38,937 INFO:     Epoch: 20
2023-01-04 11:28:40,406 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42185565729935964, 'Total loss': 0.42185565729935964} | train loss {'Reaction outcome loss': 0.4112693673394022, 'Total loss': 0.4112693673394022}
2023-01-04 11:28:40,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:40,406 INFO:     Epoch: 21
2023-01-04 11:28:41,958 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43290978074073794, 'Total loss': 0.43290978074073794} | train loss {'Reaction outcome loss': 0.40255235233446107, 'Total loss': 0.40255235233446107}
2023-01-04 11:28:41,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:41,959 INFO:     Epoch: 22
2023-01-04 11:28:43,478 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42143768866856895, 'Total loss': 0.42143768866856895} | train loss {'Reaction outcome loss': 0.40189360152848447, 'Total loss': 0.40189360152848447}
2023-01-04 11:28:43,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:43,478 INFO:     Epoch: 23
2023-01-04 11:28:45,010 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4225602428118388, 'Total loss': 0.4225602428118388} | train loss {'Reaction outcome loss': 0.3956819930433357, 'Total loss': 0.3956819930433357}
2023-01-04 11:28:45,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:45,010 INFO:     Epoch: 24
2023-01-04 11:28:46,582 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39809980193773903, 'Total loss': 0.39809980193773903} | train loss {'Reaction outcome loss': 0.39689399416211746, 'Total loss': 0.39689399416211746}
2023-01-04 11:28:46,582 INFO:     Found new best model at epoch 24
2023-01-04 11:28:46,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:46,583 INFO:     Epoch: 25
2023-01-04 11:28:48,172 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4014541725317637, 'Total loss': 0.4014541725317637} | train loss {'Reaction outcome loss': 0.3937099705701762, 'Total loss': 0.3937099705701762}
2023-01-04 11:28:48,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:48,173 INFO:     Epoch: 26
2023-01-04 11:28:49,651 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40543767213821413, 'Total loss': 0.40543767213821413} | train loss {'Reaction outcome loss': 0.38945192759380726, 'Total loss': 0.38945192759380726}
2023-01-04 11:28:49,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:49,651 INFO:     Epoch: 27
2023-01-04 11:28:51,204 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3990372598171234, 'Total loss': 0.3990372598171234} | train loss {'Reaction outcome loss': 0.38243773720995355, 'Total loss': 0.38243773720995355}
2023-01-04 11:28:51,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:51,204 INFO:     Epoch: 28
2023-01-04 11:28:52,760 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40424542923768364, 'Total loss': 0.40424542923768364} | train loss {'Reaction outcome loss': 0.3852340299228247, 'Total loss': 0.3852340299228247}
2023-01-04 11:28:52,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:52,760 INFO:     Epoch: 29
2023-01-04 11:28:54,315 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4095453937848409, 'Total loss': 0.4095453937848409} | train loss {'Reaction outcome loss': 0.37864820001116634, 'Total loss': 0.37864820001116634}
2023-01-04 11:28:54,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:54,315 INFO:     Epoch: 30
2023-01-04 11:28:55,843 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39316409478584924, 'Total loss': 0.39316409478584924} | train loss {'Reaction outcome loss': 0.37533190117700255, 'Total loss': 0.37533190117700255}
2023-01-04 11:28:55,843 INFO:     Found new best model at epoch 30
2023-01-04 11:28:55,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:55,844 INFO:     Epoch: 31
2023-01-04 11:28:57,389 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3969337701797485, 'Total loss': 0.3969337701797485} | train loss {'Reaction outcome loss': 0.37539326899895703, 'Total loss': 0.37539326899895703}
2023-01-04 11:28:57,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:57,389 INFO:     Epoch: 32
2023-01-04 11:28:58,871 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41422007580598197, 'Total loss': 0.41422007580598197} | train loss {'Reaction outcome loss': 0.3699354840184215, 'Total loss': 0.3699354840184215}
2023-01-04 11:28:58,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:28:58,871 INFO:     Epoch: 33
2023-01-04 11:29:00,420 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3940112888813019, 'Total loss': 0.3940112888813019} | train loss {'Reaction outcome loss': 0.36699410519786996, 'Total loss': 0.36699410519786996}
2023-01-04 11:29:00,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:00,421 INFO:     Epoch: 34
2023-01-04 11:29:01,969 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38857146017253397, 'Total loss': 0.38857146017253397} | train loss {'Reaction outcome loss': 0.36491757881467357, 'Total loss': 0.36491757881467357}
2023-01-04 11:29:01,969 INFO:     Found new best model at epoch 34
2023-01-04 11:29:01,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:01,970 INFO:     Epoch: 35
2023-01-04 11:29:03,516 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4003308614095052, 'Total loss': 0.4003308614095052} | train loss {'Reaction outcome loss': 0.36472920589420915, 'Total loss': 0.36472920589420915}
2023-01-04 11:29:03,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:03,516 INFO:     Epoch: 36
2023-01-04 11:29:05,090 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38310213486353556, 'Total loss': 0.38310213486353556} | train loss {'Reaction outcome loss': 0.35866255043958223, 'Total loss': 0.35866255043958223}
2023-01-04 11:29:05,090 INFO:     Found new best model at epoch 36
2023-01-04 11:29:05,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:05,091 INFO:     Epoch: 37
2023-01-04 11:29:06,651 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40672831833362577, 'Total loss': 0.40672831833362577} | train loss {'Reaction outcome loss': 0.35526370616072284, 'Total loss': 0.35526370616072284}
2023-01-04 11:29:06,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:06,651 INFO:     Epoch: 38
2023-01-04 11:29:08,171 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3628224442402522, 'Total loss': 0.3628224442402522} | train loss {'Reaction outcome loss': 0.35371247222171215, 'Total loss': 0.35371247222171215}
2023-01-04 11:29:08,171 INFO:     Found new best model at epoch 38
2023-01-04 11:29:08,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:08,172 INFO:     Epoch: 39
2023-01-04 11:29:09,742 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39623353878657025, 'Total loss': 0.39623353878657025} | train loss {'Reaction outcome loss': 0.34710007536150245, 'Total loss': 0.34710007536150245}
2023-01-04 11:29:09,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:09,742 INFO:     Epoch: 40
2023-01-04 11:29:11,310 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4013677994410197, 'Total loss': 0.4013677994410197} | train loss {'Reaction outcome loss': 0.34911616372257254, 'Total loss': 0.34911616372257254}
2023-01-04 11:29:11,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:11,311 INFO:     Epoch: 41
2023-01-04 11:29:12,893 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3836652338504791, 'Total loss': 0.3836652338504791} | train loss {'Reaction outcome loss': 0.34381600569960846, 'Total loss': 0.34381600569960846}
2023-01-04 11:29:12,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:12,893 INFO:     Epoch: 42
2023-01-04 11:29:14,486 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3818249444166819, 'Total loss': 0.3818249444166819} | train loss {'Reaction outcome loss': 0.3397783029851687, 'Total loss': 0.3397783029851687}
2023-01-04 11:29:14,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:14,486 INFO:     Epoch: 43
2023-01-04 11:29:16,017 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3780906597773234, 'Total loss': 0.3780906597773234} | train loss {'Reaction outcome loss': 0.33684204804309964, 'Total loss': 0.33684204804309964}
2023-01-04 11:29:16,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:16,017 INFO:     Epoch: 44
2023-01-04 11:29:17,575 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.389211572209994, 'Total loss': 0.389211572209994} | train loss {'Reaction outcome loss': 0.33808257463422137, 'Total loss': 0.33808257463422137}
2023-01-04 11:29:17,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:17,576 INFO:     Epoch: 45
2023-01-04 11:29:19,166 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.398642369111379, 'Total loss': 0.398642369111379} | train loss {'Reaction outcome loss': 0.33259491600694446, 'Total loss': 0.33259491600694446}
2023-01-04 11:29:19,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:19,166 INFO:     Epoch: 46
2023-01-04 11:29:20,743 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4081262896458308, 'Total loss': 0.4081262896458308} | train loss {'Reaction outcome loss': 0.33118623315635387, 'Total loss': 0.33118623315635387}
2023-01-04 11:29:20,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:20,743 INFO:     Epoch: 47
2023-01-04 11:29:22,318 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3963663160800934, 'Total loss': 0.3963663160800934} | train loss {'Reaction outcome loss': 0.33487713653730217, 'Total loss': 0.33487713653730217}
2023-01-04 11:29:22,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:22,318 INFO:     Epoch: 48
2023-01-04 11:29:23,883 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3751915896932284, 'Total loss': 0.3751915896932284} | train loss {'Reaction outcome loss': 0.32621891233716566, 'Total loss': 0.32621891233716566}
2023-01-04 11:29:23,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:23,884 INFO:     Epoch: 49
2023-01-04 11:29:25,378 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3901430477698644, 'Total loss': 0.3901430477698644} | train loss {'Reaction outcome loss': 0.3244570889068346, 'Total loss': 0.3244570889068346}
2023-01-04 11:29:25,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:25,378 INFO:     Epoch: 50
2023-01-04 11:29:26,954 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39151487151781716, 'Total loss': 0.39151487151781716} | train loss {'Reaction outcome loss': 0.32583072566746796, 'Total loss': 0.32583072566746796}
2023-01-04 11:29:26,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:26,955 INFO:     Epoch: 51
2023-01-04 11:29:28,525 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36312087774276736, 'Total loss': 0.36312087774276736} | train loss {'Reaction outcome loss': 0.3222390485886675, 'Total loss': 0.3222390485886675}
2023-01-04 11:29:28,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:28,525 INFO:     Epoch: 52
2023-01-04 11:29:30,080 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37849936783313753, 'Total loss': 0.37849936783313753} | train loss {'Reaction outcome loss': 0.31550440401600227, 'Total loss': 0.31550440401600227}
2023-01-04 11:29:30,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:30,080 INFO:     Epoch: 53
2023-01-04 11:29:31,656 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3642138550678889, 'Total loss': 0.3642138550678889} | train loss {'Reaction outcome loss': 0.3138233880056952, 'Total loss': 0.3138233880056952}
2023-01-04 11:29:31,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:31,657 INFO:     Epoch: 54
2023-01-04 11:29:33,228 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3726978152990341, 'Total loss': 0.3726978152990341} | train loss {'Reaction outcome loss': 0.3146170553119078, 'Total loss': 0.3146170553119078}
2023-01-04 11:29:33,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:33,228 INFO:     Epoch: 55
2023-01-04 11:29:34,725 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37857311467329663, 'Total loss': 0.37857311467329663} | train loss {'Reaction outcome loss': 0.313643721985991, 'Total loss': 0.313643721985991}
2023-01-04 11:29:34,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:34,725 INFO:     Epoch: 56
2023-01-04 11:29:36,286 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3622193853060404, 'Total loss': 0.3622193853060404} | train loss {'Reaction outcome loss': 0.3127777327368729, 'Total loss': 0.3127777327368729}
2023-01-04 11:29:36,287 INFO:     Found new best model at epoch 56
2023-01-04 11:29:36,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:36,288 INFO:     Epoch: 57
2023-01-04 11:29:37,844 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3755789359410604, 'Total loss': 0.3755789359410604} | train loss {'Reaction outcome loss': 0.3089720525228194, 'Total loss': 0.3089720525228194}
2023-01-04 11:29:37,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:37,844 INFO:     Epoch: 58
2023-01-04 11:29:39,408 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3536680196722349, 'Total loss': 0.3536680196722349} | train loss {'Reaction outcome loss': 0.30469200004191294, 'Total loss': 0.30469200004191294}
2023-01-04 11:29:39,408 INFO:     Found new best model at epoch 58
2023-01-04 11:29:39,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:39,409 INFO:     Epoch: 59
2023-01-04 11:29:40,975 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3950661212205887, 'Total loss': 0.3950661212205887} | train loss {'Reaction outcome loss': 0.30538372502383526, 'Total loss': 0.30538372502383526}
2023-01-04 11:29:40,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:40,975 INFO:     Epoch: 60
2023-01-04 11:29:42,543 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3828849862019221, 'Total loss': 0.3828849862019221} | train loss {'Reaction outcome loss': 0.3059488274700885, 'Total loss': 0.3059488274700885}
2023-01-04 11:29:42,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:42,544 INFO:     Epoch: 61
2023-01-04 11:29:44,043 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37354180912176765, 'Total loss': 0.37354180912176765} | train loss {'Reaction outcome loss': 0.3020683135701357, 'Total loss': 0.3020683135701357}
2023-01-04 11:29:44,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:44,043 INFO:     Epoch: 62
2023-01-04 11:29:45,611 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37628196477890014, 'Total loss': 0.37628196477890014} | train loss {'Reaction outcome loss': 0.302038057469321, 'Total loss': 0.302038057469321}
2023-01-04 11:29:45,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:45,611 INFO:     Epoch: 63
2023-01-04 11:29:47,157 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.35760960628588995, 'Total loss': 0.35760960628588995} | train loss {'Reaction outcome loss': 0.2979277175762793, 'Total loss': 0.2979277175762793}
2023-01-04 11:29:47,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:47,157 INFO:     Epoch: 64
2023-01-04 11:29:48,697 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38083449502786, 'Total loss': 0.38083449502786} | train loss {'Reaction outcome loss': 0.297387012491261, 'Total loss': 0.297387012491261}
2023-01-04 11:29:48,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:48,697 INFO:     Epoch: 65
2023-01-04 11:29:50,242 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37912132441997526, 'Total loss': 0.37912132441997526} | train loss {'Reaction outcome loss': 0.2954331760423897, 'Total loss': 0.2954331760423897}
2023-01-04 11:29:50,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:50,243 INFO:     Epoch: 66
2023-01-04 11:29:51,795 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39845951497554777, 'Total loss': 0.39845951497554777} | train loss {'Reaction outcome loss': 0.29051823144520283, 'Total loss': 0.29051823144520283}
2023-01-04 11:29:51,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:51,795 INFO:     Epoch: 67
2023-01-04 11:29:53,269 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3817799607912699, 'Total loss': 0.3817799607912699} | train loss {'Reaction outcome loss': 0.29385651291830694, 'Total loss': 0.29385651291830694}
2023-01-04 11:29:53,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:53,270 INFO:     Epoch: 68
2023-01-04 11:29:54,812 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4106540520985921, 'Total loss': 0.4106540520985921} | train loss {'Reaction outcome loss': 0.2909464262099597, 'Total loss': 0.2909464262099597}
2023-01-04 11:29:54,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:54,812 INFO:     Epoch: 69
2023-01-04 11:29:56,353 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.37067907651265464, 'Total loss': 0.37067907651265464} | train loss {'Reaction outcome loss': 0.2890467145174307, 'Total loss': 0.2890467145174307}
2023-01-04 11:29:56,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:56,353 INFO:     Epoch: 70
2023-01-04 11:29:57,894 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4084715207417806, 'Total loss': 0.4084715207417806} | train loss {'Reaction outcome loss': 0.2911456466591271, 'Total loss': 0.2911456466591271}
2023-01-04 11:29:57,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:57,895 INFO:     Epoch: 71
2023-01-04 11:29:59,454 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3855295111735662, 'Total loss': 0.3855295111735662} | train loss {'Reaction outcome loss': 0.28728946893863433, 'Total loss': 0.28728946893863433}
2023-01-04 11:29:59,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:29:59,454 INFO:     Epoch: 72
2023-01-04 11:30:00,970 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37684289117654163, 'Total loss': 0.37684289117654163} | train loss {'Reaction outcome loss': 0.2869256183396291, 'Total loss': 0.2869256183396291}
2023-01-04 11:30:00,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:00,970 INFO:     Epoch: 73
2023-01-04 11:30:02,455 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37839596569538114, 'Total loss': 0.37839596569538114} | train loss {'Reaction outcome loss': 0.28141123167898535, 'Total loss': 0.28141123167898535}
2023-01-04 11:30:02,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:02,455 INFO:     Epoch: 74
2023-01-04 11:30:03,994 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3979890078306198, 'Total loss': 0.3979890078306198} | train loss {'Reaction outcome loss': 0.283249939581121, 'Total loss': 0.283249939581121}
2023-01-04 11:30:03,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:03,995 INFO:     Epoch: 75
2023-01-04 11:30:05,520 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37951124608516695, 'Total loss': 0.37951124608516695} | train loss {'Reaction outcome loss': 0.2809759957620697, 'Total loss': 0.2809759957620697}
2023-01-04 11:30:05,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:05,520 INFO:     Epoch: 76
2023-01-04 11:30:07,050 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.381462362408638, 'Total loss': 0.381462362408638} | train loss {'Reaction outcome loss': 0.2817441093715003, 'Total loss': 0.2817441093715003}
2023-01-04 11:30:07,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:07,050 INFO:     Epoch: 77
2023-01-04 11:30:08,608 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37678211033344267, 'Total loss': 0.37678211033344267} | train loss {'Reaction outcome loss': 0.2819508606581575, 'Total loss': 0.2819508606581575}
2023-01-04 11:30:08,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:08,608 INFO:     Epoch: 78
2023-01-04 11:30:10,133 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4010937472184499, 'Total loss': 0.4010937472184499} | train loss {'Reaction outcome loss': 0.2791211248586213, 'Total loss': 0.2791211248586213}
2023-01-04 11:30:10,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:10,133 INFO:     Epoch: 79
2023-01-04 11:30:11,643 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.37839765747388204, 'Total loss': 0.37839765747388204} | train loss {'Reaction outcome loss': 0.2811673838291725, 'Total loss': 0.2811673838291725}
2023-01-04 11:30:11,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:11,644 INFO:     Epoch: 80
2023-01-04 11:30:13,207 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3720429648955663, 'Total loss': 0.3720429648955663} | train loss {'Reaction outcome loss': 0.2732863602683927, 'Total loss': 0.2732863602683927}
2023-01-04 11:30:13,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:13,207 INFO:     Epoch: 81
2023-01-04 11:30:14,760 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.379363273580869, 'Total loss': 0.379363273580869} | train loss {'Reaction outcome loss': 0.2719306790942911, 'Total loss': 0.2719306790942911}
2023-01-04 11:30:14,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:14,760 INFO:     Epoch: 82
2023-01-04 11:30:16,309 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3832432230313619, 'Total loss': 0.3832432230313619} | train loss {'Reaction outcome loss': 0.27192012805246957, 'Total loss': 0.27192012805246957}
2023-01-04 11:30:16,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:16,309 INFO:     Epoch: 83
2023-01-04 11:30:17,858 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38937834203243255, 'Total loss': 0.38937834203243255} | train loss {'Reaction outcome loss': 0.2720150757227501, 'Total loss': 0.2720150757227501}
2023-01-04 11:30:17,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:17,859 INFO:     Epoch: 84
2023-01-04 11:30:19,383 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3781456718842188, 'Total loss': 0.3781456718842188} | train loss {'Reaction outcome loss': 0.27081211126089966, 'Total loss': 0.27081211126089966}
2023-01-04 11:30:19,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:19,384 INFO:     Epoch: 85
2023-01-04 11:30:20,887 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40273492137591044, 'Total loss': 0.40273492137591044} | train loss {'Reaction outcome loss': 0.2723754770836256, 'Total loss': 0.2723754770836256}
2023-01-04 11:30:20,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:20,887 INFO:     Epoch: 86
2023-01-04 11:30:22,433 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37915594975153605, 'Total loss': 0.37915594975153605} | train loss {'Reaction outcome loss': 0.27130048164594783, 'Total loss': 0.27130048164594783}
2023-01-04 11:30:22,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:22,433 INFO:     Epoch: 87
2023-01-04 11:30:23,984 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38728686968485515, 'Total loss': 0.38728686968485515} | train loss {'Reaction outcome loss': 0.2641064198619693, 'Total loss': 0.2641064198619693}
2023-01-04 11:30:23,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:23,985 INFO:     Epoch: 88
2023-01-04 11:30:25,538 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.36620091199874877, 'Total loss': 0.36620091199874877} | train loss {'Reaction outcome loss': 0.2673981687883391, 'Total loss': 0.2673981687883391}
2023-01-04 11:30:25,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:25,538 INFO:     Epoch: 89
2023-01-04 11:30:27,091 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39960021128257117, 'Total loss': 0.39960021128257117} | train loss {'Reaction outcome loss': 0.26728490082016826, 'Total loss': 0.26728490082016826}
2023-01-04 11:30:27,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:27,092 INFO:     Epoch: 90
2023-01-04 11:30:28,612 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3824178665876389, 'Total loss': 0.3824178665876389} | train loss {'Reaction outcome loss': 0.2681396008897437, 'Total loss': 0.2681396008897437}
2023-01-04 11:30:28,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:28,612 INFO:     Epoch: 91
2023-01-04 11:30:30,128 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.413699205716451, 'Total loss': 0.413699205716451} | train loss {'Reaction outcome loss': 0.2649242684217918, 'Total loss': 0.2649242684217918}
2023-01-04 11:30:30,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:30,129 INFO:     Epoch: 92
2023-01-04 11:30:31,686 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4168284436066945, 'Total loss': 0.4168284436066945} | train loss {'Reaction outcome loss': 0.2614842496377273, 'Total loss': 0.2614842496377273}
2023-01-04 11:30:31,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:31,686 INFO:     Epoch: 93
2023-01-04 11:30:33,247 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36437541296084724, 'Total loss': 0.36437541296084724} | train loss {'Reaction outcome loss': 0.26307473913596496, 'Total loss': 0.26307473913596496}
2023-01-04 11:30:33,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:33,248 INFO:     Epoch: 94
2023-01-04 11:30:34,797 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.391701806584994, 'Total loss': 0.391701806584994} | train loss {'Reaction outcome loss': 0.26138636089154405, 'Total loss': 0.26138636089154405}
2023-01-04 11:30:34,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:34,797 INFO:     Epoch: 95
2023-01-04 11:30:36,345 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4045741985241572, 'Total loss': 0.4045741985241572} | train loss {'Reaction outcome loss': 0.2605453583065176, 'Total loss': 0.2605453583065176}
2023-01-04 11:30:36,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:36,345 INFO:     Epoch: 96
2023-01-04 11:30:37,866 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3892409751812617, 'Total loss': 0.3892409751812617} | train loss {'Reaction outcome loss': 0.2646463381221695, 'Total loss': 0.2646463381221695}
2023-01-04 11:30:37,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:37,866 INFO:     Epoch: 97
2023-01-04 11:30:39,420 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44376962234576545, 'Total loss': 0.44376962234576545} | train loss {'Reaction outcome loss': 0.26146137385364, 'Total loss': 0.26146137385364}
2023-01-04 11:30:39,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:39,420 INFO:     Epoch: 98
2023-01-04 11:30:40,981 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3860147217909495, 'Total loss': 0.3860147217909495} | train loss {'Reaction outcome loss': 0.2572897849128629, 'Total loss': 0.2572897849128629}
2023-01-04 11:30:40,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:40,981 INFO:     Epoch: 99
2023-01-04 11:30:42,520 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3770600269238154, 'Total loss': 0.3770600269238154} | train loss {'Reaction outcome loss': 0.256303567357742, 'Total loss': 0.256303567357742}
2023-01-04 11:30:42,521 INFO:     Best model found after epoch 59 of 100.
2023-01-04 11:30:42,521 INFO:   Done with stage: TRAINING
2023-01-04 11:30:42,521 INFO:   Starting stage: EVALUATION
2023-01-04 11:30:42,654 INFO:   Done with stage: EVALUATION
2023-01-04 11:30:42,654 INFO:   Leaving out SEQ value Fold_6
2023-01-04 11:30:42,667 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 11:30:42,667 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:30:43,304 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:30:43,305 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:30:43,371 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:30:43,371 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:30:43,371 INFO:     No hyperparam tuning for this model
2023-01-04 11:30:43,371 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:30:43,372 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:30:43,372 INFO:     None feature selector for col prot
2023-01-04 11:30:43,372 INFO:     None feature selector for col prot
2023-01-04 11:30:43,372 INFO:     None feature selector for col prot
2023-01-04 11:30:43,373 INFO:     None feature selector for col chem
2023-01-04 11:30:43,373 INFO:     None feature selector for col chem
2023-01-04 11:30:43,373 INFO:     None feature selector for col chem
2023-01-04 11:30:43,373 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:30:43,373 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:30:43,374 INFO:     Number of params in model 70111
2023-01-04 11:30:43,377 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:30:43,378 INFO:   Starting stage: TRAINING
2023-01-04 11:30:43,420 INFO:     Val loss before train {'Reaction outcome loss': 1.0885295589764914, 'Total loss': 1.0885295589764914}
2023-01-04 11:30:43,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:43,420 INFO:     Epoch: 0
2023-01-04 11:30:44,970 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7738016247749329, 'Total loss': 0.7738016247749329} | train loss {'Reaction outcome loss': 0.8128421169060928, 'Total loss': 0.8128421169060928}
2023-01-04 11:30:44,970 INFO:     Found new best model at epoch 0
2023-01-04 11:30:44,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:44,971 INFO:     Epoch: 1
2023-01-04 11:30:46,478 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6502738893032074, 'Total loss': 0.6502738893032074} | train loss {'Reaction outcome loss': 0.6369797756602039, 'Total loss': 0.6369797756602039}
2023-01-04 11:30:46,478 INFO:     Found new best model at epoch 1
2023-01-04 11:30:46,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:46,479 INFO:     Epoch: 2
2023-01-04 11:30:48,007 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5967683881521225, 'Total loss': 0.5967683881521225} | train loss {'Reaction outcome loss': 0.5595506991877224, 'Total loss': 0.5595506991877224}
2023-01-04 11:30:48,007 INFO:     Found new best model at epoch 2
2023-01-04 11:30:48,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:48,008 INFO:     Epoch: 3
2023-01-04 11:30:49,583 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5770569086074829, 'Total loss': 0.5770569086074829} | train loss {'Reaction outcome loss': 0.5254317613748404, 'Total loss': 0.5254317613748404}
2023-01-04 11:30:49,583 INFO:     Found new best model at epoch 3
2023-01-04 11:30:49,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:49,584 INFO:     Epoch: 4
2023-01-04 11:30:51,132 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5717933386564255, 'Total loss': 0.5717933386564255} | train loss {'Reaction outcome loss': 0.5094012186859117, 'Total loss': 0.5094012186859117}
2023-01-04 11:30:51,132 INFO:     Found new best model at epoch 4
2023-01-04 11:30:51,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:51,133 INFO:     Epoch: 5
2023-01-04 11:30:52,677 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5607472598552704, 'Total loss': 0.5607472598552704} | train loss {'Reaction outcome loss': 0.5009589207259727, 'Total loss': 0.5009589207259727}
2023-01-04 11:30:52,677 INFO:     Found new best model at epoch 5
2023-01-04 11:30:52,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:52,678 INFO:     Epoch: 6
2023-01-04 11:30:54,208 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5511803746223449, 'Total loss': 0.5511803746223449} | train loss {'Reaction outcome loss': 0.4870559321545856, 'Total loss': 0.4870559321545856}
2023-01-04 11:30:54,209 INFO:     Found new best model at epoch 6
2023-01-04 11:30:54,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:54,210 INFO:     Epoch: 7
2023-01-04 11:30:55,703 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5602742473284403, 'Total loss': 0.5602742473284403} | train loss {'Reaction outcome loss': 0.4779813843114035, 'Total loss': 0.4779813843114035}
2023-01-04 11:30:55,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:55,703 INFO:     Epoch: 8
2023-01-04 11:30:57,268 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5229060689608256, 'Total loss': 0.5229060689608256} | train loss {'Reaction outcome loss': 0.474906692083502, 'Total loss': 0.474906692083502}
2023-01-04 11:30:57,268 INFO:     Found new best model at epoch 8
2023-01-04 11:30:57,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:57,269 INFO:     Epoch: 9
2023-01-04 11:30:58,841 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5080370277166366, 'Total loss': 0.5080370277166366} | train loss {'Reaction outcome loss': 0.4616181079175446, 'Total loss': 0.4616181079175446}
2023-01-04 11:30:58,841 INFO:     Found new best model at epoch 9
2023-01-04 11:30:58,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:30:58,842 INFO:     Epoch: 10
2023-01-04 11:31:00,405 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5565466463565827, 'Total loss': 0.5565466463565827} | train loss {'Reaction outcome loss': 0.45352742550792274, 'Total loss': 0.45352742550792274}
2023-01-04 11:31:00,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:00,406 INFO:     Epoch: 11
2023-01-04 11:31:01,996 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5210387428601583, 'Total loss': 0.5210387428601583} | train loss {'Reaction outcome loss': 0.4509158159568633, 'Total loss': 0.4509158159568633}
2023-01-04 11:31:01,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:01,997 INFO:     Epoch: 12
2023-01-04 11:31:03,573 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5345397273699443, 'Total loss': 0.5345397273699443} | train loss {'Reaction outcome loss': 0.44432908869706667, 'Total loss': 0.44432908869706667}
2023-01-04 11:31:03,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:03,573 INFO:     Epoch: 13
2023-01-04 11:31:05,062 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5245536764462789, 'Total loss': 0.5245536764462789} | train loss {'Reaction outcome loss': 0.4414060918730257, 'Total loss': 0.4414060918730257}
2023-01-04 11:31:05,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:05,063 INFO:     Epoch: 14
2023-01-04 11:31:06,628 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5091553688049316, 'Total loss': 0.5091553688049316} | train loss {'Reaction outcome loss': 0.4378666768307651, 'Total loss': 0.4378666768307651}
2023-01-04 11:31:06,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:06,628 INFO:     Epoch: 15
2023-01-04 11:31:08,185 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49471683700879415, 'Total loss': 0.49471683700879415} | train loss {'Reaction outcome loss': 0.4289245306626781, 'Total loss': 0.4289245306626781}
2023-01-04 11:31:08,185 INFO:     Found new best model at epoch 15
2023-01-04 11:31:08,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:08,186 INFO:     Epoch: 16
2023-01-04 11:31:09,748 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5356354693571727, 'Total loss': 0.5356354693571727} | train loss {'Reaction outcome loss': 0.4246431460856518, 'Total loss': 0.4246431460856518}
2023-01-04 11:31:09,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:09,748 INFO:     Epoch: 17
2023-01-04 11:31:11,310 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5203562994798024, 'Total loss': 0.5203562994798024} | train loss {'Reaction outcome loss': 0.4175285833986688, 'Total loss': 0.4175285833986688}
2023-01-04 11:31:11,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:11,311 INFO:     Epoch: 18
2023-01-04 11:31:12,874 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5010037402311961, 'Total loss': 0.5010037402311961} | train loss {'Reaction outcome loss': 0.4121063246013044, 'Total loss': 0.4121063246013044}
2023-01-04 11:31:12,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:12,875 INFO:     Epoch: 19
2023-01-04 11:31:14,369 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5100428362687429, 'Total loss': 0.5100428362687429} | train loss {'Reaction outcome loss': 0.40443220068683555, 'Total loss': 0.40443220068683555}
2023-01-04 11:31:14,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:14,369 INFO:     Epoch: 20
2023-01-04 11:31:15,904 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5043900805215041, 'Total loss': 0.5043900805215041} | train loss {'Reaction outcome loss': 0.4069590641137881, 'Total loss': 0.4069590641137881}
2023-01-04 11:31:15,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:15,905 INFO:     Epoch: 21
2023-01-04 11:31:17,442 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5035675754149754, 'Total loss': 0.5035675754149754} | train loss {'Reaction outcome loss': 0.4003191763064364, 'Total loss': 0.4003191763064364}
2023-01-04 11:31:17,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:17,442 INFO:     Epoch: 22
2023-01-04 11:31:18,982 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.522702357172966, 'Total loss': 0.522702357172966} | train loss {'Reaction outcome loss': 0.3963005793836964, 'Total loss': 0.3963005793836964}
2023-01-04 11:31:18,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:18,982 INFO:     Epoch: 23
2023-01-04 11:31:20,541 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4766889611879985, 'Total loss': 0.4766889611879985} | train loss {'Reaction outcome loss': 0.39077182834620006, 'Total loss': 0.39077182834620006}
2023-01-04 11:31:20,541 INFO:     Found new best model at epoch 23
2023-01-04 11:31:20,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:20,542 INFO:     Epoch: 24
2023-01-04 11:31:22,115 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4780671000480652, 'Total loss': 0.4780671000480652} | train loss {'Reaction outcome loss': 0.392383085611539, 'Total loss': 0.392383085611539}
2023-01-04 11:31:22,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:22,116 INFO:     Epoch: 25
2023-01-04 11:31:23,586 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4897796750068665, 'Total loss': 0.4897796750068665} | train loss {'Reaction outcome loss': 0.38569161765304677, 'Total loss': 0.38569161765304677}
2023-01-04 11:31:23,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:23,586 INFO:     Epoch: 26
2023-01-04 11:31:25,147 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5186867713928223, 'Total loss': 0.5186867713928223} | train loss {'Reaction outcome loss': 0.38023651866139946, 'Total loss': 0.38023651866139946}
2023-01-04 11:31:25,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:25,148 INFO:     Epoch: 27
2023-01-04 11:31:26,700 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48837810158729555, 'Total loss': 0.48837810158729555} | train loss {'Reaction outcome loss': 0.37897123811227496, 'Total loss': 0.37897123811227496}
2023-01-04 11:31:26,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:26,700 INFO:     Epoch: 28
2023-01-04 11:31:28,255 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47949193318684896, 'Total loss': 0.47949193318684896} | train loss {'Reaction outcome loss': 0.368573675716753, 'Total loss': 0.368573675716753}
2023-01-04 11:31:28,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:28,255 INFO:     Epoch: 29
2023-01-04 11:31:29,815 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46300233403841656, 'Total loss': 0.46300233403841656} | train loss {'Reaction outcome loss': 0.3650584057683036, 'Total loss': 0.3650584057683036}
2023-01-04 11:31:29,815 INFO:     Found new best model at epoch 29
2023-01-04 11:31:29,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:29,816 INFO:     Epoch: 30
2023-01-04 11:31:31,369 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47690067092577615, 'Total loss': 0.47690067092577615} | train loss {'Reaction outcome loss': 0.36007453948805185, 'Total loss': 0.36007453948805185}
2023-01-04 11:31:31,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:31,370 INFO:     Epoch: 31
2023-01-04 11:31:32,879 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.481275741259257, 'Total loss': 0.481275741259257} | train loss {'Reaction outcome loss': 0.3573374658168017, 'Total loss': 0.3573374658168017}
2023-01-04 11:31:32,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:32,879 INFO:     Epoch: 32
2023-01-04 11:31:34,426 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4948234558105469, 'Total loss': 0.4948234558105469} | train loss {'Reaction outcome loss': 0.35599390873105535, 'Total loss': 0.35599390873105535}
2023-01-04 11:31:34,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:34,427 INFO:     Epoch: 33
2023-01-04 11:31:35,983 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48354051212469734, 'Total loss': 0.48354051212469734} | train loss {'Reaction outcome loss': 0.3576955974866182, 'Total loss': 0.3576955974866182}
2023-01-04 11:31:35,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:35,983 INFO:     Epoch: 34
2023-01-04 11:31:37,531 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4718224008878072, 'Total loss': 0.4718224008878072} | train loss {'Reaction outcome loss': 0.3487917135159175, 'Total loss': 0.3487917135159175}
2023-01-04 11:31:37,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:37,531 INFO:     Epoch: 35
2023-01-04 11:31:39,100 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4817231376965841, 'Total loss': 0.4817231376965841} | train loss {'Reaction outcome loss': 0.3447752149004639, 'Total loss': 0.3447752149004639}
2023-01-04 11:31:39,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:39,100 INFO:     Epoch: 36
2023-01-04 11:31:40,629 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.482841694355011, 'Total loss': 0.482841694355011} | train loss {'Reaction outcome loss': 0.34350615174888255, 'Total loss': 0.34350615174888255}
2023-01-04 11:31:40,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:40,629 INFO:     Epoch: 37
2023-01-04 11:31:42,129 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5102737466494243, 'Total loss': 0.5102737466494243} | train loss {'Reaction outcome loss': 0.33809667143411254, 'Total loss': 0.33809667143411254}
2023-01-04 11:31:42,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:42,129 INFO:     Epoch: 38
2023-01-04 11:31:43,657 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4962001303831736, 'Total loss': 0.4962001303831736} | train loss {'Reaction outcome loss': 0.3398218164732168, 'Total loss': 0.3398218164732168}
2023-01-04 11:31:43,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:43,658 INFO:     Epoch: 39
2023-01-04 11:31:45,180 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5028250366449356, 'Total loss': 0.5028250366449356} | train loss {'Reaction outcome loss': 0.3370593793881245, 'Total loss': 0.3370593793881245}
2023-01-04 11:31:45,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:45,180 INFO:     Epoch: 40
2023-01-04 11:31:46,716 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46757619380950927, 'Total loss': 0.46757619380950927} | train loss {'Reaction outcome loss': 0.3338939285813234, 'Total loss': 0.3338939285813234}
2023-01-04 11:31:46,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:46,716 INFO:     Epoch: 41
2023-01-04 11:31:48,246 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4850148399670919, 'Total loss': 0.4850148399670919} | train loss {'Reaction outcome loss': 0.3275533892459922, 'Total loss': 0.3275533892459922}
2023-01-04 11:31:48,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:48,246 INFO:     Epoch: 42
2023-01-04 11:31:49,749 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4683072646458944, 'Total loss': 0.4683072646458944} | train loss {'Reaction outcome loss': 0.32613300753163765, 'Total loss': 0.32613300753163765}
2023-01-04 11:31:49,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:49,749 INFO:     Epoch: 43
2023-01-04 11:31:51,245 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46556769410769144, 'Total loss': 0.46556769410769144} | train loss {'Reaction outcome loss': 0.32320237773787847, 'Total loss': 0.32320237773787847}
2023-01-04 11:31:51,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:51,245 INFO:     Epoch: 44
2023-01-04 11:31:52,775 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48360605041186017, 'Total loss': 0.48360605041186017} | train loss {'Reaction outcome loss': 0.3236551237848652, 'Total loss': 0.3236551237848652}
2023-01-04 11:31:52,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:52,775 INFO:     Epoch: 45
2023-01-04 11:31:54,308 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48794586658477784, 'Total loss': 0.48794586658477784} | train loss {'Reaction outcome loss': 0.3182183903379318, 'Total loss': 0.3182183903379318}
2023-01-04 11:31:54,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:54,309 INFO:     Epoch: 46
2023-01-04 11:31:55,825 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4766955335934957, 'Total loss': 0.4766955335934957} | train loss {'Reaction outcome loss': 0.31635675358248283, 'Total loss': 0.31635675358248283}
2023-01-04 11:31:55,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:55,827 INFO:     Epoch: 47
2023-01-04 11:31:57,345 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4658071309328079, 'Total loss': 0.4658071309328079} | train loss {'Reaction outcome loss': 0.31678309597266024, 'Total loss': 0.31678309597266024}
2023-01-04 11:31:57,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:57,346 INFO:     Epoch: 48
2023-01-04 11:31:58,853 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47017167607943217, 'Total loss': 0.47017167607943217} | train loss {'Reaction outcome loss': 0.3164171075427925, 'Total loss': 0.3164171075427925}
2023-01-04 11:31:58,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:31:58,853 INFO:     Epoch: 49
2023-01-04 11:32:00,355 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48028062184651693, 'Total loss': 0.48028062184651693} | train loss {'Reaction outcome loss': 0.3118869967130951, 'Total loss': 0.3118869967130951}
2023-01-04 11:32:00,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:00,355 INFO:     Epoch: 50
2023-01-04 11:32:01,918 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46423195401827494, 'Total loss': 0.46423195401827494} | train loss {'Reaction outcome loss': 0.309202243966279, 'Total loss': 0.309202243966279}
2023-01-04 11:32:01,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:01,919 INFO:     Epoch: 51
2023-01-04 11:32:03,461 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4658576689660549, 'Total loss': 0.4658576689660549} | train loss {'Reaction outcome loss': 0.30689402231639556, 'Total loss': 0.30689402231639556}
2023-01-04 11:32:03,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:03,462 INFO:     Epoch: 52
2023-01-04 11:32:05,009 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49496854543685914, 'Total loss': 0.49496854543685914} | train loss {'Reaction outcome loss': 0.30427055756796845, 'Total loss': 0.30427055756796845}
2023-01-04 11:32:05,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:05,009 INFO:     Epoch: 53
2023-01-04 11:32:06,554 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4749763488769531, 'Total loss': 0.4749763488769531} | train loss {'Reaction outcome loss': 0.30345421674705686, 'Total loss': 0.30345421674705686}
2023-01-04 11:32:06,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:06,555 INFO:     Epoch: 54
2023-01-04 11:32:08,058 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5025251885255178, 'Total loss': 0.5025251885255178} | train loss {'Reaction outcome loss': 0.29925295555002085, 'Total loss': 0.29925295555002085}
2023-01-04 11:32:08,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:08,058 INFO:     Epoch: 55
2023-01-04 11:32:09,571 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47047014236450196, 'Total loss': 0.47047014236450196} | train loss {'Reaction outcome loss': 0.2994863600248382, 'Total loss': 0.2994863600248382}
2023-01-04 11:32:09,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:09,571 INFO:     Epoch: 56
2023-01-04 11:32:11,142 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4933470398187637, 'Total loss': 0.4933470398187637} | train loss {'Reaction outcome loss': 0.2963631115444414, 'Total loss': 0.2963631115444414}
2023-01-04 11:32:11,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:11,142 INFO:     Epoch: 57
2023-01-04 11:32:12,691 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4869936227798462, 'Total loss': 0.4869936227798462} | train loss {'Reaction outcome loss': 0.296151822030326, 'Total loss': 0.296151822030326}
2023-01-04 11:32:12,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:12,691 INFO:     Epoch: 58
2023-01-04 11:32:14,240 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4707776953776677, 'Total loss': 0.4707776953776677} | train loss {'Reaction outcome loss': 0.29324769275092377, 'Total loss': 0.29324769275092377}
2023-01-04 11:32:14,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:14,241 INFO:     Epoch: 59
2023-01-04 11:32:15,777 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47297980785369875, 'Total loss': 0.47297980785369875} | train loss {'Reaction outcome loss': 0.2931986682308026, 'Total loss': 0.2931986682308026}
2023-01-04 11:32:15,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:15,778 INFO:     Epoch: 60
2023-01-04 11:32:17,279 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4554138779640198, 'Total loss': 0.4554138779640198} | train loss {'Reaction outcome loss': 0.29084165843251425, 'Total loss': 0.29084165843251425}
2023-01-04 11:32:17,279 INFO:     Found new best model at epoch 60
2023-01-04 11:32:17,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:17,280 INFO:     Epoch: 61
2023-01-04 11:32:18,817 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4735865821441015, 'Total loss': 0.4735865821441015} | train loss {'Reaction outcome loss': 0.2880832111060401, 'Total loss': 0.2880832111060401}
2023-01-04 11:32:18,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:18,817 INFO:     Epoch: 62
2023-01-04 11:32:20,365 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47085945010185243, 'Total loss': 0.47085945010185243} | train loss {'Reaction outcome loss': 0.2844315027551992, 'Total loss': 0.2844315027551992}
2023-01-04 11:32:20,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:20,365 INFO:     Epoch: 63
2023-01-04 11:32:21,909 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46692277789115905, 'Total loss': 0.46692277789115905} | train loss {'Reaction outcome loss': 0.2866303922519797, 'Total loss': 0.2866303922519797}
2023-01-04 11:32:21,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:21,909 INFO:     Epoch: 64
2023-01-04 11:32:23,448 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4501156985759735, 'Total loss': 0.4501156985759735} | train loss {'Reaction outcome loss': 0.2839779053633903, 'Total loss': 0.2839779053633903}
2023-01-04 11:32:23,448 INFO:     Found new best model at epoch 64
2023-01-04 11:32:23,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:23,449 INFO:     Epoch: 65
2023-01-04 11:32:25,001 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.486111456155777, 'Total loss': 0.486111456155777} | train loss {'Reaction outcome loss': 0.2893366156753166, 'Total loss': 0.2893366156753166}
2023-01-04 11:32:25,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:25,002 INFO:     Epoch: 66
2023-01-04 11:32:26,492 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45767321487267815, 'Total loss': 0.45767321487267815} | train loss {'Reaction outcome loss': 0.28209404999410714, 'Total loss': 0.28209404999410714}
2023-01-04 11:32:26,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:26,493 INFO:     Epoch: 67
2023-01-04 11:32:28,066 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47179414629936217, 'Total loss': 0.47179414629936217} | train loss {'Reaction outcome loss': 0.2795708648614831, 'Total loss': 0.2795708648614831}
2023-01-04 11:32:28,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:28,066 INFO:     Epoch: 68
2023-01-04 11:32:29,618 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4792409638563792, 'Total loss': 0.4792409638563792} | train loss {'Reaction outcome loss': 0.2800114444958476, 'Total loss': 0.2800114444958476}
2023-01-04 11:32:29,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:29,618 INFO:     Epoch: 69
2023-01-04 11:32:31,178 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4626420875390371, 'Total loss': 0.4626420875390371} | train loss {'Reaction outcome loss': 0.2711442892504481, 'Total loss': 0.2711442892504481}
2023-01-04 11:32:31,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:31,179 INFO:     Epoch: 70
2023-01-04 11:32:32,777 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4523460268974304, 'Total loss': 0.4523460268974304} | train loss {'Reaction outcome loss': 0.2745293066342235, 'Total loss': 0.2745293066342235}
2023-01-04 11:32:32,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:32,778 INFO:     Epoch: 71
2023-01-04 11:32:34,383 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4929066856702169, 'Total loss': 0.4929066856702169} | train loss {'Reaction outcome loss': 0.2734244191821242, 'Total loss': 0.2734244191821242}
2023-01-04 11:32:34,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:34,383 INFO:     Epoch: 72
2023-01-04 11:32:35,890 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44336286584536233, 'Total loss': 0.44336286584536233} | train loss {'Reaction outcome loss': 0.2722564473639041, 'Total loss': 0.2722564473639041}
2023-01-04 11:32:35,890 INFO:     Found new best model at epoch 72
2023-01-04 11:32:35,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:35,891 INFO:     Epoch: 73
2023-01-04 11:32:37,503 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45476681490739185, 'Total loss': 0.45476681490739185} | train loss {'Reaction outcome loss': 0.27165675526246047, 'Total loss': 0.27165675526246047}
2023-01-04 11:32:37,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:37,504 INFO:     Epoch: 74
2023-01-04 11:32:39,116 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4962300876776377, 'Total loss': 0.4962300876776377} | train loss {'Reaction outcome loss': 0.2674746950064878, 'Total loss': 0.2674746950064878}
2023-01-04 11:32:39,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:39,116 INFO:     Epoch: 75
2023-01-04 11:32:40,740 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4693577448527018, 'Total loss': 0.4693577448527018} | train loss {'Reaction outcome loss': 0.26724894426681184, 'Total loss': 0.26724894426681184}
2023-01-04 11:32:40,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:40,740 INFO:     Epoch: 76
2023-01-04 11:32:42,323 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4910528540611267, 'Total loss': 0.4910528540611267} | train loss {'Reaction outcome loss': 0.27232886927250105, 'Total loss': 0.27232886927250105}
2023-01-04 11:32:42,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:42,324 INFO:     Epoch: 77
2023-01-04 11:32:43,895 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.478325096766154, 'Total loss': 0.478325096766154} | train loss {'Reaction outcome loss': 0.26913367004403266, 'Total loss': 0.26913367004403266}
2023-01-04 11:32:43,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:43,895 INFO:     Epoch: 78
2023-01-04 11:32:45,374 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46411983370780946, 'Total loss': 0.46411983370780946} | train loss {'Reaction outcome loss': 0.2616546383270851, 'Total loss': 0.2616546383270851}
2023-01-04 11:32:45,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:45,375 INFO:     Epoch: 79
2023-01-04 11:32:46,931 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44992490609486896, 'Total loss': 0.44992490609486896} | train loss {'Reaction outcome loss': 0.26406657433771824, 'Total loss': 0.26406657433771824}
2023-01-04 11:32:46,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:46,931 INFO:     Epoch: 80
2023-01-04 11:32:48,541 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46612576047579446, 'Total loss': 0.46612576047579446} | train loss {'Reaction outcome loss': 0.2619331175045216, 'Total loss': 0.2619331175045216}
2023-01-04 11:32:48,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:48,541 INFO:     Epoch: 81
2023-01-04 11:32:50,133 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4884573628505071, 'Total loss': 0.4884573628505071} | train loss {'Reaction outcome loss': 0.26256897675739976, 'Total loss': 0.26256897675739976}
2023-01-04 11:32:50,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:50,134 INFO:     Epoch: 82
2023-01-04 11:32:51,720 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46832414865493777, 'Total loss': 0.46832414865493777} | train loss {'Reaction outcome loss': 0.25897662794633663, 'Total loss': 0.25897662794633663}
2023-01-04 11:32:51,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:51,720 INFO:     Epoch: 83
2023-01-04 11:32:53,277 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4672424852848053, 'Total loss': 0.4672424852848053} | train loss {'Reaction outcome loss': 0.25897458837036685, 'Total loss': 0.25897458837036685}
2023-01-04 11:32:53,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:53,277 INFO:     Epoch: 84
2023-01-04 11:32:54,812 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47020933230717976, 'Total loss': 0.47020933230717976} | train loss {'Reaction outcome loss': 0.2597047587918056, 'Total loss': 0.2597047587918056}
2023-01-04 11:32:54,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:54,813 INFO:     Epoch: 85
2023-01-04 11:32:56,375 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4732942869265874, 'Total loss': 0.4732942869265874} | train loss {'Reaction outcome loss': 0.2584475112512653, 'Total loss': 0.2584475112512653}
2023-01-04 11:32:56,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:56,375 INFO:     Epoch: 86
2023-01-04 11:32:57,947 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47063523332277934, 'Total loss': 0.47063523332277934} | train loss {'Reaction outcome loss': 0.2555489958205939, 'Total loss': 0.2555489958205939}
2023-01-04 11:32:57,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:57,948 INFO:     Epoch: 87
2023-01-04 11:32:59,514 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46665190160274506, 'Total loss': 0.46665190160274506} | train loss {'Reaction outcome loss': 0.2551010328280183, 'Total loss': 0.2551010328280183}
2023-01-04 11:32:59,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:32:59,514 INFO:     Epoch: 88
2023-01-04 11:33:01,086 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47269682586193085, 'Total loss': 0.47269682586193085} | train loss {'Reaction outcome loss': 0.2502386301428407, 'Total loss': 0.2502386301428407}
2023-01-04 11:33:01,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:01,086 INFO:     Epoch: 89
2023-01-04 11:33:02,630 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4386536260445913, 'Total loss': 0.4386536260445913} | train loss {'Reaction outcome loss': 0.2540327603809344, 'Total loss': 0.2540327603809344}
2023-01-04 11:33:02,630 INFO:     Found new best model at epoch 89
2023-01-04 11:33:02,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:02,631 INFO:     Epoch: 90
2023-01-04 11:33:04,178 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46356369654337565, 'Total loss': 0.46356369654337565} | train loss {'Reaction outcome loss': 0.25177885989075177, 'Total loss': 0.25177885989075177}
2023-01-04 11:33:04,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:04,179 INFO:     Epoch: 91
2023-01-04 11:33:05,743 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.487349600593249, 'Total loss': 0.487349600593249} | train loss {'Reaction outcome loss': 0.25179646579009707, 'Total loss': 0.25179646579009707}
2023-01-04 11:33:05,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:05,743 INFO:     Epoch: 92
2023-01-04 11:33:07,309 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44263487259546913, 'Total loss': 0.44263487259546913} | train loss {'Reaction outcome loss': 0.24793449401746304, 'Total loss': 0.24793449401746304}
2023-01-04 11:33:07,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:07,310 INFO:     Epoch: 93
2023-01-04 11:33:08,898 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47627824743588765, 'Total loss': 0.47627824743588765} | train loss {'Reaction outcome loss': 0.245492944869148, 'Total loss': 0.245492944869148}
2023-01-04 11:33:08,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:08,898 INFO:     Epoch: 94
2023-01-04 11:33:10,467 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47618858913580575, 'Total loss': 0.47618858913580575} | train loss {'Reaction outcome loss': 0.24659850672160313, 'Total loss': 0.24659850672160313}
2023-01-04 11:33:10,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:10,468 INFO:     Epoch: 95
2023-01-04 11:33:11,982 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46765995224316914, 'Total loss': 0.46765995224316914} | train loss {'Reaction outcome loss': 0.24651860332478098, 'Total loss': 0.24651860332478098}
2023-01-04 11:33:11,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:11,982 INFO:     Epoch: 96
2023-01-04 11:33:13,532 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45667160451412203, 'Total loss': 0.45667160451412203} | train loss {'Reaction outcome loss': 0.24166499913393796, 'Total loss': 0.24166499913393796}
2023-01-04 11:33:13,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:13,532 INFO:     Epoch: 97
2023-01-04 11:33:15,087 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4583389262358348, 'Total loss': 0.4583389262358348} | train loss {'Reaction outcome loss': 0.24405255706319007, 'Total loss': 0.24405255706319007}
2023-01-04 11:33:15,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:15,087 INFO:     Epoch: 98
2023-01-04 11:33:16,659 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4630474259455999, 'Total loss': 0.4630474259455999} | train loss {'Reaction outcome loss': 0.2417849247981777, 'Total loss': 0.2417849247981777}
2023-01-04 11:33:16,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:16,660 INFO:     Epoch: 99
2023-01-04 11:33:18,259 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5266315887371699, 'Total loss': 0.5266315887371699} | train loss {'Reaction outcome loss': 0.24197826160616054, 'Total loss': 0.24197826160616054}
2023-01-04 11:33:18,259 INFO:     Best model found after epoch 90 of 100.
2023-01-04 11:33:18,259 INFO:   Done with stage: TRAINING
2023-01-04 11:33:18,259 INFO:   Starting stage: EVALUATION
2023-01-04 11:33:18,398 INFO:   Done with stage: EVALUATION
2023-01-04 11:33:18,399 INFO:   Leaving out SEQ value Fold_7
2023-01-04 11:33:18,411 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 11:33:18,411 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:33:19,067 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:33:19,067 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:33:19,136 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:33:19,136 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:33:19,136 INFO:     No hyperparam tuning for this model
2023-01-04 11:33:19,136 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:33:19,136 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:33:19,137 INFO:     None feature selector for col prot
2023-01-04 11:33:19,137 INFO:     None feature selector for col prot
2023-01-04 11:33:19,137 INFO:     None feature selector for col prot
2023-01-04 11:33:19,137 INFO:     None feature selector for col chem
2023-01-04 11:33:19,138 INFO:     None feature selector for col chem
2023-01-04 11:33:19,138 INFO:     None feature selector for col chem
2023-01-04 11:33:19,138 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:33:19,138 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:33:19,139 INFO:     Number of params in model 70111
2023-01-04 11:33:19,142 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:33:19,142 INFO:   Starting stage: TRAINING
2023-01-04 11:33:19,185 INFO:     Val loss before train {'Reaction outcome loss': 0.9783851583798726, 'Total loss': 0.9783851583798726}
2023-01-04 11:33:19,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:19,185 INFO:     Epoch: 0
2023-01-04 11:33:20,721 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7239067395528157, 'Total loss': 0.7239067395528157} | train loss {'Reaction outcome loss': 0.8384827542175886, 'Total loss': 0.8384827542175886}
2023-01-04 11:33:20,721 INFO:     Found new best model at epoch 0
2023-01-04 11:33:20,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:20,722 INFO:     Epoch: 1
2023-01-04 11:33:22,299 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.627288963397344, 'Total loss': 0.627288963397344} | train loss {'Reaction outcome loss': 0.6607291552671887, 'Total loss': 0.6607291552671887}
2023-01-04 11:33:22,299 INFO:     Found new best model at epoch 1
2023-01-04 11:33:22,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:22,300 INFO:     Epoch: 2
2023-01-04 11:33:23,889 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5963665246963501, 'Total loss': 0.5963665246963501} | train loss {'Reaction outcome loss': 0.5683511618242367, 'Total loss': 0.5683511618242367}
2023-01-04 11:33:23,889 INFO:     Found new best model at epoch 2
2023-01-04 11:33:23,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:23,890 INFO:     Epoch: 3
2023-01-04 11:33:25,470 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5289985756079356, 'Total loss': 0.5289985756079356} | train loss {'Reaction outcome loss': 0.536249489345275, 'Total loss': 0.536249489345275}
2023-01-04 11:33:25,470 INFO:     Found new best model at epoch 3
2023-01-04 11:33:25,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:25,471 INFO:     Epoch: 4
2023-01-04 11:33:27,047 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4977022081613541, 'Total loss': 0.4977022081613541} | train loss {'Reaction outcome loss': 0.510198942214143, 'Total loss': 0.510198942214143}
2023-01-04 11:33:27,048 INFO:     Found new best model at epoch 4
2023-01-04 11:33:27,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:27,048 INFO:     Epoch: 5
2023-01-04 11:33:28,630 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5222706000010172, 'Total loss': 0.5222706000010172} | train loss {'Reaction outcome loss': 0.5020199759127001, 'Total loss': 0.5020199759127001}
2023-01-04 11:33:28,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:28,630 INFO:     Epoch: 6
2023-01-04 11:33:30,160 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5014819145202637, 'Total loss': 0.5014819145202637} | train loss {'Reaction outcome loss': 0.48735319519086007, 'Total loss': 0.48735319519086007}
2023-01-04 11:33:30,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:30,160 INFO:     Epoch: 7
2023-01-04 11:33:31,767 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4899237742026647, 'Total loss': 0.4899237742026647} | train loss {'Reaction outcome loss': 0.47885552220826544, 'Total loss': 0.47885552220826544}
2023-01-04 11:33:31,767 INFO:     Found new best model at epoch 7
2023-01-04 11:33:31,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:31,768 INFO:     Epoch: 8
2023-01-04 11:33:33,356 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4964716017246246, 'Total loss': 0.4964716017246246} | train loss {'Reaction outcome loss': 0.4719233354452715, 'Total loss': 0.4719233354452715}
2023-01-04 11:33:33,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:33,357 INFO:     Epoch: 9
2023-01-04 11:33:34,949 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4948580086231232, 'Total loss': 0.4948580086231232} | train loss {'Reaction outcome loss': 0.46395079361187425, 'Total loss': 0.46395079361187425}
2023-01-04 11:33:34,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:34,949 INFO:     Epoch: 10
2023-01-04 11:33:36,533 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4824899812539419, 'Total loss': 0.4824899812539419} | train loss {'Reaction outcome loss': 0.46154584482796357, 'Total loss': 0.46154584482796357}
2023-01-04 11:33:36,533 INFO:     Found new best model at epoch 10
2023-01-04 11:33:36,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:36,534 INFO:     Epoch: 11
2023-01-04 11:33:38,101 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4848536640405655, 'Total loss': 0.4848536640405655} | train loss {'Reaction outcome loss': 0.4537383235372361, 'Total loss': 0.4537383235372361}
2023-01-04 11:33:38,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:38,101 INFO:     Epoch: 12
2023-01-04 11:33:39,614 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47022693753242495, 'Total loss': 0.47022693753242495} | train loss {'Reaction outcome loss': 0.45051689768741277, 'Total loss': 0.45051689768741277}
2023-01-04 11:33:39,614 INFO:     Found new best model at epoch 12
2023-01-04 11:33:39,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:39,615 INFO:     Epoch: 13
2023-01-04 11:33:41,215 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4807625194390615, 'Total loss': 0.4807625194390615} | train loss {'Reaction outcome loss': 0.4514523915381638, 'Total loss': 0.4514523915381638}
2023-01-04 11:33:41,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:41,215 INFO:     Epoch: 14
2023-01-04 11:33:42,824 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4516055847207705, 'Total loss': 0.4516055847207705} | train loss {'Reaction outcome loss': 0.4466927705151079, 'Total loss': 0.4466927705151079}
2023-01-04 11:33:42,824 INFO:     Found new best model at epoch 14
2023-01-04 11:33:42,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:42,825 INFO:     Epoch: 15
2023-01-04 11:33:44,424 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44498701492945353, 'Total loss': 0.44498701492945353} | train loss {'Reaction outcome loss': 0.43591005745132044, 'Total loss': 0.43591005745132044}
2023-01-04 11:33:44,424 INFO:     Found new best model at epoch 15
2023-01-04 11:33:44,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:44,425 INFO:     Epoch: 16
2023-01-04 11:33:46,004 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47061323523521426, 'Total loss': 0.47061323523521426} | train loss {'Reaction outcome loss': 0.43606410893722564, 'Total loss': 0.43606410893722564}
2023-01-04 11:33:46,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:46,004 INFO:     Epoch: 17
2023-01-04 11:33:47,530 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4577948068579038, 'Total loss': 0.4577948068579038} | train loss {'Reaction outcome loss': 0.4329855104215739, 'Total loss': 0.4329855104215739}
2023-01-04 11:33:47,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:47,531 INFO:     Epoch: 18
2023-01-04 11:33:49,062 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45574456254641216, 'Total loss': 0.45574456254641216} | train loss {'Reaction outcome loss': 0.4265709938447828, 'Total loss': 0.4265709938447828}
2023-01-04 11:33:49,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:49,062 INFO:     Epoch: 19
2023-01-04 11:33:50,647 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47529802322387693, 'Total loss': 0.47529802322387693} | train loss {'Reaction outcome loss': 0.42383848630994664, 'Total loss': 0.42383848630994664}
2023-01-04 11:33:50,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:50,648 INFO:     Epoch: 20
2023-01-04 11:33:52,198 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4618676205476125, 'Total loss': 0.4618676205476125} | train loss {'Reaction outcome loss': 0.4208263553652092, 'Total loss': 0.4208263553652092}
2023-01-04 11:33:52,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:52,199 INFO:     Epoch: 21
2023-01-04 11:33:53,768 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47079064945379895, 'Total loss': 0.47079064945379895} | train loss {'Reaction outcome loss': 0.4151855753432112, 'Total loss': 0.4151855753432112}
2023-01-04 11:33:53,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:53,768 INFO:     Epoch: 22
2023-01-04 11:33:55,344 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47397114237149557, 'Total loss': 0.47397114237149557} | train loss {'Reaction outcome loss': 0.41042898113869586, 'Total loss': 0.41042898113869586}
2023-01-04 11:33:55,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:55,344 INFO:     Epoch: 23
2023-01-04 11:33:56,864 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4505356659491857, 'Total loss': 0.4505356659491857} | train loss {'Reaction outcome loss': 0.4081047997685546, 'Total loss': 0.4081047997685546}
2023-01-04 11:33:56,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:56,864 INFO:     Epoch: 24
2023-01-04 11:33:58,394 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4714882959922155, 'Total loss': 0.4714882959922155} | train loss {'Reaction outcome loss': 0.4018533519781884, 'Total loss': 0.4018533519781884}
2023-01-04 11:33:58,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:58,394 INFO:     Epoch: 25
2023-01-04 11:33:59,965 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4273021231094996, 'Total loss': 0.4273021231094996} | train loss {'Reaction outcome loss': 0.40312319714239786, 'Total loss': 0.40312319714239786}
2023-01-04 11:33:59,965 INFO:     Found new best model at epoch 25
2023-01-04 11:33:59,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:33:59,966 INFO:     Epoch: 26
2023-01-04 11:34:01,535 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45565708974997204, 'Total loss': 0.45565708974997204} | train loss {'Reaction outcome loss': 0.3959481671506317, 'Total loss': 0.3959481671506317}
2023-01-04 11:34:01,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:01,535 INFO:     Epoch: 27
2023-01-04 11:34:03,096 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44128222366174064, 'Total loss': 0.44128222366174064} | train loss {'Reaction outcome loss': 0.39085265789651696, 'Total loss': 0.39085265789651696}
2023-01-04 11:34:03,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:03,096 INFO:     Epoch: 28
2023-01-04 11:34:04,664 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45899732907613117, 'Total loss': 0.45899732907613117} | train loss {'Reaction outcome loss': 0.3873069658068543, 'Total loss': 0.3873069658068543}
2023-01-04 11:34:04,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:04,665 INFO:     Epoch: 29
2023-01-04 11:34:06,158 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4448815027872721, 'Total loss': 0.4448815027872721} | train loss {'Reaction outcome loss': 0.3845652526089861, 'Total loss': 0.3845652526089861}
2023-01-04 11:34:06,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:06,158 INFO:     Epoch: 30
2023-01-04 11:34:07,725 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4147164354721705, 'Total loss': 0.4147164354721705} | train loss {'Reaction outcome loss': 0.38329758712961354, 'Total loss': 0.38329758712961354}
2023-01-04 11:34:07,725 INFO:     Found new best model at epoch 30
2023-01-04 11:34:07,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:07,726 INFO:     Epoch: 31
2023-01-04 11:34:09,294 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4211396316687266, 'Total loss': 0.4211396316687266} | train loss {'Reaction outcome loss': 0.3706952135754406, 'Total loss': 0.3706952135754406}
2023-01-04 11:34:09,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:09,295 INFO:     Epoch: 32
2023-01-04 11:34:10,851 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44503131409486135, 'Total loss': 0.44503131409486135} | train loss {'Reaction outcome loss': 0.3748771397645723, 'Total loss': 0.3748771397645723}
2023-01-04 11:34:10,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:10,851 INFO:     Epoch: 33
2023-01-04 11:34:12,413 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4039645870526632, 'Total loss': 0.4039645870526632} | train loss {'Reaction outcome loss': 0.3722506078625844, 'Total loss': 0.3722506078625844}
2023-01-04 11:34:12,413 INFO:     Found new best model at epoch 33
2023-01-04 11:34:12,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:12,414 INFO:     Epoch: 34
2023-01-04 11:34:13,969 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42576864957809446, 'Total loss': 0.42576864957809446} | train loss {'Reaction outcome loss': 0.36778378634569014, 'Total loss': 0.36778378634569014}
2023-01-04 11:34:13,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:13,970 INFO:     Epoch: 35
2023-01-04 11:34:15,474 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42039998173713683, 'Total loss': 0.42039998173713683} | train loss {'Reaction outcome loss': 0.36480032499301307, 'Total loss': 0.36480032499301307}
2023-01-04 11:34:15,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:15,474 INFO:     Epoch: 36
2023-01-04 11:34:17,041 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4203677852948507, 'Total loss': 0.4203677852948507} | train loss {'Reaction outcome loss': 0.3607376947837616, 'Total loss': 0.3607376947837616}
2023-01-04 11:34:17,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:17,041 INFO:     Epoch: 37
2023-01-04 11:34:18,669 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41019110282262167, 'Total loss': 0.41019110282262167} | train loss {'Reaction outcome loss': 0.3555184831365351, 'Total loss': 0.3555184831365351}
2023-01-04 11:34:18,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:18,670 INFO:     Epoch: 38
2023-01-04 11:34:20,275 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39566913346449534, 'Total loss': 0.39566913346449534} | train loss {'Reaction outcome loss': 0.35599376930979615, 'Total loss': 0.35599376930979615}
2023-01-04 11:34:20,275 INFO:     Found new best model at epoch 38
2023-01-04 11:34:20,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:20,276 INFO:     Epoch: 39
2023-01-04 11:34:21,867 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39893255233764646, 'Total loss': 0.39893255233764646} | train loss {'Reaction outcome loss': 0.34923949851133335, 'Total loss': 0.34923949851133335}
2023-01-04 11:34:21,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:21,868 INFO:     Epoch: 40
2023-01-04 11:34:23,465 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40622586409250894, 'Total loss': 0.40622586409250894} | train loss {'Reaction outcome loss': 0.3492727299836138, 'Total loss': 0.3492727299836138}
2023-01-04 11:34:23,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:23,466 INFO:     Epoch: 41
2023-01-04 11:34:25,013 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4022975971301397, 'Total loss': 0.4022975971301397} | train loss {'Reaction outcome loss': 0.34384796284273644, 'Total loss': 0.34384796284273644}
2023-01-04 11:34:25,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:25,013 INFO:     Epoch: 42
2023-01-04 11:34:26,613 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40672952433427173, 'Total loss': 0.40672952433427173} | train loss {'Reaction outcome loss': 0.34350147032404205, 'Total loss': 0.34350147032404205}
2023-01-04 11:34:26,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:26,613 INFO:     Epoch: 43
2023-01-04 11:34:28,199 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41207506954669954, 'Total loss': 0.41207506954669954} | train loss {'Reaction outcome loss': 0.33932033050738086, 'Total loss': 0.33932033050738086}
2023-01-04 11:34:28,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:28,199 INFO:     Epoch: 44
2023-01-04 11:34:29,797 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3963109602530797, 'Total loss': 0.3963109602530797} | train loss {'Reaction outcome loss': 0.33887256652331954, 'Total loss': 0.33887256652331954}
2023-01-04 11:34:29,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:29,798 INFO:     Epoch: 45
2023-01-04 11:34:31,376 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4066994229952494, 'Total loss': 0.4066994229952494} | train loss {'Reaction outcome loss': 0.33511360710493493, 'Total loss': 0.33511360710493493}
2023-01-04 11:34:31,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:31,376 INFO:     Epoch: 46
2023-01-04 11:34:32,936 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3929241766532262, 'Total loss': 0.3929241766532262} | train loss {'Reaction outcome loss': 0.33499114602696595, 'Total loss': 0.33499114602696595}
2023-01-04 11:34:32,936 INFO:     Found new best model at epoch 46
2023-01-04 11:34:32,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:32,937 INFO:     Epoch: 47
2023-01-04 11:34:34,502 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41195668578147887, 'Total loss': 0.41195668578147887} | train loss {'Reaction outcome loss': 0.327262787504747, 'Total loss': 0.327262787504747}
2023-01-04 11:34:34,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:34,503 INFO:     Epoch: 48
2023-01-04 11:34:36,108 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38571805159250894, 'Total loss': 0.38571805159250894} | train loss {'Reaction outcome loss': 0.32640788454011027, 'Total loss': 0.32640788454011027}
2023-01-04 11:34:36,108 INFO:     Found new best model at epoch 48
2023-01-04 11:34:36,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:36,108 INFO:     Epoch: 49
2023-01-04 11:34:37,703 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4085080395142237, 'Total loss': 0.4085080395142237} | train loss {'Reaction outcome loss': 0.3262520506440087, 'Total loss': 0.3262520506440087}
2023-01-04 11:34:37,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:37,704 INFO:     Epoch: 50
2023-01-04 11:34:39,317 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3878195951382319, 'Total loss': 0.3878195951382319} | train loss {'Reaction outcome loss': 0.3225692347875571, 'Total loss': 0.3225692347875571}
2023-01-04 11:34:39,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:39,317 INFO:     Epoch: 51
2023-01-04 11:34:40,942 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.380015504360199, 'Total loss': 0.380015504360199} | train loss {'Reaction outcome loss': 0.3198507961006801, 'Total loss': 0.3198507961006801}
2023-01-04 11:34:40,943 INFO:     Found new best model at epoch 51
2023-01-04 11:34:40,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:40,944 INFO:     Epoch: 52
2023-01-04 11:34:42,485 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40363860328992207, 'Total loss': 0.40363860328992207} | train loss {'Reaction outcome loss': 0.3206976699484815, 'Total loss': 0.3206976699484815}
2023-01-04 11:34:42,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:42,485 INFO:     Epoch: 53
2023-01-04 11:34:44,098 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.367232612768809, 'Total loss': 0.367232612768809} | train loss {'Reaction outcome loss': 0.3196985741895674, 'Total loss': 0.3196985741895674}
2023-01-04 11:34:44,098 INFO:     Found new best model at epoch 53
2023-01-04 11:34:44,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:44,099 INFO:     Epoch: 54
2023-01-04 11:34:45,706 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3888380030790965, 'Total loss': 0.3888380030790965} | train loss {'Reaction outcome loss': 0.3161608368319725, 'Total loss': 0.3161608368319725}
2023-01-04 11:34:45,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:45,707 INFO:     Epoch: 55
2023-01-04 11:34:47,300 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3855000724395116, 'Total loss': 0.3855000724395116} | train loss {'Reaction outcome loss': 0.3131503277468337, 'Total loss': 0.3131503277468337}
2023-01-04 11:34:47,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:47,301 INFO:     Epoch: 56
2023-01-04 11:34:48,927 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39409548938274386, 'Total loss': 0.39409548938274386} | train loss {'Reaction outcome loss': 0.3050270266830921, 'Total loss': 0.3050270266830921}
2023-01-04 11:34:48,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:48,927 INFO:     Epoch: 57
2023-01-04 11:34:50,558 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39866338471571605, 'Total loss': 0.39866338471571605} | train loss {'Reaction outcome loss': 0.3138521362889545, 'Total loss': 0.3138521362889545}
2023-01-04 11:34:50,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:50,559 INFO:     Epoch: 58
2023-01-04 11:34:52,103 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3936196188131968, 'Total loss': 0.3936196188131968} | train loss {'Reaction outcome loss': 0.30913111777297, 'Total loss': 0.30913111777297}
2023-01-04 11:34:52,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:52,104 INFO:     Epoch: 59
2023-01-04 11:34:53,732 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39836167097091674, 'Total loss': 0.39836167097091674} | train loss {'Reaction outcome loss': 0.31039598984946415, 'Total loss': 0.31039598984946415}
2023-01-04 11:34:53,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:53,732 INFO:     Epoch: 60
2023-01-04 11:34:55,373 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.396370064218839, 'Total loss': 0.396370064218839} | train loss {'Reaction outcome loss': 0.3020959198474884, 'Total loss': 0.3020959198474884}
2023-01-04 11:34:55,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:55,373 INFO:     Epoch: 61
2023-01-04 11:34:57,004 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3964479704697927, 'Total loss': 0.3964479704697927} | train loss {'Reaction outcome loss': 0.30262414667257764, 'Total loss': 0.30262414667257764}
2023-01-04 11:34:57,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:57,004 INFO:     Epoch: 62
2023-01-04 11:34:58,638 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3987813433011373, 'Total loss': 0.3987813433011373} | train loss {'Reaction outcome loss': 0.29640934524876117, 'Total loss': 0.29640934524876117}
2023-01-04 11:34:58,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:34:58,639 INFO:     Epoch: 63
2023-01-04 11:35:00,242 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3851892878611883, 'Total loss': 0.3851892878611883} | train loss {'Reaction outcome loss': 0.2998519129782162, 'Total loss': 0.2998519129782162}
2023-01-04 11:35:00,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:00,243 INFO:     Epoch: 64
2023-01-04 11:35:01,834 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40519078572591144, 'Total loss': 0.40519078572591144} | train loss {'Reaction outcome loss': 0.2940829818806063, 'Total loss': 0.2940829818806063}
2023-01-04 11:35:01,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:01,834 INFO:     Epoch: 65
2023-01-04 11:35:03,456 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38140929440657295, 'Total loss': 0.38140929440657295} | train loss {'Reaction outcome loss': 0.2939179728500249, 'Total loss': 0.2939179728500249}
2023-01-04 11:35:03,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:03,456 INFO:     Epoch: 66
2023-01-04 11:35:05,090 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37433332403500874, 'Total loss': 0.37433332403500874} | train loss {'Reaction outcome loss': 0.29470670056472187, 'Total loss': 0.29470670056472187}
2023-01-04 11:35:05,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:05,090 INFO:     Epoch: 67
2023-01-04 11:35:06,717 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3994753658771515, 'Total loss': 0.3994753658771515} | train loss {'Reaction outcome loss': 0.2935809057595928, 'Total loss': 0.2935809057595928}
2023-01-04 11:35:06,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:06,718 INFO:     Epoch: 68
2023-01-04 11:35:08,341 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3772084166606267, 'Total loss': 0.3772084166606267} | train loss {'Reaction outcome loss': 0.290120293624995, 'Total loss': 0.290120293624995}
2023-01-04 11:35:08,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:08,342 INFO:     Epoch: 69
2023-01-04 11:35:09,929 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.35575848519802095, 'Total loss': 0.35575848519802095} | train loss {'Reaction outcome loss': 0.28674595909267125, 'Total loss': 0.28674595909267125}
2023-01-04 11:35:09,929 INFO:     Found new best model at epoch 69
2023-01-04 11:35:09,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:09,931 INFO:     Epoch: 70
2023-01-04 11:35:11,514 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3680023610591888, 'Total loss': 0.3680023610591888} | train loss {'Reaction outcome loss': 0.2888709879093652, 'Total loss': 0.2888709879093652}
2023-01-04 11:35:11,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:11,514 INFO:     Epoch: 71
2023-01-04 11:35:13,141 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4020435114701589, 'Total loss': 0.4020435114701589} | train loss {'Reaction outcome loss': 0.2814575002431224, 'Total loss': 0.2814575002431224}
2023-01-04 11:35:13,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:13,142 INFO:     Epoch: 72
2023-01-04 11:35:14,768 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3788678248723348, 'Total loss': 0.3788678248723348} | train loss {'Reaction outcome loss': 0.28835966042663214, 'Total loss': 0.28835966042663214}
2023-01-04 11:35:14,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:14,769 INFO:     Epoch: 73
2023-01-04 11:35:16,411 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3917862912019094, 'Total loss': 0.3917862912019094} | train loss {'Reaction outcome loss': 0.28422357564260814, 'Total loss': 0.28422357564260814}
2023-01-04 11:35:16,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:16,412 INFO:     Epoch: 74
2023-01-04 11:35:18,043 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37233924070994057, 'Total loss': 0.37233924070994057} | train loss {'Reaction outcome loss': 0.27736599044033766, 'Total loss': 0.27736599044033766}
2023-01-04 11:35:18,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:18,044 INFO:     Epoch: 75
2023-01-04 11:35:19,647 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3648970862229665, 'Total loss': 0.3648970862229665} | train loss {'Reaction outcome loss': 0.27844839007845856, 'Total loss': 0.27844839007845856}
2023-01-04 11:35:19,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:19,648 INFO:     Epoch: 76
2023-01-04 11:35:21,246 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3904594217737516, 'Total loss': 0.3904594217737516} | train loss {'Reaction outcome loss': 0.28022584975411313, 'Total loss': 0.28022584975411313}
2023-01-04 11:35:21,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:21,246 INFO:     Epoch: 77
2023-01-04 11:35:22,872 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3859580159187317, 'Total loss': 0.3859580159187317} | train loss {'Reaction outcome loss': 0.2825075819927002, 'Total loss': 0.2825075819927002}
2023-01-04 11:35:22,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:22,873 INFO:     Epoch: 78
2023-01-04 11:35:24,509 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3929219077030818, 'Total loss': 0.3929219077030818} | train loss {'Reaction outcome loss': 0.2784293650478017, 'Total loss': 0.2784293650478017}
2023-01-04 11:35:24,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:24,509 INFO:     Epoch: 79
2023-01-04 11:35:26,140 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3885142385959625, 'Total loss': 0.3885142385959625} | train loss {'Reaction outcome loss': 0.2764933593974647, 'Total loss': 0.2764933593974647}
2023-01-04 11:35:26,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:26,141 INFO:     Epoch: 80
2023-01-04 11:35:27,732 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38353128880262377, 'Total loss': 0.38353128880262377} | train loss {'Reaction outcome loss': 0.26880341281421777, 'Total loss': 0.26880341281421777}
2023-01-04 11:35:27,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:27,732 INFO:     Epoch: 81
2023-01-04 11:35:29,362 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3756608635187149, 'Total loss': 0.3756608635187149} | train loss {'Reaction outcome loss': 0.2698016001402471, 'Total loss': 0.2698016001402471}
2023-01-04 11:35:29,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:29,362 INFO:     Epoch: 82
2023-01-04 11:35:30,956 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3857667565345764, 'Total loss': 0.3857667565345764} | train loss {'Reaction outcome loss': 0.27341162547845704, 'Total loss': 0.27341162547845704}
2023-01-04 11:35:30,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:30,956 INFO:     Epoch: 83
2023-01-04 11:35:32,584 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38375851809978484, 'Total loss': 0.38375851809978484} | train loss {'Reaction outcome loss': 0.2694422067260699, 'Total loss': 0.2694422067260699}
2023-01-04 11:35:32,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:32,585 INFO:     Epoch: 84
2023-01-04 11:35:34,200 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37541973193486533, 'Total loss': 0.37541973193486533} | train loss {'Reaction outcome loss': 0.2654198128797302, 'Total loss': 0.2654198128797302}
2023-01-04 11:35:34,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:34,201 INFO:     Epoch: 85
2023-01-04 11:35:35,785 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3869090894858042, 'Total loss': 0.3869090894858042} | train loss {'Reaction outcome loss': 0.2722183433411784, 'Total loss': 0.2722183433411784}
2023-01-04 11:35:35,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:35,786 INFO:     Epoch: 86
2023-01-04 11:35:37,312 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.349246450761954, 'Total loss': 0.349246450761954} | train loss {'Reaction outcome loss': 0.2654929680729601, 'Total loss': 0.2654929680729601}
2023-01-04 11:35:37,312 INFO:     Found new best model at epoch 86
2023-01-04 11:35:37,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:37,313 INFO:     Epoch: 87
2023-01-04 11:35:38,871 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3542967692017555, 'Total loss': 0.3542967692017555} | train loss {'Reaction outcome loss': 0.26104587169922217, 'Total loss': 0.26104587169922217}
2023-01-04 11:35:38,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:38,871 INFO:     Epoch: 88
2023-01-04 11:35:40,386 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3917615423599879, 'Total loss': 0.3917615423599879} | train loss {'Reaction outcome loss': 0.2662192885679889, 'Total loss': 0.2662192885679889}
2023-01-04 11:35:40,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:40,386 INFO:     Epoch: 89
2023-01-04 11:35:41,963 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.36568101197481157, 'Total loss': 0.36568101197481157} | train loss {'Reaction outcome loss': 0.2626744664210275, 'Total loss': 0.2626744664210275}
2023-01-04 11:35:41,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:41,963 INFO:     Epoch: 90
2023-01-04 11:35:43,539 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3972182671229045, 'Total loss': 0.3972182671229045} | train loss {'Reaction outcome loss': 0.2561072076701085, 'Total loss': 0.2561072076701085}
2023-01-04 11:35:43,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:43,539 INFO:     Epoch: 91
2023-01-04 11:35:45,110 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3853405555089315, 'Total loss': 0.3853405555089315} | train loss {'Reaction outcome loss': 0.2625003131341848, 'Total loss': 0.2625003131341848}
2023-01-04 11:35:45,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:45,111 INFO:     Epoch: 92
2023-01-04 11:35:46,625 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3758140375216802, 'Total loss': 0.3758140375216802} | train loss {'Reaction outcome loss': 0.2594757202057847, 'Total loss': 0.2594757202057847}
2023-01-04 11:35:46,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:46,625 INFO:     Epoch: 93
2023-01-04 11:35:48,173 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3491174379984538, 'Total loss': 0.3491174379984538} | train loss {'Reaction outcome loss': 0.2606784905633126, 'Total loss': 0.2606784905633126}
2023-01-04 11:35:48,173 INFO:     Found new best model at epoch 93
2023-01-04 11:35:48,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:48,174 INFO:     Epoch: 94
2023-01-04 11:35:49,717 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3582306464513143, 'Total loss': 0.3582306464513143} | train loss {'Reaction outcome loss': 0.2633348511874891, 'Total loss': 0.2633348511874891}
2023-01-04 11:35:49,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:49,717 INFO:     Epoch: 95
2023-01-04 11:35:51,281 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3453580876191457, 'Total loss': 0.3453580876191457} | train loss {'Reaction outcome loss': 0.2552629847361938, 'Total loss': 0.2552629847361938}
2023-01-04 11:35:51,282 INFO:     Found new best model at epoch 95
2023-01-04 11:35:51,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:51,282 INFO:     Epoch: 96
2023-01-04 11:35:52,836 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.359241750339667, 'Total loss': 0.359241750339667} | train loss {'Reaction outcome loss': 0.2547891020828636, 'Total loss': 0.2547891020828636}
2023-01-04 11:35:52,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:52,836 INFO:     Epoch: 97
2023-01-04 11:35:54,372 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3637014329433441, 'Total loss': 0.3637014329433441} | train loss {'Reaction outcome loss': 0.2580047909587299, 'Total loss': 0.2580047909587299}
2023-01-04 11:35:54,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:54,372 INFO:     Epoch: 98
2023-01-04 11:35:55,918 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3914662440617879, 'Total loss': 0.3914662440617879} | train loss {'Reaction outcome loss': 0.26018650837861246, 'Total loss': 0.26018650837861246}
2023-01-04 11:35:55,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:55,918 INFO:     Epoch: 99
2023-01-04 11:35:57,441 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3724449227253596, 'Total loss': 0.3724449227253596} | train loss {'Reaction outcome loss': 0.2536700944204408, 'Total loss': 0.2536700944204408}
2023-01-04 11:35:57,442 INFO:     Best model found after epoch 96 of 100.
2023-01-04 11:35:57,442 INFO:   Done with stage: TRAINING
2023-01-04 11:35:57,442 INFO:   Starting stage: EVALUATION
2023-01-04 11:35:57,565 INFO:   Done with stage: EVALUATION
2023-01-04 11:35:57,565 INFO:   Leaving out SEQ value Fold_8
2023-01-04 11:35:57,577 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 11:35:57,577 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:35:58,223 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:35:58,223 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:35:58,291 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:35:58,292 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:35:58,292 INFO:     No hyperparam tuning for this model
2023-01-04 11:35:58,292 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:35:58,292 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:35:58,292 INFO:     None feature selector for col prot
2023-01-04 11:35:58,293 INFO:     None feature selector for col prot
2023-01-04 11:35:58,293 INFO:     None feature selector for col prot
2023-01-04 11:35:58,293 INFO:     None feature selector for col chem
2023-01-04 11:35:58,293 INFO:     None feature selector for col chem
2023-01-04 11:35:58,293 INFO:     None feature selector for col chem
2023-01-04 11:35:58,293 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:35:58,294 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:35:58,294 INFO:     Number of params in model 70111
2023-01-04 11:35:58,298 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:35:58,298 INFO:   Starting stage: TRAINING
2023-01-04 11:35:58,341 INFO:     Val loss before train {'Reaction outcome loss': 1.1040959358215332, 'Total loss': 1.1040959358215332}
2023-01-04 11:35:58,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:58,341 INFO:     Epoch: 0
2023-01-04 11:35:59,905 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7758769472440084, 'Total loss': 0.7758769472440084} | train loss {'Reaction outcome loss': 0.8269438409664924, 'Total loss': 0.8269438409664924}
2023-01-04 11:35:59,905 INFO:     Found new best model at epoch 0
2023-01-04 11:35:59,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:35:59,906 INFO:     Epoch: 1
2023-01-04 11:36:01,459 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6249424338340759, 'Total loss': 0.6249424338340759} | train loss {'Reaction outcome loss': 0.6561270821822699, 'Total loss': 0.6561270821822699}
2023-01-04 11:36:01,459 INFO:     Found new best model at epoch 1
2023-01-04 11:36:01,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:01,459 INFO:     Epoch: 2
2023-01-04 11:36:02,993 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5303625583648681, 'Total loss': 0.5303625583648681} | train loss {'Reaction outcome loss': 0.5903055810410044, 'Total loss': 0.5903055810410044}
2023-01-04 11:36:02,993 INFO:     Found new best model at epoch 2
2023-01-04 11:36:02,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:02,994 INFO:     Epoch: 3
2023-01-04 11:36:04,509 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5202006200949351, 'Total loss': 0.5202006200949351} | train loss {'Reaction outcome loss': 0.5486027797063192, 'Total loss': 0.5486027797063192}
2023-01-04 11:36:04,509 INFO:     Found new best model at epoch 3
2023-01-04 11:36:04,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:04,510 INFO:     Epoch: 4
2023-01-04 11:36:06,023 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5479922195275625, 'Total loss': 0.5479922195275625} | train loss {'Reaction outcome loss': 0.5191360582476077, 'Total loss': 0.5191360582476077}
2023-01-04 11:36:06,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:06,023 INFO:     Epoch: 5
2023-01-04 11:36:07,584 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5303316394488017, 'Total loss': 0.5303316394488017} | train loss {'Reaction outcome loss': 0.5157249051591625, 'Total loss': 0.5157249051591625}
2023-01-04 11:36:07,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:07,584 INFO:     Epoch: 6
2023-01-04 11:36:09,137 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4957603911558787, 'Total loss': 0.4957603911558787} | train loss {'Reaction outcome loss': 0.5002715544964093, 'Total loss': 0.5002715544964093}
2023-01-04 11:36:09,137 INFO:     Found new best model at epoch 6
2023-01-04 11:36:09,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:09,138 INFO:     Epoch: 7
2023-01-04 11:36:10,679 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49429439902305605, 'Total loss': 0.49429439902305605} | train loss {'Reaction outcome loss': 0.48601186196321866, 'Total loss': 0.48601186196321866}
2023-01-04 11:36:10,680 INFO:     Found new best model at epoch 7
2023-01-04 11:36:10,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:10,680 INFO:     Epoch: 8
2023-01-04 11:36:12,194 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4805741528669993, 'Total loss': 0.4805741528669993} | train loss {'Reaction outcome loss': 0.469617673459942, 'Total loss': 0.469617673459942}
2023-01-04 11:36:12,195 INFO:     Found new best model at epoch 8
2023-01-04 11:36:12,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:12,195 INFO:     Epoch: 9
2023-01-04 11:36:13,737 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4988442381223043, 'Total loss': 0.4988442381223043} | train loss {'Reaction outcome loss': 0.46660641561712785, 'Total loss': 0.46660641561712785}
2023-01-04 11:36:13,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:13,737 INFO:     Epoch: 10
2023-01-04 11:36:15,249 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4690693785746892, 'Total loss': 0.4690693785746892} | train loss {'Reaction outcome loss': 0.462644060668738, 'Total loss': 0.462644060668738}
2023-01-04 11:36:15,249 INFO:     Found new best model at epoch 10
2023-01-04 11:36:15,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:15,250 INFO:     Epoch: 11
2023-01-04 11:36:16,803 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4729825258255005, 'Total loss': 0.4729825258255005} | train loss {'Reaction outcome loss': 0.46130802379786107, 'Total loss': 0.46130802379786107}
2023-01-04 11:36:16,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:16,803 INFO:     Epoch: 12
2023-01-04 11:36:18,362 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4789922853310903, 'Total loss': 0.4789922853310903} | train loss {'Reaction outcome loss': 0.45266888422918494, 'Total loss': 0.45266888422918494}
2023-01-04 11:36:18,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:18,362 INFO:     Epoch: 13
2023-01-04 11:36:19,919 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4801155745983124, 'Total loss': 0.4801155745983124} | train loss {'Reaction outcome loss': 0.44897058284908964, 'Total loss': 0.44897058284908964}
2023-01-04 11:36:19,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:19,919 INFO:     Epoch: 14
2023-01-04 11:36:21,441 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4861832360426585, 'Total loss': 0.4861832360426585} | train loss {'Reaction outcome loss': 0.4589843467922723, 'Total loss': 0.4589843467922723}
2023-01-04 11:36:21,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:21,441 INFO:     Epoch: 15
2023-01-04 11:36:22,996 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47434706886609396, 'Total loss': 0.47434706886609396} | train loss {'Reaction outcome loss': 0.43871817578548106, 'Total loss': 0.43871817578548106}
2023-01-04 11:36:22,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:22,998 INFO:     Epoch: 16
2023-01-04 11:36:24,513 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4858667333920797, 'Total loss': 0.4858667333920797} | train loss {'Reaction outcome loss': 0.44371311998237734, 'Total loss': 0.44371311998237734}
2023-01-04 11:36:24,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:24,513 INFO:     Epoch: 17
2023-01-04 11:36:26,057 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4743060787518819, 'Total loss': 0.4743060787518819} | train loss {'Reaction outcome loss': 0.4596803485961328, 'Total loss': 0.4596803485961328}
2023-01-04 11:36:26,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:26,057 INFO:     Epoch: 18
2023-01-04 11:36:27,613 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45742591718832654, 'Total loss': 0.45742591718832654} | train loss {'Reaction outcome loss': 0.4339654627053634, 'Total loss': 0.4339654627053634}
2023-01-04 11:36:27,613 INFO:     Found new best model at epoch 18
2023-01-04 11:36:27,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:27,614 INFO:     Epoch: 19
2023-01-04 11:36:29,174 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47809106707572935, 'Total loss': 0.47809106707572935} | train loss {'Reaction outcome loss': 0.42517836842065054, 'Total loss': 0.42517836842065054}
2023-01-04 11:36:29,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:29,175 INFO:     Epoch: 20
2023-01-04 11:36:30,700 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4603909134864807, 'Total loss': 0.4603909134864807} | train loss {'Reaction outcome loss': 0.41857437223265204, 'Total loss': 0.41857437223265204}
2023-01-04 11:36:30,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:30,700 INFO:     Epoch: 21
2023-01-04 11:36:32,248 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4537940263748169, 'Total loss': 0.4537940263748169} | train loss {'Reaction outcome loss': 0.4254371404539848, 'Total loss': 0.4254371404539848}
2023-01-04 11:36:32,248 INFO:     Found new best model at epoch 21
2023-01-04 11:36:32,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:32,249 INFO:     Epoch: 22
2023-01-04 11:36:33,761 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45868682066599525, 'Total loss': 0.45868682066599525} | train loss {'Reaction outcome loss': 0.43452781267410173, 'Total loss': 0.43452781267410173}
2023-01-04 11:36:33,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:33,762 INFO:     Epoch: 23
2023-01-04 11:36:35,308 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48678520520528157, 'Total loss': 0.48678520520528157} | train loss {'Reaction outcome loss': 0.41259201621447783, 'Total loss': 0.41259201621447783}
2023-01-04 11:36:35,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:35,309 INFO:     Epoch: 24
2023-01-04 11:36:36,853 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46183302799860637, 'Total loss': 0.46183302799860637} | train loss {'Reaction outcome loss': 0.4149234291112077, 'Total loss': 0.4149234291112077}
2023-01-04 11:36:36,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:36,853 INFO:     Epoch: 25
2023-01-04 11:36:38,397 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4442836249868075, 'Total loss': 0.4442836249868075} | train loss {'Reaction outcome loss': 0.39964659988502227, 'Total loss': 0.39964659988502227}
2023-01-04 11:36:38,397 INFO:     Found new best model at epoch 25
2023-01-04 11:36:38,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:38,398 INFO:     Epoch: 26
2023-01-04 11:36:39,920 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44312852223714194, 'Total loss': 0.44312852223714194} | train loss {'Reaction outcome loss': 0.3985199871324543, 'Total loss': 0.3985199871324543}
2023-01-04 11:36:39,920 INFO:     Found new best model at epoch 26
2023-01-04 11:36:39,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:39,921 INFO:     Epoch: 27
2023-01-04 11:36:41,461 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44765485525131227, 'Total loss': 0.44765485525131227} | train loss {'Reaction outcome loss': 0.3906745505359786, 'Total loss': 0.3906745505359786}
2023-01-04 11:36:41,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:41,462 INFO:     Epoch: 28
2023-01-04 11:36:42,975 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.427618541320165, 'Total loss': 0.427618541320165} | train loss {'Reaction outcome loss': 0.3899280702951702, 'Total loss': 0.3899280702951702}
2023-01-04 11:36:42,975 INFO:     Found new best model at epoch 28
2023-01-04 11:36:42,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:42,976 INFO:     Epoch: 29
2023-01-04 11:36:44,532 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4368239720662435, 'Total loss': 0.4368239720662435} | train loss {'Reaction outcome loss': 0.38991613094897376, 'Total loss': 0.38991613094897376}
2023-01-04 11:36:44,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:44,532 INFO:     Epoch: 30
2023-01-04 11:36:46,109 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4401110033194224, 'Total loss': 0.4401110033194224} | train loss {'Reaction outcome loss': 0.3877167949757532, 'Total loss': 0.3877167949757532}
2023-01-04 11:36:46,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:46,109 INFO:     Epoch: 31
2023-01-04 11:36:47,711 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45625627040863037, 'Total loss': 0.45625627040863037} | train loss {'Reaction outcome loss': 0.40753310376211355, 'Total loss': 0.40753310376211355}
2023-01-04 11:36:47,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:47,712 INFO:     Epoch: 32
2023-01-04 11:36:49,263 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44184088706970215, 'Total loss': 0.44184088706970215} | train loss {'Reaction outcome loss': 0.3863013992389745, 'Total loss': 0.3863013992389745}
2023-01-04 11:36:49,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:49,264 INFO:     Epoch: 33
2023-01-04 11:36:50,837 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4303081194559733, 'Total loss': 0.4303081194559733} | train loss {'Reaction outcome loss': 0.37774499614539125, 'Total loss': 0.37774499614539125}
2023-01-04 11:36:50,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:50,837 INFO:     Epoch: 34
2023-01-04 11:36:52,360 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4312427977720896, 'Total loss': 0.4312427977720896} | train loss {'Reaction outcome loss': 0.3686347493523921, 'Total loss': 0.3686347493523921}
2023-01-04 11:36:52,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:52,360 INFO:     Epoch: 35
2023-01-04 11:36:53,931 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45154868563016254, 'Total loss': 0.45154868563016254} | train loss {'Reaction outcome loss': 0.3791493194960598, 'Total loss': 0.3791493194960598}
2023-01-04 11:36:53,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:53,931 INFO:     Epoch: 36
2023-01-04 11:36:55,514 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4494619091351827, 'Total loss': 0.4494619091351827} | train loss {'Reaction outcome loss': 0.3902968347725434, 'Total loss': 0.3902968347725434}
2023-01-04 11:36:55,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:55,514 INFO:     Epoch: 37
2023-01-04 11:36:57,076 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4299895832935969, 'Total loss': 0.4299895832935969} | train loss {'Reaction outcome loss': 0.3634617916726764, 'Total loss': 0.3634617916726764}
2023-01-04 11:36:57,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:57,076 INFO:     Epoch: 38
2023-01-04 11:36:58,625 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43372175097465515, 'Total loss': 0.43372175097465515} | train loss {'Reaction outcome loss': 0.35822901253461326, 'Total loss': 0.35822901253461326}
2023-01-04 11:36:58,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:36:58,626 INFO:     Epoch: 39
2023-01-04 11:37:00,227 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40916181206703184, 'Total loss': 0.40916181206703184} | train loss {'Reaction outcome loss': 0.35775255541438644, 'Total loss': 0.35775255541438644}
2023-01-04 11:37:00,227 INFO:     Found new best model at epoch 39
2023-01-04 11:37:00,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:00,228 INFO:     Epoch: 40
2023-01-04 11:37:01,775 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4357796510060628, 'Total loss': 0.4357796510060628} | train loss {'Reaction outcome loss': 0.3562526923293869, 'Total loss': 0.3562526923293869}
2023-01-04 11:37:01,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:01,775 INFO:     Epoch: 41
2023-01-04 11:37:03,373 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4050680170456568, 'Total loss': 0.4050680170456568} | train loss {'Reaction outcome loss': 0.3501170246821383, 'Total loss': 0.3501170246821383}
2023-01-04 11:37:03,373 INFO:     Found new best model at epoch 41
2023-01-04 11:37:03,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:03,374 INFO:     Epoch: 42
2023-01-04 11:37:04,983 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44453669190406797, 'Total loss': 0.44453669190406797} | train loss {'Reaction outcome loss': 0.3472646717252075, 'Total loss': 0.3472646717252075}
2023-01-04 11:37:04,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:04,984 INFO:     Epoch: 43
2023-01-04 11:37:06,579 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4108692546685537, 'Total loss': 0.4108692546685537} | train loss {'Reaction outcome loss': 0.3550392998301465, 'Total loss': 0.3550392998301465}
2023-01-04 11:37:06,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:06,579 INFO:     Epoch: 44
2023-01-04 11:37:08,145 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.396746693054835, 'Total loss': 0.396746693054835} | train loss {'Reaction outcome loss': 0.36504593507751176, 'Total loss': 0.36504593507751176}
2023-01-04 11:37:08,145 INFO:     Found new best model at epoch 44
2023-01-04 11:37:08,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:08,146 INFO:     Epoch: 45
2023-01-04 11:37:09,705 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4003600726524989, 'Total loss': 0.4003600726524989} | train loss {'Reaction outcome loss': 0.35180785331497155, 'Total loss': 0.35180785331497155}
2023-01-04 11:37:09,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:09,706 INFO:     Epoch: 46
2023-01-04 11:37:11,291 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3996507227420807, 'Total loss': 0.3996507227420807} | train loss {'Reaction outcome loss': 0.34481562061262305, 'Total loss': 0.34481562061262305}
2023-01-04 11:37:11,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:11,291 INFO:     Epoch: 47
2023-01-04 11:37:12,867 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3983171800772349, 'Total loss': 0.3983171800772349} | train loss {'Reaction outcome loss': 0.3467590471658353, 'Total loss': 0.3467590471658353}
2023-01-04 11:37:12,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:12,867 INFO:     Epoch: 48
2023-01-04 11:37:14,454 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3916496306657791, 'Total loss': 0.3916496306657791} | train loss {'Reaction outcome loss': 0.3330540513964387, 'Total loss': 0.3330540513964387}
2023-01-04 11:37:14,454 INFO:     Found new best model at epoch 48
2023-01-04 11:37:14,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:14,455 INFO:     Epoch: 49
2023-01-04 11:37:15,996 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4183399890859922, 'Total loss': 0.4183399890859922} | train loss {'Reaction outcome loss': 0.3297215780260993, 'Total loss': 0.3297215780260993}
2023-01-04 11:37:15,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:15,996 INFO:     Epoch: 50
2023-01-04 11:37:17,587 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41852198739846547, 'Total loss': 0.41852198739846547} | train loss {'Reaction outcome loss': 0.33068378491030226, 'Total loss': 0.33068378491030226}
2023-01-04 11:37:17,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:17,588 INFO:     Epoch: 51
2023-01-04 11:37:19,123 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41289402345816295, 'Total loss': 0.41289402345816295} | train loss {'Reaction outcome loss': 0.3411629843809035, 'Total loss': 0.3411629843809035}
2023-01-04 11:37:19,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:19,123 INFO:     Epoch: 52
2023-01-04 11:37:20,705 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3991081813971202, 'Total loss': 0.3991081813971202} | train loss {'Reaction outcome loss': 0.33729488182596973, 'Total loss': 0.33729488182596973}
2023-01-04 11:37:20,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:20,706 INFO:     Epoch: 53
2023-01-04 11:37:22,284 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39586844146251676, 'Total loss': 0.39586844146251676} | train loss {'Reaction outcome loss': 0.32282775577049755, 'Total loss': 0.32282775577049755}
2023-01-04 11:37:22,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:22,284 INFO:     Epoch: 54
2023-01-04 11:37:23,860 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4004740397135417, 'Total loss': 0.4004740397135417} | train loss {'Reaction outcome loss': 0.32666218124222063, 'Total loss': 0.32666218124222063}
2023-01-04 11:37:23,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:23,860 INFO:     Epoch: 55
2023-01-04 11:37:25,404 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38846038579940795, 'Total loss': 0.38846038579940795} | train loss {'Reaction outcome loss': 0.33114460114713595, 'Total loss': 0.33114460114713595}
2023-01-04 11:37:25,404 INFO:     Found new best model at epoch 55
2023-01-04 11:37:25,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:25,404 INFO:     Epoch: 56
2023-01-04 11:37:27,009 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39164565602938334, 'Total loss': 0.39164565602938334} | train loss {'Reaction outcome loss': 0.3234560231043809, 'Total loss': 0.3234560231043809}
2023-01-04 11:37:27,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:27,009 INFO:     Epoch: 57
2023-01-04 11:37:28,542 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4140982468922933, 'Total loss': 0.4140982468922933} | train loss {'Reaction outcome loss': 0.3193317154908837, 'Total loss': 0.3193317154908837}
2023-01-04 11:37:28,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:28,542 INFO:     Epoch: 58
2023-01-04 11:37:30,129 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44017919997374216, 'Total loss': 0.44017919997374216} | train loss {'Reaction outcome loss': 0.316055372111884, 'Total loss': 0.316055372111884}
2023-01-04 11:37:30,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:30,129 INFO:     Epoch: 59
2023-01-04 11:37:31,721 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4268097668886185, 'Total loss': 0.4268097668886185} | train loss {'Reaction outcome loss': 0.3147714542278993, 'Total loss': 0.3147714542278993}
2023-01-04 11:37:31,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:31,721 INFO:     Epoch: 60
2023-01-04 11:37:33,306 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3916220525900523, 'Total loss': 0.3916220525900523} | train loss {'Reaction outcome loss': 0.31392872522068815, 'Total loss': 0.31392872522068815}
2023-01-04 11:37:33,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:33,306 INFO:     Epoch: 61
2023-01-04 11:37:34,861 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39885310729344686, 'Total loss': 0.39885310729344686} | train loss {'Reaction outcome loss': 0.3093461639895711, 'Total loss': 0.3093461639895711}
2023-01-04 11:37:34,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:34,862 INFO:     Epoch: 62
2023-01-04 11:37:36,462 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.386923282345136, 'Total loss': 0.386923282345136} | train loss {'Reaction outcome loss': 0.3090493433157225, 'Total loss': 0.3090493433157225}
2023-01-04 11:37:36,462 INFO:     Found new best model at epoch 62
2023-01-04 11:37:36,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:36,463 INFO:     Epoch: 63
2023-01-04 11:37:38,043 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.391458860039711, 'Total loss': 0.391458860039711} | train loss {'Reaction outcome loss': 0.30547889402352163, 'Total loss': 0.30547889402352163}
2023-01-04 11:37:38,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:38,043 INFO:     Epoch: 64
2023-01-04 11:37:39,671 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3935814042886098, 'Total loss': 0.3935814042886098} | train loss {'Reaction outcome loss': 0.30715883738847205, 'Total loss': 0.30715883738847205}
2023-01-04 11:37:39,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:39,671 INFO:     Epoch: 65
2023-01-04 11:37:41,290 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41140822172164915, 'Total loss': 0.41140822172164915} | train loss {'Reaction outcome loss': 0.3065369906185694, 'Total loss': 0.3065369906185694}
2023-01-04 11:37:41,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:41,291 INFO:     Epoch: 66
2023-01-04 11:37:42,908 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.384931510190169, 'Total loss': 0.384931510190169} | train loss {'Reaction outcome loss': 0.3067034131757058, 'Total loss': 0.3067034131757058}
2023-01-04 11:37:42,908 INFO:     Found new best model at epoch 66
2023-01-04 11:37:42,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:42,909 INFO:     Epoch: 67
2023-01-04 11:37:44,497 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3904792418082555, 'Total loss': 0.3904792418082555} | train loss {'Reaction outcome loss': 0.2999050619710824, 'Total loss': 0.2999050619710824}
2023-01-04 11:37:44,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:44,497 INFO:     Epoch: 68
2023-01-04 11:37:46,076 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3833825925985972, 'Total loss': 0.3833825925985972} | train loss {'Reaction outcome loss': 0.3034673735121454, 'Total loss': 0.3034673735121454}
2023-01-04 11:37:46,076 INFO:     Found new best model at epoch 68
2023-01-04 11:37:46,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:46,077 INFO:     Epoch: 69
2023-01-04 11:37:47,702 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3985675076643626, 'Total loss': 0.3985675076643626} | train loss {'Reaction outcome loss': 0.32988740270535555, 'Total loss': 0.32988740270535555}
2023-01-04 11:37:47,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:47,702 INFO:     Epoch: 70
2023-01-04 11:37:49,326 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3877715806166331, 'Total loss': 0.3877715806166331} | train loss {'Reaction outcome loss': 0.3015615675881829, 'Total loss': 0.3015615675881829}
2023-01-04 11:37:49,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:49,326 INFO:     Epoch: 71
2023-01-04 11:37:50,945 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3971113959948222, 'Total loss': 0.3971113959948222} | train loss {'Reaction outcome loss': 0.3000558311443614, 'Total loss': 0.3000558311443614}
2023-01-04 11:37:50,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:50,945 INFO:     Epoch: 72
2023-01-04 11:37:52,531 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3938791071375211, 'Total loss': 0.3938791071375211} | train loss {'Reaction outcome loss': 0.3146169887066049, 'Total loss': 0.3146169887066049}
2023-01-04 11:37:52,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:52,531 INFO:     Epoch: 73
2023-01-04 11:37:54,157 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39162994076808294, 'Total loss': 0.39162994076808294} | train loss {'Reaction outcome loss': 0.296204863206831, 'Total loss': 0.296204863206831}
2023-01-04 11:37:54,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:54,158 INFO:     Epoch: 74
2023-01-04 11:37:55,747 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37678193549315137, 'Total loss': 0.37678193549315137} | train loss {'Reaction outcome loss': 0.3079153970018893, 'Total loss': 0.3079153970018893}
2023-01-04 11:37:55,747 INFO:     Found new best model at epoch 74
2023-01-04 11:37:55,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:55,748 INFO:     Epoch: 75
2023-01-04 11:37:57,369 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37432114283243817, 'Total loss': 0.37432114283243817} | train loss {'Reaction outcome loss': 0.30524158149510977, 'Total loss': 0.30524158149510977}
2023-01-04 11:37:57,369 INFO:     Found new best model at epoch 75
2023-01-04 11:37:57,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:57,370 INFO:     Epoch: 76
2023-01-04 11:37:58,993 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3782096525033315, 'Total loss': 0.3782096525033315} | train loss {'Reaction outcome loss': 0.29066316813122534, 'Total loss': 0.29066316813122534}
2023-01-04 11:37:58,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:37:58,993 INFO:     Epoch: 77
2023-01-04 11:38:00,606 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38470552265644076, 'Total loss': 0.38470552265644076} | train loss {'Reaction outcome loss': 0.2946376093472202, 'Total loss': 0.2946376093472202}
2023-01-04 11:38:00,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:00,607 INFO:     Epoch: 78
2023-01-04 11:38:02,186 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3628462349375089, 'Total loss': 0.3628462349375089} | train loss {'Reaction outcome loss': 0.28872596043283527, 'Total loss': 0.28872596043283527}
2023-01-04 11:38:02,186 INFO:     Found new best model at epoch 78
2023-01-04 11:38:02,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:02,187 INFO:     Epoch: 79
2023-01-04 11:38:03,804 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43256693085034686, 'Total loss': 0.43256693085034686} | train loss {'Reaction outcome loss': 0.29722484361812257, 'Total loss': 0.29722484361812257}
2023-01-04 11:38:03,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:03,804 INFO:     Epoch: 80
2023-01-04 11:38:05,383 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40393548607826235, 'Total loss': 0.40393548607826235} | train loss {'Reaction outcome loss': 0.3625366597004451, 'Total loss': 0.3625366597004451}
2023-01-04 11:38:05,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:05,383 INFO:     Epoch: 81
2023-01-04 11:38:06,982 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3837240527073542, 'Total loss': 0.3837240527073542} | train loss {'Reaction outcome loss': 0.29525886572209065, 'Total loss': 0.29525886572209065}
2023-01-04 11:38:06,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:06,982 INFO:     Epoch: 82
2023-01-04 11:38:08,607 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3825654983520508, 'Total loss': 0.3825654983520508} | train loss {'Reaction outcome loss': 0.2863870202732421, 'Total loss': 0.2863870202732421}
2023-01-04 11:38:08,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:08,607 INFO:     Epoch: 83
2023-01-04 11:38:10,214 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3631926755110423, 'Total loss': 0.3631926755110423} | train loss {'Reaction outcome loss': 0.28490551859410346, 'Total loss': 0.28490551859410346}
2023-01-04 11:38:10,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:10,215 INFO:     Epoch: 84
2023-01-04 11:38:11,810 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3674076040585836, 'Total loss': 0.3674076040585836} | train loss {'Reaction outcome loss': 0.2819855978334512, 'Total loss': 0.2819855978334512}
2023-01-04 11:38:11,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:11,810 INFO:     Epoch: 85
2023-01-04 11:38:13,383 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3926132649183273, 'Total loss': 0.3926132649183273} | train loss {'Reaction outcome loss': 0.28247290966438426, 'Total loss': 0.28247290966438426}
2023-01-04 11:38:13,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:13,383 INFO:     Epoch: 86
2023-01-04 11:38:14,997 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37343073785305025, 'Total loss': 0.37343073785305025} | train loss {'Reaction outcome loss': 0.2842252367763254, 'Total loss': 0.2842252367763254}
2023-01-04 11:38:14,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:14,998 INFO:     Epoch: 87
2023-01-04 11:38:16,619 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3906647086143494, 'Total loss': 0.3906647086143494} | train loss {'Reaction outcome loss': 0.29771527599381364, 'Total loss': 0.29771527599381364}
2023-01-04 11:38:16,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:16,620 INFO:     Epoch: 88
2023-01-04 11:38:18,244 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39606236616770424, 'Total loss': 0.39606236616770424} | train loss {'Reaction outcome loss': 0.33078827339804906, 'Total loss': 0.33078827339804906}
2023-01-04 11:38:18,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:18,245 INFO:     Epoch: 89
2023-01-04 11:38:19,798 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38237495919068654, 'Total loss': 0.38237495919068654} | train loss {'Reaction outcome loss': 0.298192373972953, 'Total loss': 0.298192373972953}
2023-01-04 11:38:19,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:19,798 INFO:     Epoch: 90
2023-01-04 11:38:21,415 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38522461652755735, 'Total loss': 0.38522461652755735} | train loss {'Reaction outcome loss': 0.2921991054954824, 'Total loss': 0.2921991054954824}
2023-01-04 11:38:21,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:21,415 INFO:     Epoch: 91
2023-01-04 11:38:22,760 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3751415103673935, 'Total loss': 0.3751415103673935} | train loss {'Reaction outcome loss': 0.2873497346173162, 'Total loss': 0.2873497346173162}
2023-01-04 11:38:22,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:22,761 INFO:     Epoch: 92
2023-01-04 11:38:23,786 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39412654042243955, 'Total loss': 0.39412654042243955} | train loss {'Reaction outcome loss': 0.2883985280126765, 'Total loss': 0.2883985280126765}
2023-01-04 11:38:23,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:23,787 INFO:     Epoch: 93
2023-01-04 11:38:24,802 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39855056603749595, 'Total loss': 0.39855056603749595} | train loss {'Reaction outcome loss': 0.28605524128964305, 'Total loss': 0.28605524128964305}
2023-01-04 11:38:24,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:24,802 INFO:     Epoch: 94
2023-01-04 11:38:25,817 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3870686054229736, 'Total loss': 0.3870686054229736} | train loss {'Reaction outcome loss': 0.2847419958696633, 'Total loss': 0.2847419958696633}
2023-01-04 11:38:25,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:25,817 INFO:     Epoch: 95
2023-01-04 11:38:26,837 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37702474494775134, 'Total loss': 0.37702474494775134} | train loss {'Reaction outcome loss': 0.2795552342066042, 'Total loss': 0.2795552342066042}
2023-01-04 11:38:26,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:26,837 INFO:     Epoch: 96
2023-01-04 11:38:28,399 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4091933846473694, 'Total loss': 0.4091933846473694} | train loss {'Reaction outcome loss': 0.28345904453401116, 'Total loss': 0.28345904453401116}
2023-01-04 11:38:28,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:28,399 INFO:     Epoch: 97
2023-01-04 11:38:30,012 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3846384068330129, 'Total loss': 0.3846384068330129} | train loss {'Reaction outcome loss': 0.29669391730882466, 'Total loss': 0.29669391730882466}
2023-01-04 11:38:30,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:30,013 INFO:     Epoch: 98
2023-01-04 11:38:31,617 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3897184987862905, 'Total loss': 0.3897184987862905} | train loss {'Reaction outcome loss': 0.2797860916791673, 'Total loss': 0.2797860916791673}
2023-01-04 11:38:31,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:31,617 INFO:     Epoch: 99
2023-01-04 11:38:33,223 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37240529457728067, 'Total loss': 0.37240529457728067} | train loss {'Reaction outcome loss': 0.27160377887523046, 'Total loss': 0.27160377887523046}
2023-01-04 11:38:33,223 INFO:     Best model found after epoch 79 of 100.
2023-01-04 11:38:33,223 INFO:   Done with stage: TRAINING
2023-01-04 11:38:33,224 INFO:   Starting stage: EVALUATION
2023-01-04 11:38:33,352 INFO:   Done with stage: EVALUATION
2023-01-04 11:38:33,352 INFO:   Leaving out SEQ value Fold_9
2023-01-04 11:38:33,365 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 11:38:33,365 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:38:34,015 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:38:34,015 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:38:34,084 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:38:34,084 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:38:34,084 INFO:     No hyperparam tuning for this model
2023-01-04 11:38:34,084 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:38:34,084 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:38:34,085 INFO:     None feature selector for col prot
2023-01-04 11:38:34,085 INFO:     None feature selector for col prot
2023-01-04 11:38:34,085 INFO:     None feature selector for col prot
2023-01-04 11:38:34,086 INFO:     None feature selector for col chem
2023-01-04 11:38:34,086 INFO:     None feature selector for col chem
2023-01-04 11:38:34,086 INFO:     None feature selector for col chem
2023-01-04 11:38:34,086 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:38:34,086 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:38:34,087 INFO:     Number of params in model 70111
2023-01-04 11:38:34,090 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:38:34,090 INFO:   Starting stage: TRAINING
2023-01-04 11:38:34,132 INFO:     Val loss before train {'Reaction outcome loss': 0.9879800041516622, 'Total loss': 0.9879800041516622}
2023-01-04 11:38:34,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:34,133 INFO:     Epoch: 0
2023-01-04 11:38:35,676 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7930710315704346, 'Total loss': 0.7930710315704346} | train loss {'Reaction outcome loss': 0.8460133152102736, 'Total loss': 0.8460133152102736}
2023-01-04 11:38:35,676 INFO:     Found new best model at epoch 0
2023-01-04 11:38:35,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:35,677 INFO:     Epoch: 1
2023-01-04 11:38:37,255 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6502121607462565, 'Total loss': 0.6502121607462565} | train loss {'Reaction outcome loss': 0.6931294198500981, 'Total loss': 0.6931294198500981}
2023-01-04 11:38:37,255 INFO:     Found new best model at epoch 1
2023-01-04 11:38:37,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:37,256 INFO:     Epoch: 2
2023-01-04 11:38:38,880 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5519561648368836, 'Total loss': 0.5519561648368836} | train loss {'Reaction outcome loss': 0.5907726359926837, 'Total loss': 0.5907726359926837}
2023-01-04 11:38:38,881 INFO:     Found new best model at epoch 2
2023-01-04 11:38:38,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:38,881 INFO:     Epoch: 3
2023-01-04 11:38:40,474 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.535073208808899, 'Total loss': 0.535073208808899} | train loss {'Reaction outcome loss': 0.5489264836918146, 'Total loss': 0.5489264836918146}
2023-01-04 11:38:40,474 INFO:     Found new best model at epoch 3
2023-01-04 11:38:40,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:40,475 INFO:     Epoch: 4
2023-01-04 11:38:42,073 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5270319879055023, 'Total loss': 0.5270319879055023} | train loss {'Reaction outcome loss': 0.5273697589278652, 'Total loss': 0.5273697589278652}
2023-01-04 11:38:42,073 INFO:     Found new best model at epoch 4
2023-01-04 11:38:42,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:42,074 INFO:     Epoch: 5
2023-01-04 11:38:43,652 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.523344890276591, 'Total loss': 0.523344890276591} | train loss {'Reaction outcome loss': 0.5105316862732925, 'Total loss': 0.5105316862732925}
2023-01-04 11:38:43,652 INFO:     Found new best model at epoch 5
2023-01-04 11:38:43,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:43,653 INFO:     Epoch: 6
2023-01-04 11:38:45,174 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5029495020707448, 'Total loss': 0.5029495020707448} | train loss {'Reaction outcome loss': 0.49621693763061553, 'Total loss': 0.49621693763061553}
2023-01-04 11:38:45,175 INFO:     Found new best model at epoch 6
2023-01-04 11:38:45,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:45,176 INFO:     Epoch: 7
2023-01-04 11:38:46,740 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49011780321598053, 'Total loss': 0.49011780321598053} | train loss {'Reaction outcome loss': 0.4887938475780969, 'Total loss': 0.4887938475780969}
2023-01-04 11:38:46,740 INFO:     Found new best model at epoch 7
2023-01-04 11:38:46,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:46,741 INFO:     Epoch: 8
2023-01-04 11:38:48,335 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4813068687915802, 'Total loss': 0.4813068687915802} | train loss {'Reaction outcome loss': 0.4870292063977314, 'Total loss': 0.4870292063977314}
2023-01-04 11:38:48,335 INFO:     Found new best model at epoch 8
2023-01-04 11:38:48,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:48,336 INFO:     Epoch: 9
2023-01-04 11:38:49,924 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4943846801916758, 'Total loss': 0.4943846801916758} | train loss {'Reaction outcome loss': 0.47471194916038306, 'Total loss': 0.47471194916038306}
2023-01-04 11:38:49,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:49,924 INFO:     Epoch: 10
2023-01-04 11:38:51,487 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45919371048609414, 'Total loss': 0.45919371048609414} | train loss {'Reaction outcome loss': 0.47127197698995954, 'Total loss': 0.47127197698995954}
2023-01-04 11:38:51,488 INFO:     Found new best model at epoch 10
2023-01-04 11:38:51,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:51,489 INFO:     Epoch: 11
2023-01-04 11:38:53,019 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45788341959317524, 'Total loss': 0.45788341959317524} | train loss {'Reaction outcome loss': 0.46265278805033827, 'Total loss': 0.46265278805033827}
2023-01-04 11:38:53,019 INFO:     Found new best model at epoch 11
2023-01-04 11:38:53,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:53,020 INFO:     Epoch: 12
2023-01-04 11:38:54,577 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45655516982078553, 'Total loss': 0.45655516982078553} | train loss {'Reaction outcome loss': 0.4595083587866828, 'Total loss': 0.4595083587866828}
2023-01-04 11:38:54,577 INFO:     Found new best model at epoch 12
2023-01-04 11:38:54,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:54,578 INFO:     Epoch: 13
2023-01-04 11:38:56,145 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.457360968987147, 'Total loss': 0.457360968987147} | train loss {'Reaction outcome loss': 0.4493696443225503, 'Total loss': 0.4493696443225503}
2023-01-04 11:38:56,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:56,145 INFO:     Epoch: 14
2023-01-04 11:38:57,727 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47632792592048645, 'Total loss': 0.47632792592048645} | train loss {'Reaction outcome loss': 0.4485328877445593, 'Total loss': 0.4485328877445593}
2023-01-04 11:38:57,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:57,727 INFO:     Epoch: 15
2023-01-04 11:38:59,331 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4381454209486643, 'Total loss': 0.4381454209486643} | train loss {'Reaction outcome loss': 0.44398526180306924, 'Total loss': 0.44398526180306924}
2023-01-04 11:38:59,331 INFO:     Found new best model at epoch 15
2023-01-04 11:38:59,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:38:59,332 INFO:     Epoch: 16
2023-01-04 11:39:00,925 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4533405582110087, 'Total loss': 0.4533405582110087} | train loss {'Reaction outcome loss': 0.4424559723061345, 'Total loss': 0.4424559723061345}
2023-01-04 11:39:00,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:00,926 INFO:     Epoch: 17
2023-01-04 11:39:02,471 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4493628223737081, 'Total loss': 0.4493628223737081} | train loss {'Reaction outcome loss': 0.4384906003083563, 'Total loss': 0.4384906003083563}
2023-01-04 11:39:02,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:02,472 INFO:     Epoch: 18
2023-01-04 11:39:04,062 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4449353277683258, 'Total loss': 0.4449353277683258} | train loss {'Reaction outcome loss': 0.4331889888439798, 'Total loss': 0.4331889888439798}
2023-01-04 11:39:04,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:04,063 INFO:     Epoch: 19
2023-01-04 11:39:05,693 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4459963023662567, 'Total loss': 0.4459963023662567} | train loss {'Reaction outcome loss': 0.42636988610567167, 'Total loss': 0.42636988610567167}
2023-01-04 11:39:05,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:05,693 INFO:     Epoch: 20
2023-01-04 11:39:07,329 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42953287760416664, 'Total loss': 0.42953287760416664} | train loss {'Reaction outcome loss': 0.4228391169640992, 'Total loss': 0.4228391169640992}
2023-01-04 11:39:07,329 INFO:     Found new best model at epoch 20
2023-01-04 11:39:07,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:07,330 INFO:     Epoch: 21
2023-01-04 11:39:08,978 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4504515081644058, 'Total loss': 0.4504515081644058} | train loss {'Reaction outcome loss': 0.4172104010190344, 'Total loss': 0.4172104010190344}
2023-01-04 11:39:08,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:08,978 INFO:     Epoch: 22
2023-01-04 11:39:10,610 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4382546603679657, 'Total loss': 0.4382546603679657} | train loss {'Reaction outcome loss': 0.41645339206668014, 'Total loss': 0.41645339206668014}
2023-01-04 11:39:10,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:10,610 INFO:     Epoch: 23
2023-01-04 11:39:12,143 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42260239720344545, 'Total loss': 0.42260239720344545} | train loss {'Reaction outcome loss': 0.4121833922953382, 'Total loss': 0.4121833922953382}
2023-01-04 11:39:12,143 INFO:     Found new best model at epoch 23
2023-01-04 11:39:12,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:12,144 INFO:     Epoch: 24
2023-01-04 11:39:13,749 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4257636328538259, 'Total loss': 0.4257636328538259} | train loss {'Reaction outcome loss': 0.40550541622221253, 'Total loss': 0.40550541622221253}
2023-01-04 11:39:13,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:13,749 INFO:     Epoch: 25
2023-01-04 11:39:15,335 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42028904557228086, 'Total loss': 0.42028904557228086} | train loss {'Reaction outcome loss': 0.4072456338883307, 'Total loss': 0.4072456338883307}
2023-01-04 11:39:15,335 INFO:     Found new best model at epoch 25
2023-01-04 11:39:15,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:15,336 INFO:     Epoch: 26
2023-01-04 11:39:16,922 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42429348826408386, 'Total loss': 0.42429348826408386} | train loss {'Reaction outcome loss': 0.4014835679896902, 'Total loss': 0.4014835679896902}
2023-01-04 11:39:16,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:16,923 INFO:     Epoch: 27
2023-01-04 11:39:18,478 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41919656495253244, 'Total loss': 0.41919656495253244} | train loss {'Reaction outcome loss': 0.401028447431455, 'Total loss': 0.401028447431455}
2023-01-04 11:39:18,479 INFO:     Found new best model at epoch 27
2023-01-04 11:39:18,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:18,479 INFO:     Epoch: 28
2023-01-04 11:39:20,053 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4190416206916173, 'Total loss': 0.4190416206916173} | train loss {'Reaction outcome loss': 0.3940169287825319, 'Total loss': 0.3940169287825319}
2023-01-04 11:39:20,053 INFO:     Found new best model at epoch 28
2023-01-04 11:39:20,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:20,054 INFO:     Epoch: 29
2023-01-04 11:39:21,550 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4098495264848073, 'Total loss': 0.4098495264848073} | train loss {'Reaction outcome loss': 0.39282761484599715, 'Total loss': 0.39282761484599715}
2023-01-04 11:39:21,551 INFO:     Found new best model at epoch 29
2023-01-04 11:39:21,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:21,552 INFO:     Epoch: 30
2023-01-04 11:39:23,111 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39778304398059844, 'Total loss': 0.39778304398059844} | train loss {'Reaction outcome loss': 0.3845360682813269, 'Total loss': 0.3845360682813269}
2023-01-04 11:39:23,111 INFO:     Found new best model at epoch 30
2023-01-04 11:39:23,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:23,111 INFO:     Epoch: 31
2023-01-04 11:39:24,667 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41124591827392576, 'Total loss': 0.41124591827392576} | train loss {'Reaction outcome loss': 0.38948764998990276, 'Total loss': 0.38948764998990276}
2023-01-04 11:39:24,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:24,668 INFO:     Epoch: 32
2023-01-04 11:39:26,230 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40821812152862547, 'Total loss': 0.40821812152862547} | train loss {'Reaction outcome loss': 0.3812918013721597, 'Total loss': 0.3812918013721597}
2023-01-04 11:39:26,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:26,231 INFO:     Epoch: 33
2023-01-04 11:39:27,800 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3964814166227976, 'Total loss': 0.3964814166227976} | train loss {'Reaction outcome loss': 0.3771054634979055, 'Total loss': 0.3771054634979055}
2023-01-04 11:39:27,801 INFO:     Found new best model at epoch 33
2023-01-04 11:39:27,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:27,802 INFO:     Epoch: 34
2023-01-04 11:39:29,348 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41265694200992586, 'Total loss': 0.41265694200992586} | train loss {'Reaction outcome loss': 0.373621301153937, 'Total loss': 0.373621301153937}
2023-01-04 11:39:29,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:29,348 INFO:     Epoch: 35
2023-01-04 11:39:30,910 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3938669045766195, 'Total loss': 0.3938669045766195} | train loss {'Reaction outcome loss': 0.37287794150385184, 'Total loss': 0.37287794150385184}
2023-01-04 11:39:30,910 INFO:     Found new best model at epoch 35
2023-01-04 11:39:30,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:30,911 INFO:     Epoch: 36
2023-01-04 11:39:32,521 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40569150149822236, 'Total loss': 0.40569150149822236} | train loss {'Reaction outcome loss': 0.36881905041016394, 'Total loss': 0.36881905041016394}
2023-01-04 11:39:32,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:32,521 INFO:     Epoch: 37
2023-01-04 11:39:34,084 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41439743141333263, 'Total loss': 0.41439743141333263} | train loss {'Reaction outcome loss': 0.3628794499790625, 'Total loss': 0.3628794499790625}
2023-01-04 11:39:34,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:34,084 INFO:     Epoch: 38
2023-01-04 11:39:35,652 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3879217267036438, 'Total loss': 0.3879217267036438} | train loss {'Reaction outcome loss': 0.36411190613942884, 'Total loss': 0.36411190613942884}
2023-01-04 11:39:35,652 INFO:     Found new best model at epoch 38
2023-01-04 11:39:35,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:35,653 INFO:     Epoch: 39
2023-01-04 11:39:37,227 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40914950569470726, 'Total loss': 0.40914950569470726} | train loss {'Reaction outcome loss': 0.36299175900887926, 'Total loss': 0.36299175900887926}
2023-01-04 11:39:37,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:37,227 INFO:     Epoch: 40
2023-01-04 11:39:38,778 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39941357970237734, 'Total loss': 0.39941357970237734} | train loss {'Reaction outcome loss': 0.3594068274278503, 'Total loss': 0.3594068274278503}
2023-01-04 11:39:38,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:38,778 INFO:     Epoch: 41
2023-01-04 11:39:40,312 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4296628733476003, 'Total loss': 0.4296628733476003} | train loss {'Reaction outcome loss': 0.35544764931021183, 'Total loss': 0.35544764931021183}
2023-01-04 11:39:40,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:40,313 INFO:     Epoch: 42
2023-01-04 11:39:41,904 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3956183781226476, 'Total loss': 0.3956183781226476} | train loss {'Reaction outcome loss': 0.35375959272849433, 'Total loss': 0.35375959272849433}
2023-01-04 11:39:41,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:41,904 INFO:     Epoch: 43
2023-01-04 11:39:43,501 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4071760515371958, 'Total loss': 0.4071760515371958} | train loss {'Reaction outcome loss': 0.34847306083578494, 'Total loss': 0.34847306083578494}
2023-01-04 11:39:43,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:43,501 INFO:     Epoch: 44
2023-01-04 11:39:45,105 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3990057309468587, 'Total loss': 0.3990057309468587} | train loss {'Reaction outcome loss': 0.34932280856349407, 'Total loss': 0.34932280856349407}
2023-01-04 11:39:45,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:45,105 INFO:     Epoch: 45
2023-01-04 11:39:46,684 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40974734326203666, 'Total loss': 0.40974734326203666} | train loss {'Reaction outcome loss': 0.34818229572813864, 'Total loss': 0.34818229572813864}
2023-01-04 11:39:46,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:46,684 INFO:     Epoch: 46
2023-01-04 11:39:48,221 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38743763069311776, 'Total loss': 0.38743763069311776} | train loss {'Reaction outcome loss': 0.3416205541859465, 'Total loss': 0.3416205541859465}
2023-01-04 11:39:48,222 INFO:     Found new best model at epoch 46
2023-01-04 11:39:48,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:48,222 INFO:     Epoch: 47
2023-01-04 11:39:49,796 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39215124448140465, 'Total loss': 0.39215124448140465} | train loss {'Reaction outcome loss': 0.3420835432431758, 'Total loss': 0.3420835432431758}
2023-01-04 11:39:49,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:49,796 INFO:     Epoch: 48
2023-01-04 11:39:51,405 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37058895428975425, 'Total loss': 0.37058895428975425} | train loss {'Reaction outcome loss': 0.338800157531289, 'Total loss': 0.338800157531289}
2023-01-04 11:39:51,405 INFO:     Found new best model at epoch 48
2023-01-04 11:39:51,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:51,406 INFO:     Epoch: 49
2023-01-04 11:39:52,997 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42316766977310183, 'Total loss': 0.42316766977310183} | train loss {'Reaction outcome loss': 0.3337466676016792, 'Total loss': 0.3337466676016792}
2023-01-04 11:39:52,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:52,998 INFO:     Epoch: 50
2023-01-04 11:39:54,616 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38162797192732495, 'Total loss': 0.38162797192732495} | train loss {'Reaction outcome loss': 0.33798713702372263, 'Total loss': 0.33798713702372263}
2023-01-04 11:39:54,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:54,616 INFO:     Epoch: 51
2023-01-04 11:39:56,183 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3768734832604726, 'Total loss': 0.3768734832604726} | train loss {'Reaction outcome loss': 0.3317046807372828, 'Total loss': 0.3317046807372828}
2023-01-04 11:39:56,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:56,183 INFO:     Epoch: 52
2023-01-04 11:39:57,743 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38255315124988554, 'Total loss': 0.38255315124988554} | train loss {'Reaction outcome loss': 0.33196788394171406, 'Total loss': 0.33196788394171406}
2023-01-04 11:39:57,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:57,743 INFO:     Epoch: 53
2023-01-04 11:39:59,333 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3846910645564397, 'Total loss': 0.3846910645564397} | train loss {'Reaction outcome loss': 0.3284918169090894, 'Total loss': 0.3284918169090894}
2023-01-04 11:39:59,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:39:59,334 INFO:     Epoch: 54
2023-01-04 11:40:00,955 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40421419342358905, 'Total loss': 0.40421419342358905} | train loss {'Reaction outcome loss': 0.3272750316597925, 'Total loss': 0.3272750316597925}
2023-01-04 11:40:00,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:00,955 INFO:     Epoch: 55
2023-01-04 11:40:02,567 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37790881395339965, 'Total loss': 0.37790881395339965} | train loss {'Reaction outcome loss': 0.3253665121561353, 'Total loss': 0.3253665121561353}
2023-01-04 11:40:02,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:02,567 INFO:     Epoch: 56
2023-01-04 11:40:04,166 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3782898187637329, 'Total loss': 0.3782898187637329} | train loss {'Reaction outcome loss': 0.32087864428220675, 'Total loss': 0.32087864428220675}
2023-01-04 11:40:04,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:04,166 INFO:     Epoch: 57
2023-01-04 11:40:05,760 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3625584304332733, 'Total loss': 0.3625584304332733} | train loss {'Reaction outcome loss': 0.3222374599494228, 'Total loss': 0.3222374599494228}
2023-01-04 11:40:05,760 INFO:     Found new best model at epoch 57
2023-01-04 11:40:05,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:05,761 INFO:     Epoch: 58
2023-01-04 11:40:07,306 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3593381335337957, 'Total loss': 0.3593381335337957} | train loss {'Reaction outcome loss': 0.3216929788085958, 'Total loss': 0.3216929788085958}
2023-01-04 11:40:07,306 INFO:     Found new best model at epoch 58
2023-01-04 11:40:07,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:07,307 INFO:     Epoch: 59
2023-01-04 11:40:08,886 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4080136964718501, 'Total loss': 0.4080136964718501} | train loss {'Reaction outcome loss': 0.31555821660516065, 'Total loss': 0.31555821660516065}
2023-01-04 11:40:08,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:08,887 INFO:     Epoch: 60
2023-01-04 11:40:10,468 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3850591729084651, 'Total loss': 0.3850591729084651} | train loss {'Reaction outcome loss': 0.3135224257457988, 'Total loss': 0.3135224257457988}
2023-01-04 11:40:10,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:10,468 INFO:     Epoch: 61
2023-01-04 11:40:12,064 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3892802874247233, 'Total loss': 0.3892802874247233} | train loss {'Reaction outcome loss': 0.3168255187006203, 'Total loss': 0.3168255187006203}
2023-01-04 11:40:12,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:12,065 INFO:     Epoch: 62
2023-01-04 11:40:13,646 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39284017980098723, 'Total loss': 0.39284017980098723} | train loss {'Reaction outcome loss': 0.31010560761289907, 'Total loss': 0.31010560761289907}
2023-01-04 11:40:13,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:13,646 INFO:     Epoch: 63
2023-01-04 11:40:15,197 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39601261814435323, 'Total loss': 0.39601261814435323} | train loss {'Reaction outcome loss': 0.30552326328380014, 'Total loss': 0.30552326328380014}
2023-01-04 11:40:15,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:15,197 INFO:     Epoch: 64
2023-01-04 11:40:16,744 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3919319311777751, 'Total loss': 0.3919319311777751} | train loss {'Reaction outcome loss': 0.3099132502713789, 'Total loss': 0.3099132502713789}
2023-01-04 11:40:16,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:16,744 INFO:     Epoch: 65
2023-01-04 11:40:18,336 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39282636245091757, 'Total loss': 0.39282636245091757} | train loss {'Reaction outcome loss': 0.3077317661326715, 'Total loss': 0.3077317661326715}
2023-01-04 11:40:18,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:18,336 INFO:     Epoch: 66
2023-01-04 11:40:19,934 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40343862573305767, 'Total loss': 0.40343862573305767} | train loss {'Reaction outcome loss': 0.30379693277368475, 'Total loss': 0.30379693277368475}
2023-01-04 11:40:19,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:19,934 INFO:     Epoch: 67
2023-01-04 11:40:21,517 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38146582543849944, 'Total loss': 0.38146582543849944} | train loss {'Reaction outcome loss': 0.30844643545279865, 'Total loss': 0.30844643545279865}
2023-01-04 11:40:21,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:21,517 INFO:     Epoch: 68
2023-01-04 11:40:23,083 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3885817070802053, 'Total loss': 0.3885817070802053} | train loss {'Reaction outcome loss': 0.3000630096461799, 'Total loss': 0.3000630096461799}
2023-01-04 11:40:23,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:23,083 INFO:     Epoch: 69
2023-01-04 11:40:24,619 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38981042901674906, 'Total loss': 0.38981042901674906} | train loss {'Reaction outcome loss': 0.3010005964914384, 'Total loss': 0.3010005964914384}
2023-01-04 11:40:24,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:24,619 INFO:     Epoch: 70
2023-01-04 11:40:26,160 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38254996538162234, 'Total loss': 0.38254996538162234} | train loss {'Reaction outcome loss': 0.2966266111991896, 'Total loss': 0.2966266111991896}
2023-01-04 11:40:26,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:26,160 INFO:     Epoch: 71
2023-01-04 11:40:27,734 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3875608513752619, 'Total loss': 0.3875608513752619} | train loss {'Reaction outcome loss': 0.2935840587135041, 'Total loss': 0.2935840587135041}
2023-01-04 11:40:27,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:27,735 INFO:     Epoch: 72
2023-01-04 11:40:29,322 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40809906721115113, 'Total loss': 0.40809906721115113} | train loss {'Reaction outcome loss': 0.2965553343726409, 'Total loss': 0.2965553343726409}
2023-01-04 11:40:29,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:29,322 INFO:     Epoch: 73
2023-01-04 11:40:30,884 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3687579403320948, 'Total loss': 0.3687579403320948} | train loss {'Reaction outcome loss': 0.2945582699635829, 'Total loss': 0.2945582699635829}
2023-01-04 11:40:30,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:30,884 INFO:     Epoch: 74
2023-01-04 11:40:32,458 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38062397042910256, 'Total loss': 0.38062397042910256} | train loss {'Reaction outcome loss': 0.296661365871395, 'Total loss': 0.296661365871395}
2023-01-04 11:40:32,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:32,458 INFO:     Epoch: 75
2023-01-04 11:40:33,984 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3840977311134338, 'Total loss': 0.3840977311134338} | train loss {'Reaction outcome loss': 0.29028308483022214, 'Total loss': 0.29028308483022214}
2023-01-04 11:40:33,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:33,985 INFO:     Epoch: 76
2023-01-04 11:40:35,518 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37859710057576496, 'Total loss': 0.37859710057576496} | train loss {'Reaction outcome loss': 0.29218571274020183, 'Total loss': 0.29218571274020183}
2023-01-04 11:40:35,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:35,519 INFO:     Epoch: 77
2023-01-04 11:40:37,141 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3974861274162928, 'Total loss': 0.3974861274162928} | train loss {'Reaction outcome loss': 0.28901888204180376, 'Total loss': 0.28901888204180376}
2023-01-04 11:40:37,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:37,142 INFO:     Epoch: 78
2023-01-04 11:40:38,708 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38587118685245514, 'Total loss': 0.38587118685245514} | train loss {'Reaction outcome loss': 0.2919058841838088, 'Total loss': 0.2919058841838088}
2023-01-04 11:40:38,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:38,709 INFO:     Epoch: 79
2023-01-04 11:40:40,280 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38197905917962394, 'Total loss': 0.38197905917962394} | train loss {'Reaction outcome loss': 0.2882231988739021, 'Total loss': 0.2882231988739021}
2023-01-04 11:40:40,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:40,280 INFO:     Epoch: 80
2023-01-04 11:40:41,852 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38278687993685406, 'Total loss': 0.38278687993685406} | train loss {'Reaction outcome loss': 0.2930078892716432, 'Total loss': 0.2930078892716432}
2023-01-04 11:40:41,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:41,853 INFO:     Epoch: 81
2023-01-04 11:40:43,358 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3795529286066691, 'Total loss': 0.3795529286066691} | train loss {'Reaction outcome loss': 0.2820063128744652, 'Total loss': 0.2820063128744652}
2023-01-04 11:40:43,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:43,358 INFO:     Epoch: 82
2023-01-04 11:40:44,941 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3890972594420115, 'Total loss': 0.3890972594420115} | train loss {'Reaction outcome loss': 0.2848252983568808, 'Total loss': 0.2848252983568808}
2023-01-04 11:40:44,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:44,941 INFO:     Epoch: 83
2023-01-04 11:40:46,522 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3967559297879537, 'Total loss': 0.3967559297879537} | train loss {'Reaction outcome loss': 0.2847248081803752, 'Total loss': 0.2847248081803752}
2023-01-04 11:40:46,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:46,523 INFO:     Epoch: 84
2023-01-04 11:40:48,096 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40072415471076966, 'Total loss': 0.40072415471076966} | train loss {'Reaction outcome loss': 0.28108875698238506, 'Total loss': 0.28108875698238506}
2023-01-04 11:40:48,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:48,096 INFO:     Epoch: 85
2023-01-04 11:40:49,677 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3970119764407476, 'Total loss': 0.3970119764407476} | train loss {'Reaction outcome loss': 0.27860683673448083, 'Total loss': 0.27860683673448083}
2023-01-04 11:40:49,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:49,677 INFO:     Epoch: 86
2023-01-04 11:40:51,227 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41018444697062173, 'Total loss': 0.41018444697062173} | train loss {'Reaction outcome loss': 0.280507970749256, 'Total loss': 0.280507970749256}
2023-01-04 11:40:51,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:51,227 INFO:     Epoch: 87
2023-01-04 11:40:52,762 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3764016032218933, 'Total loss': 0.3764016032218933} | train loss {'Reaction outcome loss': 0.2769877668806362, 'Total loss': 0.2769877668806362}
2023-01-04 11:40:52,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:52,762 INFO:     Epoch: 88
2023-01-04 11:40:54,317 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37483731706937157, 'Total loss': 0.37483731706937157} | train loss {'Reaction outcome loss': 0.27714284700391956, 'Total loss': 0.27714284700391956}
2023-01-04 11:40:54,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:54,317 INFO:     Epoch: 89
2023-01-04 11:40:55,881 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40604835053284966, 'Total loss': 0.40604835053284966} | train loss {'Reaction outcome loss': 0.27619367125124705, 'Total loss': 0.27619367125124705}
2023-01-04 11:40:55,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:55,881 INFO:     Epoch: 90
2023-01-04 11:40:57,446 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3940317819515864, 'Total loss': 0.3940317819515864} | train loss {'Reaction outcome loss': 0.27271577430761246, 'Total loss': 0.27271577430761246}
2023-01-04 11:40:57,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:57,446 INFO:     Epoch: 91
2023-01-04 11:40:59,005 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38442549407482146, 'Total loss': 0.38442549407482146} | train loss {'Reaction outcome loss': 0.27362793763353077, 'Total loss': 0.27362793763353077}
2023-01-04 11:40:59,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:40:59,006 INFO:     Epoch: 92
2023-01-04 11:41:00,547 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.38220613201459247, 'Total loss': 0.38220613201459247} | train loss {'Reaction outcome loss': 0.27731486552458806, 'Total loss': 0.27731486552458806}
2023-01-04 11:41:00,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:00,548 INFO:     Epoch: 93
2023-01-04 11:41:02,076 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38371041317780813, 'Total loss': 0.38371041317780813} | train loss {'Reaction outcome loss': 0.27382876721315, 'Total loss': 0.27382876721315}
2023-01-04 11:41:02,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:02,076 INFO:     Epoch: 94
2023-01-04 11:41:03,623 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40728962123394014, 'Total loss': 0.40728962123394014} | train loss {'Reaction outcome loss': 0.2722985150312689, 'Total loss': 0.2722985150312689}
2023-01-04 11:41:03,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:03,623 INFO:     Epoch: 95
2023-01-04 11:41:05,186 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38676505784193677, 'Total loss': 0.38676505784193677} | train loss {'Reaction outcome loss': 0.27734301229838, 'Total loss': 0.27734301229838}
2023-01-04 11:41:05,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:05,187 INFO:     Epoch: 96
2023-01-04 11:41:06,767 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.389228234688441, 'Total loss': 0.389228234688441} | train loss {'Reaction outcome loss': 0.2695492759131783, 'Total loss': 0.2695492759131783}
2023-01-04 11:41:06,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:06,767 INFO:     Epoch: 97
2023-01-04 11:41:08,347 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4112041483322779, 'Total loss': 0.4112041483322779} | train loss {'Reaction outcome loss': 0.270893112739501, 'Total loss': 0.270893112739501}
2023-01-04 11:41:08,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:08,347 INFO:     Epoch: 98
2023-01-04 11:41:09,896 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4302929788827896, 'Total loss': 0.4302929788827896} | train loss {'Reaction outcome loss': 0.2693190630458107, 'Total loss': 0.2693190630458107}
2023-01-04 11:41:09,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:09,896 INFO:     Epoch: 99
2023-01-04 11:41:11,445 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4107161611318588, 'Total loss': 0.4107161611318588} | train loss {'Reaction outcome loss': 0.27061705713560436, 'Total loss': 0.27061705713560436}
2023-01-04 11:41:11,445 INFO:     Best model found after epoch 59 of 100.
2023-01-04 11:41:11,445 INFO:   Done with stage: TRAINING
2023-01-04 11:41:11,445 INFO:   Starting stage: EVALUATION
2023-01-04 11:41:11,567 INFO:   Done with stage: EVALUATION
2023-01-04 11:41:11,575 INFO:   Leaving out SEQ value Fold_0
2023-01-04 11:41:11,588 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 11:41:11,588 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:41:12,240 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:41:12,240 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:41:12,307 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:41:12,308 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:41:12,308 INFO:     No hyperparam tuning for this model
2023-01-04 11:41:12,308 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:41:12,308 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:41:12,309 INFO:     None feature selector for col prot
2023-01-04 11:41:12,309 INFO:     None feature selector for col prot
2023-01-04 11:41:12,309 INFO:     None feature selector for col prot
2023-01-04 11:41:12,309 INFO:     None feature selector for col chem
2023-01-04 11:41:12,309 INFO:     None feature selector for col chem
2023-01-04 11:41:12,309 INFO:     None feature selector for col chem
2023-01-04 11:41:12,309 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:41:12,310 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:41:12,311 INFO:     Number of params in model 70111
2023-01-04 11:41:12,314 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:41:12,314 INFO:   Starting stage: TRAINING
2023-01-04 11:41:12,357 INFO:     Val loss before train {'Reaction outcome loss': 0.941465429464976, 'Total loss': 0.941465429464976}
2023-01-04 11:41:12,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:12,357 INFO:     Epoch: 0
2023-01-04 11:41:13,913 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7346008439858754, 'Total loss': 0.7346008439858754} | train loss {'Reaction outcome loss': 0.8411093137469109, 'Total loss': 0.8411093137469109}
2023-01-04 11:41:13,913 INFO:     Found new best model at epoch 0
2023-01-04 11:41:13,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:13,914 INFO:     Epoch: 1
2023-01-04 11:41:15,467 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.612460833787918, 'Total loss': 0.612460833787918} | train loss {'Reaction outcome loss': 0.6434741508539604, 'Total loss': 0.6434741508539604}
2023-01-04 11:41:15,467 INFO:     Found new best model at epoch 1
2023-01-04 11:41:15,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:15,468 INFO:     Epoch: 2
2023-01-04 11:41:17,008 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5575253307819367, 'Total loss': 0.5575253307819367} | train loss {'Reaction outcome loss': 0.5760859146282293, 'Total loss': 0.5760859146282293}
2023-01-04 11:41:17,008 INFO:     Found new best model at epoch 2
2023-01-04 11:41:17,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:17,009 INFO:     Epoch: 3
2023-01-04 11:41:18,524 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5672697365283966, 'Total loss': 0.5672697365283966} | train loss {'Reaction outcome loss': 0.5487155077432323, 'Total loss': 0.5487155077432323}
2023-01-04 11:41:18,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:18,525 INFO:     Epoch: 4
2023-01-04 11:41:20,043 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5716899971167246, 'Total loss': 0.5716899971167246} | train loss {'Reaction outcome loss': 0.5082444821794828, 'Total loss': 0.5082444821794828}
2023-01-04 11:41:20,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:20,043 INFO:     Epoch: 5
2023-01-04 11:41:21,596 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5313358922799428, 'Total loss': 0.5313358922799428} | train loss {'Reaction outcome loss': 0.4941817843220264, 'Total loss': 0.4941817843220264}
2023-01-04 11:41:21,596 INFO:     Found new best model at epoch 5
2023-01-04 11:41:21,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:21,597 INFO:     Epoch: 6
2023-01-04 11:41:23,144 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5262082695960999, 'Total loss': 0.5262082695960999} | train loss {'Reaction outcome loss': 0.48322467100471206, 'Total loss': 0.48322467100471206}
2023-01-04 11:41:23,144 INFO:     Found new best model at epoch 6
2023-01-04 11:41:23,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:23,144 INFO:     Epoch: 7
2023-01-04 11:41:24,678 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5221992750962575, 'Total loss': 0.5221992750962575} | train loss {'Reaction outcome loss': 0.47679890443839174, 'Total loss': 0.47679890443839174}
2023-01-04 11:41:24,678 INFO:     Found new best model at epoch 7
2023-01-04 11:41:24,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:24,679 INFO:     Epoch: 8
2023-01-04 11:41:26,224 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5397454897562662, 'Total loss': 0.5397454897562662} | train loss {'Reaction outcome loss': 0.4742395084417101, 'Total loss': 0.4742395084417101}
2023-01-04 11:41:26,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:26,224 INFO:     Epoch: 9
2023-01-04 11:41:27,754 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5203729341427485, 'Total loss': 0.5203729341427485} | train loss {'Reaction outcome loss': 0.46443672538262565, 'Total loss': 0.46443672538262565}
2023-01-04 11:41:27,754 INFO:     Found new best model at epoch 9
2023-01-04 11:41:27,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:27,755 INFO:     Epoch: 10
2023-01-04 11:41:29,272 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5337664345900218, 'Total loss': 0.5337664345900218} | train loss {'Reaction outcome loss': 0.4561931143170628, 'Total loss': 0.4561931143170628}
2023-01-04 11:41:29,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:29,273 INFO:     Epoch: 11
2023-01-04 11:41:30,835 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.520983350276947, 'Total loss': 0.520983350276947} | train loss {'Reaction outcome loss': 0.44836588527402416, 'Total loss': 0.44836588527402416}
2023-01-04 11:41:30,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:30,835 INFO:     Epoch: 12
2023-01-04 11:41:32,403 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5184758683045705, 'Total loss': 0.5184758683045705} | train loss {'Reaction outcome loss': 0.44806916678520053, 'Total loss': 0.44806916678520053}
2023-01-04 11:41:32,403 INFO:     Found new best model at epoch 12
2023-01-04 11:41:32,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:32,404 INFO:     Epoch: 13
2023-01-04 11:41:33,963 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5230725129445394, 'Total loss': 0.5230725129445394} | train loss {'Reaction outcome loss': 0.44155671204561775, 'Total loss': 0.44155671204561775}
2023-01-04 11:41:33,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:33,964 INFO:     Epoch: 14
2023-01-04 11:41:35,517 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4999213774998983, 'Total loss': 0.4999213774998983} | train loss {'Reaction outcome loss': 0.46248934121019597, 'Total loss': 0.46248934121019597}
2023-01-04 11:41:35,518 INFO:     Found new best model at epoch 14
2023-01-04 11:41:35,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:35,519 INFO:     Epoch: 15
2023-01-04 11:41:37,049 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4916470944881439, 'Total loss': 0.4916470944881439} | train loss {'Reaction outcome loss': 0.442408337640792, 'Total loss': 0.442408337640792}
2023-01-04 11:41:37,049 INFO:     Found new best model at epoch 15
2023-01-04 11:41:37,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:37,050 INFO:     Epoch: 16
2023-01-04 11:41:38,580 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4973559578259786, 'Total loss': 0.4973559578259786} | train loss {'Reaction outcome loss': 0.42817443704057107, 'Total loss': 0.42817443704057107}
2023-01-04 11:41:38,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:38,580 INFO:     Epoch: 17
2023-01-04 11:41:40,130 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5119840860366821, 'Total loss': 0.5119840860366821} | train loss {'Reaction outcome loss': 0.42104175029089674, 'Total loss': 0.42104175029089674}
2023-01-04 11:41:40,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:40,130 INFO:     Epoch: 18
2023-01-04 11:41:41,682 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49996706545352937, 'Total loss': 0.49996706545352937} | train loss {'Reaction outcome loss': 0.41931929207150487, 'Total loss': 0.41931929207150487}
2023-01-04 11:41:41,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:41,683 INFO:     Epoch: 19
2023-01-04 11:41:43,235 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5253597338994344, 'Total loss': 0.5253597338994344} | train loss {'Reaction outcome loss': 0.4272019584187428, 'Total loss': 0.4272019584187428}
2023-01-04 11:41:43,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:43,235 INFO:     Epoch: 20
2023-01-04 11:41:44,801 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5022714833418528, 'Total loss': 0.5022714833418528} | train loss {'Reaction outcome loss': 0.4091599084828319, 'Total loss': 0.4091599084828319}
2023-01-04 11:41:44,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:44,801 INFO:     Epoch: 21
2023-01-04 11:41:46,306 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5028121411800385, 'Total loss': 0.5028121411800385} | train loss {'Reaction outcome loss': 0.4068106693904037, 'Total loss': 0.4068106693904037}
2023-01-04 11:41:46,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:46,307 INFO:     Epoch: 22
2023-01-04 11:41:47,869 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5250342170397441, 'Total loss': 0.5250342170397441} | train loss {'Reaction outcome loss': 0.41350680184753047, 'Total loss': 0.41350680184753047}
2023-01-04 11:41:47,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:47,870 INFO:     Epoch: 23
2023-01-04 11:41:49,428 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.49305691917737327, 'Total loss': 0.49305691917737327} | train loss {'Reaction outcome loss': 0.4383811875097994, 'Total loss': 0.4383811875097994}
2023-01-04 11:41:49,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:49,429 INFO:     Epoch: 24
2023-01-04 11:41:50,992 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48349600036938983, 'Total loss': 0.48349600036938983} | train loss {'Reaction outcome loss': 0.4286838623330645, 'Total loss': 0.4286838623330645}
2023-01-04 11:41:50,992 INFO:     Found new best model at epoch 24
2023-01-04 11:41:50,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:50,993 INFO:     Epoch: 25
2023-01-04 11:41:52,561 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49528923630714417, 'Total loss': 0.49528923630714417} | train loss {'Reaction outcome loss': 0.4366788205250328, 'Total loss': 0.4366788205250328}
2023-01-04 11:41:52,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:52,562 INFO:     Epoch: 26
2023-01-04 11:41:54,119 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49035046199957527, 'Total loss': 0.49035046199957527} | train loss {'Reaction outcome loss': 0.3926099671209712, 'Total loss': 0.3926099671209712}
2023-01-04 11:41:54,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:54,119 INFO:     Epoch: 27
2023-01-04 11:41:55,617 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4855613589286804, 'Total loss': 0.4855613589286804} | train loss {'Reaction outcome loss': 0.39649104326963425, 'Total loss': 0.39649104326963425}
2023-01-04 11:41:55,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:55,618 INFO:     Epoch: 28
2023-01-04 11:41:57,189 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.497448992729187, 'Total loss': 0.497448992729187} | train loss {'Reaction outcome loss': 0.435027798666008, 'Total loss': 0.435027798666008}
2023-01-04 11:41:57,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:57,189 INFO:     Epoch: 29
2023-01-04 11:41:58,759 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47168577114741006, 'Total loss': 0.47168577114741006} | train loss {'Reaction outcome loss': 0.3858618348890889, 'Total loss': 0.3858618348890889}
2023-01-04 11:41:58,759 INFO:     Found new best model at epoch 29
2023-01-04 11:41:58,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:41:58,760 INFO:     Epoch: 30
2023-01-04 11:42:00,343 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4771518111228943, 'Total loss': 0.4771518111228943} | train loss {'Reaction outcome loss': 0.3801699294245222, 'Total loss': 0.3801699294245222}
2023-01-04 11:42:00,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:00,344 INFO:     Epoch: 31
2023-01-04 11:42:01,909 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4981974800427755, 'Total loss': 0.4981974800427755} | train loss {'Reaction outcome loss': 0.3733918338480905, 'Total loss': 0.3733918338480905}
2023-01-04 11:42:01,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:01,909 INFO:     Epoch: 32
2023-01-04 11:42:03,434 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4833474616209666, 'Total loss': 0.4833474616209666} | train loss {'Reaction outcome loss': 0.36845933296717703, 'Total loss': 0.36845933296717703}
2023-01-04 11:42:03,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:03,434 INFO:     Epoch: 33
2023-01-04 11:42:04,965 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47857317129770915, 'Total loss': 0.47857317129770915} | train loss {'Reaction outcome loss': 0.3693896955203103, 'Total loss': 0.3693896955203103}
2023-01-04 11:42:04,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:04,965 INFO:     Epoch: 34
2023-01-04 11:42:06,519 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4731398671865463, 'Total loss': 0.4731398671865463} | train loss {'Reaction outcome loss': 0.37123472807739955, 'Total loss': 0.37123472807739955}
2023-01-04 11:42:06,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:06,519 INFO:     Epoch: 35
2023-01-04 11:42:08,067 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4795032779375712, 'Total loss': 0.4795032779375712} | train loss {'Reaction outcome loss': 0.37210943390601786, 'Total loss': 0.37210943390601786}
2023-01-04 11:42:08,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:08,067 INFO:     Epoch: 36
2023-01-04 11:42:09,625 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4824219986796379, 'Total loss': 0.4824219986796379} | train loss {'Reaction outcome loss': 0.36554070909345604, 'Total loss': 0.36554070909345604}
2023-01-04 11:42:09,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:09,625 INFO:     Epoch: 37
2023-01-04 11:42:11,189 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4675281584262848, 'Total loss': 0.4675281584262848} | train loss {'Reaction outcome loss': 0.35550956792144134, 'Total loss': 0.35550956792144134}
2023-01-04 11:42:11,189 INFO:     Found new best model at epoch 37
2023-01-04 11:42:11,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:11,190 INFO:     Epoch: 38
2023-01-04 11:42:12,731 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4582696239153544, 'Total loss': 0.4582696239153544} | train loss {'Reaction outcome loss': 0.35134881837618287, 'Total loss': 0.35134881837618287}
2023-01-04 11:42:12,732 INFO:     Found new best model at epoch 38
2023-01-04 11:42:12,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:12,732 INFO:     Epoch: 39
2023-01-04 11:42:14,284 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46323015640179316, 'Total loss': 0.46323015640179316} | train loss {'Reaction outcome loss': 0.3513963642746102, 'Total loss': 0.3513963642746102}
2023-01-04 11:42:14,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:14,284 INFO:     Epoch: 40
2023-01-04 11:42:15,838 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44610263109207154, 'Total loss': 0.44610263109207154} | train loss {'Reaction outcome loss': 0.34853718586922355, 'Total loss': 0.34853718586922355}
2023-01-04 11:42:15,838 INFO:     Found new best model at epoch 40
2023-01-04 11:42:15,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:15,838 INFO:     Epoch: 41
2023-01-04 11:42:17,403 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4691148598988851, 'Total loss': 0.4691148598988851} | train loss {'Reaction outcome loss': 0.34526220223178034, 'Total loss': 0.34526220223178034}
2023-01-04 11:42:17,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:17,403 INFO:     Epoch: 42
2023-01-04 11:42:18,980 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4637033402919769, 'Total loss': 0.4637033402919769} | train loss {'Reaction outcome loss': 0.3435708918925915, 'Total loss': 0.3435708918925915}
2023-01-04 11:42:18,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:18,982 INFO:     Epoch: 43
2023-01-04 11:42:20,527 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4532225290934245, 'Total loss': 0.4532225290934245} | train loss {'Reaction outcome loss': 0.3420975036890435, 'Total loss': 0.3420975036890435}
2023-01-04 11:42:20,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:20,528 INFO:     Epoch: 44
2023-01-04 11:42:22,059 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4797642509142558, 'Total loss': 0.4797642509142558} | train loss {'Reaction outcome loss': 0.3353105660096027, 'Total loss': 0.3353105660096027}
2023-01-04 11:42:22,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:22,060 INFO:     Epoch: 45
2023-01-04 11:42:23,607 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4669818719228109, 'Total loss': 0.4669818719228109} | train loss {'Reaction outcome loss': 0.33560102657192264, 'Total loss': 0.33560102657192264}
2023-01-04 11:42:23,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:23,608 INFO:     Epoch: 46
2023-01-04 11:42:25,186 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44454366266727446, 'Total loss': 0.44454366266727446} | train loss {'Reaction outcome loss': 0.3309656467450702, 'Total loss': 0.3309656467450702}
2023-01-04 11:42:25,187 INFO:     Found new best model at epoch 46
2023-01-04 11:42:25,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:25,187 INFO:     Epoch: 47
2023-01-04 11:42:26,763 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4320211629072825, 'Total loss': 0.4320211629072825} | train loss {'Reaction outcome loss': 0.32818265365220717, 'Total loss': 0.32818265365220717}
2023-01-04 11:42:26,764 INFO:     Found new best model at epoch 47
2023-01-04 11:42:26,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:26,764 INFO:     Epoch: 48
2023-01-04 11:42:28,341 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47301669319470724, 'Total loss': 0.47301669319470724} | train loss {'Reaction outcome loss': 0.32967094079610787, 'Total loss': 0.32967094079610787}
2023-01-04 11:42:28,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:28,342 INFO:     Epoch: 49
2023-01-04 11:42:29,949 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41368098656336466, 'Total loss': 0.41368098656336466} | train loss {'Reaction outcome loss': 0.3253838614682141, 'Total loss': 0.3253838614682141}
2023-01-04 11:42:29,950 INFO:     Found new best model at epoch 49
2023-01-04 11:42:29,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:29,950 INFO:     Epoch: 50
2023-01-04 11:42:31,503 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4202074577411016, 'Total loss': 0.4202074577411016} | train loss {'Reaction outcome loss': 0.31808961656318296, 'Total loss': 0.31808961656318296}
2023-01-04 11:42:31,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:31,504 INFO:     Epoch: 51
2023-01-04 11:42:33,030 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4616600533326467, 'Total loss': 0.4616600533326467} | train loss {'Reaction outcome loss': 0.31617451623838017, 'Total loss': 0.31617451623838017}
2023-01-04 11:42:33,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:33,030 INFO:     Epoch: 52
2023-01-04 11:42:34,601 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42430478235085806, 'Total loss': 0.42430478235085806} | train loss {'Reaction outcome loss': 0.3252537475031652, 'Total loss': 0.3252537475031652}
2023-01-04 11:42:34,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:34,601 INFO:     Epoch: 53
2023-01-04 11:42:36,153 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43776967773834863, 'Total loss': 0.43776967773834863} | train loss {'Reaction outcome loss': 0.3163347828399771, 'Total loss': 0.3163347828399771}
2023-01-04 11:42:36,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:36,153 INFO:     Epoch: 54
2023-01-04 11:42:37,711 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42029614647229513, 'Total loss': 0.42029614647229513} | train loss {'Reaction outcome loss': 0.3083508728450397, 'Total loss': 0.3083508728450397}
2023-01-04 11:42:37,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:37,712 INFO:     Epoch: 55
2023-01-04 11:42:39,265 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4207757741212845, 'Total loss': 0.4207757741212845} | train loss {'Reaction outcome loss': 0.30802381980786286, 'Total loss': 0.30802381980786286}
2023-01-04 11:42:39,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:39,265 INFO:     Epoch: 56
2023-01-04 11:42:40,776 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42899988691012064, 'Total loss': 0.42899988691012064} | train loss {'Reaction outcome loss': 0.3083167486871336, 'Total loss': 0.3083167486871336}
2023-01-04 11:42:40,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:40,776 INFO:     Epoch: 57
2023-01-04 11:42:42,326 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4398485859235128, 'Total loss': 0.4398485859235128} | train loss {'Reaction outcome loss': 0.30399687350153975, 'Total loss': 0.30399687350153975}
2023-01-04 11:42:42,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:42,326 INFO:     Epoch: 58
2023-01-04 11:42:43,891 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42346781889597573, 'Total loss': 0.42346781889597573} | train loss {'Reaction outcome loss': 0.3011106740211118, 'Total loss': 0.3011106740211118}
2023-01-04 11:42:43,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:43,891 INFO:     Epoch: 59
2023-01-04 11:42:45,454 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4331637461980184, 'Total loss': 0.4331637461980184} | train loss {'Reaction outcome loss': 0.30100756233887427, 'Total loss': 0.30100756233887427}
2023-01-04 11:42:45,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:45,454 INFO:     Epoch: 60
2023-01-04 11:42:47,028 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4256312757730484, 'Total loss': 0.4256312757730484} | train loss {'Reaction outcome loss': 0.299624563550806, 'Total loss': 0.299624563550806}
2023-01-04 11:42:47,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:47,028 INFO:     Epoch: 61
2023-01-04 11:42:48,597 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4611690918604533, 'Total loss': 0.4611690918604533} | train loss {'Reaction outcome loss': 0.29573926037309045, 'Total loss': 0.29573926037309045}
2023-01-04 11:42:48,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:48,597 INFO:     Epoch: 62
2023-01-04 11:42:50,092 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4405556430419286, 'Total loss': 0.4405556430419286} | train loss {'Reaction outcome loss': 0.30083221593952697, 'Total loss': 0.30083221593952697}
2023-01-04 11:42:50,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:50,093 INFO:     Epoch: 63
2023-01-04 11:42:51,662 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.497405747572581, 'Total loss': 0.497405747572581} | train loss {'Reaction outcome loss': 0.3155049518479601, 'Total loss': 0.3155049518479601}
2023-01-04 11:42:51,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:51,662 INFO:     Epoch: 64
2023-01-04 11:42:53,238 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4317412008841833, 'Total loss': 0.4317412008841833} | train loss {'Reaction outcome loss': 0.34942303066128405, 'Total loss': 0.34942303066128405}
2023-01-04 11:42:53,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:53,238 INFO:     Epoch: 65
2023-01-04 11:42:54,792 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43236636916796367, 'Total loss': 0.43236636916796367} | train loss {'Reaction outcome loss': 0.38249629669284646, 'Total loss': 0.38249629669284646}
2023-01-04 11:42:54,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:54,793 INFO:     Epoch: 66
2023-01-04 11:42:56,357 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4124913394451141, 'Total loss': 0.4124913394451141} | train loss {'Reaction outcome loss': 0.3052483289081821, 'Total loss': 0.3052483289081821}
2023-01-04 11:42:56,358 INFO:     Found new best model at epoch 66
2023-01-04 11:42:56,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:56,358 INFO:     Epoch: 67
2023-01-04 11:42:57,882 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48108242750167846, 'Total loss': 0.48108242750167846} | train loss {'Reaction outcome loss': 0.29724218250940676, 'Total loss': 0.29724218250940676}
2023-01-04 11:42:57,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:57,882 INFO:     Epoch: 68
2023-01-04 11:42:59,407 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4338338236014048, 'Total loss': 0.4338338236014048} | train loss {'Reaction outcome loss': 0.29408775207897025, 'Total loss': 0.29408775207897025}
2023-01-04 11:42:59,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:42:59,408 INFO:     Epoch: 69
2023-01-04 11:43:00,981 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4505823532740275, 'Total loss': 0.4505823532740275} | train loss {'Reaction outcome loss': 0.30116275173740165, 'Total loss': 0.30116275173740165}
2023-01-04 11:43:00,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:00,981 INFO:     Epoch: 70
2023-01-04 11:43:02,551 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42528138558069867, 'Total loss': 0.42528138558069867} | train loss {'Reaction outcome loss': 0.2886931396399935, 'Total loss': 0.2886931396399935}
2023-01-04 11:43:02,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:02,552 INFO:     Epoch: 71
2023-01-04 11:43:04,117 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4404925137758255, 'Total loss': 0.4404925137758255} | train loss {'Reaction outcome loss': 0.296044775693124, 'Total loss': 0.296044775693124}
2023-01-04 11:43:04,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:04,117 INFO:     Epoch: 72
2023-01-04 11:43:05,699 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4391164978345235, 'Total loss': 0.4391164978345235} | train loss {'Reaction outcome loss': 0.28376510909370023, 'Total loss': 0.28376510909370023}
2023-01-04 11:43:05,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:05,699 INFO:     Epoch: 73
2023-01-04 11:43:07,250 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41931037803490956, 'Total loss': 0.41931037803490956} | train loss {'Reaction outcome loss': 0.2870173486050023, 'Total loss': 0.2870173486050023}
2023-01-04 11:43:07,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:07,252 INFO:     Epoch: 74
2023-01-04 11:43:08,765 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5091358194748561, 'Total loss': 0.5091358194748561} | train loss {'Reaction outcome loss': 0.28134688218056725, 'Total loss': 0.28134688218056725}
2023-01-04 11:43:08,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:08,765 INFO:     Epoch: 75
2023-01-04 11:43:10,330 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4092439373334249, 'Total loss': 0.4092439373334249} | train loss {'Reaction outcome loss': 0.279254970777876, 'Total loss': 0.279254970777876}
2023-01-04 11:43:10,330 INFO:     Found new best model at epoch 75
2023-01-04 11:43:10,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:10,330 INFO:     Epoch: 76
2023-01-04 11:43:11,877 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46371061603228253, 'Total loss': 0.46371061603228253} | train loss {'Reaction outcome loss': 0.2934956348676612, 'Total loss': 0.2934956348676612}
2023-01-04 11:43:11,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:11,878 INFO:     Epoch: 77
2023-01-04 11:43:13,432 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4115123276909192, 'Total loss': 0.4115123276909192} | train loss {'Reaction outcome loss': 0.32896228221015655, 'Total loss': 0.32896228221015655}
2023-01-04 11:43:13,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:13,433 INFO:     Epoch: 78
2023-01-04 11:43:14,988 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4553487588961919, 'Total loss': 0.4553487588961919} | train loss {'Reaction outcome loss': 0.29401564436283073, 'Total loss': 0.29401564436283073}
2023-01-04 11:43:14,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:14,988 INFO:     Epoch: 79
2023-01-04 11:43:16,513 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4503778378168742, 'Total loss': 0.4503778378168742} | train loss {'Reaction outcome loss': 0.28492580343415774, 'Total loss': 0.28492580343415774}
2023-01-04 11:43:16,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:16,513 INFO:     Epoch: 80
2023-01-04 11:43:18,030 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41777657469113666, 'Total loss': 0.41777657469113666} | train loss {'Reaction outcome loss': 0.2924064692815064, 'Total loss': 0.2924064692815064}
2023-01-04 11:43:18,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:18,030 INFO:     Epoch: 81
2023-01-04 11:43:19,595 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4448653479417165, 'Total loss': 0.4448653479417165} | train loss {'Reaction outcome loss': 0.27930017362983117, 'Total loss': 0.27930017362983117}
2023-01-04 11:43:19,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:19,595 INFO:     Epoch: 82
2023-01-04 11:43:21,152 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44031654198964437, 'Total loss': 0.44031654198964437} | train loss {'Reaction outcome loss': 0.2954941405037391, 'Total loss': 0.2954941405037391}
2023-01-04 11:43:21,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:21,152 INFO:     Epoch: 83
2023-01-04 11:43:22,712 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41110093196233116, 'Total loss': 0.41110093196233116} | train loss {'Reaction outcome loss': 0.2755024077664332, 'Total loss': 0.2755024077664332}
2023-01-04 11:43:22,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:22,712 INFO:     Epoch: 84
2023-01-04 11:43:24,282 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4278645555178324, 'Total loss': 0.4278645555178324} | train loss {'Reaction outcome loss': 0.2751532682218501, 'Total loss': 0.2751532682218501}
2023-01-04 11:43:24,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:24,282 INFO:     Epoch: 85
2023-01-04 11:43:25,815 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4856979469458262, 'Total loss': 0.4856979469458262} | train loss {'Reaction outcome loss': 0.27965115958257863, 'Total loss': 0.27965115958257863}
2023-01-04 11:43:25,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:25,816 INFO:     Epoch: 86
2023-01-04 11:43:27,332 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4242196768522263, 'Total loss': 0.4242196768522263} | train loss {'Reaction outcome loss': 0.3047954115115673, 'Total loss': 0.3047954115115673}
2023-01-04 11:43:27,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:27,332 INFO:     Epoch: 87
2023-01-04 11:43:28,880 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4219811538855235, 'Total loss': 0.4219811538855235} | train loss {'Reaction outcome loss': 0.2675230636545482, 'Total loss': 0.2675230636545482}
2023-01-04 11:43:28,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:28,880 INFO:     Epoch: 88
2023-01-04 11:43:30,428 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42392203013102214, 'Total loss': 0.42392203013102214} | train loss {'Reaction outcome loss': 0.2672992558568628, 'Total loss': 0.2672992558568628}
2023-01-04 11:43:30,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:30,429 INFO:     Epoch: 89
2023-01-04 11:43:31,988 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.433966796596845, 'Total loss': 0.433966796596845} | train loss {'Reaction outcome loss': 0.26767496937187074, 'Total loss': 0.26767496937187074}
2023-01-04 11:43:31,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:31,988 INFO:     Epoch: 90
2023-01-04 11:43:33,544 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4247483551502228, 'Total loss': 0.4247483551502228} | train loss {'Reaction outcome loss': 0.2678465848194732, 'Total loss': 0.2678465848194732}
2023-01-04 11:43:33,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:33,544 INFO:     Epoch: 91
2023-01-04 11:43:34,742 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4201487571001053, 'Total loss': 0.4201487571001053} | train loss {'Reaction outcome loss': 0.28783885627796035, 'Total loss': 0.28783885627796035}
2023-01-04 11:43:34,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:34,742 INFO:     Epoch: 92
2023-01-04 11:43:35,773 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4298356235027313, 'Total loss': 0.4298356235027313} | train loss {'Reaction outcome loss': 0.26354461779861804, 'Total loss': 0.26354461779861804}
2023-01-04 11:43:35,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:35,774 INFO:     Epoch: 93
2023-01-04 11:43:36,798 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4404792219400406, 'Total loss': 0.4404792219400406} | train loss {'Reaction outcome loss': 0.2641436412012663, 'Total loss': 0.2641436412012663}
2023-01-04 11:43:36,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:36,799 INFO:     Epoch: 94
2023-01-04 11:43:37,825 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4413391500711441, 'Total loss': 0.4413391500711441} | train loss {'Reaction outcome loss': 0.2657433202004303, 'Total loss': 0.2657433202004303}
2023-01-04 11:43:37,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:37,826 INFO:     Epoch: 95
2023-01-04 11:43:39,139 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44795299669106803, 'Total loss': 0.44795299669106803} | train loss {'Reaction outcome loss': 0.2608549071434106, 'Total loss': 0.2608549071434106}
2023-01-04 11:43:39,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:39,140 INFO:     Epoch: 96
2023-01-04 11:43:40,701 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42139104604721067, 'Total loss': 0.42139104604721067} | train loss {'Reaction outcome loss': 0.26206168096657656, 'Total loss': 0.26206168096657656}
2023-01-04 11:43:40,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:40,701 INFO:     Epoch: 97
2023-01-04 11:43:42,230 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4344834268093109, 'Total loss': 0.4344834268093109} | train loss {'Reaction outcome loss': 0.26770060199002427, 'Total loss': 0.26770060199002427}
2023-01-04 11:43:42,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:42,231 INFO:     Epoch: 98
2023-01-04 11:43:43,796 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.434710552295049, 'Total loss': 0.434710552295049} | train loss {'Reaction outcome loss': 0.28604745849592605, 'Total loss': 0.28604745849592605}
2023-01-04 11:43:43,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:43,797 INFO:     Epoch: 99
2023-01-04 11:43:45,370 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43863616486390433, 'Total loss': 0.43863616486390433} | train loss {'Reaction outcome loss': 0.2575521924789401, 'Total loss': 0.2575521924789401}
2023-01-04 11:43:45,370 INFO:     Best model found after epoch 76 of 100.
2023-01-04 11:43:45,370 INFO:   Done with stage: TRAINING
2023-01-04 11:43:45,370 INFO:   Starting stage: EVALUATION
2023-01-04 11:43:45,497 INFO:   Done with stage: EVALUATION
2023-01-04 11:43:45,497 INFO:   Leaving out SEQ value Fold_1
2023-01-04 11:43:45,510 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 11:43:45,510 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:43:46,163 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:43:46,163 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:43:46,231 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:43:46,231 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:43:46,231 INFO:     No hyperparam tuning for this model
2023-01-04 11:43:46,231 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:43:46,231 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:43:46,232 INFO:     None feature selector for col prot
2023-01-04 11:43:46,232 INFO:     None feature selector for col prot
2023-01-04 11:43:46,232 INFO:     None feature selector for col prot
2023-01-04 11:43:46,233 INFO:     None feature selector for col chem
2023-01-04 11:43:46,233 INFO:     None feature selector for col chem
2023-01-04 11:43:46,233 INFO:     None feature selector for col chem
2023-01-04 11:43:46,233 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:43:46,233 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:43:46,234 INFO:     Number of params in model 70111
2023-01-04 11:43:46,237 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:43:46,237 INFO:   Starting stage: TRAINING
2023-01-04 11:43:46,280 INFO:     Val loss before train {'Reaction outcome loss': 0.9350159684816997, 'Total loss': 0.9350159684816997}
2023-01-04 11:43:46,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:46,280 INFO:     Epoch: 0
2023-01-04 11:43:47,789 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.708963414033254, 'Total loss': 0.708963414033254} | train loss {'Reaction outcome loss': 0.846150613821827, 'Total loss': 0.846150613821827}
2023-01-04 11:43:47,789 INFO:     Found new best model at epoch 0
2023-01-04 11:43:47,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:47,790 INFO:     Epoch: 1
2023-01-04 11:43:49,334 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5778102735678355, 'Total loss': 0.5778102735678355} | train loss {'Reaction outcome loss': 0.7016920292938965, 'Total loss': 0.7016920292938965}
2023-01-04 11:43:49,334 INFO:     Found new best model at epoch 1
2023-01-04 11:43:49,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:49,335 INFO:     Epoch: 2
2023-01-04 11:43:50,860 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5177696923414866, 'Total loss': 0.5177696923414866} | train loss {'Reaction outcome loss': 0.6161491431943749, 'Total loss': 0.6161491431943749}
2023-01-04 11:43:50,860 INFO:     Found new best model at epoch 2
2023-01-04 11:43:50,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:50,861 INFO:     Epoch: 3
2023-01-04 11:43:52,406 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46767631570498147, 'Total loss': 0.46767631570498147} | train loss {'Reaction outcome loss': 0.5627677086116476, 'Total loss': 0.5627677086116476}
2023-01-04 11:43:52,406 INFO:     Found new best model at epoch 3
2023-01-04 11:43:52,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:52,407 INFO:     Epoch: 4
2023-01-04 11:43:53,987 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48933709363142647, 'Total loss': 0.48933709363142647} | train loss {'Reaction outcome loss': 0.5322451581031192, 'Total loss': 0.5322451581031192}
2023-01-04 11:43:53,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:53,988 INFO:     Epoch: 5
2023-01-04 11:43:55,561 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43453895548979443, 'Total loss': 0.43453895548979443} | train loss {'Reaction outcome loss': 0.5118825980377572, 'Total loss': 0.5118825980377572}
2023-01-04 11:43:55,561 INFO:     Found new best model at epoch 5
2023-01-04 11:43:55,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:55,562 INFO:     Epoch: 6
2023-01-04 11:43:57,096 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4359852373600006, 'Total loss': 0.4359852373600006} | train loss {'Reaction outcome loss': 0.5005268145055659, 'Total loss': 0.5005268145055659}
2023-01-04 11:43:57,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:57,097 INFO:     Epoch: 7
2023-01-04 11:43:58,658 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4191007951895396, 'Total loss': 0.4191007951895396} | train loss {'Reaction outcome loss': 0.49272633131350513, 'Total loss': 0.49272633131350513}
2023-01-04 11:43:58,658 INFO:     Found new best model at epoch 7
2023-01-04 11:43:58,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:43:58,659 INFO:     Epoch: 8
2023-01-04 11:44:00,198 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41774871746699016, 'Total loss': 0.41774871746699016} | train loss {'Reaction outcome loss': 0.4835779611928139, 'Total loss': 0.4835779611928139}
2023-01-04 11:44:00,198 INFO:     Found new best model at epoch 8
2023-01-04 11:44:00,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:00,199 INFO:     Epoch: 9
2023-01-04 11:44:01,765 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42289695839087166, 'Total loss': 0.42289695839087166} | train loss {'Reaction outcome loss': 0.47447154093263805, 'Total loss': 0.47447154093263805}
2023-01-04 11:44:01,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:01,766 INFO:     Epoch: 10
2023-01-04 11:44:03,340 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39741837978363037, 'Total loss': 0.39741837978363037} | train loss {'Reaction outcome loss': 0.4758341880110295, 'Total loss': 0.4758341880110295}
2023-01-04 11:44:03,340 INFO:     Found new best model at epoch 10
2023-01-04 11:44:03,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:03,340 INFO:     Epoch: 11
2023-01-04 11:44:04,907 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3842973011235396, 'Total loss': 0.3842973011235396} | train loss {'Reaction outcome loss': 0.4738177467083585, 'Total loss': 0.4738177467083585}
2023-01-04 11:44:04,907 INFO:     Found new best model at epoch 11
2023-01-04 11:44:04,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:04,908 INFO:     Epoch: 12
2023-01-04 11:44:06,463 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.38309823324282966, 'Total loss': 0.38309823324282966} | train loss {'Reaction outcome loss': 0.46012775076256285, 'Total loss': 0.46012775076256285}
2023-01-04 11:44:06,463 INFO:     Found new best model at epoch 12
2023-01-04 11:44:06,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:06,463 INFO:     Epoch: 13
2023-01-04 11:44:08,042 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4072829450170199, 'Total loss': 0.4072829450170199} | train loss {'Reaction outcome loss': 0.4569901867459218, 'Total loss': 0.4569901867459218}
2023-01-04 11:44:08,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:08,042 INFO:     Epoch: 14
2023-01-04 11:44:09,585 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.419536920885245, 'Total loss': 0.419536920885245} | train loss {'Reaction outcome loss': 0.4655232905153779, 'Total loss': 0.4655232905153779}
2023-01-04 11:44:09,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:09,585 INFO:     Epoch: 15
2023-01-04 11:44:11,161 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3847816417614619, 'Total loss': 0.3847816417614619} | train loss {'Reaction outcome loss': 0.44625525910785235, 'Total loss': 0.44625525910785235}
2023-01-04 11:44:11,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:11,161 INFO:     Epoch: 16
2023-01-04 11:44:12,737 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4055906613667806, 'Total loss': 0.4055906613667806} | train loss {'Reaction outcome loss': 0.43904214349669823, 'Total loss': 0.43904214349669823}
2023-01-04 11:44:12,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:12,737 INFO:     Epoch: 17
2023-01-04 11:44:14,303 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40330558717250825, 'Total loss': 0.40330558717250825} | train loss {'Reaction outcome loss': 0.4324524854512318, 'Total loss': 0.4324524854512318}
2023-01-04 11:44:14,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:14,304 INFO:     Epoch: 18
2023-01-04 11:44:15,873 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.368854820728302, 'Total loss': 0.368854820728302} | train loss {'Reaction outcome loss': 0.4309889429680787, 'Total loss': 0.4309889429680787}
2023-01-04 11:44:15,873 INFO:     Found new best model at epoch 18
2023-01-04 11:44:15,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:15,874 INFO:     Epoch: 19
2023-01-04 11:44:17,455 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38759729663530984, 'Total loss': 0.38759729663530984} | train loss {'Reaction outcome loss': 0.42696781434874603, 'Total loss': 0.42696781434874603}
2023-01-04 11:44:17,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:17,456 INFO:     Epoch: 20
2023-01-04 11:44:18,994 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39709151685237887, 'Total loss': 0.39709151685237887} | train loss {'Reaction outcome loss': 0.4230485608180364, 'Total loss': 0.4230485608180364}
2023-01-04 11:44:18,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:18,994 INFO:     Epoch: 21
2023-01-04 11:44:20,573 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3760385433832804, 'Total loss': 0.3760385433832804} | train loss {'Reaction outcome loss': 0.420286072364104, 'Total loss': 0.420286072364104}
2023-01-04 11:44:20,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:20,574 INFO:     Epoch: 22
2023-01-04 11:44:22,161 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.36898497541745506, 'Total loss': 0.36898497541745506} | train loss {'Reaction outcome loss': 0.425795331435359, 'Total loss': 0.425795331435359}
2023-01-04 11:44:22,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:22,161 INFO:     Epoch: 23
2023-01-04 11:44:23,705 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4085978309313456, 'Total loss': 0.4085978309313456} | train loss {'Reaction outcome loss': 0.43563551439539244, 'Total loss': 0.43563551439539244}
2023-01-04 11:44:23,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:23,705 INFO:     Epoch: 24
2023-01-04 11:44:25,287 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4103253205617269, 'Total loss': 0.4103253205617269} | train loss {'Reaction outcome loss': 0.42380304197254387, 'Total loss': 0.42380304197254387}
2023-01-04 11:44:25,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:25,287 INFO:     Epoch: 25
2023-01-04 11:44:26,852 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38291262288888295, 'Total loss': 0.38291262288888295} | train loss {'Reaction outcome loss': 0.4154556019145631, 'Total loss': 0.4154556019145631}
2023-01-04 11:44:26,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:26,852 INFO:     Epoch: 26
2023-01-04 11:44:28,418 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.380526077747345, 'Total loss': 0.380526077747345} | train loss {'Reaction outcome loss': 0.40132741969537694, 'Total loss': 0.40132741969537694}
2023-01-04 11:44:28,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:28,418 INFO:     Epoch: 27
2023-01-04 11:44:30,003 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3627750883499781, 'Total loss': 0.3627750883499781} | train loss {'Reaction outcome loss': 0.399313320554253, 'Total loss': 0.399313320554253}
2023-01-04 11:44:30,003 INFO:     Found new best model at epoch 27
2023-01-04 11:44:30,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:30,004 INFO:     Epoch: 28
2023-01-04 11:44:31,567 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.36681923965613045, 'Total loss': 0.36681923965613045} | train loss {'Reaction outcome loss': 0.4179896054168542, 'Total loss': 0.4179896054168542}
2023-01-04 11:44:31,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:31,567 INFO:     Epoch: 29
2023-01-04 11:44:33,114 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.373608672618866, 'Total loss': 0.373608672618866} | train loss {'Reaction outcome loss': 0.39445524999831355, 'Total loss': 0.39445524999831355}
2023-01-04 11:44:33,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:33,115 INFO:     Epoch: 30
2023-01-04 11:44:34,686 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3566488732894262, 'Total loss': 0.3566488732894262} | train loss {'Reaction outcome loss': 0.38682517423776386, 'Total loss': 0.38682517423776386}
2023-01-04 11:44:34,686 INFO:     Found new best model at epoch 30
2023-01-04 11:44:34,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:34,687 INFO:     Epoch: 31
2023-01-04 11:44:36,228 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.35521900455156963, 'Total loss': 0.35521900455156963} | train loss {'Reaction outcome loss': 0.3846467921672308, 'Total loss': 0.3846467921672308}
2023-01-04 11:44:36,228 INFO:     Found new best model at epoch 31
2023-01-04 11:44:36,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:36,229 INFO:     Epoch: 32
2023-01-04 11:44:37,809 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.35383320848147076, 'Total loss': 0.35383320848147076} | train loss {'Reaction outcome loss': 0.38334377590512886, 'Total loss': 0.38334377590512886}
2023-01-04 11:44:37,809 INFO:     Found new best model at epoch 32
2023-01-04 11:44:37,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:37,810 INFO:     Epoch: 33
2023-01-04 11:44:39,399 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3670095642407735, 'Total loss': 0.3670095642407735} | train loss {'Reaction outcome loss': 0.39703390023954643, 'Total loss': 0.39703390023954643}
2023-01-04 11:44:39,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:39,400 INFO:     Epoch: 34
2023-01-04 11:44:40,972 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.35164792835712433, 'Total loss': 0.35164792835712433} | train loss {'Reaction outcome loss': 0.3781462191887524, 'Total loss': 0.3781462191887524}
2023-01-04 11:44:40,972 INFO:     Found new best model at epoch 34
2023-01-04 11:44:40,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:40,973 INFO:     Epoch: 35
2023-01-04 11:44:42,499 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3456175873676936, 'Total loss': 0.3456175873676936} | train loss {'Reaction outcome loss': 0.3876464095808552, 'Total loss': 0.3876464095808552}
2023-01-04 11:44:42,499 INFO:     Found new best model at epoch 35
2023-01-04 11:44:42,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:42,500 INFO:     Epoch: 36
2023-01-04 11:44:44,073 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40165575842062634, 'Total loss': 0.40165575842062634} | train loss {'Reaction outcome loss': 0.37131970097391825, 'Total loss': 0.37131970097391825}
2023-01-04 11:44:44,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:44,073 INFO:     Epoch: 37
2023-01-04 11:44:45,622 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3334194908539454, 'Total loss': 0.3334194908539454} | train loss {'Reaction outcome loss': 0.36737816722191374, 'Total loss': 0.36737816722191374}
2023-01-04 11:44:45,622 INFO:     Found new best model at epoch 37
2023-01-04 11:44:45,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:45,623 INFO:     Epoch: 38
2023-01-04 11:44:47,209 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3413296560446421, 'Total loss': 0.3413296560446421} | train loss {'Reaction outcome loss': 0.3666733819367885, 'Total loss': 0.3666733819367885}
2023-01-04 11:44:47,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:47,209 INFO:     Epoch: 39
2023-01-04 11:44:48,787 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.34018345872561134, 'Total loss': 0.34018345872561134} | train loss {'Reaction outcome loss': 0.3610711878024723, 'Total loss': 0.3610711878024723}
2023-01-04 11:44:48,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:48,789 INFO:     Epoch: 40
2023-01-04 11:44:50,381 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3600746691226959, 'Total loss': 0.3600746691226959} | train loss {'Reaction outcome loss': 0.3633668242508303, 'Total loss': 0.3633668242508303}
2023-01-04 11:44:50,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:50,381 INFO:     Epoch: 41
2023-01-04 11:44:51,947 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.33121805091698964, 'Total loss': 0.33121805091698964} | train loss {'Reaction outcome loss': 0.3556377996717566, 'Total loss': 0.3556377996717566}
2023-01-04 11:44:51,947 INFO:     Found new best model at epoch 41
2023-01-04 11:44:51,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:51,948 INFO:     Epoch: 42
2023-01-04 11:44:53,542 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.35170737008253733, 'Total loss': 0.35170737008253733} | train loss {'Reaction outcome loss': 0.3549298976102601, 'Total loss': 0.3549298976102601}
2023-01-04 11:44:53,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:53,542 INFO:     Epoch: 43
2023-01-04 11:44:55,089 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.35061240394910176, 'Total loss': 0.35061240394910176} | train loss {'Reaction outcome loss': 0.36188341600738594, 'Total loss': 0.36188341600738594}
2023-01-04 11:44:55,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:55,089 INFO:     Epoch: 44
2023-01-04 11:44:56,670 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38371608157952625, 'Total loss': 0.38371608157952625} | train loss {'Reaction outcome loss': 0.3510345756953609, 'Total loss': 0.3510345756953609}
2023-01-04 11:44:56,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:56,671 INFO:     Epoch: 45
2023-01-04 11:44:58,257 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3836498647928238, 'Total loss': 0.3836498647928238} | train loss {'Reaction outcome loss': 0.3519784503791859, 'Total loss': 0.3519784503791859}
2023-01-04 11:44:58,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:58,257 INFO:     Epoch: 46
2023-01-04 11:44:59,827 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3265744835138321, 'Total loss': 0.3265744835138321} | train loss {'Reaction outcome loss': 0.3465857250916272, 'Total loss': 0.3465857250916272}
2023-01-04 11:44:59,827 INFO:     Found new best model at epoch 46
2023-01-04 11:44:59,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:44:59,828 INFO:     Epoch: 47
2023-01-04 11:45:01,395 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.33774652481079104, 'Total loss': 0.33774652481079104} | train loss {'Reaction outcome loss': 0.3444094271922106, 'Total loss': 0.3444094271922106}
2023-01-04 11:45:01,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:01,396 INFO:     Epoch: 48
2023-01-04 11:45:02,969 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.36020135680834453, 'Total loss': 0.36020135680834453} | train loss {'Reaction outcome loss': 0.3395193412889848, 'Total loss': 0.3395193412889848}
2023-01-04 11:45:02,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:02,969 INFO:     Epoch: 49
2023-01-04 11:45:04,506 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3370140512784322, 'Total loss': 0.3370140512784322} | train loss {'Reaction outcome loss': 0.3380806323248839, 'Total loss': 0.3380806323248839}
2023-01-04 11:45:04,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:04,507 INFO:     Epoch: 50
2023-01-04 11:45:06,085 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.33908323347568514, 'Total loss': 0.33908323347568514} | train loss {'Reaction outcome loss': 0.3393013289576207, 'Total loss': 0.3393013289576207}
2023-01-04 11:45:06,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:06,085 INFO:     Epoch: 51
2023-01-04 11:45:07,652 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.34145372013250985, 'Total loss': 0.34145372013250985} | train loss {'Reaction outcome loss': 0.33263627875704266, 'Total loss': 0.33263627875704266}
2023-01-04 11:45:07,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:07,653 INFO:     Epoch: 52
2023-01-04 11:45:09,190 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3403144031763077, 'Total loss': 0.3403144031763077} | train loss {'Reaction outcome loss': 0.33001536755287764, 'Total loss': 0.33001536755287764}
2023-01-04 11:45:09,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:09,190 INFO:     Epoch: 53
2023-01-04 11:45:10,782 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37597672939300536, 'Total loss': 0.37597672939300536} | train loss {'Reaction outcome loss': 0.32829478350670444, 'Total loss': 0.32829478350670444}
2023-01-04 11:45:10,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:10,783 INFO:     Epoch: 54
2023-01-04 11:45:12,344 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3548811346292496, 'Total loss': 0.3548811346292496} | train loss {'Reaction outcome loss': 0.3221945859545815, 'Total loss': 0.3221945859545815}
2023-01-04 11:45:12,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:12,344 INFO:     Epoch: 55
2023-01-04 11:45:13,951 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.33377440869808195, 'Total loss': 0.33377440869808195} | train loss {'Reaction outcome loss': 0.3292541137181114, 'Total loss': 0.3292541137181114}
2023-01-04 11:45:13,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:13,951 INFO:     Epoch: 56
2023-01-04 11:45:15,558 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.34631109436353047, 'Total loss': 0.34631109436353047} | train loss {'Reaction outcome loss': 0.3200492785523976, 'Total loss': 0.3200492785523976}
2023-01-04 11:45:15,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:15,558 INFO:     Epoch: 57
2023-01-04 11:45:17,149 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3458897958199183, 'Total loss': 0.3458897958199183} | train loss {'Reaction outcome loss': 0.32120604724522034, 'Total loss': 0.32120604724522034}
2023-01-04 11:45:17,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:17,149 INFO:     Epoch: 58
2023-01-04 11:45:18,694 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3585580309232076, 'Total loss': 0.3585580309232076} | train loss {'Reaction outcome loss': 0.32049282285742514, 'Total loss': 0.32049282285742514}
2023-01-04 11:45:18,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:18,695 INFO:     Epoch: 59
2023-01-04 11:45:20,287 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.348313828309377, 'Total loss': 0.348313828309377} | train loss {'Reaction outcome loss': 0.3166984094617267, 'Total loss': 0.3166984094617267}
2023-01-04 11:45:20,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:20,288 INFO:     Epoch: 60
2023-01-04 11:45:21,839 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.33089088201522826, 'Total loss': 0.33089088201522826} | train loss {'Reaction outcome loss': 0.31306199899267667, 'Total loss': 0.31306199899267667}
2023-01-04 11:45:21,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:21,839 INFO:     Epoch: 61
2023-01-04 11:45:23,407 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.32134370108445487, 'Total loss': 0.32134370108445487} | train loss {'Reaction outcome loss': 0.30916004137916686, 'Total loss': 0.30916004137916686}
2023-01-04 11:45:23,407 INFO:     Found new best model at epoch 61
2023-01-04 11:45:23,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:23,408 INFO:     Epoch: 62
2023-01-04 11:45:24,985 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.32546728452046714, 'Total loss': 0.32546728452046714} | train loss {'Reaction outcome loss': 0.309246843667242, 'Total loss': 0.309246843667242}
2023-01-04 11:45:24,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:24,986 INFO:     Epoch: 63
2023-01-04 11:45:26,561 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.35586501757303873, 'Total loss': 0.35586501757303873} | train loss {'Reaction outcome loss': 0.30634049456009804, 'Total loss': 0.30634049456009804}
2023-01-04 11:45:26,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:26,562 INFO:     Epoch: 64
2023-01-04 11:45:28,102 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3338079144557317, 'Total loss': 0.3338079144557317} | train loss {'Reaction outcome loss': 0.3095943611655114, 'Total loss': 0.3095943611655114}
2023-01-04 11:45:28,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:28,102 INFO:     Epoch: 65
2023-01-04 11:45:29,686 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.321823450922966, 'Total loss': 0.321823450922966} | train loss {'Reaction outcome loss': 0.325521824867937, 'Total loss': 0.325521824867937}
2023-01-04 11:45:29,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:29,686 INFO:     Epoch: 66
2023-01-04 11:45:31,227 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.30294273296991986, 'Total loss': 0.30294273296991986} | train loss {'Reaction outcome loss': 0.30552785225091095, 'Total loss': 0.30552785225091095}
2023-01-04 11:45:31,227 INFO:     Found new best model at epoch 66
2023-01-04 11:45:31,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:31,228 INFO:     Epoch: 67
2023-01-04 11:45:32,819 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.33654805918534597, 'Total loss': 0.33654805918534597} | train loss {'Reaction outcome loss': 0.3035275958650543, 'Total loss': 0.3035275958650543}
2023-01-04 11:45:32,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:32,819 INFO:     Epoch: 68
2023-01-04 11:45:34,381 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3408252904812495, 'Total loss': 0.3408252904812495} | train loss {'Reaction outcome loss': 0.30087384292763064, 'Total loss': 0.30087384292763064}
2023-01-04 11:45:34,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:34,381 INFO:     Epoch: 69
2023-01-04 11:45:35,954 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.31316307981808983, 'Total loss': 0.31316307981808983} | train loss {'Reaction outcome loss': 0.2989966841091898, 'Total loss': 0.2989966841091898}
2023-01-04 11:45:35,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:35,954 INFO:     Epoch: 70
2023-01-04 11:45:37,502 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.32501205106576286, 'Total loss': 0.32501205106576286} | train loss {'Reaction outcome loss': 0.29446408402957563, 'Total loss': 0.29446408402957563}
2023-01-04 11:45:37,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:37,502 INFO:     Epoch: 71
2023-01-04 11:45:39,061 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.32465304533640543, 'Total loss': 0.32465304533640543} | train loss {'Reaction outcome loss': 0.29468989528059086, 'Total loss': 0.29468989528059086}
2023-01-04 11:45:39,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:39,062 INFO:     Epoch: 72
2023-01-04 11:45:40,593 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3358673224846522, 'Total loss': 0.3358673224846522} | train loss {'Reaction outcome loss': 0.31292371357372706, 'Total loss': 0.31292371357372706}
2023-01-04 11:45:40,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:40,594 INFO:     Epoch: 73
2023-01-04 11:45:42,194 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3322354624668757, 'Total loss': 0.3322354624668757} | train loss {'Reaction outcome loss': 0.3171686509867077, 'Total loss': 0.3171686509867077}
2023-01-04 11:45:42,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:42,194 INFO:     Epoch: 74
2023-01-04 11:45:43,787 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3432287613550822, 'Total loss': 0.3432287613550822} | train loss {'Reaction outcome loss': 0.29291261546946457, 'Total loss': 0.29291261546946457}
2023-01-04 11:45:43,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:43,788 INFO:     Epoch: 75
2023-01-04 11:45:45,345 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3409961690505346, 'Total loss': 0.3409961690505346} | train loss {'Reaction outcome loss': 0.29176840994615055, 'Total loss': 0.29176840994615055}
2023-01-04 11:45:45,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:45,345 INFO:     Epoch: 76
2023-01-04 11:45:46,943 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3294829140106837, 'Total loss': 0.3294829140106837} | train loss {'Reaction outcome loss': 0.3090661688829246, 'Total loss': 0.3090661688829246}
2023-01-04 11:45:46,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:46,944 INFO:     Epoch: 77
2023-01-04 11:45:48,508 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3162335852781932, 'Total loss': 0.3162335852781932} | train loss {'Reaction outcome loss': 0.28991020403826545, 'Total loss': 0.28991020403826545}
2023-01-04 11:45:48,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:48,508 INFO:     Epoch: 78
2023-01-04 11:45:50,055 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3214930454889933, 'Total loss': 0.3214930454889933} | train loss {'Reaction outcome loss': 0.28587324200518616, 'Total loss': 0.28587324200518616}
2023-01-04 11:45:50,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:50,055 INFO:     Epoch: 79
2023-01-04 11:45:51,641 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.36029478212197624, 'Total loss': 0.36029478212197624} | train loss {'Reaction outcome loss': 0.28046948228797375, 'Total loss': 0.28046948228797375}
2023-01-04 11:45:51,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:51,641 INFO:     Epoch: 80
2023-01-04 11:45:53,215 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3214415321747462, 'Total loss': 0.3214415321747462} | train loss {'Reaction outcome loss': 0.28384724797249056, 'Total loss': 0.28384724797249056}
2023-01-04 11:45:53,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:53,215 INFO:     Epoch: 81
2023-01-04 11:45:54,758 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3013600250085195, 'Total loss': 0.3013600250085195} | train loss {'Reaction outcome loss': 0.2855995804382711, 'Total loss': 0.2855995804382711}
2023-01-04 11:45:54,758 INFO:     Found new best model at epoch 81
2023-01-04 11:45:54,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:54,759 INFO:     Epoch: 82
2023-01-04 11:45:56,335 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.31706902086734773, 'Total loss': 0.31706902086734773} | train loss {'Reaction outcome loss': 0.28135594212875253, 'Total loss': 0.28135594212875253}
2023-01-04 11:45:56,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:56,336 INFO:     Epoch: 83
2023-01-04 11:45:57,865 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3250900795062383, 'Total loss': 0.3250900795062383} | train loss {'Reaction outcome loss': 0.28291975319439516, 'Total loss': 0.28291975319439516}
2023-01-04 11:45:57,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:57,865 INFO:     Epoch: 84
2023-01-04 11:45:59,429 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3212144096692403, 'Total loss': 0.3212144096692403} | train loss {'Reaction outcome loss': 0.28072932522838423, 'Total loss': 0.28072932522838423}
2023-01-04 11:45:59,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:45:59,430 INFO:     Epoch: 85
2023-01-04 11:46:01,002 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.334839661916097, 'Total loss': 0.334839661916097} | train loss {'Reaction outcome loss': 0.27780972414378385, 'Total loss': 0.27780972414378385}
2023-01-04 11:46:01,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:01,002 INFO:     Epoch: 86
2023-01-04 11:46:02,580 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3306000153223673, 'Total loss': 0.3306000153223673} | train loss {'Reaction outcome loss': 0.27479939017798577, 'Total loss': 0.27479939017798577}
2023-01-04 11:46:02,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:02,581 INFO:     Epoch: 87
2023-01-04 11:46:04,121 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.34767712925871214, 'Total loss': 0.34767712925871214} | train loss {'Reaction outcome loss': 0.2901578923768323, 'Total loss': 0.2901578923768323}
2023-01-04 11:46:04,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:04,121 INFO:     Epoch: 88
2023-01-04 11:46:05,706 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.32928373515605924, 'Total loss': 0.32928373515605924} | train loss {'Reaction outcome loss': 0.30228079072844266, 'Total loss': 0.30228079072844266}
2023-01-04 11:46:05,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:05,706 INFO:     Epoch: 89
2023-01-04 11:46:07,243 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3064216693242391, 'Total loss': 0.3064216693242391} | train loss {'Reaction outcome loss': 0.2781976050329462, 'Total loss': 0.2781976050329462}
2023-01-04 11:46:07,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:07,243 INFO:     Epoch: 90
2023-01-04 11:46:08,808 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.30880670150121053, 'Total loss': 0.30880670150121053} | train loss {'Reaction outcome loss': 0.27819136330040434, 'Total loss': 0.27819136330040434}
2023-01-04 11:46:08,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:08,808 INFO:     Epoch: 91
2023-01-04 11:46:10,398 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3130060215791067, 'Total loss': 0.3130060215791067} | train loss {'Reaction outcome loss': 0.2742329362030748, 'Total loss': 0.2742329362030748}
2023-01-04 11:46:10,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:10,399 INFO:     Epoch: 92
2023-01-04 11:46:11,983 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3190514286359151, 'Total loss': 0.3190514286359151} | train loss {'Reaction outcome loss': 0.2706441382135803, 'Total loss': 0.2706441382135803}
2023-01-04 11:46:11,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:11,984 INFO:     Epoch: 93
2023-01-04 11:46:13,530 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.35584207574526466, 'Total loss': 0.35584207574526466} | train loss {'Reaction outcome loss': 0.26917807466056926, 'Total loss': 0.26917807466056926}
2023-01-04 11:46:13,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:13,530 INFO:     Epoch: 94
2023-01-04 11:46:15,105 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3158091532687346, 'Total loss': 0.3158091532687346} | train loss {'Reaction outcome loss': 0.26539046170723124, 'Total loss': 0.26539046170723124}
2023-01-04 11:46:15,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:15,106 INFO:     Epoch: 95
2023-01-04 11:46:16,649 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3453782727320989, 'Total loss': 0.3453782727320989} | train loss {'Reaction outcome loss': 0.26964758363538893, 'Total loss': 0.26964758363538893}
2023-01-04 11:46:16,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:16,649 INFO:     Epoch: 96
2023-01-04 11:46:18,211 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3139489064613978, 'Total loss': 0.3139489064613978} | train loss {'Reaction outcome loss': 0.26684365497962775, 'Total loss': 0.26684365497962775}
2023-01-04 11:46:18,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:18,211 INFO:     Epoch: 97
2023-01-04 11:46:19,781 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3167793144782384, 'Total loss': 0.3167793144782384} | train loss {'Reaction outcome loss': 0.26705057999002957, 'Total loss': 0.26705057999002957}
2023-01-04 11:46:19,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:19,781 INFO:     Epoch: 98
2023-01-04 11:46:21,373 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3590553939342499, 'Total loss': 0.3590553939342499} | train loss {'Reaction outcome loss': 0.2699715765463053, 'Total loss': 0.2699715765463053}
2023-01-04 11:46:21,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:21,373 INFO:     Epoch: 99
2023-01-04 11:46:22,923 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3489114095767339, 'Total loss': 0.3489114095767339} | train loss {'Reaction outcome loss': 0.28529866913036595, 'Total loss': 0.28529866913036595}
2023-01-04 11:46:22,923 INFO:     Best model found after epoch 82 of 100.
2023-01-04 11:46:22,923 INFO:   Done with stage: TRAINING
2023-01-04 11:46:22,923 INFO:   Starting stage: EVALUATION
2023-01-04 11:46:23,052 INFO:   Done with stage: EVALUATION
2023-01-04 11:46:23,052 INFO:   Leaving out SEQ value Fold_2
2023-01-04 11:46:23,065 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-04 11:46:23,065 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:46:23,705 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:46:23,705 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:46:23,773 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:46:23,773 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:46:23,773 INFO:     No hyperparam tuning for this model
2023-01-04 11:46:23,773 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:46:23,773 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:46:23,774 INFO:     None feature selector for col prot
2023-01-04 11:46:23,774 INFO:     None feature selector for col prot
2023-01-04 11:46:23,774 INFO:     None feature selector for col prot
2023-01-04 11:46:23,775 INFO:     None feature selector for col chem
2023-01-04 11:46:23,775 INFO:     None feature selector for col chem
2023-01-04 11:46:23,775 INFO:     None feature selector for col chem
2023-01-04 11:46:23,775 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:46:23,775 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:46:23,776 INFO:     Number of params in model 70111
2023-01-04 11:46:23,779 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:46:23,779 INFO:   Starting stage: TRAINING
2023-01-04 11:46:23,821 INFO:     Val loss before train {'Reaction outcome loss': 1.0412624796231589, 'Total loss': 1.0412624796231589}
2023-01-04 11:46:23,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:23,821 INFO:     Epoch: 0
2023-01-04 11:46:25,348 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7964090804258982, 'Total loss': 0.7964090804258982} | train loss {'Reaction outcome loss': 0.8465690235590143, 'Total loss': 0.8465690235590143}
2023-01-04 11:46:25,349 INFO:     Found new best model at epoch 0
2023-01-04 11:46:25,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:25,349 INFO:     Epoch: 1
2023-01-04 11:46:26,890 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6628786583741506, 'Total loss': 0.6628786583741506} | train loss {'Reaction outcome loss': 0.6913363283630667, 'Total loss': 0.6913363283630667}
2023-01-04 11:46:26,890 INFO:     Found new best model at epoch 1
2023-01-04 11:46:26,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:26,891 INFO:     Epoch: 2
2023-01-04 11:46:28,456 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5575172384579976, 'Total loss': 0.5575172384579976} | train loss {'Reaction outcome loss': 0.5904580626870434, 'Total loss': 0.5904580626870434}
2023-01-04 11:46:28,456 INFO:     Found new best model at epoch 2
2023-01-04 11:46:28,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:28,457 INFO:     Epoch: 3
2023-01-04 11:46:29,980 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5183775305747986, 'Total loss': 0.5183775305747986} | train loss {'Reaction outcome loss': 0.5511699661997411, 'Total loss': 0.5511699661997411}
2023-01-04 11:46:29,980 INFO:     Found new best model at epoch 3
2023-01-04 11:46:29,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:29,981 INFO:     Epoch: 4
2023-01-04 11:46:31,506 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5425224006175995, 'Total loss': 0.5425224006175995} | train loss {'Reaction outcome loss': 0.5225405685356183, 'Total loss': 0.5225405685356183}
2023-01-04 11:46:31,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:31,507 INFO:     Epoch: 5
2023-01-04 11:46:33,046 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5335496842861176, 'Total loss': 0.5335496842861176} | train loss {'Reaction outcome loss': 0.5091282144683753, 'Total loss': 0.5091282144683753}
2023-01-04 11:46:33,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:33,046 INFO:     Epoch: 6
2023-01-04 11:46:34,557 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5016595244407653, 'Total loss': 0.5016595244407653} | train loss {'Reaction outcome loss': 0.5014541758382453, 'Total loss': 0.5014541758382453}
2023-01-04 11:46:34,557 INFO:     Found new best model at epoch 6
2023-01-04 11:46:34,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:34,558 INFO:     Epoch: 7
2023-01-04 11:46:36,096 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.498346217473348, 'Total loss': 0.498346217473348} | train loss {'Reaction outcome loss': 0.490418742558613, 'Total loss': 0.490418742558613}
2023-01-04 11:46:36,096 INFO:     Found new best model at epoch 7
2023-01-04 11:46:36,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:36,097 INFO:     Epoch: 8
2023-01-04 11:46:37,658 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4838807463645935, 'Total loss': 0.4838807463645935} | train loss {'Reaction outcome loss': 0.4810687697241667, 'Total loss': 0.4810687697241667}
2023-01-04 11:46:37,658 INFO:     Found new best model at epoch 8
2023-01-04 11:46:37,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:37,659 INFO:     Epoch: 9
2023-01-04 11:46:39,171 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47899638414382933, 'Total loss': 0.47899638414382933} | train loss {'Reaction outcome loss': 0.47574389871636, 'Total loss': 0.47574389871636}
2023-01-04 11:46:39,171 INFO:     Found new best model at epoch 9
2023-01-04 11:46:39,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:39,172 INFO:     Epoch: 10
2023-01-04 11:46:40,689 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45561173955599465, 'Total loss': 0.45561173955599465} | train loss {'Reaction outcome loss': 0.46806837574362314, 'Total loss': 0.46806837574362314}
2023-01-04 11:46:40,689 INFO:     Found new best model at epoch 10
2023-01-04 11:46:40,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:40,690 INFO:     Epoch: 11
2023-01-04 11:46:42,221 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5086317559083303, 'Total loss': 0.5086317559083303} | train loss {'Reaction outcome loss': 0.4583533097787097, 'Total loss': 0.4583533097787097}
2023-01-04 11:46:42,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:42,222 INFO:     Epoch: 12
2023-01-04 11:46:43,723 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46638527115186057, 'Total loss': 0.46638527115186057} | train loss {'Reaction outcome loss': 0.4576062142738997, 'Total loss': 0.4576062142738997}
2023-01-04 11:46:43,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:43,724 INFO:     Epoch: 13
2023-01-04 11:46:45,252 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46788411140441893, 'Total loss': 0.46788411140441893} | train loss {'Reaction outcome loss': 0.4507957882766794, 'Total loss': 0.4507957882766794}
2023-01-04 11:46:45,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:45,252 INFO:     Epoch: 14
2023-01-04 11:46:46,796 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4675838162501653, 'Total loss': 0.4675838162501653} | train loss {'Reaction outcome loss': 0.44778768564282306, 'Total loss': 0.44778768564282306}
2023-01-04 11:46:46,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:46,796 INFO:     Epoch: 15
2023-01-04 11:46:48,326 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44675205449263256, 'Total loss': 0.44675205449263256} | train loss {'Reaction outcome loss': 0.44317663078818376, 'Total loss': 0.44317663078818376}
2023-01-04 11:46:48,326 INFO:     Found new best model at epoch 15
2023-01-04 11:46:48,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:48,327 INFO:     Epoch: 16
2023-01-04 11:46:49,851 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4748224308093389, 'Total loss': 0.4748224308093389} | train loss {'Reaction outcome loss': 0.43708767475237265, 'Total loss': 0.43708767475237265}
2023-01-04 11:46:49,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:49,851 INFO:     Epoch: 17
2023-01-04 11:46:51,372 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43239280929168067, 'Total loss': 0.43239280929168067} | train loss {'Reaction outcome loss': 0.4321151674893509, 'Total loss': 0.4321151674893509}
2023-01-04 11:46:51,372 INFO:     Found new best model at epoch 17
2023-01-04 11:46:51,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:51,373 INFO:     Epoch: 18
2023-01-04 11:46:52,887 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4369162937005361, 'Total loss': 0.4369162937005361} | train loss {'Reaction outcome loss': 0.4294190312223681, 'Total loss': 0.4294190312223681}
2023-01-04 11:46:52,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:52,887 INFO:     Epoch: 19
2023-01-04 11:46:54,416 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43574252327283225, 'Total loss': 0.43574252327283225} | train loss {'Reaction outcome loss': 0.42437962148462277, 'Total loss': 0.42437962148462277}
2023-01-04 11:46:54,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:54,416 INFO:     Epoch: 20
2023-01-04 11:46:55,954 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45575101176897687, 'Total loss': 0.45575101176897687} | train loss {'Reaction outcome loss': 0.41943577063919435, 'Total loss': 0.41943577063919435}
2023-01-04 11:46:55,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:55,954 INFO:     Epoch: 21
2023-01-04 11:46:57,461 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42401109139124554, 'Total loss': 0.42401109139124554} | train loss {'Reaction outcome loss': 0.41738209672739585, 'Total loss': 0.41738209672739585}
2023-01-04 11:46:57,461 INFO:     Found new best model at epoch 21
2023-01-04 11:46:57,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:57,462 INFO:     Epoch: 22
2023-01-04 11:46:59,004 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4220758030811946, 'Total loss': 0.4220758030811946} | train loss {'Reaction outcome loss': 0.41012337592145176, 'Total loss': 0.41012337592145176}
2023-01-04 11:46:59,004 INFO:     Found new best model at epoch 22
2023-01-04 11:46:59,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:46:59,005 INFO:     Epoch: 23
2023-01-04 11:47:00,539 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4280998637278875, 'Total loss': 0.4280998637278875} | train loss {'Reaction outcome loss': 0.4046423171004246, 'Total loss': 0.4046423171004246}
2023-01-04 11:47:00,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:00,539 INFO:     Epoch: 24
2023-01-04 11:47:02,059 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4306297858556112, 'Total loss': 0.4306297858556112} | train loss {'Reaction outcome loss': 0.4034967155254195, 'Total loss': 0.4034967155254195}
2023-01-04 11:47:02,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:02,060 INFO:     Epoch: 25
2023-01-04 11:47:03,606 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42980852723121643, 'Total loss': 0.42980852723121643} | train loss {'Reaction outcome loss': 0.3966708535197916, 'Total loss': 0.3966708535197916}
2023-01-04 11:47:03,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:03,607 INFO:     Epoch: 26
2023-01-04 11:47:05,153 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41798685789108275, 'Total loss': 0.41798685789108275} | train loss {'Reaction outcome loss': 0.3967133569651424, 'Total loss': 0.3967133569651424}
2023-01-04 11:47:05,153 INFO:     Found new best model at epoch 26
2023-01-04 11:47:05,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:05,154 INFO:     Epoch: 27
2023-01-04 11:47:06,663 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41756214797496793, 'Total loss': 0.41756214797496793} | train loss {'Reaction outcome loss': 0.3905645238572381, 'Total loss': 0.3905645238572381}
2023-01-04 11:47:06,663 INFO:     Found new best model at epoch 27
2023-01-04 11:47:06,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:06,664 INFO:     Epoch: 28
2023-01-04 11:47:08,196 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4012792229652405, 'Total loss': 0.4012792229652405} | train loss {'Reaction outcome loss': 0.3823829746334315, 'Total loss': 0.3823829746334315}
2023-01-04 11:47:08,197 INFO:     Found new best model at epoch 28
2023-01-04 11:47:08,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:08,197 INFO:     Epoch: 29
2023-01-04 11:47:09,733 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3889665752649307, 'Total loss': 0.3889665752649307} | train loss {'Reaction outcome loss': 0.3828983027006867, 'Total loss': 0.3828983027006867}
2023-01-04 11:47:09,733 INFO:     Found new best model at epoch 29
2023-01-04 11:47:09,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:09,734 INFO:     Epoch: 30
2023-01-04 11:47:11,225 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4094762593507767, 'Total loss': 0.4094762593507767} | train loss {'Reaction outcome loss': 0.376802136097447, 'Total loss': 0.376802136097447}
2023-01-04 11:47:11,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:11,225 INFO:     Epoch: 31
2023-01-04 11:47:12,737 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.385187562306722, 'Total loss': 0.385187562306722} | train loss {'Reaction outcome loss': 0.37556578463623885, 'Total loss': 0.37556578463623885}
2023-01-04 11:47:12,737 INFO:     Found new best model at epoch 31
2023-01-04 11:47:12,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:12,737 INFO:     Epoch: 32
2023-01-04 11:47:14,269 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4113659828901291, 'Total loss': 0.4113659828901291} | train loss {'Reaction outcome loss': 0.3724329307180489, 'Total loss': 0.3724329307180489}
2023-01-04 11:47:14,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:14,269 INFO:     Epoch: 33
2023-01-04 11:47:15,765 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40401833057403563, 'Total loss': 0.40401833057403563} | train loss {'Reaction outcome loss': 0.3725081415248973, 'Total loss': 0.3725081415248973}
2023-01-04 11:47:15,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:15,766 INFO:     Epoch: 34
2023-01-04 11:47:17,304 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38493573690454164, 'Total loss': 0.38493573690454164} | train loss {'Reaction outcome loss': 0.3626225745765925, 'Total loss': 0.3626225745765925}
2023-01-04 11:47:17,304 INFO:     Found new best model at epoch 34
2023-01-04 11:47:17,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:17,305 INFO:     Epoch: 35
2023-01-04 11:47:18,833 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3853503664334615, 'Total loss': 0.3853503664334615} | train loss {'Reaction outcome loss': 0.3600103093304317, 'Total loss': 0.3600103093304317}
2023-01-04 11:47:18,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:18,833 INFO:     Epoch: 36
2023-01-04 11:47:20,319 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40484147022167843, 'Total loss': 0.40484147022167843} | train loss {'Reaction outcome loss': 0.3564731654645772, 'Total loss': 0.3564731654645772}
2023-01-04 11:47:20,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:20,320 INFO:     Epoch: 37
2023-01-04 11:47:21,852 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38336567481358846, 'Total loss': 0.38336567481358846} | train loss {'Reaction outcome loss': 0.3570783352719902, 'Total loss': 0.3570783352719902}
2023-01-04 11:47:21,852 INFO:     Found new best model at epoch 37
2023-01-04 11:47:21,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:21,853 INFO:     Epoch: 38
2023-01-04 11:47:23,401 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.424686132868131, 'Total loss': 0.424686132868131} | train loss {'Reaction outcome loss': 0.3561031532188623, 'Total loss': 0.3561031532188623}
2023-01-04 11:47:23,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:23,401 INFO:     Epoch: 39
2023-01-04 11:47:24,913 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3972919483979543, 'Total loss': 0.3972919483979543} | train loss {'Reaction outcome loss': 0.35352621463941913, 'Total loss': 0.35352621463941913}
2023-01-04 11:47:24,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:24,913 INFO:     Epoch: 40
2023-01-04 11:47:26,438 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3734022264679273, 'Total loss': 0.3734022264679273} | train loss {'Reaction outcome loss': 0.34788744220324547, 'Total loss': 0.34788744220324547}
2023-01-04 11:47:26,438 INFO:     Found new best model at epoch 40
2023-01-04 11:47:26,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:26,439 INFO:     Epoch: 41
2023-01-04 11:47:27,970 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41072159906228384, 'Total loss': 0.41072159906228384} | train loss {'Reaction outcome loss': 0.3424926079067357, 'Total loss': 0.3424926079067357}
2023-01-04 11:47:27,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:27,970 INFO:     Epoch: 42
2023-01-04 11:47:29,486 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3919168084859848, 'Total loss': 0.3919168084859848} | train loss {'Reaction outcome loss': 0.3411586368765778, 'Total loss': 0.3411586368765778}
2023-01-04 11:47:29,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:29,486 INFO:     Epoch: 43
2023-01-04 11:47:31,020 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38738508423169454, 'Total loss': 0.38738508423169454} | train loss {'Reaction outcome loss': 0.3356284968747424, 'Total loss': 0.3356284968747424}
2023-01-04 11:47:31,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:31,021 INFO:     Epoch: 44
2023-01-04 11:47:32,561 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.37155400663614274, 'Total loss': 0.37155400663614274} | train loss {'Reaction outcome loss': 0.3341674155579722, 'Total loss': 0.3341674155579722}
2023-01-04 11:47:32,562 INFO:     Found new best model at epoch 44
2023-01-04 11:47:32,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:32,563 INFO:     Epoch: 45
2023-01-04 11:47:34,070 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3952541559934616, 'Total loss': 0.3952541559934616} | train loss {'Reaction outcome loss': 0.3313965292379425, 'Total loss': 0.3313965292379425}
2023-01-04 11:47:34,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:34,070 INFO:     Epoch: 46
2023-01-04 11:47:35,603 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.36949860205252966, 'Total loss': 0.36949860205252966} | train loss {'Reaction outcome loss': 0.3256882015629448, 'Total loss': 0.3256882015629448}
2023-01-04 11:47:35,603 INFO:     Found new best model at epoch 46
2023-01-04 11:47:35,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:35,604 INFO:     Epoch: 47
2023-01-04 11:47:37,137 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4177109142144521, 'Total loss': 0.4177109142144521} | train loss {'Reaction outcome loss': 0.3288570042025999, 'Total loss': 0.3288570042025999}
2023-01-04 11:47:37,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:37,137 INFO:     Epoch: 48
2023-01-04 11:47:38,665 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3712164198358854, 'Total loss': 0.3712164198358854} | train loss {'Reaction outcome loss': 0.3257231361806613, 'Total loss': 0.3257231361806613}
2023-01-04 11:47:38,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:38,666 INFO:     Epoch: 49
2023-01-04 11:47:40,212 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39354058702786765, 'Total loss': 0.39354058702786765} | train loss {'Reaction outcome loss': 0.32102788588877534, 'Total loss': 0.32102788588877534}
2023-01-04 11:47:40,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:40,212 INFO:     Epoch: 50
2023-01-04 11:47:41,768 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3769604062040647, 'Total loss': 0.3769604062040647} | train loss {'Reaction outcome loss': 0.3187746730017926, 'Total loss': 0.3187746730017926}
2023-01-04 11:47:41,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:41,768 INFO:     Epoch: 51
2023-01-04 11:47:43,271 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.387329238653183, 'Total loss': 0.387329238653183} | train loss {'Reaction outcome loss': 0.3217565123940306, 'Total loss': 0.3217565123940306}
2023-01-04 11:47:43,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:43,271 INFO:     Epoch: 52
2023-01-04 11:47:44,815 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3607838446895281, 'Total loss': 0.3607838446895281} | train loss {'Reaction outcome loss': 0.31357331420002826, 'Total loss': 0.31357331420002826}
2023-01-04 11:47:44,815 INFO:     Found new best model at epoch 52
2023-01-04 11:47:44,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:44,816 INFO:     Epoch: 53
2023-01-04 11:47:46,329 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39266226092974343, 'Total loss': 0.39266226092974343} | train loss {'Reaction outcome loss': 0.3131044569710524, 'Total loss': 0.3131044569710524}
2023-01-04 11:47:46,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:46,329 INFO:     Epoch: 54
2023-01-04 11:47:47,865 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4077777624130249, 'Total loss': 0.4077777624130249} | train loss {'Reaction outcome loss': 0.3159184114409549, 'Total loss': 0.3159184114409549}
2023-01-04 11:47:47,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:47,865 INFO:     Epoch: 55
2023-01-04 11:47:49,397 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41106873055299126, 'Total loss': 0.41106873055299126} | train loss {'Reaction outcome loss': 0.30800966658660406, 'Total loss': 0.30800966658660406}
2023-01-04 11:47:49,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:49,397 INFO:     Epoch: 56
2023-01-04 11:47:50,988 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40429263512293495, 'Total loss': 0.40429263512293495} | train loss {'Reaction outcome loss': 0.31250457784566493, 'Total loss': 0.31250457784566493}
2023-01-04 11:47:50,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:50,988 INFO:     Epoch: 57
2023-01-04 11:47:52,507 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3668690750996272, 'Total loss': 0.3668690750996272} | train loss {'Reaction outcome loss': 0.3062138284429413, 'Total loss': 0.3062138284429413}
2023-01-04 11:47:52,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:52,507 INFO:     Epoch: 58
2023-01-04 11:47:54,058 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3503118137518565, 'Total loss': 0.3503118137518565} | train loss {'Reaction outcome loss': 0.3074300825265941, 'Total loss': 0.3074300825265941}
2023-01-04 11:47:54,058 INFO:     Found new best model at epoch 58
2023-01-04 11:47:54,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:54,059 INFO:     Epoch: 59
2023-01-04 11:47:55,569 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4339125454425812, 'Total loss': 0.4339125454425812} | train loss {'Reaction outcome loss': 0.3014444501527561, 'Total loss': 0.3014444501527561}
2023-01-04 11:47:55,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:55,569 INFO:     Epoch: 60
2023-01-04 11:47:57,104 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3569683944185575, 'Total loss': 0.3569683944185575} | train loss {'Reaction outcome loss': 0.2954424803052441, 'Total loss': 0.2954424803052441}
2023-01-04 11:47:57,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:57,104 INFO:     Epoch: 61
2023-01-04 11:47:58,658 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37652116219202675, 'Total loss': 0.37652116219202675} | train loss {'Reaction outcome loss': 0.301436244699128, 'Total loss': 0.301436244699128}
2023-01-04 11:47:58,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:47:58,659 INFO:     Epoch: 62
2023-01-04 11:48:00,246 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3763960028688113, 'Total loss': 0.3763960028688113} | train loss {'Reaction outcome loss': 0.2939789534109985, 'Total loss': 0.2939789534109985}
2023-01-04 11:48:00,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:00,246 INFO:     Epoch: 63
2023-01-04 11:48:01,769 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39795384705066683, 'Total loss': 0.39795384705066683} | train loss {'Reaction outcome loss': 0.29143760171873545, 'Total loss': 0.29143760171873545}
2023-01-04 11:48:01,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:01,769 INFO:     Epoch: 64
2023-01-04 11:48:03,345 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42660577098528546, 'Total loss': 0.42660577098528546} | train loss {'Reaction outcome loss': 0.2942682358529075, 'Total loss': 0.2942682358529075}
2023-01-04 11:48:03,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:03,346 INFO:     Epoch: 65
2023-01-04 11:48:04,854 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3721544985969861, 'Total loss': 0.3721544985969861} | train loss {'Reaction outcome loss': 0.29329730699533024, 'Total loss': 0.29329730699533024}
2023-01-04 11:48:04,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:04,855 INFO:     Epoch: 66
2023-01-04 11:48:06,391 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.35744764109452565, 'Total loss': 0.35744764109452565} | train loss {'Reaction outcome loss': 0.2915526984527542, 'Total loss': 0.2915526984527542}
2023-01-04 11:48:06,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:06,391 INFO:     Epoch: 67
2023-01-04 11:48:07,926 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36935710310935976, 'Total loss': 0.36935710310935976} | train loss {'Reaction outcome loss': 0.28831843341738533, 'Total loss': 0.28831843341738533}
2023-01-04 11:48:07,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:07,926 INFO:     Epoch: 68
2023-01-04 11:48:09,480 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.367742391427358, 'Total loss': 0.367742391427358} | train loss {'Reaction outcome loss': 0.2867434703335991, 'Total loss': 0.2867434703335991}
2023-01-04 11:48:09,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:09,481 INFO:     Epoch: 69
2023-01-04 11:48:10,986 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3614347110191981, 'Total loss': 0.3614347110191981} | train loss {'Reaction outcome loss': 0.28592547317932454, 'Total loss': 0.28592547317932454}
2023-01-04 11:48:10,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:10,986 INFO:     Epoch: 70
2023-01-04 11:48:12,517 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38238254338502886, 'Total loss': 0.38238254338502886} | train loss {'Reaction outcome loss': 0.28186359171277925, 'Total loss': 0.28186359171277925}
2023-01-04 11:48:12,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:12,517 INFO:     Epoch: 71
2023-01-04 11:48:14,019 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.36568129776666564, 'Total loss': 0.36568129776666564} | train loss {'Reaction outcome loss': 0.28085125221207574, 'Total loss': 0.28085125221207574}
2023-01-04 11:48:14,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:14,019 INFO:     Epoch: 72
2023-01-04 11:48:15,551 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3882263958454132, 'Total loss': 0.3882263958454132} | train loss {'Reaction outcome loss': 0.2861521281164511, 'Total loss': 0.2861521281164511}
2023-01-04 11:48:15,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:15,552 INFO:     Epoch: 73
2023-01-04 11:48:17,154 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3837205708026886, 'Total loss': 0.3837205708026886} | train loss {'Reaction outcome loss': 0.28093063990788264, 'Total loss': 0.28093063990788264}
2023-01-04 11:48:17,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:17,155 INFO:     Epoch: 74
2023-01-04 11:48:18,759 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.36581703225771584, 'Total loss': 0.36581703225771584} | train loss {'Reaction outcome loss': 0.2788890605703051, 'Total loss': 0.2788890605703051}
2023-01-04 11:48:18,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:18,759 INFO:     Epoch: 75
2023-01-04 11:48:20,265 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4238957519332568, 'Total loss': 0.4238957519332568} | train loss {'Reaction outcome loss': 0.2787165632162147, 'Total loss': 0.2787165632162147}
2023-01-04 11:48:20,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:20,265 INFO:     Epoch: 76
2023-01-04 11:48:21,801 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3749853531519572, 'Total loss': 0.3749853531519572} | train loss {'Reaction outcome loss': 0.27966982951023484, 'Total loss': 0.27966982951023484}
2023-01-04 11:48:21,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:21,802 INFO:     Epoch: 77
2023-01-04 11:48:23,311 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3886111487944921, 'Total loss': 0.3886111487944921} | train loss {'Reaction outcome loss': 0.27315092347974707, 'Total loss': 0.27315092347974707}
2023-01-04 11:48:23,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:23,311 INFO:     Epoch: 78
2023-01-04 11:48:24,874 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40366414686044055, 'Total loss': 0.40366414686044055} | train loss {'Reaction outcome loss': 0.27212467865255485, 'Total loss': 0.27212467865255485}
2023-01-04 11:48:24,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:24,875 INFO:     Epoch: 79
2023-01-04 11:48:26,400 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39478640456994374, 'Total loss': 0.39478640456994374} | train loss {'Reaction outcome loss': 0.2733406373660503, 'Total loss': 0.2733406373660503}
2023-01-04 11:48:26,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:26,401 INFO:     Epoch: 80
2023-01-04 11:48:27,925 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40046632289886475, 'Total loss': 0.40046632289886475} | train loss {'Reaction outcome loss': 0.27250423656288547, 'Total loss': 0.27250423656288547}
2023-01-04 11:48:27,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:27,926 INFO:     Epoch: 81
2023-01-04 11:48:29,433 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.35909040793776514, 'Total loss': 0.35909040793776514} | train loss {'Reaction outcome loss': 0.268597123037845, 'Total loss': 0.268597123037845}
2023-01-04 11:48:29,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:29,434 INFO:     Epoch: 82
2023-01-04 11:48:30,973 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39070538282394407, 'Total loss': 0.39070538282394407} | train loss {'Reaction outcome loss': 0.27141817371838645, 'Total loss': 0.27141817371838645}
2023-01-04 11:48:30,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:30,973 INFO:     Epoch: 83
2023-01-04 11:48:32,481 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.366772190729777, 'Total loss': 0.366772190729777} | train loss {'Reaction outcome loss': 0.2679007827575796, 'Total loss': 0.2679007827575796}
2023-01-04 11:48:32,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:32,482 INFO:     Epoch: 84
2023-01-04 11:48:34,008 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.374770487844944, 'Total loss': 0.374770487844944} | train loss {'Reaction outcome loss': 0.2684905244607987, 'Total loss': 0.2684905244607987}
2023-01-04 11:48:34,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:34,009 INFO:     Epoch: 85
2023-01-04 11:48:35,544 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3829624613126119, 'Total loss': 0.3829624613126119} | train loss {'Reaction outcome loss': 0.26803338773741053, 'Total loss': 0.26803338773741053}
2023-01-04 11:48:35,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:35,544 INFO:     Epoch: 86
2023-01-04 11:48:37,076 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3916756441195806, 'Total loss': 0.3916756441195806} | train loss {'Reaction outcome loss': 0.2637897632823659, 'Total loss': 0.2637897632823659}
2023-01-04 11:48:37,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:37,077 INFO:     Epoch: 87
2023-01-04 11:48:38,592 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3626891866326332, 'Total loss': 0.3626891866326332} | train loss {'Reaction outcome loss': 0.27159219330032375, 'Total loss': 0.27159219330032375}
2023-01-04 11:48:38,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:38,592 INFO:     Epoch: 88
2023-01-04 11:48:40,127 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3658425917228063, 'Total loss': 0.3658425917228063} | train loss {'Reaction outcome loss': 0.2674830992228431, 'Total loss': 0.2674830992228431}
2023-01-04 11:48:40,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:40,128 INFO:     Epoch: 89
2023-01-04 11:48:41,648 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3914891680081685, 'Total loss': 0.3914891680081685} | train loss {'Reaction outcome loss': 0.2641716933503362, 'Total loss': 0.2641716933503362}
2023-01-04 11:48:41,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:41,648 INFO:     Epoch: 90
2023-01-04 11:48:43,192 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42070720593134564, 'Total loss': 0.42070720593134564} | train loss {'Reaction outcome loss': 0.26133626159211804, 'Total loss': 0.26133626159211804}
2023-01-04 11:48:43,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:43,192 INFO:     Epoch: 91
2023-01-04 11:48:44,750 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3730927069981893, 'Total loss': 0.3730927069981893} | train loss {'Reaction outcome loss': 0.2621441692168862, 'Total loss': 0.2621441692168862}
2023-01-04 11:48:44,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:44,750 INFO:     Epoch: 92
2023-01-04 11:48:46,281 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3753454109032949, 'Total loss': 0.3753454109032949} | train loss {'Reaction outcome loss': 0.26119650692792395, 'Total loss': 0.26119650692792395}
2023-01-04 11:48:46,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:46,281 INFO:     Epoch: 93
2023-01-04 11:48:47,827 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37828629910945893, 'Total loss': 0.37828629910945893} | train loss {'Reaction outcome loss': 0.25723171884338353, 'Total loss': 0.25723171884338353}
2023-01-04 11:48:47,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:47,827 INFO:     Epoch: 94
2023-01-04 11:48:49,371 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3771903832753499, 'Total loss': 0.3771903832753499} | train loss {'Reaction outcome loss': 0.2581038162442151, 'Total loss': 0.2581038162442151}
2023-01-04 11:48:49,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:49,371 INFO:     Epoch: 95
2023-01-04 11:48:50,892 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39488593141237893, 'Total loss': 0.39488593141237893} | train loss {'Reaction outcome loss': 0.2592975580136934, 'Total loss': 0.2592975580136934}
2023-01-04 11:48:50,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:50,892 INFO:     Epoch: 96
2023-01-04 11:48:52,447 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40023965338865913, 'Total loss': 0.40023965338865913} | train loss {'Reaction outcome loss': 0.2549226717865335, 'Total loss': 0.2549226717865335}
2023-01-04 11:48:52,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:52,447 INFO:     Epoch: 97
2023-01-04 11:48:53,974 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4011998146772385, 'Total loss': 0.4011998146772385} | train loss {'Reaction outcome loss': 0.2546525419968081, 'Total loss': 0.2546525419968081}
2023-01-04 11:48:53,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:53,975 INFO:     Epoch: 98
2023-01-04 11:48:55,483 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.36997388303279877, 'Total loss': 0.36997388303279877} | train loss {'Reaction outcome loss': 0.2589161024322369, 'Total loss': 0.2589161024322369}
2023-01-04 11:48:55,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:55,483 INFO:     Epoch: 99
2023-01-04 11:48:57,028 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3925826812783877, 'Total loss': 0.3925826812783877} | train loss {'Reaction outcome loss': 0.2527530813569072, 'Total loss': 0.2527530813569072}
2023-01-04 11:48:57,028 INFO:     Best model found after epoch 59 of 100.
2023-01-04 11:48:57,028 INFO:   Done with stage: TRAINING
2023-01-04 11:48:57,028 INFO:   Starting stage: EVALUATION
2023-01-04 11:48:57,175 INFO:   Done with stage: EVALUATION
2023-01-04 11:48:57,175 INFO:   Leaving out SEQ value Fold_3
2023-01-04 11:48:57,188 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-04 11:48:57,188 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:48:57,827 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:48:57,827 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:48:57,893 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:48:57,894 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:48:57,894 INFO:     No hyperparam tuning for this model
2023-01-04 11:48:57,894 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:48:57,894 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:48:57,894 INFO:     None feature selector for col prot
2023-01-04 11:48:57,895 INFO:     None feature selector for col prot
2023-01-04 11:48:57,895 INFO:     None feature selector for col prot
2023-01-04 11:48:57,895 INFO:     None feature selector for col chem
2023-01-04 11:48:57,895 INFO:     None feature selector for col chem
2023-01-04 11:48:57,895 INFO:     None feature selector for col chem
2023-01-04 11:48:57,895 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:48:57,895 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:48:57,896 INFO:     Number of params in model 70111
2023-01-04 11:48:57,900 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:48:57,900 INFO:   Starting stage: TRAINING
2023-01-04 11:48:57,941 INFO:     Val loss before train {'Reaction outcome loss': 1.0136445085207622, 'Total loss': 1.0136445085207622}
2023-01-04 11:48:57,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:57,941 INFO:     Epoch: 0
2023-01-04 11:48:59,452 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7596240937709808, 'Total loss': 0.7596240937709808} | train loss {'Reaction outcome loss': 0.8231343100211717, 'Total loss': 0.8231343100211717}
2023-01-04 11:48:59,452 INFO:     Found new best model at epoch 0
2023-01-04 11:48:59,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:48:59,453 INFO:     Epoch: 1
2023-01-04 11:49:01,007 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6281102538108826, 'Total loss': 0.6281102538108826} | train loss {'Reaction outcome loss': 0.6642924317354646, 'Total loss': 0.6642924317354646}
2023-01-04 11:49:01,007 INFO:     Found new best model at epoch 1
2023-01-04 11:49:01,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:01,008 INFO:     Epoch: 2
2023-01-04 11:49:02,572 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5690297563870748, 'Total loss': 0.5690297563870748} | train loss {'Reaction outcome loss': 0.5863388656910056, 'Total loss': 0.5863388656910056}
2023-01-04 11:49:02,572 INFO:     Found new best model at epoch 2
2023-01-04 11:49:02,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:02,573 INFO:     Epoch: 3
2023-01-04 11:49:04,098 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5391827940940856, 'Total loss': 0.5391827940940856} | train loss {'Reaction outcome loss': 0.5418192483072352, 'Total loss': 0.5418192483072352}
2023-01-04 11:49:04,099 INFO:     Found new best model at epoch 3
2023-01-04 11:49:04,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:04,099 INFO:     Epoch: 4
2023-01-04 11:49:05,641 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5340215543905894, 'Total loss': 0.5340215543905894} | train loss {'Reaction outcome loss': 0.5209901511009329, 'Total loss': 0.5209901511009329}
2023-01-04 11:49:05,642 INFO:     Found new best model at epoch 4
2023-01-04 11:49:05,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:05,643 INFO:     Epoch: 5
2023-01-04 11:49:07,188 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5237717151641845, 'Total loss': 0.5237717151641845} | train loss {'Reaction outcome loss': 0.5046672410850596, 'Total loss': 0.5046672410850596}
2023-01-04 11:49:07,188 INFO:     Found new best model at epoch 5
2023-01-04 11:49:07,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:07,189 INFO:     Epoch: 6
2023-01-04 11:49:08,705 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48992250164349876, 'Total loss': 0.48992250164349876} | train loss {'Reaction outcome loss': 0.49275163789296944, 'Total loss': 0.49275163789296944}
2023-01-04 11:49:08,706 INFO:     Found new best model at epoch 6
2023-01-04 11:49:08,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:08,706 INFO:     Epoch: 7
2023-01-04 11:49:10,239 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49668570756912234, 'Total loss': 0.49668570756912234} | train loss {'Reaction outcome loss': 0.4803893289002985, 'Total loss': 0.4803893289002985}
2023-01-04 11:49:10,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:10,239 INFO:     Epoch: 8
2023-01-04 11:49:11,779 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4798050870498021, 'Total loss': 0.4798050870498021} | train loss {'Reaction outcome loss': 0.47059951205755074, 'Total loss': 0.47059951205755074}
2023-01-04 11:49:11,780 INFO:     Found new best model at epoch 8
2023-01-04 11:49:11,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:11,781 INFO:     Epoch: 9
2023-01-04 11:49:13,282 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4910481830437978, 'Total loss': 0.4910481830437978} | train loss {'Reaction outcome loss': 0.46253451237599347, 'Total loss': 0.46253451237599347}
2023-01-04 11:49:13,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:13,282 INFO:     Epoch: 10
2023-01-04 11:49:14,813 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46704491786658764, 'Total loss': 0.46704491786658764} | train loss {'Reaction outcome loss': 0.45973233378241424, 'Total loss': 0.45973233378241424}
2023-01-04 11:49:14,813 INFO:     Found new best model at epoch 10
2023-01-04 11:49:14,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:14,814 INFO:     Epoch: 11
2023-01-04 11:49:16,337 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46466406136751176, 'Total loss': 0.46466406136751176} | train loss {'Reaction outcome loss': 0.4530041195809621, 'Total loss': 0.4530041195809621}
2023-01-04 11:49:16,337 INFO:     Found new best model at epoch 11
2023-01-04 11:49:16,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:16,338 INFO:     Epoch: 12
2023-01-04 11:49:17,865 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47726831237475076, 'Total loss': 0.47726831237475076} | train loss {'Reaction outcome loss': 0.4497571360471064, 'Total loss': 0.4497571360471064}
2023-01-04 11:49:17,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:17,866 INFO:     Epoch: 13
2023-01-04 11:49:19,408 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.474274210135142, 'Total loss': 0.474274210135142} | train loss {'Reaction outcome loss': 0.4439583415254896, 'Total loss': 0.4439583415254896}
2023-01-04 11:49:19,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:19,409 INFO:     Epoch: 14
2023-01-04 11:49:20,964 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.506538591782252, 'Total loss': 0.506538591782252} | train loss {'Reaction outcome loss': 0.44044895563618286, 'Total loss': 0.44044895563618286}
2023-01-04 11:49:20,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:20,964 INFO:     Epoch: 15
2023-01-04 11:49:22,478 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4654365360736847, 'Total loss': 0.4654365360736847} | train loss {'Reaction outcome loss': 0.4355048089119781, 'Total loss': 0.4355048089119781}
2023-01-04 11:49:22,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:22,479 INFO:     Epoch: 16
2023-01-04 11:49:24,029 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45884755353132883, 'Total loss': 0.45884755353132883} | train loss {'Reaction outcome loss': 0.4294529624860665, 'Total loss': 0.4294529624860665}
2023-01-04 11:49:24,030 INFO:     Found new best model at epoch 16
2023-01-04 11:49:24,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:24,030 INFO:     Epoch: 17
2023-01-04 11:49:25,555 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4646355390548706, 'Total loss': 0.4646355390548706} | train loss {'Reaction outcome loss': 0.426405145783266, 'Total loss': 0.426405145783266}
2023-01-04 11:49:25,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:25,555 INFO:     Epoch: 18
2023-01-04 11:49:27,090 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4645965377489726, 'Total loss': 0.4645965377489726} | train loss {'Reaction outcome loss': 0.42863199125796664, 'Total loss': 0.42863199125796664}
2023-01-04 11:49:27,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:27,090 INFO:     Epoch: 19
2023-01-04 11:49:28,641 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42478001515070596, 'Total loss': 0.42478001515070596} | train loss {'Reaction outcome loss': 0.41869119128617854, 'Total loss': 0.41869119128617854}
2023-01-04 11:49:28,641 INFO:     Found new best model at epoch 19
2023-01-04 11:49:28,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:28,642 INFO:     Epoch: 20
2023-01-04 11:49:30,199 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4379613647858302, 'Total loss': 0.4379613647858302} | train loss {'Reaction outcome loss': 0.4113345600362194, 'Total loss': 0.4113345600362194}
2023-01-04 11:49:30,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:30,199 INFO:     Epoch: 21
2023-01-04 11:49:31,710 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42734026511510215, 'Total loss': 0.42734026511510215} | train loss {'Reaction outcome loss': 0.41590721047452456, 'Total loss': 0.41590721047452456}
2023-01-04 11:49:31,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:31,710 INFO:     Epoch: 22
2023-01-04 11:49:33,258 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43588039676348367, 'Total loss': 0.43588039676348367} | train loss {'Reaction outcome loss': 0.40800618613997947, 'Total loss': 0.40800618613997947}
2023-01-04 11:49:33,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:33,258 INFO:     Epoch: 23
2023-01-04 11:49:34,755 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4487696508566538, 'Total loss': 0.4487696508566538} | train loss {'Reaction outcome loss': 0.40755007105339935, 'Total loss': 0.40755007105339935}
2023-01-04 11:49:34,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:34,755 INFO:     Epoch: 24
2023-01-04 11:49:36,298 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45087387760480246, 'Total loss': 0.45087387760480246} | train loss {'Reaction outcome loss': 0.4007851981808779, 'Total loss': 0.4007851981808779}
2023-01-04 11:49:36,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:36,299 INFO:     Epoch: 25
2023-01-04 11:49:37,848 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42848929663499197, 'Total loss': 0.42848929663499197} | train loss {'Reaction outcome loss': 0.3979761599944526, 'Total loss': 0.3979761599944526}
2023-01-04 11:49:37,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:37,848 INFO:     Epoch: 26
2023-01-04 11:49:39,400 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4897297630707423, 'Total loss': 0.4897297630707423} | train loss {'Reaction outcome loss': 0.39237751088679057, 'Total loss': 0.39237751088679057}
2023-01-04 11:49:39,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:39,400 INFO:     Epoch: 27
2023-01-04 11:49:40,917 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43680766423543294, 'Total loss': 0.43680766423543294} | train loss {'Reaction outcome loss': 0.3893154600009707, 'Total loss': 0.3893154600009707}
2023-01-04 11:49:40,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:40,919 INFO:     Epoch: 28
2023-01-04 11:49:42,458 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41709920863310496, 'Total loss': 0.41709920863310496} | train loss {'Reaction outcome loss': 0.3860607333068918, 'Total loss': 0.3860607333068918}
2023-01-04 11:49:42,458 INFO:     Found new best model at epoch 28
2023-01-04 11:49:42,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:42,459 INFO:     Epoch: 29
2023-01-04 11:49:43,973 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41526162723700205, 'Total loss': 0.41526162723700205} | train loss {'Reaction outcome loss': 0.38605212183786053, 'Total loss': 0.38605212183786053}
2023-01-04 11:49:43,973 INFO:     Found new best model at epoch 29
2023-01-04 11:49:43,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:43,974 INFO:     Epoch: 30
2023-01-04 11:49:45,518 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41909281611442567, 'Total loss': 0.41909281611442567} | train loss {'Reaction outcome loss': 0.3830863205214268, 'Total loss': 0.3830863205214268}
2023-01-04 11:49:45,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:45,518 INFO:     Epoch: 31
2023-01-04 11:49:47,061 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4152468790610631, 'Total loss': 0.4152468790610631} | train loss {'Reaction outcome loss': 0.3743024831603374, 'Total loss': 0.3743024831603374}
2023-01-04 11:49:47,062 INFO:     Found new best model at epoch 31
2023-01-04 11:49:47,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:47,063 INFO:     Epoch: 32
2023-01-04 11:49:48,619 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4595958948135376, 'Total loss': 0.4595958948135376} | train loss {'Reaction outcome loss': 0.3767152924599243, 'Total loss': 0.3767152924599243}
2023-01-04 11:49:48,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:48,620 INFO:     Epoch: 33
2023-01-04 11:49:50,149 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4062369113167127, 'Total loss': 0.4062369113167127} | train loss {'Reaction outcome loss': 0.371226121001358, 'Total loss': 0.371226121001358}
2023-01-04 11:49:50,149 INFO:     Found new best model at epoch 33
2023-01-04 11:49:50,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:50,150 INFO:     Epoch: 34
2023-01-04 11:49:51,690 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42612701157728833, 'Total loss': 0.42612701157728833} | train loss {'Reaction outcome loss': 0.36753550985642464, 'Total loss': 0.36753550985642464}
2023-01-04 11:49:51,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:51,690 INFO:     Epoch: 35
2023-01-04 11:49:53,195 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3962605287631353, 'Total loss': 0.3962605287631353} | train loss {'Reaction outcome loss': 0.36603445067616847, 'Total loss': 0.36603445067616847}
2023-01-04 11:49:53,195 INFO:     Found new best model at epoch 35
2023-01-04 11:49:53,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:53,196 INFO:     Epoch: 36
2023-01-04 11:49:54,743 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4427922487258911, 'Total loss': 0.4427922487258911} | train loss {'Reaction outcome loss': 0.3604361833626494, 'Total loss': 0.3604361833626494}
2023-01-04 11:49:54,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:54,744 INFO:     Epoch: 37
2023-01-04 11:49:56,287 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4268593450387319, 'Total loss': 0.4268593450387319} | train loss {'Reaction outcome loss': 0.3584291387308128, 'Total loss': 0.3584291387308128}
2023-01-04 11:49:56,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:56,287 INFO:     Epoch: 38
2023-01-04 11:49:57,829 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41412142515182493, 'Total loss': 0.41412142515182493} | train loss {'Reaction outcome loss': 0.35599615982977667, 'Total loss': 0.35599615982977667}
2023-01-04 11:49:57,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:57,830 INFO:     Epoch: 39
2023-01-04 11:49:59,345 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4226487874984741, 'Total loss': 0.4226487874984741} | train loss {'Reaction outcome loss': 0.351957697201369, 'Total loss': 0.351957697201369}
2023-01-04 11:49:59,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:49:59,346 INFO:     Epoch: 40
2023-01-04 11:50:00,891 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4073688377936681, 'Total loss': 0.4073688377936681} | train loss {'Reaction outcome loss': 0.35365124797359165, 'Total loss': 0.35365124797359165}
2023-01-04 11:50:00,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:00,892 INFO:     Epoch: 41
2023-01-04 11:50:02,410 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.404171750942866, 'Total loss': 0.404171750942866} | train loss {'Reaction outcome loss': 0.3462538726875263, 'Total loss': 0.3462538726875263}
2023-01-04 11:50:02,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:02,410 INFO:     Epoch: 42
2023-01-04 11:50:03,954 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43052344421545663, 'Total loss': 0.43052344421545663} | train loss {'Reaction outcome loss': 0.3462043461764431, 'Total loss': 0.3462043461764431}
2023-01-04 11:50:03,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:03,954 INFO:     Epoch: 43
2023-01-04 11:50:05,502 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39583958784739176, 'Total loss': 0.39583958784739176} | train loss {'Reaction outcome loss': 0.3405986884643231, 'Total loss': 0.3405986884643231}
2023-01-04 11:50:05,502 INFO:     Found new best model at epoch 43
2023-01-04 11:50:05,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:05,503 INFO:     Epoch: 44
2023-01-04 11:50:07,049 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38874680499235786, 'Total loss': 0.38874680499235786} | train loss {'Reaction outcome loss': 0.3443345715089038, 'Total loss': 0.3443345715089038}
2023-01-04 11:50:07,049 INFO:     Found new best model at epoch 44
2023-01-04 11:50:07,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:07,049 INFO:     Epoch: 45
2023-01-04 11:50:08,557 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39095278481642404, 'Total loss': 0.39095278481642404} | train loss {'Reaction outcome loss': 0.33746710675338976, 'Total loss': 0.33746710675338976}
2023-01-04 11:50:08,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:08,557 INFO:     Epoch: 46
2023-01-04 11:50:10,109 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41344649692376456, 'Total loss': 0.41344649692376456} | train loss {'Reaction outcome loss': 0.3388114953722901, 'Total loss': 0.3388114953722901}
2023-01-04 11:50:10,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:10,109 INFO:     Epoch: 47
2023-01-04 11:50:11,624 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3975630521774292, 'Total loss': 0.3975630521774292} | train loss {'Reaction outcome loss': 0.33536581312928254, 'Total loss': 0.33536581312928254}
2023-01-04 11:50:11,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:11,625 INFO:     Epoch: 48
2023-01-04 11:50:13,174 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.391444227596124, 'Total loss': 0.391444227596124} | train loss {'Reaction outcome loss': 0.3364495710638176, 'Total loss': 0.3364495710638176}
2023-01-04 11:50:13,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:13,174 INFO:     Epoch: 49
2023-01-04 11:50:14,712 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38329678525527316, 'Total loss': 0.38329678525527316} | train loss {'Reaction outcome loss': 0.32774584781639693, 'Total loss': 0.32774584781639693}
2023-01-04 11:50:14,712 INFO:     Found new best model at epoch 49
2023-01-04 11:50:14,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:14,713 INFO:     Epoch: 50
2023-01-04 11:50:16,257 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39745774666468303, 'Total loss': 0.39745774666468303} | train loss {'Reaction outcome loss': 0.3268438610368549, 'Total loss': 0.3268438610368549}
2023-01-04 11:50:16,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:16,258 INFO:     Epoch: 51
2023-01-04 11:50:17,743 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43014147182305656, 'Total loss': 0.43014147182305656} | train loss {'Reaction outcome loss': 0.32539135979220435, 'Total loss': 0.32539135979220435}
2023-01-04 11:50:17,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:17,744 INFO:     Epoch: 52
2023-01-04 11:50:19,276 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3805191179116567, 'Total loss': 0.3805191179116567} | train loss {'Reaction outcome loss': 0.3206617556429877, 'Total loss': 0.3206617556429877}
2023-01-04 11:50:19,276 INFO:     Found new best model at epoch 52
2023-01-04 11:50:19,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:19,277 INFO:     Epoch: 53
2023-01-04 11:50:20,768 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38367917637030285, 'Total loss': 0.38367917637030285} | train loss {'Reaction outcome loss': 0.32499503366291743, 'Total loss': 0.32499503366291743}
2023-01-04 11:50:20,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:20,768 INFO:     Epoch: 54
2023-01-04 11:50:22,293 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38807702511548997, 'Total loss': 0.38807702511548997} | train loss {'Reaction outcome loss': 0.3190303363895724, 'Total loss': 0.3190303363895724}
2023-01-04 11:50:22,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:22,293 INFO:     Epoch: 55
2023-01-04 11:50:23,820 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40438155134518944, 'Total loss': 0.40438155134518944} | train loss {'Reaction outcome loss': 0.31929714900761075, 'Total loss': 0.31929714900761075}
2023-01-04 11:50:23,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:23,820 INFO:     Epoch: 56
2023-01-04 11:50:25,352 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.431643216808637, 'Total loss': 0.431643216808637} | train loss {'Reaction outcome loss': 0.31553282959874707, 'Total loss': 0.31553282959874707}
2023-01-04 11:50:25,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:25,352 INFO:     Epoch: 57
2023-01-04 11:50:26,853 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3837790578603745, 'Total loss': 0.3837790578603745} | train loss {'Reaction outcome loss': 0.31192291222815144, 'Total loss': 0.31192291222815144}
2023-01-04 11:50:26,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:26,853 INFO:     Epoch: 58
2023-01-04 11:50:28,386 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4079766899347305, 'Total loss': 0.4079766899347305} | train loss {'Reaction outcome loss': 0.31072052988838883, 'Total loss': 0.31072052988838883}
2023-01-04 11:50:28,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:28,386 INFO:     Epoch: 59
2023-01-04 11:50:29,894 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38572523593902586, 'Total loss': 0.38572523593902586} | train loss {'Reaction outcome loss': 0.3145170248357572, 'Total loss': 0.3145170248357572}
2023-01-04 11:50:29,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:29,895 INFO:     Epoch: 60
2023-01-04 11:50:31,434 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40560697416464486, 'Total loss': 0.40560697416464486} | train loss {'Reaction outcome loss': 0.3042166831858484, 'Total loss': 0.3042166831858484}
2023-01-04 11:50:31,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:31,434 INFO:     Epoch: 61
2023-01-04 11:50:32,962 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.36462690830230715, 'Total loss': 0.36462690830230715} | train loss {'Reaction outcome loss': 0.3066636490260983, 'Total loss': 0.3066636490260983}
2023-01-04 11:50:32,962 INFO:     Found new best model at epoch 61
2023-01-04 11:50:32,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:32,963 INFO:     Epoch: 62
2023-01-04 11:50:34,497 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3866848945617676, 'Total loss': 0.3866848945617676} | train loss {'Reaction outcome loss': 0.304766190612888, 'Total loss': 0.304766190612888}
2023-01-04 11:50:34,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:34,497 INFO:     Epoch: 63
2023-01-04 11:50:36,007 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4081708590189616, 'Total loss': 0.4081708590189616} | train loss {'Reaction outcome loss': 0.30029054439705677, 'Total loss': 0.30029054439705677}
2023-01-04 11:50:36,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:36,007 INFO:     Epoch: 64
2023-01-04 11:50:37,543 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.394603556394577, 'Total loss': 0.394603556394577} | train loss {'Reaction outcome loss': 0.30230130171368924, 'Total loss': 0.30230130171368924}
2023-01-04 11:50:37,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:37,543 INFO:     Epoch: 65
2023-01-04 11:50:39,041 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40409509936968485, 'Total loss': 0.40409509936968485} | train loss {'Reaction outcome loss': 0.29909550211636343, 'Total loss': 0.29909550211636343}
2023-01-04 11:50:39,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:39,042 INFO:     Epoch: 66
2023-01-04 11:50:40,583 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4123191068569819, 'Total loss': 0.4123191068569819} | train loss {'Reaction outcome loss': 0.29946613784645754, 'Total loss': 0.29946613784645754}
2023-01-04 11:50:40,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:40,583 INFO:     Epoch: 67
2023-01-04 11:50:42,107 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40526192386945087, 'Total loss': 0.40526192386945087} | train loss {'Reaction outcome loss': 0.2989810227083104, 'Total loss': 0.2989810227083104}
2023-01-04 11:50:42,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:42,109 INFO:     Epoch: 68
2023-01-04 11:50:43,647 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4150020956993103, 'Total loss': 0.4150020956993103} | train loss {'Reaction outcome loss': 0.29601220407169243, 'Total loss': 0.29601220407169243}
2023-01-04 11:50:43,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:43,647 INFO:     Epoch: 69
2023-01-04 11:50:45,146 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40246535936991373, 'Total loss': 0.40246535936991373} | train loss {'Reaction outcome loss': 0.2922056957364522, 'Total loss': 0.2922056957364522}
2023-01-04 11:50:45,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:45,146 INFO:     Epoch: 70
2023-01-04 11:50:46,668 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40635423064231874, 'Total loss': 0.40635423064231874} | train loss {'Reaction outcome loss': 0.29510967139278393, 'Total loss': 0.29510967139278393}
2023-01-04 11:50:46,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:46,669 INFO:     Epoch: 71
2023-01-04 11:50:48,201 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4126992483933767, 'Total loss': 0.4126992483933767} | train loss {'Reaction outcome loss': 0.2908570443957054, 'Total loss': 0.2908570443957054}
2023-01-04 11:50:48,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:48,202 INFO:     Epoch: 72
2023-01-04 11:50:49,794 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40181879202524823, 'Total loss': 0.40181879202524823} | train loss {'Reaction outcome loss': 0.2904878553979071, 'Total loss': 0.2904878553979071}
2023-01-04 11:50:49,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:49,794 INFO:     Epoch: 73
2023-01-04 11:50:51,336 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3788754646976789, 'Total loss': 0.3788754646976789} | train loss {'Reaction outcome loss': 0.2887220107211398, 'Total loss': 0.2887220107211398}
2023-01-04 11:50:51,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:51,336 INFO:     Epoch: 74
2023-01-04 11:50:52,863 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37687963296969734, 'Total loss': 0.37687963296969734} | train loss {'Reaction outcome loss': 0.2859396606381309, 'Total loss': 0.2859396606381309}
2023-01-04 11:50:52,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:52,863 INFO:     Epoch: 75
2023-01-04 11:50:54,397 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39599569340546925, 'Total loss': 0.39599569340546925} | train loss {'Reaction outcome loss': 0.2879524718681385, 'Total loss': 0.2879524718681385}
2023-01-04 11:50:54,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:54,397 INFO:     Epoch: 76
2023-01-04 11:50:55,945 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3722830226023992, 'Total loss': 0.3722830226023992} | train loss {'Reaction outcome loss': 0.2812991580784981, 'Total loss': 0.2812991580784981}
2023-01-04 11:50:55,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:55,946 INFO:     Epoch: 77
2023-01-04 11:50:57,450 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39370430409908297, 'Total loss': 0.39370430409908297} | train loss {'Reaction outcome loss': 0.28409813740376616, 'Total loss': 0.28409813740376616}
2023-01-04 11:50:57,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:57,450 INFO:     Epoch: 78
2023-01-04 11:50:59,026 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3899640033952892, 'Total loss': 0.3899640033952892} | train loss {'Reaction outcome loss': 0.2827626737006476, 'Total loss': 0.2827626737006476}
2023-01-04 11:50:59,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:50:59,026 INFO:     Epoch: 79
2023-01-04 11:51:00,581 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3982403258482615, 'Total loss': 0.3982403258482615} | train loss {'Reaction outcome loss': 0.2831239424563422, 'Total loss': 0.2831239424563422}
2023-01-04 11:51:00,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:00,582 INFO:     Epoch: 80
2023-01-04 11:51:02,087 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3922225634256999, 'Total loss': 0.3922225634256999} | train loss {'Reaction outcome loss': 0.27847003296182604, 'Total loss': 0.27847003296182604}
2023-01-04 11:51:02,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:02,087 INFO:     Epoch: 81
2023-01-04 11:51:03,613 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.431030410528183, 'Total loss': 0.431030410528183} | train loss {'Reaction outcome loss': 0.27744004831432856, 'Total loss': 0.27744004831432856}
2023-01-04 11:51:03,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:03,613 INFO:     Epoch: 82
2023-01-04 11:51:05,151 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40228119219342867, 'Total loss': 0.40228119219342867} | train loss {'Reaction outcome loss': 0.2802293909321852, 'Total loss': 0.2802293909321852}
2023-01-04 11:51:05,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:05,151 INFO:     Epoch: 83
2023-01-04 11:51:06,645 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3822990054885546, 'Total loss': 0.3822990054885546} | train loss {'Reaction outcome loss': 0.27598086541099304, 'Total loss': 0.27598086541099304}
2023-01-04 11:51:06,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:06,645 INFO:     Epoch: 84
2023-01-04 11:51:08,179 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40816400150458015, 'Total loss': 0.40816400150458015} | train loss {'Reaction outcome loss': 0.2730372159628411, 'Total loss': 0.2730372159628411}
2023-01-04 11:51:08,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:08,179 INFO:     Epoch: 85
2023-01-04 11:51:09,719 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4069066643714905, 'Total loss': 0.4069066643714905} | train loss {'Reaction outcome loss': 0.27301632436988976, 'Total loss': 0.27301632436988976}
2023-01-04 11:51:09,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:09,720 INFO:     Epoch: 86
2023-01-04 11:51:11,222 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4048563023408254, 'Total loss': 0.4048563023408254} | train loss {'Reaction outcome loss': 0.2723970134017432, 'Total loss': 0.2723970134017432}
2023-01-04 11:51:11,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:11,223 INFO:     Epoch: 87
2023-01-04 11:51:12,760 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38849753340085347, 'Total loss': 0.38849753340085347} | train loss {'Reaction outcome loss': 0.2686123354051166, 'Total loss': 0.2686123354051166}
2023-01-04 11:51:12,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:12,761 INFO:     Epoch: 88
2023-01-04 11:51:14,299 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40760358025630317, 'Total loss': 0.40760358025630317} | train loss {'Reaction outcome loss': 0.2701017875568013, 'Total loss': 0.2701017875568013}
2023-01-04 11:51:14,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:14,300 INFO:     Epoch: 89
2023-01-04 11:51:15,823 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40019926726818084, 'Total loss': 0.40019926726818084} | train loss {'Reaction outcome loss': 0.26651200300213157, 'Total loss': 0.26651200300213157}
2023-01-04 11:51:15,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:15,824 INFO:     Epoch: 90
2023-01-04 11:51:17,375 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39217589298884076, 'Total loss': 0.39217589298884076} | train loss {'Reaction outcome loss': 0.26924664329228803, 'Total loss': 0.26924664329228803}
2023-01-04 11:51:17,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:17,376 INFO:     Epoch: 91
2023-01-04 11:51:18,920 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38173076609770457, 'Total loss': 0.38173076609770457} | train loss {'Reaction outcome loss': 0.2669724465048841, 'Total loss': 0.2669724465048841}
2023-01-04 11:51:18,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:18,921 INFO:     Epoch: 92
2023-01-04 11:51:20,454 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39450286428133646, 'Total loss': 0.39450286428133646} | train loss {'Reaction outcome loss': 0.26582142217187865, 'Total loss': 0.26582142217187865}
2023-01-04 11:51:20,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:20,454 INFO:     Epoch: 93
2023-01-04 11:51:22,025 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4155377765496572, 'Total loss': 0.4155377765496572} | train loss {'Reaction outcome loss': 0.2636839345070049, 'Total loss': 0.2636839345070049}
2023-01-04 11:51:22,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:22,026 INFO:     Epoch: 94
2023-01-04 11:51:23,563 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4063134104013443, 'Total loss': 0.4063134104013443} | train loss {'Reaction outcome loss': 0.2621839555234707, 'Total loss': 0.2621839555234707}
2023-01-04 11:51:23,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:23,563 INFO:     Epoch: 95
2023-01-04 11:51:25,103 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3852542221546173, 'Total loss': 0.3852542221546173} | train loss {'Reaction outcome loss': 0.2633155622000624, 'Total loss': 0.2633155622000624}
2023-01-04 11:51:25,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:25,103 INFO:     Epoch: 96
2023-01-04 11:51:26,653 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3902197207013766, 'Total loss': 0.3902197207013766} | train loss {'Reaction outcome loss': 0.2636606333522999, 'Total loss': 0.2636606333522999}
2023-01-04 11:51:26,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:26,653 INFO:     Epoch: 97
2023-01-04 11:51:28,203 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4189171741406123, 'Total loss': 0.4189171741406123} | train loss {'Reaction outcome loss': 0.2557305660909832, 'Total loss': 0.2557305660909832}
2023-01-04 11:51:28,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:28,203 INFO:     Epoch: 98
2023-01-04 11:51:29,719 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37867623766263325, 'Total loss': 0.37867623766263325} | train loss {'Reaction outcome loss': 0.2569931783469401, 'Total loss': 0.2569931783469401}
2023-01-04 11:51:29,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:29,720 INFO:     Epoch: 99
2023-01-04 11:51:31,270 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3997661421696345, 'Total loss': 0.3997661421696345} | train loss {'Reaction outcome loss': 0.2558015261216577, 'Total loss': 0.2558015261216577}
2023-01-04 11:51:31,271 INFO:     Best model found after epoch 62 of 100.
2023-01-04 11:51:31,271 INFO:   Done with stage: TRAINING
2023-01-04 11:51:31,271 INFO:   Starting stage: EVALUATION
2023-01-04 11:51:31,418 INFO:   Done with stage: EVALUATION
2023-01-04 11:51:31,418 INFO:   Leaving out SEQ value Fold_4
2023-01-04 11:51:31,431 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 11:51:31,431 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:51:32,080 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:51:32,080 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:51:32,148 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:51:32,148 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:51:32,148 INFO:     No hyperparam tuning for this model
2023-01-04 11:51:32,149 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:51:32,149 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:51:32,149 INFO:     None feature selector for col prot
2023-01-04 11:51:32,149 INFO:     None feature selector for col prot
2023-01-04 11:51:32,149 INFO:     None feature selector for col prot
2023-01-04 11:51:32,150 INFO:     None feature selector for col chem
2023-01-04 11:51:32,150 INFO:     None feature selector for col chem
2023-01-04 11:51:32,150 INFO:     None feature selector for col chem
2023-01-04 11:51:32,150 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:51:32,150 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:51:32,151 INFO:     Number of params in model 70111
2023-01-04 11:51:32,155 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:51:32,155 INFO:   Starting stage: TRAINING
2023-01-04 11:51:32,193 INFO:     Val loss before train {'Reaction outcome loss': 0.9320716718832652, 'Total loss': 0.9320716718832652}
2023-01-04 11:51:32,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:32,193 INFO:     Epoch: 0
2023-01-04 11:51:33,746 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7025197943051656, 'Total loss': 0.7025197943051656} | train loss {'Reaction outcome loss': 0.8560307812389484, 'Total loss': 0.8560307812389484}
2023-01-04 11:51:33,746 INFO:     Found new best model at epoch 0
2023-01-04 11:51:33,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:33,747 INFO:     Epoch: 1
2023-01-04 11:51:35,309 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6094919701417287, 'Total loss': 0.6094919701417287} | train loss {'Reaction outcome loss': 0.6891853201475384, 'Total loss': 0.6891853201475384}
2023-01-04 11:51:35,309 INFO:     Found new best model at epoch 1
2023-01-04 11:51:35,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:35,310 INFO:     Epoch: 2
2023-01-04 11:51:36,880 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5382823089758555, 'Total loss': 0.5382823089758555} | train loss {'Reaction outcome loss': 0.5914332131831654, 'Total loss': 0.5914332131831654}
2023-01-04 11:51:36,880 INFO:     Found new best model at epoch 2
2023-01-04 11:51:36,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:36,881 INFO:     Epoch: 3
2023-01-04 11:51:38,427 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5207035183906555, 'Total loss': 0.5207035183906555} | train loss {'Reaction outcome loss': 0.5440838241727773, 'Total loss': 0.5440838241727773}
2023-01-04 11:51:38,428 INFO:     Found new best model at epoch 3
2023-01-04 11:51:38,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:38,428 INFO:     Epoch: 4
2023-01-04 11:51:40,005 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5125720938046773, 'Total loss': 0.5125720938046773} | train loss {'Reaction outcome loss': 0.5258274003056412, 'Total loss': 0.5258274003056412}
2023-01-04 11:51:40,005 INFO:     Found new best model at epoch 4
2023-01-04 11:51:40,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:40,006 INFO:     Epoch: 5
2023-01-04 11:51:41,547 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48988237778345745, 'Total loss': 0.48988237778345745} | train loss {'Reaction outcome loss': 0.5096584105534674, 'Total loss': 0.5096584105534674}
2023-01-04 11:51:41,547 INFO:     Found new best model at epoch 5
2023-01-04 11:51:41,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:41,548 INFO:     Epoch: 6
2023-01-04 11:51:43,119 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47361285189787544, 'Total loss': 0.47361285189787544} | train loss {'Reaction outcome loss': 0.4938185255342442, 'Total loss': 0.4938185255342442}
2023-01-04 11:51:43,119 INFO:     Found new best model at epoch 6
2023-01-04 11:51:43,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:43,120 INFO:     Epoch: 7
2023-01-04 11:51:44,681 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4650960306326548, 'Total loss': 0.4650960306326548} | train loss {'Reaction outcome loss': 0.48815633431883926, 'Total loss': 0.48815633431883926}
2023-01-04 11:51:44,683 INFO:     Found new best model at epoch 7
2023-01-04 11:51:44,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:44,683 INFO:     Epoch: 8
2023-01-04 11:51:46,244 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4655277609825134, 'Total loss': 0.4655277609825134} | train loss {'Reaction outcome loss': 0.47914258667708304, 'Total loss': 0.47914258667708304}
2023-01-04 11:51:46,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:46,244 INFO:     Epoch: 9
2023-01-04 11:51:47,777 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4463576912879944, 'Total loss': 0.4463576912879944} | train loss {'Reaction outcome loss': 0.47361191563873084, 'Total loss': 0.47361191563873084}
2023-01-04 11:51:47,778 INFO:     Found new best model at epoch 9
2023-01-04 11:51:47,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:47,778 INFO:     Epoch: 10
2023-01-04 11:51:49,344 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4560346692800522, 'Total loss': 0.4560346692800522} | train loss {'Reaction outcome loss': 0.4667259510673771, 'Total loss': 0.4667259510673771}
2023-01-04 11:51:49,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:49,344 INFO:     Epoch: 11
2023-01-04 11:51:50,881 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4541332503159841, 'Total loss': 0.4541332503159841} | train loss {'Reaction outcome loss': 0.46117070973565, 'Total loss': 0.46117070973565}
2023-01-04 11:51:50,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:50,882 INFO:     Epoch: 12
2023-01-04 11:51:52,465 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4411505490541458, 'Total loss': 0.4411505490541458} | train loss {'Reaction outcome loss': 0.45741416336396973, 'Total loss': 0.45741416336396973}
2023-01-04 11:51:52,466 INFO:     Found new best model at epoch 12
2023-01-04 11:51:52,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:52,466 INFO:     Epoch: 13
2023-01-04 11:51:54,037 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4376446356376012, 'Total loss': 0.4376446356376012} | train loss {'Reaction outcome loss': 0.45282564360634947, 'Total loss': 0.45282564360634947}
2023-01-04 11:51:54,037 INFO:     Found new best model at epoch 13
2023-01-04 11:51:54,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:54,038 INFO:     Epoch: 14
2023-01-04 11:51:55,619 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45149958729743955, 'Total loss': 0.45149958729743955} | train loss {'Reaction outcome loss': 0.4473839593170352, 'Total loss': 0.4473839593170352}
2023-01-04 11:51:55,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:55,619 INFO:     Epoch: 15
2023-01-04 11:51:57,165 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4280476907889048, 'Total loss': 0.4280476907889048} | train loss {'Reaction outcome loss': 0.4420602950486035, 'Total loss': 0.4420602950486035}
2023-01-04 11:51:57,165 INFO:     Found new best model at epoch 15
2023-01-04 11:51:57,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:57,166 INFO:     Epoch: 16
2023-01-04 11:51:58,745 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42460692723592125, 'Total loss': 0.42460692723592125} | train loss {'Reaction outcome loss': 0.4386407879285434, 'Total loss': 0.4386407879285434}
2023-01-04 11:51:58,745 INFO:     Found new best model at epoch 16
2023-01-04 11:51:58,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:51:58,746 INFO:     Epoch: 17
2023-01-04 11:52:00,293 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4245314399401347, 'Total loss': 0.4245314399401347} | train loss {'Reaction outcome loss': 0.43126596230677317, 'Total loss': 0.43126596230677317}
2023-01-04 11:52:00,293 INFO:     Found new best model at epoch 17
2023-01-04 11:52:00,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:00,294 INFO:     Epoch: 18
2023-01-04 11:52:01,871 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4226477841536204, 'Total loss': 0.4226477841536204} | train loss {'Reaction outcome loss': 0.4270678321807393, 'Total loss': 0.4270678321807393}
2023-01-04 11:52:01,871 INFO:     Found new best model at epoch 18
2023-01-04 11:52:01,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:01,872 INFO:     Epoch: 19
2023-01-04 11:52:03,461 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44733959833780923, 'Total loss': 0.44733959833780923} | train loss {'Reaction outcome loss': 0.4211020596083321, 'Total loss': 0.4211020596083321}
2023-01-04 11:52:03,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:03,461 INFO:     Epoch: 20
2023-01-04 11:52:05,015 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43060126105944313, 'Total loss': 0.43060126105944313} | train loss {'Reaction outcome loss': 0.42259197843526675, 'Total loss': 0.42259197843526675}
2023-01-04 11:52:05,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:05,016 INFO:     Epoch: 21
2023-01-04 11:52:06,591 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4056633174419403, 'Total loss': 0.4056633174419403} | train loss {'Reaction outcome loss': 0.4190847361292219, 'Total loss': 0.4190847361292219}
2023-01-04 11:52:06,591 INFO:     Found new best model at epoch 21
2023-01-04 11:52:06,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:06,592 INFO:     Epoch: 22
2023-01-04 11:52:08,198 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41393224398295086, 'Total loss': 0.41393224398295086} | train loss {'Reaction outcome loss': 0.41249418177974784, 'Total loss': 0.41249418177974784}
2023-01-04 11:52:08,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:08,198 INFO:     Epoch: 23
2023-01-04 11:52:09,767 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3979457328716914, 'Total loss': 0.3979457328716914} | train loss {'Reaction outcome loss': 0.4103426715419611, 'Total loss': 0.4103426715419611}
2023-01-04 11:52:09,767 INFO:     Found new best model at epoch 23
2023-01-04 11:52:09,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:09,767 INFO:     Epoch: 24
2023-01-04 11:52:11,364 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38828839162985485, 'Total loss': 0.38828839162985485} | train loss {'Reaction outcome loss': 0.4051779712473012, 'Total loss': 0.4051779712473012}
2023-01-04 11:52:11,364 INFO:     Found new best model at epoch 24
2023-01-04 11:52:11,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:11,365 INFO:     Epoch: 25
2023-01-04 11:52:12,964 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38270802795886993, 'Total loss': 0.38270802795886993} | train loss {'Reaction outcome loss': 0.40256674501654904, 'Total loss': 0.40256674501654904}
2023-01-04 11:52:12,964 INFO:     Found new best model at epoch 25
2023-01-04 11:52:12,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:12,964 INFO:     Epoch: 26
2023-01-04 11:52:14,529 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3990944763024648, 'Total loss': 0.3990944763024648} | train loss {'Reaction outcome loss': 0.39928429915371355, 'Total loss': 0.39928429915371355}
2023-01-04 11:52:14,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:14,529 INFO:     Epoch: 27
2023-01-04 11:52:16,127 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3947151909271876, 'Total loss': 0.3947151909271876} | train loss {'Reaction outcome loss': 0.3930484204946442, 'Total loss': 0.3930484204946442}
2023-01-04 11:52:16,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:16,127 INFO:     Epoch: 28
2023-01-04 11:52:17,687 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40263544718424477, 'Total loss': 0.40263544718424477} | train loss {'Reaction outcome loss': 0.3895283222521255, 'Total loss': 0.3895283222521255}
2023-01-04 11:52:17,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:17,687 INFO:     Epoch: 29
2023-01-04 11:52:19,278 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3940792108575503, 'Total loss': 0.3940792108575503} | train loss {'Reaction outcome loss': 0.39019261639471087, 'Total loss': 0.39019261639471087}
2023-01-04 11:52:19,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:19,279 INFO:     Epoch: 30
2023-01-04 11:52:20,874 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.37849092185497285, 'Total loss': 0.37849092185497285} | train loss {'Reaction outcome loss': 0.3836448660073298, 'Total loss': 0.3836448660073298}
2023-01-04 11:52:20,874 INFO:     Found new best model at epoch 30
2023-01-04 11:52:20,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:20,874 INFO:     Epoch: 31
2023-01-04 11:52:22,502 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.37671124935150146, 'Total loss': 0.37671124935150146} | train loss {'Reaction outcome loss': 0.378968253355164, 'Total loss': 0.378968253355164}
2023-01-04 11:52:22,503 INFO:     Found new best model at epoch 31
2023-01-04 11:52:22,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:22,503 INFO:     Epoch: 32
2023-01-04 11:52:24,074 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39684339265028634, 'Total loss': 0.39684339265028634} | train loss {'Reaction outcome loss': 0.37388582148384103, 'Total loss': 0.37388582148384103}
2023-01-04 11:52:24,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:24,074 INFO:     Epoch: 33
2023-01-04 11:52:25,680 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39364547034104663, 'Total loss': 0.39364547034104663} | train loss {'Reaction outcome loss': 0.372424854079954, 'Total loss': 0.372424854079954}
2023-01-04 11:52:25,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:25,681 INFO:     Epoch: 34
2023-01-04 11:52:27,246 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3631788929303487, 'Total loss': 0.3631788929303487} | train loss {'Reaction outcome loss': 0.3715969242343834, 'Total loss': 0.3715969242343834}
2023-01-04 11:52:27,246 INFO:     Found new best model at epoch 34
2023-01-04 11:52:27,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:27,247 INFO:     Epoch: 35
2023-01-04 11:52:28,863 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3835844546556473, 'Total loss': 0.3835844546556473} | train loss {'Reaction outcome loss': 0.3650284901476509, 'Total loss': 0.3650284901476509}
2023-01-04 11:52:28,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:28,863 INFO:     Epoch: 36
2023-01-04 11:52:30,457 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.36109264492988585, 'Total loss': 0.36109264492988585} | train loss {'Reaction outcome loss': 0.36164776991635883, 'Total loss': 0.36164776991635883}
2023-01-04 11:52:30,457 INFO:     Found new best model at epoch 36
2023-01-04 11:52:30,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:30,458 INFO:     Epoch: 37
2023-01-04 11:52:32,057 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.35156295299530027, 'Total loss': 0.35156295299530027} | train loss {'Reaction outcome loss': 0.3567564364805118, 'Total loss': 0.3567564364805118}
2023-01-04 11:52:32,057 INFO:     Found new best model at epoch 37
2023-01-04 11:52:32,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:32,058 INFO:     Epoch: 38
2023-01-04 11:52:33,626 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38465941945711773, 'Total loss': 0.38465941945711773} | train loss {'Reaction outcome loss': 0.3536827966086701, 'Total loss': 0.3536827966086701}
2023-01-04 11:52:33,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:33,627 INFO:     Epoch: 39
2023-01-04 11:52:35,240 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.35080187519391376, 'Total loss': 0.35080187519391376} | train loss {'Reaction outcome loss': 0.354896737403818, 'Total loss': 0.354896737403818}
2023-01-04 11:52:35,240 INFO:     Found new best model at epoch 39
2023-01-04 11:52:35,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:35,241 INFO:     Epoch: 40
2023-01-04 11:52:36,817 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3666108032067617, 'Total loss': 0.3666108032067617} | train loss {'Reaction outcome loss': 0.3502502168397611, 'Total loss': 0.3502502168397611}
2023-01-04 11:52:36,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:36,817 INFO:     Epoch: 41
2023-01-04 11:52:38,443 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37536901235580444, 'Total loss': 0.37536901235580444} | train loss {'Reaction outcome loss': 0.3436385195177815, 'Total loss': 0.3436385195177815}
2023-01-04 11:52:38,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:38,444 INFO:     Epoch: 42
2023-01-04 11:52:40,068 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3589820226033529, 'Total loss': 0.3589820226033529} | train loss {'Reaction outcome loss': 0.3474212668647835, 'Total loss': 0.3474212668647835}
2023-01-04 11:52:40,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:40,068 INFO:     Epoch: 43
2023-01-04 11:52:41,644 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3599415351947149, 'Total loss': 0.3599415351947149} | train loss {'Reaction outcome loss': 0.34177927264022484, 'Total loss': 0.34177927264022484}
2023-01-04 11:52:41,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:41,644 INFO:     Epoch: 44
2023-01-04 11:52:43,201 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3889922241369883, 'Total loss': 0.3889922241369883} | train loss {'Reaction outcome loss': 0.3382899224596764, 'Total loss': 0.3382899224596764}
2023-01-04 11:52:43,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:43,201 INFO:     Epoch: 45
2023-01-04 11:52:44,744 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.37113305926322937, 'Total loss': 0.37113305926322937} | train loss {'Reaction outcome loss': 0.3355040806967644, 'Total loss': 0.3355040806967644}
2023-01-04 11:52:44,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:44,744 INFO:     Epoch: 46
2023-01-04 11:52:46,276 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3873414138952891, 'Total loss': 0.3873414138952891} | train loss {'Reaction outcome loss': 0.3323459833699013, 'Total loss': 0.3323459833699013}
2023-01-04 11:52:46,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:46,276 INFO:     Epoch: 47
2023-01-04 11:52:47,842 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3524293730656306, 'Total loss': 0.3524293730656306} | train loss {'Reaction outcome loss': 0.3297125994352227, 'Total loss': 0.3297125994352227}
2023-01-04 11:52:47,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:47,842 INFO:     Epoch: 48
2023-01-04 11:52:49,413 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3580355847875277, 'Total loss': 0.3580355847875277} | train loss {'Reaction outcome loss': 0.3264068739643381, 'Total loss': 0.3264068739643381}
2023-01-04 11:52:49,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:49,413 INFO:     Epoch: 49
2023-01-04 11:52:50,953 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3593546519676844, 'Total loss': 0.3593546519676844} | train loss {'Reaction outcome loss': 0.3246747363990825, 'Total loss': 0.3246747363990825}
2023-01-04 11:52:50,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:50,953 INFO:     Epoch: 50
2023-01-04 11:52:52,524 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3676253755887349, 'Total loss': 0.3676253755887349} | train loss {'Reaction outcome loss': 0.3242292416278636, 'Total loss': 0.3242292416278636}
2023-01-04 11:52:52,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:52,524 INFO:     Epoch: 51
2023-01-04 11:52:54,073 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3462861031293869, 'Total loss': 0.3462861031293869} | train loss {'Reaction outcome loss': 0.3205093474863669, 'Total loss': 0.3205093474863669}
2023-01-04 11:52:54,073 INFO:     Found new best model at epoch 51
2023-01-04 11:52:54,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:54,074 INFO:     Epoch: 52
2023-01-04 11:52:55,622 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.34879815876483916, 'Total loss': 0.34879815876483916} | train loss {'Reaction outcome loss': 0.3189739243325774, 'Total loss': 0.3189739243325774}
2023-01-04 11:52:55,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:55,623 INFO:     Epoch: 53
2023-01-04 11:52:57,196 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37165355881055195, 'Total loss': 0.37165355881055195} | train loss {'Reaction outcome loss': 0.3169519871419518, 'Total loss': 0.3169519871419518}
2023-01-04 11:52:57,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:57,197 INFO:     Epoch: 54
2023-01-04 11:52:58,755 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.34086224834124246, 'Total loss': 0.34086224834124246} | train loss {'Reaction outcome loss': 0.31674471852581426, 'Total loss': 0.31674471852581426}
2023-01-04 11:52:58,755 INFO:     Found new best model at epoch 54
2023-01-04 11:52:58,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:52:58,755 INFO:     Epoch: 55
2023-01-04 11:53:00,298 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3487831220030785, 'Total loss': 0.3487831220030785} | train loss {'Reaction outcome loss': 0.31080534497430606, 'Total loss': 0.31080534497430606}
2023-01-04 11:53:00,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:00,298 INFO:     Epoch: 56
2023-01-04 11:53:01,876 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3810644249121348, 'Total loss': 0.3810644249121348} | train loss {'Reaction outcome loss': 0.3133015122116688, 'Total loss': 0.3133015122116688}
2023-01-04 11:53:01,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:01,876 INFO:     Epoch: 57
2023-01-04 11:53:03,427 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3317478060722351, 'Total loss': 0.3317478060722351} | train loss {'Reaction outcome loss': 0.3091719598115997, 'Total loss': 0.3091719598115997}
2023-01-04 11:53:03,427 INFO:     Found new best model at epoch 57
2023-01-04 11:53:03,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:03,428 INFO:     Epoch: 58
2023-01-04 11:53:05,014 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.34194920361042025, 'Total loss': 0.34194920361042025} | train loss {'Reaction outcome loss': 0.3040558893758037, 'Total loss': 0.3040558893758037}
2023-01-04 11:53:05,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:05,015 INFO:     Epoch: 59
2023-01-04 11:53:06,585 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3482275525728861, 'Total loss': 0.3482275525728861} | train loss {'Reaction outcome loss': 0.30342316358528415, 'Total loss': 0.30342316358528415}
2023-01-04 11:53:06,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:06,586 INFO:     Epoch: 60
2023-01-04 11:53:08,164 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.34387368261814116, 'Total loss': 0.34387368261814116} | train loss {'Reaction outcome loss': 0.30550178952703405, 'Total loss': 0.30550178952703405}
2023-01-04 11:53:08,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:08,164 INFO:     Epoch: 61
2023-01-04 11:53:09,695 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.344108226398627, 'Total loss': 0.344108226398627} | train loss {'Reaction outcome loss': 0.29969539703122117, 'Total loss': 0.29969539703122117}
2023-01-04 11:53:09,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:09,695 INFO:     Epoch: 62
2023-01-04 11:53:11,283 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3466523418823878, 'Total loss': 0.3466523418823878} | train loss {'Reaction outcome loss': 0.3021769133877238, 'Total loss': 0.3021769133877238}
2023-01-04 11:53:11,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:11,284 INFO:     Epoch: 63
2023-01-04 11:53:12,809 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3426310400168101, 'Total loss': 0.3426310400168101} | train loss {'Reaction outcome loss': 0.30169062144274317, 'Total loss': 0.30169062144274317}
2023-01-04 11:53:12,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:12,809 INFO:     Epoch: 64
2023-01-04 11:53:14,398 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.36808062295118965, 'Total loss': 0.36808062295118965} | train loss {'Reaction outcome loss': 0.2941404957364612, 'Total loss': 0.2941404957364612}
2023-01-04 11:53:14,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:14,399 INFO:     Epoch: 65
2023-01-04 11:53:15,967 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.33244977593421937, 'Total loss': 0.33244977593421937} | train loss {'Reaction outcome loss': 0.29354170535015284, 'Total loss': 0.29354170535015284}
2023-01-04 11:53:15,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:15,967 INFO:     Epoch: 66
2023-01-04 11:53:17,531 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.33839006125926974, 'Total loss': 0.33839006125926974} | train loss {'Reaction outcome loss': 0.29903758134329794, 'Total loss': 0.29903758134329794}
2023-01-04 11:53:17,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:17,531 INFO:     Epoch: 67
2023-01-04 11:53:19,061 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.34223222037156426, 'Total loss': 0.34223222037156426} | train loss {'Reaction outcome loss': 0.28956686420238403, 'Total loss': 0.28956686420238403}
2023-01-04 11:53:19,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:19,061 INFO:     Epoch: 68
2023-01-04 11:53:20,604 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.32688631216684977, 'Total loss': 0.32688631216684977} | train loss {'Reaction outcome loss': 0.29282712707773445, 'Total loss': 0.29282712707773445}
2023-01-04 11:53:20,604 INFO:     Found new best model at epoch 68
2023-01-04 11:53:20,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:20,605 INFO:     Epoch: 69
2023-01-04 11:53:22,144 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.34535571237405144, 'Total loss': 0.34535571237405144} | train loss {'Reaction outcome loss': 0.29294607193891753, 'Total loss': 0.29294607193891753}
2023-01-04 11:53:22,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:22,144 INFO:     Epoch: 70
2023-01-04 11:53:23,696 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.34697697858015697, 'Total loss': 0.34697697858015697} | train loss {'Reaction outcome loss': 0.2919062024204309, 'Total loss': 0.2919062024204309}
2023-01-04 11:53:23,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:23,696 INFO:     Epoch: 71
2023-01-04 11:53:25,254 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.34606688320636747, 'Total loss': 0.34606688320636747} | train loss {'Reaction outcome loss': 0.2896556370901717, 'Total loss': 0.2896556370901717}
2023-01-04 11:53:25,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:25,255 INFO:     Epoch: 72
2023-01-04 11:53:26,798 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3264383484919866, 'Total loss': 0.3264383484919866} | train loss {'Reaction outcome loss': 0.2857429406165216, 'Total loss': 0.2857429406165216}
2023-01-04 11:53:26,799 INFO:     Found new best model at epoch 72
2023-01-04 11:53:26,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:26,800 INFO:     Epoch: 73
2023-01-04 11:53:28,364 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.33127383291721346, 'Total loss': 0.33127383291721346} | train loss {'Reaction outcome loss': 0.28336024133737336, 'Total loss': 0.28336024133737336}
2023-01-04 11:53:28,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:28,365 INFO:     Epoch: 74
2023-01-04 11:53:29,912 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3390161191423734, 'Total loss': 0.3390161191423734} | train loss {'Reaction outcome loss': 0.2823576246411792, 'Total loss': 0.2823576246411792}
2023-01-04 11:53:29,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:29,913 INFO:     Epoch: 75
2023-01-04 11:53:31,083 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3344136953353882, 'Total loss': 0.3344136953353882} | train loss {'Reaction outcome loss': 0.28060671941306614, 'Total loss': 0.28060671941306614}
2023-01-04 11:53:31,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:31,084 INFO:     Epoch: 76
2023-01-04 11:53:32,098 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.33151352902253467, 'Total loss': 0.33151352902253467} | train loss {'Reaction outcome loss': 0.2784387158626684, 'Total loss': 0.2784387158626684}
2023-01-04 11:53:32,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:32,098 INFO:     Epoch: 77
2023-01-04 11:53:33,105 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.33630630473295847, 'Total loss': 0.33630630473295847} | train loss {'Reaction outcome loss': 0.28142119437079566, 'Total loss': 0.28142119437079566}
2023-01-04 11:53:33,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:33,106 INFO:     Epoch: 78
2023-01-04 11:53:34,124 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.30573362360397977, 'Total loss': 0.30573362360397977} | train loss {'Reaction outcome loss': 0.27924048481004765, 'Total loss': 0.27924048481004765}
2023-01-04 11:53:34,124 INFO:     Found new best model at epoch 78
2023-01-04 11:53:34,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:34,125 INFO:     Epoch: 79
2023-01-04 11:53:35,244 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.33523562947909036, 'Total loss': 0.33523562947909036} | train loss {'Reaction outcome loss': 0.2806256638860014, 'Total loss': 0.2806256638860014}
2023-01-04 11:53:35,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:35,244 INFO:     Epoch: 80
2023-01-04 11:53:36,817 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.32816857745250066, 'Total loss': 0.32816857745250066} | train loss {'Reaction outcome loss': 0.27609570220865925, 'Total loss': 0.27609570220865925}
2023-01-04 11:53:36,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:36,817 INFO:     Epoch: 81
2023-01-04 11:53:38,386 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.32274319529533385, 'Total loss': 0.32274319529533385} | train loss {'Reaction outcome loss': 0.27656070438855823, 'Total loss': 0.27656070438855823}
2023-01-04 11:53:38,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:38,386 INFO:     Epoch: 82
2023-01-04 11:53:39,947 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.32932075659434, 'Total loss': 0.32932075659434} | train loss {'Reaction outcome loss': 0.2722851764343491, 'Total loss': 0.2722851764343491}
2023-01-04 11:53:39,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:39,947 INFO:     Epoch: 83
2023-01-04 11:53:41,507 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.33244474480549496, 'Total loss': 0.33244474480549496} | train loss {'Reaction outcome loss': 0.2724968048101728, 'Total loss': 0.2724968048101728}
2023-01-04 11:53:41,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:41,508 INFO:     Epoch: 84
2023-01-04 11:53:43,042 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.32434676935275397, 'Total loss': 0.32434676935275397} | train loss {'Reaction outcome loss': 0.27265775225222755, 'Total loss': 0.27265775225222755}
2023-01-04 11:53:43,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:43,042 INFO:     Epoch: 85
2023-01-04 11:53:44,590 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.34957232177257536, 'Total loss': 0.34957232177257536} | train loss {'Reaction outcome loss': 0.27015488433386015, 'Total loss': 0.27015488433386015}
2023-01-04 11:53:44,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:44,590 INFO:     Epoch: 86
2023-01-04 11:53:46,153 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.32773999869823456, 'Total loss': 0.32773999869823456} | train loss {'Reaction outcome loss': 0.274620815869488, 'Total loss': 0.274620815869488}
2023-01-04 11:53:46,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:46,154 INFO:     Epoch: 87
2023-01-04 11:53:47,763 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.31665960848331454, 'Total loss': 0.31665960848331454} | train loss {'Reaction outcome loss': 0.26776243961459895, 'Total loss': 0.26776243961459895}
2023-01-04 11:53:47,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:47,763 INFO:     Epoch: 88
2023-01-04 11:53:49,345 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.325634249051412, 'Total loss': 0.325634249051412} | train loss {'Reaction outcome loss': 0.2701148882051022, 'Total loss': 0.2701148882051022}
2023-01-04 11:53:49,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:49,345 INFO:     Epoch: 89
2023-01-04 11:53:50,913 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.36546571056048077, 'Total loss': 0.36546571056048077} | train loss {'Reaction outcome loss': 0.26804713868546143, 'Total loss': 0.26804713868546143}
2023-01-04 11:53:50,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:50,913 INFO:     Epoch: 90
2023-01-04 11:53:52,441 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3190692772467931, 'Total loss': 0.3190692772467931} | train loss {'Reaction outcome loss': 0.2653914125777431, 'Total loss': 0.2653914125777431}
2023-01-04 11:53:52,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:52,441 INFO:     Epoch: 91
2023-01-04 11:53:53,958 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3223552534977595, 'Total loss': 0.3223552534977595} | train loss {'Reaction outcome loss': 0.2650414630232735, 'Total loss': 0.2650414630232735}
2023-01-04 11:53:53,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:53,959 INFO:     Epoch: 92
2023-01-04 11:53:55,511 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.34207441508769987, 'Total loss': 0.34207441508769987} | train loss {'Reaction outcome loss': 0.26492349919106556, 'Total loss': 0.26492349919106556}
2023-01-04 11:53:55,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:55,512 INFO:     Epoch: 93
2023-01-04 11:53:57,073 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3214290241400401, 'Total loss': 0.3214290241400401} | train loss {'Reaction outcome loss': 0.26099225596292785, 'Total loss': 0.26099225596292785}
2023-01-04 11:53:57,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:57,073 INFO:     Epoch: 94
2023-01-04 11:53:58,641 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3203673705458641, 'Total loss': 0.3203673705458641} | train loss {'Reaction outcome loss': 0.2673964408841589, 'Total loss': 0.2673964408841589}
2023-01-04 11:53:58,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:53:58,641 INFO:     Epoch: 95
2023-01-04 11:54:00,204 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3591426223516464, 'Total loss': 0.3591426223516464} | train loss {'Reaction outcome loss': 0.25955944430311667, 'Total loss': 0.25955944430311667}
2023-01-04 11:54:00,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:00,204 INFO:     Epoch: 96
2023-01-04 11:54:01,732 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.32050093561410903, 'Total loss': 0.32050093561410903} | train loss {'Reaction outcome loss': 0.2592307698613685, 'Total loss': 0.2592307698613685}
2023-01-04 11:54:01,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:01,733 INFO:     Epoch: 97
2023-01-04 11:54:03,258 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3332524448633194, 'Total loss': 0.3332524448633194} | train loss {'Reaction outcome loss': 0.26241457508036375, 'Total loss': 0.26241457508036375}
2023-01-04 11:54:03,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:03,258 INFO:     Epoch: 98
2023-01-04 11:54:04,802 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3500330030918121, 'Total loss': 0.3500330030918121} | train loss {'Reaction outcome loss': 0.2598480923027338, 'Total loss': 0.2598480923027338}
2023-01-04 11:54:04,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:04,803 INFO:     Epoch: 99
2023-01-04 11:54:06,366 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3106146256128947, 'Total loss': 0.3106146256128947} | train loss {'Reaction outcome loss': 0.26245290218492706, 'Total loss': 0.26245290218492706}
2023-01-04 11:54:06,366 INFO:     Best model found after epoch 79 of 100.
2023-01-04 11:54:06,367 INFO:   Done with stage: TRAINING
2023-01-04 11:54:06,367 INFO:   Starting stage: EVALUATION
2023-01-04 11:54:06,491 INFO:   Done with stage: EVALUATION
2023-01-04 11:54:06,491 INFO:   Leaving out SEQ value Fold_5
2023-01-04 11:54:06,504 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 11:54:06,504 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:54:07,142 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:54:07,143 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:54:07,210 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:54:07,210 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:54:07,210 INFO:     No hyperparam tuning for this model
2023-01-04 11:54:07,210 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:54:07,210 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:54:07,211 INFO:     None feature selector for col prot
2023-01-04 11:54:07,211 INFO:     None feature selector for col prot
2023-01-04 11:54:07,211 INFO:     None feature selector for col prot
2023-01-04 11:54:07,212 INFO:     None feature selector for col chem
2023-01-04 11:54:07,212 INFO:     None feature selector for col chem
2023-01-04 11:54:07,212 INFO:     None feature selector for col chem
2023-01-04 11:54:07,212 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:54:07,212 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:54:07,213 INFO:     Number of params in model 70111
2023-01-04 11:54:07,216 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:54:07,216 INFO:   Starting stage: TRAINING
2023-01-04 11:54:07,259 INFO:     Val loss before train {'Reaction outcome loss': 1.015126496553421, 'Total loss': 1.015126496553421}
2023-01-04 11:54:07,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:07,260 INFO:     Epoch: 0
2023-01-04 11:54:08,798 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7803382297356923, 'Total loss': 0.7803382297356923} | train loss {'Reaction outcome loss': 0.8450757637076134, 'Total loss': 0.8450757637076134}
2023-01-04 11:54:08,799 INFO:     Found new best model at epoch 0
2023-01-04 11:54:08,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:08,800 INFO:     Epoch: 1
2023-01-04 11:54:10,311 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6775709470113118, 'Total loss': 0.6775709470113118} | train loss {'Reaction outcome loss': 0.6807846068574565, 'Total loss': 0.6807846068574565}
2023-01-04 11:54:10,311 INFO:     Found new best model at epoch 1
2023-01-04 11:54:10,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:10,312 INFO:     Epoch: 2
2023-01-04 11:54:11,836 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5794165253639221, 'Total loss': 0.5794165253639221} | train loss {'Reaction outcome loss': 0.5943751548872377, 'Total loss': 0.5943751548872377}
2023-01-04 11:54:11,837 INFO:     Found new best model at epoch 2
2023-01-04 11:54:11,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:11,837 INFO:     Epoch: 3
2023-01-04 11:54:13,382 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5880707025527954, 'Total loss': 0.5880707025527954} | train loss {'Reaction outcome loss': 0.5506953303940105, 'Total loss': 0.5506953303940105}
2023-01-04 11:54:13,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:13,382 INFO:     Epoch: 4
2023-01-04 11:54:14,937 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5886042098204295, 'Total loss': 0.5886042098204295} | train loss {'Reaction outcome loss': 0.5329301235993413, 'Total loss': 0.5329301235993413}
2023-01-04 11:54:14,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:14,938 INFO:     Epoch: 5
2023-01-04 11:54:16,474 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5300137599309286, 'Total loss': 0.5300137599309286} | train loss {'Reaction outcome loss': 0.5117404337455757, 'Total loss': 0.5117404337455757}
2023-01-04 11:54:16,474 INFO:     Found new best model at epoch 5
2023-01-04 11:54:16,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:16,475 INFO:     Epoch: 6
2023-01-04 11:54:17,997 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5358484307924907, 'Total loss': 0.5358484307924907} | train loss {'Reaction outcome loss': 0.4971624268014936, 'Total loss': 0.4971624268014936}
2023-01-04 11:54:17,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:17,997 INFO:     Epoch: 7
2023-01-04 11:54:19,523 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5457201103369395, 'Total loss': 0.5457201103369395} | train loss {'Reaction outcome loss': 0.48643247413374213, 'Total loss': 0.48643247413374213}
2023-01-04 11:54:19,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:19,524 INFO:     Epoch: 8
2023-01-04 11:54:21,031 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5033241907755533, 'Total loss': 0.5033241907755533} | train loss {'Reaction outcome loss': 0.4798459831054193, 'Total loss': 0.4798459831054193}
2023-01-04 11:54:21,031 INFO:     Found new best model at epoch 8
2023-01-04 11:54:21,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:21,032 INFO:     Epoch: 9
2023-01-04 11:54:22,574 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5382872919241587, 'Total loss': 0.5382872919241587} | train loss {'Reaction outcome loss': 0.47406812566910345, 'Total loss': 0.47406812566910345}
2023-01-04 11:54:22,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:22,574 INFO:     Epoch: 10
2023-01-04 11:54:24,120 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5412673453489939, 'Total loss': 0.5412673453489939} | train loss {'Reaction outcome loss': 0.46779314945213984, 'Total loss': 0.46779314945213984}
2023-01-04 11:54:24,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:24,120 INFO:     Epoch: 11
2023-01-04 11:54:25,671 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5179145991802215, 'Total loss': 0.5179145991802215} | train loss {'Reaction outcome loss': 0.4590263034414201, 'Total loss': 0.4590263034414201}
2023-01-04 11:54:25,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:25,671 INFO:     Epoch: 12
2023-01-04 11:54:27,211 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48576244910558064, 'Total loss': 0.48576244910558064} | train loss {'Reaction outcome loss': 0.4545974576995321, 'Total loss': 0.4545974576995321}
2023-01-04 11:54:27,211 INFO:     Found new best model at epoch 12
2023-01-04 11:54:27,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:27,212 INFO:     Epoch: 13
2023-01-04 11:54:28,784 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4836644689242045, 'Total loss': 0.4836644689242045} | train loss {'Reaction outcome loss': 0.44769078797667566, 'Total loss': 0.44769078797667566}
2023-01-04 11:54:28,784 INFO:     Found new best model at epoch 13
2023-01-04 11:54:28,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:28,785 INFO:     Epoch: 14
2023-01-04 11:54:30,326 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48532098134358725, 'Total loss': 0.48532098134358725} | train loss {'Reaction outcome loss': 0.4435384154972369, 'Total loss': 0.4435384154972369}
2023-01-04 11:54:30,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:30,326 INFO:     Epoch: 15
2023-01-04 11:54:31,907 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46345457832018533, 'Total loss': 0.46345457832018533} | train loss {'Reaction outcome loss': 0.441970078723274, 'Total loss': 0.441970078723274}
2023-01-04 11:54:31,907 INFO:     Found new best model at epoch 15
2023-01-04 11:54:31,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:31,908 INFO:     Epoch: 16
2023-01-04 11:54:33,480 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48606142699718474, 'Total loss': 0.48606142699718474} | train loss {'Reaction outcome loss': 0.43609045424165516, 'Total loss': 0.43609045424165516}
2023-01-04 11:54:33,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:33,481 INFO:     Epoch: 17
2023-01-04 11:54:35,049 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45442170798778536, 'Total loss': 0.45442170798778536} | train loss {'Reaction outcome loss': 0.4312165233775647, 'Total loss': 0.4312165233775647}
2023-01-04 11:54:35,049 INFO:     Found new best model at epoch 17
2023-01-04 11:54:35,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:35,050 INFO:     Epoch: 18
2023-01-04 11:54:36,583 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4857259114583333, 'Total loss': 0.4857259114583333} | train loss {'Reaction outcome loss': 0.4272424115860549, 'Total loss': 0.4272424115860549}
2023-01-04 11:54:36,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:36,584 INFO:     Epoch: 19
2023-01-04 11:54:38,150 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47549182971318565, 'Total loss': 0.47549182971318565} | train loss {'Reaction outcome loss': 0.4256800145563418, 'Total loss': 0.4256800145563418}
2023-01-04 11:54:38,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:38,150 INFO:     Epoch: 20
2023-01-04 11:54:39,678 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48053054412206014, 'Total loss': 0.48053054412206014} | train loss {'Reaction outcome loss': 0.41700075558611077, 'Total loss': 0.41700075558611077}
2023-01-04 11:54:39,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:39,679 INFO:     Epoch: 21
2023-01-04 11:54:41,214 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44857054750124614, 'Total loss': 0.44857054750124614} | train loss {'Reaction outcome loss': 0.41651706838042196, 'Total loss': 0.41651706838042196}
2023-01-04 11:54:41,214 INFO:     Found new best model at epoch 21
2023-01-04 11:54:41,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:41,215 INFO:     Epoch: 22
2023-01-04 11:54:42,765 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4511779765288035, 'Total loss': 0.4511779765288035} | train loss {'Reaction outcome loss': 0.40934044234182715, 'Total loss': 0.40934044234182715}
2023-01-04 11:54:42,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:42,766 INFO:     Epoch: 23
2023-01-04 11:54:44,307 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5019064605236053, 'Total loss': 0.5019064605236053} | train loss {'Reaction outcome loss': 0.40683837751620006, 'Total loss': 0.40683837751620006}
2023-01-04 11:54:44,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:44,307 INFO:     Epoch: 24
2023-01-04 11:54:45,822 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4457130491733551, 'Total loss': 0.4457130491733551} | train loss {'Reaction outcome loss': 0.402600959487205, 'Total loss': 0.402600959487205}
2023-01-04 11:54:45,822 INFO:     Found new best model at epoch 24
2023-01-04 11:54:45,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:45,823 INFO:     Epoch: 25
2023-01-04 11:54:47,381 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.455391122897466, 'Total loss': 0.455391122897466} | train loss {'Reaction outcome loss': 0.3957705973871868, 'Total loss': 0.3957705973871868}
2023-01-04 11:54:47,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:47,382 INFO:     Epoch: 26
2023-01-04 11:54:48,902 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46429984271526337, 'Total loss': 0.46429984271526337} | train loss {'Reaction outcome loss': 0.39114224807406867, 'Total loss': 0.39114224807406867}
2023-01-04 11:54:48,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:48,903 INFO:     Epoch: 27
2023-01-04 11:54:50,463 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4642654339472453, 'Total loss': 0.4642654339472453} | train loss {'Reaction outcome loss': 0.38652760176545514, 'Total loss': 0.38652760176545514}
2023-01-04 11:54:50,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:50,463 INFO:     Epoch: 28
2023-01-04 11:54:52,026 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4481903294722239, 'Total loss': 0.4481903294722239} | train loss {'Reaction outcome loss': 0.3840816780707262, 'Total loss': 0.3840816780707262}
2023-01-04 11:54:52,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:52,027 INFO:     Epoch: 29
2023-01-04 11:54:53,581 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4438102781772614, 'Total loss': 0.4438102781772614} | train loss {'Reaction outcome loss': 0.3758777316088659, 'Total loss': 0.3758777316088659}
2023-01-04 11:54:53,581 INFO:     Found new best model at epoch 29
2023-01-04 11:54:53,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:53,582 INFO:     Epoch: 30
2023-01-04 11:54:55,109 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4462336152791977, 'Total loss': 0.4462336152791977} | train loss {'Reaction outcome loss': 0.3724164555433893, 'Total loss': 0.3724164555433893}
2023-01-04 11:54:55,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:55,109 INFO:     Epoch: 31
2023-01-04 11:54:56,662 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45093517899513247, 'Total loss': 0.45093517899513247} | train loss {'Reaction outcome loss': 0.37251485938573403, 'Total loss': 0.37251485938573403}
2023-01-04 11:54:56,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:56,663 INFO:     Epoch: 32
2023-01-04 11:54:58,232 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4477617780367533, 'Total loss': 0.4477617780367533} | train loss {'Reaction outcome loss': 0.3671846961208286, 'Total loss': 0.3671846961208286}
2023-01-04 11:54:58,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:58,232 INFO:     Epoch: 33
2023-01-04 11:54:59,824 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42561282714207965, 'Total loss': 0.42561282714207965} | train loss {'Reaction outcome loss': 0.36016356085773804, 'Total loss': 0.36016356085773804}
2023-01-04 11:54:59,824 INFO:     Found new best model at epoch 33
2023-01-04 11:54:59,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:54:59,825 INFO:     Epoch: 34
2023-01-04 11:55:01,417 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4593748807907104, 'Total loss': 0.4593748807907104} | train loss {'Reaction outcome loss': 0.35790897685572176, 'Total loss': 0.35790897685572176}
2023-01-04 11:55:01,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:01,417 INFO:     Epoch: 35
2023-01-04 11:55:03,004 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4331535369157791, 'Total loss': 0.4331535369157791} | train loss {'Reaction outcome loss': 0.35537922259991184, 'Total loss': 0.35537922259991184}
2023-01-04 11:55:03,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:03,005 INFO:     Epoch: 36
2023-01-04 11:55:04,535 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43413472175598145, 'Total loss': 0.43413472175598145} | train loss {'Reaction outcome loss': 0.35533755800149736, 'Total loss': 0.35533755800149736}
2023-01-04 11:55:04,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:04,535 INFO:     Epoch: 37
2023-01-04 11:55:06,055 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41415776014328004, 'Total loss': 0.41415776014328004} | train loss {'Reaction outcome loss': 0.3467261689803461, 'Total loss': 0.3467261689803461}
2023-01-04 11:55:06,055 INFO:     Found new best model at epoch 37
2023-01-04 11:55:06,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:06,056 INFO:     Epoch: 38
2023-01-04 11:55:07,608 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42210530241330463, 'Total loss': 0.42210530241330463} | train loss {'Reaction outcome loss': 0.3458078135974216, 'Total loss': 0.3458078135974216}
2023-01-04 11:55:07,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:07,608 INFO:     Epoch: 39
2023-01-04 11:55:09,173 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.443075496951739, 'Total loss': 0.443075496951739} | train loss {'Reaction outcome loss': 0.3395906252256275, 'Total loss': 0.3395906252256275}
2023-01-04 11:55:09,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:09,174 INFO:     Epoch: 40
2023-01-04 11:55:10,733 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4149184872706731, 'Total loss': 0.4149184872706731} | train loss {'Reaction outcome loss': 0.33428070585440545, 'Total loss': 0.33428070585440545}
2023-01-04 11:55:10,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:10,733 INFO:     Epoch: 41
2023-01-04 11:55:12,267 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44077074229717256, 'Total loss': 0.44077074229717256} | train loss {'Reaction outcome loss': 0.33608246847552103, 'Total loss': 0.33608246847552103}
2023-01-04 11:55:12,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:12,268 INFO:     Epoch: 42
2023-01-04 11:55:13,811 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4309955358505249, 'Total loss': 0.4309955358505249} | train loss {'Reaction outcome loss': 0.32808755493185815, 'Total loss': 0.32808755493185815}
2023-01-04 11:55:13,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:13,811 INFO:     Epoch: 43
2023-01-04 11:55:15,342 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4054701914389928, 'Total loss': 0.4054701914389928} | train loss {'Reaction outcome loss': 0.32769785141640334, 'Total loss': 0.32769785141640334}
2023-01-04 11:55:15,343 INFO:     Found new best model at epoch 43
2023-01-04 11:55:15,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:15,343 INFO:     Epoch: 44
2023-01-04 11:55:16,907 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4207678476969401, 'Total loss': 0.4207678476969401} | train loss {'Reaction outcome loss': 0.3222453336428552, 'Total loss': 0.3222453336428552}
2023-01-04 11:55:16,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:16,907 INFO:     Epoch: 45
2023-01-04 11:55:18,457 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43908950289090476, 'Total loss': 0.43908950289090476} | train loss {'Reaction outcome loss': 0.3210463880894393, 'Total loss': 0.3210463880894393}
2023-01-04 11:55:18,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:18,457 INFO:     Epoch: 46
2023-01-04 11:55:20,017 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41860380619764326, 'Total loss': 0.41860380619764326} | train loss {'Reaction outcome loss': 0.31753260609659834, 'Total loss': 0.31753260609659834}
2023-01-04 11:55:20,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:20,018 INFO:     Epoch: 47
2023-01-04 11:55:21,548 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4034369627634684, 'Total loss': 0.4034369627634684} | train loss {'Reaction outcome loss': 0.32068104345868104, 'Total loss': 0.32068104345868104}
2023-01-04 11:55:21,548 INFO:     Found new best model at epoch 47
2023-01-04 11:55:21,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:21,549 INFO:     Epoch: 48
2023-01-04 11:55:23,112 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4345063120126724, 'Total loss': 0.4345063120126724} | train loss {'Reaction outcome loss': 0.3164324182337218, 'Total loss': 0.3164324182337218}
2023-01-04 11:55:23,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:23,112 INFO:     Epoch: 49
2023-01-04 11:55:24,638 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41688208480676014, 'Total loss': 0.41688208480676014} | train loss {'Reaction outcome loss': 0.30774109291225454, 'Total loss': 0.30774109291225454}
2023-01-04 11:55:24,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:24,638 INFO:     Epoch: 50
2023-01-04 11:55:26,199 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40622514486312866, 'Total loss': 0.40622514486312866} | train loss {'Reaction outcome loss': 0.31593055306614315, 'Total loss': 0.31593055306614315}
2023-01-04 11:55:26,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:26,199 INFO:     Epoch: 51
2023-01-04 11:55:27,777 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3988584756851196, 'Total loss': 0.3988584756851196} | train loss {'Reaction outcome loss': 0.30578726453937755, 'Total loss': 0.30578726453937755}
2023-01-04 11:55:27,777 INFO:     Found new best model at epoch 51
2023-01-04 11:55:27,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:27,778 INFO:     Epoch: 52
2023-01-04 11:55:29,325 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.425617316365242, 'Total loss': 0.425617316365242} | train loss {'Reaction outcome loss': 0.3094412105796981, 'Total loss': 0.3094412105796981}
2023-01-04 11:55:29,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:29,325 INFO:     Epoch: 53
2023-01-04 11:55:30,849 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42249703605969746, 'Total loss': 0.42249703605969746} | train loss {'Reaction outcome loss': 0.2987728276337585, 'Total loss': 0.2987728276337585}
2023-01-04 11:55:30,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:30,849 INFO:     Epoch: 54
2023-01-04 11:55:32,413 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4013359894355138, 'Total loss': 0.4013359894355138} | train loss {'Reaction outcome loss': 0.30038119586062256, 'Total loss': 0.30038119586062256}
2023-01-04 11:55:32,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:32,413 INFO:     Epoch: 55
2023-01-04 11:55:33,935 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40391520659128827, 'Total loss': 0.40391520659128827} | train loss {'Reaction outcome loss': 0.2965720748039384, 'Total loss': 0.2965720748039384}
2023-01-04 11:55:33,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:33,935 INFO:     Epoch: 56
2023-01-04 11:55:35,493 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4319746573766073, 'Total loss': 0.4319746573766073} | train loss {'Reaction outcome loss': 0.29677364488478997, 'Total loss': 0.29677364488478997}
2023-01-04 11:55:35,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:35,493 INFO:     Epoch: 57
2023-01-04 11:55:37,079 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4074904680252075, 'Total loss': 0.4074904680252075} | train loss {'Reaction outcome loss': 0.29586294122094653, 'Total loss': 0.29586294122094653}
2023-01-04 11:55:37,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:37,079 INFO:     Epoch: 58
2023-01-04 11:55:38,627 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41755402783552803, 'Total loss': 0.41755402783552803} | train loss {'Reaction outcome loss': 0.29595599394210065, 'Total loss': 0.29595599394210065}
2023-01-04 11:55:38,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:38,627 INFO:     Epoch: 59
2023-01-04 11:55:40,132 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38564749956130984, 'Total loss': 0.38564749956130984} | train loss {'Reaction outcome loss': 0.29084878961426497, 'Total loss': 0.29084878961426497}
2023-01-04 11:55:40,132 INFO:     Found new best model at epoch 59
2023-01-04 11:55:40,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:40,133 INFO:     Epoch: 60
2023-01-04 11:55:41,680 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4173012177149455, 'Total loss': 0.4173012177149455} | train loss {'Reaction outcome loss': 0.288030282478698, 'Total loss': 0.288030282478698}
2023-01-04 11:55:41,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:41,680 INFO:     Epoch: 61
2023-01-04 11:55:43,233 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40376728773117065, 'Total loss': 0.40376728773117065} | train loss {'Reaction outcome loss': 0.2906038424775113, 'Total loss': 0.2906038424775113}
2023-01-04 11:55:43,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:43,233 INFO:     Epoch: 62
2023-01-04 11:55:44,842 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41544834872086844, 'Total loss': 0.41544834872086844} | train loss {'Reaction outcome loss': 0.2855055597440822, 'Total loss': 0.2855055597440822}
2023-01-04 11:55:44,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:44,843 INFO:     Epoch: 63
2023-01-04 11:55:46,457 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42522194385528567, 'Total loss': 0.42522194385528567} | train loss {'Reaction outcome loss': 0.28017858581712646, 'Total loss': 0.28017858581712646}
2023-01-04 11:55:46,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:46,457 INFO:     Epoch: 64
2023-01-04 11:55:48,063 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4226138800382614, 'Total loss': 0.4226138800382614} | train loss {'Reaction outcome loss': 0.2833407158779837, 'Total loss': 0.2833407158779837}
2023-01-04 11:55:48,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:48,063 INFO:     Epoch: 65
2023-01-04 11:55:49,633 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4043271084626516, 'Total loss': 0.4043271084626516} | train loss {'Reaction outcome loss': 0.2791466057490911, 'Total loss': 0.2791466057490911}
2023-01-04 11:55:49,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:49,634 INFO:     Epoch: 66
2023-01-04 11:55:51,249 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46060789227485655, 'Total loss': 0.46060789227485655} | train loss {'Reaction outcome loss': 0.2774741196814571, 'Total loss': 0.2774741196814571}
2023-01-04 11:55:51,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:51,250 INFO:     Epoch: 67
2023-01-04 11:55:52,820 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3884368379910787, 'Total loss': 0.3884368379910787} | train loss {'Reaction outcome loss': 0.27607906324258685, 'Total loss': 0.27607906324258685}
2023-01-04 11:55:52,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:52,820 INFO:     Epoch: 68
2023-01-04 11:55:54,426 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45141982634862265, 'Total loss': 0.45141982634862265} | train loss {'Reaction outcome loss': 0.27493076203187017, 'Total loss': 0.27493076203187017}
2023-01-04 11:55:54,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:54,427 INFO:     Epoch: 69
2023-01-04 11:55:56,026 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4189639647801717, 'Total loss': 0.4189639647801717} | train loss {'Reaction outcome loss': 0.2727656909230634, 'Total loss': 0.2727656909230634}
2023-01-04 11:55:56,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:56,026 INFO:     Epoch: 70
2023-01-04 11:55:57,630 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38493041396141053, 'Total loss': 0.38493041396141053} | train loss {'Reaction outcome loss': 0.2732661651433819, 'Total loss': 0.2732661651433819}
2023-01-04 11:55:57,630 INFO:     Found new best model at epoch 70
2023-01-04 11:55:57,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:57,631 INFO:     Epoch: 71
2023-01-04 11:55:59,197 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45203717648983, 'Total loss': 0.45203717648983} | train loss {'Reaction outcome loss': 0.2693260747150783, 'Total loss': 0.2693260747150783}
2023-01-04 11:55:59,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:55:59,198 INFO:     Epoch: 72
2023-01-04 11:56:00,704 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41243011752764386, 'Total loss': 0.41243011752764386} | train loss {'Reaction outcome loss': 0.2692956141311757, 'Total loss': 0.2692956141311757}
2023-01-04 11:56:00,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:00,705 INFO:     Epoch: 73
2023-01-04 11:56:02,249 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38703846087058386, 'Total loss': 0.38703846087058386} | train loss {'Reaction outcome loss': 0.2693849591008068, 'Total loss': 0.2693849591008068}
2023-01-04 11:56:02,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:02,249 INFO:     Epoch: 74
2023-01-04 11:56:03,801 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4194158981243769, 'Total loss': 0.4194158981243769} | train loss {'Reaction outcome loss': 0.26535294475509735, 'Total loss': 0.26535294475509735}
2023-01-04 11:56:03,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:03,802 INFO:     Epoch: 75
2023-01-04 11:56:05,361 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43747507135073344, 'Total loss': 0.43747507135073344} | train loss {'Reaction outcome loss': 0.26460548737732165, 'Total loss': 0.26460548737732165}
2023-01-04 11:56:05,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:05,362 INFO:     Epoch: 76
2023-01-04 11:56:06,899 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3950663407643636, 'Total loss': 0.3950663407643636} | train loss {'Reaction outcome loss': 0.26293629270563595, 'Total loss': 0.26293629270563595}
2023-01-04 11:56:06,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:06,900 INFO:     Epoch: 77
2023-01-04 11:56:08,442 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3947811414798101, 'Total loss': 0.3947811414798101} | train loss {'Reaction outcome loss': 0.2615913260102707, 'Total loss': 0.2615913260102707}
2023-01-04 11:56:08,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:08,442 INFO:     Epoch: 78
2023-01-04 11:56:09,958 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39570475518703463, 'Total loss': 0.39570475518703463} | train loss {'Reaction outcome loss': 0.26409676235957735, 'Total loss': 0.26409676235957735}
2023-01-04 11:56:09,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:09,958 INFO:     Epoch: 79
2023-01-04 11:56:11,538 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39580055127541225, 'Total loss': 0.39580055127541225} | train loss {'Reaction outcome loss': 0.25901447456792326, 'Total loss': 0.25901447456792326}
2023-01-04 11:56:11,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:11,539 INFO:     Epoch: 80
2023-01-04 11:56:13,136 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4332010308901469, 'Total loss': 0.4332010308901469} | train loss {'Reaction outcome loss': 0.2622368559241295, 'Total loss': 0.2622368559241295}
2023-01-04 11:56:13,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:13,136 INFO:     Epoch: 81
2023-01-04 11:56:14,712 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.409364586075147, 'Total loss': 0.409364586075147} | train loss {'Reaction outcome loss': 0.25840088752281926, 'Total loss': 0.25840088752281926}
2023-01-04 11:56:14,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:14,714 INFO:     Epoch: 82
2023-01-04 11:56:16,244 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43367649912834166, 'Total loss': 0.43367649912834166} | train loss {'Reaction outcome loss': 0.2518918148520654, 'Total loss': 0.2518918148520654}
2023-01-04 11:56:16,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:16,244 INFO:     Epoch: 83
2023-01-04 11:56:17,809 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4449082414309184, 'Total loss': 0.4449082414309184} | train loss {'Reaction outcome loss': 0.2525273720686236, 'Total loss': 0.2525273720686236}
2023-01-04 11:56:17,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:17,809 INFO:     Epoch: 84
2023-01-04 11:56:19,332 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41855741540590924, 'Total loss': 0.41855741540590924} | train loss {'Reaction outcome loss': 0.258054349136396, 'Total loss': 0.258054349136396}
2023-01-04 11:56:19,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:19,332 INFO:     Epoch: 85
2023-01-04 11:56:20,878 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4320230563481649, 'Total loss': 0.4320230563481649} | train loss {'Reaction outcome loss': 0.25470706903423274, 'Total loss': 0.25470706903423274}
2023-01-04 11:56:20,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:20,879 INFO:     Epoch: 86
2023-01-04 11:56:22,441 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42753369410832726, 'Total loss': 0.42753369410832726} | train loss {'Reaction outcome loss': 0.2511203357419611, 'Total loss': 0.2511203357419611}
2023-01-04 11:56:22,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:22,442 INFO:     Epoch: 87
2023-01-04 11:56:23,994 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4278468430042267, 'Total loss': 0.4278468430042267} | train loss {'Reaction outcome loss': 0.2513290944162512, 'Total loss': 0.2513290944162512}
2023-01-04 11:56:23,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:23,994 INFO:     Epoch: 88
2023-01-04 11:56:25,519 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46250352064768474, 'Total loss': 0.46250352064768474} | train loss {'Reaction outcome loss': 0.2556129545381252, 'Total loss': 0.2556129545381252}
2023-01-04 11:56:25,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:25,519 INFO:     Epoch: 89
2023-01-04 11:56:27,058 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3932050327459971, 'Total loss': 0.3932050327459971} | train loss {'Reaction outcome loss': 0.24665996353447872, 'Total loss': 0.24665996353447872}
2023-01-04 11:56:27,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:27,059 INFO:     Epoch: 90
2023-01-04 11:56:28,567 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3844494268298149, 'Total loss': 0.3844494268298149} | train loss {'Reaction outcome loss': 0.2504415112364031, 'Total loss': 0.2504415112364031}
2023-01-04 11:56:28,567 INFO:     Found new best model at epoch 90
2023-01-04 11:56:28,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:28,567 INFO:     Epoch: 91
2023-01-04 11:56:30,109 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41181766291459404, 'Total loss': 0.41181766291459404} | train loss {'Reaction outcome loss': 0.25451671854205377, 'Total loss': 0.25451671854205377}
2023-01-04 11:56:30,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:30,109 INFO:     Epoch: 92
2023-01-04 11:56:31,642 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4413863817850749, 'Total loss': 0.4413863817850749} | train loss {'Reaction outcome loss': 0.2477490261033939, 'Total loss': 0.2477490261033939}
2023-01-04 11:56:31,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:31,642 INFO:     Epoch: 93
2023-01-04 11:56:33,179 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41166986525058746, 'Total loss': 0.41166986525058746} | train loss {'Reaction outcome loss': 0.24426477715155503, 'Total loss': 0.24426477715155503}
2023-01-04 11:56:33,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:33,180 INFO:     Epoch: 94
2023-01-04 11:56:34,692 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41884880761305493, 'Total loss': 0.41884880761305493} | train loss {'Reaction outcome loss': 0.24070155479177072, 'Total loss': 0.24070155479177072}
2023-01-04 11:56:34,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:34,693 INFO:     Epoch: 95
2023-01-04 11:56:36,227 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4110969066619873, 'Total loss': 0.4110969066619873} | train loss {'Reaction outcome loss': 0.24359400034712178, 'Total loss': 0.24359400034712178}
2023-01-04 11:56:36,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:36,227 INFO:     Epoch: 96
2023-01-04 11:56:37,727 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3973291883865992, 'Total loss': 0.3973291883865992} | train loss {'Reaction outcome loss': 0.24422044373613638, 'Total loss': 0.24422044373613638}
2023-01-04 11:56:37,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:37,727 INFO:     Epoch: 97
2023-01-04 11:56:39,251 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3999950021505356, 'Total loss': 0.3999950021505356} | train loss {'Reaction outcome loss': 0.24836187855931965, 'Total loss': 0.24836187855931965}
2023-01-04 11:56:39,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:39,252 INFO:     Epoch: 98
2023-01-04 11:56:40,803 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39577544381221136, 'Total loss': 0.39577544381221136} | train loss {'Reaction outcome loss': 0.24146049184194446, 'Total loss': 0.24146049184194446}
2023-01-04 11:56:40,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:40,804 INFO:     Epoch: 99
2023-01-04 11:56:42,346 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39356095492839815, 'Total loss': 0.39356095492839815} | train loss {'Reaction outcome loss': 0.23991364842946947, 'Total loss': 0.23991364842946947}
2023-01-04 11:56:42,346 INFO:     Best model found after epoch 91 of 100.
2023-01-04 11:56:42,346 INFO:   Done with stage: TRAINING
2023-01-04 11:56:42,346 INFO:   Starting stage: EVALUATION
2023-01-04 11:56:42,479 INFO:   Done with stage: EVALUATION
2023-01-04 11:56:42,479 INFO:   Leaving out SEQ value Fold_6
2023-01-04 11:56:42,492 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 11:56:42,492 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:56:43,132 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:56:43,132 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:56:43,200 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:56:43,200 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:56:43,200 INFO:     No hyperparam tuning for this model
2023-01-04 11:56:43,200 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:56:43,200 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:56:43,201 INFO:     None feature selector for col prot
2023-01-04 11:56:43,201 INFO:     None feature selector for col prot
2023-01-04 11:56:43,201 INFO:     None feature selector for col prot
2023-01-04 11:56:43,202 INFO:     None feature selector for col chem
2023-01-04 11:56:43,202 INFO:     None feature selector for col chem
2023-01-04 11:56:43,202 INFO:     None feature selector for col chem
2023-01-04 11:56:43,202 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:56:43,202 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:56:43,203 INFO:     Number of params in model 70111
2023-01-04 11:56:43,206 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:56:43,206 INFO:   Starting stage: TRAINING
2023-01-04 11:56:43,249 INFO:     Val loss before train {'Reaction outcome loss': 1.0405584891637167, 'Total loss': 1.0405584891637167}
2023-01-04 11:56:43,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:43,249 INFO:     Epoch: 0
2023-01-04 11:56:44,800 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7284457842508952, 'Total loss': 0.7284457842508952} | train loss {'Reaction outcome loss': 0.8352574899738876, 'Total loss': 0.8352574899738876}
2023-01-04 11:56:44,800 INFO:     Found new best model at epoch 0
2023-01-04 11:56:44,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:44,800 INFO:     Epoch: 1
2023-01-04 11:56:46,312 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.596053671836853, 'Total loss': 0.596053671836853} | train loss {'Reaction outcome loss': 0.665134745276792, 'Total loss': 0.665134745276792}
2023-01-04 11:56:46,312 INFO:     Found new best model at epoch 1
2023-01-04 11:56:46,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:46,313 INFO:     Epoch: 2
2023-01-04 11:56:47,855 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5179358959197998, 'Total loss': 0.5179358959197998} | train loss {'Reaction outcome loss': 0.581620393031771, 'Total loss': 0.581620393031771}
2023-01-04 11:56:47,855 INFO:     Found new best model at epoch 2
2023-01-04 11:56:47,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:47,856 INFO:     Epoch: 3
2023-01-04 11:56:49,403 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4860735058784485, 'Total loss': 0.4860735058784485} | train loss {'Reaction outcome loss': 0.5457882002695372, 'Total loss': 0.5457882002695372}
2023-01-04 11:56:49,403 INFO:     Found new best model at epoch 3
2023-01-04 11:56:49,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:49,403 INFO:     Epoch: 4
2023-01-04 11:56:50,946 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4562948207060496, 'Total loss': 0.4562948207060496} | train loss {'Reaction outcome loss': 0.5224039618073818, 'Total loss': 0.5224039618073818}
2023-01-04 11:56:50,947 INFO:     Found new best model at epoch 4
2023-01-04 11:56:50,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:50,948 INFO:     Epoch: 5
2023-01-04 11:56:52,470 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4724622666835785, 'Total loss': 0.4724622666835785} | train loss {'Reaction outcome loss': 0.511226325420266, 'Total loss': 0.511226325420266}
2023-01-04 11:56:52,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:52,471 INFO:     Epoch: 6
2023-01-04 11:56:54,026 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46822115977605183, 'Total loss': 0.46822115977605183} | train loss {'Reaction outcome loss': 0.4958674484857153, 'Total loss': 0.4958674484857153}
2023-01-04 11:56:54,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:54,027 INFO:     Epoch: 7
2023-01-04 11:56:55,539 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44784978628158567, 'Total loss': 0.44784978628158567} | train loss {'Reaction outcome loss': 0.4871629187131186, 'Total loss': 0.4871629187131186}
2023-01-04 11:56:55,539 INFO:     Found new best model at epoch 7
2023-01-04 11:56:55,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:55,540 INFO:     Epoch: 8
2023-01-04 11:56:57,086 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43588488300641376, 'Total loss': 0.43588488300641376} | train loss {'Reaction outcome loss': 0.478331687594579, 'Total loss': 0.478331687594579}
2023-01-04 11:56:57,087 INFO:     Found new best model at epoch 8
2023-01-04 11:56:57,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:57,088 INFO:     Epoch: 9
2023-01-04 11:56:58,637 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4468352874120077, 'Total loss': 0.4468352874120077} | train loss {'Reaction outcome loss': 0.4722618568513798, 'Total loss': 0.4722618568513798}
2023-01-04 11:56:58,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:56:58,637 INFO:     Epoch: 10
2023-01-04 11:57:00,189 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4335814873377482, 'Total loss': 0.4335814873377482} | train loss {'Reaction outcome loss': 0.4664949445517915, 'Total loss': 0.4664949445517915}
2023-01-04 11:57:00,189 INFO:     Found new best model at epoch 10
2023-01-04 11:57:00,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:00,190 INFO:     Epoch: 11
2023-01-04 11:57:01,713 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43164217472076416, 'Total loss': 0.43164217472076416} | train loss {'Reaction outcome loss': 0.46049154003819837, 'Total loss': 0.46049154003819837}
2023-01-04 11:57:01,713 INFO:     Found new best model at epoch 11
2023-01-04 11:57:01,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:01,714 INFO:     Epoch: 12
2023-01-04 11:57:03,265 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41896728177865344, 'Total loss': 0.41896728177865344} | train loss {'Reaction outcome loss': 0.45395601123894164, 'Total loss': 0.45395601123894164}
2023-01-04 11:57:03,265 INFO:     Found new best model at epoch 12
2023-01-04 11:57:03,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:03,266 INFO:     Epoch: 13
2023-01-04 11:57:04,786 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4358539084593455, 'Total loss': 0.4358539084593455} | train loss {'Reaction outcome loss': 0.4457701948145236, 'Total loss': 0.4457701948145236}
2023-01-04 11:57:04,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:04,786 INFO:     Epoch: 14
2023-01-04 11:57:06,333 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4263332853714625, 'Total loss': 0.4263332853714625} | train loss {'Reaction outcome loss': 0.4439539905059208, 'Total loss': 0.4439539905059208}
2023-01-04 11:57:06,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:06,333 INFO:     Epoch: 15
2023-01-04 11:57:07,883 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40737263957659403, 'Total loss': 0.40737263957659403} | train loss {'Reaction outcome loss': 0.43808654714577466, 'Total loss': 0.43808654714577466}
2023-01-04 11:57:07,883 INFO:     Found new best model at epoch 15
2023-01-04 11:57:07,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:07,884 INFO:     Epoch: 16
2023-01-04 11:57:09,422 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42341236074765526, 'Total loss': 0.42341236074765526} | train loss {'Reaction outcome loss': 0.43615046304916216, 'Total loss': 0.43615046304916216}
2023-01-04 11:57:09,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:09,423 INFO:     Epoch: 17
2023-01-04 11:57:10,954 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4436096986134847, 'Total loss': 0.4436096986134847} | train loss {'Reaction outcome loss': 0.431972359761004, 'Total loss': 0.431972359761004}
2023-01-04 11:57:10,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:10,954 INFO:     Epoch: 18
2023-01-04 11:57:12,501 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4217080364624659, 'Total loss': 0.4217080364624659} | train loss {'Reaction outcome loss': 0.42350468884091086, 'Total loss': 0.42350468884091086}
2023-01-04 11:57:12,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:12,501 INFO:     Epoch: 19
2023-01-04 11:57:14,013 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42551667193571724, 'Total loss': 0.42551667193571724} | train loss {'Reaction outcome loss': 0.42038679660872863, 'Total loss': 0.42038679660872863}
2023-01-04 11:57:14,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:14,013 INFO:     Epoch: 20
2023-01-04 11:57:15,563 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40336400667826333, 'Total loss': 0.40336400667826333} | train loss {'Reaction outcome loss': 0.41564258782441865, 'Total loss': 0.41564258782441865}
2023-01-04 11:57:15,564 INFO:     Found new best model at epoch 20
2023-01-04 11:57:15,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:15,564 INFO:     Epoch: 21
2023-01-04 11:57:17,112 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41564322809378307, 'Total loss': 0.41564322809378307} | train loss {'Reaction outcome loss': 0.41176735639356965, 'Total loss': 0.41176735639356965}
2023-01-04 11:57:17,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:17,112 INFO:     Epoch: 22
2023-01-04 11:57:18,659 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44145565032958983, 'Total loss': 0.44145565032958983} | train loss {'Reaction outcome loss': 0.4102682408335407, 'Total loss': 0.4102682408335407}
2023-01-04 11:57:18,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:18,659 INFO:     Epoch: 23
2023-01-04 11:57:20,188 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39815413653850557, 'Total loss': 0.39815413653850557} | train loss {'Reaction outcome loss': 0.4020925121724821, 'Total loss': 0.4020925121724821}
2023-01-04 11:57:20,188 INFO:     Found new best model at epoch 23
2023-01-04 11:57:20,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:20,188 INFO:     Epoch: 24
2023-01-04 11:57:21,730 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4181194802125295, 'Total loss': 0.4181194802125295} | train loss {'Reaction outcome loss': 0.4001655846511414, 'Total loss': 0.4001655846511414}
2023-01-04 11:57:21,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:21,731 INFO:     Epoch: 25
2023-01-04 11:57:23,249 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41606227854887645, 'Total loss': 0.41606227854887645} | train loss {'Reaction outcome loss': 0.3942497163634438, 'Total loss': 0.3942497163634438}
2023-01-04 11:57:23,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:23,249 INFO:     Epoch: 26
2023-01-04 11:57:24,806 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40053289333979286, 'Total loss': 0.40053289333979286} | train loss {'Reaction outcome loss': 0.3960361894663921, 'Total loss': 0.3960361894663921}
2023-01-04 11:57:24,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:24,807 INFO:     Epoch: 27
2023-01-04 11:57:26,358 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39513115187486014, 'Total loss': 0.39513115187486014} | train loss {'Reaction outcome loss': 0.38497747502387214, 'Total loss': 0.38497747502387214}
2023-01-04 11:57:26,358 INFO:     Found new best model at epoch 27
2023-01-04 11:57:26,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:26,359 INFO:     Epoch: 28
2023-01-04 11:57:27,918 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4079915891091029, 'Total loss': 0.4079915891091029} | train loss {'Reaction outcome loss': 0.3860980659615692, 'Total loss': 0.3860980659615692}
2023-01-04 11:57:27,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:27,919 INFO:     Epoch: 29
2023-01-04 11:57:29,445 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40433811843395234, 'Total loss': 0.40433811843395234} | train loss {'Reaction outcome loss': 0.3791678435697022, 'Total loss': 0.3791678435697022}
2023-01-04 11:57:29,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:29,446 INFO:     Epoch: 30
2023-01-04 11:57:31,007 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4126871287822723, 'Total loss': 0.4126871287822723} | train loss {'Reaction outcome loss': 0.37716252467047007, 'Total loss': 0.37716252467047007}
2023-01-04 11:57:31,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:31,007 INFO:     Epoch: 31
2023-01-04 11:57:32,538 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3822589526573817, 'Total loss': 0.3822589526573817} | train loss {'Reaction outcome loss': 0.3744566732419097, 'Total loss': 0.3744566732419097}
2023-01-04 11:57:32,538 INFO:     Found new best model at epoch 31
2023-01-04 11:57:32,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:32,539 INFO:     Epoch: 32
2023-01-04 11:57:34,101 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.399093371629715, 'Total loss': 0.399093371629715} | train loss {'Reaction outcome loss': 0.37046567832089505, 'Total loss': 0.37046567832089505}
2023-01-04 11:57:34,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:34,102 INFO:     Epoch: 33
2023-01-04 11:57:35,665 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39237068096796673, 'Total loss': 0.39237068096796673} | train loss {'Reaction outcome loss': 0.36405042774087687, 'Total loss': 0.36405042774087687}
2023-01-04 11:57:35,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:35,665 INFO:     Epoch: 34
2023-01-04 11:57:37,226 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37379310429096224, 'Total loss': 0.37379310429096224} | train loss {'Reaction outcome loss': 0.3628476242188512, 'Total loss': 0.3628476242188512}
2023-01-04 11:57:37,226 INFO:     Found new best model at epoch 34
2023-01-04 11:57:37,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:37,227 INFO:     Epoch: 35
2023-01-04 11:57:38,764 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3964003582795461, 'Total loss': 0.3964003582795461} | train loss {'Reaction outcome loss': 0.36259465745317376, 'Total loss': 0.36259465745317376}
2023-01-04 11:57:38,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:38,764 INFO:     Epoch: 36
2023-01-04 11:57:40,294 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3835892970363299, 'Total loss': 0.3835892970363299} | train loss {'Reaction outcome loss': 0.36043913874923106, 'Total loss': 0.36043913874923106}
2023-01-04 11:57:40,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:40,295 INFO:     Epoch: 37
2023-01-04 11:57:41,889 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38744157056013745, 'Total loss': 0.38744157056013745} | train loss {'Reaction outcome loss': 0.3558517026341779, 'Total loss': 0.3558517026341779}
2023-01-04 11:57:41,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:41,890 INFO:     Epoch: 38
2023-01-04 11:57:43,458 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3631663570801417, 'Total loss': 0.3631663570801417} | train loss {'Reaction outcome loss': 0.34913064267768756, 'Total loss': 0.34913064267768756}
2023-01-04 11:57:43,458 INFO:     Found new best model at epoch 38
2023-01-04 11:57:43,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:43,459 INFO:     Epoch: 39
2023-01-04 11:57:45,023 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.37786914507548014, 'Total loss': 0.37786914507548014} | train loss {'Reaction outcome loss': 0.34510178237292743, 'Total loss': 0.34510178237292743}
2023-01-04 11:57:45,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:45,024 INFO:     Epoch: 40
2023-01-04 11:57:46,562 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3959976424773534, 'Total loss': 0.3959976424773534} | train loss {'Reaction outcome loss': 0.34535685421004625, 'Total loss': 0.34535685421004625}
2023-01-04 11:57:46,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:46,563 INFO:     Epoch: 41
2023-01-04 11:57:48,108 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3712627649307251, 'Total loss': 0.3712627649307251} | train loss {'Reaction outcome loss': 0.349421155259067, 'Total loss': 0.349421155259067}
2023-01-04 11:57:48,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:48,108 INFO:     Epoch: 42
2023-01-04 11:57:49,632 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3883965661128362, 'Total loss': 0.3883965661128362} | train loss {'Reaction outcome loss': 0.3420511554886288, 'Total loss': 0.3420511554886288}
2023-01-04 11:57:49,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:49,632 INFO:     Epoch: 43
2023-01-04 11:57:51,201 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40481399595737455, 'Total loss': 0.40481399595737455} | train loss {'Reaction outcome loss': 0.3378598609609724, 'Total loss': 0.3378598609609724}
2023-01-04 11:57:51,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:51,201 INFO:     Epoch: 44
2023-01-04 11:57:52,767 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40544691185156506, 'Total loss': 0.40544691185156506} | train loss {'Reaction outcome loss': 0.33838309326111626, 'Total loss': 0.33838309326111626}
2023-01-04 11:57:52,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:52,768 INFO:     Epoch: 45
2023-01-04 11:57:54,324 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3774852434794108, 'Total loss': 0.3774852434794108} | train loss {'Reaction outcome loss': 0.3351042265549894, 'Total loss': 0.3351042265549894}
2023-01-04 11:57:54,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:54,324 INFO:     Epoch: 46
2023-01-04 11:57:55,838 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3793932686249415, 'Total loss': 0.3793932686249415} | train loss {'Reaction outcome loss': 0.32893681582668627, 'Total loss': 0.32893681582668627}
2023-01-04 11:57:55,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:55,839 INFO:     Epoch: 47
2023-01-04 11:57:57,404 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38352301021416985, 'Total loss': 0.38352301021416985} | train loss {'Reaction outcome loss': 0.32700374754757655, 'Total loss': 0.32700374754757655}
2023-01-04 11:57:57,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:57,404 INFO:     Epoch: 48
2023-01-04 11:57:58,938 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3661067639787992, 'Total loss': 0.3661067639787992} | train loss {'Reaction outcome loss': 0.32632939625087626, 'Total loss': 0.32632939625087626}
2023-01-04 11:57:58,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:57:58,939 INFO:     Epoch: 49
2023-01-04 11:58:00,490 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3807397057612737, 'Total loss': 0.3807397057612737} | train loss {'Reaction outcome loss': 0.32646770211817555, 'Total loss': 0.32646770211817555}
2023-01-04 11:58:00,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:00,491 INFO:     Epoch: 50
2023-01-04 11:58:02,044 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37007635136445366, 'Total loss': 0.37007635136445366} | train loss {'Reaction outcome loss': 0.32659108689330546, 'Total loss': 0.32659108689330546}
2023-01-04 11:58:02,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:02,044 INFO:     Epoch: 51
2023-01-04 11:58:03,663 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3572978941102823, 'Total loss': 0.3572978941102823} | train loss {'Reaction outcome loss': 0.32286589022470297, 'Total loss': 0.32286589022470297}
2023-01-04 11:58:03,663 INFO:     Found new best model at epoch 51
2023-01-04 11:58:03,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:03,664 INFO:     Epoch: 52
2023-01-04 11:58:05,248 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.35205395420392355, 'Total loss': 0.35205395420392355} | train loss {'Reaction outcome loss': 0.3248361069641819, 'Total loss': 0.3248361069641819}
2023-01-04 11:58:05,248 INFO:     Found new best model at epoch 52
2023-01-04 11:58:05,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:05,249 INFO:     Epoch: 53
2023-01-04 11:58:06,870 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36663635273774464, 'Total loss': 0.36663635273774464} | train loss {'Reaction outcome loss': 0.31832610186364246, 'Total loss': 0.31832610186364246}
2023-01-04 11:58:06,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:06,870 INFO:     Epoch: 54
2023-01-04 11:58:08,450 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3951938062906265, 'Total loss': 0.3951938062906265} | train loss {'Reaction outcome loss': 0.3157021834209077, 'Total loss': 0.3157021834209077}
2023-01-04 11:58:08,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:08,450 INFO:     Epoch: 55
2023-01-04 11:58:10,086 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3616863936185837, 'Total loss': 0.3616863936185837} | train loss {'Reaction outcome loss': 0.313457646982119, 'Total loss': 0.313457646982119}
2023-01-04 11:58:10,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:10,087 INFO:     Epoch: 56
2023-01-04 11:58:11,724 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3810658484697342, 'Total loss': 0.3810658484697342} | train loss {'Reaction outcome loss': 0.3135050345575336, 'Total loss': 0.3135050345575336}
2023-01-04 11:58:11,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:11,724 INFO:     Epoch: 57
2023-01-04 11:58:13,361 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3564295868078868, 'Total loss': 0.3564295868078868} | train loss {'Reaction outcome loss': 0.31017813933777894, 'Total loss': 0.31017813933777894}
2023-01-04 11:58:13,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:13,361 INFO:     Epoch: 58
2023-01-04 11:58:14,947 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3525936563809713, 'Total loss': 0.3525936563809713} | train loss {'Reaction outcome loss': 0.3096676093630412, 'Total loss': 0.3096676093630412}
2023-01-04 11:58:14,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:14,947 INFO:     Epoch: 59
2023-01-04 11:58:16,547 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.36756616036097206, 'Total loss': 0.36756616036097206} | train loss {'Reaction outcome loss': 0.30386462993247415, 'Total loss': 0.30386462993247415}
2023-01-04 11:58:16,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:16,547 INFO:     Epoch: 60
2023-01-04 11:58:18,175 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39062208235263823, 'Total loss': 0.39062208235263823} | train loss {'Reaction outcome loss': 0.30477856051190233, 'Total loss': 0.30477856051190233}
2023-01-04 11:58:18,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:18,175 INFO:     Epoch: 61
2023-01-04 11:58:19,810 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38932551940282184, 'Total loss': 0.38932551940282184} | train loss {'Reaction outcome loss': 0.31033061498554176, 'Total loss': 0.31033061498554176}
2023-01-04 11:58:19,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:19,810 INFO:     Epoch: 62
2023-01-04 11:58:21,433 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37070773740609486, 'Total loss': 0.37070773740609486} | train loss {'Reaction outcome loss': 0.3057220814621836, 'Total loss': 0.3057220814621836}
2023-01-04 11:58:21,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:21,434 INFO:     Epoch: 63
2023-01-04 11:58:23,018 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3750358899434408, 'Total loss': 0.3750358899434408} | train loss {'Reaction outcome loss': 0.302225414945976, 'Total loss': 0.302225414945976}
2023-01-04 11:58:23,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:23,019 INFO:     Epoch: 64
2023-01-04 11:58:24,641 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3834364990393321, 'Total loss': 0.3834364990393321} | train loss {'Reaction outcome loss': 0.29959136189805474, 'Total loss': 0.29959136189805474}
2023-01-04 11:58:24,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:24,641 INFO:     Epoch: 65
2023-01-04 11:58:26,222 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38012625177701315, 'Total loss': 0.38012625177701315} | train loss {'Reaction outcome loss': 0.29657050636378435, 'Total loss': 0.29657050636378435}
2023-01-04 11:58:26,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:26,222 INFO:     Epoch: 66
2023-01-04 11:58:27,859 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37443525791168214, 'Total loss': 0.37443525791168214} | train loss {'Reaction outcome loss': 0.29384758133804323, 'Total loss': 0.29384758133804323}
2023-01-04 11:58:27,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:27,859 INFO:     Epoch: 67
2023-01-04 11:58:29,486 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37300560424725215, 'Total loss': 0.37300560424725215} | train loss {'Reaction outcome loss': 0.2949157950841563, 'Total loss': 0.2949157950841563}
2023-01-04 11:58:29,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:29,487 INFO:     Epoch: 68
2023-01-04 11:58:31,117 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40165775616963706, 'Total loss': 0.40165775616963706} | train loss {'Reaction outcome loss': 0.29701697515720493, 'Total loss': 0.29701697515720493}
2023-01-04 11:58:31,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:31,117 INFO:     Epoch: 69
2023-01-04 11:58:32,649 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3553759753704071, 'Total loss': 0.3553759753704071} | train loss {'Reaction outcome loss': 0.2910261039591868, 'Total loss': 0.2910261039591868}
2023-01-04 11:58:32,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:32,649 INFO:     Epoch: 70
2023-01-04 11:58:34,278 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.35728398760159813, 'Total loss': 0.35728398760159813} | train loss {'Reaction outcome loss': 0.2914943990401843, 'Total loss': 0.2914943990401843}
2023-01-04 11:58:34,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:34,279 INFO:     Epoch: 71
2023-01-04 11:58:35,811 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.35953175524870556, 'Total loss': 0.35953175524870556} | train loss {'Reaction outcome loss': 0.2866455573682751, 'Total loss': 0.2866455573682751}
2023-01-04 11:58:35,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:35,811 INFO:     Epoch: 72
2023-01-04 11:58:37,361 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3818541795015335, 'Total loss': 0.3818541795015335} | train loss {'Reaction outcome loss': 0.2896441092398623, 'Total loss': 0.2896441092398623}
2023-01-04 11:58:37,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:37,361 INFO:     Epoch: 73
2023-01-04 11:58:38,908 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3675974835952123, 'Total loss': 0.3675974835952123} | train loss {'Reaction outcome loss': 0.2857379088655706, 'Total loss': 0.2857379088655706}
2023-01-04 11:58:38,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:38,908 INFO:     Epoch: 74
2023-01-04 11:58:40,466 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39056107997894285, 'Total loss': 0.39056107997894285} | train loss {'Reaction outcome loss': 0.2850934985070237, 'Total loss': 0.2850934985070237}
2023-01-04 11:58:40,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:40,467 INFO:     Epoch: 75
2023-01-04 11:58:41,724 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4021832118431727, 'Total loss': 0.4021832118431727} | train loss {'Reaction outcome loss': 0.2808625691365249, 'Total loss': 0.2808625691365249}
2023-01-04 11:58:41,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:41,725 INFO:     Epoch: 76
2023-01-04 11:58:42,745 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39221819639205935, 'Total loss': 0.39221819639205935} | train loss {'Reaction outcome loss': 0.2807287600711795, 'Total loss': 0.2807287600711795}
2023-01-04 11:58:42,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:42,746 INFO:     Epoch: 77
2023-01-04 11:58:43,768 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39410331547260286, 'Total loss': 0.39410331547260286} | train loss {'Reaction outcome loss': 0.2844858231285204, 'Total loss': 0.2844858231285204}
2023-01-04 11:58:43,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:43,769 INFO:     Epoch: 78
2023-01-04 11:58:44,796 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3792742043733597, 'Total loss': 0.3792742043733597} | train loss {'Reaction outcome loss': 0.28038744025927587, 'Total loss': 0.28038744025927587}
2023-01-04 11:58:44,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:44,796 INFO:     Epoch: 79
2023-01-04 11:58:46,068 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.37724030315876006, 'Total loss': 0.37724030315876006} | train loss {'Reaction outcome loss': 0.2783277806177036, 'Total loss': 0.2783277806177036}
2023-01-04 11:58:46,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:46,069 INFO:     Epoch: 80
2023-01-04 11:58:47,636 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3966826190551122, 'Total loss': 0.3966826190551122} | train loss {'Reaction outcome loss': 0.2800093897843619, 'Total loss': 0.2800093897843619}
2023-01-04 11:58:47,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:47,637 INFO:     Epoch: 81
2023-01-04 11:58:49,209 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39868085185686747, 'Total loss': 0.39868085185686747} | train loss {'Reaction outcome loss': 0.27298593058482834, 'Total loss': 0.27298593058482834}
2023-01-04 11:58:49,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:49,210 INFO:     Epoch: 82
2023-01-04 11:58:50,725 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37750128110249836, 'Total loss': 0.37750128110249836} | train loss {'Reaction outcome loss': 0.2771371968278816, 'Total loss': 0.2771371968278816}
2023-01-04 11:58:50,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:50,725 INFO:     Epoch: 83
2023-01-04 11:58:52,294 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3996668855349223, 'Total loss': 0.3996668855349223} | train loss {'Reaction outcome loss': 0.2722578689267704, 'Total loss': 0.2722578689267704}
2023-01-04 11:58:52,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:52,295 INFO:     Epoch: 84
2023-01-04 11:58:53,859 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3752314488093058, 'Total loss': 0.3752314488093058} | train loss {'Reaction outcome loss': 0.2699626990012313, 'Total loss': 0.2699626990012313}
2023-01-04 11:58:53,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:53,860 INFO:     Epoch: 85
2023-01-04 11:58:55,391 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4105450510978699, 'Total loss': 0.4105450510978699} | train loss {'Reaction outcome loss': 0.27456394244079557, 'Total loss': 0.27456394244079557}
2023-01-04 11:58:55,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:55,391 INFO:     Epoch: 86
2023-01-04 11:58:56,956 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3928416142861048, 'Total loss': 0.3928416142861048} | train loss {'Reaction outcome loss': 0.2726483837523185, 'Total loss': 0.2726483837523185}
2023-01-04 11:58:56,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:56,956 INFO:     Epoch: 87
2023-01-04 11:58:58,516 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40041891038417815, 'Total loss': 0.40041891038417815} | train loss {'Reaction outcome loss': 0.2727583424870718, 'Total loss': 0.2727583424870718}
2023-01-04 11:58:58,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:58:58,516 INFO:     Epoch: 88
2023-01-04 11:59:00,033 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38562739789485934, 'Total loss': 0.38562739789485934} | train loss {'Reaction outcome loss': 0.2673099728751699, 'Total loss': 0.2673099728751699}
2023-01-04 11:59:00,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:00,034 INFO:     Epoch: 89
2023-01-04 11:59:01,584 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37005186875661217, 'Total loss': 0.37005186875661217} | train loss {'Reaction outcome loss': 0.2689275625111394, 'Total loss': 0.2689275625111394}
2023-01-04 11:59:01,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:01,584 INFO:     Epoch: 90
2023-01-04 11:59:03,142 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40819286505381264, 'Total loss': 0.40819286505381264} | train loss {'Reaction outcome loss': 0.27039690766254915, 'Total loss': 0.27039690766254915}
2023-01-04 11:59:03,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:03,142 INFO:     Epoch: 91
2023-01-04 11:59:04,666 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4232230673233668, 'Total loss': 0.4232230673233668} | train loss {'Reaction outcome loss': 0.2663439543050334, 'Total loss': 0.2663439543050334}
2023-01-04 11:59:04,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:04,666 INFO:     Epoch: 92
2023-01-04 11:59:06,235 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3800110956033071, 'Total loss': 0.3800110956033071} | train loss {'Reaction outcome loss': 0.2669105499122117, 'Total loss': 0.2669105499122117}
2023-01-04 11:59:06,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:06,235 INFO:     Epoch: 93
2023-01-04 11:59:07,796 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37408223350842795, 'Total loss': 0.37408223350842795} | train loss {'Reaction outcome loss': 0.2642123189213474, 'Total loss': 0.2642123189213474}
2023-01-04 11:59:07,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:07,796 INFO:     Epoch: 94
2023-01-04 11:59:09,318 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.37140121857325237, 'Total loss': 0.37140121857325237} | train loss {'Reaction outcome loss': 0.2626746529545164, 'Total loss': 0.2626746529545164}
2023-01-04 11:59:09,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:09,319 INFO:     Epoch: 95
2023-01-04 11:59:10,866 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3593591550985972, 'Total loss': 0.3593591550985972} | train loss {'Reaction outcome loss': 0.26111701151040057, 'Total loss': 0.26111701151040057}
2023-01-04 11:59:10,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:10,867 INFO:     Epoch: 96
2023-01-04 11:59:12,428 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38035917381445566, 'Total loss': 0.38035917381445566} | train loss {'Reaction outcome loss': 0.2619509805760444, 'Total loss': 0.2619509805760444}
2023-01-04 11:59:12,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:12,429 INFO:     Epoch: 97
2023-01-04 11:59:13,949 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4015642593304316, 'Total loss': 0.4015642593304316} | train loss {'Reaction outcome loss': 0.2609446441976602, 'Total loss': 0.2609446441976602}
2023-01-04 11:59:13,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:13,949 INFO:     Epoch: 98
2023-01-04 11:59:15,507 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.38570428142944974, 'Total loss': 0.38570428142944974} | train loss {'Reaction outcome loss': 0.2637301099886748, 'Total loss': 0.2637301099886748}
2023-01-04 11:59:15,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:15,507 INFO:     Epoch: 99
2023-01-04 11:59:17,047 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3713943709929784, 'Total loss': 0.3713943709929784} | train loss {'Reaction outcome loss': 0.2615003717478217, 'Total loss': 0.2615003717478217}
2023-01-04 11:59:17,047 INFO:     Best model found after epoch 53 of 100.
2023-01-04 11:59:17,047 INFO:   Done with stage: TRAINING
2023-01-04 11:59:17,047 INFO:   Starting stage: EVALUATION
2023-01-04 11:59:17,168 INFO:   Done with stage: EVALUATION
2023-01-04 11:59:17,168 INFO:   Leaving out SEQ value Fold_7
2023-01-04 11:59:17,181 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 11:59:17,181 INFO:   Starting stage: FEATURE SCALING
2023-01-04 11:59:17,828 INFO:   Done with stage: FEATURE SCALING
2023-01-04 11:59:17,828 INFO:   Starting stage: SCALING TARGETS
2023-01-04 11:59:17,895 INFO:   Done with stage: SCALING TARGETS
2023-01-04 11:59:17,895 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:59:17,895 INFO:     No hyperparam tuning for this model
2023-01-04 11:59:17,895 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 11:59:17,895 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 11:59:17,896 INFO:     None feature selector for col prot
2023-01-04 11:59:17,896 INFO:     None feature selector for col prot
2023-01-04 11:59:17,896 INFO:     None feature selector for col prot
2023-01-04 11:59:17,897 INFO:     None feature selector for col chem
2023-01-04 11:59:17,897 INFO:     None feature selector for col chem
2023-01-04 11:59:17,897 INFO:     None feature selector for col chem
2023-01-04 11:59:17,897 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 11:59:17,897 INFO:   Starting stage: BUILD MODEL
2023-01-04 11:59:17,898 INFO:     Number of params in model 70111
2023-01-04 11:59:17,901 INFO:   Done with stage: BUILD MODEL
2023-01-04 11:59:17,901 INFO:   Starting stage: TRAINING
2023-01-04 11:59:17,948 INFO:     Val loss before train {'Reaction outcome loss': 1.0230475505193075, 'Total loss': 1.0230475505193075}
2023-01-04 11:59:17,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:17,948 INFO:     Epoch: 0
2023-01-04 11:59:19,512 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7578728278477986, 'Total loss': 0.7578728278477986} | train loss {'Reaction outcome loss': 0.8308883266328474, 'Total loss': 0.8308883266328474}
2023-01-04 11:59:19,512 INFO:     Found new best model at epoch 0
2023-01-04 11:59:19,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:19,513 INFO:     Epoch: 1
2023-01-04 11:59:21,076 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6036004950602849, 'Total loss': 0.6036004950602849} | train loss {'Reaction outcome loss': 0.6670121200355812, 'Total loss': 0.6670121200355812}
2023-01-04 11:59:21,076 INFO:     Found new best model at epoch 1
2023-01-04 11:59:21,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:21,077 INFO:     Epoch: 2
2023-01-04 11:59:22,611 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5628911594549815, 'Total loss': 0.5628911594549815} | train loss {'Reaction outcome loss': 0.5703070809264476, 'Total loss': 0.5703070809264476}
2023-01-04 11:59:22,611 INFO:     Found new best model at epoch 2
2023-01-04 11:59:22,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:22,612 INFO:     Epoch: 3
2023-01-04 11:59:24,166 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5260760545730591, 'Total loss': 0.5260760545730591} | train loss {'Reaction outcome loss': 0.5325198909435892, 'Total loss': 0.5325198909435892}
2023-01-04 11:59:24,168 INFO:     Found new best model at epoch 3
2023-01-04 11:59:24,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:24,168 INFO:     Epoch: 4
2023-01-04 11:59:25,737 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5211757560571034, 'Total loss': 0.5211757560571034} | train loss {'Reaction outcome loss': 0.5168281011417885, 'Total loss': 0.5168281011417885}
2023-01-04 11:59:25,738 INFO:     Found new best model at epoch 4
2023-01-04 11:59:25,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:25,738 INFO:     Epoch: 5
2023-01-04 11:59:27,280 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5159462968508403, 'Total loss': 0.5159462968508403} | train loss {'Reaction outcome loss': 0.4994004451088096, 'Total loss': 0.4994004451088096}
2023-01-04 11:59:27,280 INFO:     Found new best model at epoch 5
2023-01-04 11:59:27,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:27,281 INFO:     Epoch: 6
2023-01-04 11:59:28,850 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.509928027788798, 'Total loss': 0.509928027788798} | train loss {'Reaction outcome loss': 0.4940725561728977, 'Total loss': 0.4940725561728977}
2023-01-04 11:59:28,850 INFO:     Found new best model at epoch 6
2023-01-04 11:59:28,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:28,851 INFO:     Epoch: 7
2023-01-04 11:59:30,421 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49269723395506543, 'Total loss': 0.49269723395506543} | train loss {'Reaction outcome loss': 0.48096887089500356, 'Total loss': 0.48096887089500356}
2023-01-04 11:59:30,422 INFO:     Found new best model at epoch 7
2023-01-04 11:59:30,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:30,422 INFO:     Epoch: 8
2023-01-04 11:59:31,955 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48786896069844565, 'Total loss': 0.48786896069844565} | train loss {'Reaction outcome loss': 0.4736543989568841, 'Total loss': 0.4736543989568841}
2023-01-04 11:59:31,955 INFO:     Found new best model at epoch 8
2023-01-04 11:59:31,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:31,956 INFO:     Epoch: 9
2023-01-04 11:59:33,517 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49671093026796975, 'Total loss': 0.49671093026796975} | train loss {'Reaction outcome loss': 0.46974093249128185, 'Total loss': 0.46974093249128185}
2023-01-04 11:59:33,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:33,517 INFO:     Epoch: 10
2023-01-04 11:59:35,077 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4717732628186544, 'Total loss': 0.4717732628186544} | train loss {'Reaction outcome loss': 0.460536446489582, 'Total loss': 0.460536446489582}
2023-01-04 11:59:35,077 INFO:     Found new best model at epoch 10
2023-01-04 11:59:35,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:35,078 INFO:     Epoch: 11
2023-01-04 11:59:36,606 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45500239729881287, 'Total loss': 0.45500239729881287} | train loss {'Reaction outcome loss': 0.45615792930771726, 'Total loss': 0.45615792930771726}
2023-01-04 11:59:36,606 INFO:     Found new best model at epoch 11
2023-01-04 11:59:36,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:36,607 INFO:     Epoch: 12
2023-01-04 11:59:38,174 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46254335045814515, 'Total loss': 0.46254335045814515} | train loss {'Reaction outcome loss': 0.45042453413082806, 'Total loss': 0.45042453413082806}
2023-01-04 11:59:38,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:38,174 INFO:     Epoch: 13
2023-01-04 11:59:39,738 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4555544018745422, 'Total loss': 0.4555544018745422} | train loss {'Reaction outcome loss': 0.4442202438623897, 'Total loss': 0.4442202438623897}
2023-01-04 11:59:39,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:39,738 INFO:     Epoch: 14
2023-01-04 11:59:41,299 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4539583186308543, 'Total loss': 0.4539583186308543} | train loss {'Reaction outcome loss': 0.4401854641923836, 'Total loss': 0.4401854641923836}
2023-01-04 11:59:41,299 INFO:     Found new best model at epoch 14
2023-01-04 11:59:41,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:41,300 INFO:     Epoch: 15
2023-01-04 11:59:42,865 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46556657950083413, 'Total loss': 0.46556657950083413} | train loss {'Reaction outcome loss': 0.43275692451086284, 'Total loss': 0.43275692451086284}
2023-01-04 11:59:42,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:42,866 INFO:     Epoch: 16
2023-01-04 11:59:44,463 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4549638281265895, 'Total loss': 0.4549638281265895} | train loss {'Reaction outcome loss': 0.42660583631011123, 'Total loss': 0.42660583631011123}
2023-01-04 11:59:44,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:44,463 INFO:     Epoch: 17
2023-01-04 11:59:46,029 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44435910085837044, 'Total loss': 0.44435910085837044} | train loss {'Reaction outcome loss': 0.42693226582737176, 'Total loss': 0.42693226582737176}
2023-01-04 11:59:46,029 INFO:     Found new best model at epoch 17
2023-01-04 11:59:46,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:46,030 INFO:     Epoch: 18
2023-01-04 11:59:47,596 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43489865909020103, 'Total loss': 0.43489865909020103} | train loss {'Reaction outcome loss': 0.4175886533858544, 'Total loss': 0.4175886533858544}
2023-01-04 11:59:47,596 INFO:     Found new best model at epoch 18
2023-01-04 11:59:47,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:47,597 INFO:     Epoch: 19
2023-01-04 11:59:49,138 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4291672309239705, 'Total loss': 0.4291672309239705} | train loss {'Reaction outcome loss': 0.41259796557013306, 'Total loss': 0.41259796557013306}
2023-01-04 11:59:49,138 INFO:     Found new best model at epoch 19
2023-01-04 11:59:49,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:49,139 INFO:     Epoch: 20
2023-01-04 11:59:50,732 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4690650592247645, 'Total loss': 0.4690650592247645} | train loss {'Reaction outcome loss': 0.4085278282957387, 'Total loss': 0.4085278282957387}
2023-01-04 11:59:50,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:50,732 INFO:     Epoch: 21
2023-01-04 11:59:52,305 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44685318768024446, 'Total loss': 0.44685318768024446} | train loss {'Reaction outcome loss': 0.40952568022460284, 'Total loss': 0.40952568022460284}
2023-01-04 11:59:52,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:52,305 INFO:     Epoch: 22
2023-01-04 11:59:53,858 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4283625225226084, 'Total loss': 0.4283625225226084} | train loss {'Reaction outcome loss': 0.3991858373910511, 'Total loss': 0.3991858373910511}
2023-01-04 11:59:53,859 INFO:     Found new best model at epoch 22
2023-01-04 11:59:53,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:53,860 INFO:     Epoch: 23
2023-01-04 11:59:55,474 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4306881566842397, 'Total loss': 0.4306881566842397} | train loss {'Reaction outcome loss': 0.39749525444387096, 'Total loss': 0.39749525444387096}
2023-01-04 11:59:55,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:55,475 INFO:     Epoch: 24
2023-01-04 11:59:57,068 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4429858048756917, 'Total loss': 0.4429858048756917} | train loss {'Reaction outcome loss': 0.38985409732867665, 'Total loss': 0.38985409732867665}
2023-01-04 11:59:57,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:57,068 INFO:     Epoch: 25
2023-01-04 11:59:58,648 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4279372682174047, 'Total loss': 0.4279372682174047} | train loss {'Reaction outcome loss': 0.3877067905632167, 'Total loss': 0.3877067905632167}
2023-01-04 11:59:58,648 INFO:     Found new best model at epoch 25
2023-01-04 11:59:58,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 11:59:58,648 INFO:     Epoch: 26
2023-01-04 12:00:00,254 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43195649087429044, 'Total loss': 0.43195649087429044} | train loss {'Reaction outcome loss': 0.38598329657251657, 'Total loss': 0.38598329657251657}
2023-01-04 12:00:00,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:00,254 INFO:     Epoch: 27
2023-01-04 12:00:01,851 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4170756508906682, 'Total loss': 0.4170756508906682} | train loss {'Reaction outcome loss': 0.38164238475720375, 'Total loss': 0.38164238475720375}
2023-01-04 12:00:01,852 INFO:     Found new best model at epoch 27
2023-01-04 12:00:01,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:01,853 INFO:     Epoch: 28
2023-01-04 12:00:03,412 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4381351888179779, 'Total loss': 0.4381351888179779} | train loss {'Reaction outcome loss': 0.37626441473995303, 'Total loss': 0.37626441473995303}
2023-01-04 12:00:03,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:03,413 INFO:     Epoch: 29
2023-01-04 12:00:04,999 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4165202282369137, 'Total loss': 0.4165202282369137} | train loss {'Reaction outcome loss': 0.37398456297949334, 'Total loss': 0.37398456297949334}
2023-01-04 12:00:04,999 INFO:     Found new best model at epoch 29
2023-01-04 12:00:05,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:05,000 INFO:     Epoch: 30
2023-01-04 12:00:06,580 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45838449001312254, 'Total loss': 0.45838449001312254} | train loss {'Reaction outcome loss': 0.3728168439456272, 'Total loss': 0.3728168439456272}
2023-01-04 12:00:06,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:06,580 INFO:     Epoch: 31
2023-01-04 12:00:08,125 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44324739277362823, 'Total loss': 0.44324739277362823} | train loss {'Reaction outcome loss': 0.3713584984467778, 'Total loss': 0.3713584984467778}
2023-01-04 12:00:08,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:08,126 INFO:     Epoch: 32
2023-01-04 12:00:09,692 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41582725842793783, 'Total loss': 0.41582725842793783} | train loss {'Reaction outcome loss': 0.36621690764754256, 'Total loss': 0.36621690764754256}
2023-01-04 12:00:09,692 INFO:     Found new best model at epoch 32
2023-01-04 12:00:09,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:09,693 INFO:     Epoch: 33
2023-01-04 12:00:11,256 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4242931028207143, 'Total loss': 0.4242931028207143} | train loss {'Reaction outcome loss': 0.358658353828351, 'Total loss': 0.358658353828351}
2023-01-04 12:00:11,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:11,257 INFO:     Epoch: 34
2023-01-04 12:00:12,801 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4216683655977249, 'Total loss': 0.4216683655977249} | train loss {'Reaction outcome loss': 0.35749476349203163, 'Total loss': 0.35749476349203163}
2023-01-04 12:00:12,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:12,801 INFO:     Epoch: 35
2023-01-04 12:00:14,381 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4426694045464198, 'Total loss': 0.4426694045464198} | train loss {'Reaction outcome loss': 0.3588337803306562, 'Total loss': 0.3588337803306562}
2023-01-04 12:00:14,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:14,382 INFO:     Epoch: 36
2023-01-04 12:00:15,953 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43869858980178833, 'Total loss': 0.43869858980178833} | train loss {'Reaction outcome loss': 0.3527655078884927, 'Total loss': 0.3527655078884927}
2023-01-04 12:00:15,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:15,953 INFO:     Epoch: 37
2023-01-04 12:00:17,504 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4417747696240743, 'Total loss': 0.4417747696240743} | train loss {'Reaction outcome loss': 0.34502215672701275, 'Total loss': 0.34502215672701275}
2023-01-04 12:00:17,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:17,504 INFO:     Epoch: 38
2023-01-04 12:00:19,098 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4519581834475199, 'Total loss': 0.4519581834475199} | train loss {'Reaction outcome loss': 0.34796304887812923, 'Total loss': 0.34796304887812923}
2023-01-04 12:00:19,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:19,099 INFO:     Epoch: 39
2023-01-04 12:00:20,690 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4458237816890081, 'Total loss': 0.4458237816890081} | train loss {'Reaction outcome loss': 0.34505468792540933, 'Total loss': 0.34505468792540933}
2023-01-04 12:00:20,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:20,691 INFO:     Epoch: 40
2023-01-04 12:00:22,228 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41110403537750245, 'Total loss': 0.41110403537750245} | train loss {'Reaction outcome loss': 0.34413210286452883, 'Total loss': 0.34413210286452883}
2023-01-04 12:00:22,228 INFO:     Found new best model at epoch 40
2023-01-04 12:00:22,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:22,228 INFO:     Epoch: 41
2023-01-04 12:00:23,796 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4254848341147105, 'Total loss': 0.4254848341147105} | train loss {'Reaction outcome loss': 0.33847693356581116, 'Total loss': 0.33847693356581116}
2023-01-04 12:00:23,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:23,796 INFO:     Epoch: 42
2023-01-04 12:00:25,347 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4206770439942678, 'Total loss': 0.4206770439942678} | train loss {'Reaction outcome loss': 0.33998730345645967, 'Total loss': 0.33998730345645967}
2023-01-04 12:00:25,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:25,347 INFO:     Epoch: 43
2023-01-04 12:00:26,923 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41341071923573813, 'Total loss': 0.41341071923573813} | train loss {'Reaction outcome loss': 0.33536423027300233, 'Total loss': 0.33536423027300233}
2023-01-04 12:00:26,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:26,923 INFO:     Epoch: 44
2023-01-04 12:00:28,497 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44556251565615335, 'Total loss': 0.44556251565615335} | train loss {'Reaction outcome loss': 0.3349892378445136, 'Total loss': 0.3349892378445136}
2023-01-04 12:00:28,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:28,497 INFO:     Epoch: 45
2023-01-04 12:00:30,079 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4128023197253545, 'Total loss': 0.4128023197253545} | train loss {'Reaction outcome loss': 0.3301962605721253, 'Total loss': 0.3301962605721253}
2023-01-04 12:00:30,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:30,080 INFO:     Epoch: 46
2023-01-04 12:00:31,642 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42836650609970095, 'Total loss': 0.42836650609970095} | train loss {'Reaction outcome loss': 0.3208805066583819, 'Total loss': 0.3208805066583819}
2023-01-04 12:00:31,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:31,642 INFO:     Epoch: 47
2023-01-04 12:00:33,239 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44022509853045144, 'Total loss': 0.44022509853045144} | train loss {'Reaction outcome loss': 0.3270148499616647, 'Total loss': 0.3270148499616647}
2023-01-04 12:00:33,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:33,240 INFO:     Epoch: 48
2023-01-04 12:00:34,789 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4256161461273829, 'Total loss': 0.4256161461273829} | train loss {'Reaction outcome loss': 0.3231325116990275, 'Total loss': 0.3231325116990275}
2023-01-04 12:00:34,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:34,789 INFO:     Epoch: 49
2023-01-04 12:00:36,387 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4341148972511292, 'Total loss': 0.4341148972511292} | train loss {'Reaction outcome loss': 0.32335521364147485, 'Total loss': 0.32335521364147485}
2023-01-04 12:00:36,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:36,388 INFO:     Epoch: 50
2023-01-04 12:00:37,978 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41941061715284983, 'Total loss': 0.41941061715284983} | train loss {'Reaction outcome loss': 0.32076082924643146, 'Total loss': 0.32076082924643146}
2023-01-04 12:00:37,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:37,979 INFO:     Epoch: 51
2023-01-04 12:00:39,533 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44242326021194456, 'Total loss': 0.44242326021194456} | train loss {'Reaction outcome loss': 0.3114249716758298, 'Total loss': 0.3114249716758298}
2023-01-04 12:00:39,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:39,534 INFO:     Epoch: 52
2023-01-04 12:00:41,135 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40249780416488645, 'Total loss': 0.40249780416488645} | train loss {'Reaction outcome loss': 0.3166166821272795, 'Total loss': 0.3166166821272795}
2023-01-04 12:00:41,136 INFO:     Found new best model at epoch 52
2023-01-04 12:00:41,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:41,136 INFO:     Epoch: 53
2023-01-04 12:00:42,724 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4385134776433309, 'Total loss': 0.4385134776433309} | train loss {'Reaction outcome loss': 0.30987550272515535, 'Total loss': 0.30987550272515535}
2023-01-04 12:00:42,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:42,724 INFO:     Epoch: 54
2023-01-04 12:00:44,281 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44143132368723553, 'Total loss': 0.44143132368723553} | train loss {'Reaction outcome loss': 0.3175875987010312, 'Total loss': 0.3175875987010312}
2023-01-04 12:00:44,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:44,281 INFO:     Epoch: 55
2023-01-04 12:00:45,891 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45684888859589895, 'Total loss': 0.45684888859589895} | train loss {'Reaction outcome loss': 0.31261874719216937, 'Total loss': 0.31261874719216937}
2023-01-04 12:00:45,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:45,891 INFO:     Epoch: 56
2023-01-04 12:00:47,492 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4286938269933065, 'Total loss': 0.4286938269933065} | train loss {'Reaction outcome loss': 0.3121734128639586, 'Total loss': 0.3121734128639586}
2023-01-04 12:00:47,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:47,493 INFO:     Epoch: 57
2023-01-04 12:00:49,025 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4372106691201528, 'Total loss': 0.4372106691201528} | train loss {'Reaction outcome loss': 0.30668332988550945, 'Total loss': 0.30668332988550945}
2023-01-04 12:00:49,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:49,025 INFO:     Epoch: 58
2023-01-04 12:00:50,603 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41423964897791543, 'Total loss': 0.41423964897791543} | train loss {'Reaction outcome loss': 0.3047407492457314, 'Total loss': 0.3047407492457314}
2023-01-04 12:00:50,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:50,603 INFO:     Epoch: 59
2023-01-04 12:00:52,183 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4064263333876928, 'Total loss': 0.4064263333876928} | train loss {'Reaction outcome loss': 0.2992885851903082, 'Total loss': 0.2992885851903082}
2023-01-04 12:00:52,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:52,184 INFO:     Epoch: 60
2023-01-04 12:00:53,738 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4235213309526443, 'Total loss': 0.4235213309526443} | train loss {'Reaction outcome loss': 0.3011536931598875, 'Total loss': 0.3011536931598875}
2023-01-04 12:00:53,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:53,738 INFO:     Epoch: 61
2023-01-04 12:00:55,322 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44018728931744894, 'Total loss': 0.44018728931744894} | train loss {'Reaction outcome loss': 0.29598444381506867, 'Total loss': 0.29598444381506867}
2023-01-04 12:00:55,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:55,323 INFO:     Epoch: 62
2023-01-04 12:00:56,906 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4252207100391388, 'Total loss': 0.4252207100391388} | train loss {'Reaction outcome loss': 0.29780373009533656, 'Total loss': 0.29780373009533656}
2023-01-04 12:00:56,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:56,906 INFO:     Epoch: 63
2023-01-04 12:00:58,446 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44138088822364807, 'Total loss': 0.44138088822364807} | train loss {'Reaction outcome loss': 0.29442387934948994, 'Total loss': 0.29442387934948994}
2023-01-04 12:00:58,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:00:58,446 INFO:     Epoch: 64
2023-01-04 12:01:00,018 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43204007943471273, 'Total loss': 0.43204007943471273} | train loss {'Reaction outcome loss': 0.2998125263984023, 'Total loss': 0.2998125263984023}
2023-01-04 12:01:00,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:00,018 INFO:     Epoch: 65
2023-01-04 12:01:01,558 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4402417063713074, 'Total loss': 0.4402417063713074} | train loss {'Reaction outcome loss': 0.2931580574719054, 'Total loss': 0.2931580574719054}
2023-01-04 12:01:01,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:01,559 INFO:     Epoch: 66
2023-01-04 12:01:03,193 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4167123178641001, 'Total loss': 0.4167123178641001} | train loss {'Reaction outcome loss': 0.29783220096938445, 'Total loss': 0.29783220096938445}
2023-01-04 12:01:03,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:03,193 INFO:     Epoch: 67
2023-01-04 12:01:04,831 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4264674514532089, 'Total loss': 0.4264674514532089} | train loss {'Reaction outcome loss': 0.2901978477674271, 'Total loss': 0.2901978477674271}
2023-01-04 12:01:04,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:04,831 INFO:     Epoch: 68
2023-01-04 12:01:06,462 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4202525123953819, 'Total loss': 0.4202525123953819} | train loss {'Reaction outcome loss': 0.2874144102154226, 'Total loss': 0.2874144102154226}
2023-01-04 12:01:06,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:06,462 INFO:     Epoch: 69
2023-01-04 12:01:08,066 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4451984425385793, 'Total loss': 0.4451984425385793} | train loss {'Reaction outcome loss': 0.28770868730351384, 'Total loss': 0.28770868730351384}
2023-01-04 12:01:08,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:08,067 INFO:     Epoch: 70
2023-01-04 12:01:09,701 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4283150941133499, 'Total loss': 0.4283150941133499} | train loss {'Reaction outcome loss': 0.28496277493690325, 'Total loss': 0.28496277493690325}
2023-01-04 12:01:09,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:09,702 INFO:     Epoch: 71
2023-01-04 12:01:11,296 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4301082988580068, 'Total loss': 0.4301082988580068} | train loss {'Reaction outcome loss': 0.2874772049728714, 'Total loss': 0.2874772049728714}
2023-01-04 12:01:11,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:11,296 INFO:     Epoch: 72
2023-01-04 12:01:12,930 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.437135507663091, 'Total loss': 0.437135507663091} | train loss {'Reaction outcome loss': 0.28385328028068646, 'Total loss': 0.28385328028068646}
2023-01-04 12:01:12,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:12,930 INFO:     Epoch: 73
2023-01-04 12:01:14,567 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42972378730773925, 'Total loss': 0.42972378730773925} | train loss {'Reaction outcome loss': 0.2801904933332106, 'Total loss': 0.2801904933332106}
2023-01-04 12:01:14,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:14,568 INFO:     Epoch: 74
2023-01-04 12:01:16,144 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4427028109629949, 'Total loss': 0.4427028109629949} | train loss {'Reaction outcome loss': 0.27968439785259297, 'Total loss': 0.27968439785259297}
2023-01-04 12:01:16,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:16,145 INFO:     Epoch: 75
2023-01-04 12:01:17,773 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4205507735411326, 'Total loss': 0.4205507735411326} | train loss {'Reaction outcome loss': 0.2867379506061439, 'Total loss': 0.2867379506061439}
2023-01-04 12:01:17,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:17,773 INFO:     Epoch: 76
2023-01-04 12:01:19,401 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4416296462217967, 'Total loss': 0.4416296462217967} | train loss {'Reaction outcome loss': 0.2788569188074945, 'Total loss': 0.2788569188074945}
2023-01-04 12:01:19,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:19,401 INFO:     Epoch: 77
2023-01-04 12:01:20,948 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42255149483680726, 'Total loss': 0.42255149483680726} | train loss {'Reaction outcome loss': 0.2725762961708036, 'Total loss': 0.2725762961708036}
2023-01-04 12:01:20,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:20,948 INFO:     Epoch: 78
2023-01-04 12:01:22,525 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4101904660463333, 'Total loss': 0.4101904660463333} | train loss {'Reaction outcome loss': 0.2784956104596169, 'Total loss': 0.2784956104596169}
2023-01-04 12:01:22,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:22,525 INFO:     Epoch: 79
2023-01-04 12:01:24,110 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4389937291542689, 'Total loss': 0.4389937291542689} | train loss {'Reaction outcome loss': 0.276123424622126, 'Total loss': 0.276123424622126}
2023-01-04 12:01:24,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:24,110 INFO:     Epoch: 80
2023-01-04 12:01:25,657 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44891309837500254, 'Total loss': 0.44891309837500254} | train loss {'Reaction outcome loss': 0.27493920072321426, 'Total loss': 0.27493920072321426}
2023-01-04 12:01:25,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:25,657 INFO:     Epoch: 81
2023-01-04 12:01:27,232 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4376654674609502, 'Total loss': 0.4376654674609502} | train loss {'Reaction outcome loss': 0.27469757374120535, 'Total loss': 0.27469757374120535}
2023-01-04 12:01:27,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:27,233 INFO:     Epoch: 82
2023-01-04 12:01:28,788 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4172165900468826, 'Total loss': 0.4172165900468826} | train loss {'Reaction outcome loss': 0.27667270778318603, 'Total loss': 0.27667270778318603}
2023-01-04 12:01:28,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:28,788 INFO:     Epoch: 83
2023-01-04 12:01:30,324 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4486353317896525, 'Total loss': 0.4486353317896525} | train loss {'Reaction outcome loss': 0.2734570069110781, 'Total loss': 0.2734570069110781}
2023-01-04 12:01:30,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:30,324 INFO:     Epoch: 84
2023-01-04 12:01:31,890 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42088456551233927, 'Total loss': 0.42088456551233927} | train loss {'Reaction outcome loss': 0.27555012712355986, 'Total loss': 0.27555012712355986}
2023-01-04 12:01:31,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:31,890 INFO:     Epoch: 85
2023-01-04 12:01:33,451 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40054027636845907, 'Total loss': 0.40054027636845907} | train loss {'Reaction outcome loss': 0.27056258018481605, 'Total loss': 0.27056258018481605}
2023-01-04 12:01:33,451 INFO:     Found new best model at epoch 85
2023-01-04 12:01:33,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:33,451 INFO:     Epoch: 86
2023-01-04 12:01:34,982 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4362850288550059, 'Total loss': 0.4362850288550059} | train loss {'Reaction outcome loss': 0.27061399266069974, 'Total loss': 0.27061399266069974}
2023-01-04 12:01:34,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:34,983 INFO:     Epoch: 87
2023-01-04 12:01:36,541 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4079389363527298, 'Total loss': 0.4079389363527298} | train loss {'Reaction outcome loss': 0.2722748373551059, 'Total loss': 0.2722748373551059}
2023-01-04 12:01:36,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:36,542 INFO:     Epoch: 88
2023-01-04 12:01:38,084 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4332056204477946, 'Total loss': 0.4332056204477946} | train loss {'Reaction outcome loss': 0.2689283666762419, 'Total loss': 0.2689283666762419}
2023-01-04 12:01:38,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:38,084 INFO:     Epoch: 89
2023-01-04 12:01:39,718 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42566230793793997, 'Total loss': 0.42566230793793997} | train loss {'Reaction outcome loss': 0.2701427553669425, 'Total loss': 0.2701427553669425}
2023-01-04 12:01:39,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:39,720 INFO:     Epoch: 90
2023-01-04 12:01:41,349 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44787981112798053, 'Total loss': 0.44787981112798053} | train loss {'Reaction outcome loss': 0.2650680237513587, 'Total loss': 0.2650680237513587}
2023-01-04 12:01:41,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:41,349 INFO:     Epoch: 91
2023-01-04 12:01:42,958 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42690583169460294, 'Total loss': 0.42690583169460294} | train loss {'Reaction outcome loss': 0.2679136585081097, 'Total loss': 0.2679136585081097}
2023-01-04 12:01:42,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:42,959 INFO:     Epoch: 92
2023-01-04 12:01:44,588 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4162355860074361, 'Total loss': 0.4162355860074361} | train loss {'Reaction outcome loss': 0.26767587772022516, 'Total loss': 0.26767587772022516}
2023-01-04 12:01:44,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:44,588 INFO:     Epoch: 93
2023-01-04 12:01:46,228 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4144245733817418, 'Total loss': 0.4144245733817418} | train loss {'Reaction outcome loss': 0.2666344864811708, 'Total loss': 0.2666344864811708}
2023-01-04 12:01:46,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:46,229 INFO:     Epoch: 94
2023-01-04 12:01:47,821 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4438235491514206, 'Total loss': 0.4438235491514206} | train loss {'Reaction outcome loss': 0.26636814946033033, 'Total loss': 0.26636814946033033}
2023-01-04 12:01:47,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:47,822 INFO:     Epoch: 95
2023-01-04 12:01:49,458 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4409208635489146, 'Total loss': 0.4409208635489146} | train loss {'Reaction outcome loss': 0.2666070796145859, 'Total loss': 0.2666070796145859}
2023-01-04 12:01:49,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:49,458 INFO:     Epoch: 96
2023-01-04 12:01:51,095 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4407506207625071, 'Total loss': 0.4407506207625071} | train loss {'Reaction outcome loss': 0.2619511030802658, 'Total loss': 0.2619511030802658}
2023-01-04 12:01:51,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:51,095 INFO:     Epoch: 97
2023-01-04 12:01:52,687 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4331698387861252, 'Total loss': 0.4331698387861252} | train loss {'Reaction outcome loss': 0.2611476902443149, 'Total loss': 0.2611476902443149}
2023-01-04 12:01:52,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:52,687 INFO:     Epoch: 98
2023-01-04 12:01:54,324 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40125288466612496, 'Total loss': 0.40125288466612496} | train loss {'Reaction outcome loss': 0.2632809009550926, 'Total loss': 0.2632809009550926}
2023-01-04 12:01:54,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:54,324 INFO:     Epoch: 99
2023-01-04 12:01:55,904 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4265405257542928, 'Total loss': 0.4265405257542928} | train loss {'Reaction outcome loss': 0.25590789681199655, 'Total loss': 0.25590789681199655}
2023-01-04 12:01:55,905 INFO:     Best model found after epoch 86 of 100.
2023-01-04 12:01:55,905 INFO:   Done with stage: TRAINING
2023-01-04 12:01:55,905 INFO:   Starting stage: EVALUATION
2023-01-04 12:01:56,026 INFO:   Done with stage: EVALUATION
2023-01-04 12:01:56,026 INFO:   Leaving out SEQ value Fold_8
2023-01-04 12:01:56,038 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 12:01:56,039 INFO:   Starting stage: FEATURE SCALING
2023-01-04 12:01:56,694 INFO:   Done with stage: FEATURE SCALING
2023-01-04 12:01:56,694 INFO:   Starting stage: SCALING TARGETS
2023-01-04 12:01:56,761 INFO:   Done with stage: SCALING TARGETS
2023-01-04 12:01:56,761 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 12:01:56,761 INFO:     No hyperparam tuning for this model
2023-01-04 12:01:56,761 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 12:01:56,761 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 12:01:56,762 INFO:     None feature selector for col prot
2023-01-04 12:01:56,762 INFO:     None feature selector for col prot
2023-01-04 12:01:56,762 INFO:     None feature selector for col prot
2023-01-04 12:01:56,763 INFO:     None feature selector for col chem
2023-01-04 12:01:56,763 INFO:     None feature selector for col chem
2023-01-04 12:01:56,763 INFO:     None feature selector for col chem
2023-01-04 12:01:56,763 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 12:01:56,763 INFO:   Starting stage: BUILD MODEL
2023-01-04 12:01:56,764 INFO:     Number of params in model 70111
2023-01-04 12:01:56,767 INFO:   Done with stage: BUILD MODEL
2023-01-04 12:01:56,767 INFO:   Starting stage: TRAINING
2023-01-04 12:01:56,812 INFO:     Val loss before train {'Reaction outcome loss': 0.9424717863400777, 'Total loss': 0.9424717863400777}
2023-01-04 12:01:56,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:56,812 INFO:     Epoch: 0
2023-01-04 12:01:58,388 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6792055706183115, 'Total loss': 0.6792055706183115} | train loss {'Reaction outcome loss': 0.8141228740450239, 'Total loss': 0.8141228740450239}
2023-01-04 12:01:58,389 INFO:     Found new best model at epoch 0
2023-01-04 12:01:58,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:58,389 INFO:     Epoch: 1
2023-01-04 12:01:59,954 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5380104740460714, 'Total loss': 0.5380104740460714} | train loss {'Reaction outcome loss': 0.6468786928993072, 'Total loss': 0.6468786928993072}
2023-01-04 12:01:59,955 INFO:     Found new best model at epoch 1
2023-01-04 12:01:59,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:01:59,955 INFO:     Epoch: 2
2023-01-04 12:02:01,505 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.512441090742747, 'Total loss': 0.512441090742747} | train loss {'Reaction outcome loss': 0.5605708394389953, 'Total loss': 0.5605708394389953}
2023-01-04 12:02:01,505 INFO:     Found new best model at epoch 2
2023-01-04 12:02:01,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:01,506 INFO:     Epoch: 3
2023-01-04 12:02:03,075 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47886112332344055, 'Total loss': 0.47886112332344055} | train loss {'Reaction outcome loss': 0.5274428069917825, 'Total loss': 0.5274428069917825}
2023-01-04 12:02:03,076 INFO:     Found new best model at epoch 3
2023-01-04 12:02:03,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:03,076 INFO:     Epoch: 4
2023-01-04 12:02:04,641 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4680553952852885, 'Total loss': 0.4680553952852885} | train loss {'Reaction outcome loss': 0.5022052752710607, 'Total loss': 0.5022052752710607}
2023-01-04 12:02:04,641 INFO:     Found new best model at epoch 4
2023-01-04 12:02:04,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:04,642 INFO:     Epoch: 5
2023-01-04 12:02:06,184 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4317903439203898, 'Total loss': 0.4317903439203898} | train loss {'Reaction outcome loss': 0.4936741646515192, 'Total loss': 0.4936741646515192}
2023-01-04 12:02:06,184 INFO:     Found new best model at epoch 5
2023-01-04 12:02:06,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:06,185 INFO:     Epoch: 6
2023-01-04 12:02:07,753 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4334879477818807, 'Total loss': 0.4334879477818807} | train loss {'Reaction outcome loss': 0.479154084394448, 'Total loss': 0.479154084394448}
2023-01-04 12:02:07,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:07,754 INFO:     Epoch: 7
2023-01-04 12:02:09,310 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43669410745302834, 'Total loss': 0.43669410745302834} | train loss {'Reaction outcome loss': 0.4741239606463996, 'Total loss': 0.4741239606463996}
2023-01-04 12:02:09,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:09,310 INFO:     Epoch: 8
2023-01-04 12:02:10,836 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43867128193378446, 'Total loss': 0.43867128193378446} | train loss {'Reaction outcome loss': 0.4618751097769633, 'Total loss': 0.4618751097769633}
2023-01-04 12:02:10,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:10,837 INFO:     Epoch: 9
2023-01-04 12:02:12,416 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43268130520979564, 'Total loss': 0.43268130520979564} | train loss {'Reaction outcome loss': 0.45286155587238985, 'Total loss': 0.45286155587238985}
2023-01-04 12:02:12,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:12,416 INFO:     Epoch: 10
2023-01-04 12:02:13,977 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42832565208276113, 'Total loss': 0.42832565208276113} | train loss {'Reaction outcome loss': 0.4461750348989111, 'Total loss': 0.4461750348989111}
2023-01-04 12:02:13,977 INFO:     Found new best model at epoch 10
2023-01-04 12:02:13,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:13,978 INFO:     Epoch: 11
2023-01-04 12:02:15,520 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4223883559306463, 'Total loss': 0.4223883559306463} | train loss {'Reaction outcome loss': 0.4400793848029018, 'Total loss': 0.4400793848029018}
2023-01-04 12:02:15,521 INFO:     Found new best model at epoch 11
2023-01-04 12:02:15,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:15,522 INFO:     Epoch: 12
2023-01-04 12:02:17,091 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44445871909459433, 'Total loss': 0.44445871909459433} | train loss {'Reaction outcome loss': 0.43594517493552537, 'Total loss': 0.43594517493552537}
2023-01-04 12:02:17,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:17,091 INFO:     Epoch: 13
2023-01-04 12:02:18,646 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43820072809855143, 'Total loss': 0.43820072809855143} | train loss {'Reaction outcome loss': 0.42853766416002365, 'Total loss': 0.42853766416002365}
2023-01-04 12:02:18,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:18,647 INFO:     Epoch: 14
2023-01-04 12:02:20,188 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4371341576178869, 'Total loss': 0.4371341576178869} | train loss {'Reaction outcome loss': 0.4233026906956721, 'Total loss': 0.4233026906956721}
2023-01-04 12:02:20,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:20,189 INFO:     Epoch: 15
2023-01-04 12:02:21,765 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4300977935393651, 'Total loss': 0.4300977935393651} | train loss {'Reaction outcome loss': 0.4163397368397156, 'Total loss': 0.4163397368397156}
2023-01-04 12:02:21,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:21,765 INFO:     Epoch: 16
2023-01-04 12:02:23,319 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4294854541619619, 'Total loss': 0.4294854541619619} | train loss {'Reaction outcome loss': 0.41538051390734904, 'Total loss': 0.41538051390734904}
2023-01-04 12:02:23,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:23,319 INFO:     Epoch: 17
2023-01-04 12:02:24,886 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43842288355032605, 'Total loss': 0.43842288355032605} | train loss {'Reaction outcome loss': 0.4087858431204392, 'Total loss': 0.4087858431204392}
2023-01-04 12:02:24,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:24,886 INFO:     Epoch: 18
2023-01-04 12:02:26,463 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.433510289589564, 'Total loss': 0.433510289589564} | train loss {'Reaction outcome loss': 0.40595438945902523, 'Total loss': 0.40595438945902523}
2023-01-04 12:02:26,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:26,463 INFO:     Epoch: 19
2023-01-04 12:02:28,040 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41273488104343414, 'Total loss': 0.41273488104343414} | train loss {'Reaction outcome loss': 0.402168012992309, 'Total loss': 0.402168012992309}
2023-01-04 12:02:28,040 INFO:     Found new best model at epoch 19
2023-01-04 12:02:28,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:28,041 INFO:     Epoch: 20
2023-01-04 12:02:29,565 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43528106311957043, 'Total loss': 0.43528106311957043} | train loss {'Reaction outcome loss': 0.39693017649280765, 'Total loss': 0.39693017649280765}
2023-01-04 12:02:29,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:29,565 INFO:     Epoch: 21
2023-01-04 12:02:31,136 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40279132723808286, 'Total loss': 0.40279132723808286} | train loss {'Reaction outcome loss': 0.3930812283915325, 'Total loss': 0.3930812283915325}
2023-01-04 12:02:31,136 INFO:     Found new best model at epoch 21
2023-01-04 12:02:31,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:31,137 INFO:     Epoch: 22
2023-01-04 12:02:32,673 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41370057066281635, 'Total loss': 0.41370057066281635} | train loss {'Reaction outcome loss': 0.39227376946241316, 'Total loss': 0.39227376946241316}
2023-01-04 12:02:32,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:32,674 INFO:     Epoch: 23
2023-01-04 12:02:34,232 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42933599948883056, 'Total loss': 0.42933599948883056} | train loss {'Reaction outcome loss': 0.3820512560706069, 'Total loss': 0.3820512560706069}
2023-01-04 12:02:34,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:34,233 INFO:     Epoch: 24
2023-01-04 12:02:35,767 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40457712213198344, 'Total loss': 0.40457712213198344} | train loss {'Reaction outcome loss': 0.3838610096569479, 'Total loss': 0.3838610096569479}
2023-01-04 12:02:35,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:35,767 INFO:     Epoch: 25
2023-01-04 12:02:37,321 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4001147270202637, 'Total loss': 0.4001147270202637} | train loss {'Reaction outcome loss': 0.37642933463636974, 'Total loss': 0.37642933463636974}
2023-01-04 12:02:37,322 INFO:     Found new best model at epoch 25
2023-01-04 12:02:37,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:37,322 INFO:     Epoch: 26
2023-01-04 12:02:38,841 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39407981634140016, 'Total loss': 0.39407981634140016} | train loss {'Reaction outcome loss': 0.37066490899254806, 'Total loss': 0.37066490899254806}
2023-01-04 12:02:38,841 INFO:     Found new best model at epoch 26
2023-01-04 12:02:38,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:38,842 INFO:     Epoch: 27
2023-01-04 12:02:40,375 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41297046293814976, 'Total loss': 0.41297046293814976} | train loss {'Reaction outcome loss': 0.3677079588392355, 'Total loss': 0.3677079588392355}
2023-01-04 12:02:40,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:40,375 INFO:     Epoch: 28
2023-01-04 12:02:41,874 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4114259570837021, 'Total loss': 0.4114259570837021} | train loss {'Reaction outcome loss': 0.36544617852807915, 'Total loss': 0.36544617852807915}
2023-01-04 12:02:41,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:41,875 INFO:     Epoch: 29
2023-01-04 12:02:43,407 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3967127054929733, 'Total loss': 0.3967127054929733} | train loss {'Reaction outcome loss': 0.3634112853366528, 'Total loss': 0.3634112853366528}
2023-01-04 12:02:43,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:43,407 INFO:     Epoch: 30
2023-01-04 12:02:44,948 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3843026851614316, 'Total loss': 0.3843026851614316} | train loss {'Reaction outcome loss': 0.358733381260268, 'Total loss': 0.358733381260268}
2023-01-04 12:02:44,948 INFO:     Found new best model at epoch 30
2023-01-04 12:02:44,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:44,949 INFO:     Epoch: 31
2023-01-04 12:02:46,466 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4019699662923813, 'Total loss': 0.4019699662923813} | train loss {'Reaction outcome loss': 0.3547086585177122, 'Total loss': 0.3547086585177122}
2023-01-04 12:02:46,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:46,466 INFO:     Epoch: 32
2023-01-04 12:02:48,077 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39864967664082845, 'Total loss': 0.39864967664082845} | train loss {'Reaction outcome loss': 0.35109149240446785, 'Total loss': 0.35109149240446785}
2023-01-04 12:02:48,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:48,077 INFO:     Epoch: 33
2023-01-04 12:02:49,669 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41402289966742195, 'Total loss': 0.41402289966742195} | train loss {'Reaction outcome loss': 0.3509860710941092, 'Total loss': 0.3509860710941092}
2023-01-04 12:02:49,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:49,669 INFO:     Epoch: 34
2023-01-04 12:02:51,169 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.408571857213974, 'Total loss': 0.408571857213974} | train loss {'Reaction outcome loss': 0.34695029930367954, 'Total loss': 0.34695029930367954}
2023-01-04 12:02:51,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:51,171 INFO:     Epoch: 35
2023-01-04 12:02:52,726 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42174262503782906, 'Total loss': 0.42174262503782906} | train loss {'Reaction outcome loss': 0.34392913145414233, 'Total loss': 0.34392913145414233}
2023-01-04 12:02:52,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:52,726 INFO:     Epoch: 36
2023-01-04 12:02:54,266 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40441589752833046, 'Total loss': 0.40441589752833046} | train loss {'Reaction outcome loss': 0.3386219724278598, 'Total loss': 0.3386219724278598}
2023-01-04 12:02:54,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:54,266 INFO:     Epoch: 37
2023-01-04 12:02:55,769 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39301200409730275, 'Total loss': 0.39301200409730275} | train loss {'Reaction outcome loss': 0.3333274589674751, 'Total loss': 0.3333274589674751}
2023-01-04 12:02:55,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:55,770 INFO:     Epoch: 38
2023-01-04 12:02:57,327 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4235947569211324, 'Total loss': 0.4235947569211324} | train loss {'Reaction outcome loss': 0.3323175586542509, 'Total loss': 0.3323175586542509}
2023-01-04 12:02:57,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:57,328 INFO:     Epoch: 39
2023-01-04 12:02:58,887 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40393701791763303, 'Total loss': 0.40393701791763303} | train loss {'Reaction outcome loss': 0.3285320643199621, 'Total loss': 0.3285320643199621}
2023-01-04 12:02:58,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:02:58,887 INFO:     Epoch: 40
2023-01-04 12:03:00,396 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37791927456855773, 'Total loss': 0.37791927456855773} | train loss {'Reaction outcome loss': 0.32737338406978733, 'Total loss': 0.32737338406978733}
2023-01-04 12:03:00,396 INFO:     Found new best model at epoch 40
2023-01-04 12:03:00,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:00,397 INFO:     Epoch: 41
2023-01-04 12:03:01,936 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3672422210375468, 'Total loss': 0.3672422210375468} | train loss {'Reaction outcome loss': 0.32410916715969135, 'Total loss': 0.32410916715969135}
2023-01-04 12:03:01,936 INFO:     Found new best model at epoch 41
2023-01-04 12:03:01,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:01,937 INFO:     Epoch: 42
2023-01-04 12:03:03,472 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4207501212755839, 'Total loss': 0.4207501212755839} | train loss {'Reaction outcome loss': 0.3250976944219892, 'Total loss': 0.3250976944219892}
2023-01-04 12:03:03,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:03,472 INFO:     Epoch: 43
2023-01-04 12:03:04,976 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3970425844192505, 'Total loss': 0.3970425844192505} | train loss {'Reaction outcome loss': 0.32077426039171913, 'Total loss': 0.32077426039171913}
2023-01-04 12:03:04,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:04,977 INFO:     Epoch: 44
2023-01-04 12:03:06,514 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39046215017636615, 'Total loss': 0.39046215017636615} | train loss {'Reaction outcome loss': 0.31604839662892104, 'Total loss': 0.31604839662892104}
2023-01-04 12:03:06,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:06,515 INFO:     Epoch: 45
2023-01-04 12:03:08,045 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40327394505341846, 'Total loss': 0.40327394505341846} | train loss {'Reaction outcome loss': 0.3149629402497824, 'Total loss': 0.3149629402497824}
2023-01-04 12:03:08,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:08,046 INFO:     Epoch: 46
2023-01-04 12:03:09,549 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3924717366695404, 'Total loss': 0.3924717366695404} | train loss {'Reaction outcome loss': 0.3119656442236291, 'Total loss': 0.3119656442236291}
2023-01-04 12:03:09,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:09,550 INFO:     Epoch: 47
2023-01-04 12:03:11,092 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39588775833447776, 'Total loss': 0.39588775833447776} | train loss {'Reaction outcome loss': 0.3099944685606191, 'Total loss': 0.3099944685606191}
2023-01-04 12:03:11,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:11,092 INFO:     Epoch: 48
2023-01-04 12:03:12,624 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3713096638520559, 'Total loss': 0.3713096638520559} | train loss {'Reaction outcome loss': 0.3066056814506976, 'Total loss': 0.3066056814506976}
2023-01-04 12:03:12,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:12,625 INFO:     Epoch: 49
2023-01-04 12:03:14,142 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3633867343266805, 'Total loss': 0.3633867343266805} | train loss {'Reaction outcome loss': 0.3077751327659527, 'Total loss': 0.3077751327659527}
2023-01-04 12:03:14,143 INFO:     Found new best model at epoch 49
2023-01-04 12:03:14,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:14,143 INFO:     Epoch: 50
2023-01-04 12:03:15,712 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41179940700531004, 'Total loss': 0.41179940700531004} | train loss {'Reaction outcome loss': 0.3042393878482989, 'Total loss': 0.3042393878482989}
2023-01-04 12:03:15,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:15,712 INFO:     Epoch: 51
2023-01-04 12:03:17,258 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3902884970108668, 'Total loss': 0.3902884970108668} | train loss {'Reaction outcome loss': 0.3087690870148422, 'Total loss': 0.3087690870148422}
2023-01-04 12:03:17,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:17,258 INFO:     Epoch: 52
2023-01-04 12:03:18,771 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3693316027522087, 'Total loss': 0.3693316027522087} | train loss {'Reaction outcome loss': 0.29898413923317496, 'Total loss': 0.29898413923317496}
2023-01-04 12:03:18,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:18,771 INFO:     Epoch: 53
2023-01-04 12:03:20,318 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38581130703290306, 'Total loss': 0.38581130703290306} | train loss {'Reaction outcome loss': 0.30036926037040507, 'Total loss': 0.30036926037040507}
2023-01-04 12:03:20,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:20,319 INFO:     Epoch: 54
2023-01-04 12:03:21,867 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3621870383620262, 'Total loss': 0.3621870383620262} | train loss {'Reaction outcome loss': 0.2932657713383219, 'Total loss': 0.2932657713383219}
2023-01-04 12:03:21,867 INFO:     Found new best model at epoch 54
2023-01-04 12:03:21,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:21,867 INFO:     Epoch: 55
2023-01-04 12:03:23,384 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37398956120014193, 'Total loss': 0.37398956120014193} | train loss {'Reaction outcome loss': 0.29067515538339195, 'Total loss': 0.29067515538339195}
2023-01-04 12:03:23,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:23,384 INFO:     Epoch: 56
2023-01-04 12:03:24,933 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3956831621627013, 'Total loss': 0.3956831621627013} | train loss {'Reaction outcome loss': 0.29144642531980564, 'Total loss': 0.29144642531980564}
2023-01-04 12:03:24,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:24,933 INFO:     Epoch: 57
2023-01-04 12:03:26,484 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38123022615909574, 'Total loss': 0.38123022615909574} | train loss {'Reaction outcome loss': 0.2908478469526681, 'Total loss': 0.2908478469526681}
2023-01-04 12:03:26,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:26,485 INFO:     Epoch: 58
2023-01-04 12:03:28,021 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38367743492126466, 'Total loss': 0.38367743492126466} | train loss {'Reaction outcome loss': 0.2904067763474083, 'Total loss': 0.2904067763474083}
2023-01-04 12:03:28,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:28,021 INFO:     Epoch: 59
2023-01-04 12:03:29,564 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38948929210503896, 'Total loss': 0.38948929210503896} | train loss {'Reaction outcome loss': 0.2916148289983725, 'Total loss': 0.2916148289983725}
2023-01-04 12:03:29,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:29,564 INFO:     Epoch: 60
2023-01-04 12:03:31,101 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3774295081694921, 'Total loss': 0.3774295081694921} | train loss {'Reaction outcome loss': 0.28434432792837605, 'Total loss': 0.28434432792837605}
2023-01-04 12:03:31,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:31,102 INFO:     Epoch: 61
2023-01-04 12:03:32,642 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4171721965074539, 'Total loss': 0.4171721965074539} | train loss {'Reaction outcome loss': 0.28512486616951704, 'Total loss': 0.28512486616951704}
2023-01-04 12:03:32,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:32,643 INFO:     Epoch: 62
2023-01-04 12:03:34,182 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40808398326238, 'Total loss': 0.40808398326238} | train loss {'Reaction outcome loss': 0.2822137470934948, 'Total loss': 0.2822137470934948}
2023-01-04 12:03:34,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:34,182 INFO:     Epoch: 63
2023-01-04 12:03:35,735 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3781014362970988, 'Total loss': 0.3781014362970988} | train loss {'Reaction outcome loss': 0.2792100997464935, 'Total loss': 0.2792100997464935}
2023-01-04 12:03:35,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:35,735 INFO:     Epoch: 64
2023-01-04 12:03:37,309 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39726485510667164, 'Total loss': 0.39726485510667164} | train loss {'Reaction outcome loss': 0.280787864903899, 'Total loss': 0.280787864903899}
2023-01-04 12:03:37,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:37,310 INFO:     Epoch: 65
2023-01-04 12:03:38,888 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3866979936758677, 'Total loss': 0.3866979936758677} | train loss {'Reaction outcome loss': 0.2767556986778322, 'Total loss': 0.2767556986778322}
2023-01-04 12:03:38,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:38,888 INFO:     Epoch: 66
2023-01-04 12:03:40,494 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.372597307463487, 'Total loss': 0.372597307463487} | train loss {'Reaction outcome loss': 0.2755460025076448, 'Total loss': 0.2755460025076448}
2023-01-04 12:03:40,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:40,494 INFO:     Epoch: 67
2023-01-04 12:03:42,033 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43321109414100645, 'Total loss': 0.43321109414100645} | train loss {'Reaction outcome loss': 0.27557972146973125, 'Total loss': 0.27557972146973125}
2023-01-04 12:03:42,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:42,033 INFO:     Epoch: 68
2023-01-04 12:03:43,617 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3709474851687749, 'Total loss': 0.3709474851687749} | train loss {'Reaction outcome loss': 0.27362730427488796, 'Total loss': 0.27362730427488796}
2023-01-04 12:03:43,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:43,617 INFO:     Epoch: 69
2023-01-04 12:03:45,170 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3843053122361501, 'Total loss': 0.3843053122361501} | train loss {'Reaction outcome loss': 0.2770871780540821, 'Total loss': 0.2770871780540821}
2023-01-04 12:03:45,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:45,171 INFO:     Epoch: 70
2023-01-04 12:03:46,783 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37661967873573304, 'Total loss': 0.37661967873573304} | train loss {'Reaction outcome loss': 0.27171569664275996, 'Total loss': 0.27171569664275996}
2023-01-04 12:03:46,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:46,784 INFO:     Epoch: 71
2023-01-04 12:03:48,374 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4044882615407308, 'Total loss': 0.4044882615407308} | train loss {'Reaction outcome loss': 0.2748280323933076, 'Total loss': 0.2748280323933076}
2023-01-04 12:03:48,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:48,374 INFO:     Epoch: 72
2023-01-04 12:03:49,956 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4068230589230855, 'Total loss': 0.4068230589230855} | train loss {'Reaction outcome loss': 0.2689766689156094, 'Total loss': 0.2689766689156094}
2023-01-04 12:03:49,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:49,956 INFO:     Epoch: 73
2023-01-04 12:03:51,544 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44066883325576783, 'Total loss': 0.44066883325576783} | train loss {'Reaction outcome loss': 0.267563885920783, 'Total loss': 0.267563885920783}
2023-01-04 12:03:51,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:51,544 INFO:     Epoch: 74
2023-01-04 12:03:53,125 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3883173366387685, 'Total loss': 0.3883173366387685} | train loss {'Reaction outcome loss': 0.2678060677092876, 'Total loss': 0.2678060677092876}
2023-01-04 12:03:53,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:53,125 INFO:     Epoch: 75
2023-01-04 12:03:54,673 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4083252549171448, 'Total loss': 0.4083252549171448} | train loss {'Reaction outcome loss': 0.2642354694922475, 'Total loss': 0.2642354694922475}
2023-01-04 12:03:54,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:54,673 INFO:     Epoch: 76
2023-01-04 12:03:56,262 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40542460680007936, 'Total loss': 0.40542460680007936} | train loss {'Reaction outcome loss': 0.2653796905991587, 'Total loss': 0.2653796905991587}
2023-01-04 12:03:56,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:56,262 INFO:     Epoch: 77
2023-01-04 12:03:57,873 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4047784556945165, 'Total loss': 0.4047784556945165} | train loss {'Reaction outcome loss': 0.25958892357719204, 'Total loss': 0.25958892357719204}
2023-01-04 12:03:57,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:57,874 INFO:     Epoch: 78
2023-01-04 12:03:59,428 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3932773451010386, 'Total loss': 0.3932773451010386} | train loss {'Reaction outcome loss': 0.26039684697115506, 'Total loss': 0.26039684697115506}
2023-01-04 12:03:59,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:03:59,428 INFO:     Epoch: 79
2023-01-04 12:04:01,042 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.37878751357396445, 'Total loss': 0.37878751357396445} | train loss {'Reaction outcome loss': 0.25823988148222005, 'Total loss': 0.25823988148222005}
2023-01-04 12:04:01,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:01,042 INFO:     Epoch: 80
2023-01-04 12:04:02,624 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37599776635567345, 'Total loss': 0.37599776635567345} | train loss {'Reaction outcome loss': 0.26114943958003156, 'Total loss': 0.26114943958003156}
2023-01-04 12:04:02,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:02,625 INFO:     Epoch: 81
2023-01-04 12:04:04,187 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3674627155065536, 'Total loss': 0.3674627155065536} | train loss {'Reaction outcome loss': 0.2564352200550102, 'Total loss': 0.2564352200550102}
2023-01-04 12:04:04,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:04,188 INFO:     Epoch: 82
2023-01-04 12:04:05,777 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3683635433514913, 'Total loss': 0.3683635433514913} | train loss {'Reaction outcome loss': 0.2586995694024937, 'Total loss': 0.2586995694024937}
2023-01-04 12:04:05,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:05,777 INFO:     Epoch: 83
2023-01-04 12:04:07,368 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3801580756902695, 'Total loss': 0.3801580756902695} | train loss {'Reaction outcome loss': 0.2614329917913806, 'Total loss': 0.2614329917913806}
2023-01-04 12:04:07,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:07,368 INFO:     Epoch: 84
2023-01-04 12:04:08,927 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.39353702664375306, 'Total loss': 0.39353702664375306} | train loss {'Reaction outcome loss': 0.25375571681091386, 'Total loss': 0.25375571681091386}
2023-01-04 12:04:08,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:08,927 INFO:     Epoch: 85
2023-01-04 12:04:10,530 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4141747891902924, 'Total loss': 0.4141747891902924} | train loss {'Reaction outcome loss': 0.25473720989577525, 'Total loss': 0.25473720989577525}
2023-01-04 12:04:10,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:10,530 INFO:     Epoch: 86
2023-01-04 12:04:12,095 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38367629299561185, 'Total loss': 0.38367629299561185} | train loss {'Reaction outcome loss': 0.2528053492062936, 'Total loss': 0.2528053492062936}
2023-01-04 12:04:12,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:12,096 INFO:     Epoch: 87
2023-01-04 12:04:13,649 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3931929220755895, 'Total loss': 0.3931929220755895} | train loss {'Reaction outcome loss': 0.2516735693181518, 'Total loss': 0.2516735693181518}
2023-01-04 12:04:13,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:13,649 INFO:     Epoch: 88
2023-01-04 12:04:15,258 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3587032943964005, 'Total loss': 0.3587032943964005} | train loss {'Reaction outcome loss': 0.2523587635126862, 'Total loss': 0.2523587635126862}
2023-01-04 12:04:15,259 INFO:     Found new best model at epoch 88
2023-01-04 12:04:15,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:15,259 INFO:     Epoch: 89
2023-01-04 12:04:16,863 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40406693319479625, 'Total loss': 0.40406693319479625} | train loss {'Reaction outcome loss': 0.24807565258204067, 'Total loss': 0.24807565258204067}
2023-01-04 12:04:16,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:16,864 INFO:     Epoch: 90
2023-01-04 12:04:18,413 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39132043719291687, 'Total loss': 0.39132043719291687} | train loss {'Reaction outcome loss': 0.24923193254881967, 'Total loss': 0.24923193254881967}
2023-01-04 12:04:18,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:18,414 INFO:     Epoch: 91
2023-01-04 12:04:20,029 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3802662561337153, 'Total loss': 0.3802662561337153} | train loss {'Reaction outcome loss': 0.2510217889925859, 'Total loss': 0.2510217889925859}
2023-01-04 12:04:20,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:20,030 INFO:     Epoch: 92
2023-01-04 12:04:21,590 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3887002925078074, 'Total loss': 0.3887002925078074} | train loss {'Reaction outcome loss': 0.2489849808116029, 'Total loss': 0.2489849808116029}
2023-01-04 12:04:21,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:21,590 INFO:     Epoch: 93
2023-01-04 12:04:23,159 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3508516450723012, 'Total loss': 0.3508516450723012} | train loss {'Reaction outcome loss': 0.24954128926144029, 'Total loss': 0.24954128926144029}
2023-01-04 12:04:23,160 INFO:     Found new best model at epoch 93
2023-01-04 12:04:23,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:23,160 INFO:     Epoch: 94
2023-01-04 12:04:24,768 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41970221797625223, 'Total loss': 0.41970221797625223} | train loss {'Reaction outcome loss': 0.2436217460509417, 'Total loss': 0.2436217460509417}
2023-01-04 12:04:24,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:24,768 INFO:     Epoch: 95
2023-01-04 12:04:26,355 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38003083765506745, 'Total loss': 0.38003083765506745} | train loss {'Reaction outcome loss': 0.2457852032389084, 'Total loss': 0.2457852032389084}
2023-01-04 12:04:26,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:26,355 INFO:     Epoch: 96
2023-01-04 12:04:27,902 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3475436275204023, 'Total loss': 0.3475436275204023} | train loss {'Reaction outcome loss': 0.24550421988713916, 'Total loss': 0.24550421988713916}
2023-01-04 12:04:27,902 INFO:     Found new best model at epoch 96
2023-01-04 12:04:27,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:27,903 INFO:     Epoch: 97
2023-01-04 12:04:29,479 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3742937557399273, 'Total loss': 0.3742937557399273} | train loss {'Reaction outcome loss': 0.24824689936409466, 'Total loss': 0.24824689936409466}
2023-01-04 12:04:29,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:29,479 INFO:     Epoch: 98
2023-01-04 12:04:31,016 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3908116261164347, 'Total loss': 0.3908116261164347} | train loss {'Reaction outcome loss': 0.23765002307991911, 'Total loss': 0.23765002307991911}
2023-01-04 12:04:31,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:31,017 INFO:     Epoch: 99
2023-01-04 12:04:32,582 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3530013769865036, 'Total loss': 0.3530013769865036} | train loss {'Reaction outcome loss': 0.24090633057329777, 'Total loss': 0.24090633057329777}
2023-01-04 12:04:32,583 INFO:     Best model found after epoch 97 of 100.
2023-01-04 12:04:32,584 INFO:   Done with stage: TRAINING
2023-01-04 12:04:32,584 INFO:   Starting stage: EVALUATION
2023-01-04 12:04:32,720 INFO:   Done with stage: EVALUATION
2023-01-04 12:04:32,720 INFO:   Leaving out SEQ value Fold_9
2023-01-04 12:04:32,732 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 12:04:32,732 INFO:   Starting stage: FEATURE SCALING
2023-01-04 12:04:33,381 INFO:   Done with stage: FEATURE SCALING
2023-01-04 12:04:33,381 INFO:   Starting stage: SCALING TARGETS
2023-01-04 12:04:33,450 INFO:   Done with stage: SCALING TARGETS
2023-01-04 12:04:33,450 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 12:04:33,450 INFO:     No hyperparam tuning for this model
2023-01-04 12:04:33,450 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 12:04:33,450 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 12:04:33,451 INFO:     None feature selector for col prot
2023-01-04 12:04:33,451 INFO:     None feature selector for col prot
2023-01-04 12:04:33,451 INFO:     None feature selector for col prot
2023-01-04 12:04:33,452 INFO:     None feature selector for col chem
2023-01-04 12:04:33,452 INFO:     None feature selector for col chem
2023-01-04 12:04:33,452 INFO:     None feature selector for col chem
2023-01-04 12:04:33,452 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 12:04:33,452 INFO:   Starting stage: BUILD MODEL
2023-01-04 12:04:33,453 INFO:     Number of params in model 70111
2023-01-04 12:04:33,456 INFO:   Done with stage: BUILD MODEL
2023-01-04 12:04:33,456 INFO:   Starting stage: TRAINING
2023-01-04 12:04:33,500 INFO:     Val loss before train {'Reaction outcome loss': 0.8886114438374837, 'Total loss': 0.8886114438374837}
2023-01-04 12:04:33,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:33,500 INFO:     Epoch: 0
2023-01-04 12:04:35,118 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.678042072057724, 'Total loss': 0.678042072057724} | train loss {'Reaction outcome loss': 0.879198331157223, 'Total loss': 0.879198331157223}
2023-01-04 12:04:35,118 INFO:     Found new best model at epoch 0
2023-01-04 12:04:35,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:35,119 INFO:     Epoch: 1
2023-01-04 12:04:36,696 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6045907318592072, 'Total loss': 0.6045907318592072} | train loss {'Reaction outcome loss': 0.7197785826151122, 'Total loss': 0.7197785826151122}
2023-01-04 12:04:36,697 INFO:     Found new best model at epoch 1
2023-01-04 12:04:36,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:36,697 INFO:     Epoch: 2
2023-01-04 12:04:38,287 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5407766371965408, 'Total loss': 0.5407766371965408} | train loss {'Reaction outcome loss': 0.6206514813839744, 'Total loss': 0.6206514813839744}
2023-01-04 12:04:38,287 INFO:     Found new best model at epoch 2
2023-01-04 12:04:38,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:38,288 INFO:     Epoch: 3
2023-01-04 12:04:39,840 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5309663077195486, 'Total loss': 0.5309663077195486} | train loss {'Reaction outcome loss': 0.5687615224815878, 'Total loss': 0.5687615224815878}
2023-01-04 12:04:39,840 INFO:     Found new best model at epoch 3
2023-01-04 12:04:39,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:39,841 INFO:     Epoch: 4
2023-01-04 12:04:41,444 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49597121675809225, 'Total loss': 0.49597121675809225} | train loss {'Reaction outcome loss': 0.5402527519834601, 'Total loss': 0.5402527519834601}
2023-01-04 12:04:41,444 INFO:     Found new best model at epoch 4
2023-01-04 12:04:41,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:41,445 INFO:     Epoch: 5
2023-01-04 12:04:43,046 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4723661204179128, 'Total loss': 0.4723661204179128} | train loss {'Reaction outcome loss': 0.5198855110669395, 'Total loss': 0.5198855110669395}
2023-01-04 12:04:43,046 INFO:     Found new best model at epoch 5
2023-01-04 12:04:43,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:43,047 INFO:     Epoch: 6
2023-01-04 12:04:44,603 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46584103504816693, 'Total loss': 0.46584103504816693} | train loss {'Reaction outcome loss': 0.5109589645901311, 'Total loss': 0.5109589645901311}
2023-01-04 12:04:44,603 INFO:     Found new best model at epoch 6
2023-01-04 12:04:44,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:44,604 INFO:     Epoch: 7
2023-01-04 12:04:46,198 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45369203090667726, 'Total loss': 0.45369203090667726} | train loss {'Reaction outcome loss': 0.4930478951453302, 'Total loss': 0.4930478951453302}
2023-01-04 12:04:46,199 INFO:     Found new best model at epoch 7
2023-01-04 12:04:46,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:46,199 INFO:     Epoch: 8
2023-01-04 12:04:47,784 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44890020887056986, 'Total loss': 0.44890020887056986} | train loss {'Reaction outcome loss': 0.4885491434525066, 'Total loss': 0.4885491434525066}
2023-01-04 12:04:47,784 INFO:     Found new best model at epoch 8
2023-01-04 12:04:47,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:47,785 INFO:     Epoch: 9
2023-01-04 12:04:49,346 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44873775442441305, 'Total loss': 0.44873775442441305} | train loss {'Reaction outcome loss': 0.4765495138263014, 'Total loss': 0.4765495138263014}
2023-01-04 12:04:49,346 INFO:     Found new best model at epoch 9
2023-01-04 12:04:49,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:49,347 INFO:     Epoch: 10
2023-01-04 12:04:50,936 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44052930076917013, 'Total loss': 0.44052930076917013} | train loss {'Reaction outcome loss': 0.47084998670252654, 'Total loss': 0.47084998670252654}
2023-01-04 12:04:50,936 INFO:     Found new best model at epoch 10
2023-01-04 12:04:50,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:50,937 INFO:     Epoch: 11
2023-01-04 12:04:52,522 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4439670960108439, 'Total loss': 0.4439670960108439} | train loss {'Reaction outcome loss': 0.46654715972686933, 'Total loss': 0.46654715972686933}
2023-01-04 12:04:52,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:52,523 INFO:     Epoch: 12
2023-01-04 12:04:54,067 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43327064911524454, 'Total loss': 0.43327064911524454} | train loss {'Reaction outcome loss': 0.4614566637720872, 'Total loss': 0.4614566637720872}
2023-01-04 12:04:54,068 INFO:     Found new best model at epoch 12
2023-01-04 12:04:54,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:54,068 INFO:     Epoch: 13
2023-01-04 12:04:55,669 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4350893427928289, 'Total loss': 0.4350893427928289} | train loss {'Reaction outcome loss': 0.45394068402288623, 'Total loss': 0.45394068402288623}
2023-01-04 12:04:55,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:55,669 INFO:     Epoch: 14
2023-01-04 12:04:57,263 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4049930304288864, 'Total loss': 0.4049930304288864} | train loss {'Reaction outcome loss': 0.45308275257207, 'Total loss': 0.45308275257207}
2023-01-04 12:04:57,263 INFO:     Found new best model at epoch 14
2023-01-04 12:04:57,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:57,264 INFO:     Epoch: 15
2023-01-04 12:04:58,821 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43233888745307925, 'Total loss': 0.43233888745307925} | train loss {'Reaction outcome loss': 0.4472454249966446, 'Total loss': 0.4472454249966446}
2023-01-04 12:04:58,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:04:58,821 INFO:     Epoch: 16
2023-01-04 12:05:00,408 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4071091771125793, 'Total loss': 0.4071091771125793} | train loss {'Reaction outcome loss': 0.4387998438376382, 'Total loss': 0.4387998438376382}
2023-01-04 12:05:00,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:00,408 INFO:     Epoch: 17
2023-01-04 12:05:01,986 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42032923698425295, 'Total loss': 0.42032923698425295} | train loss {'Reaction outcome loss': 0.43511379935143224, 'Total loss': 0.43511379935143224}
2023-01-04 12:05:01,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:01,986 INFO:     Epoch: 18
2023-01-04 12:05:03,504 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4260178079207738, 'Total loss': 0.4260178079207738} | train loss {'Reaction outcome loss': 0.43430311902550583, 'Total loss': 0.43430311902550583}
2023-01-04 12:05:03,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:03,505 INFO:     Epoch: 19
2023-01-04 12:05:05,076 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40791984697182976, 'Total loss': 0.40791984697182976} | train loss {'Reaction outcome loss': 0.4291569658349998, 'Total loss': 0.4291569658349998}
2023-01-04 12:05:05,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:05,076 INFO:     Epoch: 20
2023-01-04 12:05:06,606 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4004853069782257, 'Total loss': 0.4004853069782257} | train loss {'Reaction outcome loss': 0.42361825050967694, 'Total loss': 0.42361825050967694}
2023-01-04 12:05:06,606 INFO:     Found new best model at epoch 20
2023-01-04 12:05:06,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:06,607 INFO:     Epoch: 21
2023-01-04 12:05:08,187 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39134345153967537, 'Total loss': 0.39134345153967537} | train loss {'Reaction outcome loss': 0.4210463881169846, 'Total loss': 0.4210463881169846}
2023-01-04 12:05:08,187 INFO:     Found new best model at epoch 21
2023-01-04 12:05:08,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:08,188 INFO:     Epoch: 22
2023-01-04 12:05:09,762 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3999848524729411, 'Total loss': 0.3999848524729411} | train loss {'Reaction outcome loss': 0.4230584473977881, 'Total loss': 0.4230584473977881}
2023-01-04 12:05:09,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:09,763 INFO:     Epoch: 23
2023-01-04 12:05:11,339 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3973930170138677, 'Total loss': 0.3973930170138677} | train loss {'Reaction outcome loss': 0.41572503906940295, 'Total loss': 0.41572503906940295}
2023-01-04 12:05:11,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:11,339 INFO:     Epoch: 24
2023-01-04 12:05:12,879 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4052376429239909, 'Total loss': 0.4052376429239909} | train loss {'Reaction outcome loss': 0.41069464676001444, 'Total loss': 0.41069464676001444}
2023-01-04 12:05:12,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:12,879 INFO:     Epoch: 25
2023-01-04 12:05:14,466 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3924492845932643, 'Total loss': 0.3924492845932643} | train loss {'Reaction outcome loss': 0.4070347219920761, 'Total loss': 0.4070347219920761}
2023-01-04 12:05:14,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:14,466 INFO:     Epoch: 26
2023-01-04 12:05:16,005 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39580973188082375, 'Total loss': 0.39580973188082375} | train loss {'Reaction outcome loss': 0.40521399596107566, 'Total loss': 0.40521399596107566}
2023-01-04 12:05:16,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:16,005 INFO:     Epoch: 27
2023-01-04 12:05:17,576 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39501106639703115, 'Total loss': 0.39501106639703115} | train loss {'Reaction outcome loss': 0.40050775092431357, 'Total loss': 0.40050775092431357}
2023-01-04 12:05:17,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:17,576 INFO:     Epoch: 28
2023-01-04 12:05:19,143 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40982907116413114, 'Total loss': 0.40982907116413114} | train loss {'Reaction outcome loss': 0.3992125905969513, 'Total loss': 0.3992125905969513}
2023-01-04 12:05:19,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:19,143 INFO:     Epoch: 29
2023-01-04 12:05:20,713 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40305157701174416, 'Total loss': 0.40305157701174416} | train loss {'Reaction outcome loss': 0.3923988109891595, 'Total loss': 0.3923988109891595}
2023-01-04 12:05:20,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:20,713 INFO:     Epoch: 30
2023-01-04 12:05:22,281 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39487769405047096, 'Total loss': 0.39487769405047096} | train loss {'Reaction outcome loss': 0.39105195947502497, 'Total loss': 0.39105195947502497}
2023-01-04 12:05:22,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:22,281 INFO:     Epoch: 31
2023-01-04 12:05:23,861 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3893456866343816, 'Total loss': 0.3893456866343816} | train loss {'Reaction outcome loss': 0.3853315632749981, 'Total loss': 0.3853315632749981}
2023-01-04 12:05:23,861 INFO:     Found new best model at epoch 31
2023-01-04 12:05:23,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:23,862 INFO:     Epoch: 32
2023-01-04 12:05:25,425 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.37538129885991417, 'Total loss': 0.37538129885991417} | train loss {'Reaction outcome loss': 0.38308638619386765, 'Total loss': 0.38308638619386765}
2023-01-04 12:05:25,425 INFO:     Found new best model at epoch 32
2023-01-04 12:05:25,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:25,426 INFO:     Epoch: 33
2023-01-04 12:05:27,005 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3928251683712006, 'Total loss': 0.3928251683712006} | train loss {'Reaction outcome loss': 0.37714791002041165, 'Total loss': 0.37714791002041165}
2023-01-04 12:05:27,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:27,006 INFO:     Epoch: 34
2023-01-04 12:05:28,580 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3929931958516439, 'Total loss': 0.3929931958516439} | train loss {'Reaction outcome loss': 0.37574699241331766, 'Total loss': 0.37574699241331766}
2023-01-04 12:05:28,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:28,581 INFO:     Epoch: 35
2023-01-04 12:05:30,115 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3894774536291758, 'Total loss': 0.3894774536291758} | train loss {'Reaction outcome loss': 0.37549208403171613, 'Total loss': 0.37549208403171613}
2023-01-04 12:05:30,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:30,115 INFO:     Epoch: 36
2023-01-04 12:05:31,673 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37812986274560295, 'Total loss': 0.37812986274560295} | train loss {'Reaction outcome loss': 0.37175939232110977, 'Total loss': 0.37175939232110977}
2023-01-04 12:05:31,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:31,673 INFO:     Epoch: 37
2023-01-04 12:05:33,235 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3842404435078303, 'Total loss': 0.3842404435078303} | train loss {'Reaction outcome loss': 0.36690161605819466, 'Total loss': 0.36690161605819466}
2023-01-04 12:05:33,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:33,236 INFO:     Epoch: 38
2023-01-04 12:05:34,774 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3797711690266927, 'Total loss': 0.3797711690266927} | train loss {'Reaction outcome loss': 0.362420391197239, 'Total loss': 0.362420391197239}
2023-01-04 12:05:34,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:34,775 INFO:     Epoch: 39
2023-01-04 12:05:36,377 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40250930388768513, 'Total loss': 0.40250930388768513} | train loss {'Reaction outcome loss': 0.3596939910673923, 'Total loss': 0.3596939910673923}
2023-01-04 12:05:36,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:36,377 INFO:     Epoch: 40
2023-01-04 12:05:37,954 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4082846254110336, 'Total loss': 0.4082846254110336} | train loss {'Reaction outcome loss': 0.3569177200056155, 'Total loss': 0.3569177200056155}
2023-01-04 12:05:37,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:37,954 INFO:     Epoch: 41
2023-01-04 12:05:39,502 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37502513925234476, 'Total loss': 0.37502513925234476} | train loss {'Reaction outcome loss': 0.35536669560503015, 'Total loss': 0.35536669560503015}
2023-01-04 12:05:39,502 INFO:     Found new best model at epoch 41
2023-01-04 12:05:39,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:39,503 INFO:     Epoch: 42
2023-01-04 12:05:41,103 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3924164960781733, 'Total loss': 0.3924164960781733} | train loss {'Reaction outcome loss': 0.3517303855733321, 'Total loss': 0.3517303855733321}
2023-01-04 12:05:41,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:41,104 INFO:     Epoch: 43
2023-01-04 12:05:42,709 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3756819109121958, 'Total loss': 0.3756819109121958} | train loss {'Reaction outcome loss': 0.3473970365007862, 'Total loss': 0.3473970365007862}
2023-01-04 12:05:42,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:42,709 INFO:     Epoch: 44
2023-01-04 12:05:44,289 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.36246624489625295, 'Total loss': 0.36246624489625295} | train loss {'Reaction outcome loss': 0.3474668266002882, 'Total loss': 0.3474668266002882}
2023-01-04 12:05:44,289 INFO:     Found new best model at epoch 44
2023-01-04 12:05:44,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:44,290 INFO:     Epoch: 45
2023-01-04 12:05:45,875 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3786189834276835, 'Total loss': 0.3786189834276835} | train loss {'Reaction outcome loss': 0.3453142781496478, 'Total loss': 0.3453142781496478}
2023-01-04 12:05:45,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:45,875 INFO:     Epoch: 46
2023-01-04 12:05:47,463 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3724655956029892, 'Total loss': 0.3724655956029892} | train loss {'Reaction outcome loss': 0.3402913869879736, 'Total loss': 0.3402913869879736}
2023-01-04 12:05:47,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:47,463 INFO:     Epoch: 47
2023-01-04 12:05:49,019 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3683846781651179, 'Total loss': 0.3683846781651179} | train loss {'Reaction outcome loss': 0.340398086940984, 'Total loss': 0.340398086940984}
2023-01-04 12:05:49,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:49,019 INFO:     Epoch: 48
2023-01-04 12:05:50,603 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3896703084309896, 'Total loss': 0.3896703084309896} | train loss {'Reaction outcome loss': 0.3387429621406841, 'Total loss': 0.3387429621406841}
2023-01-04 12:05:50,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:50,603 INFO:     Epoch: 49
2023-01-04 12:05:52,152 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38348320027192434, 'Total loss': 0.38348320027192434} | train loss {'Reaction outcome loss': 0.3367763588789998, 'Total loss': 0.3367763588789998}
2023-01-04 12:05:52,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:52,153 INFO:     Epoch: 50
2023-01-04 12:05:53,742 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.371897828578949, 'Total loss': 0.371897828578949} | train loss {'Reaction outcome loss': 0.33069810013048057, 'Total loss': 0.33069810013048057}
2023-01-04 12:05:53,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:53,743 INFO:     Epoch: 51
2023-01-04 12:05:55,313 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.37761424779891967, 'Total loss': 0.37761424779891967} | train loss {'Reaction outcome loss': 0.3249692702497816, 'Total loss': 0.3249692702497816}
2023-01-04 12:05:55,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:55,313 INFO:     Epoch: 52
2023-01-04 12:05:56,899 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3691853523254395, 'Total loss': 0.3691853523254395} | train loss {'Reaction outcome loss': 0.32822238048706676, 'Total loss': 0.32822238048706676}
2023-01-04 12:05:56,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:56,900 INFO:     Epoch: 53
2023-01-04 12:05:58,451 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3580337474743525, 'Total loss': 0.3580337474743525} | train loss {'Reaction outcome loss': 0.3231447736063589, 'Total loss': 0.3231447736063589}
2023-01-04 12:05:58,451 INFO:     Found new best model at epoch 53
2023-01-04 12:05:58,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:05:58,452 INFO:     Epoch: 54
2023-01-04 12:06:00,033 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.36752740293741226, 'Total loss': 0.36752740293741226} | train loss {'Reaction outcome loss': 0.3229074945357302, 'Total loss': 0.3229074945357302}
2023-01-04 12:06:00,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:00,034 INFO:     Epoch: 55
2023-01-04 12:06:01,593 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40832459131876625, 'Total loss': 0.40832459131876625} | train loss {'Reaction outcome loss': 0.3235609864392435, 'Total loss': 0.3235609864392435}
2023-01-04 12:06:01,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:01,593 INFO:     Epoch: 56
2023-01-04 12:06:03,180 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4024779876073202, 'Total loss': 0.4024779876073202} | train loss {'Reaction outcome loss': 0.3204649131650959, 'Total loss': 0.3204649131650959}
2023-01-04 12:06:03,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:03,181 INFO:     Epoch: 57
2023-01-04 12:06:04,754 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4033425817886988, 'Total loss': 0.4033425817886988} | train loss {'Reaction outcome loss': 0.3150227755335049, 'Total loss': 0.3150227755335049}
2023-01-04 12:06:04,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:04,754 INFO:     Epoch: 58
2023-01-04 12:06:06,290 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3734774092833201, 'Total loss': 0.3734774092833201} | train loss {'Reaction outcome loss': 0.3164182609007677, 'Total loss': 0.3164182609007677}
2023-01-04 12:06:06,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:06,290 INFO:     Epoch: 59
2023-01-04 12:06:07,885 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3730097105105718, 'Total loss': 0.3730097105105718} | train loss {'Reaction outcome loss': 0.31635721097784353, 'Total loss': 0.31635721097784353}
2023-01-04 12:06:07,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:07,885 INFO:     Epoch: 60
2023-01-04 12:06:09,499 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3560431738694509, 'Total loss': 0.3560431738694509} | train loss {'Reaction outcome loss': 0.314913840742533, 'Total loss': 0.314913840742533}
2023-01-04 12:06:09,499 INFO:     Found new best model at epoch 60
2023-01-04 12:06:09,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:09,500 INFO:     Epoch: 61
2023-01-04 12:06:11,047 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3625973343849182, 'Total loss': 0.3625973343849182} | train loss {'Reaction outcome loss': 0.31601113212775667, 'Total loss': 0.31601113212775667}
2023-01-04 12:06:11,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:11,048 INFO:     Epoch: 62
2023-01-04 12:06:12,647 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3746127595504125, 'Total loss': 0.3746127595504125} | train loss {'Reaction outcome loss': 0.3107203535385941, 'Total loss': 0.3107203535385941}
2023-01-04 12:06:12,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:12,647 INFO:     Epoch: 63
2023-01-04 12:06:14,237 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3676929841438929, 'Total loss': 0.3676929841438929} | train loss {'Reaction outcome loss': 0.3106048180577127, 'Total loss': 0.3106048180577127}
2023-01-04 12:06:14,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:14,238 INFO:     Epoch: 64
2023-01-04 12:06:15,784 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3448235506812731, 'Total loss': 0.3448235506812731} | train loss {'Reaction outcome loss': 0.3077054146125859, 'Total loss': 0.3077054146125859}
2023-01-04 12:06:15,784 INFO:     Found new best model at epoch 64
2023-01-04 12:06:15,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:15,785 INFO:     Epoch: 65
2023-01-04 12:06:17,395 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38407061994075775, 'Total loss': 0.38407061994075775} | train loss {'Reaction outcome loss': 0.30581678511299165, 'Total loss': 0.30581678511299165}
2023-01-04 12:06:17,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:17,396 INFO:     Epoch: 66
2023-01-04 12:06:18,993 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.354216290016969, 'Total loss': 0.354216290016969} | train loss {'Reaction outcome loss': 0.30498677400690555, 'Total loss': 0.30498677400690555}
2023-01-04 12:06:18,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:18,993 INFO:     Epoch: 67
2023-01-04 12:06:20,562 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3554681728283564, 'Total loss': 0.3554681728283564} | train loss {'Reaction outcome loss': 0.30413917262470247, 'Total loss': 0.30413917262470247}
2023-01-04 12:06:20,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:20,562 INFO:     Epoch: 68
2023-01-04 12:06:22,138 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.35974843402703605, 'Total loss': 0.35974843402703605} | train loss {'Reaction outcome loss': 0.30191546511779194, 'Total loss': 0.30191546511779194}
2023-01-04 12:06:22,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:22,138 INFO:     Epoch: 69
2023-01-04 12:06:23,765 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.36334755619366965, 'Total loss': 0.36334755619366965} | train loss {'Reaction outcome loss': 0.3071526776770607, 'Total loss': 0.3071526776770607}
2023-01-04 12:06:23,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:23,766 INFO:     Epoch: 70
2023-01-04 12:06:25,339 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.36956301927566526, 'Total loss': 0.36956301927566526} | train loss {'Reaction outcome loss': 0.2983770664472012, 'Total loss': 0.2983770664472012}
2023-01-04 12:06:25,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:25,340 INFO:     Epoch: 71
2023-01-04 12:06:26,970 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3835107853015264, 'Total loss': 0.3835107853015264} | train loss {'Reaction outcome loss': 0.2988444168645122, 'Total loss': 0.2988444168645122}
2023-01-04 12:06:26,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:26,970 INFO:     Epoch: 72
2023-01-04 12:06:28,535 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3763742595911026, 'Total loss': 0.3763742595911026} | train loss {'Reaction outcome loss': 0.2943015542916873, 'Total loss': 0.2943015542916873}
2023-01-04 12:06:28,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:28,536 INFO:     Epoch: 73
2023-01-04 12:06:30,140 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3532292485237122, 'Total loss': 0.3532292485237122} | train loss {'Reaction outcome loss': 0.2945659217367534, 'Total loss': 0.2945659217367534}
2023-01-04 12:06:30,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:30,141 INFO:     Epoch: 74
2023-01-04 12:06:31,758 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37232894798119864, 'Total loss': 0.37232894798119864} | train loss {'Reaction outcome loss': 0.2928466663463882, 'Total loss': 0.2928466663463882}
2023-01-04 12:06:31,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:31,758 INFO:     Epoch: 75
2023-01-04 12:06:33,374 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3626401424407959, 'Total loss': 0.3626401424407959} | train loss {'Reaction outcome loss': 0.2910803755483042, 'Total loss': 0.2910803755483042}
2023-01-04 12:06:33,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:33,375 INFO:     Epoch: 76
2023-01-04 12:06:34,932 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.36708050991098085, 'Total loss': 0.36708050991098085} | train loss {'Reaction outcome loss': 0.29319974529936854, 'Total loss': 0.29319974529936854}
2023-01-04 12:06:34,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:34,932 INFO:     Epoch: 77
2023-01-04 12:06:36,539 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3684369643529256, 'Total loss': 0.3684369643529256} | train loss {'Reaction outcome loss': 0.29529366526577877, 'Total loss': 0.29529366526577877}
2023-01-04 12:06:36,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:36,540 INFO:     Epoch: 78
2023-01-04 12:06:38,097 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.36836194694042207, 'Total loss': 0.36836194694042207} | train loss {'Reaction outcome loss': 0.2895408850499439, 'Total loss': 0.2895408850499439}
2023-01-04 12:06:38,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:38,097 INFO:     Epoch: 79
2023-01-04 12:06:39,710 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.36924225588639575, 'Total loss': 0.36924225588639575} | train loss {'Reaction outcome loss': 0.2869577055077475, 'Total loss': 0.2869577055077475}
2023-01-04 12:06:39,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:39,711 INFO:     Epoch: 80
2023-01-04 12:06:41,305 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4056944330533346, 'Total loss': 0.4056944330533346} | train loss {'Reaction outcome loss': 0.2840274221361329, 'Total loss': 0.2840274221361329}
2023-01-04 12:06:41,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:41,306 INFO:     Epoch: 81
2023-01-04 12:06:42,878 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.35839245667060216, 'Total loss': 0.35839245667060216} | train loss {'Reaction outcome loss': 0.28630686855273124, 'Total loss': 0.28630686855273124}
2023-01-04 12:06:42,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:42,878 INFO:     Epoch: 82
2023-01-04 12:06:44,480 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3403920034567515, 'Total loss': 0.3403920034567515} | train loss {'Reaction outcome loss': 0.2847462830130374, 'Total loss': 0.2847462830130374}
2023-01-04 12:06:44,480 INFO:     Found new best model at epoch 82
2023-01-04 12:06:44,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:44,481 INFO:     Epoch: 83
2023-01-04 12:06:46,075 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.35107623835404717, 'Total loss': 0.35107623835404717} | train loss {'Reaction outcome loss': 0.2857044685887516, 'Total loss': 0.2857044685887516}
2023-01-04 12:06:46,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:46,077 INFO:     Epoch: 84
2023-01-04 12:06:47,644 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37248643636703493, 'Total loss': 0.37248643636703493} | train loss {'Reaction outcome loss': 0.2849701203217575, 'Total loss': 0.2849701203217575}
2023-01-04 12:06:47,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:47,645 INFO:     Epoch: 85
2023-01-04 12:06:49,241 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.338315020998319, 'Total loss': 0.338315020998319} | train loss {'Reaction outcome loss': 0.2801056659447587, 'Total loss': 0.2801056659447587}
2023-01-04 12:06:49,241 INFO:     Found new best model at epoch 85
2023-01-04 12:06:49,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:49,242 INFO:     Epoch: 86
2023-01-04 12:06:50,831 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3523483738303185, 'Total loss': 0.3523483738303185} | train loss {'Reaction outcome loss': 0.28043396877198873, 'Total loss': 0.28043396877198873}
2023-01-04 12:06:50,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:50,831 INFO:     Epoch: 87
2023-01-04 12:06:52,397 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.35470934907595314, 'Total loss': 0.35470934907595314} | train loss {'Reaction outcome loss': 0.2776484239833019, 'Total loss': 0.2776484239833019}
2023-01-04 12:06:52,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:52,398 INFO:     Epoch: 88
2023-01-04 12:06:53,989 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3633632625142733, 'Total loss': 0.3633632625142733} | train loss {'Reaction outcome loss': 0.2831226950141497, 'Total loss': 0.2831226950141497}
2023-01-04 12:06:53,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:53,989 INFO:     Epoch: 89
2023-01-04 12:06:55,584 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3709244102239609, 'Total loss': 0.3709244102239609} | train loss {'Reaction outcome loss': 0.27664671615035097, 'Total loss': 0.27664671615035097}
2023-01-04 12:06:55,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:55,584 INFO:     Epoch: 90
2023-01-04 12:06:57,155 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3706809451182683, 'Total loss': 0.3706809451182683} | train loss {'Reaction outcome loss': 0.2768662382280353, 'Total loss': 0.2768662382280353}
2023-01-04 12:06:57,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:57,155 INFO:     Epoch: 91
2023-01-04 12:06:58,780 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3426712056001027, 'Total loss': 0.3426712056001027} | train loss {'Reaction outcome loss': 0.2806045476764118, 'Total loss': 0.2806045476764118}
2023-01-04 12:06:58,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:06:58,780 INFO:     Epoch: 92
2023-01-04 12:07:00,378 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3689010918140411, 'Total loss': 0.3689010918140411} | train loss {'Reaction outcome loss': 0.2761342575242373, 'Total loss': 0.2761342575242373}
2023-01-04 12:07:00,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:07:00,378 INFO:     Epoch: 93
2023-01-04 12:07:01,949 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39112155338128407, 'Total loss': 0.39112155338128407} | train loss {'Reaction outcome loss': 0.275210350563595, 'Total loss': 0.275210350563595}
2023-01-04 12:07:01,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:07:01,949 INFO:     Epoch: 94
2023-01-04 12:07:03,549 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3642560680707296, 'Total loss': 0.3642560680707296} | train loss {'Reaction outcome loss': 0.27481922977990625, 'Total loss': 0.27481922977990625}
2023-01-04 12:07:03,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:07:03,549 INFO:     Epoch: 95
2023-01-04 12:07:05,122 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37186129838228227, 'Total loss': 0.37186129838228227} | train loss {'Reaction outcome loss': 0.2719299941986046, 'Total loss': 0.2719299941986046}
2023-01-04 12:07:05,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:07:05,123 INFO:     Epoch: 96
2023-01-04 12:07:06,734 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3686330979069074, 'Total loss': 0.3686330979069074} | train loss {'Reaction outcome loss': 0.2749876532743984, 'Total loss': 0.2749876532743984}
2023-01-04 12:07:06,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:07:06,734 INFO:     Epoch: 97
2023-01-04 12:07:08,360 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36330864230791726, 'Total loss': 0.36330864230791726} | train loss {'Reaction outcome loss': 0.27253001823429596, 'Total loss': 0.27253001823429596}
2023-01-04 12:07:08,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:07:08,360 INFO:     Epoch: 98
2023-01-04 12:07:09,962 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37066162526607516, 'Total loss': 0.37066162526607516} | train loss {'Reaction outcome loss': 0.2635047461850979, 'Total loss': 0.2635047461850979}
2023-01-04 12:07:09,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 12:07:09,962 INFO:     Epoch: 99
2023-01-04 12:07:11,530 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.380619153380394, 'Total loss': 0.380619153380394} | train loss {'Reaction outcome loss': 0.269481330101348, 'Total loss': 0.269481330101348}
2023-01-04 12:07:11,530 INFO:     Best model found after epoch 86 of 100.
2023-01-04 12:07:11,531 INFO:   Done with stage: TRAINING
2023-01-04 12:07:11,531 INFO:   Starting stage: EVALUATION
2023-01-04 12:07:11,652 INFO:   Done with stage: EVALUATION
2023-01-04 12:07:11,652 INFO: Done with stage: RUNNING SPLITS
2023-01-04 12:07:11,652 INFO: Starting stage: COMPUTE METRICS
2023-01-04 12:07:12,832 INFO: Done with stage: COMPUTE METRICS
2023-01-04 12:07:12,833 INFO: Starting stage: EXPORT RESULTS
2023-01-04 12:07:12,850 INFO:   Final results averaged over 50 folds: 
2023-01-04 12:07:12,854 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.209026           NaN  0.345264       NaN
2023-01-04 12:07:14,558 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2023-01-04 12:07:14,563 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2023-01-04 12:07:14,565 DEBUG:   interactive is False
2023-01-04 12:07:14,565 DEBUG:   platform is linux
2023-01-04 12:07:14,565 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.sql.naming', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2023-01-04 12:07:14,734 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2023-01-04 12:07:14,736 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2023-01-04 12:07:15,176 DEBUG:   Loaded backend agg version unknown.
2023-01-04 12:07:15,178 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-04 12:07:15,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 12:07:15,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 12:07:15,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 12:07:15,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,179 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,179 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,179 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,179 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 12:07:15,179 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 12:07:15,179 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,179 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,179 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,179 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 12:07:15,179 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,179 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 12:07:15,179 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,179 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,179 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-04 12:07:15,179 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 12:07:15,179 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 12:07:15,179 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,180 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,180 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,180 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,180 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,180 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,180 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,180 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,180 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,180 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-04 12:07:15,180 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,180 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,180 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,180 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,180 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 12:07:15,180 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 12:07:15,180 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,181 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,181 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,181 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 12:07:15,181 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,181 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-04 12:07:15,217 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2023-01-04 12:07:15,217 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,217 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,217 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,217 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 12:07:15,217 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 12:07:15,217 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 12:07:15,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 12:07:15,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 12:07:15,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 12:07:15,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 12:07:15,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-04 12:07:15,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 12:07:15,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 12:07:15,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-04 12:07:15,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 12:07:15,219 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 12:07:15,219 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,220 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,220 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,220 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 12:07:15,220 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,220 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-04 12:07:15,228 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-04 12:07:15,228 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,228 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,228 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,228 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 12:07:15,229 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 12:07:15,229 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 12:07:15,229 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,229 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,229 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,229 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,229 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 12:07:15,229 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 12:07:15,229 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,229 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,229 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,229 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 12:07:15,229 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,229 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 12:07:15,229 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,229 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-04 12:07:15,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 12:07:15,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 12:07:15,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-04 12:07:15,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,230 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,231 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 12:07:15,231 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 12:07:15,231 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,231 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,231 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 12:07:15,231 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 12:07:15,231 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 12:07:15,231 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-04 12:07:15,626 INFO: Done with stage: EXPORT RESULTS
2023-01-04 12:07:15,627 INFO: Starting stage: SAVE MODEL
2023-01-04 12:07:15,692 INFO: Done with stage: SAVE MODEL
2023-01-04 12:07:15,692 INFO: Wall time for program:  7833.47 seconds
