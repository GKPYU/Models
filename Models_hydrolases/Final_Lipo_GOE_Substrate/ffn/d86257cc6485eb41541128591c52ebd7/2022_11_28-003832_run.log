2022-11-28 04:43:46,385 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/d86257cc6485eb41541128591c52ebd7/2022_11_28-003832",
  "seed": 2,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "jtvae",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffn/a84e288a23e2297711eccae574abbf00/2021_05_26-165105_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.85,
  "val_size": 0.15,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.001491528877467142,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 90,
  "model_dropout": 0.13830197814960504,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.00785511672758935,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-11-28 04:43:46,393 INFO: Starting stage: BUILD FEATURIZERS
2022-11-28 04:43:46,398 INFO:   Creating esm representation model
2022-11-28 04:43:46,399 INFO:   Done esm representation model
2022-11-28 04:43:46,399 INFO: Done with stage: BUILD FEATURIZERS
2022-11-28 04:43:46,399 INFO: Starting stage: BUILDING DATASET
2022-11-28 04:43:46,451 INFO: Done with stage: BUILDING DATASET
2022-11-28 04:43:46,452 INFO: Starting stage: FEATURIZING DATA
2022-11-28 04:43:46,452 INFO:   Featurizing proteins
2022-11-28 04:43:46,453 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-11-28 04:43:46,475 INFO:   Loaded feature cache of size 204
2022-11-28 04:43:46,476 INFO:   Starting to pool ESM Embeddings
2022-11-28 04:43:46,554 INFO:   Featurizing molecules
2022-11-28 04:43:46,577 INFO: Done with stage: FEATURIZING DATA
2022-11-28 04:43:46,577 INFO: Starting stage: RUNNING SPLITS
2022-11-28 04:43:46,585 INFO:   Leaving out SEQ value Fold_0
2022-11-28 04:43:46,599 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 04:43:46,599 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:43:47,259 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:43:47,259 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:43:47,328 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:43:47,328 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:43:47,328 INFO:     No hyperparam tuning for this model
2022-11-28 04:43:47,328 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:43:47,328 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:43:47,329 INFO:     None feature selector for col prot
2022-11-28 04:43:47,329 INFO:     None feature selector for col prot
2022-11-28 04:43:47,329 INFO:     None feature selector for col prot
2022-11-28 04:43:47,329 INFO:     None feature selector for col chem
2022-11-28 04:43:47,329 INFO:     None feature selector for col chem
2022-11-28 04:43:47,330 INFO:     None feature selector for col chem
2022-11-28 04:43:47,330 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:43:47,330 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:43:47,331 INFO:     Number of params in model 169651
2022-11-28 04:43:47,331 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:43:47,331 INFO:   Starting stage: TRAINING
2022-11-28 04:43:49,360 INFO:     Val loss before train {'Reaction outcome loss': 1.0172159935152807, 'Total loss': 1.0172159935152807}
2022-11-28 04:43:49,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:49,361 INFO:     Epoch: 0
2022-11-28 04:43:50,009 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6011794174826423, 'Total loss': 0.6011794174826423} | train loss {'Reaction outcome loss': 0.6861543313401645, 'Total loss': 0.6861543313401645}
2022-11-28 04:43:50,010 INFO:     Found new best model at epoch 0
2022-11-28 04:43:50,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:50,011 INFO:     Epoch: 1
2022-11-28 04:43:50,659 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5640898152839305, 'Total loss': 0.5640898152839305} | train loss {'Reaction outcome loss': 0.5794721966395613, 'Total loss': 0.5794721966395613}
2022-11-28 04:43:50,659 INFO:     Found new best model at epoch 1
2022-11-28 04:43:50,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:50,660 INFO:     Epoch: 2
2022-11-28 04:43:51,307 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5222658767949703, 'Total loss': 0.5222658767949703} | train loss {'Reaction outcome loss': 0.5495498201764021, 'Total loss': 0.5495498201764021}
2022-11-28 04:43:51,308 INFO:     Found new best model at epoch 2
2022-11-28 04:43:51,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:51,308 INFO:     Epoch: 3
2022-11-28 04:43:51,955 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5250390851220419, 'Total loss': 0.5250390851220419} | train loss {'Reaction outcome loss': 0.542656588871948, 'Total loss': 0.542656588871948}
2022-11-28 04:43:51,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:51,955 INFO:     Epoch: 4
2022-11-28 04:43:52,601 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5271298483360646, 'Total loss': 0.5271298483360646} | train loss {'Reaction outcome loss': 0.5221166578350497, 'Total loss': 0.5221166578350497}
2022-11-28 04:43:52,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:52,601 INFO:     Epoch: 5
2022-11-28 04:43:53,250 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5023071460945662, 'Total loss': 0.5023071460945662} | train loss {'Reaction outcome loss': 0.5151902408507026, 'Total loss': 0.5151902408507026}
2022-11-28 04:43:53,250 INFO:     Found new best model at epoch 5
2022-11-28 04:43:53,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:53,251 INFO:     Epoch: 6
2022-11-28 04:43:53,898 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4958960673836775, 'Total loss': 0.4958960673836775} | train loss {'Reaction outcome loss': 0.5020593677754285, 'Total loss': 0.5020593677754285}
2022-11-28 04:43:53,898 INFO:     Found new best model at epoch 6
2022-11-28 04:43:53,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:53,899 INFO:     Epoch: 7
2022-11-28 04:43:54,548 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5108721283979194, 'Total loss': 0.5108721283979194} | train loss {'Reaction outcome loss': 0.5017435653287856, 'Total loss': 0.5017435653287856}
2022-11-28 04:43:54,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:54,548 INFO:     Epoch: 8
2022-11-28 04:43:55,196 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49597804768140924, 'Total loss': 0.49597804768140924} | train loss {'Reaction outcome loss': 0.5021734881962909, 'Total loss': 0.5021734881962909}
2022-11-28 04:43:55,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:55,197 INFO:     Epoch: 9
2022-11-28 04:43:55,847 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5248626404723455, 'Total loss': 0.5248626404723455} | train loss {'Reaction outcome loss': 0.4912154629337983, 'Total loss': 0.4912154629337983}
2022-11-28 04:43:55,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:55,847 INFO:     Epoch: 10
2022-11-28 04:43:56,500 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48008685818938324, 'Total loss': 0.48008685818938324} | train loss {'Reaction outcome loss': 0.4913613272556027, 'Total loss': 0.4913613272556027}
2022-11-28 04:43:56,501 INFO:     Found new best model at epoch 10
2022-11-28 04:43:56,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:56,502 INFO:     Epoch: 11
2022-11-28 04:43:57,152 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4722733695146649, 'Total loss': 0.4722733695146649} | train loss {'Reaction outcome loss': 0.48412177754474467, 'Total loss': 0.48412177754474467}
2022-11-28 04:43:57,152 INFO:     Found new best model at epoch 11
2022-11-28 04:43:57,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:57,153 INFO:     Epoch: 12
2022-11-28 04:43:57,801 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5083538733942564, 'Total loss': 0.5083538733942564} | train loss {'Reaction outcome loss': 0.4879533087254548, 'Total loss': 0.4879533087254548}
2022-11-28 04:43:57,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:57,802 INFO:     Epoch: 13
2022-11-28 04:43:58,448 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5261110905991044, 'Total loss': 0.5261110905991044} | train loss {'Reaction outcome loss': 0.48796488454595943, 'Total loss': 0.48796488454595943}
2022-11-28 04:43:58,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:58,448 INFO:     Epoch: 14
2022-11-28 04:43:59,101 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5459834825853969, 'Total loss': 0.5459834825853969} | train loss {'Reaction outcome loss': 0.4786889090767649, 'Total loss': 0.4786889090767649}
2022-11-28 04:43:59,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:59,102 INFO:     Epoch: 15
2022-11-28 04:43:59,752 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48728524183118066, 'Total loss': 0.48728524183118066} | train loss {'Reaction outcome loss': 0.48425393301199693, 'Total loss': 0.48425393301199693}
2022-11-28 04:43:59,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:43:59,752 INFO:     Epoch: 16
2022-11-28 04:44:00,401 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5840904179007508, 'Total loss': 0.5840904179007508} | train loss {'Reaction outcome loss': 0.4815259221635881, 'Total loss': 0.4815259221635881}
2022-11-28 04:44:00,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:00,402 INFO:     Epoch: 17
2022-11-28 04:44:01,057 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5871074442253557, 'Total loss': 0.5871074442253557} | train loss {'Reaction outcome loss': 0.4760632210212653, 'Total loss': 0.4760632210212653}
2022-11-28 04:44:01,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:01,057 INFO:     Epoch: 18
2022-11-28 04:44:01,707 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48869642684626025, 'Total loss': 0.48869642684626025} | train loss {'Reaction outcome loss': 0.47947232174824495, 'Total loss': 0.47947232174824495}
2022-11-28 04:44:01,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:01,708 INFO:     Epoch: 19
2022-11-28 04:44:02,356 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5121645962083062, 'Total loss': 0.5121645962083062} | train loss {'Reaction outcome loss': 0.4704242450658415, 'Total loss': 0.4704242450658415}
2022-11-28 04:44:02,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:02,356 INFO:     Epoch: 20
2022-11-28 04:44:03,009 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49832065801980885, 'Total loss': 0.49832065801980885} | train loss {'Reaction outcome loss': 0.47495305318324293, 'Total loss': 0.47495305318324293}
2022-11-28 04:44:03,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:03,010 INFO:     Epoch: 21
2022-11-28 04:44:03,661 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49883372665837755, 'Total loss': 0.49883372665837755} | train loss {'Reaction outcome loss': 0.4714195301420376, 'Total loss': 0.4714195301420376}
2022-11-28 04:44:03,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:03,661 INFO:     Epoch: 22
2022-11-28 04:44:04,311 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.573849045260008, 'Total loss': 0.573849045260008} | train loss {'Reaction outcome loss': 0.47642932282608064, 'Total loss': 0.47642932282608064}
2022-11-28 04:44:04,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:04,312 INFO:     Epoch: 23
2022-11-28 04:44:04,961 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5242277813512225, 'Total loss': 0.5242277813512225} | train loss {'Reaction outcome loss': 0.476994802411951, 'Total loss': 0.476994802411951}
2022-11-28 04:44:04,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:04,961 INFO:     Epoch: 24
2022-11-28 04:44:05,610 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.49839567133160523, 'Total loss': 0.49839567133160523} | train loss {'Reaction outcome loss': 0.47446544285191866, 'Total loss': 0.47446544285191866}
2022-11-28 04:44:05,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:05,611 INFO:     Epoch: 25
2022-11-28 04:44:06,260 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4731308790140374, 'Total loss': 0.4731308790140374} | train loss {'Reaction outcome loss': 0.4696951360121125, 'Total loss': 0.4696951360121125}
2022-11-28 04:44:06,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:06,260 INFO:     Epoch: 26
2022-11-28 04:44:06,914 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4952683403741482, 'Total loss': 0.4952683403741482} | train loss {'Reaction outcome loss': 0.46526037431398376, 'Total loss': 0.46526037431398376}
2022-11-28 04:44:06,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:06,914 INFO:     Epoch: 27
2022-11-28 04:44:07,567 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5027268639830655, 'Total loss': 0.5027268639830655} | train loss {'Reaction outcome loss': 0.4715221054913079, 'Total loss': 0.4715221054913079}
2022-11-28 04:44:07,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:07,567 INFO:     Epoch: 28
2022-11-28 04:44:08,218 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4722405970096588, 'Total loss': 0.4722405970096588} | train loss {'Reaction outcome loss': 0.46393858708563396, 'Total loss': 0.46393858708563396}
2022-11-28 04:44:08,218 INFO:     Found new best model at epoch 28
2022-11-28 04:44:08,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:08,219 INFO:     Epoch: 29
2022-11-28 04:44:08,870 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4855585784413094, 'Total loss': 0.4855585784413094} | train loss {'Reaction outcome loss': 0.46867726059233555, 'Total loss': 0.46867726059233555}
2022-11-28 04:44:08,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:08,871 INFO:     Epoch: 30
2022-11-28 04:44:09,522 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4750599556191023, 'Total loss': 0.4750599556191023} | train loss {'Reaction outcome loss': 0.46976036334135496, 'Total loss': 0.46976036334135496}
2022-11-28 04:44:09,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:09,522 INFO:     Epoch: 31
2022-11-28 04:44:10,175 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4635397438393083, 'Total loss': 0.4635397438393083} | train loss {'Reaction outcome loss': 0.4697185034756778, 'Total loss': 0.4697185034756778}
2022-11-28 04:44:10,175 INFO:     Found new best model at epoch 31
2022-11-28 04:44:10,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:10,176 INFO:     Epoch: 32
2022-11-28 04:44:10,826 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48042618396670317, 'Total loss': 0.48042618396670317} | train loss {'Reaction outcome loss': 0.4724213932259161, 'Total loss': 0.4724213932259161}
2022-11-28 04:44:10,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:10,826 INFO:     Epoch: 33
2022-11-28 04:44:11,477 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4797523652398309, 'Total loss': 0.4797523652398309} | train loss {'Reaction outcome loss': 0.4670544351588507, 'Total loss': 0.4670544351588507}
2022-11-28 04:44:11,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:11,477 INFO:     Epoch: 34
2022-11-28 04:44:12,127 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5092943775099378, 'Total loss': 0.5092943775099378} | train loss {'Reaction outcome loss': 0.4713436979495111, 'Total loss': 0.4713436979495111}
2022-11-28 04:44:12,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:12,127 INFO:     Epoch: 35
2022-11-28 04:44:12,776 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49737967169562053, 'Total loss': 0.49737967169562053} | train loss {'Reaction outcome loss': 0.458888352497435, 'Total loss': 0.458888352497435}
2022-11-28 04:44:12,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:12,777 INFO:     Epoch: 36
2022-11-28 04:44:13,428 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46955298822979596, 'Total loss': 0.46955298822979596} | train loss {'Reaction outcome loss': 0.4743832584898003, 'Total loss': 0.4743832584898003}
2022-11-28 04:44:13,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:13,428 INFO:     Epoch: 37
2022-11-28 04:44:14,074 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4902558257413465, 'Total loss': 0.4902558257413465} | train loss {'Reaction outcome loss': 0.47112910046440654, 'Total loss': 0.47112910046440654}
2022-11-28 04:44:14,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:14,074 INFO:     Epoch: 38
2022-11-28 04:44:14,724 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49513154043707736, 'Total loss': 0.49513154043707736} | train loss {'Reaction outcome loss': 0.4631154063905849, 'Total loss': 0.4631154063905849}
2022-11-28 04:44:14,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:14,724 INFO:     Epoch: 39
2022-11-28 04:44:15,370 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4938622934873714, 'Total loss': 0.4938622934873714} | train loss {'Reaction outcome loss': 0.46067940535359697, 'Total loss': 0.46067940535359697}
2022-11-28 04:44:15,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:15,371 INFO:     Epoch: 40
2022-11-28 04:44:16,020 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45656842998293945, 'Total loss': 0.45656842998293945} | train loss {'Reaction outcome loss': 0.47150869582031596, 'Total loss': 0.47150869582031596}
2022-11-28 04:44:16,020 INFO:     Found new best model at epoch 40
2022-11-28 04:44:16,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:16,021 INFO:     Epoch: 41
2022-11-28 04:44:16,668 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46546041480330536, 'Total loss': 0.46546041480330536} | train loss {'Reaction outcome loss': 0.4671761588056068, 'Total loss': 0.4671761588056068}
2022-11-28 04:44:16,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:16,669 INFO:     Epoch: 42
2022-11-28 04:44:17,316 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47673047420590425, 'Total loss': 0.47673047420590425} | train loss {'Reaction outcome loss': 0.464265980864646, 'Total loss': 0.464265980864646}
2022-11-28 04:44:17,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:17,316 INFO:     Epoch: 43
2022-11-28 04:44:17,964 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4871751038834106, 'Total loss': 0.4871751038834106} | train loss {'Reaction outcome loss': 0.46215542106599106, 'Total loss': 0.46215542106599106}
2022-11-28 04:44:17,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:17,964 INFO:     Epoch: 44
2022-11-28 04:44:18,614 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49193532938180967, 'Total loss': 0.49193532938180967} | train loss {'Reaction outcome loss': 0.46801081519634996, 'Total loss': 0.46801081519634996}
2022-11-28 04:44:18,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:18,615 INFO:     Epoch: 45
2022-11-28 04:44:19,262 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5045894432899564, 'Total loss': 0.5045894432899564} | train loss {'Reaction outcome loss': 0.46479388567634294, 'Total loss': 0.46479388567634294}
2022-11-28 04:44:19,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:19,263 INFO:     Epoch: 46
2022-11-28 04:44:19,910 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4663221479155297, 'Total loss': 0.4663221479155297} | train loss {'Reaction outcome loss': 0.4615164786332943, 'Total loss': 0.4615164786332943}
2022-11-28 04:44:19,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:19,910 INFO:     Epoch: 47
2022-11-28 04:44:20,561 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4697000183338343, 'Total loss': 0.4697000183338343} | train loss {'Reaction outcome loss': 0.46658416116823914, 'Total loss': 0.46658416116823914}
2022-11-28 04:44:20,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:20,561 INFO:     Epoch: 48
2022-11-28 04:44:21,210 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46183922159117324, 'Total loss': 0.46183922159117324} | train loss {'Reaction outcome loss': 0.46395648710551807, 'Total loss': 0.46395648710551807}
2022-11-28 04:44:21,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:21,212 INFO:     Epoch: 49
2022-11-28 04:44:21,865 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5954237684260967, 'Total loss': 0.5954237684260967} | train loss {'Reaction outcome loss': 0.4636503039691292, 'Total loss': 0.4636503039691292}
2022-11-28 04:44:21,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:21,865 INFO:     Epoch: 50
2022-11-28 04:44:22,515 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46503095952577367, 'Total loss': 0.46503095952577367} | train loss {'Reaction outcome loss': 0.46093030530409734, 'Total loss': 0.46093030530409734}
2022-11-28 04:44:22,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:22,516 INFO:     Epoch: 51
2022-11-28 04:44:23,166 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4834670195745867, 'Total loss': 0.4834670195745867} | train loss {'Reaction outcome loss': 0.4609179573713756, 'Total loss': 0.4609179573713756}
2022-11-28 04:44:23,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:23,167 INFO:     Epoch: 52
2022-11-28 04:44:23,816 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4652899403211682, 'Total loss': 0.4652899403211682} | train loss {'Reaction outcome loss': 0.4624361235220901, 'Total loss': 0.4624361235220901}
2022-11-28 04:44:23,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:23,816 INFO:     Epoch: 53
2022-11-28 04:44:24,467 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4747222537218138, 'Total loss': 0.4747222537218138} | train loss {'Reaction outcome loss': 0.472301926952405, 'Total loss': 0.472301926952405}
2022-11-28 04:44:24,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:24,467 INFO:     Epoch: 54
2022-11-28 04:44:25,114 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4662721139747043, 'Total loss': 0.4662721139747043} | train loss {'Reaction outcome loss': 0.4759606792301428, 'Total loss': 0.4759606792301428}
2022-11-28 04:44:25,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:25,115 INFO:     Epoch: 55
2022-11-28 04:44:25,766 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4510223210551018, 'Total loss': 0.4510223210551018} | train loss {'Reaction outcome loss': 0.4601973740414518, 'Total loss': 0.4601973740414518}
2022-11-28 04:44:25,766 INFO:     Found new best model at epoch 55
2022-11-28 04:44:25,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:25,767 INFO:     Epoch: 56
2022-11-28 04:44:26,418 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48416184270104695, 'Total loss': 0.48416184270104695} | train loss {'Reaction outcome loss': 0.45519710344369296, 'Total loss': 0.45519710344369296}
2022-11-28 04:44:26,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:26,418 INFO:     Epoch: 57
2022-11-28 04:44:27,065 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5464393274728642, 'Total loss': 0.5464393274728642} | train loss {'Reaction outcome loss': 0.4681077561051142, 'Total loss': 0.4681077561051142}
2022-11-28 04:44:27,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:27,065 INFO:     Epoch: 58
2022-11-28 04:44:27,714 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4902501937954925, 'Total loss': 0.4902501937954925} | train loss {'Reaction outcome loss': 0.4715499474254788, 'Total loss': 0.4715499474254788}
2022-11-28 04:44:27,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:27,715 INFO:     Epoch: 59
2022-11-28 04:44:28,365 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46568804078323894, 'Total loss': 0.46568804078323894} | train loss {'Reaction outcome loss': 0.4639296779622797, 'Total loss': 0.4639296779622797}
2022-11-28 04:44:28,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:28,365 INFO:     Epoch: 60
2022-11-28 04:44:29,016 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49592967677948085, 'Total loss': 0.49592967677948085} | train loss {'Reaction outcome loss': 0.47358678757655814, 'Total loss': 0.47358678757655814}
2022-11-28 04:44:29,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:29,016 INFO:     Epoch: 61
2022-11-28 04:44:29,664 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5081955918739008, 'Total loss': 0.5081955918739008} | train loss {'Reaction outcome loss': 0.46280017440192034, 'Total loss': 0.46280017440192034}
2022-11-28 04:44:29,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:29,665 INFO:     Epoch: 62
2022-11-28 04:44:30,311 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4823802616014037, 'Total loss': 0.4823802616014037} | train loss {'Reaction outcome loss': 0.45834262669086456, 'Total loss': 0.45834262669086456}
2022-11-28 04:44:30,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:30,311 INFO:     Epoch: 63
2022-11-28 04:44:30,960 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4709933219954025, 'Total loss': 0.4709933219954025} | train loss {'Reaction outcome loss': 0.4707070942052075, 'Total loss': 0.4707070942052075}
2022-11-28 04:44:30,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:30,961 INFO:     Epoch: 64
2022-11-28 04:44:31,608 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5034956214732902, 'Total loss': 0.5034956214732902} | train loss {'Reaction outcome loss': 0.4665021454518447, 'Total loss': 0.4665021454518447}
2022-11-28 04:44:31,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:31,609 INFO:     Epoch: 65
2022-11-28 04:44:32,259 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4624742841304735, 'Total loss': 0.4624742841304735} | train loss {'Reaction outcome loss': 0.4666209855406988, 'Total loss': 0.4666209855406988}
2022-11-28 04:44:32,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:32,259 INFO:     Epoch: 66
2022-11-28 04:44:32,907 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4697953164577484, 'Total loss': 0.4697953164577484} | train loss {'Reaction outcome loss': 0.4628997693662761, 'Total loss': 0.4628997693662761}
2022-11-28 04:44:32,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:32,907 INFO:     Epoch: 67
2022-11-28 04:44:33,552 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4475856010997018, 'Total loss': 0.4475856010997018} | train loss {'Reaction outcome loss': 0.468564081265301, 'Total loss': 0.468564081265301}
2022-11-28 04:44:33,552 INFO:     Found new best model at epoch 67
2022-11-28 04:44:33,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:33,553 INFO:     Epoch: 68
2022-11-28 04:44:34,200 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48375867515109305, 'Total loss': 0.48375867515109305} | train loss {'Reaction outcome loss': 0.4706550415177814, 'Total loss': 0.4706550415177814}
2022-11-28 04:44:34,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:34,200 INFO:     Epoch: 69
2022-11-28 04:44:34,844 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4898215411014335, 'Total loss': 0.4898215411014335} | train loss {'Reaction outcome loss': 0.4670545042293971, 'Total loss': 0.4670545042293971}
2022-11-28 04:44:34,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:34,844 INFO:     Epoch: 70
2022-11-28 04:44:35,490 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46698840343674947, 'Total loss': 0.46698840343674947} | train loss {'Reaction outcome loss': 0.4650362083291421, 'Total loss': 0.4650362083291421}
2022-11-28 04:44:35,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:35,490 INFO:     Epoch: 71
2022-11-28 04:44:36,139 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.483388384067735, 'Total loss': 0.483388384067735} | train loss {'Reaction outcome loss': 0.4589955848870707, 'Total loss': 0.4589955848870707}
2022-11-28 04:44:36,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:36,139 INFO:     Epoch: 72
2022-11-28 04:44:36,787 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48491945793462354, 'Total loss': 0.48491945793462354} | train loss {'Reaction outcome loss': 0.4636760577559471, 'Total loss': 0.4636760577559471}
2022-11-28 04:44:36,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:36,787 INFO:     Epoch: 73
2022-11-28 04:44:37,436 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46900532065435896, 'Total loss': 0.46900532065435896} | train loss {'Reaction outcome loss': 0.4617781982314391, 'Total loss': 0.4617781982314391}
2022-11-28 04:44:37,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:37,437 INFO:     Epoch: 74
2022-11-28 04:44:38,083 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47177953047807825, 'Total loss': 0.47177953047807825} | train loss {'Reaction outcome loss': 0.46978420342822547, 'Total loss': 0.46978420342822547}
2022-11-28 04:44:38,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:38,083 INFO:     Epoch: 75
2022-11-28 04:44:38,733 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49082602699135625, 'Total loss': 0.49082602699135625} | train loss {'Reaction outcome loss': 0.46586385766258004, 'Total loss': 0.46586385766258004}
2022-11-28 04:44:38,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:38,733 INFO:     Epoch: 76
2022-11-28 04:44:39,383 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4636597404646319, 'Total loss': 0.4636597404646319} | train loss {'Reaction outcome loss': 0.46851597017929203, 'Total loss': 0.46851597017929203}
2022-11-28 04:44:39,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:39,383 INFO:     Epoch: 77
2022-11-28 04:44:40,033 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45691281834314035, 'Total loss': 0.45691281834314035} | train loss {'Reaction outcome loss': 0.46344229291941297, 'Total loss': 0.46344229291941297}
2022-11-28 04:44:40,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:40,034 INFO:     Epoch: 78
2022-11-28 04:44:40,683 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47783719730931656, 'Total loss': 0.47783719730931656} | train loss {'Reaction outcome loss': 0.4702002662004995, 'Total loss': 0.4702002662004995}
2022-11-28 04:44:40,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:40,683 INFO:     Epoch: 79
2022-11-28 04:44:41,328 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4862500768761302, 'Total loss': 0.4862500768761302} | train loss {'Reaction outcome loss': 0.4616809702921109, 'Total loss': 0.4616809702921109}
2022-11-28 04:44:41,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:41,328 INFO:     Epoch: 80
2022-11-28 04:44:41,976 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4629243421693181, 'Total loss': 0.4629243421693181} | train loss {'Reaction outcome loss': 0.47353969422764464, 'Total loss': 0.47353969422764464}
2022-11-28 04:44:41,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:41,976 INFO:     Epoch: 81
2022-11-28 04:44:42,624 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47433695405028586, 'Total loss': 0.47433695405028586} | train loss {'Reaction outcome loss': 0.4644903086858695, 'Total loss': 0.4644903086858695}
2022-11-28 04:44:42,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:42,624 INFO:     Epoch: 82
2022-11-28 04:44:43,270 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4643763050783512, 'Total loss': 0.4643763050783512} | train loss {'Reaction outcome loss': 0.470556772573561, 'Total loss': 0.470556772573561}
2022-11-28 04:44:43,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:43,270 INFO:     Epoch: 83
2022-11-28 04:44:43,916 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4619125872850418, 'Total loss': 0.4619125872850418} | train loss {'Reaction outcome loss': 0.46908395199990666, 'Total loss': 0.46908395199990666}
2022-11-28 04:44:43,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:43,916 INFO:     Epoch: 84
2022-11-28 04:44:44,562 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4797811473524848, 'Total loss': 0.4797811473524848} | train loss {'Reaction outcome loss': 0.465335308100845, 'Total loss': 0.465335308100845}
2022-11-28 04:44:44,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:44,562 INFO:     Epoch: 85
2022-11-28 04:44:45,214 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4563053790913072, 'Total loss': 0.4563053790913072} | train loss {'Reaction outcome loss': 0.46877103793572206, 'Total loss': 0.46877103793572206}
2022-11-28 04:44:45,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:45,214 INFO:     Epoch: 86
2022-11-28 04:44:45,865 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4968636583450229, 'Total loss': 0.4968636583450229} | train loss {'Reaction outcome loss': 0.467957590721914, 'Total loss': 0.467957590721914}
2022-11-28 04:44:45,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:45,865 INFO:     Epoch: 87
2022-11-28 04:44:46,518 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47769806204840193, 'Total loss': 0.47769806204840193} | train loss {'Reaction outcome loss': 0.46527687747214663, 'Total loss': 0.46527687747214663}
2022-11-28 04:44:46,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:46,518 INFO:     Epoch: 88
2022-11-28 04:44:47,171 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48147388183793355, 'Total loss': 0.48147388183793355} | train loss {'Reaction outcome loss': 0.4628935042829787, 'Total loss': 0.4628935042829787}
2022-11-28 04:44:47,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:47,172 INFO:     Epoch: 89
2022-11-28 04:44:47,824 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5088340328183285, 'Total loss': 0.5088340328183285} | train loss {'Reaction outcome loss': 0.4691204034769144, 'Total loss': 0.4691204034769144}
2022-11-28 04:44:47,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:47,824 INFO:     Epoch: 90
2022-11-28 04:44:48,476 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4629686949558036, 'Total loss': 0.4629686949558036} | train loss {'Reaction outcome loss': 0.4673985968359181, 'Total loss': 0.4673985968359181}
2022-11-28 04:44:48,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:48,476 INFO:     Epoch: 91
2022-11-28 04:44:49,128 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4838093789510949, 'Total loss': 0.4838093789510949} | train loss {'Reaction outcome loss': 0.4717060659752517, 'Total loss': 0.4717060659752517}
2022-11-28 04:44:49,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:49,128 INFO:     Epoch: 92
2022-11-28 04:44:49,782 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48668024810247645, 'Total loss': 0.48668024810247645} | train loss {'Reaction outcome loss': 0.472179717704898, 'Total loss': 0.472179717704898}
2022-11-28 04:44:49,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:49,782 INFO:     Epoch: 93
2022-11-28 04:44:50,436 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4690601319767708, 'Total loss': 0.4690601319767708} | train loss {'Reaction outcome loss': 0.4639378318288287, 'Total loss': 0.4639378318288287}
2022-11-28 04:44:50,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:50,436 INFO:     Epoch: 94
2022-11-28 04:44:51,089 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4602909978739051, 'Total loss': 0.4602909978739051} | train loss {'Reaction outcome loss': 0.4717708079785597, 'Total loss': 0.4717708079785597}
2022-11-28 04:44:51,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:51,089 INFO:     Epoch: 95
2022-11-28 04:44:51,741 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45408583311147466, 'Total loss': 0.45408583311147466} | train loss {'Reaction outcome loss': 0.4769538025386998, 'Total loss': 0.4769538025386998}
2022-11-28 04:44:51,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:51,741 INFO:     Epoch: 96
2022-11-28 04:44:52,395 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47564282250958817, 'Total loss': 0.47564282250958817} | train loss {'Reaction outcome loss': 0.4746353141352779, 'Total loss': 0.4746353141352779}
2022-11-28 04:44:52,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:52,396 INFO:     Epoch: 97
2022-11-28 04:44:53,054 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48336863587068957, 'Total loss': 0.48336863587068957} | train loss {'Reaction outcome loss': 0.4693464310076393, 'Total loss': 0.4693464310076393}
2022-11-28 04:44:53,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:53,054 INFO:     Epoch: 98
2022-11-28 04:44:53,707 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48459038554235945, 'Total loss': 0.48459038554235945} | train loss {'Reaction outcome loss': 0.4700982633550636, 'Total loss': 0.4700982633550636}
2022-11-28 04:44:53,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:53,708 INFO:     Epoch: 99
2022-11-28 04:44:54,358 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4668488752010257, 'Total loss': 0.4668488752010257} | train loss {'Reaction outcome loss': 0.4699971113415038, 'Total loss': 0.4699971113415038}
2022-11-28 04:44:54,359 INFO:     Best model found after epoch 68 of 100.
2022-11-28 04:44:54,359 INFO:   Done with stage: TRAINING
2022-11-28 04:44:54,359 INFO:   Starting stage: EVALUATION
2022-11-28 04:44:54,488 INFO:   Done with stage: EVALUATION
2022-11-28 04:44:54,488 INFO:   Leaving out SEQ value Fold_1
2022-11-28 04:44:54,501 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:44:54,501 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:44:55,306 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:44:55,307 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:44:55,376 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:44:55,377 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:44:55,377 INFO:     No hyperparam tuning for this model
2022-11-28 04:44:55,377 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:44:55,377 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:44:55,377 INFO:     None feature selector for col prot
2022-11-28 04:44:55,378 INFO:     None feature selector for col prot
2022-11-28 04:44:55,378 INFO:     None feature selector for col prot
2022-11-28 04:44:55,378 INFO:     None feature selector for col chem
2022-11-28 04:44:55,378 INFO:     None feature selector for col chem
2022-11-28 04:44:55,378 INFO:     None feature selector for col chem
2022-11-28 04:44:55,378 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:44:55,378 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:44:55,380 INFO:     Number of params in model 169651
2022-11-28 04:44:55,383 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:44:55,383 INFO:   Starting stage: TRAINING
2022-11-28 04:44:55,433 INFO:     Val loss before train {'Reaction outcome loss': 1.0471300360831348, 'Total loss': 1.0471300360831348}
2022-11-28 04:44:55,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:55,433 INFO:     Epoch: 0
2022-11-28 04:44:56,094 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5959987579421564, 'Total loss': 0.5959987579421564} | train loss {'Reaction outcome loss': 0.7032133281713555, 'Total loss': 0.7032133281713555}
2022-11-28 04:44:56,094 INFO:     Found new best model at epoch 0
2022-11-28 04:44:56,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:56,095 INFO:     Epoch: 1
2022-11-28 04:44:56,755 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5435846647755667, 'Total loss': 0.5435846647755667} | train loss {'Reaction outcome loss': 0.603627971490385, 'Total loss': 0.603627971490385}
2022-11-28 04:44:56,755 INFO:     Found new best model at epoch 1
2022-11-28 04:44:56,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:56,756 INFO:     Epoch: 2
2022-11-28 04:44:57,418 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5465693243525245, 'Total loss': 0.5465693243525245} | train loss {'Reaction outcome loss': 0.5627631520049322, 'Total loss': 0.5627631520049322}
2022-11-28 04:44:57,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:57,418 INFO:     Epoch: 3
2022-11-28 04:44:58,080 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5349172604354945, 'Total loss': 0.5349172604354945} | train loss {'Reaction outcome loss': 0.5407204357869471, 'Total loss': 0.5407204357869471}
2022-11-28 04:44:58,080 INFO:     Found new best model at epoch 3
2022-11-28 04:44:58,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:58,081 INFO:     Epoch: 4
2022-11-28 04:44:58,742 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5195259018377825, 'Total loss': 0.5195259018377825} | train loss {'Reaction outcome loss': 0.5181733697109859, 'Total loss': 0.5181733697109859}
2022-11-28 04:44:58,743 INFO:     Found new best model at epoch 4
2022-11-28 04:44:58,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:58,744 INFO:     Epoch: 5
2022-11-28 04:44:59,402 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.526226019994779, 'Total loss': 0.526226019994779} | train loss {'Reaction outcome loss': 0.5122509936572086, 'Total loss': 0.5122509936572086}
2022-11-28 04:44:59,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:44:59,402 INFO:     Epoch: 6
2022-11-28 04:45:00,063 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5372766236012633, 'Total loss': 0.5372766236012633} | train loss {'Reaction outcome loss': 0.5227141954638215, 'Total loss': 0.5227141954638215}
2022-11-28 04:45:00,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:00,064 INFO:     Epoch: 7
2022-11-28 04:45:00,727 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5295008210973307, 'Total loss': 0.5295008210973307} | train loss {'Reaction outcome loss': 0.5165875223597233, 'Total loss': 0.5165875223597233}
2022-11-28 04:45:00,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:00,727 INFO:     Epoch: 8
2022-11-28 04:45:01,391 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5059280216016553, 'Total loss': 0.5059280216016553} | train loss {'Reaction outcome loss': 0.4875760006940799, 'Total loss': 0.4875760006940799}
2022-11-28 04:45:01,391 INFO:     Found new best model at epoch 8
2022-11-28 04:45:01,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:01,391 INFO:     Epoch: 9
2022-11-28 04:45:02,052 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49680183218284085, 'Total loss': 0.49680183218284085} | train loss {'Reaction outcome loss': 0.49193556950642514, 'Total loss': 0.49193556950642514}
2022-11-28 04:45:02,052 INFO:     Found new best model at epoch 9
2022-11-28 04:45:02,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:02,053 INFO:     Epoch: 10
2022-11-28 04:45:02,717 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5343324772336266, 'Total loss': 0.5343324772336266} | train loss {'Reaction outcome loss': 0.4833037930310738, 'Total loss': 0.4833037930310738}
2022-11-28 04:45:02,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:02,717 INFO:     Epoch: 11
2022-11-28 04:45:03,377 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49206722832538863, 'Total loss': 0.49206722832538863} | train loss {'Reaction outcome loss': 0.4872256361762522, 'Total loss': 0.4872256361762522}
2022-11-28 04:45:03,377 INFO:     Found new best model at epoch 11
2022-11-28 04:45:03,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:03,378 INFO:     Epoch: 12
2022-11-28 04:45:04,040 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4732286621901122, 'Total loss': 0.4732286621901122} | train loss {'Reaction outcome loss': 0.4979683167719648, 'Total loss': 0.4979683167719648}
2022-11-28 04:45:04,040 INFO:     Found new best model at epoch 12
2022-11-28 04:45:04,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:04,041 INFO:     Epoch: 13
2022-11-28 04:45:04,703 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48124272494830866, 'Total loss': 0.48124272494830866} | train loss {'Reaction outcome loss': 0.48385971838887404, 'Total loss': 0.48385971838887404}
2022-11-28 04:45:04,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:04,704 INFO:     Epoch: 14
2022-11-28 04:45:05,364 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4848929393020543, 'Total loss': 0.4848929393020543} | train loss {'Reaction outcome loss': 0.48552760898101666, 'Total loss': 0.48552760898101666}
2022-11-28 04:45:05,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:05,364 INFO:     Epoch: 15
2022-11-28 04:45:06,030 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5275913907045667, 'Total loss': 0.5275913907045667} | train loss {'Reaction outcome loss': 0.48669785602010696, 'Total loss': 0.48669785602010696}
2022-11-28 04:45:06,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:06,030 INFO:     Epoch: 16
2022-11-28 04:45:06,690 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4644173292273825, 'Total loss': 0.4644173292273825} | train loss {'Reaction outcome loss': 0.48807949063025025, 'Total loss': 0.48807949063025025}
2022-11-28 04:45:06,690 INFO:     Found new best model at epoch 16
2022-11-28 04:45:06,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:06,691 INFO:     Epoch: 17
2022-11-28 04:45:07,355 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47444419732147997, 'Total loss': 0.47444419732147997} | train loss {'Reaction outcome loss': 0.484668565212715, 'Total loss': 0.484668565212715}
2022-11-28 04:45:07,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:07,355 INFO:     Epoch: 18
2022-11-28 04:45:08,019 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4667871756987138, 'Total loss': 0.4667871756987138} | train loss {'Reaction outcome loss': 0.4767440060372295, 'Total loss': 0.4767440060372295}
2022-11-28 04:45:08,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:08,019 INFO:     Epoch: 19
2022-11-28 04:45:08,682 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45746269754388114, 'Total loss': 0.45746269754388114} | train loss {'Reaction outcome loss': 0.4821470765329083, 'Total loss': 0.4821470765329083}
2022-11-28 04:45:08,682 INFO:     Found new best model at epoch 19
2022-11-28 04:45:08,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:08,683 INFO:     Epoch: 20
2022-11-28 04:45:09,342 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4825462411073121, 'Total loss': 0.4825462411073121} | train loss {'Reaction outcome loss': 0.47252230424630015, 'Total loss': 0.47252230424630015}
2022-11-28 04:45:09,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:09,342 INFO:     Epoch: 21
2022-11-28 04:45:10,005 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4551924257115884, 'Total loss': 0.4551924257115884} | train loss {'Reaction outcome loss': 0.4711936702103418, 'Total loss': 0.4711936702103418}
2022-11-28 04:45:10,005 INFO:     Found new best model at epoch 21
2022-11-28 04:45:10,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:10,006 INFO:     Epoch: 22
2022-11-28 04:45:10,667 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5037709521976385, 'Total loss': 0.5037709521976385} | train loss {'Reaction outcome loss': 0.4655241850265848, 'Total loss': 0.4655241850265848}
2022-11-28 04:45:10,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:10,667 INFO:     Epoch: 23
2022-11-28 04:45:11,327 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5281106172637506, 'Total loss': 0.5281106172637506} | train loss {'Reaction outcome loss': 0.47570393913187964, 'Total loss': 0.47570393913187964}
2022-11-28 04:45:11,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:11,328 INFO:     Epoch: 24
2022-11-28 04:45:11,991 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45259559933434834, 'Total loss': 0.45259559933434834} | train loss {'Reaction outcome loss': 0.47826446563397584, 'Total loss': 0.47826446563397584}
2022-11-28 04:45:11,991 INFO:     Found new best model at epoch 24
2022-11-28 04:45:11,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:11,992 INFO:     Epoch: 25
2022-11-28 04:45:12,654 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4650394090197303, 'Total loss': 0.4650394090197303} | train loss {'Reaction outcome loss': 0.4844339309554351, 'Total loss': 0.4844339309554351}
2022-11-28 04:45:12,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:12,655 INFO:     Epoch: 26
2022-11-28 04:45:13,317 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4753881330517205, 'Total loss': 0.4753881330517205} | train loss {'Reaction outcome loss': 0.47251681835665876, 'Total loss': 0.47251681835665876}
2022-11-28 04:45:13,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:13,317 INFO:     Epoch: 27
2022-11-28 04:45:13,983 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.483540553599596, 'Total loss': 0.483540553599596} | train loss {'Reaction outcome loss': 0.4709949668361108, 'Total loss': 0.4709949668361108}
2022-11-28 04:45:13,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:13,984 INFO:     Epoch: 28
2022-11-28 04:45:14,645 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4670129306614399, 'Total loss': 0.4670129306614399} | train loss {'Reaction outcome loss': 0.4702049800258899, 'Total loss': 0.4702049800258899}
2022-11-28 04:45:14,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:14,645 INFO:     Epoch: 29
2022-11-28 04:45:15,306 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47741383043202484, 'Total loss': 0.47741383043202484} | train loss {'Reaction outcome loss': 0.47209784797268356, 'Total loss': 0.47209784797268356}
2022-11-28 04:45:15,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:15,307 INFO:     Epoch: 30
2022-11-28 04:45:15,969 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.477210709317164, 'Total loss': 0.477210709317164} | train loss {'Reaction outcome loss': 0.47669799885286496, 'Total loss': 0.47669799885286496}
2022-11-28 04:45:15,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:15,969 INFO:     Epoch: 31
2022-11-28 04:45:16,632 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4695091481235894, 'Total loss': 0.4695091481235894} | train loss {'Reaction outcome loss': 0.470794716729266, 'Total loss': 0.470794716729266}
2022-11-28 04:45:16,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:16,633 INFO:     Epoch: 32
2022-11-28 04:45:17,296 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49550152163613925, 'Total loss': 0.49550152163613925} | train loss {'Reaction outcome loss': 0.45856091666680115, 'Total loss': 0.45856091666680115}
2022-11-28 04:45:17,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:17,297 INFO:     Epoch: 33
2022-11-28 04:45:17,962 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4894308644262227, 'Total loss': 0.4894308644262227} | train loss {'Reaction outcome loss': 0.47260387778764795, 'Total loss': 0.47260387778764795}
2022-11-28 04:45:17,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:17,963 INFO:     Epoch: 34
2022-11-28 04:45:18,627 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4790566556833007, 'Total loss': 0.4790566556833007} | train loss {'Reaction outcome loss': 0.4768902979157714, 'Total loss': 0.4768902979157714}
2022-11-28 04:45:18,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:18,628 INFO:     Epoch: 35
2022-11-28 04:45:19,293 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4484510926360434, 'Total loss': 0.4484510926360434} | train loss {'Reaction outcome loss': 0.4842870456849033, 'Total loss': 0.4842870456849033}
2022-11-28 04:45:19,293 INFO:     Found new best model at epoch 35
2022-11-28 04:45:19,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:19,294 INFO:     Epoch: 36
2022-11-28 04:45:19,959 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4898060702464797, 'Total loss': 0.4898060702464797} | train loss {'Reaction outcome loss': 0.4592644579799069, 'Total loss': 0.4592644579799069}
2022-11-28 04:45:19,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:19,959 INFO:     Epoch: 37
2022-11-28 04:45:20,621 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45096312124620785, 'Total loss': 0.45096312124620785} | train loss {'Reaction outcome loss': 0.46912203203162806, 'Total loss': 0.46912203203162806}
2022-11-28 04:45:20,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:20,621 INFO:     Epoch: 38
2022-11-28 04:45:21,282 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4625983211127194, 'Total loss': 0.4625983211127194} | train loss {'Reaction outcome loss': 0.47968110125436475, 'Total loss': 0.47968110125436475}
2022-11-28 04:45:21,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:21,283 INFO:     Epoch: 39
2022-11-28 04:45:21,947 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5022186237302694, 'Total loss': 0.5022186237302694} | train loss {'Reaction outcome loss': 0.4786939536511657, 'Total loss': 0.4786939536511657}
2022-11-28 04:45:21,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:21,947 INFO:     Epoch: 40
2022-11-28 04:45:22,609 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4831746569411321, 'Total loss': 0.4831746569411321} | train loss {'Reaction outcome loss': 0.4751375952230291, 'Total loss': 0.4751375952230291}
2022-11-28 04:45:22,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:22,609 INFO:     Epoch: 41
2022-11-28 04:45:23,271 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47494422644376755, 'Total loss': 0.47494422644376755} | train loss {'Reaction outcome loss': 0.46696969443886926, 'Total loss': 0.46696969443886926}
2022-11-28 04:45:23,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:23,272 INFO:     Epoch: 42
2022-11-28 04:45:23,935 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4488962384110147, 'Total loss': 0.4488962384110147} | train loss {'Reaction outcome loss': 0.4680492270639853, 'Total loss': 0.4680492270639853}
2022-11-28 04:45:23,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:23,935 INFO:     Epoch: 43
2022-11-28 04:45:24,596 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45377032391049643, 'Total loss': 0.45377032391049643} | train loss {'Reaction outcome loss': 0.47052054867329385, 'Total loss': 0.47052054867329385}
2022-11-28 04:45:24,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:24,596 INFO:     Epoch: 44
2022-11-28 04:45:25,261 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4678539755669507, 'Total loss': 0.4678539755669507} | train loss {'Reaction outcome loss': 0.47179819154835906, 'Total loss': 0.47179819154835906}
2022-11-28 04:45:25,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:25,261 INFO:     Epoch: 45
2022-11-28 04:45:25,922 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4610065377571366, 'Total loss': 0.4610065377571366} | train loss {'Reaction outcome loss': 0.47379570079661965, 'Total loss': 0.47379570079661965}
2022-11-28 04:45:25,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:25,922 INFO:     Epoch: 46
2022-11-28 04:45:26,588 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48426302894949913, 'Total loss': 0.48426302894949913} | train loss {'Reaction outcome loss': 0.46761734751976936, 'Total loss': 0.46761734751976936}
2022-11-28 04:45:26,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:26,589 INFO:     Epoch: 47
2022-11-28 04:45:27,255 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.460015361959284, 'Total loss': 0.460015361959284} | train loss {'Reaction outcome loss': 0.47286377243908795, 'Total loss': 0.47286377243908795}
2022-11-28 04:45:27,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:27,255 INFO:     Epoch: 48
2022-11-28 04:45:27,918 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48952746188098734, 'Total loss': 0.48952746188098734} | train loss {'Reaction outcome loss': 0.48895652511869725, 'Total loss': 0.48895652511869725}
2022-11-28 04:45:27,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:27,918 INFO:     Epoch: 49
2022-11-28 04:45:28,583 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45682438192042435, 'Total loss': 0.45682438192042435} | train loss {'Reaction outcome loss': 0.4754117172256655, 'Total loss': 0.4754117172256655}
2022-11-28 04:45:28,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:28,583 INFO:     Epoch: 50
2022-11-28 04:45:29,246 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4728870242834091, 'Total loss': 0.4728870242834091} | train loss {'Reaction outcome loss': 0.4781634466503916, 'Total loss': 0.4781634466503916}
2022-11-28 04:45:29,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:29,246 INFO:     Epoch: 51
2022-11-28 04:45:29,910 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44731361080299725, 'Total loss': 0.44731361080299725} | train loss {'Reaction outcome loss': 0.4670241453650932, 'Total loss': 0.4670241453650932}
2022-11-28 04:45:29,911 INFO:     Found new best model at epoch 51
2022-11-28 04:45:29,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:29,912 INFO:     Epoch: 52
2022-11-28 04:45:30,574 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4991178834302859, 'Total loss': 0.4991178834302859} | train loss {'Reaction outcome loss': 0.47025504970719456, 'Total loss': 0.47025504970719456}
2022-11-28 04:45:30,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:30,575 INFO:     Epoch: 53
2022-11-28 04:45:31,243 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46309343657710333, 'Total loss': 0.46309343657710333} | train loss {'Reaction outcome loss': 0.47383088537073326, 'Total loss': 0.47383088537073326}
2022-11-28 04:45:31,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:31,243 INFO:     Epoch: 54
2022-11-28 04:45:31,909 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4739483574574644, 'Total loss': 0.4739483574574644} | train loss {'Reaction outcome loss': 0.4780066472436735, 'Total loss': 0.4780066472436735}
2022-11-28 04:45:31,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:31,909 INFO:     Epoch: 55
2022-11-28 04:45:32,571 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5565006841312755, 'Total loss': 0.5565006841312755} | train loss {'Reaction outcome loss': 0.48392232887537373, 'Total loss': 0.48392232887537373}
2022-11-28 04:45:32,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:32,571 INFO:     Epoch: 56
2022-11-28 04:45:33,236 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48731127313592215, 'Total loss': 0.48731127313592215} | train loss {'Reaction outcome loss': 0.4851952947465032, 'Total loss': 0.4851952947465032}
2022-11-28 04:45:33,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:33,236 INFO:     Epoch: 57
2022-11-28 04:45:33,898 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44382573528723285, 'Total loss': 0.44382573528723285} | train loss {'Reaction outcome loss': 0.46965673053071566, 'Total loss': 0.46965673053071566}
2022-11-28 04:45:33,898 INFO:     Found new best model at epoch 57
2022-11-28 04:45:33,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:33,899 INFO:     Epoch: 58
2022-11-28 04:45:34,561 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44626250727610156, 'Total loss': 0.44626250727610156} | train loss {'Reaction outcome loss': 0.46664534196368823, 'Total loss': 0.46664534196368823}
2022-11-28 04:45:34,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:34,562 INFO:     Epoch: 59
2022-11-28 04:45:35,224 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.507570858028802, 'Total loss': 0.507570858028802} | train loss {'Reaction outcome loss': 0.4658070646739199, 'Total loss': 0.4658070646739199}
2022-11-28 04:45:35,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:35,224 INFO:     Epoch: 60
2022-11-28 04:45:35,887 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4408271990039132, 'Total loss': 0.4408271990039132} | train loss {'Reaction outcome loss': 0.47367742772285754, 'Total loss': 0.47367742772285754}
2022-11-28 04:45:35,887 INFO:     Found new best model at epoch 60
2022-11-28 04:45:35,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:35,888 INFO:     Epoch: 61
2022-11-28 04:45:36,554 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47725116461515427, 'Total loss': 0.47725116461515427} | train loss {'Reaction outcome loss': 0.4672042084895527, 'Total loss': 0.4672042084895527}
2022-11-28 04:45:36,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:36,554 INFO:     Epoch: 62
2022-11-28 04:45:37,214 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4426976445723664, 'Total loss': 0.4426976445723664} | train loss {'Reaction outcome loss': 0.4754969465587786, 'Total loss': 0.4754969465587786}
2022-11-28 04:45:37,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:37,214 INFO:     Epoch: 63
2022-11-28 04:45:37,878 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4677694036879323, 'Total loss': 0.4677694036879323} | train loss {'Reaction outcome loss': 0.47931783812248757, 'Total loss': 0.47931783812248757}
2022-11-28 04:45:37,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:37,878 INFO:     Epoch: 64
2022-11-28 04:45:38,546 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47396965731274, 'Total loss': 0.47396965731274} | train loss {'Reaction outcome loss': 0.46977016614393713, 'Total loss': 0.46977016614393713}
2022-11-28 04:45:38,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:38,546 INFO:     Epoch: 65
2022-11-28 04:45:39,213 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4744129885326732, 'Total loss': 0.4744129885326732} | train loss {'Reaction outcome loss': 0.47029439571053394, 'Total loss': 0.47029439571053394}
2022-11-28 04:45:39,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:39,214 INFO:     Epoch: 66
2022-11-28 04:45:39,879 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49784099750898103, 'Total loss': 0.49784099750898103} | train loss {'Reaction outcome loss': 0.47756498816766235, 'Total loss': 0.47756498816766235}
2022-11-28 04:45:39,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:39,880 INFO:     Epoch: 67
2022-11-28 04:45:40,541 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4590274417264895, 'Total loss': 0.4590274417264895} | train loss {'Reaction outcome loss': 0.4777579164577399, 'Total loss': 0.4777579164577399}
2022-11-28 04:45:40,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:40,542 INFO:     Epoch: 68
2022-11-28 04:45:41,202 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4619374441152269, 'Total loss': 0.4619374441152269} | train loss {'Reaction outcome loss': 0.46990465306439383, 'Total loss': 0.46990465306439383}
2022-11-28 04:45:41,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:41,202 INFO:     Epoch: 69
2022-11-28 04:45:41,863 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5110117908228528, 'Total loss': 0.5110117908228528} | train loss {'Reaction outcome loss': 0.4656988837971137, 'Total loss': 0.4656988837971137}
2022-11-28 04:45:41,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:41,863 INFO:     Epoch: 70
2022-11-28 04:45:42,525 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4597115990790454, 'Total loss': 0.4597115990790454} | train loss {'Reaction outcome loss': 0.4660576910142474, 'Total loss': 0.4660576910142474}
2022-11-28 04:45:42,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:42,526 INFO:     Epoch: 71
2022-11-28 04:45:43,191 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46268307891759003, 'Total loss': 0.46268307891759003} | train loss {'Reaction outcome loss': 0.4721557919071753, 'Total loss': 0.4721557919071753}
2022-11-28 04:45:43,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:43,191 INFO:     Epoch: 72
2022-11-28 04:45:43,854 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5164583201774142, 'Total loss': 0.5164583201774142} | train loss {'Reaction outcome loss': 0.46714688861659664, 'Total loss': 0.46714688861659664}
2022-11-28 04:45:43,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:43,855 INFO:     Epoch: 73
2022-11-28 04:45:44,520 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4867327365685593, 'Total loss': 0.4867327365685593} | train loss {'Reaction outcome loss': 0.4737706408206268, 'Total loss': 0.4737706408206268}
2022-11-28 04:45:44,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:44,520 INFO:     Epoch: 74
2022-11-28 04:45:45,179 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4851963775740428, 'Total loss': 0.4851963775740428} | train loss {'Reaction outcome loss': 0.4710347928136949, 'Total loss': 0.4710347928136949}
2022-11-28 04:45:45,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:45,179 INFO:     Epoch: 75
2022-11-28 04:45:45,841 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4973079697652297, 'Total loss': 0.4973079697652297} | train loss {'Reaction outcome loss': 0.4656792162099348, 'Total loss': 0.4656792162099348}
2022-11-28 04:45:45,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:45,842 INFO:     Epoch: 76
2022-11-28 04:45:46,508 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4874184544790875, 'Total loss': 0.4874184544790875} | train loss {'Reaction outcome loss': 0.47010221800612295, 'Total loss': 0.47010221800612295}
2022-11-28 04:45:46,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:46,508 INFO:     Epoch: 77
2022-11-28 04:45:47,173 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4393460652367635, 'Total loss': 0.4393460652367635} | train loss {'Reaction outcome loss': 0.4742186036307802, 'Total loss': 0.4742186036307802}
2022-11-28 04:45:47,173 INFO:     Found new best model at epoch 77
2022-11-28 04:45:47,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:47,174 INFO:     Epoch: 78
2022-11-28 04:45:47,840 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4450016065754674, 'Total loss': 0.4450016065754674} | train loss {'Reaction outcome loss': 0.4683445470354818, 'Total loss': 0.4683445470354818}
2022-11-28 04:45:47,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:47,840 INFO:     Epoch: 79
2022-11-28 04:45:48,503 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45396012237126177, 'Total loss': 0.45396012237126177} | train loss {'Reaction outcome loss': 0.47427811639511636, 'Total loss': 0.47427811639511636}
2022-11-28 04:45:48,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:48,503 INFO:     Epoch: 80
2022-11-28 04:45:49,164 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4773657460781661, 'Total loss': 0.4773657460781661} | train loss {'Reaction outcome loss': 0.4704046004153939, 'Total loss': 0.4704046004153939}
2022-11-28 04:45:49,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:49,164 INFO:     Epoch: 81
2022-11-28 04:45:49,827 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4681804244491187, 'Total loss': 0.4681804244491187} | train loss {'Reaction outcome loss': 0.4669324100273944, 'Total loss': 0.4669324100273944}
2022-11-28 04:45:49,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:49,827 INFO:     Epoch: 82
2022-11-28 04:45:50,492 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4666720103811134, 'Total loss': 0.4666720103811134} | train loss {'Reaction outcome loss': 0.46908123435279137, 'Total loss': 0.46908123435279137}
2022-11-28 04:45:50,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:50,492 INFO:     Epoch: 83
2022-11-28 04:45:51,156 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44092200764200906, 'Total loss': 0.44092200764200906} | train loss {'Reaction outcome loss': 0.46891916844134146, 'Total loss': 0.46891916844134146}
2022-11-28 04:45:51,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:51,157 INFO:     Epoch: 84
2022-11-28 04:45:51,817 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.470818180590868, 'Total loss': 0.470818180590868} | train loss {'Reaction outcome loss': 0.47195649086705105, 'Total loss': 0.47195649086705105}
2022-11-28 04:45:51,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:51,817 INFO:     Epoch: 85
2022-11-28 04:45:52,476 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48654569956389343, 'Total loss': 0.48654569956389343} | train loss {'Reaction outcome loss': 0.4707843658593502, 'Total loss': 0.4707843658593502}
2022-11-28 04:45:52,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:52,476 INFO:     Epoch: 86
2022-11-28 04:45:53,138 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4384806589646773, 'Total loss': 0.4384806589646773} | train loss {'Reaction outcome loss': 0.4762546509986947, 'Total loss': 0.4762546509986947}
2022-11-28 04:45:53,138 INFO:     Found new best model at epoch 86
2022-11-28 04:45:53,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:53,139 INFO:     Epoch: 87
2022-11-28 04:45:53,801 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46986025910485874, 'Total loss': 0.46986025910485874} | train loss {'Reaction outcome loss': 0.4678398384618373, 'Total loss': 0.4678398384618373}
2022-11-28 04:45:53,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:53,802 INFO:     Epoch: 88
2022-11-28 04:45:54,462 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45789763873273676, 'Total loss': 0.45789763873273676} | train loss {'Reaction outcome loss': 0.4763837589426079, 'Total loss': 0.4763837589426079}
2022-11-28 04:45:54,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:54,463 INFO:     Epoch: 89
2022-11-28 04:45:55,131 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4659004726193168, 'Total loss': 0.4659004726193168} | train loss {'Reaction outcome loss': 0.4759488424685923, 'Total loss': 0.4759488424685923}
2022-11-28 04:45:55,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:55,131 INFO:     Epoch: 90
2022-11-28 04:45:55,796 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.481356218457222, 'Total loss': 0.481356218457222} | train loss {'Reaction outcome loss': 0.4635847423240723, 'Total loss': 0.4635847423240723}
2022-11-28 04:45:55,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:55,797 INFO:     Epoch: 91
2022-11-28 04:45:56,466 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4682481861249967, 'Total loss': 0.4682481861249967} | train loss {'Reaction outcome loss': 0.47150301740237094, 'Total loss': 0.47150301740237094}
2022-11-28 04:45:56,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:56,466 INFO:     Epoch: 92
2022-11-28 04:45:57,130 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45630909654904495, 'Total loss': 0.45630909654904495} | train loss {'Reaction outcome loss': 0.46641372910395323, 'Total loss': 0.46641372910395323}
2022-11-28 04:45:57,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:57,131 INFO:     Epoch: 93
2022-11-28 04:45:57,794 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4887732131914659, 'Total loss': 0.4887732131914659} | train loss {'Reaction outcome loss': 0.48035400019589103, 'Total loss': 0.48035400019589103}
2022-11-28 04:45:57,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:57,795 INFO:     Epoch: 94
2022-11-28 04:45:58,461 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44677683440121735, 'Total loss': 0.44677683440121735} | train loss {'Reaction outcome loss': 0.47287501126569265, 'Total loss': 0.47287501126569265}
2022-11-28 04:45:58,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:58,461 INFO:     Epoch: 95
2022-11-28 04:45:59,125 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4830329235304486, 'Total loss': 0.4830329235304486} | train loss {'Reaction outcome loss': 0.4770050518184538, 'Total loss': 0.4770050518184538}
2022-11-28 04:45:59,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:59,125 INFO:     Epoch: 96
2022-11-28 04:45:59,790 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4429821859706532, 'Total loss': 0.4429821859706532} | train loss {'Reaction outcome loss': 0.48367334962615116, 'Total loss': 0.48367334962615116}
2022-11-28 04:45:59,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:45:59,790 INFO:     Epoch: 97
2022-11-28 04:46:00,453 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45374965227463027, 'Total loss': 0.45374965227463027} | train loss {'Reaction outcome loss': 0.4671466371670426, 'Total loss': 0.4671466371670426}
2022-11-28 04:46:00,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:00,454 INFO:     Epoch: 98
2022-11-28 04:46:01,116 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4458080049265515, 'Total loss': 0.4458080049265515} | train loss {'Reaction outcome loss': 0.4749126087738435, 'Total loss': 0.4749126087738435}
2022-11-28 04:46:01,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:01,116 INFO:     Epoch: 99
2022-11-28 04:46:01,777 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46178323606198485, 'Total loss': 0.46178323606198485} | train loss {'Reaction outcome loss': 0.46610428000751297, 'Total loss': 0.46610428000751297}
2022-11-28 04:46:01,777 INFO:     Best model found after epoch 87 of 100.
2022-11-28 04:46:01,777 INFO:   Done with stage: TRAINING
2022-11-28 04:46:01,777 INFO:   Starting stage: EVALUATION
2022-11-28 04:46:01,894 INFO:   Done with stage: EVALUATION
2022-11-28 04:46:01,894 INFO:   Leaving out SEQ value Fold_2
2022-11-28 04:46:01,907 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 04:46:01,907 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:46:02,550 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:46:02,551 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:46:02,621 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:46:02,621 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:46:02,622 INFO:     No hyperparam tuning for this model
2022-11-28 04:46:02,622 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:46:02,622 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:46:02,622 INFO:     None feature selector for col prot
2022-11-28 04:46:02,623 INFO:     None feature selector for col prot
2022-11-28 04:46:02,623 INFO:     None feature selector for col prot
2022-11-28 04:46:02,623 INFO:     None feature selector for col chem
2022-11-28 04:46:02,623 INFO:     None feature selector for col chem
2022-11-28 04:46:02,623 INFO:     None feature selector for col chem
2022-11-28 04:46:02,623 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:46:02,623 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:46:02,625 INFO:     Number of params in model 169651
2022-11-28 04:46:02,628 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:46:02,628 INFO:   Starting stage: TRAINING
2022-11-28 04:46:02,679 INFO:     Val loss before train {'Reaction outcome loss': 0.9936742863871835, 'Total loss': 0.9936742863871835}
2022-11-28 04:46:02,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:02,679 INFO:     Epoch: 0
2022-11-28 04:46:03,340 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5784063786268234, 'Total loss': 0.5784063786268234} | train loss {'Reaction outcome loss': 0.6968004912746196, 'Total loss': 0.6968004912746196}
2022-11-28 04:46:03,340 INFO:     Found new best model at epoch 0
2022-11-28 04:46:03,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:03,341 INFO:     Epoch: 1
2022-11-28 04:46:03,998 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5978517925197427, 'Total loss': 0.5978517925197427} | train loss {'Reaction outcome loss': 0.5894119495031785, 'Total loss': 0.5894119495031785}
2022-11-28 04:46:03,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:03,999 INFO:     Epoch: 2
2022-11-28 04:46:04,657 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5340324518355456, 'Total loss': 0.5340324518355456} | train loss {'Reaction outcome loss': 0.5640009610628595, 'Total loss': 0.5640009610628595}
2022-11-28 04:46:04,657 INFO:     Found new best model at epoch 2
2022-11-28 04:46:04,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:04,658 INFO:     Epoch: 3
2022-11-28 04:46:05,315 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5041845867579634, 'Total loss': 0.5041845867579634} | train loss {'Reaction outcome loss': 0.5375422665659262, 'Total loss': 0.5375422665659262}
2022-11-28 04:46:05,316 INFO:     Found new best model at epoch 3
2022-11-28 04:46:05,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:05,316 INFO:     Epoch: 4
2022-11-28 04:46:05,971 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5316065925766121, 'Total loss': 0.5316065925766121} | train loss {'Reaction outcome loss': 0.5113761452387791, 'Total loss': 0.5113761452387791}
2022-11-28 04:46:05,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:05,972 INFO:     Epoch: 5
2022-11-28 04:46:06,624 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5301244387572462, 'Total loss': 0.5301244387572462} | train loss {'Reaction outcome loss': 0.506754942876952, 'Total loss': 0.506754942876952}
2022-11-28 04:46:06,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:06,624 INFO:     Epoch: 6
2022-11-28 04:46:07,274 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5188573602248322, 'Total loss': 0.5188573602248322} | train loss {'Reaction outcome loss': 0.5005237051418849, 'Total loss': 0.5005237051418849}
2022-11-28 04:46:07,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:07,275 INFO:     Epoch: 7
2022-11-28 04:46:07,929 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48009518398479983, 'Total loss': 0.48009518398479983} | train loss {'Reaction outcome loss': 0.4919847931788892, 'Total loss': 0.4919847931788892}
2022-11-28 04:46:07,929 INFO:     Found new best model at epoch 7
2022-11-28 04:46:07,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:07,929 INFO:     Epoch: 8
2022-11-28 04:46:08,584 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47656153853644023, 'Total loss': 0.47656153853644023} | train loss {'Reaction outcome loss': 0.5022543207115057, 'Total loss': 0.5022543207115057}
2022-11-28 04:46:08,584 INFO:     Found new best model at epoch 8
2022-11-28 04:46:08,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:08,585 INFO:     Epoch: 9
2022-11-28 04:46:09,237 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4986870508979667, 'Total loss': 0.4986870508979667} | train loss {'Reaction outcome loss': 0.4855519392660686, 'Total loss': 0.4855519392660686}
2022-11-28 04:46:09,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:09,238 INFO:     Epoch: 10
2022-11-28 04:46:09,893 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49289981072599237, 'Total loss': 0.49289981072599237} | train loss {'Reaction outcome loss': 0.49226891881957346, 'Total loss': 0.49226891881957346}
2022-11-28 04:46:09,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:09,893 INFO:     Epoch: 11
2022-11-28 04:46:10,546 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4840289191766219, 'Total loss': 0.4840289191766219} | train loss {'Reaction outcome loss': 0.4854097300646256, 'Total loss': 0.4854097300646256}
2022-11-28 04:46:10,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:10,546 INFO:     Epoch: 12
2022-11-28 04:46:11,203 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4922309240156954, 'Total loss': 0.4922309240156954} | train loss {'Reaction outcome loss': 0.48048030229247346, 'Total loss': 0.48048030229247346}
2022-11-28 04:46:11,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:11,204 INFO:     Epoch: 13
2022-11-28 04:46:11,859 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47129959240555763, 'Total loss': 0.47129959240555763} | train loss {'Reaction outcome loss': 0.4774806289648523, 'Total loss': 0.4774806289648523}
2022-11-28 04:46:11,859 INFO:     Found new best model at epoch 13
2022-11-28 04:46:11,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:11,860 INFO:     Epoch: 14
2022-11-28 04:46:12,515 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4728462912819602, 'Total loss': 0.4728462912819602} | train loss {'Reaction outcome loss': 0.4880488796805849, 'Total loss': 0.4880488796805849}
2022-11-28 04:46:12,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:12,515 INFO:     Epoch: 15
2022-11-28 04:46:13,171 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4695483495227315, 'Total loss': 0.4695483495227315} | train loss {'Reaction outcome loss': 0.4783039735896247, 'Total loss': 0.4783039735896247}
2022-11-28 04:46:13,171 INFO:     Found new best model at epoch 15
2022-11-28 04:46:13,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:13,172 INFO:     Epoch: 16
2022-11-28 04:46:13,826 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4718387231908061, 'Total loss': 0.4718387231908061} | train loss {'Reaction outcome loss': 0.48139617485659464, 'Total loss': 0.48139617485659464}
2022-11-28 04:46:13,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:13,827 INFO:     Epoch: 17
2022-11-28 04:46:14,485 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5106907060200517, 'Total loss': 0.5106907060200517} | train loss {'Reaction outcome loss': 0.4804751048282701, 'Total loss': 0.4804751048282701}
2022-11-28 04:46:14,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:14,486 INFO:     Epoch: 18
2022-11-28 04:46:15,143 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47171511060812255, 'Total loss': 0.47171511060812255} | train loss {'Reaction outcome loss': 0.47891732077209315, 'Total loss': 0.47891732077209315}
2022-11-28 04:46:15,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:15,144 INFO:     Epoch: 19
2022-11-28 04:46:15,803 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47971299358389596, 'Total loss': 0.47971299358389596} | train loss {'Reaction outcome loss': 0.4708264900713551, 'Total loss': 0.4708264900713551}
2022-11-28 04:46:15,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:15,803 INFO:     Epoch: 20
2022-11-28 04:46:16,462 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4947611144320531, 'Total loss': 0.4947611144320531} | train loss {'Reaction outcome loss': 0.48116865748045395, 'Total loss': 0.48116865748045395}
2022-11-28 04:46:16,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:16,462 INFO:     Epoch: 21
2022-11-28 04:46:17,119 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4582413705912503, 'Total loss': 0.4582413705912503} | train loss {'Reaction outcome loss': 0.4714358590695323, 'Total loss': 0.4714358590695323}
2022-11-28 04:46:17,119 INFO:     Found new best model at epoch 21
2022-11-28 04:46:17,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:17,120 INFO:     Epoch: 22
2022-11-28 04:46:17,776 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5012090317904949, 'Total loss': 0.5012090317904949} | train loss {'Reaction outcome loss': 0.47774545063777846, 'Total loss': 0.47774545063777846}
2022-11-28 04:46:17,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:17,776 INFO:     Epoch: 23
2022-11-28 04:46:18,436 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46288634498010983, 'Total loss': 0.46288634498010983} | train loss {'Reaction outcome loss': 0.4754894671999678, 'Total loss': 0.4754894671999678}
2022-11-28 04:46:18,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:18,437 INFO:     Epoch: 24
2022-11-28 04:46:19,091 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4759277965534817, 'Total loss': 0.4759277965534817} | train loss {'Reaction outcome loss': 0.4769929218048952, 'Total loss': 0.4769929218048952}
2022-11-28 04:46:19,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:19,091 INFO:     Epoch: 25
2022-11-28 04:46:19,746 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5118239149451256, 'Total loss': 0.5118239149451256} | train loss {'Reaction outcome loss': 0.4655274585801728, 'Total loss': 0.4655274585801728}
2022-11-28 04:46:19,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:19,746 INFO:     Epoch: 26
2022-11-28 04:46:20,399 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46870299259370024, 'Total loss': 0.46870299259370024} | train loss {'Reaction outcome loss': 0.4711828474487577, 'Total loss': 0.4711828474487577}
2022-11-28 04:46:20,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:20,399 INFO:     Epoch: 27
2022-11-28 04:46:21,050 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4839102038266984, 'Total loss': 0.4839102038266984} | train loss {'Reaction outcome loss': 0.47474738085756496, 'Total loss': 0.47474738085756496}
2022-11-28 04:46:21,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:21,050 INFO:     Epoch: 28
2022-11-28 04:46:21,701 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.461549023674293, 'Total loss': 0.461549023674293} | train loss {'Reaction outcome loss': 0.46560250216600846, 'Total loss': 0.46560250216600846}
2022-11-28 04:46:21,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:21,701 INFO:     Epoch: 29
2022-11-28 04:46:22,355 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.495561904866587, 'Total loss': 0.495561904866587} | train loss {'Reaction outcome loss': 0.4711861269814627, 'Total loss': 0.4711861269814627}
2022-11-28 04:46:22,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:22,356 INFO:     Epoch: 30
2022-11-28 04:46:23,009 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47294220836325124, 'Total loss': 0.47294220836325124} | train loss {'Reaction outcome loss': 0.46643352222685913, 'Total loss': 0.46643352222685913}
2022-11-28 04:46:23,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:23,009 INFO:     Epoch: 31
2022-11-28 04:46:23,661 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47956230491399765, 'Total loss': 0.47956230491399765} | train loss {'Reaction outcome loss': 0.4719440198066283, 'Total loss': 0.4719440198066283}
2022-11-28 04:46:23,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:23,662 INFO:     Epoch: 32
2022-11-28 04:46:24,316 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49124912037090823, 'Total loss': 0.49124912037090823} | train loss {'Reaction outcome loss': 0.4700738543150376, 'Total loss': 0.4700738543150376}
2022-11-28 04:46:24,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:24,317 INFO:     Epoch: 33
2022-11-28 04:46:24,970 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47266061637889256, 'Total loss': 0.47266061637889256} | train loss {'Reaction outcome loss': 0.4678483779333076, 'Total loss': 0.4678483779333076}
2022-11-28 04:46:24,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:24,970 INFO:     Epoch: 34
2022-11-28 04:46:25,625 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45577526329593226, 'Total loss': 0.45577526329593226} | train loss {'Reaction outcome loss': 0.46766748580397394, 'Total loss': 0.46766748580397394}
2022-11-28 04:46:25,626 INFO:     Found new best model at epoch 34
2022-11-28 04:46:25,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:25,627 INFO:     Epoch: 35
2022-11-28 04:46:26,278 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4652065004814755, 'Total loss': 0.4652065004814755} | train loss {'Reaction outcome loss': 0.4700974523412938, 'Total loss': 0.4700974523412938}
2022-11-28 04:46:26,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:26,279 INFO:     Epoch: 36
2022-11-28 04:46:26,930 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47755958851088176, 'Total loss': 0.47755958851088176} | train loss {'Reaction outcome loss': 0.46387442922105593, 'Total loss': 0.46387442922105593}
2022-11-28 04:46:26,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:26,930 INFO:     Epoch: 37
2022-11-28 04:46:27,584 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4820329889401116, 'Total loss': 0.4820329889401116} | train loss {'Reaction outcome loss': 0.4724104510278118, 'Total loss': 0.4724104510278118}
2022-11-28 04:46:27,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:27,584 INFO:     Epoch: 38
2022-11-28 04:46:28,234 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45280294120311737, 'Total loss': 0.45280294120311737} | train loss {'Reaction outcome loss': 0.467271356832008, 'Total loss': 0.467271356832008}
2022-11-28 04:46:28,234 INFO:     Found new best model at epoch 38
2022-11-28 04:46:28,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:28,235 INFO:     Epoch: 39
2022-11-28 04:46:28,886 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48201327872547234, 'Total loss': 0.48201327872547234} | train loss {'Reaction outcome loss': 0.4638893375591356, 'Total loss': 0.4638893375591356}
2022-11-28 04:46:28,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:28,886 INFO:     Epoch: 40
2022-11-28 04:46:29,541 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.470082008025863, 'Total loss': 0.470082008025863} | train loss {'Reaction outcome loss': 0.4720266482051538, 'Total loss': 0.4720266482051538}
2022-11-28 04:46:29,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:29,541 INFO:     Epoch: 41
2022-11-28 04:46:30,197 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47897236760367046, 'Total loss': 0.47897236760367046} | train loss {'Reaction outcome loss': 0.47020440673341557, 'Total loss': 0.47020440673341557}
2022-11-28 04:46:30,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:30,197 INFO:     Epoch: 42
2022-11-28 04:46:30,854 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45421170273965056, 'Total loss': 0.45421170273965056} | train loss {'Reaction outcome loss': 0.4706213220041625, 'Total loss': 0.4706213220041625}
2022-11-28 04:46:30,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:30,855 INFO:     Epoch: 43
2022-11-28 04:46:31,509 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46406973762945697, 'Total loss': 0.46406973762945697} | train loss {'Reaction outcome loss': 0.4700677692586062, 'Total loss': 0.4700677692586062}
2022-11-28 04:46:31,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:31,509 INFO:     Epoch: 44
2022-11-28 04:46:32,161 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49887062710794533, 'Total loss': 0.49887062710794533} | train loss {'Reaction outcome loss': 0.47034020271836496, 'Total loss': 0.47034020271836496}
2022-11-28 04:46:32,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:32,162 INFO:     Epoch: 45
2022-11-28 04:46:32,816 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4871256574988365, 'Total loss': 0.4871256574988365} | train loss {'Reaction outcome loss': 0.4706561612231391, 'Total loss': 0.4706561612231391}
2022-11-28 04:46:32,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:32,816 INFO:     Epoch: 46
2022-11-28 04:46:33,469 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4695984666997736, 'Total loss': 0.4695984666997736} | train loss {'Reaction outcome loss': 0.4641067990539025, 'Total loss': 0.4641067990539025}
2022-11-28 04:46:33,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:33,470 INFO:     Epoch: 47
2022-11-28 04:46:34,126 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47060175985097885, 'Total loss': 0.47060175985097885} | train loss {'Reaction outcome loss': 0.47074936251251065, 'Total loss': 0.47074936251251065}
2022-11-28 04:46:34,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:34,127 INFO:     Epoch: 48
2022-11-28 04:46:34,781 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4860561192035675, 'Total loss': 0.4860561192035675} | train loss {'Reaction outcome loss': 0.4633915149435705, 'Total loss': 0.4633915149435705}
2022-11-28 04:46:34,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:34,782 INFO:     Epoch: 49
2022-11-28 04:46:35,435 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4347904016348449, 'Total loss': 0.4347904016348449} | train loss {'Reaction outcome loss': 0.46834923701018705, 'Total loss': 0.46834923701018705}
2022-11-28 04:46:35,435 INFO:     Found new best model at epoch 49
2022-11-28 04:46:35,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:35,436 INFO:     Epoch: 50
2022-11-28 04:46:36,093 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4723919260908257, 'Total loss': 0.4723919260908257} | train loss {'Reaction outcome loss': 0.46328419945677934, 'Total loss': 0.46328419945677934}
2022-11-28 04:46:36,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:36,093 INFO:     Epoch: 51
2022-11-28 04:46:36,749 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47061199288476596, 'Total loss': 0.47061199288476596} | train loss {'Reaction outcome loss': 0.46801847103907135, 'Total loss': 0.46801847103907135}
2022-11-28 04:46:36,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:36,749 INFO:     Epoch: 52
2022-11-28 04:46:37,405 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4681720459325747, 'Total loss': 0.4681720459325747} | train loss {'Reaction outcome loss': 0.466892843647879, 'Total loss': 0.466892843647879}
2022-11-28 04:46:37,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:37,406 INFO:     Epoch: 53
2022-11-28 04:46:38,060 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4538933370601047, 'Total loss': 0.4538933370601047} | train loss {'Reaction outcome loss': 0.4656417808362416, 'Total loss': 0.4656417808362416}
2022-11-28 04:46:38,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:38,060 INFO:     Epoch: 54
2022-11-28 04:46:38,715 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4898113449188796, 'Total loss': 0.4898113449188796} | train loss {'Reaction outcome loss': 0.47457237143297587, 'Total loss': 0.47457237143297587}
2022-11-28 04:46:38,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:38,715 INFO:     Epoch: 55
2022-11-28 04:46:39,369 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4534268463877114, 'Total loss': 0.4534268463877114} | train loss {'Reaction outcome loss': 0.4666351891293818, 'Total loss': 0.4666351891293818}
2022-11-28 04:46:39,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:39,370 INFO:     Epoch: 56
2022-11-28 04:46:40,023 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4547174254601652, 'Total loss': 0.4547174254601652} | train loss {'Reaction outcome loss': 0.4627173672221145, 'Total loss': 0.4627173672221145}
2022-11-28 04:46:40,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:40,023 INFO:     Epoch: 57
2022-11-28 04:46:40,680 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47661825675855984, 'Total loss': 0.47661825675855984} | train loss {'Reaction outcome loss': 0.4682662310040727, 'Total loss': 0.4682662310040727}
2022-11-28 04:46:40,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:40,680 INFO:     Epoch: 58
2022-11-28 04:46:41,338 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5124715360897508, 'Total loss': 0.5124715360897508} | train loss {'Reaction outcome loss': 0.4672381294016935, 'Total loss': 0.4672381294016935}
2022-11-28 04:46:41,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:41,338 INFO:     Epoch: 59
2022-11-28 04:46:41,995 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47434988482431933, 'Total loss': 0.47434988482431933} | train loss {'Reaction outcome loss': 0.4726586574498488, 'Total loss': 0.4726586574498488}
2022-11-28 04:46:41,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:41,995 INFO:     Epoch: 60
2022-11-28 04:46:42,652 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47362536513669923, 'Total loss': 0.47362536513669923} | train loss {'Reaction outcome loss': 0.46189008081445887, 'Total loss': 0.46189008081445887}
2022-11-28 04:46:42,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:42,652 INFO:     Epoch: 61
2022-11-28 04:46:43,306 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45971658995205705, 'Total loss': 0.45971658995205705} | train loss {'Reaction outcome loss': 0.4704244138026724, 'Total loss': 0.4704244138026724}
2022-11-28 04:46:43,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:43,306 INFO:     Epoch: 62
2022-11-28 04:46:43,964 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45837847905402834, 'Total loss': 0.45837847905402834} | train loss {'Reaction outcome loss': 0.46762954696100584, 'Total loss': 0.46762954696100584}
2022-11-28 04:46:43,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:43,964 INFO:     Epoch: 63
2022-11-28 04:46:44,618 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4770809777758338, 'Total loss': 0.4770809777758338} | train loss {'Reaction outcome loss': 0.4648921076132327, 'Total loss': 0.4648921076132327}
2022-11-28 04:46:44,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:44,619 INFO:     Epoch: 64
2022-11-28 04:46:45,276 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4825883514501832, 'Total loss': 0.4825883514501832} | train loss {'Reaction outcome loss': 0.4694302376435727, 'Total loss': 0.4694302376435727}
2022-11-28 04:46:45,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:45,276 INFO:     Epoch: 65
2022-11-28 04:46:45,933 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4625304974615574, 'Total loss': 0.4625304974615574} | train loss {'Reaction outcome loss': 0.46375938289019525, 'Total loss': 0.46375938289019525}
2022-11-28 04:46:45,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:45,933 INFO:     Epoch: 66
2022-11-28 04:46:46,588 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5028094232759692, 'Total loss': 0.5028094232759692} | train loss {'Reaction outcome loss': 0.4709508417820444, 'Total loss': 0.4709508417820444}
2022-11-28 04:46:46,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:46,588 INFO:     Epoch: 67
2022-11-28 04:46:47,241 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48672286116264085, 'Total loss': 0.48672286116264085} | train loss {'Reaction outcome loss': 0.47017700550507524, 'Total loss': 0.47017700550507524}
2022-11-28 04:46:47,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:47,241 INFO:     Epoch: 68
2022-11-28 04:46:47,900 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4674285069446672, 'Total loss': 0.4674285069446672} | train loss {'Reaction outcome loss': 0.4644555374067657, 'Total loss': 0.4644555374067657}
2022-11-28 04:46:47,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:47,901 INFO:     Epoch: 69
2022-11-28 04:46:48,554 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44813176921822806, 'Total loss': 0.44813176921822806} | train loss {'Reaction outcome loss': 0.46219330089432853, 'Total loss': 0.46219330089432853}
2022-11-28 04:46:48,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:48,554 INFO:     Epoch: 70
2022-11-28 04:46:49,207 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46716551008549606, 'Total loss': 0.46716551008549606} | train loss {'Reaction outcome loss': 0.47192461581862705, 'Total loss': 0.47192461581862705}
2022-11-28 04:46:49,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:49,207 INFO:     Epoch: 71
2022-11-28 04:46:49,862 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4970277009362524, 'Total loss': 0.4970277009362524} | train loss {'Reaction outcome loss': 0.4652765600656977, 'Total loss': 0.4652765600656977}
2022-11-28 04:46:49,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:49,862 INFO:     Epoch: 72
2022-11-28 04:46:50,518 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5032849393107675, 'Total loss': 0.5032849393107675} | train loss {'Reaction outcome loss': 0.4680559876621986, 'Total loss': 0.4680559876621986}
2022-11-28 04:46:50,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:50,518 INFO:     Epoch: 73
2022-11-28 04:46:51,172 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4619488153945316, 'Total loss': 0.4619488153945316} | train loss {'Reaction outcome loss': 0.46992439864849556, 'Total loss': 0.46992439864849556}
2022-11-28 04:46:51,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:51,173 INFO:     Epoch: 74
2022-11-28 04:46:51,830 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5022993233393539, 'Total loss': 0.5022993233393539} | train loss {'Reaction outcome loss': 0.46767007051681986, 'Total loss': 0.46767007051681986}
2022-11-28 04:46:51,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:51,830 INFO:     Epoch: 75
2022-11-28 04:46:52,488 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46664127572016284, 'Total loss': 0.46664127572016284} | train loss {'Reaction outcome loss': 0.4664468656389081, 'Total loss': 0.4664468656389081}
2022-11-28 04:46:52,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:52,488 INFO:     Epoch: 76
2022-11-28 04:46:53,142 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46926433593034744, 'Total loss': 0.46926433593034744} | train loss {'Reaction outcome loss': 0.46733980385624635, 'Total loss': 0.46733980385624635}
2022-11-28 04:46:53,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:53,142 INFO:     Epoch: 77
2022-11-28 04:46:53,797 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45946350117976015, 'Total loss': 0.45946350117976015} | train loss {'Reaction outcome loss': 0.4624217745600914, 'Total loss': 0.4624217745600914}
2022-11-28 04:46:53,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:53,797 INFO:     Epoch: 78
2022-11-28 04:46:54,452 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4766889932480725, 'Total loss': 0.4766889932480725} | train loss {'Reaction outcome loss': 0.46935043821529465, 'Total loss': 0.46935043821529465}
2022-11-28 04:46:54,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:54,452 INFO:     Epoch: 79
2022-11-28 04:46:55,105 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4915475896136327, 'Total loss': 0.4915475896136327} | train loss {'Reaction outcome loss': 0.46217628498466645, 'Total loss': 0.46217628498466645}
2022-11-28 04:46:55,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:55,106 INFO:     Epoch: 80
2022-11-28 04:46:55,762 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4805554906752976, 'Total loss': 0.4805554906752976} | train loss {'Reaction outcome loss': 0.4723064631831889, 'Total loss': 0.4723064631831889}
2022-11-28 04:46:55,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:55,762 INFO:     Epoch: 81
2022-11-28 04:46:56,413 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4805072539231994, 'Total loss': 0.4805072539231994} | train loss {'Reaction outcome loss': 0.46302376964262554, 'Total loss': 0.46302376964262554}
2022-11-28 04:46:56,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:56,414 INFO:     Epoch: 82
2022-11-28 04:46:57,067 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4672011357139457, 'Total loss': 0.4672011357139457} | train loss {'Reaction outcome loss': 0.46401972776773026, 'Total loss': 0.46401972776773026}
2022-11-28 04:46:57,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:57,067 INFO:     Epoch: 83
2022-11-28 04:46:57,722 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4721671989695592, 'Total loss': 0.4721671989695592} | train loss {'Reaction outcome loss': 0.4671507538581381, 'Total loss': 0.4671507538581381}
2022-11-28 04:46:57,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:57,722 INFO:     Epoch: 84
2022-11-28 04:46:58,376 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4636671082539992, 'Total loss': 0.4636671082539992} | train loss {'Reaction outcome loss': 0.47009558902711285, 'Total loss': 0.47009558902711285}
2022-11-28 04:46:58,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:58,376 INFO:     Epoch: 85
2022-11-28 04:46:59,027 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4576566285369071, 'Total loss': 0.4576566285369071} | train loss {'Reaction outcome loss': 0.4730627473215668, 'Total loss': 0.4730627473215668}
2022-11-28 04:46:59,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:59,027 INFO:     Epoch: 86
2022-11-28 04:46:59,678 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4486923197453672, 'Total loss': 0.4486923197453672} | train loss {'Reaction outcome loss': 0.463706983352194, 'Total loss': 0.463706983352194}
2022-11-28 04:46:59,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:46:59,678 INFO:     Epoch: 87
2022-11-28 04:47:00,334 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48315679688345303, 'Total loss': 0.48315679688345303} | train loss {'Reaction outcome loss': 0.4702438240756794, 'Total loss': 0.4702438240756794}
2022-11-28 04:47:00,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:00,334 INFO:     Epoch: 88
2022-11-28 04:47:00,987 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45233775539831683, 'Total loss': 0.45233775539831683} | train loss {'Reaction outcome loss': 0.46974181231795525, 'Total loss': 0.46974181231795525}
2022-11-28 04:47:00,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:00,987 INFO:     Epoch: 89
2022-11-28 04:47:01,645 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5097406113689597, 'Total loss': 0.5097406113689597} | train loss {'Reaction outcome loss': 0.4614470756783777, 'Total loss': 0.4614470756783777}
2022-11-28 04:47:01,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:01,645 INFO:     Epoch: 90
2022-11-28 04:47:02,300 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4770352047952739, 'Total loss': 0.4770352047952739} | train loss {'Reaction outcome loss': 0.4667672370161329, 'Total loss': 0.4667672370161329}
2022-11-28 04:47:02,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:02,300 INFO:     Epoch: 91
2022-11-28 04:47:02,958 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4711151692000302, 'Total loss': 0.4711151692000302} | train loss {'Reaction outcome loss': 0.46322784074106993, 'Total loss': 0.46322784074106993}
2022-11-28 04:47:02,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:02,959 INFO:     Epoch: 92
2022-11-28 04:47:03,615 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47622551972215826, 'Total loss': 0.47622551972215826} | train loss {'Reaction outcome loss': 0.46320955935789615, 'Total loss': 0.46320955935789615}
2022-11-28 04:47:03,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:03,615 INFO:     Epoch: 93
2022-11-28 04:47:04,266 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46178827908906067, 'Total loss': 0.46178827908906067} | train loss {'Reaction outcome loss': 0.46041859759359943, 'Total loss': 0.46041859759359943}
2022-11-28 04:47:04,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:04,266 INFO:     Epoch: 94
2022-11-28 04:47:04,921 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4832789085128091, 'Total loss': 0.4832789085128091} | train loss {'Reaction outcome loss': 0.46903191981266956, 'Total loss': 0.46903191981266956}
2022-11-28 04:47:04,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:04,922 INFO:     Epoch: 95
2022-11-28 04:47:05,576 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48170717466961255, 'Total loss': 0.48170717466961255} | train loss {'Reaction outcome loss': 0.46789743924627497, 'Total loss': 0.46789743924627497}
2022-11-28 04:47:05,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:05,576 INFO:     Epoch: 96
2022-11-28 04:47:06,229 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5054115446453745, 'Total loss': 0.5054115446453745} | train loss {'Reaction outcome loss': 0.46979118619038135, 'Total loss': 0.46979118619038135}
2022-11-28 04:47:06,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:06,230 INFO:     Epoch: 97
2022-11-28 04:47:06,884 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4584010218968615, 'Total loss': 0.4584010218968615} | train loss {'Reaction outcome loss': 0.4641928667924842, 'Total loss': 0.4641928667924842}
2022-11-28 04:47:06,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:06,885 INFO:     Epoch: 98
2022-11-28 04:47:07,539 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4718997356566516, 'Total loss': 0.4718997356566516} | train loss {'Reaction outcome loss': 0.4614202487833646, 'Total loss': 0.4614202487833646}
2022-11-28 04:47:07,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:07,540 INFO:     Epoch: 99
2022-11-28 04:47:08,193 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48683392764492467, 'Total loss': 0.48683392764492467} | train loss {'Reaction outcome loss': 0.4651901328137943, 'Total loss': 0.4651901328137943}
2022-11-28 04:47:08,193 INFO:     Best model found after epoch 50 of 100.
2022-11-28 04:47:08,193 INFO:   Done with stage: TRAINING
2022-11-28 04:47:08,193 INFO:   Starting stage: EVALUATION
2022-11-28 04:47:08,316 INFO:   Done with stage: EVALUATION
2022-11-28 04:47:08,316 INFO:   Leaving out SEQ value Fold_3
2022-11-28 04:47:08,329 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 04:47:08,329 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:47:08,968 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:47:08,968 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:47:09,038 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:47:09,038 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:47:09,038 INFO:     No hyperparam tuning for this model
2022-11-28 04:47:09,038 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:47:09,038 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:47:09,039 INFO:     None feature selector for col prot
2022-11-28 04:47:09,039 INFO:     None feature selector for col prot
2022-11-28 04:47:09,039 INFO:     None feature selector for col prot
2022-11-28 04:47:09,040 INFO:     None feature selector for col chem
2022-11-28 04:47:09,040 INFO:     None feature selector for col chem
2022-11-28 04:47:09,040 INFO:     None feature selector for col chem
2022-11-28 04:47:09,040 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:47:09,040 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:47:09,041 INFO:     Number of params in model 169651
2022-11-28 04:47:09,044 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:47:09,044 INFO:   Starting stage: TRAINING
2022-11-28 04:47:09,094 INFO:     Val loss before train {'Reaction outcome loss': 0.9907409722028777, 'Total loss': 0.9907409722028777}
2022-11-28 04:47:09,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:09,094 INFO:     Epoch: 0
2022-11-28 04:47:09,745 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6204042746577152, 'Total loss': 0.6204042746577152} | train loss {'Reaction outcome loss': 0.6975262765390952, 'Total loss': 0.6975262765390952}
2022-11-28 04:47:09,745 INFO:     Found new best model at epoch 0
2022-11-28 04:47:09,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:09,746 INFO:     Epoch: 1
2022-11-28 04:47:10,397 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6029293259908987, 'Total loss': 0.6029293259908987} | train loss {'Reaction outcome loss': 0.5968719246934672, 'Total loss': 0.5968719246934672}
2022-11-28 04:47:10,398 INFO:     Found new best model at epoch 1
2022-11-28 04:47:10,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:10,398 INFO:     Epoch: 2
2022-11-28 04:47:11,050 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5109096529871918, 'Total loss': 0.5109096529871918} | train loss {'Reaction outcome loss': 0.5668573514482037, 'Total loss': 0.5668573514482037}
2022-11-28 04:47:11,050 INFO:     Found new best model at epoch 2
2022-11-28 04:47:11,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:11,051 INFO:     Epoch: 3
2022-11-28 04:47:11,703 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5133337995340658, 'Total loss': 0.5133337995340658} | train loss {'Reaction outcome loss': 0.5390450450607011, 'Total loss': 0.5390450450607011}
2022-11-28 04:47:11,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:11,703 INFO:     Epoch: 4
2022-11-28 04:47:12,352 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5239994047686111, 'Total loss': 0.5239994047686111} | train loss {'Reaction outcome loss': 0.5209011612612693, 'Total loss': 0.5209011612612693}
2022-11-28 04:47:12,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:12,352 INFO:     Epoch: 5
2022-11-28 04:47:13,005 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.520715209633805, 'Total loss': 0.520715209633805} | train loss {'Reaction outcome loss': 0.5234680844501394, 'Total loss': 0.5234680844501394}
2022-11-28 04:47:13,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:13,005 INFO:     Epoch: 6
2022-11-28 04:47:13,659 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49593658364096355, 'Total loss': 0.49593658364096355} | train loss {'Reaction outcome loss': 0.5088137268531517, 'Total loss': 0.5088137268531517}
2022-11-28 04:47:13,659 INFO:     Found new best model at epoch 6
2022-11-28 04:47:13,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:13,660 INFO:     Epoch: 7
2022-11-28 04:47:14,310 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5140501537988352, 'Total loss': 0.5140501537988352} | train loss {'Reaction outcome loss': 0.5023318260419564, 'Total loss': 0.5023318260419564}
2022-11-28 04:47:14,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:14,311 INFO:     Epoch: 8
2022-11-28 04:47:14,962 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5391801786284114, 'Total loss': 0.5391801786284114} | train loss {'Reaction outcome loss': 0.5070439268086777, 'Total loss': 0.5070439268086777}
2022-11-28 04:47:14,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:14,963 INFO:     Epoch: 9
2022-11-28 04:47:15,616 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.480688665841901, 'Total loss': 0.480688665841901} | train loss {'Reaction outcome loss': 0.5029925640489235, 'Total loss': 0.5029925640489235}
2022-11-28 04:47:15,616 INFO:     Found new best model at epoch 9
2022-11-28 04:47:15,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:15,617 INFO:     Epoch: 10
2022-11-28 04:47:16,270 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4725944271614385, 'Total loss': 0.4725944271614385} | train loss {'Reaction outcome loss': 0.5000965063933467, 'Total loss': 0.5000965063933467}
2022-11-28 04:47:16,270 INFO:     Found new best model at epoch 10
2022-11-28 04:47:16,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:16,271 INFO:     Epoch: 11
2022-11-28 04:47:16,923 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.489441292230473, 'Total loss': 0.489441292230473} | train loss {'Reaction outcome loss': 0.4960492866449669, 'Total loss': 0.4960492866449669}
2022-11-28 04:47:16,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:16,923 INFO:     Epoch: 12
2022-11-28 04:47:17,574 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5054071479758551, 'Total loss': 0.5054071479758551} | train loss {'Reaction outcome loss': 0.4954064766891667, 'Total loss': 0.4954064766891667}
2022-11-28 04:47:17,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:17,574 INFO:     Epoch: 13
2022-11-28 04:47:18,227 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47605414307394694, 'Total loss': 0.47605414307394694} | train loss {'Reaction outcome loss': 0.49590851980276773, 'Total loss': 0.49590851980276773}
2022-11-28 04:47:18,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:18,227 INFO:     Epoch: 14
2022-11-28 04:47:18,881 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4953791000122248, 'Total loss': 0.4953791000122248} | train loss {'Reaction outcome loss': 0.485550301973937, 'Total loss': 0.485550301973937}
2022-11-28 04:47:18,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:18,882 INFO:     Epoch: 15
2022-11-28 04:47:19,535 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5011532105678735, 'Total loss': 0.5011532105678735} | train loss {'Reaction outcome loss': 0.4945640955425677, 'Total loss': 0.4945640955425677}
2022-11-28 04:47:19,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:19,535 INFO:     Epoch: 16
2022-11-28 04:47:20,190 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5151778733314469, 'Total loss': 0.5151778733314469} | train loss {'Reaction outcome loss': 0.48097843939407925, 'Total loss': 0.48097843939407925}
2022-11-28 04:47:20,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:20,190 INFO:     Epoch: 17
2022-11-28 04:47:20,846 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4951038669015086, 'Total loss': 0.4951038669015086} | train loss {'Reaction outcome loss': 0.48706856956247424, 'Total loss': 0.48706856956247424}
2022-11-28 04:47:20,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:20,846 INFO:     Epoch: 18
2022-11-28 04:47:21,499 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.497340097676876, 'Total loss': 0.497340097676876} | train loss {'Reaction outcome loss': 0.4804232758698893, 'Total loss': 0.4804232758698893}
2022-11-28 04:47:21,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:21,500 INFO:     Epoch: 19
2022-11-28 04:47:22,150 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47768812176100045, 'Total loss': 0.47768812176100045} | train loss {'Reaction outcome loss': 0.48612115538266837, 'Total loss': 0.48612115538266837}
2022-11-28 04:47:22,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:22,151 INFO:     Epoch: 20
2022-11-28 04:47:22,805 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4974631504263989, 'Total loss': 0.4974631504263989} | train loss {'Reaction outcome loss': 0.4733331985160953, 'Total loss': 0.4733331985160953}
2022-11-28 04:47:22,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:22,806 INFO:     Epoch: 21
2022-11-28 04:47:23,463 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.464143966866094, 'Total loss': 0.464143966866094} | train loss {'Reaction outcome loss': 0.4719616224470197, 'Total loss': 0.4719616224470197}
2022-11-28 04:47:23,463 INFO:     Found new best model at epoch 21
2022-11-28 04:47:23,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:23,463 INFO:     Epoch: 22
2022-11-28 04:47:24,116 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4756015095599862, 'Total loss': 0.4756015095599862} | train loss {'Reaction outcome loss': 0.4826313475238495, 'Total loss': 0.4826313475238495}
2022-11-28 04:47:24,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:24,116 INFO:     Epoch: 23
2022-11-28 04:47:24,770 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4972114625365235, 'Total loss': 0.4972114625365235} | train loss {'Reaction outcome loss': 0.47491013686187933, 'Total loss': 0.47491013686187933}
2022-11-28 04:47:24,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:24,770 INFO:     Epoch: 24
2022-11-28 04:47:25,422 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4677803578764893, 'Total loss': 0.4677803578764893} | train loss {'Reaction outcome loss': 0.4724561991628076, 'Total loss': 0.4724561991628076}
2022-11-28 04:47:25,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:25,423 INFO:     Epoch: 25
2022-11-28 04:47:26,074 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48282442848349727, 'Total loss': 0.48282442848349727} | train loss {'Reaction outcome loss': 0.4794615408802619, 'Total loss': 0.4794615408802619}
2022-11-28 04:47:26,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:26,075 INFO:     Epoch: 26
2022-11-28 04:47:26,726 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49184113567651705, 'Total loss': 0.49184113567651705} | train loss {'Reaction outcome loss': 0.47929758181581733, 'Total loss': 0.47929758181581733}
2022-11-28 04:47:26,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:26,727 INFO:     Epoch: 27
2022-11-28 04:47:27,378 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4723491325627926, 'Total loss': 0.4723491325627926} | train loss {'Reaction outcome loss': 0.4782313532272323, 'Total loss': 0.4782313532272323}
2022-11-28 04:47:27,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:27,380 INFO:     Epoch: 28
2022-11-28 04:47:28,034 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46226721274298294, 'Total loss': 0.46226721274298294} | train loss {'Reaction outcome loss': 0.47339437046989064, 'Total loss': 0.47339437046989064}
2022-11-28 04:47:28,034 INFO:     Found new best model at epoch 28
2022-11-28 04:47:28,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:28,035 INFO:     Epoch: 29
2022-11-28 04:47:28,691 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.487300313142843, 'Total loss': 0.487300313142843} | train loss {'Reaction outcome loss': 0.4663002774363659, 'Total loss': 0.4663002774363659}
2022-11-28 04:47:28,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:28,691 INFO:     Epoch: 30
2022-11-28 04:47:29,343 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4751581043698067, 'Total loss': 0.4751581043698067} | train loss {'Reaction outcome loss': 0.4835371982123031, 'Total loss': 0.4835371982123031}
2022-11-28 04:47:29,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:29,343 INFO:     Epoch: 31
2022-11-28 04:47:29,997 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5419578954230907, 'Total loss': 0.5419578954230907} | train loss {'Reaction outcome loss': 0.48169691616394483, 'Total loss': 0.48169691616394483}
2022-11-28 04:47:29,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:29,997 INFO:     Epoch: 32
2022-11-28 04:47:30,649 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48245227648768313, 'Total loss': 0.48245227648768313} | train loss {'Reaction outcome loss': 0.4773322321840974, 'Total loss': 0.4773322321840974}
2022-11-28 04:47:30,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:30,649 INFO:     Epoch: 33
2022-11-28 04:47:31,301 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5168171923520953, 'Total loss': 0.5168171923520953} | train loss {'Reaction outcome loss': 0.47387746636007655, 'Total loss': 0.47387746636007655}
2022-11-28 04:47:31,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:31,302 INFO:     Epoch: 34
2022-11-28 04:47:31,956 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4702034717382387, 'Total loss': 0.4702034717382387} | train loss {'Reaction outcome loss': 0.4744842224678055, 'Total loss': 0.4744842224678055}
2022-11-28 04:47:31,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:31,956 INFO:     Epoch: 35
2022-11-28 04:47:32,609 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4784170687198639, 'Total loss': 0.4784170687198639} | train loss {'Reaction outcome loss': 0.46947174015470217, 'Total loss': 0.46947174015470217}
2022-11-28 04:47:32,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:32,610 INFO:     Epoch: 36
2022-11-28 04:47:33,263 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4892079254915548, 'Total loss': 0.4892079254915548} | train loss {'Reaction outcome loss': 0.46711010070609266, 'Total loss': 0.46711010070609266}
2022-11-28 04:47:33,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:33,263 INFO:     Epoch: 37
2022-11-28 04:47:33,916 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5092275395642879, 'Total loss': 0.5092275395642879} | train loss {'Reaction outcome loss': 0.4758142171824565, 'Total loss': 0.4758142171824565}
2022-11-28 04:47:33,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:33,916 INFO:     Epoch: 38
2022-11-28 04:47:34,575 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46786730234013046, 'Total loss': 0.46786730234013046} | train loss {'Reaction outcome loss': 0.47339011502803346, 'Total loss': 0.47339011502803346}
2022-11-28 04:47:34,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:34,575 INFO:     Epoch: 39
2022-11-28 04:47:35,231 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48511590791303055, 'Total loss': 0.48511590791303055} | train loss {'Reaction outcome loss': 0.47644585218341623, 'Total loss': 0.47644585218341623}
2022-11-28 04:47:35,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:35,231 INFO:     Epoch: 40
2022-11-28 04:47:35,884 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4700666153153708, 'Total loss': 0.4700666153153708} | train loss {'Reaction outcome loss': 0.4702400448197713, 'Total loss': 0.4702400448197713}
2022-11-28 04:47:35,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:35,885 INFO:     Epoch: 41
2022-11-28 04:47:36,537 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45969947826030644, 'Total loss': 0.45969947826030644} | train loss {'Reaction outcome loss': 0.4652489852312891, 'Total loss': 0.4652489852312891}
2022-11-28 04:47:36,537 INFO:     Found new best model at epoch 41
2022-11-28 04:47:36,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:36,537 INFO:     Epoch: 42
2022-11-28 04:47:37,185 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45784119048783944, 'Total loss': 0.45784119048783944} | train loss {'Reaction outcome loss': 0.471950572045123, 'Total loss': 0.471950572045123}
2022-11-28 04:47:37,185 INFO:     Found new best model at epoch 42
2022-11-28 04:47:37,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:37,186 INFO:     Epoch: 43
2022-11-28 04:47:37,833 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4597665154656699, 'Total loss': 0.4597665154656699} | train loss {'Reaction outcome loss': 0.4689377513332445, 'Total loss': 0.4689377513332445}
2022-11-28 04:47:37,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:37,833 INFO:     Epoch: 44
2022-11-28 04:47:38,480 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4858728019997131, 'Total loss': 0.4858728019997131} | train loss {'Reaction outcome loss': 0.46944822804605374, 'Total loss': 0.46944822804605374}
2022-11-28 04:47:38,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:38,480 INFO:     Epoch: 45
2022-11-28 04:47:39,130 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4754951173482939, 'Total loss': 0.4754951173482939} | train loss {'Reaction outcome loss': 0.465624206256671, 'Total loss': 0.465624206256671}
2022-11-28 04:47:39,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:39,131 INFO:     Epoch: 46
2022-11-28 04:47:39,782 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4776735766682514, 'Total loss': 0.4776735766682514} | train loss {'Reaction outcome loss': 0.4769086482339218, 'Total loss': 0.4769086482339218}
2022-11-28 04:47:39,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:39,782 INFO:     Epoch: 47
2022-11-28 04:47:40,430 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47490198321120686, 'Total loss': 0.47490198321120686} | train loss {'Reaction outcome loss': 0.4732967784903089, 'Total loss': 0.4732967784903089}
2022-11-28 04:47:40,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:40,430 INFO:     Epoch: 48
2022-11-28 04:47:41,076 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4806638283784999, 'Total loss': 0.4806638283784999} | train loss {'Reaction outcome loss': 0.4649839876372306, 'Total loss': 0.4649839876372306}
2022-11-28 04:47:41,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:41,077 INFO:     Epoch: 49
2022-11-28 04:47:41,722 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4656073523815288, 'Total loss': 0.4656073523815288} | train loss {'Reaction outcome loss': 0.4661688231481392, 'Total loss': 0.4661688231481392}
2022-11-28 04:47:41,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:41,722 INFO:     Epoch: 50
2022-11-28 04:47:42,371 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5082186703072038, 'Total loss': 0.5082186703072038} | train loss {'Reaction outcome loss': 0.4638625604757031, 'Total loss': 0.4638625604757031}
2022-11-28 04:47:42,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:42,371 INFO:     Epoch: 51
2022-11-28 04:47:43,018 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45961435936218087, 'Total loss': 0.45961435936218087} | train loss {'Reaction outcome loss': 0.4685102530190202, 'Total loss': 0.4685102530190202}
2022-11-28 04:47:43,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:43,018 INFO:     Epoch: 52
2022-11-28 04:47:43,664 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47345402767491895, 'Total loss': 0.47345402767491895} | train loss {'Reaction outcome loss': 0.47232109613594464, 'Total loss': 0.47232109613594464}
2022-11-28 04:47:43,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:43,664 INFO:     Epoch: 53
2022-11-28 04:47:44,313 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.49639054924942727, 'Total loss': 0.49639054924942727} | train loss {'Reaction outcome loss': 0.46641379194792176, 'Total loss': 0.46641379194792176}
2022-11-28 04:47:44,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:44,313 INFO:     Epoch: 54
2022-11-28 04:47:44,958 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4632049545992252, 'Total loss': 0.4632049545992252} | train loss {'Reaction outcome loss': 0.4693660940058896, 'Total loss': 0.4693660940058896}
2022-11-28 04:47:44,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:44,959 INFO:     Epoch: 55
2022-11-28 04:47:45,603 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4894775408645009, 'Total loss': 0.4894775408645009} | train loss {'Reaction outcome loss': 0.47182024923748656, 'Total loss': 0.47182024923748656}
2022-11-28 04:47:45,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:45,603 INFO:     Epoch: 56
2022-11-28 04:47:46,252 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45361248247845226, 'Total loss': 0.45361248247845226} | train loss {'Reaction outcome loss': 0.4712432734668255, 'Total loss': 0.4712432734668255}
2022-11-28 04:47:46,253 INFO:     Found new best model at epoch 56
2022-11-28 04:47:46,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:46,254 INFO:     Epoch: 57
2022-11-28 04:47:46,903 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44922862045986706, 'Total loss': 0.44922862045986706} | train loss {'Reaction outcome loss': 0.4732946791365498, 'Total loss': 0.4732946791365498}
2022-11-28 04:47:46,903 INFO:     Found new best model at epoch 57
2022-11-28 04:47:46,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:46,904 INFO:     Epoch: 58
2022-11-28 04:47:47,551 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47679699489543603, 'Total loss': 0.47679699489543603} | train loss {'Reaction outcome loss': 0.4671566800870856, 'Total loss': 0.4671566800870856}
2022-11-28 04:47:47,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:47,552 INFO:     Epoch: 59
2022-11-28 04:47:48,199 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45257848397243855, 'Total loss': 0.45257848397243855} | train loss {'Reaction outcome loss': 0.47374636038649276, 'Total loss': 0.47374636038649276}
2022-11-28 04:47:48,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:48,199 INFO:     Epoch: 60
2022-11-28 04:47:48,846 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49378587062968765, 'Total loss': 0.49378587062968765} | train loss {'Reaction outcome loss': 0.4612761440335727, 'Total loss': 0.4612761440335727}
2022-11-28 04:47:48,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:48,846 INFO:     Epoch: 61
2022-11-28 04:47:49,494 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45808837995972745, 'Total loss': 0.45808837995972745} | train loss {'Reaction outcome loss': 0.4726126741801129, 'Total loss': 0.4726126741801129}
2022-11-28 04:47:49,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:49,494 INFO:     Epoch: 62
2022-11-28 04:47:50,140 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4631845729295598, 'Total loss': 0.4631845729295598} | train loss {'Reaction outcome loss': 0.4642735527919941, 'Total loss': 0.4642735527919941}
2022-11-28 04:47:50,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:50,140 INFO:     Epoch: 63
2022-11-28 04:47:50,788 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.480813275936038, 'Total loss': 0.480813275936038} | train loss {'Reaction outcome loss': 0.4708394430211333, 'Total loss': 0.4708394430211333}
2022-11-28 04:47:50,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:50,788 INFO:     Epoch: 64
2022-11-28 04:47:51,436 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5265164600555287, 'Total loss': 0.5265164600555287} | train loss {'Reaction outcome loss': 0.47004851146188914, 'Total loss': 0.47004851146188914}
2022-11-28 04:47:51,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:51,436 INFO:     Epoch: 65
2022-11-28 04:47:52,084 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4672150736631349, 'Total loss': 0.4672150736631349} | train loss {'Reaction outcome loss': 0.4683439969772198, 'Total loss': 0.4683439969772198}
2022-11-28 04:47:52,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:52,084 INFO:     Epoch: 66
2022-11-28 04:47:52,731 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4706957492717477, 'Total loss': 0.4706957492717477} | train loss {'Reaction outcome loss': 0.4773393491985368, 'Total loss': 0.4773393491985368}
2022-11-28 04:47:52,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:52,731 INFO:     Epoch: 67
2022-11-28 04:47:53,380 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46158834598785226, 'Total loss': 0.46158834598785226} | train loss {'Reaction outcome loss': 0.4676627828205218, 'Total loss': 0.4676627828205218}
2022-11-28 04:47:53,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:53,381 INFO:     Epoch: 68
2022-11-28 04:47:54,027 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4962383702743885, 'Total loss': 0.4962383702743885} | train loss {'Reaction outcome loss': 0.4763573626147919, 'Total loss': 0.4763573626147919}
2022-11-28 04:47:54,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:54,027 INFO:     Epoch: 69
2022-11-28 04:47:54,675 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4456019917892855, 'Total loss': 0.4456019917892855} | train loss {'Reaction outcome loss': 0.4693156386130169, 'Total loss': 0.4693156386130169}
2022-11-28 04:47:54,675 INFO:     Found new best model at epoch 69
2022-11-28 04:47:54,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:54,676 INFO:     Epoch: 70
2022-11-28 04:47:55,322 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.492238532665164, 'Total loss': 0.492238532665164} | train loss {'Reaction outcome loss': 0.4741325550636307, 'Total loss': 0.4741325550636307}
2022-11-28 04:47:55,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:55,322 INFO:     Epoch: 71
2022-11-28 04:47:55,968 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46520133420478466, 'Total loss': 0.46520133420478466} | train loss {'Reaction outcome loss': 0.46583988541950944, 'Total loss': 0.46583988541950944}
2022-11-28 04:47:55,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:55,969 INFO:     Epoch: 72
2022-11-28 04:47:56,617 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.447349056948063, 'Total loss': 0.447349056948063} | train loss {'Reaction outcome loss': 0.4630979400311337, 'Total loss': 0.4630979400311337}
2022-11-28 04:47:56,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:56,618 INFO:     Epoch: 73
2022-11-28 04:47:57,268 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4616796235705531, 'Total loss': 0.4616796235705531} | train loss {'Reaction outcome loss': 0.4830831674034478, 'Total loss': 0.4830831674034478}
2022-11-28 04:47:57,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:57,268 INFO:     Epoch: 74
2022-11-28 04:47:57,919 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4767827381228292, 'Total loss': 0.4767827381228292} | train loss {'Reaction outcome loss': 0.4722065596429051, 'Total loss': 0.4722065596429051}
2022-11-28 04:47:57,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:57,920 INFO:     Epoch: 75
2022-11-28 04:47:58,569 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.497070214429567, 'Total loss': 0.497070214429567} | train loss {'Reaction outcome loss': 0.4668195447960838, 'Total loss': 0.4668195447960838}
2022-11-28 04:47:58,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:58,569 INFO:     Epoch: 76
2022-11-28 04:47:59,217 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48001319551190663, 'Total loss': 0.48001319551190663} | train loss {'Reaction outcome loss': 0.47515182386411997, 'Total loss': 0.47515182386411997}
2022-11-28 04:47:59,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:59,217 INFO:     Epoch: 77
2022-11-28 04:47:59,867 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4794958414033402, 'Total loss': 0.4794958414033402} | train loss {'Reaction outcome loss': 0.4699089120401711, 'Total loss': 0.4699089120401711}
2022-11-28 04:47:59,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:47:59,867 INFO:     Epoch: 78
2022-11-28 04:48:00,516 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4752734740113103, 'Total loss': 0.4752734740113103} | train loss {'Reaction outcome loss': 0.4668902061635353, 'Total loss': 0.4668902061635353}
2022-11-28 04:48:00,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:00,516 INFO:     Epoch: 79
2022-11-28 04:48:01,166 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45615186698214955, 'Total loss': 0.45615186698214955} | train loss {'Reaction outcome loss': 0.47521714102782187, 'Total loss': 0.47521714102782187}
2022-11-28 04:48:01,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:01,167 INFO:     Epoch: 80
2022-11-28 04:48:01,816 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4646290675845257, 'Total loss': 0.4646290675845257} | train loss {'Reaction outcome loss': 0.4653360454335076, 'Total loss': 0.4653360454335076}
2022-11-28 04:48:01,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:01,816 INFO:     Epoch: 81
2022-11-28 04:48:02,467 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46431190676467365, 'Total loss': 0.46431190676467365} | train loss {'Reaction outcome loss': 0.47171230308833667, 'Total loss': 0.47171230308833667}
2022-11-28 04:48:02,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:02,467 INFO:     Epoch: 82
2022-11-28 04:48:03,123 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4653695319281068, 'Total loss': 0.4653695319281068} | train loss {'Reaction outcome loss': 0.45870545817936054, 'Total loss': 0.45870545817936054}
2022-11-28 04:48:03,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:03,124 INFO:     Epoch: 83
2022-11-28 04:48:03,769 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47121950394885487, 'Total loss': 0.47121950394885487} | train loss {'Reaction outcome loss': 0.4710289967841789, 'Total loss': 0.4710289967841789}
2022-11-28 04:48:03,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:03,769 INFO:     Epoch: 84
2022-11-28 04:48:04,421 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4592499795348145, 'Total loss': 0.4592499795348145} | train loss {'Reaction outcome loss': 0.4741874243758741, 'Total loss': 0.4741874243758741}
2022-11-28 04:48:04,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:04,421 INFO:     Epoch: 85
2022-11-28 04:48:05,072 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4888136029936547, 'Total loss': 0.4888136029936547} | train loss {'Reaction outcome loss': 0.4681356924845547, 'Total loss': 0.4681356924845547}
2022-11-28 04:48:05,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:05,072 INFO:     Epoch: 86
2022-11-28 04:48:05,721 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46545099934866263, 'Total loss': 0.46545099934866263} | train loss {'Reaction outcome loss': 0.46857790056555, 'Total loss': 0.46857790056555}
2022-11-28 04:48:05,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:05,721 INFO:     Epoch: 87
2022-11-28 04:48:06,373 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47975921388282333, 'Total loss': 0.47975921388282333} | train loss {'Reaction outcome loss': 0.4662677700341236, 'Total loss': 0.4662677700341236}
2022-11-28 04:48:06,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:06,374 INFO:     Epoch: 88
2022-11-28 04:48:07,023 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.494906063689742, 'Total loss': 0.494906063689742} | train loss {'Reaction outcome loss': 0.47051912057595174, 'Total loss': 0.47051912057595174}
2022-11-28 04:48:07,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:07,023 INFO:     Epoch: 89
2022-11-28 04:48:07,670 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45964497223842976, 'Total loss': 0.45964497223842976} | train loss {'Reaction outcome loss': 0.4654574399722404, 'Total loss': 0.4654574399722404}
2022-11-28 04:48:07,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:07,671 INFO:     Epoch: 90
2022-11-28 04:48:08,320 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4921164242334144, 'Total loss': 0.4921164242334144} | train loss {'Reaction outcome loss': 0.47030514655787437, 'Total loss': 0.47030514655787437}
2022-11-28 04:48:08,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:08,320 INFO:     Epoch: 91
2022-11-28 04:48:08,968 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4666069021751714, 'Total loss': 0.4666069021751714} | train loss {'Reaction outcome loss': 0.4710671749027049, 'Total loss': 0.4710671749027049}
2022-11-28 04:48:08,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:08,968 INFO:     Epoch: 92
2022-11-28 04:48:09,615 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48967589749846346, 'Total loss': 0.48967589749846346} | train loss {'Reaction outcome loss': 0.46850874726889563, 'Total loss': 0.46850874726889563}
2022-11-28 04:48:09,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:09,615 INFO:     Epoch: 93
2022-11-28 04:48:10,264 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4728324801422829, 'Total loss': 0.4728324801422829} | train loss {'Reaction outcome loss': 0.47122433912925055, 'Total loss': 0.47122433912925055}
2022-11-28 04:48:10,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:10,264 INFO:     Epoch: 94
2022-11-28 04:48:10,910 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4575513039910516, 'Total loss': 0.4575513039910516} | train loss {'Reaction outcome loss': 0.4668066535816818, 'Total loss': 0.4668066535816818}
2022-11-28 04:48:10,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:10,911 INFO:     Epoch: 95
2022-11-28 04:48:11,564 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4671294301055198, 'Total loss': 0.4671294301055198} | train loss {'Reaction outcome loss': 0.4691358849284102, 'Total loss': 0.4691358849284102}
2022-11-28 04:48:11,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:11,564 INFO:     Epoch: 96
2022-11-28 04:48:12,216 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5111137392909028, 'Total loss': 0.5111137392909028} | train loss {'Reaction outcome loss': 0.46520185217139176, 'Total loss': 0.46520185217139176}
2022-11-28 04:48:12,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:12,216 INFO:     Epoch: 97
2022-11-28 04:48:12,867 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5255367520243622, 'Total loss': 0.5255367520243622} | train loss {'Reaction outcome loss': 0.46991753162907773, 'Total loss': 0.46991753162907773}
2022-11-28 04:48:12,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:12,867 INFO:     Epoch: 98
2022-11-28 04:48:13,518 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4614676431167957, 'Total loss': 0.4614676431167957} | train loss {'Reaction outcome loss': 0.4722322358704004, 'Total loss': 0.4722322358704004}
2022-11-28 04:48:13,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:13,518 INFO:     Epoch: 99
2022-11-28 04:48:14,166 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49506576705810634, 'Total loss': 0.49506576705810634} | train loss {'Reaction outcome loss': 0.4684002318831741, 'Total loss': 0.4684002318831741}
2022-11-28 04:48:14,166 INFO:     Best model found after epoch 70 of 100.
2022-11-28 04:48:14,166 INFO:   Done with stage: TRAINING
2022-11-28 04:48:14,166 INFO:   Starting stage: EVALUATION
2022-11-28 04:48:14,293 INFO:   Done with stage: EVALUATION
2022-11-28 04:48:14,293 INFO:   Leaving out SEQ value Fold_4
2022-11-28 04:48:14,306 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 04:48:14,306 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:48:14,949 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:48:14,949 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:48:15,019 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:48:15,019 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:48:15,019 INFO:     No hyperparam tuning for this model
2022-11-28 04:48:15,019 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:48:15,019 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:48:15,020 INFO:     None feature selector for col prot
2022-11-28 04:48:15,020 INFO:     None feature selector for col prot
2022-11-28 04:48:15,020 INFO:     None feature selector for col prot
2022-11-28 04:48:15,021 INFO:     None feature selector for col chem
2022-11-28 04:48:15,021 INFO:     None feature selector for col chem
2022-11-28 04:48:15,021 INFO:     None feature selector for col chem
2022-11-28 04:48:15,021 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:48:15,021 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:48:15,022 INFO:     Number of params in model 169651
2022-11-28 04:48:15,025 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:48:15,025 INFO:   Starting stage: TRAINING
2022-11-28 04:48:15,076 INFO:     Val loss before train {'Reaction outcome loss': 1.0292122201486067, 'Total loss': 1.0292122201486067}
2022-11-28 04:48:15,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:15,076 INFO:     Epoch: 0
2022-11-28 04:48:15,740 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6079450689933517, 'Total loss': 0.6079450689933517} | train loss {'Reaction outcome loss': 0.680451411032869, 'Total loss': 0.680451411032869}
2022-11-28 04:48:15,740 INFO:     Found new best model at epoch 0
2022-11-28 04:48:15,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:15,741 INFO:     Epoch: 1
2022-11-28 04:48:16,401 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.626452158797871, 'Total loss': 0.626452158797871} | train loss {'Reaction outcome loss': 0.5829695922232443, 'Total loss': 0.5829695922232443}
2022-11-28 04:48:16,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:16,402 INFO:     Epoch: 2
2022-11-28 04:48:17,063 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5714889771559022, 'Total loss': 0.5714889771559022} | train loss {'Reaction outcome loss': 0.5498255634259793, 'Total loss': 0.5498255634259793}
2022-11-28 04:48:17,063 INFO:     Found new best model at epoch 2
2022-11-28 04:48:17,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:17,063 INFO:     Epoch: 3
2022-11-28 04:48:17,724 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5337664471431212, 'Total loss': 0.5337664471431212} | train loss {'Reaction outcome loss': 0.5277650109041603, 'Total loss': 0.5277650109041603}
2022-11-28 04:48:17,724 INFO:     Found new best model at epoch 3
2022-11-28 04:48:17,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:17,725 INFO:     Epoch: 4
2022-11-28 04:48:18,385 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5795206563039259, 'Total loss': 0.5795206563039259} | train loss {'Reaction outcome loss': 0.5221959059276888, 'Total loss': 0.5221959059276888}
2022-11-28 04:48:18,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:18,386 INFO:     Epoch: 5
2022-11-28 04:48:19,045 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5903128195892681, 'Total loss': 0.5903128195892681} | train loss {'Reaction outcome loss': 0.5125925698948484, 'Total loss': 0.5125925698948484}
2022-11-28 04:48:19,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:19,045 INFO:     Epoch: 6
2022-11-28 04:48:19,708 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5622730654749003, 'Total loss': 0.5622730654749003} | train loss {'Reaction outcome loss': 0.5074599311356583, 'Total loss': 0.5074599311356583}
2022-11-28 04:48:19,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:19,708 INFO:     Epoch: 7
2022-11-28 04:48:20,370 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5237660218368877, 'Total loss': 0.5237660218368877} | train loss {'Reaction outcome loss': 0.5114701731551078, 'Total loss': 0.5114701731551078}
2022-11-28 04:48:20,371 INFO:     Found new best model at epoch 7
2022-11-28 04:48:20,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:20,371 INFO:     Epoch: 8
2022-11-28 04:48:21,033 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5244952016933397, 'Total loss': 0.5244952016933397} | train loss {'Reaction outcome loss': 0.49430134724224767, 'Total loss': 0.49430134724224767}
2022-11-28 04:48:21,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:21,034 INFO:     Epoch: 9
2022-11-28 04:48:21,699 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5041731670498848, 'Total loss': 0.5041731670498848} | train loss {'Reaction outcome loss': 0.48549351159242854, 'Total loss': 0.48549351159242854}
2022-11-28 04:48:21,699 INFO:     Found new best model at epoch 9
2022-11-28 04:48:21,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:21,700 INFO:     Epoch: 10
2022-11-28 04:48:22,361 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5016784925352443, 'Total loss': 0.5016784925352443} | train loss {'Reaction outcome loss': 0.4858414253159877, 'Total loss': 0.4858414253159877}
2022-11-28 04:48:22,361 INFO:     Found new best model at epoch 10
2022-11-28 04:48:22,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:22,361 INFO:     Epoch: 11
2022-11-28 04:48:23,025 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5153670412572947, 'Total loss': 0.5153670412572947} | train loss {'Reaction outcome loss': 0.48140637895032284, 'Total loss': 0.48140637895032284}
2022-11-28 04:48:23,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:23,026 INFO:     Epoch: 12
2022-11-28 04:48:23,686 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5577076280658896, 'Total loss': 0.5577076280658896} | train loss {'Reaction outcome loss': 0.4839157529415623, 'Total loss': 0.4839157529415623}
2022-11-28 04:48:23,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:23,686 INFO:     Epoch: 13
2022-11-28 04:48:24,347 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4966722990978848, 'Total loss': 0.4966722990978848} | train loss {'Reaction outcome loss': 0.47314321556158606, 'Total loss': 0.47314321556158606}
2022-11-28 04:48:24,347 INFO:     Found new best model at epoch 13
2022-11-28 04:48:24,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:24,348 INFO:     Epoch: 14
2022-11-28 04:48:25,007 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5320256542075764, 'Total loss': 0.5320256542075764} | train loss {'Reaction outcome loss': 0.48603854965298404, 'Total loss': 0.48603854965298404}
2022-11-28 04:48:25,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:25,007 INFO:     Epoch: 15
2022-11-28 04:48:25,668 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4981972761452198, 'Total loss': 0.4981972761452198} | train loss {'Reaction outcome loss': 0.4773884187903135, 'Total loss': 0.4773884187903135}
2022-11-28 04:48:25,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:25,669 INFO:     Epoch: 16
2022-11-28 04:48:26,330 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4896312803030014, 'Total loss': 0.4896312803030014} | train loss {'Reaction outcome loss': 0.47799519491532155, 'Total loss': 0.47799519491532155}
2022-11-28 04:48:26,330 INFO:     Found new best model at epoch 16
2022-11-28 04:48:26,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:26,331 INFO:     Epoch: 17
2022-11-28 04:48:26,991 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5653193796222861, 'Total loss': 0.5653193796222861} | train loss {'Reaction outcome loss': 0.4686520169939726, 'Total loss': 0.4686520169939726}
2022-11-28 04:48:26,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:26,991 INFO:     Epoch: 18
2022-11-28 04:48:27,651 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5245142850008878, 'Total loss': 0.5245142850008878} | train loss {'Reaction outcome loss': 0.47381355385145835, 'Total loss': 0.47381355385145835}
2022-11-28 04:48:27,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:27,652 INFO:     Epoch: 19
2022-11-28 04:48:28,309 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5009433715180918, 'Total loss': 0.5009433715180918} | train loss {'Reaction outcome loss': 0.47192172706127167, 'Total loss': 0.47192172706127167}
2022-11-28 04:48:28,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:28,309 INFO:     Epoch: 20
2022-11-28 04:48:28,969 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5261850614439357, 'Total loss': 0.5261850614439357} | train loss {'Reaction outcome loss': 0.4714287135509714, 'Total loss': 0.4714287135509714}
2022-11-28 04:48:28,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:28,969 INFO:     Epoch: 21
2022-11-28 04:48:29,631 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47276240993629803, 'Total loss': 0.47276240993629803} | train loss {'Reaction outcome loss': 0.46412125471678956, 'Total loss': 0.46412125471678956}
2022-11-28 04:48:29,632 INFO:     Found new best model at epoch 21
2022-11-28 04:48:29,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:29,633 INFO:     Epoch: 22
2022-11-28 04:48:30,295 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5147359808060256, 'Total loss': 0.5147359808060256} | train loss {'Reaction outcome loss': 0.46539207451766534, 'Total loss': 0.46539207451766534}
2022-11-28 04:48:30,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:30,295 INFO:     Epoch: 23
2022-11-28 04:48:30,955 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5152171982282941, 'Total loss': 0.5152171982282941} | train loss {'Reaction outcome loss': 0.46347529326956116, 'Total loss': 0.46347529326956116}
2022-11-28 04:48:30,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:30,955 INFO:     Epoch: 24
2022-11-28 04:48:31,615 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.544180032204498, 'Total loss': 0.544180032204498} | train loss {'Reaction outcome loss': 0.46162857217413766, 'Total loss': 0.46162857217413766}
2022-11-28 04:48:31,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:31,616 INFO:     Epoch: 25
2022-11-28 04:48:32,276 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4941013496030461, 'Total loss': 0.4941013496030461} | train loss {'Reaction outcome loss': 0.4568227277768235, 'Total loss': 0.4568227277768235}
2022-11-28 04:48:32,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:32,276 INFO:     Epoch: 26
2022-11-28 04:48:32,939 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5101923712275245, 'Total loss': 0.5101923712275245} | train loss {'Reaction outcome loss': 0.46323218614223505, 'Total loss': 0.46323218614223505}
2022-11-28 04:48:32,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:32,939 INFO:     Epoch: 27
2022-11-28 04:48:33,602 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5051084126938473, 'Total loss': 0.5051084126938473} | train loss {'Reaction outcome loss': 0.4654859062284231, 'Total loss': 0.4654859062284231}
2022-11-28 04:48:33,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:33,603 INFO:     Epoch: 28
2022-11-28 04:48:34,271 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.49375958198850806, 'Total loss': 0.49375958198850806} | train loss {'Reaction outcome loss': 0.45800818412774996, 'Total loss': 0.45800818412774996}
2022-11-28 04:48:34,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:34,272 INFO:     Epoch: 29
2022-11-28 04:48:34,942 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5098317062312906, 'Total loss': 0.5098317062312906} | train loss {'Reaction outcome loss': 0.4583993682697896, 'Total loss': 0.4583993682697896}
2022-11-28 04:48:34,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:34,942 INFO:     Epoch: 30
2022-11-28 04:48:35,609 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4889446571469307, 'Total loss': 0.4889446571469307} | train loss {'Reaction outcome loss': 0.4555194222278172, 'Total loss': 0.4555194222278172}
2022-11-28 04:48:35,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:35,609 INFO:     Epoch: 31
2022-11-28 04:48:36,276 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4739188575609164, 'Total loss': 0.4739188575609164} | train loss {'Reaction outcome loss': 0.4597293027045746, 'Total loss': 0.4597293027045746}
2022-11-28 04:48:36,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:36,277 INFO:     Epoch: 32
2022-11-28 04:48:36,941 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4713260358707471, 'Total loss': 0.4713260358707471} | train loss {'Reaction outcome loss': 0.45692971501980095, 'Total loss': 0.45692971501980095}
2022-11-28 04:48:36,941 INFO:     Found new best model at epoch 32
2022-11-28 04:48:36,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:36,942 INFO:     Epoch: 33
2022-11-28 04:48:37,608 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5310696383768861, 'Total loss': 0.5310696383768861} | train loss {'Reaction outcome loss': 0.4497310285786948, 'Total loss': 0.4497310285786948}
2022-11-28 04:48:37,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:37,609 INFO:     Epoch: 34
2022-11-28 04:48:38,276 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5633681077848781, 'Total loss': 0.5633681077848781} | train loss {'Reaction outcome loss': 0.4565462128769967, 'Total loss': 0.4565462128769967}
2022-11-28 04:48:38,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:38,276 INFO:     Epoch: 35
2022-11-28 04:48:38,943 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5457323010672223, 'Total loss': 0.5457323010672223} | train loss {'Reaction outcome loss': 0.45894617671447413, 'Total loss': 0.45894617671447413}
2022-11-28 04:48:38,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:38,943 INFO:     Epoch: 36
2022-11-28 04:48:39,611 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4932875707745552, 'Total loss': 0.4932875707745552} | train loss {'Reaction outcome loss': 0.4479491497960783, 'Total loss': 0.4479491497960783}
2022-11-28 04:48:39,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:39,612 INFO:     Epoch: 37
2022-11-28 04:48:40,276 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5165926251899112, 'Total loss': 0.5165926251899112} | train loss {'Reaction outcome loss': 0.45967775547216017, 'Total loss': 0.45967775547216017}
2022-11-28 04:48:40,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:40,276 INFO:     Epoch: 38
2022-11-28 04:48:40,941 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4809025458314202, 'Total loss': 0.4809025458314202} | train loss {'Reaction outcome loss': 0.4456223528231344, 'Total loss': 0.4456223528231344}
2022-11-28 04:48:40,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:40,941 INFO:     Epoch: 39
2022-11-28 04:48:41,611 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5165380632335489, 'Total loss': 0.5165380632335489} | train loss {'Reaction outcome loss': 0.4552105286669347, 'Total loss': 0.4552105286669347}
2022-11-28 04:48:41,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:41,611 INFO:     Epoch: 40
2022-11-28 04:48:42,278 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4756040388548916, 'Total loss': 0.4756040388548916} | train loss {'Reaction outcome loss': 0.448426942040603, 'Total loss': 0.448426942040603}
2022-11-28 04:48:42,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:42,278 INFO:     Epoch: 41
2022-11-28 04:48:42,942 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5182848955419931, 'Total loss': 0.5182848955419931} | train loss {'Reaction outcome loss': 0.4571118333767499, 'Total loss': 0.4571118333767499}
2022-11-28 04:48:42,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:42,943 INFO:     Epoch: 42
2022-11-28 04:48:43,607 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5102766921574419, 'Total loss': 0.5102766921574419} | train loss {'Reaction outcome loss': 0.45816384496227386, 'Total loss': 0.45816384496227386}
2022-11-28 04:48:43,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:43,607 INFO:     Epoch: 43
2022-11-28 04:48:44,271 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4675394173034213, 'Total loss': 0.4675394173034213} | train loss {'Reaction outcome loss': 0.45330912854161953, 'Total loss': 0.45330912854161953}
2022-11-28 04:48:44,272 INFO:     Found new best model at epoch 43
2022-11-28 04:48:44,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:44,272 INFO:     Epoch: 44
2022-11-28 04:48:44,939 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4909741942855445, 'Total loss': 0.4909741942855445} | train loss {'Reaction outcome loss': 0.4572504348151626, 'Total loss': 0.4572504348151626}
2022-11-28 04:48:44,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:44,940 INFO:     Epoch: 45
2022-11-28 04:48:45,609 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49087005481123924, 'Total loss': 0.49087005481123924} | train loss {'Reaction outcome loss': 0.4526308889410669, 'Total loss': 0.4526308889410669}
2022-11-28 04:48:45,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:45,609 INFO:     Epoch: 46
2022-11-28 04:48:46,277 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4811862331222404, 'Total loss': 0.4811862331222404} | train loss {'Reaction outcome loss': 0.4512227102513275, 'Total loss': 0.4512227102513275}
2022-11-28 04:48:46,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:46,277 INFO:     Epoch: 47
2022-11-28 04:48:46,942 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5066603269766677, 'Total loss': 0.5066603269766677} | train loss {'Reaction outcome loss': 0.4473842628180019, 'Total loss': 0.4473842628180019}
2022-11-28 04:48:46,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:46,942 INFO:     Epoch: 48
2022-11-28 04:48:47,607 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49321166256612, 'Total loss': 0.49321166256612} | train loss {'Reaction outcome loss': 0.45036245720280754, 'Total loss': 0.45036245720280754}
2022-11-28 04:48:47,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:47,607 INFO:     Epoch: 49
2022-11-28 04:48:48,271 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48572913997552614, 'Total loss': 0.48572913997552614} | train loss {'Reaction outcome loss': 0.4513072599506667, 'Total loss': 0.4513072599506667}
2022-11-28 04:48:48,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:48,271 INFO:     Epoch: 50
2022-11-28 04:48:48,940 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5120880136435683, 'Total loss': 0.5120880136435683} | train loss {'Reaction outcome loss': 0.4482245903702513, 'Total loss': 0.4482245903702513}
2022-11-28 04:48:48,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:48,941 INFO:     Epoch: 51
2022-11-28 04:48:49,613 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5376369147138162, 'Total loss': 0.5376369147138162} | train loss {'Reaction outcome loss': 0.4542596230523721, 'Total loss': 0.4542596230523721}
2022-11-28 04:48:49,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:49,614 INFO:     Epoch: 52
2022-11-28 04:48:50,280 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5050583495335146, 'Total loss': 0.5050583495335146} | train loss {'Reaction outcome loss': 0.45325442848186337, 'Total loss': 0.45325442848186337}
2022-11-28 04:48:50,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:50,280 INFO:     Epoch: 53
2022-11-28 04:48:50,946 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4816427943720059, 'Total loss': 0.4816427943720059} | train loss {'Reaction outcome loss': 0.4584665136531957, 'Total loss': 0.4584665136531957}
2022-11-28 04:48:50,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:50,946 INFO:     Epoch: 54
2022-11-28 04:48:51,616 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4855144264345819, 'Total loss': 0.4855144264345819} | train loss {'Reaction outcome loss': 0.44978567194794455, 'Total loss': 0.44978567194794455}
2022-11-28 04:48:51,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:51,616 INFO:     Epoch: 55
2022-11-28 04:48:52,284 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49743093245408754, 'Total loss': 0.49743093245408754} | train loss {'Reaction outcome loss': 0.45567399960371757, 'Total loss': 0.45567399960371757}
2022-11-28 04:48:52,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:52,284 INFO:     Epoch: 56
2022-11-28 04:48:52,953 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4673223542896184, 'Total loss': 0.4673223542896184} | train loss {'Reaction outcome loss': 0.45144798065866193, 'Total loss': 0.45144798065866193}
2022-11-28 04:48:52,953 INFO:     Found new best model at epoch 56
2022-11-28 04:48:52,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:52,954 INFO:     Epoch: 57
2022-11-28 04:48:53,620 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5203488340431993, 'Total loss': 0.5203488340431993} | train loss {'Reaction outcome loss': 0.45204771302580354, 'Total loss': 0.45204771302580354}
2022-11-28 04:48:53,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:53,620 INFO:     Epoch: 58
2022-11-28 04:48:54,288 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4864986572753299, 'Total loss': 0.4864986572753299} | train loss {'Reaction outcome loss': 0.45091161372200134, 'Total loss': 0.45091161372200134}
2022-11-28 04:48:54,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:54,288 INFO:     Epoch: 59
2022-11-28 04:48:54,957 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4888946813615886, 'Total loss': 0.4888946813615886} | train loss {'Reaction outcome loss': 0.4519001938883335, 'Total loss': 0.4519001938883335}
2022-11-28 04:48:54,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:54,957 INFO:     Epoch: 60
2022-11-28 04:48:55,625 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5023768049749461, 'Total loss': 0.5023768049749461} | train loss {'Reaction outcome loss': 0.4551714600454415, 'Total loss': 0.4551714600454415}
2022-11-28 04:48:55,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:55,625 INFO:     Epoch: 61
2022-11-28 04:48:56,295 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4928964166478677, 'Total loss': 0.4928964166478677} | train loss {'Reaction outcome loss': 0.4497556673783448, 'Total loss': 0.4497556673783448}
2022-11-28 04:48:56,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:56,295 INFO:     Epoch: 62
2022-11-28 04:48:56,968 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5125803771344098, 'Total loss': 0.5125803771344098} | train loss {'Reaction outcome loss': 0.45590084202347264, 'Total loss': 0.45590084202347264}
2022-11-28 04:48:56,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:56,968 INFO:     Epoch: 63
2022-11-28 04:48:57,642 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5365639660846103, 'Total loss': 0.5365639660846103} | train loss {'Reaction outcome loss': 0.45466594019484136, 'Total loss': 0.45466594019484136}
2022-11-28 04:48:57,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:57,642 INFO:     Epoch: 64
2022-11-28 04:48:58,316 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49300963228399103, 'Total loss': 0.49300963228399103} | train loss {'Reaction outcome loss': 0.45018776346959416, 'Total loss': 0.45018776346959416}
2022-11-28 04:48:58,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:58,316 INFO:     Epoch: 65
2022-11-28 04:48:58,986 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4895571158690886, 'Total loss': 0.4895571158690886} | train loss {'Reaction outcome loss': 0.4426714429451573, 'Total loss': 0.4426714429451573}
2022-11-28 04:48:58,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:58,986 INFO:     Epoch: 66
2022-11-28 04:48:59,657 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48192608898336237, 'Total loss': 0.48192608898336237} | train loss {'Reaction outcome loss': 0.45022589358831605, 'Total loss': 0.45022589358831605}
2022-11-28 04:48:59,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:48:59,657 INFO:     Epoch: 67
2022-11-28 04:49:00,332 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4814043542878194, 'Total loss': 0.4814043542878194} | train loss {'Reaction outcome loss': 0.45247205656262174, 'Total loss': 0.45247205656262174}
2022-11-28 04:49:00,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:00,334 INFO:     Epoch: 68
2022-11-28 04:49:01,001 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4764797287908467, 'Total loss': 0.4764797287908467} | train loss {'Reaction outcome loss': 0.4552774103658815, 'Total loss': 0.4552774103658815}
2022-11-28 04:49:01,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:01,001 INFO:     Epoch: 69
2022-11-28 04:49:01,669 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4963173368437724, 'Total loss': 0.4963173368437724} | train loss {'Reaction outcome loss': 0.45163855881940934, 'Total loss': 0.45163855881940934}
2022-11-28 04:49:01,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:01,669 INFO:     Epoch: 70
2022-11-28 04:49:02,341 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48863591558553954, 'Total loss': 0.48863591558553954} | train loss {'Reaction outcome loss': 0.45021419058884343, 'Total loss': 0.45021419058884343}
2022-11-28 04:49:02,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:02,341 INFO:     Epoch: 71
2022-11-28 04:49:03,014 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4712992987849496, 'Total loss': 0.4712992987849496} | train loss {'Reaction outcome loss': 0.4573699065874661, 'Total loss': 0.4573699065874661}
2022-11-28 04:49:03,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:03,014 INFO:     Epoch: 72
2022-11-28 04:49:03,685 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.460255516692996, 'Total loss': 0.460255516692996} | train loss {'Reaction outcome loss': 0.4475329214887273, 'Total loss': 0.4475329214887273}
2022-11-28 04:49:03,685 INFO:     Found new best model at epoch 72
2022-11-28 04:49:03,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:03,686 INFO:     Epoch: 73
2022-11-28 04:49:04,356 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46874612773006613, 'Total loss': 0.46874612773006613} | train loss {'Reaction outcome loss': 0.4564941583141204, 'Total loss': 0.4564941583141204}
2022-11-28 04:49:04,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:04,356 INFO:     Epoch: 74
2022-11-28 04:49:05,026 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5229445519772443, 'Total loss': 0.5229445519772443} | train loss {'Reaction outcome loss': 0.45482746043032213, 'Total loss': 0.45482746043032213}
2022-11-28 04:49:05,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:05,027 INFO:     Epoch: 75
2022-11-28 04:49:05,699 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4898680628023364, 'Total loss': 0.4898680628023364} | train loss {'Reaction outcome loss': 0.4505247596891657, 'Total loss': 0.4505247596891657}
2022-11-28 04:49:05,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:05,699 INFO:     Epoch: 76
2022-11-28 04:49:06,371 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49224182082848117, 'Total loss': 0.49224182082848117} | train loss {'Reaction outcome loss': 0.4567223376624526, 'Total loss': 0.4567223376624526}
2022-11-28 04:49:06,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:06,374 INFO:     Epoch: 77
2022-11-28 04:49:07,045 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48762408271431923, 'Total loss': 0.48762408271431923} | train loss {'Reaction outcome loss': 0.44862769243697964, 'Total loss': 0.44862769243697964}
2022-11-28 04:49:07,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:07,046 INFO:     Epoch: 78
2022-11-28 04:49:07,719 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47057716954838147, 'Total loss': 0.47057716954838147} | train loss {'Reaction outcome loss': 0.45244334115376394, 'Total loss': 0.45244334115376394}
2022-11-28 04:49:07,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:07,719 INFO:     Epoch: 79
2022-11-28 04:49:08,389 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49561160802841187, 'Total loss': 0.49561160802841187} | train loss {'Reaction outcome loss': 0.4529375016929642, 'Total loss': 0.4529375016929642}
2022-11-28 04:49:08,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:08,389 INFO:     Epoch: 80
2022-11-28 04:49:09,056 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5063537850298665, 'Total loss': 0.5063537850298665} | train loss {'Reaction outcome loss': 0.45251540902761683, 'Total loss': 0.45251540902761683}
2022-11-28 04:49:09,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:09,057 INFO:     Epoch: 81
2022-11-28 04:49:09,728 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4841327355666594, 'Total loss': 0.4841327355666594} | train loss {'Reaction outcome loss': 0.45508312115505817, 'Total loss': 0.45508312115505817}
2022-11-28 04:49:09,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:09,728 INFO:     Epoch: 82
2022-11-28 04:49:10,397 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49520511654290283, 'Total loss': 0.49520511654290283} | train loss {'Reaction outcome loss': 0.4561006327670428, 'Total loss': 0.4561006327670428}
2022-11-28 04:49:10,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:10,398 INFO:     Epoch: 83
2022-11-28 04:49:11,068 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5225177566436204, 'Total loss': 0.5225177566436204} | train loss {'Reaction outcome loss': 0.4530997379352489, 'Total loss': 0.4530997379352489}
2022-11-28 04:49:11,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:11,068 INFO:     Epoch: 84
2022-11-28 04:49:11,738 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5013457929546182, 'Total loss': 0.5013457929546182} | train loss {'Reaction outcome loss': 0.4625768908449719, 'Total loss': 0.4625768908449719}
2022-11-28 04:49:11,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:11,738 INFO:     Epoch: 85
2022-11-28 04:49:12,410 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4943073960867795, 'Total loss': 0.4943073960867795} | train loss {'Reaction outcome loss': 0.45442120256202834, 'Total loss': 0.45442120256202834}
2022-11-28 04:49:12,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:12,410 INFO:     Epoch: 86
2022-11-28 04:49:13,077 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.507961880415678, 'Total loss': 0.507961880415678} | train loss {'Reaction outcome loss': 0.4497479259847633, 'Total loss': 0.4497479259847633}
2022-11-28 04:49:13,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:13,077 INFO:     Epoch: 87
2022-11-28 04:49:13,746 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4845414730635556, 'Total loss': 0.4845414730635556} | train loss {'Reaction outcome loss': 0.4495635595953753, 'Total loss': 0.4495635595953753}
2022-11-28 04:49:13,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:13,746 INFO:     Epoch: 88
2022-11-28 04:49:14,413 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4985522668470036, 'Total loss': 0.4985522668470036} | train loss {'Reaction outcome loss': 0.4521994436339986, 'Total loss': 0.4521994436339986}
2022-11-28 04:49:14,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:14,413 INFO:     Epoch: 89
2022-11-28 04:49:15,082 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48874874582344835, 'Total loss': 0.48874874582344835} | train loss {'Reaction outcome loss': 0.45646255847907835, 'Total loss': 0.45646255847907835}
2022-11-28 04:49:15,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:15,082 INFO:     Epoch: 90
2022-11-28 04:49:15,752 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5164440856738524, 'Total loss': 0.5164440856738524} | train loss {'Reaction outcome loss': 0.450574797307772, 'Total loss': 0.450574797307772}
2022-11-28 04:49:15,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:15,752 INFO:     Epoch: 91
2022-11-28 04:49:16,418 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47783371298150584, 'Total loss': 0.47783371298150584} | train loss {'Reaction outcome loss': 0.4505552321432098, 'Total loss': 0.4505552321432098}
2022-11-28 04:49:16,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:16,418 INFO:     Epoch: 92
2022-11-28 04:49:17,083 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4735706533220681, 'Total loss': 0.4735706533220681} | train loss {'Reaction outcome loss': 0.45559122088936066, 'Total loss': 0.45559122088936066}
2022-11-28 04:49:17,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:17,083 INFO:     Epoch: 93
2022-11-28 04:49:17,747 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4858210838653825, 'Total loss': 0.4858210838653825} | train loss {'Reaction outcome loss': 0.45200709550971946, 'Total loss': 0.45200709550971946}
2022-11-28 04:49:17,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:17,747 INFO:     Epoch: 94
2022-11-28 04:49:18,414 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4998918358575214, 'Total loss': 0.4998918358575214} | train loss {'Reaction outcome loss': 0.45103499620792364, 'Total loss': 0.45103499620792364}
2022-11-28 04:49:18,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:18,415 INFO:     Epoch: 95
2022-11-28 04:49:19,081 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4800685027783567, 'Total loss': 0.4800685027783567} | train loss {'Reaction outcome loss': 0.45353174209594727, 'Total loss': 0.45353174209594727}
2022-11-28 04:49:19,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:19,081 INFO:     Epoch: 96
2022-11-28 04:49:19,748 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49778344516049733, 'Total loss': 0.49778344516049733} | train loss {'Reaction outcome loss': 0.45511977783133906, 'Total loss': 0.45511977783133906}
2022-11-28 04:49:19,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:19,749 INFO:     Epoch: 97
2022-11-28 04:49:20,416 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4849480695345185, 'Total loss': 0.4849480695345185} | train loss {'Reaction outcome loss': 0.44844358943162427, 'Total loss': 0.44844358943162427}
2022-11-28 04:49:20,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:20,417 INFO:     Epoch: 98
2022-11-28 04:49:21,081 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47726473821835086, 'Total loss': 0.47726473821835086} | train loss {'Reaction outcome loss': 0.4557956898164365, 'Total loss': 0.4557956898164365}
2022-11-28 04:49:21,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:21,082 INFO:     Epoch: 99
2022-11-28 04:49:21,745 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47790597074411134, 'Total loss': 0.47790597074411134} | train loss {'Reaction outcome loss': 0.44582034755618344, 'Total loss': 0.44582034755618344}
2022-11-28 04:49:21,745 INFO:     Best model found after epoch 73 of 100.
2022-11-28 04:49:21,746 INFO:   Done with stage: TRAINING
2022-11-28 04:49:21,746 INFO:   Starting stage: EVALUATION
2022-11-28 04:49:21,857 INFO:   Done with stage: EVALUATION
2022-11-28 04:49:21,857 INFO:   Leaving out SEQ value Fold_5
2022-11-28 04:49:21,870 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 04:49:21,870 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:49:22,509 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:49:22,509 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:49:22,579 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:49:22,579 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:49:22,579 INFO:     No hyperparam tuning for this model
2022-11-28 04:49:22,579 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:49:22,579 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:49:22,579 INFO:     None feature selector for col prot
2022-11-28 04:49:22,580 INFO:     None feature selector for col prot
2022-11-28 04:49:22,580 INFO:     None feature selector for col prot
2022-11-28 04:49:22,580 INFO:     None feature selector for col chem
2022-11-28 04:49:22,580 INFO:     None feature selector for col chem
2022-11-28 04:49:22,580 INFO:     None feature selector for col chem
2022-11-28 04:49:22,580 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:49:22,581 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:49:22,582 INFO:     Number of params in model 169651
2022-11-28 04:49:22,585 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:49:22,585 INFO:   Starting stage: TRAINING
2022-11-28 04:49:22,635 INFO:     Val loss before train {'Reaction outcome loss': 1.01791889694604, 'Total loss': 1.01791889694604}
2022-11-28 04:49:22,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:22,636 INFO:     Epoch: 0
2022-11-28 04:49:23,295 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5728749788620255, 'Total loss': 0.5728749788620255} | train loss {'Reaction outcome loss': 0.6923676740618483, 'Total loss': 0.6923676740618483}
2022-11-28 04:49:23,295 INFO:     Found new best model at epoch 0
2022-11-28 04:49:23,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:23,296 INFO:     Epoch: 1
2022-11-28 04:49:23,959 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5422844290733337, 'Total loss': 0.5422844290733337} | train loss {'Reaction outcome loss': 0.5901932384698622, 'Total loss': 0.5901932384698622}
2022-11-28 04:49:23,960 INFO:     Found new best model at epoch 1
2022-11-28 04:49:23,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:23,960 INFO:     Epoch: 2
2022-11-28 04:49:24,627 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.509319774129174, 'Total loss': 0.509319774129174} | train loss {'Reaction outcome loss': 0.5565131206906611, 'Total loss': 0.5565131206906611}
2022-11-28 04:49:24,628 INFO:     Found new best model at epoch 2
2022-11-28 04:49:24,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:24,628 INFO:     Epoch: 3
2022-11-28 04:49:25,292 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.513463789766485, 'Total loss': 0.513463789766485} | train loss {'Reaction outcome loss': 0.541183132437929, 'Total loss': 0.541183132437929}
2022-11-28 04:49:25,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:25,292 INFO:     Epoch: 4
2022-11-28 04:49:25,962 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5167717070064761, 'Total loss': 0.5167717070064761} | train loss {'Reaction outcome loss': 0.5239405181379088, 'Total loss': 0.5239405181379088}
2022-11-28 04:49:25,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:25,962 INFO:     Epoch: 5
2022-11-28 04:49:26,627 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5384795093400911, 'Total loss': 0.5384795093400911} | train loss {'Reaction outcome loss': 0.5165722010236594, 'Total loss': 0.5165722010236594}
2022-11-28 04:49:26,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:26,628 INFO:     Epoch: 6
2022-11-28 04:49:27,294 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5223061960529197, 'Total loss': 0.5223061960529197} | train loss {'Reaction outcome loss': 0.5144015289843082, 'Total loss': 0.5144015289843082}
2022-11-28 04:49:27,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:27,294 INFO:     Epoch: 7
2022-11-28 04:49:27,958 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4994269067590887, 'Total loss': 0.4994269067590887} | train loss {'Reaction outcome loss': 0.5071070582996453, 'Total loss': 0.5071070582996453}
2022-11-28 04:49:27,958 INFO:     Found new best model at epoch 7
2022-11-28 04:49:27,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:27,959 INFO:     Epoch: 8
2022-11-28 04:49:28,621 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49545530026609247, 'Total loss': 0.49545530026609247} | train loss {'Reaction outcome loss': 0.507663429564526, 'Total loss': 0.507663429564526}
2022-11-28 04:49:28,622 INFO:     Found new best model at epoch 8
2022-11-28 04:49:28,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:28,622 INFO:     Epoch: 9
2022-11-28 04:49:29,284 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5299094305797056, 'Total loss': 0.5299094305797056} | train loss {'Reaction outcome loss': 0.501634448886879, 'Total loss': 0.501634448886879}
2022-11-28 04:49:29,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:29,285 INFO:     Epoch: 10
2022-11-28 04:49:29,951 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49589291316541756, 'Total loss': 0.49589291316541756} | train loss {'Reaction outcome loss': 0.4967554609381383, 'Total loss': 0.4967554609381383}
2022-11-28 04:49:29,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:29,952 INFO:     Epoch: 11
2022-11-28 04:49:30,615 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4899089627645232, 'Total loss': 0.4899089627645232} | train loss {'Reaction outcome loss': 0.49681995454574784, 'Total loss': 0.49681995454574784}
2022-11-28 04:49:30,615 INFO:     Found new best model at epoch 11
2022-11-28 04:49:30,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:30,616 INFO:     Epoch: 12
2022-11-28 04:49:31,278 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4783142256465825, 'Total loss': 0.4783142256465825} | train loss {'Reaction outcome loss': 0.491489365877163, 'Total loss': 0.491489365877163}
2022-11-28 04:49:31,278 INFO:     Found new best model at epoch 12
2022-11-28 04:49:31,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:31,279 INFO:     Epoch: 13
2022-11-28 04:49:31,944 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47840832444754516, 'Total loss': 0.47840832444754516} | train loss {'Reaction outcome loss': 0.4965558932913888, 'Total loss': 0.4965558932913888}
2022-11-28 04:49:31,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:31,945 INFO:     Epoch: 14
2022-11-28 04:49:32,608 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5004990961063992, 'Total loss': 0.5004990961063992} | train loss {'Reaction outcome loss': 0.4839944832868153, 'Total loss': 0.4839944832868153}
2022-11-28 04:49:32,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:32,608 INFO:     Epoch: 15
2022-11-28 04:49:33,274 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5347446135499261, 'Total loss': 0.5347446135499261} | train loss {'Reaction outcome loss': 0.4854215662325582, 'Total loss': 0.4854215662325582}
2022-11-28 04:49:33,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:33,274 INFO:     Epoch: 16
2022-11-28 04:49:33,935 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4642337271097032, 'Total loss': 0.4642337271097032} | train loss {'Reaction outcome loss': 0.48725344703322454, 'Total loss': 0.48725344703322454}
2022-11-28 04:49:33,935 INFO:     Found new best model at epoch 16
2022-11-28 04:49:33,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:33,936 INFO:     Epoch: 17
2022-11-28 04:49:34,600 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48164728351614694, 'Total loss': 0.48164728351614694} | train loss {'Reaction outcome loss': 0.4857408889238873, 'Total loss': 0.4857408889238873}
2022-11-28 04:49:34,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:34,601 INFO:     Epoch: 18
2022-11-28 04:49:35,260 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5108821845867417, 'Total loss': 0.5108821845867417} | train loss {'Reaction outcome loss': 0.4828960408246325, 'Total loss': 0.4828960408246325}
2022-11-28 04:49:35,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:35,261 INFO:     Epoch: 19
2022-11-28 04:49:35,924 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4634808389977975, 'Total loss': 0.4634808389977975} | train loss {'Reaction outcome loss': 0.4798865566450742, 'Total loss': 0.4798865566450742}
2022-11-28 04:49:35,924 INFO:     Found new best model at epoch 19
2022-11-28 04:49:35,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:35,925 INFO:     Epoch: 20
2022-11-28 04:49:36,585 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46434198116714304, 'Total loss': 0.46434198116714304} | train loss {'Reaction outcome loss': 0.47336183608539645, 'Total loss': 0.47336183608539645}
2022-11-28 04:49:36,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:36,585 INFO:     Epoch: 21
2022-11-28 04:49:37,250 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48203708095984027, 'Total loss': 0.48203708095984027} | train loss {'Reaction outcome loss': 0.47808361942729644, 'Total loss': 0.47808361942729644}
2022-11-28 04:49:37,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:37,250 INFO:     Epoch: 22
2022-11-28 04:49:37,914 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5208075466481122, 'Total loss': 0.5208075466481122} | train loss {'Reaction outcome loss': 0.4756031030969274, 'Total loss': 0.4756031030969274}
2022-11-28 04:49:37,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:37,915 INFO:     Epoch: 23
2022-11-28 04:49:38,581 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45639874786138535, 'Total loss': 0.45639874786138535} | train loss {'Reaction outcome loss': 0.474691606006555, 'Total loss': 0.474691606006555}
2022-11-28 04:49:38,582 INFO:     Found new best model at epoch 23
2022-11-28 04:49:38,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:38,583 INFO:     Epoch: 24
2022-11-28 04:49:39,246 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5250030546025797, 'Total loss': 0.5250030546025797} | train loss {'Reaction outcome loss': 0.48009859908732677, 'Total loss': 0.48009859908732677}
2022-11-28 04:49:39,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:39,247 INFO:     Epoch: 25
2022-11-28 04:49:39,912 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4740170633251017, 'Total loss': 0.4740170633251017} | train loss {'Reaction outcome loss': 0.4780273665824244, 'Total loss': 0.4780273665824244}
2022-11-28 04:49:39,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:39,913 INFO:     Epoch: 26
2022-11-28 04:49:40,581 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47993499345400115, 'Total loss': 0.47993499345400115} | train loss {'Reaction outcome loss': 0.4689169121725905, 'Total loss': 0.4689169121725905}
2022-11-28 04:49:40,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:40,582 INFO:     Epoch: 27
2022-11-28 04:49:41,248 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47568661109967664, 'Total loss': 0.47568661109967664} | train loss {'Reaction outcome loss': 0.4775568105640911, 'Total loss': 0.4775568105640911}
2022-11-28 04:49:41,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:41,248 INFO:     Epoch: 28
2022-11-28 04:49:41,912 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4802862602201375, 'Total loss': 0.4802862602201375} | train loss {'Reaction outcome loss': 0.4724319380137228, 'Total loss': 0.4724319380137228}
2022-11-28 04:49:41,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:41,912 INFO:     Epoch: 29
2022-11-28 04:49:42,577 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5030381787906993, 'Total loss': 0.5030381787906993} | train loss {'Reaction outcome loss': 0.47974384765351014, 'Total loss': 0.47974384765351014}
2022-11-28 04:49:42,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:42,577 INFO:     Epoch: 30
2022-11-28 04:49:43,244 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46385497464375064, 'Total loss': 0.46385497464375064} | train loss {'Reaction outcome loss': 0.47670201554654107, 'Total loss': 0.47670201554654107}
2022-11-28 04:49:43,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:43,244 INFO:     Epoch: 31
2022-11-28 04:49:43,909 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46570548008788715, 'Total loss': 0.46570548008788715} | train loss {'Reaction outcome loss': 0.4795116703476637, 'Total loss': 0.4795116703476637}
2022-11-28 04:49:43,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:43,909 INFO:     Epoch: 32
2022-11-28 04:49:44,576 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4824484610422091, 'Total loss': 0.4824484610422091} | train loss {'Reaction outcome loss': 0.4780952964699076, 'Total loss': 0.4780952964699076}
2022-11-28 04:49:44,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:44,576 INFO:     Epoch: 33
2022-11-28 04:49:45,245 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4732204658741301, 'Total loss': 0.4732204658741301} | train loss {'Reaction outcome loss': 0.47032027186885955, 'Total loss': 0.47032027186885955}
2022-11-28 04:49:45,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:45,245 INFO:     Epoch: 34
2022-11-28 04:49:45,911 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4870241162451831, 'Total loss': 0.4870241162451831} | train loss {'Reaction outcome loss': 0.47372874599551, 'Total loss': 0.47372874599551}
2022-11-28 04:49:45,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:45,911 INFO:     Epoch: 35
2022-11-28 04:49:46,573 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47671637582508003, 'Total loss': 0.47671637582508003} | train loss {'Reaction outcome loss': 0.47248424181053716, 'Total loss': 0.47248424181053716}
2022-11-28 04:49:46,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:46,573 INFO:     Epoch: 36
2022-11-28 04:49:47,235 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47156704691323365, 'Total loss': 0.47156704691323365} | train loss {'Reaction outcome loss': 0.47708622089797453, 'Total loss': 0.47708622089797453}
2022-11-28 04:49:47,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:47,236 INFO:     Epoch: 37
2022-11-28 04:49:47,900 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4851153553886847, 'Total loss': 0.4851153553886847} | train loss {'Reaction outcome loss': 0.471818111236057, 'Total loss': 0.471818111236057}
2022-11-28 04:49:47,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:47,900 INFO:     Epoch: 38
2022-11-28 04:49:48,562 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47025632011619484, 'Total loss': 0.47025632011619484} | train loss {'Reaction outcome loss': 0.46493949188340095, 'Total loss': 0.46493949188340095}
2022-11-28 04:49:48,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:48,563 INFO:     Epoch: 39
2022-11-28 04:49:49,224 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5184795592318882, 'Total loss': 0.5184795592318882} | train loss {'Reaction outcome loss': 0.4679682236164808, 'Total loss': 0.4679682236164808}
2022-11-28 04:49:49,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:49,224 INFO:     Epoch: 40
2022-11-28 04:49:49,883 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4683463780040091, 'Total loss': 0.4683463780040091} | train loss {'Reaction outcome loss': 0.47717942766124205, 'Total loss': 0.47717942766124205}
2022-11-28 04:49:49,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:49,884 INFO:     Epoch: 41
2022-11-28 04:49:50,543 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44776958430355246, 'Total loss': 0.44776958430355246} | train loss {'Reaction outcome loss': 0.4717578934806009, 'Total loss': 0.4717578934806009}
2022-11-28 04:49:50,544 INFO:     Found new best model at epoch 41
2022-11-28 04:49:50,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:50,544 INFO:     Epoch: 42
2022-11-28 04:49:51,209 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4846647391942414, 'Total loss': 0.4846647391942414} | train loss {'Reaction outcome loss': 0.47699359984647843, 'Total loss': 0.47699359984647843}
2022-11-28 04:49:51,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:51,210 INFO:     Epoch: 43
2022-11-28 04:49:51,876 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4763286222111095, 'Total loss': 0.4763286222111095} | train loss {'Reaction outcome loss': 0.4721488438306316, 'Total loss': 0.4721488438306316}
2022-11-28 04:49:51,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:51,876 INFO:     Epoch: 44
2022-11-28 04:49:52,545 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49460055340420117, 'Total loss': 0.49460055340420117} | train loss {'Reaction outcome loss': 0.4710438344627619, 'Total loss': 0.4710438344627619}
2022-11-28 04:49:52,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:52,545 INFO:     Epoch: 45
2022-11-28 04:49:53,209 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5027762573551048, 'Total loss': 0.5027762573551048} | train loss {'Reaction outcome loss': 0.4691521254398169, 'Total loss': 0.4691521254398169}
2022-11-28 04:49:53,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:53,210 INFO:     Epoch: 46
2022-11-28 04:49:53,871 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5155395929786292, 'Total loss': 0.5155395929786292} | train loss {'Reaction outcome loss': 0.4708907881811742, 'Total loss': 0.4708907881811742}
2022-11-28 04:49:53,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:53,871 INFO:     Epoch: 47
2022-11-28 04:49:54,534 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47610609097914264, 'Total loss': 0.47610609097914264} | train loss {'Reaction outcome loss': 0.4648682366335584, 'Total loss': 0.4648682366335584}
2022-11-28 04:49:54,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:54,534 INFO:     Epoch: 48
2022-11-28 04:49:55,198 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4822140485048294, 'Total loss': 0.4822140485048294} | train loss {'Reaction outcome loss': 0.47365518413003416, 'Total loss': 0.47365518413003416}
2022-11-28 04:49:55,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:55,198 INFO:     Epoch: 49
2022-11-28 04:49:55,863 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5387843349440531, 'Total loss': 0.5387843349440531} | train loss {'Reaction outcome loss': 0.4725718059006237, 'Total loss': 0.4725718059006237}
2022-11-28 04:49:55,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:55,864 INFO:     Epoch: 50
2022-11-28 04:49:56,525 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4646672508256002, 'Total loss': 0.4646672508256002} | train loss {'Reaction outcome loss': 0.46181771675905875, 'Total loss': 0.46181771675905875}
2022-11-28 04:49:56,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:56,525 INFO:     Epoch: 51
2022-11-28 04:49:57,186 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4688174633139914, 'Total loss': 0.4688174633139914} | train loss {'Reaction outcome loss': 0.45936760396486326, 'Total loss': 0.45936760396486326}
2022-11-28 04:49:57,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:57,186 INFO:     Epoch: 52
2022-11-28 04:49:57,854 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4661308252675967, 'Total loss': 0.4661308252675967} | train loss {'Reaction outcome loss': 0.4644806270878161, 'Total loss': 0.4644806270878161}
2022-11-28 04:49:57,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:57,854 INFO:     Epoch: 53
2022-11-28 04:49:58,513 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.473558769646016, 'Total loss': 0.473558769646016} | train loss {'Reaction outcome loss': 0.4564320949176627, 'Total loss': 0.4564320949176627}
2022-11-28 04:49:58,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:58,514 INFO:     Epoch: 54
2022-11-28 04:49:59,175 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47043321417136624, 'Total loss': 0.47043321417136624} | train loss {'Reaction outcome loss': 0.46593767512709866, 'Total loss': 0.46593767512709866}
2022-11-28 04:49:59,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:59,175 INFO:     Epoch: 55
2022-11-28 04:49:59,839 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4954221255399964, 'Total loss': 0.4954221255399964} | train loss {'Reaction outcome loss': 0.46730014585679575, 'Total loss': 0.46730014585679575}
2022-11-28 04:49:59,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:49:59,839 INFO:     Epoch: 56
2022-11-28 04:50:00,504 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4960260811177167, 'Total loss': 0.4960260811177167} | train loss {'Reaction outcome loss': 0.46463615056728164, 'Total loss': 0.46463615056728164}
2022-11-28 04:50:00,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:00,504 INFO:     Epoch: 57
2022-11-28 04:50:01,166 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4891525652598251, 'Total loss': 0.4891525652598251} | train loss {'Reaction outcome loss': 0.4663420734145949, 'Total loss': 0.4663420734145949}
2022-11-28 04:50:01,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:01,166 INFO:     Epoch: 58
2022-11-28 04:50:01,828 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4947250062091784, 'Total loss': 0.4947250062091784} | train loss {'Reaction outcome loss': 0.4661255079291521, 'Total loss': 0.4661255079291521}
2022-11-28 04:50:01,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:01,828 INFO:     Epoch: 59
2022-11-28 04:50:02,489 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47801266001029447, 'Total loss': 0.47801266001029447} | train loss {'Reaction outcome loss': 0.46867717081500637, 'Total loss': 0.46867717081500637}
2022-11-28 04:50:02,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:02,491 INFO:     Epoch: 60
2022-11-28 04:50:03,154 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4730252393267371, 'Total loss': 0.4730252393267371} | train loss {'Reaction outcome loss': 0.4678667110781516, 'Total loss': 0.4678667110781516}
2022-11-28 04:50:03,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:03,154 INFO:     Epoch: 61
2022-11-28 04:50:03,818 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4650439030744813, 'Total loss': 0.4650439030744813} | train loss {'Reaction outcome loss': 0.4637999627739191, 'Total loss': 0.4637999627739191}
2022-11-28 04:50:03,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:03,819 INFO:     Epoch: 62
2022-11-28 04:50:04,484 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4895823479376056, 'Total loss': 0.4895823479376056} | train loss {'Reaction outcome loss': 0.4620321652581615, 'Total loss': 0.4620321652581615}
2022-11-28 04:50:04,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:04,484 INFO:     Epoch: 63
2022-11-28 04:50:05,145 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4810566969893195, 'Total loss': 0.4810566969893195} | train loss {'Reaction outcome loss': 0.46302669128823665, 'Total loss': 0.46302669128823665}
2022-11-28 04:50:05,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:05,146 INFO:     Epoch: 64
2022-11-28 04:50:05,805 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47293325615200127, 'Total loss': 0.47293325615200127} | train loss {'Reaction outcome loss': 0.4603450815043142, 'Total loss': 0.4603450815043142}
2022-11-28 04:50:05,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:05,806 INFO:     Epoch: 65
2022-11-28 04:50:06,466 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.463747575879097, 'Total loss': 0.463747575879097} | train loss {'Reaction outcome loss': 0.45245979005290615, 'Total loss': 0.45245979005290615}
2022-11-28 04:50:06,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:06,466 INFO:     Epoch: 66
2022-11-28 04:50:07,127 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4763958267867565, 'Total loss': 0.4763958267867565} | train loss {'Reaction outcome loss': 0.46146100981821936, 'Total loss': 0.46146100981821936}
2022-11-28 04:50:07,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:07,127 INFO:     Epoch: 67
2022-11-28 04:50:07,789 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4828239692883058, 'Total loss': 0.4828239692883058} | train loss {'Reaction outcome loss': 0.4629237368823059, 'Total loss': 0.4629237368823059}
2022-11-28 04:50:07,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:07,789 INFO:     Epoch: 68
2022-11-28 04:50:08,451 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45092056827111676, 'Total loss': 0.45092056827111676} | train loss {'Reaction outcome loss': 0.4660192891474693, 'Total loss': 0.4660192891474693}
2022-11-28 04:50:08,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:08,451 INFO:     Epoch: 69
2022-11-28 04:50:09,113 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4688016399741173, 'Total loss': 0.4688016399741173} | train loss {'Reaction outcome loss': 0.45958454762735673, 'Total loss': 0.45958454762735673}
2022-11-28 04:50:09,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:09,114 INFO:     Epoch: 70
2022-11-28 04:50:09,779 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5287562866102565, 'Total loss': 0.5287562866102565} | train loss {'Reaction outcome loss': 0.4694885793592661, 'Total loss': 0.4694885793592661}
2022-11-28 04:50:09,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:09,779 INFO:     Epoch: 71
2022-11-28 04:50:10,441 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48624313521114265, 'Total loss': 0.48624313521114265} | train loss {'Reaction outcome loss': 0.45694513919372715, 'Total loss': 0.45694513919372715}
2022-11-28 04:50:10,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:10,441 INFO:     Epoch: 72
2022-11-28 04:50:11,100 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4610318399288438, 'Total loss': 0.4610318399288438} | train loss {'Reaction outcome loss': 0.4598717583763984, 'Total loss': 0.4598717583763984}
2022-11-28 04:50:11,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:11,101 INFO:     Epoch: 73
2022-11-28 04:50:11,762 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48644178530031984, 'Total loss': 0.48644178530031984} | train loss {'Reaction outcome loss': 0.4608230375113987, 'Total loss': 0.4608230375113987}
2022-11-28 04:50:11,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:11,763 INFO:     Epoch: 74
2022-11-28 04:50:12,421 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4471100497652184, 'Total loss': 0.4471100497652184} | train loss {'Reaction outcome loss': 0.4591347188839028, 'Total loss': 0.4591347188839028}
2022-11-28 04:50:12,421 INFO:     Found new best model at epoch 74
2022-11-28 04:50:12,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:12,422 INFO:     Epoch: 75
2022-11-28 04:50:13,083 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46258156340230594, 'Total loss': 0.46258156340230594} | train loss {'Reaction outcome loss': 0.46115316426561725, 'Total loss': 0.46115316426561725}
2022-11-28 04:50:13,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:13,083 INFO:     Epoch: 76
2022-11-28 04:50:13,748 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4504258009520444, 'Total loss': 0.4504258009520444} | train loss {'Reaction outcome loss': 0.4593128828752425, 'Total loss': 0.4593128828752425}
2022-11-28 04:50:13,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:13,748 INFO:     Epoch: 77
2022-11-28 04:50:14,410 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48584911599755287, 'Total loss': 0.48584911599755287} | train loss {'Reaction outcome loss': 0.46524681883954233, 'Total loss': 0.46524681883954233}
2022-11-28 04:50:14,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:14,411 INFO:     Epoch: 78
2022-11-28 04:50:15,071 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4709870998154987, 'Total loss': 0.4709870998154987} | train loss {'Reaction outcome loss': 0.45772005533499105, 'Total loss': 0.45772005533499105}
2022-11-28 04:50:15,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:15,072 INFO:     Epoch: 79
2022-11-28 04:50:15,732 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4966565380719575, 'Total loss': 0.4966565380719575} | train loss {'Reaction outcome loss': 0.46147235374777545, 'Total loss': 0.46147235374777545}
2022-11-28 04:50:15,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:15,732 INFO:     Epoch: 80
2022-11-28 04:50:16,392 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4510006322102113, 'Total loss': 0.4510006322102113} | train loss {'Reaction outcome loss': 0.45845326727196095, 'Total loss': 0.45845326727196095}
2022-11-28 04:50:16,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:16,392 INFO:     Epoch: 81
2022-11-28 04:50:17,054 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5061778158626773, 'Total loss': 0.5061778158626773} | train loss {'Reaction outcome loss': 0.466263712714276, 'Total loss': 0.466263712714276}
2022-11-28 04:50:17,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:17,054 INFO:     Epoch: 82
2022-11-28 04:50:17,722 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.461324389685284, 'Total loss': 0.461324389685284} | train loss {'Reaction outcome loss': 0.45737193726123343, 'Total loss': 0.45737193726123343}
2022-11-28 04:50:17,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:17,722 INFO:     Epoch: 83
2022-11-28 04:50:18,392 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5079404840415175, 'Total loss': 0.5079404840415175} | train loss {'Reaction outcome loss': 0.4612360342495864, 'Total loss': 0.4612360342495864}
2022-11-28 04:50:18,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:18,392 INFO:     Epoch: 84
2022-11-28 04:50:19,057 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5273457450622862, 'Total loss': 0.5273457450622862} | train loss {'Reaction outcome loss': 0.4696707036346197, 'Total loss': 0.4696707036346197}
2022-11-28 04:50:19,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:19,058 INFO:     Epoch: 85
2022-11-28 04:50:19,727 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48107760467312555, 'Total loss': 0.48107760467312555} | train loss {'Reaction outcome loss': 0.46062750183045864, 'Total loss': 0.46062750183045864}
2022-11-28 04:50:19,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:19,727 INFO:     Epoch: 86
2022-11-28 04:50:20,396 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47569063576785003, 'Total loss': 0.47569063576785003} | train loss {'Reaction outcome loss': 0.45478380783911676, 'Total loss': 0.45478380783911676}
2022-11-28 04:50:20,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:20,396 INFO:     Epoch: 87
2022-11-28 04:50:21,065 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48609450832009315, 'Total loss': 0.48609450832009315} | train loss {'Reaction outcome loss': 0.458841641884177, 'Total loss': 0.458841641884177}
2022-11-28 04:50:21,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:21,065 INFO:     Epoch: 88
2022-11-28 04:50:21,735 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5160300643606619, 'Total loss': 0.5160300643606619} | train loss {'Reaction outcome loss': 0.46429159642467577, 'Total loss': 0.46429159642467577}
2022-11-28 04:50:21,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:21,736 INFO:     Epoch: 89
2022-11-28 04:50:22,406 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4506679593839429, 'Total loss': 0.4506679593839429} | train loss {'Reaction outcome loss': 0.4631189407119828, 'Total loss': 0.4631189407119828}
2022-11-28 04:50:22,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:22,406 INFO:     Epoch: 90
2022-11-28 04:50:23,073 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4937622533603148, 'Total loss': 0.4937622533603148} | train loss {'Reaction outcome loss': 0.4625926121708847, 'Total loss': 0.4625926121708847}
2022-11-28 04:50:23,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:23,074 INFO:     Epoch: 91
2022-11-28 04:50:23,742 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4926124594428323, 'Total loss': 0.4926124594428323} | train loss {'Reaction outcome loss': 0.4545371065577192, 'Total loss': 0.4545371065577192}
2022-11-28 04:50:23,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:23,743 INFO:     Epoch: 92
2022-11-28 04:50:24,408 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4936702092262832, 'Total loss': 0.4936702092262832} | train loss {'Reaction outcome loss': 0.45553466887964356, 'Total loss': 0.45553466887964356}
2022-11-28 04:50:24,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:24,409 INFO:     Epoch: 93
2022-11-28 04:50:25,078 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4732078682969917, 'Total loss': 0.4732078682969917} | train loss {'Reaction outcome loss': 0.46401323846751646, 'Total loss': 0.46401323846751646}
2022-11-28 04:50:25,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:25,078 INFO:     Epoch: 94
2022-11-28 04:50:25,746 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4620313210920854, 'Total loss': 0.4620313210920854} | train loss {'Reaction outcome loss': 0.45538558985196775, 'Total loss': 0.45538558985196775}
2022-11-28 04:50:25,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:25,746 INFO:     Epoch: 95
2022-11-28 04:50:26,413 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.502389389344237, 'Total loss': 0.502389389344237} | train loss {'Reaction outcome loss': 0.4617513541372553, 'Total loss': 0.4617513541372553}
2022-11-28 04:50:26,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:26,413 INFO:     Epoch: 96
2022-11-28 04:50:27,083 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5420711067589846, 'Total loss': 0.5420711067589846} | train loss {'Reaction outcome loss': 0.45784744325905075, 'Total loss': 0.45784744325905075}
2022-11-28 04:50:27,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:27,083 INFO:     Epoch: 97
2022-11-28 04:50:27,754 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4731433337385004, 'Total loss': 0.4731433337385004} | train loss {'Reaction outcome loss': 0.46048061309322236, 'Total loss': 0.46048061309322236}
2022-11-28 04:50:27,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:27,754 INFO:     Epoch: 98
2022-11-28 04:50:28,420 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4648354331200773, 'Total loss': 0.4648354331200773} | train loss {'Reaction outcome loss': 0.4569988102321663, 'Total loss': 0.4569988102321663}
2022-11-28 04:50:28,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:28,420 INFO:     Epoch: 99
2022-11-28 04:50:29,090 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47223906726999715, 'Total loss': 0.47223906726999715} | train loss {'Reaction outcome loss': 0.46494345353435607, 'Total loss': 0.46494345353435607}
2022-11-28 04:50:29,090 INFO:     Best model found after epoch 75 of 100.
2022-11-28 04:50:29,090 INFO:   Done with stage: TRAINING
2022-11-28 04:50:29,090 INFO:   Starting stage: EVALUATION
2022-11-28 04:50:29,203 INFO:   Done with stage: EVALUATION
2022-11-28 04:50:29,203 INFO:   Leaving out SEQ value Fold_6
2022-11-28 04:50:29,216 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 04:50:29,216 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:50:29,869 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:50:29,869 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:50:29,940 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:50:29,940 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:50:29,940 INFO:     No hyperparam tuning for this model
2022-11-28 04:50:29,940 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:50:29,940 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:50:29,941 INFO:     None feature selector for col prot
2022-11-28 04:50:29,941 INFO:     None feature selector for col prot
2022-11-28 04:50:29,941 INFO:     None feature selector for col prot
2022-11-28 04:50:29,942 INFO:     None feature selector for col chem
2022-11-28 04:50:29,942 INFO:     None feature selector for col chem
2022-11-28 04:50:29,942 INFO:     None feature selector for col chem
2022-11-28 04:50:29,942 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:50:29,942 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:50:29,944 INFO:     Number of params in model 169651
2022-11-28 04:50:29,947 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:50:29,947 INFO:   Starting stage: TRAINING
2022-11-28 04:50:29,998 INFO:     Val loss before train {'Reaction outcome loss': 0.9963457909497347, 'Total loss': 0.9963457909497347}
2022-11-28 04:50:29,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:29,998 INFO:     Epoch: 0
2022-11-28 04:50:30,669 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6371760307387873, 'Total loss': 0.6371760307387873} | train loss {'Reaction outcome loss': 0.695606206513701, 'Total loss': 0.695606206513701}
2022-11-28 04:50:30,670 INFO:     Found new best model at epoch 0
2022-11-28 04:50:30,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:30,670 INFO:     Epoch: 1
2022-11-28 04:50:31,338 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.578394085846164, 'Total loss': 0.578394085846164} | train loss {'Reaction outcome loss': 0.594523417312772, 'Total loss': 0.594523417312772}
2022-11-28 04:50:31,338 INFO:     Found new best model at epoch 1
2022-11-28 04:50:31,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:31,339 INFO:     Epoch: 2
2022-11-28 04:50:32,009 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.525027678094127, 'Total loss': 0.525027678094127} | train loss {'Reaction outcome loss': 0.5640390545370118, 'Total loss': 0.5640390545370118}
2022-11-28 04:50:32,009 INFO:     Found new best model at epoch 2
2022-11-28 04:50:32,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:32,010 INFO:     Epoch: 3
2022-11-28 04:50:32,677 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5443429628556425, 'Total loss': 0.5443429628556425} | train loss {'Reaction outcome loss': 0.5303602523861393, 'Total loss': 0.5303602523861393}
2022-11-28 04:50:32,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:32,678 INFO:     Epoch: 4
2022-11-28 04:50:33,346 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4930538846687837, 'Total loss': 0.4930538846687837} | train loss {'Reaction outcome loss': 0.5224694244924092, 'Total loss': 0.5224694244924092}
2022-11-28 04:50:33,346 INFO:     Found new best model at epoch 4
2022-11-28 04:50:33,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:33,347 INFO:     Epoch: 5
2022-11-28 04:50:34,016 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47000735659490933, 'Total loss': 0.47000735659490933} | train loss {'Reaction outcome loss': 0.5137173916784025, 'Total loss': 0.5137173916784025}
2022-11-28 04:50:34,017 INFO:     Found new best model at epoch 5
2022-11-28 04:50:34,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:34,018 INFO:     Epoch: 6
2022-11-28 04:50:34,683 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4863455505533652, 'Total loss': 0.4863455505533652} | train loss {'Reaction outcome loss': 0.49826180207873544, 'Total loss': 0.49826180207873544}
2022-11-28 04:50:34,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:34,683 INFO:     Epoch: 7
2022-11-28 04:50:35,350 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4777379740368236, 'Total loss': 0.4777379740368236} | train loss {'Reaction outcome loss': 0.4950915910904446, 'Total loss': 0.4950915910904446}
2022-11-28 04:50:35,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:35,350 INFO:     Epoch: 8
2022-11-28 04:50:36,017 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4853439446200024, 'Total loss': 0.4853439446200024} | train loss {'Reaction outcome loss': 0.4964387885204727, 'Total loss': 0.4964387885204727}
2022-11-28 04:50:36,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:36,017 INFO:     Epoch: 9
2022-11-28 04:50:36,687 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.484267841685902, 'Total loss': 0.484267841685902} | train loss {'Reaction outcome loss': 0.4967726598223371, 'Total loss': 0.4967726598223371}
2022-11-28 04:50:36,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:36,687 INFO:     Epoch: 10
2022-11-28 04:50:37,358 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48816627534953033, 'Total loss': 0.48816627534953033} | train loss {'Reaction outcome loss': 0.4821450160515885, 'Total loss': 0.4821450160515885}
2022-11-28 04:50:37,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:37,358 INFO:     Epoch: 11
2022-11-28 04:50:38,026 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4768354222178459, 'Total loss': 0.4768354222178459} | train loss {'Reaction outcome loss': 0.49000067846669304, 'Total loss': 0.49000067846669304}
2022-11-28 04:50:38,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:38,026 INFO:     Epoch: 12
2022-11-28 04:50:38,695 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48835197802294383, 'Total loss': 0.48835197802294383} | train loss {'Reaction outcome loss': 0.48689785203145397, 'Total loss': 0.48689785203145397}
2022-11-28 04:50:38,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:38,696 INFO:     Epoch: 13
2022-11-28 04:50:39,364 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47738121822476387, 'Total loss': 0.47738121822476387} | train loss {'Reaction outcome loss': 0.48725168551168135, 'Total loss': 0.48725168551168135}
2022-11-28 04:50:39,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:39,365 INFO:     Epoch: 14
2022-11-28 04:50:40,035 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4880786937746135, 'Total loss': 0.4880786937746135} | train loss {'Reaction outcome loss': 0.4847343931755712, 'Total loss': 0.4847343931755712}
2022-11-28 04:50:40,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:40,036 INFO:     Epoch: 15
2022-11-28 04:50:40,706 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46729233860969543, 'Total loss': 0.46729233860969543} | train loss {'Reaction outcome loss': 0.4869811980113868, 'Total loss': 0.4869811980113868}
2022-11-28 04:50:40,706 INFO:     Found new best model at epoch 15
2022-11-28 04:50:40,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:40,707 INFO:     Epoch: 16
2022-11-28 04:50:41,375 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49903547459027986, 'Total loss': 0.49903547459027986} | train loss {'Reaction outcome loss': 0.4868090164757544, 'Total loss': 0.4868090164757544}
2022-11-28 04:50:41,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:41,375 INFO:     Epoch: 17
2022-11-28 04:50:42,043 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4853126850317825, 'Total loss': 0.4853126850317825} | train loss {'Reaction outcome loss': 0.4796316170644376, 'Total loss': 0.4796316170644376}
2022-11-28 04:50:42,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:42,043 INFO:     Epoch: 18
2022-11-28 04:50:42,709 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47467398000034416, 'Total loss': 0.47467398000034416} | train loss {'Reaction outcome loss': 0.4680837112809381, 'Total loss': 0.4680837112809381}
2022-11-28 04:50:42,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:42,710 INFO:     Epoch: 19
2022-11-28 04:50:43,380 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48329918391325255, 'Total loss': 0.48329918391325255} | train loss {'Reaction outcome loss': 0.4761270948595578, 'Total loss': 0.4761270948595578}
2022-11-28 04:50:43,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:43,381 INFO:     Epoch: 20
2022-11-28 04:50:44,048 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47073063254356384, 'Total loss': 0.47073063254356384} | train loss {'Reaction outcome loss': 0.4776197670087699, 'Total loss': 0.4776197670087699}
2022-11-28 04:50:44,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:44,048 INFO:     Epoch: 21
2022-11-28 04:50:44,717 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4917445575649088, 'Total loss': 0.4917445575649088} | train loss {'Reaction outcome loss': 0.48252143945184445, 'Total loss': 0.48252143945184445}
2022-11-28 04:50:44,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:44,717 INFO:     Epoch: 22
2022-11-28 04:50:45,387 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4834760004146533, 'Total loss': 0.4834760004146533} | train loss {'Reaction outcome loss': 0.47384877725233954, 'Total loss': 0.47384877725233954}
2022-11-28 04:50:45,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:45,387 INFO:     Epoch: 23
2022-11-28 04:50:46,057 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46969813176176767, 'Total loss': 0.46969813176176767} | train loss {'Reaction outcome loss': 0.4695373154695957, 'Total loss': 0.4695373154695957}
2022-11-28 04:50:46,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:46,057 INFO:     Epoch: 24
2022-11-28 04:50:46,726 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48083382844924927, 'Total loss': 0.48083382844924927} | train loss {'Reaction outcome loss': 0.47944887219777993, 'Total loss': 0.47944887219777993}
2022-11-28 04:50:46,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:46,726 INFO:     Epoch: 25
2022-11-28 04:50:47,393 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46152721447023476, 'Total loss': 0.46152721447023476} | train loss {'Reaction outcome loss': 0.4751602215391974, 'Total loss': 0.4751602215391974}
2022-11-28 04:50:47,393 INFO:     Found new best model at epoch 25
2022-11-28 04:50:47,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:47,394 INFO:     Epoch: 26
2022-11-28 04:50:48,062 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4783253273503347, 'Total loss': 0.4783253273503347} | train loss {'Reaction outcome loss': 0.47333005653514015, 'Total loss': 0.47333005653514015}
2022-11-28 04:50:48,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:48,063 INFO:     Epoch: 27
2022-11-28 04:50:48,732 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4813949770548127, 'Total loss': 0.4813949770548127} | train loss {'Reaction outcome loss': 0.4701792185585345, 'Total loss': 0.4701792185585345}
2022-11-28 04:50:48,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:48,733 INFO:     Epoch: 28
2022-11-28 04:50:49,404 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4798024161295457, 'Total loss': 0.4798024161295457} | train loss {'Reaction outcome loss': 0.4722272263419244, 'Total loss': 0.4722272263419244}
2022-11-28 04:50:49,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:49,404 INFO:     Epoch: 29
2022-11-28 04:50:50,072 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48036776957186783, 'Total loss': 0.48036776957186783} | train loss {'Reaction outcome loss': 0.476394722418439, 'Total loss': 0.476394722418439}
2022-11-28 04:50:50,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:50,072 INFO:     Epoch: 30
2022-11-28 04:50:50,743 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4773508384823799, 'Total loss': 0.4773508384823799} | train loss {'Reaction outcome loss': 0.47473388555790147, 'Total loss': 0.47473388555790147}
2022-11-28 04:50:50,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:50,743 INFO:     Epoch: 31
2022-11-28 04:50:51,412 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4843260192058303, 'Total loss': 0.4843260192058303} | train loss {'Reaction outcome loss': 0.4751538497906539, 'Total loss': 0.4751538497906539}
2022-11-28 04:50:51,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:51,412 INFO:     Epoch: 32
2022-11-28 04:50:52,081 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5036767267368056, 'Total loss': 0.5036767267368056} | train loss {'Reaction outcome loss': 0.47493315446040324, 'Total loss': 0.47493315446040324}
2022-11-28 04:50:52,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:52,081 INFO:     Epoch: 33
2022-11-28 04:50:52,751 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4925477494570342, 'Total loss': 0.4925477494570342} | train loss {'Reaction outcome loss': 0.4745634225227179, 'Total loss': 0.4745634225227179}
2022-11-28 04:50:52,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:52,751 INFO:     Epoch: 34
2022-11-28 04:50:53,420 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48934935981577093, 'Total loss': 0.48934935981577093} | train loss {'Reaction outcome loss': 0.4748931340272388, 'Total loss': 0.4748931340272388}
2022-11-28 04:50:53,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:53,420 INFO:     Epoch: 35
2022-11-28 04:50:54,089 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45652528141032567, 'Total loss': 0.45652528141032567} | train loss {'Reaction outcome loss': 0.46937636255977616, 'Total loss': 0.46937636255977616}
2022-11-28 04:50:54,089 INFO:     Found new best model at epoch 35
2022-11-28 04:50:54,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:54,089 INFO:     Epoch: 36
2022-11-28 04:50:54,756 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.489506451243704, 'Total loss': 0.489506451243704} | train loss {'Reaction outcome loss': 0.47373945410213164, 'Total loss': 0.47373945410213164}
2022-11-28 04:50:54,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:54,756 INFO:     Epoch: 37
2022-11-28 04:50:55,426 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.488026019863107, 'Total loss': 0.488026019863107} | train loss {'Reaction outcome loss': 0.4734130083553253, 'Total loss': 0.4734130083553253}
2022-11-28 04:50:55,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:55,426 INFO:     Epoch: 38
2022-11-28 04:50:56,097 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4598857865414836, 'Total loss': 0.4598857865414836} | train loss {'Reaction outcome loss': 0.47166814631031406, 'Total loss': 0.47166814631031406}
2022-11-28 04:50:56,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:56,097 INFO:     Epoch: 39
2022-11-28 04:50:56,765 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46655683862892067, 'Total loss': 0.46655683862892067} | train loss {'Reaction outcome loss': 0.472768321092571, 'Total loss': 0.472768321092571}
2022-11-28 04:50:56,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:56,765 INFO:     Epoch: 40
2022-11-28 04:50:57,434 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5114035328680818, 'Total loss': 0.5114035328680818} | train loss {'Reaction outcome loss': 0.4649012348344249, 'Total loss': 0.4649012348344249}
2022-11-28 04:50:57,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:57,435 INFO:     Epoch: 41
2022-11-28 04:50:58,104 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48534929989413783, 'Total loss': 0.48534929989413783} | train loss {'Reaction outcome loss': 0.4714920963611334, 'Total loss': 0.4714920963611334}
2022-11-28 04:50:58,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:58,104 INFO:     Epoch: 42
2022-11-28 04:50:58,769 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4651820083910769, 'Total loss': 0.4651820083910769} | train loss {'Reaction outcome loss': 0.4789574382406089, 'Total loss': 0.4789574382406089}
2022-11-28 04:50:58,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:58,769 INFO:     Epoch: 43
2022-11-28 04:50:59,436 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4764419441873377, 'Total loss': 0.4764419441873377} | train loss {'Reaction outcome loss': 0.47052986427180227, 'Total loss': 0.47052986427180227}
2022-11-28 04:50:59,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:50:59,436 INFO:     Epoch: 44
2022-11-28 04:51:00,102 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4665240022269162, 'Total loss': 0.4665240022269162} | train loss {'Reaction outcome loss': 0.4743257318172724, 'Total loss': 0.4743257318172724}
2022-11-28 04:51:00,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:00,103 INFO:     Epoch: 45
2022-11-28 04:51:00,769 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46966971118341794, 'Total loss': 0.46966971118341794} | train loss {'Reaction outcome loss': 0.4699814419352239, 'Total loss': 0.4699814419352239}
2022-11-28 04:51:00,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:00,769 INFO:     Epoch: 46
2022-11-28 04:51:01,436 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46461785347624257, 'Total loss': 0.46461785347624257} | train loss {'Reaction outcome loss': 0.47214818697783256, 'Total loss': 0.47214818697783256}
2022-11-28 04:51:01,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:01,436 INFO:     Epoch: 47
2022-11-28 04:51:02,103 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4651724459095435, 'Total loss': 0.4651724459095435} | train loss {'Reaction outcome loss': 0.4745012714617675, 'Total loss': 0.4745012714617675}
2022-11-28 04:51:02,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:02,103 INFO:     Epoch: 48
2022-11-28 04:51:02,773 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4960494054989381, 'Total loss': 0.4960494054989381} | train loss {'Reaction outcome loss': 0.4726850640389227, 'Total loss': 0.4726850640389227}
2022-11-28 04:51:02,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:02,773 INFO:     Epoch: 49
2022-11-28 04:51:03,439 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5449831157245419, 'Total loss': 0.5449831157245419} | train loss {'Reaction outcome loss': 0.46481674380840793, 'Total loss': 0.46481674380840793}
2022-11-28 04:51:03,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:03,439 INFO:     Epoch: 50
2022-11-28 04:51:04,104 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48056160286068916, 'Total loss': 0.48056160286068916} | train loss {'Reaction outcome loss': 0.4734725547774184, 'Total loss': 0.4734725547774184}
2022-11-28 04:51:04,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:04,104 INFO:     Epoch: 51
2022-11-28 04:51:04,770 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5111005245284601, 'Total loss': 0.5111005245284601} | train loss {'Reaction outcome loss': 0.46588904699010236, 'Total loss': 0.46588904699010236}
2022-11-28 04:51:04,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:04,771 INFO:     Epoch: 52
2022-11-28 04:51:05,436 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44758895445953717, 'Total loss': 0.44758895445953717} | train loss {'Reaction outcome loss': 0.4713357272407701, 'Total loss': 0.4713357272407701}
2022-11-28 04:51:05,436 INFO:     Found new best model at epoch 52
2022-11-28 04:51:05,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:05,437 INFO:     Epoch: 53
2022-11-28 04:51:06,101 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4639504145492207, 'Total loss': 0.4639504145492207} | train loss {'Reaction outcome loss': 0.47169461945492414, 'Total loss': 0.47169461945492414}
2022-11-28 04:51:06,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:06,101 INFO:     Epoch: 54
2022-11-28 04:51:06,769 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4650070128793066, 'Total loss': 0.4650070128793066} | train loss {'Reaction outcome loss': 0.4692978280326051, 'Total loss': 0.4692978280326051}
2022-11-28 04:51:06,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:06,769 INFO:     Epoch: 55
2022-11-28 04:51:07,437 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47724752161990514, 'Total loss': 0.47724752161990514} | train loss {'Reaction outcome loss': 0.47245231547182603, 'Total loss': 0.47245231547182603}
2022-11-28 04:51:07,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:07,437 INFO:     Epoch: 56
2022-11-28 04:51:08,104 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5180266126990318, 'Total loss': 0.5180266126990318} | train loss {'Reaction outcome loss': 0.4686681001537269, 'Total loss': 0.4686681001537269}
2022-11-28 04:51:08,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:08,104 INFO:     Epoch: 57
2022-11-28 04:51:08,771 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4778171476315368, 'Total loss': 0.4778171476315368} | train loss {'Reaction outcome loss': 0.47208822055930094, 'Total loss': 0.47208822055930094}
2022-11-28 04:51:08,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:08,771 INFO:     Epoch: 58
2022-11-28 04:51:09,440 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45452654700387607, 'Total loss': 0.45452654700387607} | train loss {'Reaction outcome loss': 0.46952799154866126, 'Total loss': 0.46952799154866126}
2022-11-28 04:51:09,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:09,440 INFO:     Epoch: 59
2022-11-28 04:51:10,109 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4758678156543862, 'Total loss': 0.4758678156543862} | train loss {'Reaction outcome loss': 0.4681197529238078, 'Total loss': 0.4681197529238078}
2022-11-28 04:51:10,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:10,109 INFO:     Epoch: 60
2022-11-28 04:51:10,776 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4502321021123366, 'Total loss': 0.4502321021123366} | train loss {'Reaction outcome loss': 0.47247137606985146, 'Total loss': 0.47247137606985146}
2022-11-28 04:51:10,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:10,777 INFO:     Epoch: 61
2022-11-28 04:51:11,445 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48353333466432313, 'Total loss': 0.48353333466432313} | train loss {'Reaction outcome loss': 0.46987787880484133, 'Total loss': 0.46987787880484133}
2022-11-28 04:51:11,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:11,445 INFO:     Epoch: 62
2022-11-28 04:51:12,112 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.481947181915695, 'Total loss': 0.481947181915695} | train loss {'Reaction outcome loss': 0.4713564909574005, 'Total loss': 0.4713564909574005}
2022-11-28 04:51:12,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:12,112 INFO:     Epoch: 63
2022-11-28 04:51:12,779 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5250193984671072, 'Total loss': 0.5250193984671072} | train loss {'Reaction outcome loss': 0.47640049397464723, 'Total loss': 0.47640049397464723}
2022-11-28 04:51:12,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:12,779 INFO:     Epoch: 64
2022-11-28 04:51:13,445 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4679747481237758, 'Total loss': 0.4679747481237758} | train loss {'Reaction outcome loss': 0.4721579170455375, 'Total loss': 0.4721579170455375}
2022-11-28 04:51:13,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:13,445 INFO:     Epoch: 65
2022-11-28 04:51:14,112 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.465239365669814, 'Total loss': 0.465239365669814} | train loss {'Reaction outcome loss': 0.4702710869211343, 'Total loss': 0.4702710869211343}
2022-11-28 04:51:14,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:14,112 INFO:     Epoch: 66
2022-11-28 04:51:14,777 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4939615892415697, 'Total loss': 0.4939615892415697} | train loss {'Reaction outcome loss': 0.46780575211009673, 'Total loss': 0.46780575211009673}
2022-11-28 04:51:14,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:14,777 INFO:     Epoch: 67
2022-11-28 04:51:15,441 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4575521813874895, 'Total loss': 0.4575521813874895} | train loss {'Reaction outcome loss': 0.47648911688837314, 'Total loss': 0.47648911688837314}
2022-11-28 04:51:15,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:15,441 INFO:     Epoch: 68
2022-11-28 04:51:16,107 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.478791302239353, 'Total loss': 0.478791302239353} | train loss {'Reaction outcome loss': 0.47391072038801446, 'Total loss': 0.47391072038801446}
2022-11-28 04:51:16,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:16,107 INFO:     Epoch: 69
2022-11-28 04:51:16,777 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48800050941380585, 'Total loss': 0.48800050941380585} | train loss {'Reaction outcome loss': 0.4711673631663284, 'Total loss': 0.4711673631663284}
2022-11-28 04:51:16,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:16,777 INFO:     Epoch: 70
2022-11-28 04:51:17,442 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46201021393591707, 'Total loss': 0.46201021393591707} | train loss {'Reaction outcome loss': 0.4736604721195275, 'Total loss': 0.4736604721195275}
2022-11-28 04:51:17,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:17,443 INFO:     Epoch: 71
2022-11-28 04:51:18,109 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4580272138118744, 'Total loss': 0.4580272138118744} | train loss {'Reaction outcome loss': 0.468442267888496, 'Total loss': 0.468442267888496}
2022-11-28 04:51:18,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:18,109 INFO:     Epoch: 72
2022-11-28 04:51:18,778 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47025053203105927, 'Total loss': 0.47025053203105927} | train loss {'Reaction outcome loss': 0.48189500022319054, 'Total loss': 0.48189500022319054}
2022-11-28 04:51:18,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:18,778 INFO:     Epoch: 73
2022-11-28 04:51:19,444 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4839137162674557, 'Total loss': 0.4839137162674557} | train loss {'Reaction outcome loss': 0.46713025567512356, 'Total loss': 0.46713025567512356}
2022-11-28 04:51:19,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:19,444 INFO:     Epoch: 74
2022-11-28 04:51:20,109 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.500479633835229, 'Total loss': 0.500479633835229} | train loss {'Reaction outcome loss': 0.4694171655142019, 'Total loss': 0.4694171655142019}
2022-11-28 04:51:20,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:20,109 INFO:     Epoch: 75
2022-11-28 04:51:20,773 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47454947233200073, 'Total loss': 0.47454947233200073} | train loss {'Reaction outcome loss': 0.47222596316808657, 'Total loss': 0.47222596316808657}
2022-11-28 04:51:20,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:20,773 INFO:     Epoch: 76
2022-11-28 04:51:21,439 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5156449221751906, 'Total loss': 0.5156449221751906} | train loss {'Reaction outcome loss': 0.4760569633255082, 'Total loss': 0.4760569633255082}
2022-11-28 04:51:21,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:21,439 INFO:     Epoch: 77
2022-11-28 04:51:22,103 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4514784101735462, 'Total loss': 0.4514784101735462} | train loss {'Reaction outcome loss': 0.47104248915228153, 'Total loss': 0.47104248915228153}
2022-11-28 04:51:22,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:22,103 INFO:     Epoch: 78
2022-11-28 04:51:22,766 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4638350341807712, 'Total loss': 0.4638350341807712} | train loss {'Reaction outcome loss': 0.4727263668732297, 'Total loss': 0.4727263668732297}
2022-11-28 04:51:22,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:22,766 INFO:     Epoch: 79
2022-11-28 04:51:23,433 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5005979703908617, 'Total loss': 0.5005979703908617} | train loss {'Reaction outcome loss': 0.46977632138277253, 'Total loss': 0.46977632138277253}
2022-11-28 04:51:23,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:23,434 INFO:     Epoch: 80
2022-11-28 04:51:24,096 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5215184553103014, 'Total loss': 0.5215184553103014} | train loss {'Reaction outcome loss': 0.47886777308679396, 'Total loss': 0.47886777308679396}
2022-11-28 04:51:24,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:24,096 INFO:     Epoch: 81
2022-11-28 04:51:24,765 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4695610874755816, 'Total loss': 0.4695610874755816} | train loss {'Reaction outcome loss': 0.4688086689359719, 'Total loss': 0.4688086689359719}
2022-11-28 04:51:24,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:24,765 INFO:     Epoch: 82
2022-11-28 04:51:25,434 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4741102836348794, 'Total loss': 0.4741102836348794} | train loss {'Reaction outcome loss': 0.48093857075418195, 'Total loss': 0.48093857075418195}
2022-11-28 04:51:25,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:25,434 INFO:     Epoch: 83
2022-11-28 04:51:26,104 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49304031242023816, 'Total loss': 0.49304031242023816} | train loss {'Reaction outcome loss': 0.47434389152594153, 'Total loss': 0.47434389152594153}
2022-11-28 04:51:26,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:26,104 INFO:     Epoch: 84
2022-11-28 04:51:26,771 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4648160849782554, 'Total loss': 0.4648160849782554} | train loss {'Reaction outcome loss': 0.46862977322551513, 'Total loss': 0.46862977322551513}
2022-11-28 04:51:26,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:26,771 INFO:     Epoch: 85
2022-11-28 04:51:27,438 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49016139656305313, 'Total loss': 0.49016139656305313} | train loss {'Reaction outcome loss': 0.4703885599850647, 'Total loss': 0.4703885599850647}
2022-11-28 04:51:27,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:27,439 INFO:     Epoch: 86
2022-11-28 04:51:28,104 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46568293564698915, 'Total loss': 0.46568293564698915} | train loss {'Reaction outcome loss': 0.47153374301870504, 'Total loss': 0.47153374301870504}
2022-11-28 04:51:28,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:28,104 INFO:     Epoch: 87
2022-11-28 04:51:28,771 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4796460724689744, 'Total loss': 0.4796460724689744} | train loss {'Reaction outcome loss': 0.46730752409465853, 'Total loss': 0.46730752409465853}
2022-11-28 04:51:28,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:28,771 INFO:     Epoch: 88
2022-11-28 04:51:29,435 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48214379020712594, 'Total loss': 0.48214379020712594} | train loss {'Reaction outcome loss': 0.4706585600731834, 'Total loss': 0.4706585600731834}
2022-11-28 04:51:29,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:29,435 INFO:     Epoch: 89
2022-11-28 04:51:30,103 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4721381271427328, 'Total loss': 0.4721381271427328} | train loss {'Reaction outcome loss': 0.47529843635857105, 'Total loss': 0.47529843635857105}
2022-11-28 04:51:30,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:30,103 INFO:     Epoch: 90
2022-11-28 04:51:30,773 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4854450219056823, 'Total loss': 0.4854450219056823} | train loss {'Reaction outcome loss': 0.47891432215129176, 'Total loss': 0.47891432215129176}
2022-11-28 04:51:30,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:30,773 INFO:     Epoch: 91
2022-11-28 04:51:31,440 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4898145923560316, 'Total loss': 0.4898145923560316} | train loss {'Reaction outcome loss': 0.4707436169227285, 'Total loss': 0.4707436169227285}
2022-11-28 04:51:31,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:31,440 INFO:     Epoch: 92
2022-11-28 04:51:32,110 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4781409894878214, 'Total loss': 0.4781409894878214} | train loss {'Reaction outcome loss': 0.4755200450458834, 'Total loss': 0.4755200450458834}
2022-11-28 04:51:32,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:32,111 INFO:     Epoch: 93
2022-11-28 04:51:32,782 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46719005703926086, 'Total loss': 0.46719005703926086} | train loss {'Reaction outcome loss': 0.4683327574523226, 'Total loss': 0.4683327574523226}
2022-11-28 04:51:32,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:32,783 INFO:     Epoch: 94
2022-11-28 04:51:33,449 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.467438361861489, 'Total loss': 0.467438361861489} | train loss {'Reaction outcome loss': 0.47348438641957696, 'Total loss': 0.47348438641957696}
2022-11-28 04:51:33,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:33,449 INFO:     Epoch: 95
2022-11-28 04:51:34,117 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47136289558627387, 'Total loss': 0.47136289558627387} | train loss {'Reaction outcome loss': 0.4716199830534958, 'Total loss': 0.4716199830534958}
2022-11-28 04:51:34,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:34,117 INFO:     Epoch: 96
2022-11-28 04:51:34,787 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46360845931551675, 'Total loss': 0.46360845931551675} | train loss {'Reaction outcome loss': 0.4779742357711638, 'Total loss': 0.4779742357711638}
2022-11-28 04:51:34,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:34,788 INFO:     Epoch: 97
2022-11-28 04:51:35,458 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.485328212719072, 'Total loss': 0.485328212719072} | train loss {'Reaction outcome loss': 0.4658784204793553, 'Total loss': 0.4658784204793553}
2022-11-28 04:51:35,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:35,459 INFO:     Epoch: 98
2022-11-28 04:51:36,128 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4640909623016011, 'Total loss': 0.4640909623016011} | train loss {'Reaction outcome loss': 0.4694542880019834, 'Total loss': 0.4694542880019834}
2022-11-28 04:51:36,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:36,128 INFO:     Epoch: 99
2022-11-28 04:51:36,799 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4755304320292039, 'Total loss': 0.4755304320292039} | train loss {'Reaction outcome loss': 0.46697123781327277, 'Total loss': 0.46697123781327277}
2022-11-28 04:51:36,799 INFO:     Best model found after epoch 53 of 100.
2022-11-28 04:51:36,799 INFO:   Done with stage: TRAINING
2022-11-28 04:51:36,799 INFO:   Starting stage: EVALUATION
2022-11-28 04:51:36,912 INFO:   Done with stage: EVALUATION
2022-11-28 04:51:36,912 INFO:   Leaving out SEQ value Fold_7
2022-11-28 04:51:36,925 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 04:51:36,925 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:51:37,582 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:51:37,582 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:51:37,651 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:51:37,651 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:51:37,651 INFO:     No hyperparam tuning for this model
2022-11-28 04:51:37,651 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:51:37,651 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:51:37,652 INFO:     None feature selector for col prot
2022-11-28 04:51:37,652 INFO:     None feature selector for col prot
2022-11-28 04:51:37,652 INFO:     None feature selector for col prot
2022-11-28 04:51:37,653 INFO:     None feature selector for col chem
2022-11-28 04:51:37,653 INFO:     None feature selector for col chem
2022-11-28 04:51:37,653 INFO:     None feature selector for col chem
2022-11-28 04:51:37,653 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:51:37,653 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:51:37,654 INFO:     Number of params in model 169651
2022-11-28 04:51:37,657 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:51:37,657 INFO:   Starting stage: TRAINING
2022-11-28 04:51:37,707 INFO:     Val loss before train {'Reaction outcome loss': 1.0613343604775363, 'Total loss': 1.0613343604775363}
2022-11-28 04:51:37,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:37,708 INFO:     Epoch: 0
2022-11-28 04:51:38,365 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.640056989913763, 'Total loss': 0.640056989913763} | train loss {'Reaction outcome loss': 0.6745679593477093, 'Total loss': 0.6745679593477093}
2022-11-28 04:51:38,365 INFO:     Found new best model at epoch 0
2022-11-28 04:51:38,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:38,366 INFO:     Epoch: 1
2022-11-28 04:51:39,025 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5772043272506359, 'Total loss': 0.5772043272506359} | train loss {'Reaction outcome loss': 0.5628782424037574, 'Total loss': 0.5628782424037574}
2022-11-28 04:51:39,025 INFO:     Found new best model at epoch 1
2022-11-28 04:51:39,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:39,026 INFO:     Epoch: 2
2022-11-28 04:51:39,683 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5735495326130889, 'Total loss': 0.5735495326130889} | train loss {'Reaction outcome loss': 0.543390442418759, 'Total loss': 0.543390442418759}
2022-11-28 04:51:39,683 INFO:     Found new best model at epoch 2
2022-11-28 04:51:39,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:39,683 INFO:     Epoch: 3
2022-11-28 04:51:40,341 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5579729322777238, 'Total loss': 0.5579729322777238} | train loss {'Reaction outcome loss': 0.5269182928395076, 'Total loss': 0.5269182928395076}
2022-11-28 04:51:40,341 INFO:     Found new best model at epoch 3
2022-11-28 04:51:40,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:40,342 INFO:     Epoch: 4
2022-11-28 04:51:41,001 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5148320710936258, 'Total loss': 0.5148320710936258} | train loss {'Reaction outcome loss': 0.5144533186418111, 'Total loss': 0.5144533186418111}
2022-11-28 04:51:41,001 INFO:     Found new best model at epoch 4
2022-11-28 04:51:41,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:41,002 INFO:     Epoch: 5
2022-11-28 04:51:41,663 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5095227603302446, 'Total loss': 0.5095227603302446} | train loss {'Reaction outcome loss': 0.5024646736803602, 'Total loss': 0.5024646736803602}
2022-11-28 04:51:41,664 INFO:     Found new best model at epoch 5
2022-11-28 04:51:41,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:41,665 INFO:     Epoch: 6
2022-11-28 04:51:42,323 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5333058397437251, 'Total loss': 0.5333058397437251} | train loss {'Reaction outcome loss': 0.49835673377650686, 'Total loss': 0.49835673377650686}
2022-11-28 04:51:42,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:42,323 INFO:     Epoch: 7
2022-11-28 04:51:42,982 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5246430753275405, 'Total loss': 0.5246430753275405} | train loss {'Reaction outcome loss': 0.48633803341720927, 'Total loss': 0.48633803341720927}
2022-11-28 04:51:42,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:42,983 INFO:     Epoch: 8
2022-11-28 04:51:43,642 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5193393060634303, 'Total loss': 0.5193393060634303} | train loss {'Reaction outcome loss': 0.4840245060011989, 'Total loss': 0.4840245060011989}
2022-11-28 04:51:43,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:43,642 INFO:     Epoch: 9
2022-11-28 04:51:44,298 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5481722174688827, 'Total loss': 0.5481722174688827} | train loss {'Reaction outcome loss': 0.48776280122702237, 'Total loss': 0.48776280122702237}
2022-11-28 04:51:44,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:44,299 INFO:     Epoch: 10
2022-11-28 04:51:44,962 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5008465973443763, 'Total loss': 0.5008465973443763} | train loss {'Reaction outcome loss': 0.47802807610543047, 'Total loss': 0.47802807610543047}
2022-11-28 04:51:44,962 INFO:     Found new best model at epoch 10
2022-11-28 04:51:44,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:44,963 INFO:     Epoch: 11
2022-11-28 04:51:45,623 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47883338013360666, 'Total loss': 0.47883338013360666} | train loss {'Reaction outcome loss': 0.4759438587505309, 'Total loss': 0.4759438587505309}
2022-11-28 04:51:45,623 INFO:     Found new best model at epoch 11
2022-11-28 04:51:45,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:45,623 INFO:     Epoch: 12
2022-11-28 04:51:46,279 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4872730665428694, 'Total loss': 0.4872730665428694} | train loss {'Reaction outcome loss': 0.47032387811140935, 'Total loss': 0.47032387811140935}
2022-11-28 04:51:46,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:46,279 INFO:     Epoch: 13
2022-11-28 04:51:46,938 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5000585116619287, 'Total loss': 0.5000585116619287} | train loss {'Reaction outcome loss': 0.4633525371795795, 'Total loss': 0.4633525371795795}
2022-11-28 04:51:46,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:46,938 INFO:     Epoch: 14
2022-11-28 04:51:47,596 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5268815988025, 'Total loss': 0.5268815988025} | train loss {'Reaction outcome loss': 0.46499361116133753, 'Total loss': 0.46499361116133753}
2022-11-28 04:51:47,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:47,596 INFO:     Epoch: 15
2022-11-28 04:51:48,254 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5092425069143606, 'Total loss': 0.5092425069143606} | train loss {'Reaction outcome loss': 0.479036558602677, 'Total loss': 0.479036558602677}
2022-11-28 04:51:48,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:48,254 INFO:     Epoch: 16
2022-11-28 04:51:48,917 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46765826434590096, 'Total loss': 0.46765826434590096} | train loss {'Reaction outcome loss': 0.4634764607018623, 'Total loss': 0.4634764607018623}
2022-11-28 04:51:48,917 INFO:     Found new best model at epoch 16
2022-11-28 04:51:48,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:48,918 INFO:     Epoch: 17
2022-11-28 04:51:49,575 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5083469991074052, 'Total loss': 0.5083469991074052} | train loss {'Reaction outcome loss': 0.46690348041106444, 'Total loss': 0.46690348041106444}
2022-11-28 04:51:49,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:49,576 INFO:     Epoch: 18
2022-11-28 04:51:50,233 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4804132726303367, 'Total loss': 0.4804132726303367} | train loss {'Reaction outcome loss': 0.4764252812525288, 'Total loss': 0.4764252812525288}
2022-11-28 04:51:50,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:50,233 INFO:     Epoch: 19
2022-11-28 04:51:50,893 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48985776825006616, 'Total loss': 0.48985776825006616} | train loss {'Reaction outcome loss': 0.46723293079460254, 'Total loss': 0.46723293079460254}
2022-11-28 04:51:50,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:50,893 INFO:     Epoch: 20
2022-11-28 04:51:51,550 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48659299556599106, 'Total loss': 0.48659299556599106} | train loss {'Reaction outcome loss': 0.46263255624741806, 'Total loss': 0.46263255624741806}
2022-11-28 04:51:51,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:51,550 INFO:     Epoch: 21
2022-11-28 04:51:52,210 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4853411562914072, 'Total loss': 0.4853411562914072} | train loss {'Reaction outcome loss': 0.45836886446006964, 'Total loss': 0.45836886446006964}
2022-11-28 04:51:52,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:52,210 INFO:     Epoch: 22
2022-11-28 04:51:52,870 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4849323997663897, 'Total loss': 0.4849323997663897} | train loss {'Reaction outcome loss': 0.4661601493593122, 'Total loss': 0.4661601493593122}
2022-11-28 04:51:52,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:52,870 INFO:     Epoch: 23
2022-11-28 04:51:53,532 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46143078006977256, 'Total loss': 0.46143078006977256} | train loss {'Reaction outcome loss': 0.4653610687275402, 'Total loss': 0.4653610687275402}
2022-11-28 04:51:53,532 INFO:     Found new best model at epoch 23
2022-11-28 04:51:53,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:53,533 INFO:     Epoch: 24
2022-11-28 04:51:54,190 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45327223213606105, 'Total loss': 0.45327223213606105} | train loss {'Reaction outcome loss': 0.4615442797114126, 'Total loss': 0.4615442797114126}
2022-11-28 04:51:54,190 INFO:     Found new best model at epoch 24
2022-11-28 04:51:54,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:54,191 INFO:     Epoch: 25
2022-11-28 04:51:54,850 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4620624364808548, 'Total loss': 0.4620624364808548} | train loss {'Reaction outcome loss': 0.45864835399828974, 'Total loss': 0.45864835399828974}
2022-11-28 04:51:54,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:54,850 INFO:     Epoch: 26
2022-11-28 04:51:55,507 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49910226256348367, 'Total loss': 0.49910226256348367} | train loss {'Reaction outcome loss': 0.45717635579773636, 'Total loss': 0.45717635579773636}
2022-11-28 04:51:55,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:55,507 INFO:     Epoch: 27
2022-11-28 04:51:56,167 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4935289604026218, 'Total loss': 0.4935289604026218} | train loss {'Reaction outcome loss': 0.4644472451239336, 'Total loss': 0.4644472451239336}
2022-11-28 04:51:56,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:56,167 INFO:     Epoch: 28
2022-11-28 04:51:56,822 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46613397709158966, 'Total loss': 0.46613397709158966} | train loss {'Reaction outcome loss': 0.4672756069874177, 'Total loss': 0.4672756069874177}
2022-11-28 04:51:56,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:56,822 INFO:     Epoch: 29
2022-11-28 04:51:57,475 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4959528622932212, 'Total loss': 0.4959528622932212} | train loss {'Reaction outcome loss': 0.4605925367137448, 'Total loss': 0.4605925367137448}
2022-11-28 04:51:57,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:57,475 INFO:     Epoch: 30
2022-11-28 04:51:58,130 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.461773858513943, 'Total loss': 0.461773858513943} | train loss {'Reaction outcome loss': 0.4594387445659911, 'Total loss': 0.4594387445659911}
2022-11-28 04:51:58,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:58,131 INFO:     Epoch: 31
2022-11-28 04:51:58,786 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4774395882390266, 'Total loss': 0.4774395882390266} | train loss {'Reaction outcome loss': 0.456904945192767, 'Total loss': 0.456904945192767}
2022-11-28 04:51:58,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:58,786 INFO:     Epoch: 32
2022-11-28 04:51:59,440 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49338893488396046, 'Total loss': 0.49338893488396046} | train loss {'Reaction outcome loss': 0.45497587854500676, 'Total loss': 0.45497587854500676}
2022-11-28 04:51:59,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:51:59,441 INFO:     Epoch: 33
2022-11-28 04:52:00,094 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48290230437766674, 'Total loss': 0.48290230437766674} | train loss {'Reaction outcome loss': 0.4550771831733281, 'Total loss': 0.4550771831733281}
2022-11-28 04:52:00,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:00,095 INFO:     Epoch: 34
2022-11-28 04:52:00,750 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.49414341810137724, 'Total loss': 0.49414341810137724} | train loss {'Reaction outcome loss': 0.45815887845686226, 'Total loss': 0.45815887845686226}
2022-11-28 04:52:00,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:00,751 INFO:     Epoch: 35
2022-11-28 04:52:01,404 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4719979624415553, 'Total loss': 0.4719979624415553} | train loss {'Reaction outcome loss': 0.4552939457849401, 'Total loss': 0.4552939457849401}
2022-11-28 04:52:01,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:01,404 INFO:     Epoch: 36
2022-11-28 04:52:02,058 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4939486620038055, 'Total loss': 0.4939486620038055} | train loss {'Reaction outcome loss': 0.4518855619625967, 'Total loss': 0.4518855619625967}
2022-11-28 04:52:02,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:02,058 INFO:     Epoch: 37
2022-11-28 04:52:02,711 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48535172225430956, 'Total loss': 0.48535172225430956} | train loss {'Reaction outcome loss': 0.45535776043524506, 'Total loss': 0.45535776043524506}
2022-11-28 04:52:02,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:02,711 INFO:     Epoch: 38
2022-11-28 04:52:03,365 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4730759675419608, 'Total loss': 0.4730759675419608} | train loss {'Reaction outcome loss': 0.44937017065335494, 'Total loss': 0.44937017065335494}
2022-11-28 04:52:03,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:03,365 INFO:     Epoch: 39
2022-11-28 04:52:04,019 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4767109474470449, 'Total loss': 0.4767109474470449} | train loss {'Reaction outcome loss': 0.4527960311560357, 'Total loss': 0.4527960311560357}
2022-11-28 04:52:04,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:04,019 INFO:     Epoch: 40
2022-11-28 04:52:04,672 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4964363834885664, 'Total loss': 0.4964363834885664} | train loss {'Reaction outcome loss': 0.455865460890727, 'Total loss': 0.455865460890727}
2022-11-28 04:52:04,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:04,672 INFO:     Epoch: 41
2022-11-28 04:52:05,327 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4580534606478935, 'Total loss': 0.4580534606478935} | train loss {'Reaction outcome loss': 0.45668990928374353, 'Total loss': 0.45668990928374353}
2022-11-28 04:52:05,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:05,327 INFO:     Epoch: 42
2022-11-28 04:52:05,979 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47703422398068185, 'Total loss': 0.47703422398068185} | train loss {'Reaction outcome loss': 0.4544164476702448, 'Total loss': 0.4544164476702448}
2022-11-28 04:52:05,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:05,980 INFO:     Epoch: 43
2022-11-28 04:52:06,635 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4691800877105358, 'Total loss': 0.4691800877105358} | train loss {'Reaction outcome loss': 0.4626894924240034, 'Total loss': 0.4626894924240034}
2022-11-28 04:52:06,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:06,636 INFO:     Epoch: 44
2022-11-28 04:52:07,296 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5199956561243811, 'Total loss': 0.5199956561243811} | train loss {'Reaction outcome loss': 0.44735756113392405, 'Total loss': 0.44735756113392405}
2022-11-28 04:52:07,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:07,296 INFO:     Epoch: 45
2022-11-28 04:52:07,953 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4829248286956965, 'Total loss': 0.4829248286956965} | train loss {'Reaction outcome loss': 0.44812019834997224, 'Total loss': 0.44812019834997224}
2022-11-28 04:52:07,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:07,953 INFO:     Epoch: 46
2022-11-28 04:52:08,613 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5198003313569135, 'Total loss': 0.5198003313569135} | train loss {'Reaction outcome loss': 0.4525903255419164, 'Total loss': 0.4525903255419164}
2022-11-28 04:52:08,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:08,613 INFO:     Epoch: 47
2022-11-28 04:52:09,267 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4718222430972166, 'Total loss': 0.4718222430972166} | train loss {'Reaction outcome loss': 0.457597342121308, 'Total loss': 0.457597342121308}
2022-11-28 04:52:09,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:09,268 INFO:     Epoch: 48
2022-11-28 04:52:09,922 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46787804191888765, 'Total loss': 0.46787804191888765} | train loss {'Reaction outcome loss': 0.4629475022437143, 'Total loss': 0.4629475022437143}
2022-11-28 04:52:09,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:09,922 INFO:     Epoch: 49
2022-11-28 04:52:10,582 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48934733451798906, 'Total loss': 0.48934733451798906} | train loss {'Reaction outcome loss': 0.45138548766491843, 'Total loss': 0.45138548766491843}
2022-11-28 04:52:10,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:10,582 INFO:     Epoch: 50
2022-11-28 04:52:11,239 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4700945594976115, 'Total loss': 0.4700945594976115} | train loss {'Reaction outcome loss': 0.45778313144797184, 'Total loss': 0.45778313144797184}
2022-11-28 04:52:11,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:11,239 INFO:     Epoch: 51
2022-11-28 04:52:11,893 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5237131271251413, 'Total loss': 0.5237131271251413} | train loss {'Reaction outcome loss': 0.45229552261775635, 'Total loss': 0.45229552261775635}
2022-11-28 04:52:11,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:11,893 INFO:     Epoch: 52
2022-11-28 04:52:12,546 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49906214794447257, 'Total loss': 0.49906214794447257} | train loss {'Reaction outcome loss': 0.45111352156420226, 'Total loss': 0.45111352156420226}
2022-11-28 04:52:12,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:12,546 INFO:     Epoch: 53
2022-11-28 04:52:13,201 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48491557947424957, 'Total loss': 0.48491557947424957} | train loss {'Reaction outcome loss': 0.4535031049649735, 'Total loss': 0.4535031049649735}
2022-11-28 04:52:13,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:13,201 INFO:     Epoch: 54
2022-11-28 04:52:13,855 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45095391502214033, 'Total loss': 0.45095391502214033} | train loss {'Reaction outcome loss': 0.45315463688285623, 'Total loss': 0.45315463688285623}
2022-11-28 04:52:13,855 INFO:     Found new best model at epoch 54
2022-11-28 04:52:13,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:13,856 INFO:     Epoch: 55
2022-11-28 04:52:14,510 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46498415948346605, 'Total loss': 0.46498415948346605} | train loss {'Reaction outcome loss': 0.4571959373892331, 'Total loss': 0.4571959373892331}
2022-11-28 04:52:14,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:14,511 INFO:     Epoch: 56
2022-11-28 04:52:15,164 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5395031522872836, 'Total loss': 0.5395031522872836} | train loss {'Reaction outcome loss': 0.4546823006917219, 'Total loss': 0.4546823006917219}
2022-11-28 04:52:15,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:15,164 INFO:     Epoch: 57
2022-11-28 04:52:15,814 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47478908231092054, 'Total loss': 0.47478908231092054} | train loss {'Reaction outcome loss': 0.4557741352158492, 'Total loss': 0.4557741352158492}
2022-11-28 04:52:15,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:15,814 INFO:     Epoch: 58
2022-11-28 04:52:16,469 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4632514521133068, 'Total loss': 0.4632514521133068} | train loss {'Reaction outcome loss': 0.4571229474099933, 'Total loss': 0.4571229474099933}
2022-11-28 04:52:16,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:16,469 INFO:     Epoch: 59
2022-11-28 04:52:17,120 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4985098571971405, 'Total loss': 0.4985098571971405} | train loss {'Reaction outcome loss': 0.45004543491074295, 'Total loss': 0.45004543491074295}
2022-11-28 04:52:17,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:17,120 INFO:     Epoch: 60
2022-11-28 04:52:17,772 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4640450941961865, 'Total loss': 0.4640450941961865} | train loss {'Reaction outcome loss': 0.45620616598696007, 'Total loss': 0.45620616598696007}
2022-11-28 04:52:17,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:17,772 INFO:     Epoch: 61
2022-11-28 04:52:18,427 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46110453300697857, 'Total loss': 0.46110453300697857} | train loss {'Reaction outcome loss': 0.45994065573713816, 'Total loss': 0.45994065573713816}
2022-11-28 04:52:18,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:18,427 INFO:     Epoch: 62
2022-11-28 04:52:19,079 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4789252152969671, 'Total loss': 0.4789252152969671} | train loss {'Reaction outcome loss': 0.4552724380962184, 'Total loss': 0.4552724380962184}
2022-11-28 04:52:19,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:19,080 INFO:     Epoch: 63
2022-11-28 04:52:19,732 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4858456766882608, 'Total loss': 0.4858456766882608} | train loss {'Reaction outcome loss': 0.45450398295384936, 'Total loss': 0.45450398295384936}
2022-11-28 04:52:19,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:19,733 INFO:     Epoch: 64
2022-11-28 04:52:20,386 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4697979387155799, 'Total loss': 0.4697979387155799} | train loss {'Reaction outcome loss': 0.45768869259074085, 'Total loss': 0.45768869259074085}
2022-11-28 04:52:20,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:20,386 INFO:     Epoch: 65
2022-11-28 04:52:21,038 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.492081320563028, 'Total loss': 0.492081320563028} | train loss {'Reaction outcome loss': 0.4531643260575709, 'Total loss': 0.4531643260575709}
2022-11-28 04:52:21,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:21,038 INFO:     Epoch: 66
2022-11-28 04:52:21,689 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48160660544107126, 'Total loss': 0.48160660544107126} | train loss {'Reaction outcome loss': 0.4548442113961353, 'Total loss': 0.4548442113961353}
2022-11-28 04:52:21,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:21,690 INFO:     Epoch: 67
2022-11-28 04:52:22,345 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4782857964205187, 'Total loss': 0.4782857964205187} | train loss {'Reaction outcome loss': 0.44982260032022586, 'Total loss': 0.44982260032022586}
2022-11-28 04:52:22,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:22,345 INFO:     Epoch: 68
2022-11-28 04:52:22,998 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4691536280997964, 'Total loss': 0.4691536280997964} | train loss {'Reaction outcome loss': 0.45477484374261296, 'Total loss': 0.45477484374261296}
2022-11-28 04:52:22,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:22,998 INFO:     Epoch: 69
2022-11-28 04:52:23,651 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47963650212731473, 'Total loss': 0.47963650212731473} | train loss {'Reaction outcome loss': 0.4548530789305929, 'Total loss': 0.4548530789305929}
2022-11-28 04:52:23,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:23,651 INFO:     Epoch: 70
2022-11-28 04:52:24,301 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4958170063273851, 'Total loss': 0.4958170063273851} | train loss {'Reaction outcome loss': 0.4501111824981502, 'Total loss': 0.4501111824981502}
2022-11-28 04:52:24,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:24,301 INFO:     Epoch: 71
2022-11-28 04:52:24,953 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5388018727995628, 'Total loss': 0.5388018727995628} | train loss {'Reaction outcome loss': 0.45770521486391785, 'Total loss': 0.45770521486391785}
2022-11-28 04:52:24,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:24,953 INFO:     Epoch: 72
2022-11-28 04:52:25,607 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5068075428175371, 'Total loss': 0.5068075428175371} | train loss {'Reaction outcome loss': 0.44983469542176996, 'Total loss': 0.44983469542176996}
2022-11-28 04:52:25,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:25,608 INFO:     Epoch: 73
2022-11-28 04:52:26,259 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47283098448154537, 'Total loss': 0.47283098448154537} | train loss {'Reaction outcome loss': 0.4607942584352415, 'Total loss': 0.4607942584352415}
2022-11-28 04:52:26,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:26,260 INFO:     Epoch: 74
2022-11-28 04:52:26,916 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49496901208578153, 'Total loss': 0.49496901208578153} | train loss {'Reaction outcome loss': 0.4509055563172356, 'Total loss': 0.4509055563172356}
2022-11-28 04:52:26,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:26,916 INFO:     Epoch: 75
2022-11-28 04:52:27,566 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5120836198329926, 'Total loss': 0.5120836198329926} | train loss {'Reaction outcome loss': 0.44470886666266646, 'Total loss': 0.44470886666266646}
2022-11-28 04:52:27,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:27,566 INFO:     Epoch: 76
2022-11-28 04:52:28,221 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4815546832112379, 'Total loss': 0.4815546832112379} | train loss {'Reaction outcome loss': 0.45263748420555083, 'Total loss': 0.45263748420555083}
2022-11-28 04:52:28,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:28,221 INFO:     Epoch: 77
2022-11-28 04:52:28,878 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46195660635482433, 'Total loss': 0.46195660635482433} | train loss {'Reaction outcome loss': 0.45468522748741946, 'Total loss': 0.45468522748741946}
2022-11-28 04:52:28,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:28,878 INFO:     Epoch: 78
2022-11-28 04:52:29,532 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5132123869518901, 'Total loss': 0.5132123869518901} | train loss {'Reaction outcome loss': 0.4604028287481089, 'Total loss': 0.4604028287481089}
2022-11-28 04:52:29,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:29,532 INFO:     Epoch: 79
2022-11-28 04:52:30,182 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4874157510524572, 'Total loss': 0.4874157510524572} | train loss {'Reaction outcome loss': 0.45695536809622267, 'Total loss': 0.45695536809622267}
2022-11-28 04:52:30,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:30,182 INFO:     Epoch: 80
2022-11-28 04:52:30,836 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4921100673287414, 'Total loss': 0.4921100673287414} | train loss {'Reaction outcome loss': 0.45195923195999177, 'Total loss': 0.45195923195999177}
2022-11-28 04:52:30,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:30,837 INFO:     Epoch: 81
2022-11-28 04:52:31,492 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4642612166529478, 'Total loss': 0.4642612166529478} | train loss {'Reaction outcome loss': 0.45372841470554226, 'Total loss': 0.45372841470554226}
2022-11-28 04:52:31,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:31,492 INFO:     Epoch: 82
2022-11-28 04:52:32,145 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4784493955761887, 'Total loss': 0.4784493955761887} | train loss {'Reaction outcome loss': 0.46053885128043714, 'Total loss': 0.46053885128043714}
2022-11-28 04:52:32,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:32,145 INFO:     Epoch: 83
2022-11-28 04:52:32,797 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5068856831206832, 'Total loss': 0.5068856831206832} | train loss {'Reaction outcome loss': 0.45220284527320354, 'Total loss': 0.45220284527320354}
2022-11-28 04:52:32,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:32,798 INFO:     Epoch: 84
2022-11-28 04:52:33,451 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5173849532770556, 'Total loss': 0.5173849532770556} | train loss {'Reaction outcome loss': 0.4568749570028215, 'Total loss': 0.4568749570028215}
2022-11-28 04:52:33,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:33,451 INFO:     Epoch: 85
2022-11-28 04:52:34,102 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5030118795328362, 'Total loss': 0.5030118795328362} | train loss {'Reaction outcome loss': 0.45702776450236315, 'Total loss': 0.45702776450236315}
2022-11-28 04:52:34,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:34,102 INFO:     Epoch: 86
2022-11-28 04:52:34,755 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4703319481638975, 'Total loss': 0.4703319481638975} | train loss {'Reaction outcome loss': 0.46026489987480834, 'Total loss': 0.46026489987480834}
2022-11-28 04:52:34,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:34,755 INFO:     Epoch: 87
2022-11-28 04:52:35,405 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46707226509271665, 'Total loss': 0.46707226509271665} | train loss {'Reaction outcome loss': 0.4520392610279263, 'Total loss': 0.4520392610279263}
2022-11-28 04:52:35,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:35,405 INFO:     Epoch: 88
2022-11-28 04:52:36,059 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5022396278935809, 'Total loss': 0.5022396278935809} | train loss {'Reaction outcome loss': 0.4566865590568937, 'Total loss': 0.4566865590568937}
2022-11-28 04:52:36,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:36,059 INFO:     Epoch: 89
2022-11-28 04:52:36,710 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4841800207315489, 'Total loss': 0.4841800207315489} | train loss {'Reaction outcome loss': 0.45509962096321777, 'Total loss': 0.45509962096321777}
2022-11-28 04:52:36,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:36,710 INFO:     Epoch: 90
2022-11-28 04:52:37,362 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4635716156904088, 'Total loss': 0.4635716156904088} | train loss {'Reaction outcome loss': 0.45067817714737085, 'Total loss': 0.45067817714737085}
2022-11-28 04:52:37,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:37,362 INFO:     Epoch: 91
2022-11-28 04:52:38,020 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4675899245018183, 'Total loss': 0.4675899245018183} | train loss {'Reaction outcome loss': 0.45276206420337567, 'Total loss': 0.45276206420337567}
2022-11-28 04:52:38,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:38,021 INFO:     Epoch: 92
2022-11-28 04:52:38,680 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46693931797216104, 'Total loss': 0.46693931797216104} | train loss {'Reaction outcome loss': 0.4566379904014165, 'Total loss': 0.4566379904014165}
2022-11-28 04:52:38,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:38,680 INFO:     Epoch: 93
2022-11-28 04:52:39,336 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5227108667063158, 'Total loss': 0.5227108667063158} | train loss {'Reaction outcome loss': 0.45857691819794844, 'Total loss': 0.45857691819794844}
2022-11-28 04:52:39,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:39,336 INFO:     Epoch: 94
2022-11-28 04:52:39,991 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4873533993959427, 'Total loss': 0.4873533993959427} | train loss {'Reaction outcome loss': 0.4585117116936895, 'Total loss': 0.4585117116936895}
2022-11-28 04:52:39,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:39,991 INFO:     Epoch: 95
2022-11-28 04:52:40,643 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47265855413536695, 'Total loss': 0.47265855413536695} | train loss {'Reaction outcome loss': 0.44847597529897926, 'Total loss': 0.44847597529897926}
2022-11-28 04:52:40,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:40,644 INFO:     Epoch: 96
2022-11-28 04:52:41,294 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4847098862709001, 'Total loss': 0.4847098862709001} | train loss {'Reaction outcome loss': 0.45136655601443815, 'Total loss': 0.45136655601443815}
2022-11-28 04:52:41,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:41,294 INFO:     Epoch: 97
2022-11-28 04:52:41,946 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5035672977913258, 'Total loss': 0.5035672977913258} | train loss {'Reaction outcome loss': 0.4493769491244046, 'Total loss': 0.4493769491244046}
2022-11-28 04:52:41,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:41,946 INFO:     Epoch: 98
2022-11-28 04:52:42,601 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4831155174693396, 'Total loss': 0.4831155174693396} | train loss {'Reaction outcome loss': 0.4570627857427128, 'Total loss': 0.4570627857427128}
2022-11-28 04:52:42,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:42,601 INFO:     Epoch: 99
2022-11-28 04:52:43,249 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49145044005194377, 'Total loss': 0.49145044005194377} | train loss {'Reaction outcome loss': 0.453864792819883, 'Total loss': 0.453864792819883}
2022-11-28 04:52:43,249 INFO:     Best model found after epoch 55 of 100.
2022-11-28 04:52:43,249 INFO:   Done with stage: TRAINING
2022-11-28 04:52:43,250 INFO:   Starting stage: EVALUATION
2022-11-28 04:52:43,378 INFO:   Done with stage: EVALUATION
2022-11-28 04:52:43,378 INFO:   Leaving out SEQ value Fold_8
2022-11-28 04:52:43,390 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:52:43,391 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:52:44,035 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:52:44,036 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:52:44,104 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:52:44,104 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:52:44,104 INFO:     No hyperparam tuning for this model
2022-11-28 04:52:44,104 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:52:44,104 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:52:44,105 INFO:     None feature selector for col prot
2022-11-28 04:52:44,105 INFO:     None feature selector for col prot
2022-11-28 04:52:44,105 INFO:     None feature selector for col prot
2022-11-28 04:52:44,106 INFO:     None feature selector for col chem
2022-11-28 04:52:44,106 INFO:     None feature selector for col chem
2022-11-28 04:52:44,106 INFO:     None feature selector for col chem
2022-11-28 04:52:44,106 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:52:44,106 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:52:44,108 INFO:     Number of params in model 169651
2022-11-28 04:52:44,111 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:52:44,111 INFO:   Starting stage: TRAINING
2022-11-28 04:52:44,162 INFO:     Val loss before train {'Reaction outcome loss': 0.988550524819981, 'Total loss': 0.988550524819981}
2022-11-28 04:52:44,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:44,162 INFO:     Epoch: 0
2022-11-28 04:52:44,824 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6120985719290647, 'Total loss': 0.6120985719290647} | train loss {'Reaction outcome loss': 0.6973123850248121, 'Total loss': 0.6973123850248121}
2022-11-28 04:52:44,824 INFO:     Found new best model at epoch 0
2022-11-28 04:52:44,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:44,825 INFO:     Epoch: 1
2022-11-28 04:52:45,488 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5688744559884071, 'Total loss': 0.5688744559884071} | train loss {'Reaction outcome loss': 0.5904053102741357, 'Total loss': 0.5904053102741357}
2022-11-28 04:52:45,488 INFO:     Found new best model at epoch 1
2022-11-28 04:52:45,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:45,489 INFO:     Epoch: 2
2022-11-28 04:52:46,154 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5483744313771074, 'Total loss': 0.5483744313771074} | train loss {'Reaction outcome loss': 0.5751094427487629, 'Total loss': 0.5751094427487629}
2022-11-28 04:52:46,155 INFO:     Found new best model at epoch 2
2022-11-28 04:52:46,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:46,155 INFO:     Epoch: 3
2022-11-28 04:52:46,814 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5226343409581617, 'Total loss': 0.5226343409581617} | train loss {'Reaction outcome loss': 0.5442755436529462, 'Total loss': 0.5442755436529462}
2022-11-28 04:52:46,814 INFO:     Found new best model at epoch 3
2022-11-28 04:52:46,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:46,815 INFO:     Epoch: 4
2022-11-28 04:52:47,472 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5112451179461046, 'Total loss': 0.5112451179461046} | train loss {'Reaction outcome loss': 0.5436650411930946, 'Total loss': 0.5436650411930946}
2022-11-28 04:52:47,472 INFO:     Found new best model at epoch 4
2022-11-28 04:52:47,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:47,473 INFO:     Epoch: 5
2022-11-28 04:52:48,133 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49359611489556054, 'Total loss': 0.49359611489556054} | train loss {'Reaction outcome loss': 0.5281991105571933, 'Total loss': 0.5281991105571933}
2022-11-28 04:52:48,134 INFO:     Found new best model at epoch 5
2022-11-28 04:52:48,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:48,134 INFO:     Epoch: 6
2022-11-28 04:52:48,795 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4783397316932678, 'Total loss': 0.4783397316932678} | train loss {'Reaction outcome loss': 0.5339849774654095, 'Total loss': 0.5339849774654095}
2022-11-28 04:52:48,795 INFO:     Found new best model at epoch 6
2022-11-28 04:52:48,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:48,796 INFO:     Epoch: 7
2022-11-28 04:52:49,459 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5198398142714392, 'Total loss': 0.5198398142714392} | train loss {'Reaction outcome loss': 0.5181223849505789, 'Total loss': 0.5181223849505789}
2022-11-28 04:52:49,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:49,459 INFO:     Epoch: 8
2022-11-28 04:52:50,123 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46528448028997943, 'Total loss': 0.46528448028997943} | train loss {'Reaction outcome loss': 0.5025792626535844, 'Total loss': 0.5025792626535844}
2022-11-28 04:52:50,124 INFO:     Found new best model at epoch 8
2022-11-28 04:52:50,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:50,124 INFO:     Epoch: 9
2022-11-28 04:52:50,788 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5023619891567663, 'Total loss': 0.5023619891567663} | train loss {'Reaction outcome loss': 0.5109239663129393, 'Total loss': 0.5109239663129393}
2022-11-28 04:52:50,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:50,788 INFO:     Epoch: 10
2022-11-28 04:52:51,452 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4805839955806732, 'Total loss': 0.4805839955806732} | train loss {'Reaction outcome loss': 0.49922116203346717, 'Total loss': 0.49922116203346717}
2022-11-28 04:52:51,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:51,452 INFO:     Epoch: 11
2022-11-28 04:52:52,115 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49075779115611856, 'Total loss': 0.49075779115611856} | train loss {'Reaction outcome loss': 0.5077083554827733, 'Total loss': 0.5077083554827733}
2022-11-28 04:52:52,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:52,115 INFO:     Epoch: 12
2022-11-28 04:52:52,776 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48512365025552834, 'Total loss': 0.48512365025552834} | train loss {'Reaction outcome loss': 0.5091776206546467, 'Total loss': 0.5091776206546467}
2022-11-28 04:52:52,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:52,777 INFO:     Epoch: 13
2022-11-28 04:52:53,438 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47566941888494924, 'Total loss': 0.47566941888494924} | train loss {'Reaction outcome loss': 0.49185706296490755, 'Total loss': 0.49185706296490755}
2022-11-28 04:52:53,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:53,438 INFO:     Epoch: 14
2022-11-28 04:52:54,098 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4785220998932015, 'Total loss': 0.4785220998932015} | train loss {'Reaction outcome loss': 0.5003648111936052, 'Total loss': 0.5003648111936052}
2022-11-28 04:52:54,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:54,098 INFO:     Epoch: 15
2022-11-28 04:52:54,755 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.480980285866694, 'Total loss': 0.480980285866694} | train loss {'Reaction outcome loss': 0.5087927055624333, 'Total loss': 0.5087927055624333}
2022-11-28 04:52:54,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:54,755 INFO:     Epoch: 16
2022-11-28 04:52:55,413 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47704763236370956, 'Total loss': 0.47704763236370956} | train loss {'Reaction outcome loss': 0.493738683760694, 'Total loss': 0.493738683760694}
2022-11-28 04:52:55,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:55,413 INFO:     Epoch: 17
2022-11-28 04:52:56,076 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4682518636638468, 'Total loss': 0.4682518636638468} | train loss {'Reaction outcome loss': 0.47674445301644985, 'Total loss': 0.47674445301644985}
2022-11-28 04:52:56,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:56,077 INFO:     Epoch: 18
2022-11-28 04:52:56,741 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48141810805960134, 'Total loss': 0.48141810805960134} | train loss {'Reaction outcome loss': 0.47436380374946663, 'Total loss': 0.47436380374946663}
2022-11-28 04:52:56,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:56,741 INFO:     Epoch: 19
2022-11-28 04:52:57,403 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4940009760585698, 'Total loss': 0.4940009760585698} | train loss {'Reaction outcome loss': 0.4839652745347274, 'Total loss': 0.4839652745347274}
2022-11-28 04:52:57,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:57,403 INFO:     Epoch: 20
2022-11-28 04:52:58,063 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5098935995589603, 'Total loss': 0.5098935995589603} | train loss {'Reaction outcome loss': 0.4797630390295616, 'Total loss': 0.4797630390295616}
2022-11-28 04:52:58,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:58,063 INFO:     Epoch: 21
2022-11-28 04:52:58,724 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4721116769042882, 'Total loss': 0.4721116769042882} | train loss {'Reaction outcome loss': 0.48148807092958135, 'Total loss': 0.48148807092958135}
2022-11-28 04:52:58,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:58,724 INFO:     Epoch: 22
2022-11-28 04:52:59,389 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4941338873045011, 'Total loss': 0.4941338873045011} | train loss {'Reaction outcome loss': 0.48025475158865155, 'Total loss': 0.48025475158865155}
2022-11-28 04:52:59,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:52:59,389 INFO:     Epoch: 23
2022-11-28 04:53:00,050 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4800347357311032, 'Total loss': 0.4800347357311032} | train loss {'Reaction outcome loss': 0.48881833743952546, 'Total loss': 0.48881833743952546}
2022-11-28 04:53:00,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:00,050 INFO:     Epoch: 24
2022-11-28 04:53:00,712 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4756555983966047, 'Total loss': 0.4756555983966047} | train loss {'Reaction outcome loss': 0.4818771409722958, 'Total loss': 0.4818771409722958}
2022-11-28 04:53:00,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:00,712 INFO:     Epoch: 25
2022-11-28 04:53:01,373 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5110950591889295, 'Total loss': 0.5110950591889295} | train loss {'Reaction outcome loss': 0.48409312584263986, 'Total loss': 0.48409312584263986}
2022-11-28 04:53:01,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:01,373 INFO:     Epoch: 26
2022-11-28 04:53:02,034 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4795559433034875, 'Total loss': 0.4795559433034875} | train loss {'Reaction outcome loss': 0.48049059721381077, 'Total loss': 0.48049059721381077}
2022-11-28 04:53:02,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:02,035 INFO:     Epoch: 27
2022-11-28 04:53:02,696 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4749500853094188, 'Total loss': 0.4749500853094188} | train loss {'Reaction outcome loss': 0.49327201794395564, 'Total loss': 0.49327201794395564}
2022-11-28 04:53:02,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:02,696 INFO:     Epoch: 28
2022-11-28 04:53:03,359 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4798421361906962, 'Total loss': 0.4798421361906962} | train loss {'Reaction outcome loss': 0.4890003625439246, 'Total loss': 0.4890003625439246}
2022-11-28 04:53:03,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:03,360 INFO:     Epoch: 29
2022-11-28 04:53:04,022 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5523698966611515, 'Total loss': 0.5523698966611515} | train loss {'Reaction outcome loss': 0.5120333552601849, 'Total loss': 0.5120333552601849}
2022-11-28 04:53:04,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:04,023 INFO:     Epoch: 30
2022-11-28 04:53:04,685 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.450140791521831, 'Total loss': 0.450140791521831} | train loss {'Reaction outcome loss': 0.4945595817346322, 'Total loss': 0.4945595817346322}
2022-11-28 04:53:04,685 INFO:     Found new best model at epoch 30
2022-11-28 04:53:04,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:04,686 INFO:     Epoch: 31
2022-11-28 04:53:05,347 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4835429083217274, 'Total loss': 0.4835429083217274} | train loss {'Reaction outcome loss': 0.474900612886618, 'Total loss': 0.474900612886618}
2022-11-28 04:53:05,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:05,347 INFO:     Epoch: 32
2022-11-28 04:53:06,005 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4652786637571725, 'Total loss': 0.4652786637571725} | train loss {'Reaction outcome loss': 0.483463289962727, 'Total loss': 0.483463289962727}
2022-11-28 04:53:06,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:06,005 INFO:     Epoch: 33
2022-11-28 04:53:06,666 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47106834094632755, 'Total loss': 0.47106834094632755} | train loss {'Reaction outcome loss': 0.4848706465863023, 'Total loss': 0.4848706465863023}
2022-11-28 04:53:06,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:06,667 INFO:     Epoch: 34
2022-11-28 04:53:07,332 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4851950237696821, 'Total loss': 0.4851950237696821} | train loss {'Reaction outcome loss': 0.4773414187012655, 'Total loss': 0.4773414187012655}
2022-11-28 04:53:07,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:07,333 INFO:     Epoch: 35
2022-11-28 04:53:07,998 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5416545603762973, 'Total loss': 0.5416545603762973} | train loss {'Reaction outcome loss': 0.4835511795301669, 'Total loss': 0.4835511795301669}
2022-11-28 04:53:07,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:07,998 INFO:     Epoch: 36
2022-11-28 04:53:08,657 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4518307772549716, 'Total loss': 0.4518307772549716} | train loss {'Reaction outcome loss': 0.486147402691455, 'Total loss': 0.486147402691455}
2022-11-28 04:53:08,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:08,658 INFO:     Epoch: 37
2022-11-28 04:53:09,319 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4756422124125741, 'Total loss': 0.4756422124125741} | train loss {'Reaction outcome loss': 0.47781692837413986, 'Total loss': 0.47781692837413986}
2022-11-28 04:53:09,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:09,320 INFO:     Epoch: 38
2022-11-28 04:53:09,979 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4665638421746818, 'Total loss': 0.4665638421746818} | train loss {'Reaction outcome loss': 0.4873628693855243, 'Total loss': 0.4873628693855243}
2022-11-28 04:53:09,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:09,979 INFO:     Epoch: 39
2022-11-28 04:53:10,638 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45943251421505754, 'Total loss': 0.45943251421505754} | train loss {'Reaction outcome loss': 0.4731427820225959, 'Total loss': 0.4731427820225959}
2022-11-28 04:53:10,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:10,638 INFO:     Epoch: 40
2022-11-28 04:53:11,298 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4669064083559947, 'Total loss': 0.4669064083559947} | train loss {'Reaction outcome loss': 0.4822979850679455, 'Total loss': 0.4822979850679455}
2022-11-28 04:53:11,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:11,298 INFO:     Epoch: 41
2022-11-28 04:53:11,956 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4740089269524271, 'Total loss': 0.4740089269524271} | train loss {'Reaction outcome loss': 0.47195860864179817, 'Total loss': 0.47195860864179817}
2022-11-28 04:53:11,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:11,956 INFO:     Epoch: 42
2022-11-28 04:53:12,618 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4473706338215958, 'Total loss': 0.4473706338215958} | train loss {'Reaction outcome loss': 0.47766908985159173, 'Total loss': 0.47766908985159173}
2022-11-28 04:53:12,618 INFO:     Found new best model at epoch 42
2022-11-28 04:53:12,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:12,619 INFO:     Epoch: 43
2022-11-28 04:53:13,280 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4838375212116675, 'Total loss': 0.4838375212116675} | train loss {'Reaction outcome loss': 0.47225778094428755, 'Total loss': 0.47225778094428755}
2022-11-28 04:53:13,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:13,280 INFO:     Epoch: 44
2022-11-28 04:53:13,940 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47192649848081847, 'Total loss': 0.47192649848081847} | train loss {'Reaction outcome loss': 0.4782995430126726, 'Total loss': 0.4782995430126726}
2022-11-28 04:53:13,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:13,940 INFO:     Epoch: 45
2022-11-28 04:53:14,603 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49265002205290576, 'Total loss': 0.49265002205290576} | train loss {'Reaction outcome loss': 0.47600434598350816, 'Total loss': 0.47600434598350816}
2022-11-28 04:53:14,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:14,603 INFO:     Epoch: 46
2022-11-28 04:53:15,266 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45887022668665106, 'Total loss': 0.45887022668665106} | train loss {'Reaction outcome loss': 0.4737655123048142, 'Total loss': 0.4737655123048142}
2022-11-28 04:53:15,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:15,267 INFO:     Epoch: 47
2022-11-28 04:53:15,931 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47110631418499077, 'Total loss': 0.47110631418499077} | train loss {'Reaction outcome loss': 0.4831816904578614, 'Total loss': 0.4831816904578614}
2022-11-28 04:53:15,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:15,931 INFO:     Epoch: 48
2022-11-28 04:53:16,594 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4638075076720931, 'Total loss': 0.4638075076720931} | train loss {'Reaction outcome loss': 0.48900824537319754, 'Total loss': 0.48900824537319754}
2022-11-28 04:53:16,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:16,594 INFO:     Epoch: 49
2022-11-28 04:53:17,254 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49678500538522546, 'Total loss': 0.49678500538522546} | train loss {'Reaction outcome loss': 0.47063098822226407, 'Total loss': 0.47063098822226407}
2022-11-28 04:53:17,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:17,255 INFO:     Epoch: 50
2022-11-28 04:53:17,913 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4655625048008832, 'Total loss': 0.4655625048008832} | train loss {'Reaction outcome loss': 0.47594196141248774, 'Total loss': 0.47594196141248774}
2022-11-28 04:53:17,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:17,914 INFO:     Epoch: 51
2022-11-28 04:53:18,574 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4667188779196956, 'Total loss': 0.4667188779196956} | train loss {'Reaction outcome loss': 0.48344182696661003, 'Total loss': 0.48344182696661003}
2022-11-28 04:53:18,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:18,575 INFO:     Epoch: 52
2022-11-28 04:53:19,234 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5000223300673745, 'Total loss': 0.5000223300673745} | train loss {'Reaction outcome loss': 0.4848580291317512, 'Total loss': 0.4848580291317512}
2022-11-28 04:53:19,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:19,235 INFO:     Epoch: 53
2022-11-28 04:53:19,894 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47114909812808037, 'Total loss': 0.47114909812808037} | train loss {'Reaction outcome loss': 0.4759776095373307, 'Total loss': 0.4759776095373307}
2022-11-28 04:53:19,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:19,894 INFO:     Epoch: 54
2022-11-28 04:53:20,553 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4619267735291611, 'Total loss': 0.4619267735291611} | train loss {'Reaction outcome loss': 0.47416325165750645, 'Total loss': 0.47416325165750645}
2022-11-28 04:53:20,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:20,554 INFO:     Epoch: 55
2022-11-28 04:53:21,217 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46808190846985037, 'Total loss': 0.46808190846985037} | train loss {'Reaction outcome loss': 0.4733166422700577, 'Total loss': 0.4733166422700577}
2022-11-28 04:53:21,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:21,217 INFO:     Epoch: 56
2022-11-28 04:53:21,875 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47856692055409605, 'Total loss': 0.47856692055409605} | train loss {'Reaction outcome loss': 0.48045080737305074, 'Total loss': 0.48045080737305074}
2022-11-28 04:53:21,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:21,875 INFO:     Epoch: 57
2022-11-28 04:53:22,536 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.452750599519773, 'Total loss': 0.452750599519773} | train loss {'Reaction outcome loss': 0.4810228126372403, 'Total loss': 0.4810228126372403}
2022-11-28 04:53:22,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:22,536 INFO:     Epoch: 58
2022-11-28 04:53:23,196 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4739933271299709, 'Total loss': 0.4739933271299709} | train loss {'Reaction outcome loss': 0.4769595562355962, 'Total loss': 0.4769595562355962}
2022-11-28 04:53:23,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:23,196 INFO:     Epoch: 59
2022-11-28 04:53:23,856 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4774410707706755, 'Total loss': 0.4774410707706755} | train loss {'Reaction outcome loss': 0.47374899980992924, 'Total loss': 0.47374899980992924}
2022-11-28 04:53:23,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:23,856 INFO:     Epoch: 60
2022-11-28 04:53:24,520 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43622244852171704, 'Total loss': 0.43622244852171704} | train loss {'Reaction outcome loss': 0.46734119309225547, 'Total loss': 0.46734119309225547}
2022-11-28 04:53:24,520 INFO:     Found new best model at epoch 60
2022-11-28 04:53:24,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:24,521 INFO:     Epoch: 61
2022-11-28 04:53:25,184 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45435829494487157, 'Total loss': 0.45435829494487157} | train loss {'Reaction outcome loss': 0.47289577405428446, 'Total loss': 0.47289577405428446}
2022-11-28 04:53:25,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:25,184 INFO:     Epoch: 62
2022-11-28 04:53:25,845 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4482400996441191, 'Total loss': 0.4482400996441191} | train loss {'Reaction outcome loss': 0.4728042055600085, 'Total loss': 0.4728042055600085}
2022-11-28 04:53:25,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:25,846 INFO:     Epoch: 63
2022-11-28 04:53:26,507 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4646864961832762, 'Total loss': 0.4646864961832762} | train loss {'Reaction outcome loss': 0.47561751610716346, 'Total loss': 0.47561751610716346}
2022-11-28 04:53:26,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:26,508 INFO:     Epoch: 64
2022-11-28 04:53:27,166 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4637624601071531, 'Total loss': 0.4637624601071531} | train loss {'Reaction outcome loss': 0.4655060545562084, 'Total loss': 0.4655060545562084}
2022-11-28 04:53:27,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:27,167 INFO:     Epoch: 65
2022-11-28 04:53:27,827 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.460273995318196, 'Total loss': 0.460273995318196} | train loss {'Reaction outcome loss': 0.47236802495322244, 'Total loss': 0.47236802495322244}
2022-11-28 04:53:27,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:27,828 INFO:     Epoch: 66
2022-11-28 04:53:28,490 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45511137931184337, 'Total loss': 0.45511137931184337} | train loss {'Reaction outcome loss': 0.46628564493617547, 'Total loss': 0.46628564493617547}
2022-11-28 04:53:28,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:28,491 INFO:     Epoch: 67
2022-11-28 04:53:29,151 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46243328567255626, 'Total loss': 0.46243328567255626} | train loss {'Reaction outcome loss': 0.4896887569774983, 'Total loss': 0.4896887569774983}
2022-11-28 04:53:29,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:29,151 INFO:     Epoch: 68
2022-11-28 04:53:29,815 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4624668610366908, 'Total loss': 0.4624668610366908} | train loss {'Reaction outcome loss': 0.4818005354901557, 'Total loss': 0.4818005354901557}
2022-11-28 04:53:29,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:29,816 INFO:     Epoch: 69
2022-11-28 04:53:30,474 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.468985973095352, 'Total loss': 0.468985973095352} | train loss {'Reaction outcome loss': 0.4781425779285701, 'Total loss': 0.4781425779285701}
2022-11-28 04:53:30,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:30,474 INFO:     Epoch: 70
2022-11-28 04:53:31,133 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4509997056289153, 'Total loss': 0.4509997056289153} | train loss {'Reaction outcome loss': 0.4877327979214278, 'Total loss': 0.4877327979214278}
2022-11-28 04:53:31,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:31,134 INFO:     Epoch: 71
2022-11-28 04:53:31,793 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45515627532520075, 'Total loss': 0.45515627532520075} | train loss {'Reaction outcome loss': 0.47267826734042845, 'Total loss': 0.47267826734042845}
2022-11-28 04:53:31,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:31,793 INFO:     Epoch: 72
2022-11-28 04:53:32,455 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46570296822623775, 'Total loss': 0.46570296822623775} | train loss {'Reaction outcome loss': 0.47113102071198376, 'Total loss': 0.47113102071198376}
2022-11-28 04:53:32,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:32,455 INFO:     Epoch: 73
2022-11-28 04:53:33,117 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45894273641434585, 'Total loss': 0.45894273641434585} | train loss {'Reaction outcome loss': 0.4865871547091647, 'Total loss': 0.4865871547091647}
2022-11-28 04:53:33,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:33,117 INFO:     Epoch: 74
2022-11-28 04:53:33,779 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4778188033537431, 'Total loss': 0.4778188033537431} | train loss {'Reaction outcome loss': 0.4716257743013321, 'Total loss': 0.4716257743013321}
2022-11-28 04:53:33,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:33,779 INFO:     Epoch: 75
2022-11-28 04:53:34,439 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4602380208671093, 'Total loss': 0.4602380208671093} | train loss {'Reaction outcome loss': 0.47917021949764205, 'Total loss': 0.47917021949764205}
2022-11-28 04:53:34,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:34,439 INFO:     Epoch: 76
2022-11-28 04:53:35,100 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.454989395019683, 'Total loss': 0.454989395019683} | train loss {'Reaction outcome loss': 0.4677033117078697, 'Total loss': 0.4677033117078697}
2022-11-28 04:53:35,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:35,100 INFO:     Epoch: 77
2022-11-28 04:53:35,760 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47270973229950125, 'Total loss': 0.47270973229950125} | train loss {'Reaction outcome loss': 0.46922464517552237, 'Total loss': 0.46922464517552237}
2022-11-28 04:53:35,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:35,761 INFO:     Epoch: 78
2022-11-28 04:53:36,423 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46575147116726096, 'Total loss': 0.46575147116726096} | train loss {'Reaction outcome loss': 0.46896325946532885, 'Total loss': 0.46896325946532885}
2022-11-28 04:53:36,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:36,423 INFO:     Epoch: 79
2022-11-28 04:53:37,086 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4453208317810839, 'Total loss': 0.4453208317810839} | train loss {'Reaction outcome loss': 0.46798117835874015, 'Total loss': 0.46798117835874015}
2022-11-28 04:53:37,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:37,087 INFO:     Epoch: 80
2022-11-28 04:53:37,746 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49497121064500377, 'Total loss': 0.49497121064500377} | train loss {'Reaction outcome loss': 0.48011543230730513, 'Total loss': 0.48011543230730513}
2022-11-28 04:53:37,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:37,747 INFO:     Epoch: 81
2022-11-28 04:53:38,407 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4568112716078758, 'Total loss': 0.4568112716078758} | train loss {'Reaction outcome loss': 0.4784651710208777, 'Total loss': 0.4784651710208777}
2022-11-28 04:53:38,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:38,407 INFO:     Epoch: 82
2022-11-28 04:53:39,068 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4597145014188506, 'Total loss': 0.4597145014188506} | train loss {'Reaction outcome loss': 0.46752888992851077, 'Total loss': 0.46752888992851077}
2022-11-28 04:53:39,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:39,069 INFO:     Epoch: 83
2022-11-28 04:53:39,730 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4721865616738796, 'Total loss': 0.4721865616738796} | train loss {'Reaction outcome loss': 0.47391630009359675, 'Total loss': 0.47391630009359675}
2022-11-28 04:53:39,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:39,731 INFO:     Epoch: 84
2022-11-28 04:53:40,392 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.447480083019896, 'Total loss': 0.447480083019896} | train loss {'Reaction outcome loss': 0.4714045550538461, 'Total loss': 0.4714045550538461}
2022-11-28 04:53:40,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:40,392 INFO:     Epoch: 85
2022-11-28 04:53:41,051 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4600750604136424, 'Total loss': 0.4600750604136424} | train loss {'Reaction outcome loss': 0.46929813276689786, 'Total loss': 0.46929813276689786}
2022-11-28 04:53:41,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:41,051 INFO:     Epoch: 86
2022-11-28 04:53:41,713 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47383523698557506, 'Total loss': 0.47383523698557506} | train loss {'Reaction outcome loss': 0.4706179949677425, 'Total loss': 0.4706179949677425}
2022-11-28 04:53:41,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:41,713 INFO:     Epoch: 87
2022-11-28 04:53:42,377 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4846946932375431, 'Total loss': 0.4846946932375431} | train loss {'Reaction outcome loss': 0.47237025816672246, 'Total loss': 0.47237025816672246}
2022-11-28 04:53:42,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:42,377 INFO:     Epoch: 88
2022-11-28 04:53:43,040 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5105867006561973, 'Total loss': 0.5105867006561973} | train loss {'Reaction outcome loss': 0.48142993848333476, 'Total loss': 0.48142993848333476}
2022-11-28 04:53:43,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:43,040 INFO:     Epoch: 89
2022-11-28 04:53:43,699 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48168088698929007, 'Total loss': 0.48168088698929007} | train loss {'Reaction outcome loss': 0.48585099760308176, 'Total loss': 0.48585099760308176}
2022-11-28 04:53:43,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:43,699 INFO:     Epoch: 90
2022-11-28 04:53:44,356 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4564576071094383, 'Total loss': 0.4564576071094383} | train loss {'Reaction outcome loss': 0.46723551269967545, 'Total loss': 0.46723551269967545}
2022-11-28 04:53:44,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:44,356 INFO:     Epoch: 91
2022-11-28 04:53:45,014 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49775317480618303, 'Total loss': 0.49775317480618303} | train loss {'Reaction outcome loss': 0.4753545262673606, 'Total loss': 0.4753545262673606}
2022-11-28 04:53:45,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:45,015 INFO:     Epoch: 92
2022-11-28 04:53:45,676 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44643138044259767, 'Total loss': 0.44643138044259767} | train loss {'Reaction outcome loss': 0.46776626515485015, 'Total loss': 0.46776626515485015}
2022-11-28 04:53:45,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:45,676 INFO:     Epoch: 93
2022-11-28 04:53:46,336 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46704154360023414, 'Total loss': 0.46704154360023414} | train loss {'Reaction outcome loss': 0.4856523161957621, 'Total loss': 0.4856523161957621}
2022-11-28 04:53:46,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:46,337 INFO:     Epoch: 94
2022-11-28 04:53:47,001 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5079960064454512, 'Total loss': 0.5079960064454512} | train loss {'Reaction outcome loss': 0.4838818881796439, 'Total loss': 0.4838818881796439}
2022-11-28 04:53:47,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:47,002 INFO:     Epoch: 95
2022-11-28 04:53:47,662 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46994002400474116, 'Total loss': 0.46994002400474116} | train loss {'Reaction outcome loss': 0.47479875952849987, 'Total loss': 0.47479875952849987}
2022-11-28 04:53:47,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:47,662 INFO:     Epoch: 96
2022-11-28 04:53:48,324 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45133819532665337, 'Total loss': 0.45133819532665337} | train loss {'Reaction outcome loss': 0.48057570106346115, 'Total loss': 0.48057570106346115}
2022-11-28 04:53:48,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:48,325 INFO:     Epoch: 97
2022-11-28 04:53:48,988 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4660398445346139, 'Total loss': 0.4660398445346139} | train loss {'Reaction outcome loss': 0.4683739464194608, 'Total loss': 0.4683739464194608}
2022-11-28 04:53:48,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:48,988 INFO:     Epoch: 98
2022-11-28 04:53:49,649 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4541410803794861, 'Total loss': 0.4541410803794861} | train loss {'Reaction outcome loss': 0.47723559504337154, 'Total loss': 0.47723559504337154}
2022-11-28 04:53:49,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:49,650 INFO:     Epoch: 99
2022-11-28 04:53:50,307 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46705224398862233, 'Total loss': 0.46705224398862233} | train loss {'Reaction outcome loss': 0.47106438366977144, 'Total loss': 0.47106438366977144}
2022-11-28 04:53:50,308 INFO:     Best model found after epoch 61 of 100.
2022-11-28 04:53:50,308 INFO:   Done with stage: TRAINING
2022-11-28 04:53:50,308 INFO:   Starting stage: EVALUATION
2022-11-28 04:53:50,424 INFO:   Done with stage: EVALUATION
2022-11-28 04:53:50,424 INFO:   Leaving out SEQ value Fold_9
2022-11-28 04:53:50,437 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:53:50,437 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:53:51,083 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:53:51,083 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:53:51,153 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:53:51,153 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:53:51,153 INFO:     No hyperparam tuning for this model
2022-11-28 04:53:51,153 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:53:51,153 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:53:51,154 INFO:     None feature selector for col prot
2022-11-28 04:53:51,154 INFO:     None feature selector for col prot
2022-11-28 04:53:51,154 INFO:     None feature selector for col prot
2022-11-28 04:53:51,154 INFO:     None feature selector for col chem
2022-11-28 04:53:51,155 INFO:     None feature selector for col chem
2022-11-28 04:53:51,155 INFO:     None feature selector for col chem
2022-11-28 04:53:51,155 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:53:51,155 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:53:51,156 INFO:     Number of params in model 169651
2022-11-28 04:53:51,159 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:53:51,159 INFO:   Starting stage: TRAINING
2022-11-28 04:53:51,210 INFO:     Val loss before train {'Reaction outcome loss': 0.956336801702326, 'Total loss': 0.956336801702326}
2022-11-28 04:53:51,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:51,211 INFO:     Epoch: 0
2022-11-28 04:53:51,875 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5683057775551622, 'Total loss': 0.5683057775551622} | train loss {'Reaction outcome loss': 0.6703830805384678, 'Total loss': 0.6703830805384678}
2022-11-28 04:53:51,875 INFO:     Found new best model at epoch 0
2022-11-28 04:53:51,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:51,876 INFO:     Epoch: 1
2022-11-28 04:53:52,536 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5060797150839459, 'Total loss': 0.5060797150839459} | train loss {'Reaction outcome loss': 0.5705570933910517, 'Total loss': 0.5705570933910517}
2022-11-28 04:53:52,536 INFO:     Found new best model at epoch 1
2022-11-28 04:53:52,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:52,537 INFO:     Epoch: 2
2022-11-28 04:53:53,196 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5250768194144423, 'Total loss': 0.5250768194144423} | train loss {'Reaction outcome loss': 0.5445670755165308, 'Total loss': 0.5445670755165308}
2022-11-28 04:53:53,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:53,196 INFO:     Epoch: 3
2022-11-28 04:53:53,852 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47951759127053345, 'Total loss': 0.47951759127053345} | train loss {'Reaction outcome loss': 0.5267311653144929, 'Total loss': 0.5267311653144929}
2022-11-28 04:53:53,852 INFO:     Found new best model at epoch 3
2022-11-28 04:53:53,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:53,853 INFO:     Epoch: 4
2022-11-28 04:53:54,511 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48222445967522537, 'Total loss': 0.48222445967522537} | train loss {'Reaction outcome loss': 0.513997548655701, 'Total loss': 0.513997548655701}
2022-11-28 04:53:54,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:54,512 INFO:     Epoch: 5
2022-11-28 04:53:55,171 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48651946268298407, 'Total loss': 0.48651946268298407} | train loss {'Reaction outcome loss': 0.5022543894375867, 'Total loss': 0.5022543894375867}
2022-11-28 04:53:55,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:55,171 INFO:     Epoch: 6
2022-11-28 04:53:55,828 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45020914721218025, 'Total loss': 0.45020914721218025} | train loss {'Reaction outcome loss': 0.49611328892138323, 'Total loss': 0.49611328892138323}
2022-11-28 04:53:55,828 INFO:     Found new best model at epoch 6
2022-11-28 04:53:55,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:55,829 INFO:     Epoch: 7
2022-11-28 04:53:56,485 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4345333755693652, 'Total loss': 0.4345333755693652} | train loss {'Reaction outcome loss': 0.4997693073411702, 'Total loss': 0.4997693073411702}
2022-11-28 04:53:56,485 INFO:     Found new best model at epoch 7
2022-11-28 04:53:56,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:56,486 INFO:     Epoch: 8
2022-11-28 04:53:57,143 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45127277076244354, 'Total loss': 0.45127277076244354} | train loss {'Reaction outcome loss': 0.5091562190881143, 'Total loss': 0.5091562190881143}
2022-11-28 04:53:57,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:57,144 INFO:     Epoch: 9
2022-11-28 04:53:57,803 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45748264681209216, 'Total loss': 0.45748264681209216} | train loss {'Reaction outcome loss': 0.4894452145104466, 'Total loss': 0.4894452145104466}
2022-11-28 04:53:57,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:57,804 INFO:     Epoch: 10
2022-11-28 04:53:58,462 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.451005337590521, 'Total loss': 0.451005337590521} | train loss {'Reaction outcome loss': 0.4825639701806582, 'Total loss': 0.4825639701806582}
2022-11-28 04:53:58,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:58,463 INFO:     Epoch: 11
2022-11-28 04:53:59,122 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4871030541306192, 'Total loss': 0.4871030541306192} | train loss {'Reaction outcome loss': 0.48094993541658165, 'Total loss': 0.48094993541658165}
2022-11-28 04:53:59,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:59,122 INFO:     Epoch: 12
2022-11-28 04:53:59,781 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42858234386552463, 'Total loss': 0.42858234386552463} | train loss {'Reaction outcome loss': 0.48071367061331205, 'Total loss': 0.48071367061331205}
2022-11-28 04:53:59,781 INFO:     Found new best model at epoch 12
2022-11-28 04:53:59,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:53:59,782 INFO:     Epoch: 13
2022-11-28 04:54:00,437 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5042821070687338, 'Total loss': 0.5042821070687338} | train loss {'Reaction outcome loss': 0.4837433431553937, 'Total loss': 0.4837433431553937}
2022-11-28 04:54:00,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:00,437 INFO:     Epoch: 14
2022-11-28 04:54:01,094 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4493455697189678, 'Total loss': 0.4493455697189678} | train loss {'Reaction outcome loss': 0.4754754883889486, 'Total loss': 0.4754754883889486}
2022-11-28 04:54:01,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:01,095 INFO:     Epoch: 15
2022-11-28 04:54:01,759 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42737548832188954, 'Total loss': 0.42737548832188954} | train loss {'Reaction outcome loss': 0.4729090290151627, 'Total loss': 0.4729090290151627}
2022-11-28 04:54:01,759 INFO:     Found new best model at epoch 15
2022-11-28 04:54:01,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:01,760 INFO:     Epoch: 16
2022-11-28 04:54:02,421 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4063424667851491, 'Total loss': 0.4063424667851491} | train loss {'Reaction outcome loss': 0.4643138095944826, 'Total loss': 0.4643138095944826}
2022-11-28 04:54:02,421 INFO:     Found new best model at epoch 16
2022-11-28 04:54:02,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:02,422 INFO:     Epoch: 17
2022-11-28 04:54:03,085 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4556900147687305, 'Total loss': 0.4556900147687305} | train loss {'Reaction outcome loss': 0.46417934281623313, 'Total loss': 0.46417934281623313}
2022-11-28 04:54:03,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:03,086 INFO:     Epoch: 18
2022-11-28 04:54:03,751 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.415716388347474, 'Total loss': 0.415716388347474} | train loss {'Reaction outcome loss': 0.4656247707151691, 'Total loss': 0.4656247707151691}
2022-11-28 04:54:03,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:03,751 INFO:     Epoch: 19
2022-11-28 04:54:04,411 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43655679510398343, 'Total loss': 0.43655679510398343} | train loss {'Reaction outcome loss': 0.4671303652536109, 'Total loss': 0.4671303652536109}
2022-11-28 04:54:04,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:04,411 INFO:     Epoch: 20
2022-11-28 04:54:05,073 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4468670016662641, 'Total loss': 0.4468670016662641} | train loss {'Reaction outcome loss': 0.4641901702895338, 'Total loss': 0.4641901702895338}
2022-11-28 04:54:05,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:05,073 INFO:     Epoch: 21
2022-11-28 04:54:05,744 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4582738138057969, 'Total loss': 0.4582738138057969} | train loss {'Reaction outcome loss': 0.4698095262024235, 'Total loss': 0.4698095262024235}
2022-11-28 04:54:05,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:05,744 INFO:     Epoch: 22
2022-11-28 04:54:06,410 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41709675098007376, 'Total loss': 0.41709675098007376} | train loss {'Reaction outcome loss': 0.45240059259690735, 'Total loss': 0.45240059259690735}
2022-11-28 04:54:06,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:06,410 INFO:     Epoch: 23
2022-11-28 04:54:07,069 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4433798359876329, 'Total loss': 0.4433798359876329} | train loss {'Reaction outcome loss': 0.46799498681838697, 'Total loss': 0.46799498681838697}
2022-11-28 04:54:07,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:07,069 INFO:     Epoch: 24
2022-11-28 04:54:07,728 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42883591387759556, 'Total loss': 0.42883591387759556} | train loss {'Reaction outcome loss': 0.4571817075053177, 'Total loss': 0.4571817075053177}
2022-11-28 04:54:07,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:07,728 INFO:     Epoch: 25
2022-11-28 04:54:08,388 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44972615756771783, 'Total loss': 0.44972615756771783} | train loss {'Reaction outcome loss': 0.45455945237928075, 'Total loss': 0.45455945237928075}
2022-11-28 04:54:08,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:08,388 INFO:     Epoch: 26
2022-11-28 04:54:09,059 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45821213959292934, 'Total loss': 0.45821213959292934} | train loss {'Reaction outcome loss': 0.460644095713793, 'Total loss': 0.460644095713793}
2022-11-28 04:54:09,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:09,059 INFO:     Epoch: 27
2022-11-28 04:54:09,722 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4254418865523555, 'Total loss': 0.4254418865523555} | train loss {'Reaction outcome loss': 0.46462638087962804, 'Total loss': 0.46462638087962804}
2022-11-28 04:54:09,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:09,722 INFO:     Epoch: 28
2022-11-28 04:54:10,384 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46871361238035286, 'Total loss': 0.46871361238035286} | train loss {'Reaction outcome loss': 0.4571368795582037, 'Total loss': 0.4571368795582037}
2022-11-28 04:54:10,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:10,385 INFO:     Epoch: 29
2022-11-28 04:54:11,053 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47262116826393386, 'Total loss': 0.47262116826393386} | train loss {'Reaction outcome loss': 0.4510562584437581, 'Total loss': 0.4510562584437581}
2022-11-28 04:54:11,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:11,054 INFO:     Epoch: 30
2022-11-28 04:54:11,719 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4247010746462779, 'Total loss': 0.4247010746462779} | train loss {'Reaction outcome loss': 0.44964642965834334, 'Total loss': 0.44964642965834334}
2022-11-28 04:54:11,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:11,719 INFO:     Epoch: 31
2022-11-28 04:54:12,383 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45736888321963226, 'Total loss': 0.45736888321963226} | train loss {'Reaction outcome loss': 0.45758682465263706, 'Total loss': 0.45758682465263706}
2022-11-28 04:54:12,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:12,383 INFO:     Epoch: 32
2022-11-28 04:54:13,045 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44658770886334503, 'Total loss': 0.44658770886334503} | train loss {'Reaction outcome loss': 0.4621568151753441, 'Total loss': 0.4621568151753441}
2022-11-28 04:54:13,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:13,046 INFO:     Epoch: 33
2022-11-28 04:54:13,712 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41788945110006764, 'Total loss': 0.41788945110006764} | train loss {'Reaction outcome loss': 0.4567553956317998, 'Total loss': 0.4567553956317998}
2022-11-28 04:54:13,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:13,713 INFO:     Epoch: 34
2022-11-28 04:54:14,376 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44943704997951334, 'Total loss': 0.44943704997951334} | train loss {'Reaction outcome loss': 0.45257394887160074, 'Total loss': 0.45257394887160074}
2022-11-28 04:54:14,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:14,377 INFO:     Epoch: 35
2022-11-28 04:54:15,043 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4182879826561971, 'Total loss': 0.4182879826561971} | train loss {'Reaction outcome loss': 0.463413661214342, 'Total loss': 0.463413661214342}
2022-11-28 04:54:15,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:15,043 INFO:     Epoch: 36
2022-11-28 04:54:15,707 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4202386855401776, 'Total loss': 0.4202386855401776} | train loss {'Reaction outcome loss': 0.46257487729734736, 'Total loss': 0.46257487729734736}
2022-11-28 04:54:15,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:15,708 INFO:     Epoch: 37
2022-11-28 04:54:16,373 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42090985720807855, 'Total loss': 0.42090985720807855} | train loss {'Reaction outcome loss': 0.46839875278443943, 'Total loss': 0.46839875278443943}
2022-11-28 04:54:16,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:16,374 INFO:     Epoch: 38
2022-11-28 04:54:17,044 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4152153320610523, 'Total loss': 0.4152153320610523} | train loss {'Reaction outcome loss': 0.4502017586096096, 'Total loss': 0.4502017586096096}
2022-11-28 04:54:17,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:17,044 INFO:     Epoch: 39
2022-11-28 04:54:17,710 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44934458895163104, 'Total loss': 0.44934458895163104} | train loss {'Reaction outcome loss': 0.4636791727320868, 'Total loss': 0.4636791727320868}
2022-11-28 04:54:17,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:17,711 INFO:     Epoch: 40
2022-11-28 04:54:18,380 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41740386526692996, 'Total loss': 0.41740386526692996} | train loss {'Reaction outcome loss': 0.45826990948424406, 'Total loss': 0.45826990948424406}
2022-11-28 04:54:18,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:18,381 INFO:     Epoch: 41
2022-11-28 04:54:19,050 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47889710048382933, 'Total loss': 0.47889710048382933} | train loss {'Reaction outcome loss': 0.4634489430951686, 'Total loss': 0.4634489430951686}
2022-11-28 04:54:19,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:19,050 INFO:     Epoch: 42
2022-11-28 04:54:19,715 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41039174727418204, 'Total loss': 0.41039174727418204} | train loss {'Reaction outcome loss': 0.45507610287622885, 'Total loss': 0.45507610287622885}
2022-11-28 04:54:19,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:19,715 INFO:     Epoch: 43
2022-11-28 04:54:20,383 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4095975902270187, 'Total loss': 0.4095975902270187} | train loss {'Reaction outcome loss': 0.45973487373305716, 'Total loss': 0.45973487373305716}
2022-11-28 04:54:20,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:20,383 INFO:     Epoch: 44
2022-11-28 04:54:21,051 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4128203683278777, 'Total loss': 0.4128203683278777} | train loss {'Reaction outcome loss': 0.4576300421224432, 'Total loss': 0.4576300421224432}
2022-11-28 04:54:21,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:21,052 INFO:     Epoch: 45
2022-11-28 04:54:21,716 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40858764556998556, 'Total loss': 0.40858764556998556} | train loss {'Reaction outcome loss': 0.4516328895683231, 'Total loss': 0.4516328895683231}
2022-11-28 04:54:21,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:21,717 INFO:     Epoch: 46
2022-11-28 04:54:22,384 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4319302629340779, 'Total loss': 0.4319302629340779} | train loss {'Reaction outcome loss': 0.45261275098632703, 'Total loss': 0.45261275098632703}
2022-11-28 04:54:22,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:22,384 INFO:     Epoch: 47
2022-11-28 04:54:23,055 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4065568509765647, 'Total loss': 0.4065568509765647} | train loss {'Reaction outcome loss': 0.4525233300229316, 'Total loss': 0.4525233300229316}
2022-11-28 04:54:23,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:23,055 INFO:     Epoch: 48
2022-11-28 04:54:23,725 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42063105749812996, 'Total loss': 0.42063105749812996} | train loss {'Reaction outcome loss': 0.45298033210671385, 'Total loss': 0.45298033210671385}
2022-11-28 04:54:23,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:23,725 INFO:     Epoch: 49
2022-11-28 04:54:24,390 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4374414343725551, 'Total loss': 0.4374414343725551} | train loss {'Reaction outcome loss': 0.4487951455358793, 'Total loss': 0.4487951455358793}
2022-11-28 04:54:24,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:24,390 INFO:     Epoch: 50
2022-11-28 04:54:25,056 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42630950700153003, 'Total loss': 0.42630950700153003} | train loss {'Reaction outcome loss': 0.45895399958430694, 'Total loss': 0.45895399958430694}
2022-11-28 04:54:25,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:25,056 INFO:     Epoch: 51
2022-11-28 04:54:25,723 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42777655222876504, 'Total loss': 0.42777655222876504} | train loss {'Reaction outcome loss': 0.4536284643870134, 'Total loss': 0.4536284643870134}
2022-11-28 04:54:25,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:25,724 INFO:     Epoch: 52
2022-11-28 04:54:26,389 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4132568060674451, 'Total loss': 0.4132568060674451} | train loss {'Reaction outcome loss': 0.46372655586071826, 'Total loss': 0.46372655586071826}
2022-11-28 04:54:26,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:26,389 INFO:     Epoch: 53
2022-11-28 04:54:27,058 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4370849193497138, 'Total loss': 0.4370849193497138} | train loss {'Reaction outcome loss': 0.45682747378523053, 'Total loss': 0.45682747378523053}
2022-11-28 04:54:27,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:27,059 INFO:     Epoch: 54
2022-11-28 04:54:27,727 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4030867378142747, 'Total loss': 0.4030867378142747} | train loss {'Reaction outcome loss': 0.46026463426182024, 'Total loss': 0.46026463426182024}
2022-11-28 04:54:27,727 INFO:     Found new best model at epoch 54
2022-11-28 04:54:27,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:27,728 INFO:     Epoch: 55
2022-11-28 04:54:28,391 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4384187419306148, 'Total loss': 0.4384187419306148} | train loss {'Reaction outcome loss': 0.45033364516762103, 'Total loss': 0.45033364516762103}
2022-11-28 04:54:28,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:28,392 INFO:     Epoch: 56
2022-11-28 04:54:29,053 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4708779063075781, 'Total loss': 0.4708779063075781} | train loss {'Reaction outcome loss': 0.4591199631995035, 'Total loss': 0.4591199631995035}
2022-11-28 04:54:29,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:29,053 INFO:     Epoch: 57
2022-11-28 04:54:29,714 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4597659483551979, 'Total loss': 0.4597659483551979} | train loss {'Reaction outcome loss': 0.4506366563553692, 'Total loss': 0.4506366563553692}
2022-11-28 04:54:29,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:29,715 INFO:     Epoch: 58
2022-11-28 04:54:30,377 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44306313686750154, 'Total loss': 0.44306313686750154} | train loss {'Reaction outcome loss': 0.46851418284993424, 'Total loss': 0.46851418284993424}
2022-11-28 04:54:30,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:30,378 INFO:     Epoch: 59
2022-11-28 04:54:31,045 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4221011464568702, 'Total loss': 0.4221011464568702} | train loss {'Reaction outcome loss': 0.4694128928758837, 'Total loss': 0.4694128928758837}
2022-11-28 04:54:31,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:31,045 INFO:     Epoch: 60
2022-11-28 04:54:31,710 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42975915341892024, 'Total loss': 0.42975915341892024} | train loss {'Reaction outcome loss': 0.4622230459803994, 'Total loss': 0.4622230459803994}
2022-11-28 04:54:31,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:31,711 INFO:     Epoch: 61
2022-11-28 04:54:32,374 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46314205872741615, 'Total loss': 0.46314205872741615} | train loss {'Reaction outcome loss': 0.460664199582237, 'Total loss': 0.460664199582237}
2022-11-28 04:54:32,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:32,375 INFO:     Epoch: 62
2022-11-28 04:54:33,041 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4476554664698514, 'Total loss': 0.4476554664698514} | train loss {'Reaction outcome loss': 0.47231149408016126, 'Total loss': 0.47231149408016126}
2022-11-28 04:54:33,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:33,042 INFO:     Epoch: 63
2022-11-28 04:54:33,706 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42645804956555367, 'Total loss': 0.42645804956555367} | train loss {'Reaction outcome loss': 0.45490986486304896, 'Total loss': 0.45490986486304896}
2022-11-28 04:54:33,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:33,706 INFO:     Epoch: 64
2022-11-28 04:54:34,371 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44303695214065636, 'Total loss': 0.44303695214065636} | train loss {'Reaction outcome loss': 0.45600082443250334, 'Total loss': 0.45600082443250334}
2022-11-28 04:54:34,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:34,371 INFO:     Epoch: 65
2022-11-28 04:54:35,032 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4270681498402899, 'Total loss': 0.4270681498402899} | train loss {'Reaction outcome loss': 0.4578948034207348, 'Total loss': 0.4578948034207348}
2022-11-28 04:54:35,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:35,033 INFO:     Epoch: 66
2022-11-28 04:54:35,697 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43539007075808267, 'Total loss': 0.43539007075808267} | train loss {'Reaction outcome loss': 0.45563540646904394, 'Total loss': 0.45563540646904394}
2022-11-28 04:54:35,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:35,698 INFO:     Epoch: 67
2022-11-28 04:54:36,361 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4793622757900845, 'Total loss': 0.4793622757900845} | train loss {'Reaction outcome loss': 0.4624414988133589, 'Total loss': 0.4624414988133589}
2022-11-28 04:54:36,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:36,361 INFO:     Epoch: 68
2022-11-28 04:54:37,028 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46451172503558075, 'Total loss': 0.46451172503558075} | train loss {'Reaction outcome loss': 0.46792839111586815, 'Total loss': 0.46792839111586815}
2022-11-28 04:54:37,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:37,028 INFO:     Epoch: 69
2022-11-28 04:54:37,693 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47042896259914746, 'Total loss': 0.47042896259914746} | train loss {'Reaction outcome loss': 0.4542847011494733, 'Total loss': 0.4542847011494733}
2022-11-28 04:54:37,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:37,694 INFO:     Epoch: 70
2022-11-28 04:54:38,358 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4437343640760942, 'Total loss': 0.4437343640760942} | train loss {'Reaction outcome loss': 0.453354927782829, 'Total loss': 0.453354927782829}
2022-11-28 04:54:38,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:38,358 INFO:     Epoch: 71
2022-11-28 04:54:39,022 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.414416355504231, 'Total loss': 0.414416355504231} | train loss {'Reaction outcome loss': 0.4514987040084866, 'Total loss': 0.4514987040084866}
2022-11-28 04:54:39,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:39,023 INFO:     Epoch: 72
2022-11-28 04:54:39,687 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42484936626120046, 'Total loss': 0.42484936626120046} | train loss {'Reaction outcome loss': 0.4550503738495985, 'Total loss': 0.4550503738495985}
2022-11-28 04:54:39,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:39,688 INFO:     Epoch: 73
2022-11-28 04:54:40,355 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4250817099078135, 'Total loss': 0.4250817099078135} | train loss {'Reaction outcome loss': 0.4567341094436916, 'Total loss': 0.4567341094436916}
2022-11-28 04:54:40,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:40,355 INFO:     Epoch: 74
2022-11-28 04:54:41,023 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.421230476688255, 'Total loss': 0.421230476688255} | train loss {'Reaction outcome loss': 0.4581674416719178, 'Total loss': 0.4581674416719178}
2022-11-28 04:54:41,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:41,023 INFO:     Epoch: 75
2022-11-28 04:54:41,687 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4223137204958634, 'Total loss': 0.4223137204958634} | train loss {'Reaction outcome loss': 0.4527750926823751, 'Total loss': 0.4527750926823751}
2022-11-28 04:54:41,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:41,687 INFO:     Epoch: 76
2022-11-28 04:54:42,354 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41643133894963696, 'Total loss': 0.41643133894963696} | train loss {'Reaction outcome loss': 0.4611544981297211, 'Total loss': 0.4611544981297211}
2022-11-28 04:54:42,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:42,355 INFO:     Epoch: 77
2022-11-28 04:54:43,023 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4708634167909622, 'Total loss': 0.4708634167909622} | train loss {'Reaction outcome loss': 0.4574276395896186, 'Total loss': 0.4574276395896186}
2022-11-28 04:54:43,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:43,023 INFO:     Epoch: 78
2022-11-28 04:54:43,687 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4309545748613097, 'Total loss': 0.4309545748613097} | train loss {'Reaction outcome loss': 0.4494203451741864, 'Total loss': 0.4494203451741864}
2022-11-28 04:54:43,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:43,687 INFO:     Epoch: 79
2022-11-28 04:54:44,352 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44512511722066184, 'Total loss': 0.44512511722066184} | train loss {'Reaction outcome loss': 0.46188993474491213, 'Total loss': 0.46188993474491213}
2022-11-28 04:54:44,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:44,352 INFO:     Epoch: 80
2022-11-28 04:54:45,018 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.448410688476129, 'Total loss': 0.448410688476129} | train loss {'Reaction outcome loss': 0.4571288864011405, 'Total loss': 0.4571288864011405}
2022-11-28 04:54:45,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:45,018 INFO:     Epoch: 81
2022-11-28 04:54:45,684 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4274478060278026, 'Total loss': 0.4274478060278026} | train loss {'Reaction outcome loss': 0.4596727782113832, 'Total loss': 0.4596727782113832}
2022-11-28 04:54:45,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:45,685 INFO:     Epoch: 82
2022-11-28 04:54:46,347 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.424875417385589, 'Total loss': 0.424875417385589} | train loss {'Reaction outcome loss': 0.4567712334075166, 'Total loss': 0.4567712334075166}
2022-11-28 04:54:46,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:46,347 INFO:     Epoch: 83
2022-11-28 04:54:47,011 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40714071233841503, 'Total loss': 0.40714071233841503} | train loss {'Reaction outcome loss': 0.45199649974040174, 'Total loss': 0.45199649974040174}
2022-11-28 04:54:47,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:47,011 INFO:     Epoch: 84
2022-11-28 04:54:47,675 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45333422178571875, 'Total loss': 0.45333422178571875} | train loss {'Reaction outcome loss': 0.45599462659011486, 'Total loss': 0.45599462659011486}
2022-11-28 04:54:47,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:47,675 INFO:     Epoch: 85
2022-11-28 04:54:48,342 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4274256354705854, 'Total loss': 0.4274256354705854} | train loss {'Reaction outcome loss': 0.4536392392839497, 'Total loss': 0.4536392392839497}
2022-11-28 04:54:48,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:48,342 INFO:     Epoch: 86
2022-11-28 04:54:49,007 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43864984895018017, 'Total loss': 0.43864984895018017} | train loss {'Reaction outcome loss': 0.4587009958470399, 'Total loss': 0.4587009958470399}
2022-11-28 04:54:49,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:49,008 INFO:     Epoch: 87
2022-11-28 04:54:49,673 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45207638666033745, 'Total loss': 0.45207638666033745} | train loss {'Reaction outcome loss': 0.4616460629440995, 'Total loss': 0.4616460629440995}
2022-11-28 04:54:49,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:49,673 INFO:     Epoch: 88
2022-11-28 04:54:50,337 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4744982658462091, 'Total loss': 0.4744982658462091} | train loss {'Reaction outcome loss': 0.4553838361729585, 'Total loss': 0.4553838361729585}
2022-11-28 04:54:50,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:50,337 INFO:     Epoch: 89
2022-11-28 04:54:51,000 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4179604764689099, 'Total loss': 0.4179604764689099} | train loss {'Reaction outcome loss': 0.4568206815705126, 'Total loss': 0.4568206815705126}
2022-11-28 04:54:51,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:51,001 INFO:     Epoch: 90
2022-11-28 04:54:51,663 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4371193088591099, 'Total loss': 0.4371193088591099} | train loss {'Reaction outcome loss': 0.4598474005455913, 'Total loss': 0.4598474005455913}
2022-11-28 04:54:51,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:51,663 INFO:     Epoch: 91
2022-11-28 04:54:52,329 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41165209087458526, 'Total loss': 0.41165209087458526} | train loss {'Reaction outcome loss': 0.45771786327726444, 'Total loss': 0.45771786327726444}
2022-11-28 04:54:52,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:52,329 INFO:     Epoch: 92
2022-11-28 04:54:52,997 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40113710950721393, 'Total loss': 0.40113710950721393} | train loss {'Reaction outcome loss': 0.449800529663813, 'Total loss': 0.449800529663813}
2022-11-28 04:54:52,997 INFO:     Found new best model at epoch 92
2022-11-28 04:54:52,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:52,998 INFO:     Epoch: 93
2022-11-28 04:54:53,662 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42892063510688866, 'Total loss': 0.42892063510688866} | train loss {'Reaction outcome loss': 0.454294567294268, 'Total loss': 0.454294567294268}
2022-11-28 04:54:53,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:53,662 INFO:     Epoch: 94
2022-11-28 04:54:54,328 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.424562063745477, 'Total loss': 0.424562063745477} | train loss {'Reaction outcome loss': 0.45113228621557055, 'Total loss': 0.45113228621557055}
2022-11-28 04:54:54,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:54,328 INFO:     Epoch: 95
2022-11-28 04:54:54,990 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4527262232520364, 'Total loss': 0.4527262232520364} | train loss {'Reaction outcome loss': 0.4533265027922657, 'Total loss': 0.4533265027922657}
2022-11-28 04:54:54,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:54,991 INFO:     Epoch: 96
2022-11-28 04:54:55,656 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43699803406542, 'Total loss': 0.43699803406542} | train loss {'Reaction outcome loss': 0.4640707004408122, 'Total loss': 0.4640707004408122}
2022-11-28 04:54:55,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:55,656 INFO:     Epoch: 97
2022-11-28 04:54:56,323 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4269569489088925, 'Total loss': 0.4269569489088925} | train loss {'Reaction outcome loss': 0.4628246522504791, 'Total loss': 0.4628246522504791}
2022-11-28 04:54:56,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:56,323 INFO:     Epoch: 98
2022-11-28 04:54:56,991 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4225548996844075, 'Total loss': 0.4225548996844075} | train loss {'Reaction outcome loss': 0.4477492312633014, 'Total loss': 0.4477492312633014}
2022-11-28 04:54:56,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:56,991 INFO:     Epoch: 99
2022-11-28 04:54:57,661 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44097665358673444, 'Total loss': 0.44097665358673444} | train loss {'Reaction outcome loss': 0.46184209139964844, 'Total loss': 0.46184209139964844}
2022-11-28 04:54:57,661 INFO:     Best model found after epoch 93 of 100.
2022-11-28 04:54:57,661 INFO:   Done with stage: TRAINING
2022-11-28 04:54:57,661 INFO:   Starting stage: EVALUATION
2022-11-28 04:54:57,779 INFO:   Done with stage: EVALUATION
2022-11-28 04:54:57,788 INFO:   Leaving out SEQ value Fold_0
2022-11-28 04:54:57,801 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:54:57,801 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:54:58,444 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:54:58,444 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:54:58,515 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:54:58,515 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:54:58,515 INFO:     No hyperparam tuning for this model
2022-11-28 04:54:58,515 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:54:58,515 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:54:58,516 INFO:     None feature selector for col prot
2022-11-28 04:54:58,516 INFO:     None feature selector for col prot
2022-11-28 04:54:58,516 INFO:     None feature selector for col prot
2022-11-28 04:54:58,517 INFO:     None feature selector for col chem
2022-11-28 04:54:58,517 INFO:     None feature selector for col chem
2022-11-28 04:54:58,517 INFO:     None feature selector for col chem
2022-11-28 04:54:58,517 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:54:58,517 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:54:58,519 INFO:     Number of params in model 169651
2022-11-28 04:54:58,522 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:54:58,522 INFO:   Starting stage: TRAINING
2022-11-28 04:54:58,574 INFO:     Val loss before train {'Reaction outcome loss': 0.9887467839501121, 'Total loss': 0.9887467839501121}
2022-11-28 04:54:58,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:58,574 INFO:     Epoch: 0
2022-11-28 04:54:59,240 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5423988489942118, 'Total loss': 0.5423988489942118} | train loss {'Reaction outcome loss': 0.6912886273523091, 'Total loss': 0.6912886273523091}
2022-11-28 04:54:59,240 INFO:     Found new best model at epoch 0
2022-11-28 04:54:59,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:59,241 INFO:     Epoch: 1
2022-11-28 04:54:59,911 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5536810498345982, 'Total loss': 0.5536810498345982} | train loss {'Reaction outcome loss': 0.5891255468793726, 'Total loss': 0.5891255468793726}
2022-11-28 04:54:59,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:54:59,911 INFO:     Epoch: 2
2022-11-28 04:55:00,579 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5541658225384626, 'Total loss': 0.5541658225384626} | train loss {'Reaction outcome loss': 0.5601604564590492, 'Total loss': 0.5601604564590492}
2022-11-28 04:55:00,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:00,580 INFO:     Epoch: 3
2022-11-28 04:55:01,246 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4995565725998445, 'Total loss': 0.4995565725998445} | train loss {'Reaction outcome loss': 0.5445189171429226, 'Total loss': 0.5445189171429226}
2022-11-28 04:55:01,247 INFO:     Found new best model at epoch 3
2022-11-28 04:55:01,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:01,248 INFO:     Epoch: 4
2022-11-28 04:55:01,911 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48623375391418283, 'Total loss': 0.48623375391418283} | train loss {'Reaction outcome loss': 0.5219768227835898, 'Total loss': 0.5219768227835898}
2022-11-28 04:55:01,911 INFO:     Found new best model at epoch 4
2022-11-28 04:55:01,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:01,912 INFO:     Epoch: 5
2022-11-28 04:55:02,576 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5262180725959215, 'Total loss': 0.5262180725959215} | train loss {'Reaction outcome loss': 0.5172283754416322, 'Total loss': 0.5172283754416322}
2022-11-28 04:55:02,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:02,577 INFO:     Epoch: 6
2022-11-28 04:55:03,242 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4859560782259161, 'Total loss': 0.4859560782259161} | train loss {'Reaction outcome loss': 0.5327981823851705, 'Total loss': 0.5327981823851705}
2022-11-28 04:55:03,242 INFO:     Found new best model at epoch 6
2022-11-28 04:55:03,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:03,243 INFO:     Epoch: 7
2022-11-28 04:55:03,908 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4679574644701047, 'Total loss': 0.4679574644701047} | train loss {'Reaction outcome loss': 0.5120059275313428, 'Total loss': 0.5120059275313428}
2022-11-28 04:55:03,908 INFO:     Found new best model at epoch 7
2022-11-28 04:55:03,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:03,909 INFO:     Epoch: 8
2022-11-28 04:55:04,573 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4699609066275033, 'Total loss': 0.4699609066275033} | train loss {'Reaction outcome loss': 0.5065968141020069, 'Total loss': 0.5065968141020069}
2022-11-28 04:55:04,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:04,574 INFO:     Epoch: 9
2022-11-28 04:55:05,235 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4599780243906108, 'Total loss': 0.4599780243906108} | train loss {'Reaction outcome loss': 0.4979674851122173, 'Total loss': 0.4979674851122173}
2022-11-28 04:55:05,235 INFO:     Found new best model at epoch 9
2022-11-28 04:55:05,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:05,236 INFO:     Epoch: 10
2022-11-28 04:55:05,899 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4724792858416384, 'Total loss': 0.4724792858416384} | train loss {'Reaction outcome loss': 0.48796410525315687, 'Total loss': 0.48796410525315687}
2022-11-28 04:55:05,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:05,900 INFO:     Epoch: 11
2022-11-28 04:55:06,564 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45284605872902, 'Total loss': 0.45284605872902} | train loss {'Reaction outcome loss': 0.4802482846053506, 'Total loss': 0.4802482846053506}
2022-11-28 04:55:06,564 INFO:     Found new best model at epoch 11
2022-11-28 04:55:06,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:06,565 INFO:     Epoch: 12
2022-11-28 04:55:07,226 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46000667119568045, 'Total loss': 0.46000667119568045} | train loss {'Reaction outcome loss': 0.4853960545318812, 'Total loss': 0.4853960545318812}
2022-11-28 04:55:07,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:07,226 INFO:     Epoch: 13
2022-11-28 04:55:07,890 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4430453919551589, 'Total loss': 0.4430453919551589} | train loss {'Reaction outcome loss': 0.4896554030508165, 'Total loss': 0.4896554030508165}
2022-11-28 04:55:07,890 INFO:     Found new best model at epoch 13
2022-11-28 04:55:07,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:07,891 INFO:     Epoch: 14
2022-11-28 04:55:08,553 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.451809150590138, 'Total loss': 0.451809150590138} | train loss {'Reaction outcome loss': 0.4928182631369062, 'Total loss': 0.4928182631369062}
2022-11-28 04:55:08,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:08,553 INFO:     Epoch: 15
2022-11-28 04:55:09,218 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5507992079312151, 'Total loss': 0.5507992079312151} | train loss {'Reaction outcome loss': 0.48449259100534653, 'Total loss': 0.48449259100534653}
2022-11-28 04:55:09,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:09,218 INFO:     Epoch: 16
2022-11-28 04:55:09,881 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4910107671537183, 'Total loss': 0.4910107671537183} | train loss {'Reaction outcome loss': 0.48553388361604166, 'Total loss': 0.48553388361604166}
2022-11-28 04:55:09,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:09,882 INFO:     Epoch: 17
2022-11-28 04:55:10,543 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48601612042297015, 'Total loss': 0.48601612042297015} | train loss {'Reaction outcome loss': 0.4837226729221672, 'Total loss': 0.4837226729221672}
2022-11-28 04:55:10,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:10,543 INFO:     Epoch: 18
2022-11-28 04:55:11,204 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4653393927622925, 'Total loss': 0.4653393927622925} | train loss {'Reaction outcome loss': 0.4837522426476845, 'Total loss': 0.4837522426476845}
2022-11-28 04:55:11,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:11,204 INFO:     Epoch: 19
2022-11-28 04:55:11,868 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4576610990545966, 'Total loss': 0.4576610990545966} | train loss {'Reaction outcome loss': 0.4760296425107218, 'Total loss': 0.4760296425107218}
2022-11-28 04:55:11,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:11,869 INFO:     Epoch: 20
2022-11-28 04:55:12,532 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45612932165915315, 'Total loss': 0.45612932165915315} | train loss {'Reaction outcome loss': 0.4782324905096278, 'Total loss': 0.4782324905096278}
2022-11-28 04:55:12,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:12,532 INFO:     Epoch: 21
2022-11-28 04:55:13,200 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4675466408106414, 'Total loss': 0.4675466408106414} | train loss {'Reaction outcome loss': 0.4753423131934484, 'Total loss': 0.4753423131934484}
2022-11-28 04:55:13,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:13,200 INFO:     Epoch: 22
2022-11-28 04:55:13,865 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43351444364948705, 'Total loss': 0.43351444364948705} | train loss {'Reaction outcome loss': 0.47421007841704826, 'Total loss': 0.47421007841704826}
2022-11-28 04:55:13,866 INFO:     Found new best model at epoch 22
2022-11-28 04:55:13,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:13,867 INFO:     Epoch: 23
2022-11-28 04:55:14,529 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44187897545370186, 'Total loss': 0.44187897545370186} | train loss {'Reaction outcome loss': 0.49712379898136927, 'Total loss': 0.49712379898136927}
2022-11-28 04:55:14,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:14,529 INFO:     Epoch: 24
2022-11-28 04:55:15,194 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44833289222283795, 'Total loss': 0.44833289222283795} | train loss {'Reaction outcome loss': 0.4972106751642729, 'Total loss': 0.4972106751642729}
2022-11-28 04:55:15,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:15,194 INFO:     Epoch: 25
2022-11-28 04:55:15,860 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4723084850067442, 'Total loss': 0.4723084850067442} | train loss {'Reaction outcome loss': 0.4817936116987877, 'Total loss': 0.4817936116987877}
2022-11-28 04:55:15,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:15,861 INFO:     Epoch: 26
2022-11-28 04:55:16,523 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4915440570224415, 'Total loss': 0.4915440570224415} | train loss {'Reaction outcome loss': 0.4811143812983625, 'Total loss': 0.4811143812983625}
2022-11-28 04:55:16,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:16,523 INFO:     Epoch: 27
2022-11-28 04:55:17,185 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4455979225987738, 'Total loss': 0.4455979225987738} | train loss {'Reaction outcome loss': 0.4758601253211257, 'Total loss': 0.4758601253211257}
2022-11-28 04:55:17,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:17,186 INFO:     Epoch: 28
2022-11-28 04:55:17,847 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44475734572518955, 'Total loss': 0.44475734572518955} | train loss {'Reaction outcome loss': 0.46631379829727204, 'Total loss': 0.46631379829727204}
2022-11-28 04:55:17,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:17,847 INFO:     Epoch: 29
2022-11-28 04:55:18,509 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43149602751840244, 'Total loss': 0.43149602751840244} | train loss {'Reaction outcome loss': 0.4746794067775672, 'Total loss': 0.4746794067775672}
2022-11-28 04:55:18,509 INFO:     Found new best model at epoch 29
2022-11-28 04:55:18,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:18,510 INFO:     Epoch: 30
2022-11-28 04:55:19,173 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4680556355213577, 'Total loss': 0.4680556355213577} | train loss {'Reaction outcome loss': 0.4706126208386953, 'Total loss': 0.4706126208386953}
2022-11-28 04:55:19,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:19,173 INFO:     Epoch: 31
2022-11-28 04:55:19,836 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46536614847454155, 'Total loss': 0.46536614847454155} | train loss {'Reaction outcome loss': 0.47489587238684355, 'Total loss': 0.47489587238684355}
2022-11-28 04:55:19,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:19,837 INFO:     Epoch: 32
2022-11-28 04:55:20,499 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47096950289877976, 'Total loss': 0.47096950289877976} | train loss {'Reaction outcome loss': 0.4777340654204581, 'Total loss': 0.4777340654204581}
2022-11-28 04:55:20,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:20,500 INFO:     Epoch: 33
2022-11-28 04:55:21,162 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46107917109673674, 'Total loss': 0.46107917109673674} | train loss {'Reaction outcome loss': 0.466172905435205, 'Total loss': 0.466172905435205}
2022-11-28 04:55:21,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:21,162 INFO:     Epoch: 34
2022-11-28 04:55:21,824 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46606979620727623, 'Total loss': 0.46606979620727623} | train loss {'Reaction outcome loss': 0.4845809115149714, 'Total loss': 0.4845809115149714}
2022-11-28 04:55:21,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:21,824 INFO:     Epoch: 35
2022-11-28 04:55:22,485 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45389660921963776, 'Total loss': 0.45389660921963776} | train loss {'Reaction outcome loss': 0.47187117496241443, 'Total loss': 0.47187117496241443}
2022-11-28 04:55:22,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:22,485 INFO:     Epoch: 36
2022-11-28 04:55:23,147 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4320318079130216, 'Total loss': 0.4320318079130216} | train loss {'Reaction outcome loss': 0.47056494544633487, 'Total loss': 0.47056494544633487}
2022-11-28 04:55:23,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:23,147 INFO:     Epoch: 37
2022-11-28 04:55:23,809 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45142347348684614, 'Total loss': 0.45142347348684614} | train loss {'Reaction outcome loss': 0.46689510794906963, 'Total loss': 0.46689510794906963}
2022-11-28 04:55:23,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:23,810 INFO:     Epoch: 38
2022-11-28 04:55:24,477 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4423383559015664, 'Total loss': 0.4423383559015664} | train loss {'Reaction outcome loss': 0.46496789148341305, 'Total loss': 0.46496789148341305}
2022-11-28 04:55:24,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:24,477 INFO:     Epoch: 39
2022-11-28 04:55:25,143 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44865724207325414, 'Total loss': 0.44865724207325414} | train loss {'Reaction outcome loss': 0.45985010658439834, 'Total loss': 0.45985010658439834}
2022-11-28 04:55:25,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:25,143 INFO:     Epoch: 40
2022-11-28 04:55:25,808 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44083076512271707, 'Total loss': 0.44083076512271707} | train loss {'Reaction outcome loss': 0.4739157600339638, 'Total loss': 0.4739157600339638}
2022-11-28 04:55:25,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:25,808 INFO:     Epoch: 41
2022-11-28 04:55:26,474 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4514916054904461, 'Total loss': 0.4514916054904461} | train loss {'Reaction outcome loss': 0.4625476535394607, 'Total loss': 0.4625476535394607}
2022-11-28 04:55:26,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:26,474 INFO:     Epoch: 42
2022-11-28 04:55:27,138 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46859937466003676, 'Total loss': 0.46859937466003676} | train loss {'Reaction outcome loss': 0.4690780350071216, 'Total loss': 0.4690780350071216}
2022-11-28 04:55:27,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:27,138 INFO:     Epoch: 43
2022-11-28 04:55:27,804 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44072124463590706, 'Total loss': 0.44072124463590706} | train loss {'Reaction outcome loss': 0.47074824042980246, 'Total loss': 0.47074824042980246}
2022-11-28 04:55:27,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:27,804 INFO:     Epoch: 44
2022-11-28 04:55:28,472 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4342282099479979, 'Total loss': 0.4342282099479979} | train loss {'Reaction outcome loss': 0.46292548358199087, 'Total loss': 0.46292548358199087}
2022-11-28 04:55:28,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:28,472 INFO:     Epoch: 45
2022-11-28 04:55:29,135 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4452453873712908, 'Total loss': 0.4452453873712908} | train loss {'Reaction outcome loss': 0.48193843234405825, 'Total loss': 0.48193843234405825}
2022-11-28 04:55:29,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:29,135 INFO:     Epoch: 46
2022-11-28 04:55:29,798 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.452964458275925, 'Total loss': 0.452964458275925} | train loss {'Reaction outcome loss': 0.46627065086895636, 'Total loss': 0.46627065086895636}
2022-11-28 04:55:29,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:29,798 INFO:     Epoch: 47
2022-11-28 04:55:30,463 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43733315508474, 'Total loss': 0.43733315508474} | train loss {'Reaction outcome loss': 0.4717514268782457, 'Total loss': 0.4717514268782457}
2022-11-28 04:55:30,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:30,463 INFO:     Epoch: 48
2022-11-28 04:55:31,126 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4383714690127156, 'Total loss': 0.4383714690127156} | train loss {'Reaction outcome loss': 0.46958881357179477, 'Total loss': 0.46958881357179477}
2022-11-28 04:55:31,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:31,126 INFO:     Epoch: 49
2022-11-28 04:55:31,786 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4757212298837575, 'Total loss': 0.4757212298837575} | train loss {'Reaction outcome loss': 0.47182501532770843, 'Total loss': 0.47182501532770843}
2022-11-28 04:55:31,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:31,787 INFO:     Epoch: 50
2022-11-28 04:55:32,447 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4627484245733781, 'Total loss': 0.4627484245733781} | train loss {'Reaction outcome loss': 0.4790559468964333, 'Total loss': 0.4790559468964333}
2022-11-28 04:55:32,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:32,448 INFO:     Epoch: 51
2022-11-28 04:55:33,112 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45460210605101153, 'Total loss': 0.45460210605101153} | train loss {'Reaction outcome loss': 0.4778347203606053, 'Total loss': 0.4778347203606053}
2022-11-28 04:55:33,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:33,113 INFO:     Epoch: 52
2022-11-28 04:55:33,777 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43419401483102277, 'Total loss': 0.43419401483102277} | train loss {'Reaction outcome loss': 0.4719741693754428, 'Total loss': 0.4719741693754428}
2022-11-28 04:55:33,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:33,777 INFO:     Epoch: 53
2022-11-28 04:55:34,439 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44277581064538524, 'Total loss': 0.44277581064538524} | train loss {'Reaction outcome loss': 0.45496834795601543, 'Total loss': 0.45496834795601543}
2022-11-28 04:55:34,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:34,439 INFO:     Epoch: 54
2022-11-28 04:55:35,103 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47122830017046496, 'Total loss': 0.47122830017046496} | train loss {'Reaction outcome loss': 0.4686632495418734, 'Total loss': 0.4686632495418734}
2022-11-28 04:55:35,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:35,104 INFO:     Epoch: 55
2022-11-28 04:55:35,769 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4792229912497781, 'Total loss': 0.4792229912497781} | train loss {'Reaction outcome loss': 0.4732516844443947, 'Total loss': 0.4732516844443947}
2022-11-28 04:55:35,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:35,769 INFO:     Epoch: 56
2022-11-28 04:55:36,431 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4601915935901078, 'Total loss': 0.4601915935901078} | train loss {'Reaction outcome loss': 0.4721153222838877, 'Total loss': 0.4721153222838877}
2022-11-28 04:55:36,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:36,431 INFO:     Epoch: 57
2022-11-28 04:55:37,095 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45239960368384013, 'Total loss': 0.45239960368384013} | train loss {'Reaction outcome loss': 0.4792715242879111, 'Total loss': 0.4792715242879111}
2022-11-28 04:55:37,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:37,095 INFO:     Epoch: 58
2022-11-28 04:55:37,757 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45305578444491734, 'Total loss': 0.45305578444491734} | train loss {'Reaction outcome loss': 0.48186691031463236, 'Total loss': 0.48186691031463236}
2022-11-28 04:55:37,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:37,757 INFO:     Epoch: 59
2022-11-28 04:55:38,421 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43131867118857126, 'Total loss': 0.43131867118857126} | train loss {'Reaction outcome loss': 0.46571529907012277, 'Total loss': 0.46571529907012277}
2022-11-28 04:55:38,421 INFO:     Found new best model at epoch 59
2022-11-28 04:55:38,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:38,422 INFO:     Epoch: 60
2022-11-28 04:55:39,086 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4540113821964372, 'Total loss': 0.4540113821964372} | train loss {'Reaction outcome loss': 0.4711553564197139, 'Total loss': 0.4711553564197139}
2022-11-28 04:55:39,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:39,086 INFO:     Epoch: 61
2022-11-28 04:55:39,749 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4335574419661002, 'Total loss': 0.4335574419661002} | train loss {'Reaction outcome loss': 0.4647308135073376, 'Total loss': 0.4647308135073376}
2022-11-28 04:55:39,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:39,749 INFO:     Epoch: 62
2022-11-28 04:55:40,411 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4620116295462305, 'Total loss': 0.4620116295462305} | train loss {'Reaction outcome loss': 0.4613464823320719, 'Total loss': 0.4613464823320719}
2022-11-28 04:55:40,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:40,411 INFO:     Epoch: 63
2022-11-28 04:55:41,073 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43875265561721544, 'Total loss': 0.43875265561721544} | train loss {'Reaction outcome loss': 0.4728218640581618, 'Total loss': 0.4728218640581618}
2022-11-28 04:55:41,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:41,073 INFO:     Epoch: 64
2022-11-28 04:55:41,735 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4408794323151762, 'Total loss': 0.4408794323151762} | train loss {'Reaction outcome loss': 0.46830694498079506, 'Total loss': 0.46830694498079506}
2022-11-28 04:55:41,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:41,735 INFO:     Epoch: 65
2022-11-28 04:55:42,396 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5261032635515387, 'Total loss': 0.5261032635515387} | train loss {'Reaction outcome loss': 0.4733631315260281, 'Total loss': 0.4733631315260281}
2022-11-28 04:55:42,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:42,396 INFO:     Epoch: 66
2022-11-28 04:55:43,058 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45345687019554054, 'Total loss': 0.45345687019554054} | train loss {'Reaction outcome loss': 0.47489789007646355, 'Total loss': 0.47489789007646355}
2022-11-28 04:55:43,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:43,058 INFO:     Epoch: 67
2022-11-28 04:55:43,720 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4417013261805881, 'Total loss': 0.4417013261805881} | train loss {'Reaction outcome loss': 0.4756395378214145, 'Total loss': 0.4756395378214145}
2022-11-28 04:55:43,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:43,720 INFO:     Epoch: 68
2022-11-28 04:55:44,385 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47043314847079193, 'Total loss': 0.47043314847079193} | train loss {'Reaction outcome loss': 0.4646162605478696, 'Total loss': 0.4646162605478696}
2022-11-28 04:55:44,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:44,386 INFO:     Epoch: 69
2022-11-28 04:55:45,047 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4283002550629052, 'Total loss': 0.4283002550629052} | train loss {'Reaction outcome loss': 0.4606958315651185, 'Total loss': 0.4606958315651185}
2022-11-28 04:55:45,047 INFO:     Found new best model at epoch 69
2022-11-28 04:55:45,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:45,048 INFO:     Epoch: 70
2022-11-28 04:55:45,711 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46702512726187706, 'Total loss': 0.46702512726187706} | train loss {'Reaction outcome loss': 0.4725602961744857, 'Total loss': 0.4725602961744857}
2022-11-28 04:55:45,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:45,711 INFO:     Epoch: 71
2022-11-28 04:55:46,376 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4729564569213174, 'Total loss': 0.4729564569213174} | train loss {'Reaction outcome loss': 0.4713706217615711, 'Total loss': 0.4713706217615711}
2022-11-28 04:55:46,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:46,376 INFO:     Epoch: 72
2022-11-28 04:55:47,040 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.465686406601559, 'Total loss': 0.465686406601559} | train loss {'Reaction outcome loss': 0.4624671417209301, 'Total loss': 0.4624671417209301}
2022-11-28 04:55:47,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:47,040 INFO:     Epoch: 73
2022-11-28 04:55:47,703 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45241129195148294, 'Total loss': 0.45241129195148294} | train loss {'Reaction outcome loss': 0.46598126773952475, 'Total loss': 0.46598126773952475}
2022-11-28 04:55:47,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:47,703 INFO:     Epoch: 74
2022-11-28 04:55:48,366 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45342291044917976, 'Total loss': 0.45342291044917976} | train loss {'Reaction outcome loss': 0.4646264889733753, 'Total loss': 0.4646264889733753}
2022-11-28 04:55:48,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:48,366 INFO:     Epoch: 75
2022-11-28 04:55:49,032 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4603306654502045, 'Total loss': 0.4603306654502045} | train loss {'Reaction outcome loss': 0.46474819848698523, 'Total loss': 0.46474819848698523}
2022-11-28 04:55:49,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:49,032 INFO:     Epoch: 76
2022-11-28 04:55:49,693 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43285075067119166, 'Total loss': 0.43285075067119166} | train loss {'Reaction outcome loss': 0.47648829758649897, 'Total loss': 0.47648829758649897}
2022-11-28 04:55:49,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:49,694 INFO:     Epoch: 77
2022-11-28 04:55:50,354 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45389943663030863, 'Total loss': 0.45389943663030863} | train loss {'Reaction outcome loss': 0.4676589385921188, 'Total loss': 0.4676589385921188}
2022-11-28 04:55:50,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:50,354 INFO:     Epoch: 78
2022-11-28 04:55:51,015 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43810729242183943, 'Total loss': 0.43810729242183943} | train loss {'Reaction outcome loss': 0.4716647576374805, 'Total loss': 0.4716647576374805}
2022-11-28 04:55:51,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:51,016 INFO:     Epoch: 79
2022-11-28 04:55:51,679 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4379949132827195, 'Total loss': 0.4379949132827195} | train loss {'Reaction outcome loss': 0.46639887007285163, 'Total loss': 0.46639887007285163}
2022-11-28 04:55:51,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:51,679 INFO:     Epoch: 80
2022-11-28 04:55:52,344 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4572951929135756, 'Total loss': 0.4572951929135756} | train loss {'Reaction outcome loss': 0.4665792937341489, 'Total loss': 0.4665792937341489}
2022-11-28 04:55:52,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:52,344 INFO:     Epoch: 81
2022-11-28 04:55:53,008 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4899559478190812, 'Total loss': 0.4899559478190812} | train loss {'Reaction outcome loss': 0.47959212071039836, 'Total loss': 0.47959212071039836}
2022-11-28 04:55:53,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:53,008 INFO:     Epoch: 82
2022-11-28 04:55:53,672 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4375675381584601, 'Total loss': 0.4375675381584601} | train loss {'Reaction outcome loss': 0.47156392852304435, 'Total loss': 0.47156392852304435}
2022-11-28 04:55:53,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:53,672 INFO:     Epoch: 83
2022-11-28 04:55:54,336 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4260339896109971, 'Total loss': 0.4260339896109971} | train loss {'Reaction outcome loss': 0.47658348376089743, 'Total loss': 0.47658348376089743}
2022-11-28 04:55:54,336 INFO:     Found new best model at epoch 83
2022-11-28 04:55:54,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:54,337 INFO:     Epoch: 84
2022-11-28 04:55:55,001 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49879156865856866, 'Total loss': 0.49879156865856866} | train loss {'Reaction outcome loss': 0.4655367646437998, 'Total loss': 0.4655367646437998}
2022-11-28 04:55:55,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:55,001 INFO:     Epoch: 85
2022-11-28 04:55:55,662 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48773070627992804, 'Total loss': 0.48773070627992804} | train loss {'Reaction outcome loss': 0.4688742003339505, 'Total loss': 0.4688742003339505}
2022-11-28 04:55:55,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:55,662 INFO:     Epoch: 86
2022-11-28 04:55:56,324 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4255333175374703, 'Total loss': 0.4255333175374703} | train loss {'Reaction outcome loss': 0.4678432537838515, 'Total loss': 0.4678432537838515}
2022-11-28 04:55:56,324 INFO:     Found new best model at epoch 86
2022-11-28 04:55:56,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:56,324 INFO:     Epoch: 87
2022-11-28 04:55:56,986 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4522248746996576, 'Total loss': 0.4522248746996576} | train loss {'Reaction outcome loss': 0.46379280374724763, 'Total loss': 0.46379280374724763}
2022-11-28 04:55:56,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:56,987 INFO:     Epoch: 88
2022-11-28 04:55:57,651 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46475965343415737, 'Total loss': 0.46475965343415737} | train loss {'Reaction outcome loss': 0.4613159038805165, 'Total loss': 0.4613159038805165}
2022-11-28 04:55:57,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:57,651 INFO:     Epoch: 89
2022-11-28 04:55:58,311 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4480047628960826, 'Total loss': 0.4480047628960826} | train loss {'Reaction outcome loss': 0.46753607853221507, 'Total loss': 0.46753607853221507}
2022-11-28 04:55:58,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:58,311 INFO:     Epoch: 90
2022-11-28 04:55:58,974 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48469595136967575, 'Total loss': 0.48469595136967575} | train loss {'Reaction outcome loss': 0.4635017344102203, 'Total loss': 0.4635017344102203}
2022-11-28 04:55:58,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:58,974 INFO:     Epoch: 91
2022-11-28 04:55:59,633 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4642349058254199, 'Total loss': 0.4642349058254199} | train loss {'Reaction outcome loss': 0.4635058874302065, 'Total loss': 0.4635058874302065}
2022-11-28 04:55:59,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:55:59,634 INFO:     Epoch: 92
2022-11-28 04:56:00,295 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48938804593953217, 'Total loss': 0.48938804593953217} | train loss {'Reaction outcome loss': 0.47804719143309576, 'Total loss': 0.47804719143309576}
2022-11-28 04:56:00,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:00,296 INFO:     Epoch: 93
2022-11-28 04:56:00,961 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44498667967590416, 'Total loss': 0.44498667967590416} | train loss {'Reaction outcome loss': 0.4696224613891922, 'Total loss': 0.4696224613891922}
2022-11-28 04:56:00,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:00,962 INFO:     Epoch: 94
2022-11-28 04:56:01,627 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4640016278082674, 'Total loss': 0.4640016278082674} | train loss {'Reaction outcome loss': 0.4684570647987277, 'Total loss': 0.4684570647987277}
2022-11-28 04:56:01,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:01,627 INFO:     Epoch: 95
2022-11-28 04:56:02,291 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4675775962797078, 'Total loss': 0.4675775962797078} | train loss {'Reaction outcome loss': 0.48202266601415783, 'Total loss': 0.48202266601415783}
2022-11-28 04:56:02,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:02,292 INFO:     Epoch: 96
2022-11-28 04:56:02,951 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.446812292560935, 'Total loss': 0.446812292560935} | train loss {'Reaction outcome loss': 0.4861929208522866, 'Total loss': 0.4861929208522866}
2022-11-28 04:56:02,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:02,952 INFO:     Epoch: 97
2022-11-28 04:56:03,616 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44915114918893034, 'Total loss': 0.44915114918893034} | train loss {'Reaction outcome loss': 0.46491052433546737, 'Total loss': 0.46491052433546737}
2022-11-28 04:56:03,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:03,617 INFO:     Epoch: 98
2022-11-28 04:56:04,281 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46462020210244437, 'Total loss': 0.46462020210244437} | train loss {'Reaction outcome loss': 0.46234205801809125, 'Total loss': 0.46234205801809125}
2022-11-28 04:56:04,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:04,281 INFO:     Epoch: 99
2022-11-28 04:56:04,944 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42807133157144894, 'Total loss': 0.42807133157144894} | train loss {'Reaction outcome loss': 0.4676080974014966, 'Total loss': 0.4676080974014966}
2022-11-28 04:56:04,944 INFO:     Best model found after epoch 87 of 100.
2022-11-28 04:56:04,944 INFO:   Done with stage: TRAINING
2022-11-28 04:56:04,944 INFO:   Starting stage: EVALUATION
2022-11-28 04:56:05,062 INFO:   Done with stage: EVALUATION
2022-11-28 04:56:05,062 INFO:   Leaving out SEQ value Fold_1
2022-11-28 04:56:05,075 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:56:05,075 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:56:05,717 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:56:05,717 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:56:05,788 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:56:05,788 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:56:05,788 INFO:     No hyperparam tuning for this model
2022-11-28 04:56:05,788 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:56:05,788 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:56:05,789 INFO:     None feature selector for col prot
2022-11-28 04:56:05,789 INFO:     None feature selector for col prot
2022-11-28 04:56:05,789 INFO:     None feature selector for col prot
2022-11-28 04:56:05,789 INFO:     None feature selector for col chem
2022-11-28 04:56:05,790 INFO:     None feature selector for col chem
2022-11-28 04:56:05,790 INFO:     None feature selector for col chem
2022-11-28 04:56:05,790 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:56:05,790 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:56:05,791 INFO:     Number of params in model 169651
2022-11-28 04:56:05,794 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:56:05,794 INFO:   Starting stage: TRAINING
2022-11-28 04:56:05,845 INFO:     Val loss before train {'Reaction outcome loss': 0.9954598153179343, 'Total loss': 0.9954598153179343}
2022-11-28 04:56:05,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:05,846 INFO:     Epoch: 0
2022-11-28 04:56:06,511 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6163772039792754, 'Total loss': 0.6163772039792754} | train loss {'Reaction outcome loss': 0.7033461901823036, 'Total loss': 0.7033461901823036}
2022-11-28 04:56:06,511 INFO:     Found new best model at epoch 0
2022-11-28 04:56:06,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:06,512 INFO:     Epoch: 1
2022-11-28 04:56:07,175 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5620664520697161, 'Total loss': 0.5620664520697161} | train loss {'Reaction outcome loss': 0.5950109807827212, 'Total loss': 0.5950109807827212}
2022-11-28 04:56:07,175 INFO:     Found new best model at epoch 1
2022-11-28 04:56:07,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:07,176 INFO:     Epoch: 2
2022-11-28 04:56:07,840 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5055187585001643, 'Total loss': 0.5055187585001643} | train loss {'Reaction outcome loss': 0.5536645922493114, 'Total loss': 0.5536645922493114}
2022-11-28 04:56:07,840 INFO:     Found new best model at epoch 2
2022-11-28 04:56:07,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:07,841 INFO:     Epoch: 3
2022-11-28 04:56:08,509 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.505262010476806, 'Total loss': 0.505262010476806} | train loss {'Reaction outcome loss': 0.5445734251607285, 'Total loss': 0.5445734251607285}
2022-11-28 04:56:08,509 INFO:     Found new best model at epoch 3
2022-11-28 04:56:08,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:08,510 INFO:     Epoch: 4
2022-11-28 04:56:09,175 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5549084527248686, 'Total loss': 0.5549084527248686} | train loss {'Reaction outcome loss': 0.5366125019335071, 'Total loss': 0.5366125019335071}
2022-11-28 04:56:09,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:09,175 INFO:     Epoch: 5
2022-11-28 04:56:09,836 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47754339196465234, 'Total loss': 0.47754339196465234} | train loss {'Reaction outcome loss': 0.5278559240855669, 'Total loss': 0.5278559240855669}
2022-11-28 04:56:09,836 INFO:     Found new best model at epoch 5
2022-11-28 04:56:09,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:09,837 INFO:     Epoch: 6
2022-11-28 04:56:10,497 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5187460807236758, 'Total loss': 0.5187460807236758} | train loss {'Reaction outcome loss': 0.5200840875446072, 'Total loss': 0.5200840875446072}
2022-11-28 04:56:10,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:10,497 INFO:     Epoch: 7
2022-11-28 04:56:11,158 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48034715313803067, 'Total loss': 0.48034715313803067} | train loss {'Reaction outcome loss': 0.5171912249162612, 'Total loss': 0.5171912249162612}
2022-11-28 04:56:11,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:11,159 INFO:     Epoch: 8
2022-11-28 04:56:11,823 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48890571228482504, 'Total loss': 0.48890571228482504} | train loss {'Reaction outcome loss': 0.5177039282042005, 'Total loss': 0.5177039282042005}
2022-11-28 04:56:11,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:11,823 INFO:     Epoch: 9
2022-11-28 04:56:12,488 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47993608902801166, 'Total loss': 0.47993608902801166} | train loss {'Reaction outcome loss': 0.5000079480501322, 'Total loss': 0.5000079480501322}
2022-11-28 04:56:12,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:12,488 INFO:     Epoch: 10
2022-11-28 04:56:13,153 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46789818934418936, 'Total loss': 0.46789818934418936} | train loss {'Reaction outcome loss': 0.5023641241827475, 'Total loss': 0.5023641241827475}
2022-11-28 04:56:13,154 INFO:     Found new best model at epoch 10
2022-11-28 04:56:13,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:13,154 INFO:     Epoch: 11
2022-11-28 04:56:13,820 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4685542746023698, 'Total loss': 0.4685542746023698} | train loss {'Reaction outcome loss': 0.5036765423411058, 'Total loss': 0.5036765423411058}
2022-11-28 04:56:13,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:13,820 INFO:     Epoch: 12
2022-11-28 04:56:14,483 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45760899917645886, 'Total loss': 0.45760899917645886} | train loss {'Reaction outcome loss': 0.48426964149060037, 'Total loss': 0.48426964149060037}
2022-11-28 04:56:14,483 INFO:     Found new best model at epoch 12
2022-11-28 04:56:14,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:14,484 INFO:     Epoch: 13
2022-11-28 04:56:15,141 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.492534187707034, 'Total loss': 0.492534187707034} | train loss {'Reaction outcome loss': 0.48589649202249313, 'Total loss': 0.48589649202249313}
2022-11-28 04:56:15,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:15,141 INFO:     Epoch: 14
2022-11-28 04:56:15,803 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.464868404309858, 'Total loss': 0.464868404309858} | train loss {'Reaction outcome loss': 0.49476889240355626, 'Total loss': 0.49476889240355626}
2022-11-28 04:56:15,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:15,804 INFO:     Epoch: 15
2022-11-28 04:56:16,465 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4579247398809953, 'Total loss': 0.4579247398809953} | train loss {'Reaction outcome loss': 0.4887730806673828, 'Total loss': 0.4887730806673828}
2022-11-28 04:56:16,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:16,465 INFO:     Epoch: 16
2022-11-28 04:56:17,127 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4503235623917796, 'Total loss': 0.4503235623917796} | train loss {'Reaction outcome loss': 0.4839751861431223, 'Total loss': 0.4839751861431223}
2022-11-28 04:56:17,127 INFO:     Found new best model at epoch 16
2022-11-28 04:56:17,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:17,128 INFO:     Epoch: 17
2022-11-28 04:56:17,789 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5448517836630344, 'Total loss': 0.5448517836630344} | train loss {'Reaction outcome loss': 0.48781508876968493, 'Total loss': 0.48781508876968493}
2022-11-28 04:56:17,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:17,789 INFO:     Epoch: 18
2022-11-28 04:56:18,449 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4743170575662093, 'Total loss': 0.4743170575662093} | train loss {'Reaction outcome loss': 0.4897512374860555, 'Total loss': 0.4897512374860555}
2022-11-28 04:56:18,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:18,450 INFO:     Epoch: 19
2022-11-28 04:56:19,112 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45986357669938693, 'Total loss': 0.45986357669938693} | train loss {'Reaction outcome loss': 0.47875051278817027, 'Total loss': 0.47875051278817027}
2022-11-28 04:56:19,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:19,112 INFO:     Epoch: 20
2022-11-28 04:56:19,771 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4383032677525824, 'Total loss': 0.4383032677525824} | train loss {'Reaction outcome loss': 0.48490753100227246, 'Total loss': 0.48490753100227246}
2022-11-28 04:56:19,771 INFO:     Found new best model at epoch 20
2022-11-28 04:56:19,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:19,772 INFO:     Epoch: 21
2022-11-28 04:56:20,433 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4548999115147374, 'Total loss': 0.4548999115147374} | train loss {'Reaction outcome loss': 0.4857333018953501, 'Total loss': 0.4857333018953501}
2022-11-28 04:56:20,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:20,434 INFO:     Epoch: 22
2022-11-28 04:56:21,093 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46310691230676393, 'Total loss': 0.46310691230676393} | train loss {'Reaction outcome loss': 0.4787247952541359, 'Total loss': 0.4787247952541359}
2022-11-28 04:56:21,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:21,094 INFO:     Epoch: 23
2022-11-28 04:56:21,758 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4294630932536992, 'Total loss': 0.4294630932536992} | train loss {'Reaction outcome loss': 0.47887821911800244, 'Total loss': 0.47887821911800244}
2022-11-28 04:56:21,758 INFO:     Found new best model at epoch 23
2022-11-28 04:56:21,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:21,759 INFO:     Epoch: 24
2022-11-28 04:56:22,425 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4727903198112141, 'Total loss': 0.4727903198112141} | train loss {'Reaction outcome loss': 0.4763848356872435, 'Total loss': 0.4763848356872435}
2022-11-28 04:56:22,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:22,425 INFO:     Epoch: 25
2022-11-28 04:56:23,083 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4557715372436426, 'Total loss': 0.4557715372436426} | train loss {'Reaction outcome loss': 0.4842234246643931, 'Total loss': 0.4842234246643931}
2022-11-28 04:56:23,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:23,084 INFO:     Epoch: 26
2022-11-28 04:56:23,745 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5150309465825558, 'Total loss': 0.5150309465825558} | train loss {'Reaction outcome loss': 0.48981444555738196, 'Total loss': 0.48981444555738196}
2022-11-28 04:56:23,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:23,745 INFO:     Epoch: 27
2022-11-28 04:56:24,408 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43888006765734067, 'Total loss': 0.43888006765734067} | train loss {'Reaction outcome loss': 0.48143095628694, 'Total loss': 0.48143095628694}
2022-11-28 04:56:24,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:24,408 INFO:     Epoch: 28
2022-11-28 04:56:25,069 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4850802594287829, 'Total loss': 0.4850802594287829} | train loss {'Reaction outcome loss': 0.4788569082253375, 'Total loss': 0.4788569082253375}
2022-11-28 04:56:25,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:25,070 INFO:     Epoch: 29
2022-11-28 04:56:25,732 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4343535260043361, 'Total loss': 0.4343535260043361} | train loss {'Reaction outcome loss': 0.4905189748717706, 'Total loss': 0.4905189748717706}
2022-11-28 04:56:25,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:25,732 INFO:     Epoch: 30
2022-11-28 04:56:26,399 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.49064741419120267, 'Total loss': 0.49064741419120267} | train loss {'Reaction outcome loss': 0.4860916308425216, 'Total loss': 0.4860916308425216}
2022-11-28 04:56:26,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:26,399 INFO:     Epoch: 31
2022-11-28 04:56:27,063 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4759755991399288, 'Total loss': 0.4759755991399288} | train loss {'Reaction outcome loss': 0.4801706878038553, 'Total loss': 0.4801706878038553}
2022-11-28 04:56:27,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:27,063 INFO:     Epoch: 32
2022-11-28 04:56:27,730 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4456971748308702, 'Total loss': 0.4456971748308702} | train loss {'Reaction outcome loss': 0.4768593530905874, 'Total loss': 0.4768593530905874}
2022-11-28 04:56:27,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:27,730 INFO:     Epoch: 33
2022-11-28 04:56:28,395 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45468034425919707, 'Total loss': 0.45468034425919707} | train loss {'Reaction outcome loss': 0.4829114582012539, 'Total loss': 0.4829114582012539}
2022-11-28 04:56:28,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:28,395 INFO:     Epoch: 34
2022-11-28 04:56:29,059 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4492656199092215, 'Total loss': 0.4492656199092215} | train loss {'Reaction outcome loss': 0.4844772460972249, 'Total loss': 0.4844772460972249}
2022-11-28 04:56:29,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:29,059 INFO:     Epoch: 35
2022-11-28 04:56:29,725 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4444518173960122, 'Total loss': 0.4444518173960122} | train loss {'Reaction outcome loss': 0.4846704856224871, 'Total loss': 0.4846704856224871}
2022-11-28 04:56:29,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:29,726 INFO:     Epoch: 36
2022-11-28 04:56:30,388 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4353865446014838, 'Total loss': 0.4353865446014838} | train loss {'Reaction outcome loss': 0.4809874869588016, 'Total loss': 0.4809874869588016}
2022-11-28 04:56:30,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:30,388 INFO:     Epoch: 37
2022-11-28 04:56:31,050 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45152564414522867, 'Total loss': 0.45152564414522867} | train loss {'Reaction outcome loss': 0.4755735829593199, 'Total loss': 0.4755735829593199}
2022-11-28 04:56:31,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:31,051 INFO:     Epoch: 38
2022-11-28 04:56:31,714 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48967166380448773, 'Total loss': 0.48967166380448773} | train loss {'Reaction outcome loss': 0.47029587635506503, 'Total loss': 0.47029587635506503}
2022-11-28 04:56:31,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:31,714 INFO:     Epoch: 39
2022-11-28 04:56:32,375 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49102961949326773, 'Total loss': 0.49102961949326773} | train loss {'Reaction outcome loss': 0.48103075542370316, 'Total loss': 0.48103075542370316}
2022-11-28 04:56:32,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:32,376 INFO:     Epoch: 40
2022-11-28 04:56:33,035 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48995444720441644, 'Total loss': 0.48995444720441644} | train loss {'Reaction outcome loss': 0.4802135103627255, 'Total loss': 0.4802135103627255}
2022-11-28 04:56:33,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:33,035 INFO:     Epoch: 41
2022-11-28 04:56:33,693 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4457684809511358, 'Total loss': 0.4457684809511358} | train loss {'Reaction outcome loss': 0.4674904805868261, 'Total loss': 0.4674904805868261}
2022-11-28 04:56:33,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:33,693 INFO:     Epoch: 42
2022-11-28 04:56:34,355 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4792263111607595, 'Total loss': 0.4792263111607595} | train loss {'Reaction outcome loss': 0.4689970175445321, 'Total loss': 0.4689970175445321}
2022-11-28 04:56:34,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:34,355 INFO:     Epoch: 43
2022-11-28 04:56:35,018 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.6259078437631781, 'Total loss': 0.6259078437631781} | train loss {'Reaction outcome loss': 0.478744522280056, 'Total loss': 0.478744522280056}
2022-11-28 04:56:35,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:35,019 INFO:     Epoch: 44
2022-11-28 04:56:35,682 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4430974291806871, 'Total loss': 0.4430974291806871} | train loss {'Reaction outcome loss': 0.486069514014596, 'Total loss': 0.486069514014596}
2022-11-28 04:56:35,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:35,682 INFO:     Epoch: 45
2022-11-28 04:56:36,343 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.442205724729733, 'Total loss': 0.442205724729733} | train loss {'Reaction outcome loss': 0.47953534391727526, 'Total loss': 0.47953534391727526}
2022-11-28 04:56:36,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:36,344 INFO:     Epoch: 46
2022-11-28 04:56:37,007 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44692822139371524, 'Total loss': 0.44692822139371524} | train loss {'Reaction outcome loss': 0.47974112026604565, 'Total loss': 0.47974112026604565}
2022-11-28 04:56:37,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:37,007 INFO:     Epoch: 47
2022-11-28 04:56:37,668 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47105075825344433, 'Total loss': 0.47105075825344433} | train loss {'Reaction outcome loss': 0.4802931155029096, 'Total loss': 0.4802931155029096}
2022-11-28 04:56:37,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:37,669 INFO:     Epoch: 48
2022-11-28 04:56:38,329 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4456190348348834, 'Total loss': 0.4456190348348834} | train loss {'Reaction outcome loss': 0.47488222996655266, 'Total loss': 0.47488222996655266}
2022-11-28 04:56:38,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:38,330 INFO:     Epoch: 49
2022-11-28 04:56:38,990 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5239379026673057, 'Total loss': 0.5239379026673057} | train loss {'Reaction outcome loss': 0.4842322470567487, 'Total loss': 0.4842322470567487}
2022-11-28 04:56:38,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:38,990 INFO:     Epoch: 50
2022-11-28 04:56:39,648 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4627574136988683, 'Total loss': 0.4627574136988683} | train loss {'Reaction outcome loss': 0.4815856951933641, 'Total loss': 0.4815856951933641}
2022-11-28 04:56:39,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:39,648 INFO:     Epoch: 51
2022-11-28 04:56:40,308 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.429906390607357, 'Total loss': 0.429906390607357} | train loss {'Reaction outcome loss': 0.4835787214610258, 'Total loss': 0.4835787214610258}
2022-11-28 04:56:40,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:40,308 INFO:     Epoch: 52
2022-11-28 04:56:40,967 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4560065763917836, 'Total loss': 0.4560065763917836} | train loss {'Reaction outcome loss': 0.4833282450070748, 'Total loss': 0.4833282450070748}
2022-11-28 04:56:40,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:40,967 INFO:     Epoch: 53
2022-11-28 04:56:41,628 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5051908804611727, 'Total loss': 0.5051908804611727} | train loss {'Reaction outcome loss': 0.4841054815512437, 'Total loss': 0.4841054815512437}
2022-11-28 04:56:41,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:41,629 INFO:     Epoch: 54
2022-11-28 04:56:42,292 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44553579059852794, 'Total loss': 0.44553579059852794} | train loss {'Reaction outcome loss': 0.4765590738490043, 'Total loss': 0.4765590738490043}
2022-11-28 04:56:42,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:42,292 INFO:     Epoch: 55
2022-11-28 04:56:42,954 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49314728074453096, 'Total loss': 0.49314728074453096} | train loss {'Reaction outcome loss': 0.47553407590881536, 'Total loss': 0.47553407590881536}
2022-11-28 04:56:42,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:42,954 INFO:     Epoch: 56
2022-11-28 04:56:43,613 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4522125240076672, 'Total loss': 0.4522125240076672} | train loss {'Reaction outcome loss': 0.491880757786967, 'Total loss': 0.491880757786967}
2022-11-28 04:56:43,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:43,614 INFO:     Epoch: 57
2022-11-28 04:56:44,270 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47843435034155846, 'Total loss': 0.47843435034155846} | train loss {'Reaction outcome loss': 0.48058588905373084, 'Total loss': 0.48058588905373084}
2022-11-28 04:56:44,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:44,271 INFO:     Epoch: 58
2022-11-28 04:56:44,929 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.451020710170269, 'Total loss': 0.451020710170269} | train loss {'Reaction outcome loss': 0.48603220302083716, 'Total loss': 0.48603220302083716}
2022-11-28 04:56:44,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:44,929 INFO:     Epoch: 59
2022-11-28 04:56:45,589 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4628548344427889, 'Total loss': 0.4628548344427889} | train loss {'Reaction outcome loss': 0.4812204383524806, 'Total loss': 0.4812204383524806}
2022-11-28 04:56:45,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:45,589 INFO:     Epoch: 60
2022-11-28 04:56:46,252 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45068899338895624, 'Total loss': 0.45068899338895624} | train loss {'Reaction outcome loss': 0.48217833795498016, 'Total loss': 0.48217833795498016}
2022-11-28 04:56:46,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:46,252 INFO:     Epoch: 61
2022-11-28 04:56:46,912 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45831129259683867, 'Total loss': 0.45831129259683867} | train loss {'Reaction outcome loss': 0.47652451543190216, 'Total loss': 0.47652451543190216}
2022-11-28 04:56:46,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:46,913 INFO:     Epoch: 62
2022-11-28 04:56:47,578 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4941999072378332, 'Total loss': 0.4941999072378332} | train loss {'Reaction outcome loss': 0.47543554225944074, 'Total loss': 0.47543554225944074}
2022-11-28 04:56:47,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:47,578 INFO:     Epoch: 63
2022-11-28 04:56:48,241 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4490324363789775, 'Total loss': 0.4490324363789775} | train loss {'Reaction outcome loss': 0.47405195721851184, 'Total loss': 0.47405195721851184}
2022-11-28 04:56:48,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:48,241 INFO:     Epoch: 64
2022-11-28 04:56:48,901 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4614487432620742, 'Total loss': 0.4614487432620742} | train loss {'Reaction outcome loss': 0.47515003955338586, 'Total loss': 0.47515003955338586}
2022-11-28 04:56:48,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:48,901 INFO:     Epoch: 65
2022-11-28 04:56:49,562 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4434811290014874, 'Total loss': 0.4434811290014874} | train loss {'Reaction outcome loss': 0.4814233357003826, 'Total loss': 0.4814233357003826}
2022-11-28 04:56:49,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:49,562 INFO:     Epoch: 66
2022-11-28 04:56:50,218 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4565729566595771, 'Total loss': 0.4565729566595771} | train loss {'Reaction outcome loss': 0.4802554378866667, 'Total loss': 0.4802554378866667}
2022-11-28 04:56:50,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:50,218 INFO:     Epoch: 67
2022-11-28 04:56:50,877 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44341095875610004, 'Total loss': 0.44341095875610004} | train loss {'Reaction outcome loss': 0.474933592957041, 'Total loss': 0.474933592957041}
2022-11-28 04:56:50,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:50,877 INFO:     Epoch: 68
2022-11-28 04:56:51,540 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.446208677847277, 'Total loss': 0.446208677847277} | train loss {'Reaction outcome loss': 0.48330578310528266, 'Total loss': 0.48330578310528266}
2022-11-28 04:56:51,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:51,540 INFO:     Epoch: 69
2022-11-28 04:56:52,199 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45335797288201074, 'Total loss': 0.45335797288201074} | train loss {'Reaction outcome loss': 0.4797884803793208, 'Total loss': 0.4797884803793208}
2022-11-28 04:56:52,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:52,200 INFO:     Epoch: 70
2022-11-28 04:56:52,860 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46632071990858426, 'Total loss': 0.46632071990858426} | train loss {'Reaction outcome loss': 0.4788906140449016, 'Total loss': 0.4788906140449016}
2022-11-28 04:56:52,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:52,861 INFO:     Epoch: 71
2022-11-28 04:56:53,522 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4579889178276062, 'Total loss': 0.4579889178276062} | train loss {'Reaction outcome loss': 0.47170412866210165, 'Total loss': 0.47170412866210165}
2022-11-28 04:56:53,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:53,523 INFO:     Epoch: 72
2022-11-28 04:56:54,183 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.436708276244727, 'Total loss': 0.436708276244727} | train loss {'Reaction outcome loss': 0.47412184677143326, 'Total loss': 0.47412184677143326}
2022-11-28 04:56:54,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:54,184 INFO:     Epoch: 73
2022-11-28 04:56:54,845 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4980332546613433, 'Total loss': 0.4980332546613433} | train loss {'Reaction outcome loss': 0.46861950579563133, 'Total loss': 0.46861950579563133}
2022-11-28 04:56:54,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:54,846 INFO:     Epoch: 74
2022-11-28 04:56:55,506 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4418486868115989, 'Total loss': 0.4418486868115989} | train loss {'Reaction outcome loss': 0.47999386148534806, 'Total loss': 0.47999386148534806}
2022-11-28 04:56:55,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:55,506 INFO:     Epoch: 75
2022-11-28 04:56:56,165 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46937609938057984, 'Total loss': 0.46937609938057984} | train loss {'Reaction outcome loss': 0.4719589411880565, 'Total loss': 0.4719589411880565}
2022-11-28 04:56:56,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:56,165 INFO:     Epoch: 76
2022-11-28 04:56:56,829 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4501548558473587, 'Total loss': 0.4501548558473587} | train loss {'Reaction outcome loss': 0.48276129262408746, 'Total loss': 0.48276129262408746}
2022-11-28 04:56:56,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:56,829 INFO:     Epoch: 77
2022-11-28 04:56:57,491 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4872449602593075, 'Total loss': 0.4872449602593075} | train loss {'Reaction outcome loss': 0.4943137418041345, 'Total loss': 0.4943137418041345}
2022-11-28 04:56:57,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:57,491 INFO:     Epoch: 78
2022-11-28 04:56:58,153 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46760051121765916, 'Total loss': 0.46760051121765916} | train loss {'Reaction outcome loss': 0.4768207553427229, 'Total loss': 0.4768207553427229}
2022-11-28 04:56:58,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:58,153 INFO:     Epoch: 79
2022-11-28 04:56:58,815 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44920657033270056, 'Total loss': 0.44920657033270056} | train loss {'Reaction outcome loss': 0.47483486160334304, 'Total loss': 0.47483486160334304}
2022-11-28 04:56:58,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:58,815 INFO:     Epoch: 80
2022-11-28 04:56:59,473 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4717457013374025, 'Total loss': 0.4717457013374025} | train loss {'Reaction outcome loss': 0.4761437937798288, 'Total loss': 0.4761437937798288}
2022-11-28 04:56:59,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:56:59,473 INFO:     Epoch: 81
2022-11-28 04:57:00,134 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45427708429369057, 'Total loss': 0.45427708429369057} | train loss {'Reaction outcome loss': 0.48242262359576576, 'Total loss': 0.48242262359576576}
2022-11-28 04:57:00,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:00,135 INFO:     Epoch: 82
2022-11-28 04:57:00,792 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46915899454192683, 'Total loss': 0.46915899454192683} | train loss {'Reaction outcome loss': 0.48681128266369283, 'Total loss': 0.48681128266369283}
2022-11-28 04:57:00,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:00,793 INFO:     Epoch: 83
2022-11-28 04:57:01,451 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45064572989940643, 'Total loss': 0.45064572989940643} | train loss {'Reaction outcome loss': 0.503867004926388, 'Total loss': 0.503867004926388}
2022-11-28 04:57:01,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:01,451 INFO:     Epoch: 84
2022-11-28 04:57:02,112 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4548521959646182, 'Total loss': 0.4548521959646182} | train loss {'Reaction outcome loss': 0.47339880137670376, 'Total loss': 0.47339880137670376}
2022-11-28 04:57:02,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:02,112 INFO:     Epoch: 85
2022-11-28 04:57:02,772 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4338830594312061, 'Total loss': 0.4338830594312061} | train loss {'Reaction outcome loss': 0.47508955912792733, 'Total loss': 0.47508955912792733}
2022-11-28 04:57:02,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:02,772 INFO:     Epoch: 86
2022-11-28 04:57:03,432 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4838106625459411, 'Total loss': 0.4838106625459411} | train loss {'Reaction outcome loss': 0.4760846073705296, 'Total loss': 0.4760846073705296}
2022-11-28 04:57:03,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:03,432 INFO:     Epoch: 87
2022-11-28 04:57:04,092 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4430325695059516, 'Total loss': 0.4430325695059516} | train loss {'Reaction outcome loss': 0.47513405001356535, 'Total loss': 0.47513405001356535}
2022-11-28 04:57:04,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:04,092 INFO:     Epoch: 88
2022-11-28 04:57:04,752 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4563737112012776, 'Total loss': 0.4563737112012776} | train loss {'Reaction outcome loss': 0.478942143349995, 'Total loss': 0.478942143349995}
2022-11-28 04:57:04,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:04,753 INFO:     Epoch: 89
2022-11-28 04:57:05,412 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4387107118964195, 'Total loss': 0.4387107118964195} | train loss {'Reaction outcome loss': 0.4772200528306034, 'Total loss': 0.4772200528306034}
2022-11-28 04:57:05,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:05,413 INFO:     Epoch: 90
2022-11-28 04:57:06,080 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48929434337399225, 'Total loss': 0.48929434337399225} | train loss {'Reaction outcome loss': 0.4798819624520989, 'Total loss': 0.4798819624520989}
2022-11-28 04:57:06,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:06,081 INFO:     Epoch: 91
2022-11-28 04:57:06,744 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44926930354400113, 'Total loss': 0.44926930354400113} | train loss {'Reaction outcome loss': 0.48544014598193924, 'Total loss': 0.48544014598193924}
2022-11-28 04:57:06,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:06,745 INFO:     Epoch: 92
2022-11-28 04:57:07,406 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46802064505490387, 'Total loss': 0.46802064505490387} | train loss {'Reaction outcome loss': 0.4826908723907432, 'Total loss': 0.4826908723907432}
2022-11-28 04:57:07,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:07,406 INFO:     Epoch: 93
2022-11-28 04:57:08,066 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45727580413222313, 'Total loss': 0.45727580413222313} | train loss {'Reaction outcome loss': 0.48062082521828564, 'Total loss': 0.48062082521828564}
2022-11-28 04:57:08,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:08,066 INFO:     Epoch: 94
2022-11-28 04:57:08,726 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5321157003160227, 'Total loss': 0.5321157003160227} | train loss {'Reaction outcome loss': 0.48540383305868157, 'Total loss': 0.48540383305868157}
2022-11-28 04:57:08,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:08,727 INFO:     Epoch: 95
2022-11-28 04:57:09,387 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45972216400233185, 'Total loss': 0.45972216400233185} | train loss {'Reaction outcome loss': 0.48004361033922266, 'Total loss': 0.48004361033922266}
2022-11-28 04:57:09,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:09,387 INFO:     Epoch: 96
2022-11-28 04:57:10,050 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46506256474690005, 'Total loss': 0.46506256474690005} | train loss {'Reaction outcome loss': 0.4783094935571616, 'Total loss': 0.4783094935571616}
2022-11-28 04:57:10,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:10,051 INFO:     Epoch: 97
2022-11-28 04:57:10,712 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45622646605426614, 'Total loss': 0.45622646605426614} | train loss {'Reaction outcome loss': 0.4688403826161676, 'Total loss': 0.4688403826161676}
2022-11-28 04:57:10,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:10,712 INFO:     Epoch: 98
2022-11-28 04:57:11,373 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44368363239548425, 'Total loss': 0.44368363239548425} | train loss {'Reaction outcome loss': 0.48268717867963257, 'Total loss': 0.48268717867963257}
2022-11-28 04:57:11,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:11,373 INFO:     Epoch: 99
2022-11-28 04:57:12,033 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.456627142700282, 'Total loss': 0.456627142700282} | train loss {'Reaction outcome loss': 0.4793050745841463, 'Total loss': 0.4793050745841463}
2022-11-28 04:57:12,033 INFO:     Best model found after epoch 24 of 100.
2022-11-28 04:57:12,034 INFO:   Done with stage: TRAINING
2022-11-28 04:57:12,034 INFO:   Starting stage: EVALUATION
2022-11-28 04:57:12,151 INFO:   Done with stage: EVALUATION
2022-11-28 04:57:12,151 INFO:   Leaving out SEQ value Fold_2
2022-11-28 04:57:12,164 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 04:57:12,164 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:57:12,795 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:57:12,795 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:57:12,863 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:57:12,864 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:57:12,864 INFO:     No hyperparam tuning for this model
2022-11-28 04:57:12,864 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:57:12,864 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:57:12,864 INFO:     None feature selector for col prot
2022-11-28 04:57:12,864 INFO:     None feature selector for col prot
2022-11-28 04:57:12,865 INFO:     None feature selector for col prot
2022-11-28 04:57:12,865 INFO:     None feature selector for col chem
2022-11-28 04:57:12,865 INFO:     None feature selector for col chem
2022-11-28 04:57:12,865 INFO:     None feature selector for col chem
2022-11-28 04:57:12,865 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:57:12,865 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:57:12,867 INFO:     Number of params in model 169651
2022-11-28 04:57:12,870 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:57:12,870 INFO:   Starting stage: TRAINING
2022-11-28 04:57:12,920 INFO:     Val loss before train {'Reaction outcome loss': 1.0193567262139431, 'Total loss': 1.0193567262139431}
2022-11-28 04:57:12,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:12,920 INFO:     Epoch: 0
2022-11-28 04:57:13,569 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5984844932722491, 'Total loss': 0.5984844932722491} | train loss {'Reaction outcome loss': 0.6775158436083403, 'Total loss': 0.6775158436083403}
2022-11-28 04:57:13,569 INFO:     Found new best model at epoch 0
2022-11-28 04:57:13,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:13,570 INFO:     Epoch: 1
2022-11-28 04:57:14,220 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.535349439049876, 'Total loss': 0.535349439049876} | train loss {'Reaction outcome loss': 0.571413274182648, 'Total loss': 0.571413274182648}
2022-11-28 04:57:14,220 INFO:     Found new best model at epoch 1
2022-11-28 04:57:14,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:14,221 INFO:     Epoch: 2
2022-11-28 04:57:14,874 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.55647490745367, 'Total loss': 0.55647490745367} | train loss {'Reaction outcome loss': 0.5491460909853216, 'Total loss': 0.5491460909853216}
2022-11-28 04:57:14,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:14,874 INFO:     Epoch: 3
2022-11-28 04:57:15,524 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5299011260964149, 'Total loss': 0.5299011260964149} | train loss {'Reaction outcome loss': 0.5316517182060929, 'Total loss': 0.5316517182060929}
2022-11-28 04:57:15,524 INFO:     Found new best model at epoch 3
2022-11-28 04:57:15,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:15,525 INFO:     Epoch: 4
2022-11-28 04:57:16,177 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5453320585711058, 'Total loss': 0.5453320585711058} | train loss {'Reaction outcome loss': 0.5138186589494104, 'Total loss': 0.5138186589494104}
2022-11-28 04:57:16,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:16,177 INFO:     Epoch: 5
2022-11-28 04:57:16,828 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5006538102793139, 'Total loss': 0.5006538102793139} | train loss {'Reaction outcome loss': 0.5008100011676061, 'Total loss': 0.5008100011676061}
2022-11-28 04:57:16,828 INFO:     Found new best model at epoch 5
2022-11-28 04:57:16,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:16,829 INFO:     Epoch: 6
2022-11-28 04:57:17,482 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5280948302080465, 'Total loss': 0.5280948302080465} | train loss {'Reaction outcome loss': 0.5008230981890296, 'Total loss': 0.5008230981890296}
2022-11-28 04:57:17,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:17,482 INFO:     Epoch: 7
2022-11-28 04:57:18,132 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49170319632042286, 'Total loss': 0.49170319632042286} | train loss {'Reaction outcome loss': 0.49704487414145077, 'Total loss': 0.49704487414145077}
2022-11-28 04:57:18,133 INFO:     Found new best model at epoch 7
2022-11-28 04:57:18,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:18,134 INFO:     Epoch: 8
2022-11-28 04:57:18,789 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49177151086718535, 'Total loss': 0.49177151086718535} | train loss {'Reaction outcome loss': 0.49182204315896894, 'Total loss': 0.49182204315896894}
2022-11-28 04:57:18,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:18,789 INFO:     Epoch: 9
2022-11-28 04:57:19,442 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.545242189321407, 'Total loss': 0.545242189321407} | train loss {'Reaction outcome loss': 0.4897106380858382, 'Total loss': 0.4897106380858382}
2022-11-28 04:57:19,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:19,442 INFO:     Epoch: 10
2022-11-28 04:57:20,090 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5265665241452151, 'Total loss': 0.5265665241452151} | train loss {'Reaction outcome loss': 0.49072435919622903, 'Total loss': 0.49072435919622903}
2022-11-28 04:57:20,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:20,091 INFO:     Epoch: 11
2022-11-28 04:57:20,741 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4832480057727459, 'Total loss': 0.4832480057727459} | train loss {'Reaction outcome loss': 0.48275349533460177, 'Total loss': 0.48275349533460177}
2022-11-28 04:57:20,741 INFO:     Found new best model at epoch 11
2022-11-28 04:57:20,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:20,742 INFO:     Epoch: 12
2022-11-28 04:57:21,392 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4724794861882232, 'Total loss': 0.4724794861882232} | train loss {'Reaction outcome loss': 0.47969410989861017, 'Total loss': 0.47969410989861017}
2022-11-28 04:57:21,392 INFO:     Found new best model at epoch 12
2022-11-28 04:57:21,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:21,393 INFO:     Epoch: 13
2022-11-28 04:57:22,045 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4769861528346705, 'Total loss': 0.4769861528346705} | train loss {'Reaction outcome loss': 0.4756176092158087, 'Total loss': 0.4756176092158087}
2022-11-28 04:57:22,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:22,045 INFO:     Epoch: 14
2022-11-28 04:57:22,699 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48476880719495374, 'Total loss': 0.48476880719495374} | train loss {'Reaction outcome loss': 0.47299770351316106, 'Total loss': 0.47299770351316106}
2022-11-28 04:57:22,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:22,699 INFO:     Epoch: 15
2022-11-28 04:57:23,356 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47623111238313276, 'Total loss': 0.47623111238313276} | train loss {'Reaction outcome loss': 0.4773927776478842, 'Total loss': 0.4773927776478842}
2022-11-28 04:57:23,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:23,356 INFO:     Epoch: 16
2022-11-28 04:57:24,007 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48233985069186186, 'Total loss': 0.48233985069186186} | train loss {'Reaction outcome loss': 0.4730335577223145, 'Total loss': 0.4730335577223145}
2022-11-28 04:57:24,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:24,007 INFO:     Epoch: 17
2022-11-28 04:57:24,656 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.485025986682537, 'Total loss': 0.485025986682537} | train loss {'Reaction outcome loss': 0.4743994930301045, 'Total loss': 0.4743994930301045}
2022-11-28 04:57:24,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:24,657 INFO:     Epoch: 18
2022-11-28 04:57:25,308 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5038930988588999, 'Total loss': 0.5038930988588999} | train loss {'Reaction outcome loss': 0.47396080482934344, 'Total loss': 0.47396080482934344}
2022-11-28 04:57:25,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:25,309 INFO:     Epoch: 19
2022-11-28 04:57:25,962 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47910412487595583, 'Total loss': 0.47910412487595583} | train loss {'Reaction outcome loss': 0.46611421573601786, 'Total loss': 0.46611421573601786}
2022-11-28 04:57:25,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:25,962 INFO:     Epoch: 20
2022-11-28 04:57:26,620 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5012743213149005, 'Total loss': 0.5012743213149005} | train loss {'Reaction outcome loss': 0.46046739328102987, 'Total loss': 0.46046739328102987}
2022-11-28 04:57:26,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:26,620 INFO:     Epoch: 21
2022-11-28 04:57:27,274 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49383636650651, 'Total loss': 0.49383636650651} | train loss {'Reaction outcome loss': 0.47180737512277776, 'Total loss': 0.47180737512277776}
2022-11-28 04:57:27,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:27,274 INFO:     Epoch: 22
2022-11-28 04:57:27,927 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4933724049911943, 'Total loss': 0.4933724049911943} | train loss {'Reaction outcome loss': 0.46647805683925503, 'Total loss': 0.46647805683925503}
2022-11-28 04:57:27,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:27,927 INFO:     Epoch: 23
2022-11-28 04:57:28,577 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4738771721374157, 'Total loss': 0.4738771721374157} | train loss {'Reaction outcome loss': 0.4625883059667759, 'Total loss': 0.4625883059667759}
2022-11-28 04:57:28,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:28,577 INFO:     Epoch: 24
2022-11-28 04:57:29,228 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4832461431275967, 'Total loss': 0.4832461431275967} | train loss {'Reaction outcome loss': 0.4596592279181617, 'Total loss': 0.4596592279181617}
2022-11-28 04:57:29,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:29,228 INFO:     Epoch: 25
2022-11-28 04:57:29,876 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5012588941080626, 'Total loss': 0.5012588941080626} | train loss {'Reaction outcome loss': 0.4551126159971855, 'Total loss': 0.4551126159971855}
2022-11-28 04:57:29,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:29,876 INFO:     Epoch: 26
2022-11-28 04:57:30,526 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4899344173974769, 'Total loss': 0.4899344173974769} | train loss {'Reaction outcome loss': 0.46240104417331884, 'Total loss': 0.46240104417331884}
2022-11-28 04:57:30,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:30,526 INFO:     Epoch: 27
2022-11-28 04:57:31,173 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5029018788143645, 'Total loss': 0.5029018788143645} | train loss {'Reaction outcome loss': 0.46949803768122783, 'Total loss': 0.46949803768122783}
2022-11-28 04:57:31,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:31,174 INFO:     Epoch: 28
2022-11-28 04:57:31,818 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47352170563021373, 'Total loss': 0.47352170563021373} | train loss {'Reaction outcome loss': 0.4599037548435516, 'Total loss': 0.4599037548435516}
2022-11-28 04:57:31,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:31,818 INFO:     Epoch: 29
2022-11-28 04:57:32,467 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48773606502732564, 'Total loss': 0.48773606502732564} | train loss {'Reaction outcome loss': 0.454703889023818, 'Total loss': 0.454703889023818}
2022-11-28 04:57:32,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:32,467 INFO:     Epoch: 30
2022-11-28 04:57:33,116 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4820955090744551, 'Total loss': 0.4820955090744551} | train loss {'Reaction outcome loss': 0.4695752126882311, 'Total loss': 0.4695752126882311}
2022-11-28 04:57:33,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:33,116 INFO:     Epoch: 31
2022-11-28 04:57:33,766 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4747218666381614, 'Total loss': 0.4747218666381614} | train loss {'Reaction outcome loss': 0.45659413106250957, 'Total loss': 0.45659413106250957}
2022-11-28 04:57:33,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:33,766 INFO:     Epoch: 32
2022-11-28 04:57:34,418 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.500765590473663, 'Total loss': 0.500765590473663} | train loss {'Reaction outcome loss': 0.45759790152555607, 'Total loss': 0.45759790152555607}
2022-11-28 04:57:34,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:34,418 INFO:     Epoch: 33
2022-11-28 04:57:35,070 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5107845819966738, 'Total loss': 0.5107845819966738} | train loss {'Reaction outcome loss': 0.462096169407739, 'Total loss': 0.462096169407739}
2022-11-28 04:57:35,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:35,070 INFO:     Epoch: 34
2022-11-28 04:57:35,722 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.6105619668960571, 'Total loss': 0.6105619668960571} | train loss {'Reaction outcome loss': 0.45519325546309597, 'Total loss': 0.45519325546309597}
2022-11-28 04:57:35,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:35,722 INFO:     Epoch: 35
2022-11-28 04:57:36,378 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4804829054100569, 'Total loss': 0.4804829054100569} | train loss {'Reaction outcome loss': 0.4587634119403655, 'Total loss': 0.4587634119403655}
2022-11-28 04:57:36,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:36,378 INFO:     Epoch: 36
2022-11-28 04:57:37,035 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4865875854048618, 'Total loss': 0.4865875854048618} | train loss {'Reaction outcome loss': 0.45766120462021864, 'Total loss': 0.45766120462021864}
2022-11-28 04:57:37,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:37,036 INFO:     Epoch: 37
2022-11-28 04:57:37,689 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4820936744989351, 'Total loss': 0.4820936744989351} | train loss {'Reaction outcome loss': 0.4529703739480894, 'Total loss': 0.4529703739480894}
2022-11-28 04:57:37,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:37,690 INFO:     Epoch: 38
2022-11-28 04:57:38,343 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.486580986962762, 'Total loss': 0.486580986962762} | train loss {'Reaction outcome loss': 0.45606008764417444, 'Total loss': 0.45606008764417444}
2022-11-28 04:57:38,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:38,343 INFO:     Epoch: 39
2022-11-28 04:57:38,996 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48987759372522666, 'Total loss': 0.48987759372522666} | train loss {'Reaction outcome loss': 0.457048700542235, 'Total loss': 0.457048700542235}
2022-11-28 04:57:38,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:38,996 INFO:     Epoch: 40
2022-11-28 04:57:39,649 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4807345319625943, 'Total loss': 0.4807345319625943} | train loss {'Reaction outcome loss': 0.45613462917628833, 'Total loss': 0.45613462917628833}
2022-11-28 04:57:39,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:39,649 INFO:     Epoch: 41
2022-11-28 04:57:40,300 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.474217151833135, 'Total loss': 0.474217151833135} | train loss {'Reaction outcome loss': 0.45817627818858037, 'Total loss': 0.45817627818858037}
2022-11-28 04:57:40,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:40,300 INFO:     Epoch: 42
2022-11-28 04:57:40,951 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4883068702941717, 'Total loss': 0.4883068702941717} | train loss {'Reaction outcome loss': 0.4553147594093299, 'Total loss': 0.4553147594093299}
2022-11-28 04:57:40,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:40,951 INFO:     Epoch: 43
2022-11-28 04:57:41,601 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4747960321431936, 'Total loss': 0.4747960321431936} | train loss {'Reaction outcome loss': 0.45197695637213403, 'Total loss': 0.45197695637213403}
2022-11-28 04:57:41,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:41,601 INFO:     Epoch: 44
2022-11-28 04:57:42,254 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4583489960709283, 'Total loss': 0.4583489960709283} | train loss {'Reaction outcome loss': 0.44873966850706787, 'Total loss': 0.44873966850706787}
2022-11-28 04:57:42,254 INFO:     Found new best model at epoch 44
2022-11-28 04:57:42,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:42,255 INFO:     Epoch: 45
2022-11-28 04:57:42,908 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4615350975546726, 'Total loss': 0.4615350975546726} | train loss {'Reaction outcome loss': 0.4588694335495839, 'Total loss': 0.4588694335495839}
2022-11-28 04:57:42,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:42,909 INFO:     Epoch: 46
2022-11-28 04:57:43,561 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4901645696440408, 'Total loss': 0.4901645696440408} | train loss {'Reaction outcome loss': 0.4519461531680627, 'Total loss': 0.4519461531680627}
2022-11-28 04:57:43,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:43,561 INFO:     Epoch: 47
2022-11-28 04:57:44,213 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48511567226676056, 'Total loss': 0.48511567226676056} | train loss {'Reaction outcome loss': 0.4559607592823564, 'Total loss': 0.4559607592823564}
2022-11-28 04:57:44,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:44,214 INFO:     Epoch: 48
2022-11-28 04:57:44,869 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4684754762538644, 'Total loss': 0.4684754762538644} | train loss {'Reaction outcome loss': 0.4568075320881898, 'Total loss': 0.4568075320881898}
2022-11-28 04:57:44,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:44,869 INFO:     Epoch: 49
2022-11-28 04:57:45,522 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46638891100883484, 'Total loss': 0.46638891100883484} | train loss {'Reaction outcome loss': 0.45104445303316976, 'Total loss': 0.45104445303316976}
2022-11-28 04:57:45,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:45,523 INFO:     Epoch: 50
2022-11-28 04:57:46,174 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4765571570673654, 'Total loss': 0.4765571570673654} | train loss {'Reaction outcome loss': 0.45484344099388746, 'Total loss': 0.45484344099388746}
2022-11-28 04:57:46,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:46,175 INFO:     Epoch: 51
2022-11-28 04:57:46,826 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4673859833977943, 'Total loss': 0.4673859833977943} | train loss {'Reaction outcome loss': 0.45425232487623807, 'Total loss': 0.45425232487623807}
2022-11-28 04:57:46,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:46,826 INFO:     Epoch: 52
2022-11-28 04:57:47,477 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4672077727872272, 'Total loss': 0.4672077727872272} | train loss {'Reaction outcome loss': 0.4519149548084032, 'Total loss': 0.4519149548084032}
2022-11-28 04:57:47,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:47,477 INFO:     Epoch: 53
2022-11-28 04:57:48,128 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46783174955567647, 'Total loss': 0.46783174955567647} | train loss {'Reaction outcome loss': 0.45702985548948655, 'Total loss': 0.45702985548948655}
2022-11-28 04:57:48,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:48,128 INFO:     Epoch: 54
2022-11-28 04:57:48,780 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4804654273875924, 'Total loss': 0.4804654273875924} | train loss {'Reaction outcome loss': 0.45211734274616006, 'Total loss': 0.45211734274616006}
2022-11-28 04:57:48,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:48,781 INFO:     Epoch: 55
2022-11-28 04:57:49,429 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47907956360384474, 'Total loss': 0.47907956360384474} | train loss {'Reaction outcome loss': 0.45400432924755285, 'Total loss': 0.45400432924755285}
2022-11-28 04:57:49,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:49,430 INFO:     Epoch: 56
2022-11-28 04:57:50,078 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47350108034388966, 'Total loss': 0.47350108034388966} | train loss {'Reaction outcome loss': 0.4512713461747912, 'Total loss': 0.4512713461747912}
2022-11-28 04:57:50,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:50,078 INFO:     Epoch: 57
2022-11-28 04:57:50,728 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4725375885880271, 'Total loss': 0.4725375885880271} | train loss {'Reaction outcome loss': 0.4564247380514614, 'Total loss': 0.4564247380514614}
2022-11-28 04:57:50,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:50,729 INFO:     Epoch: 58
2022-11-28 04:57:51,381 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47100726116535274, 'Total loss': 0.47100726116535274} | train loss {'Reaction outcome loss': 0.4581292327798781, 'Total loss': 0.4581292327798781}
2022-11-28 04:57:51,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:51,381 INFO:     Epoch: 59
2022-11-28 04:57:52,035 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4829350016837896, 'Total loss': 0.4829350016837896} | train loss {'Reaction outcome loss': 0.4485452862792328, 'Total loss': 0.4485452862792328}
2022-11-28 04:57:52,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:52,035 INFO:     Epoch: 60
2022-11-28 04:57:52,690 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4911239462536435, 'Total loss': 0.4911239462536435} | train loss {'Reaction outcome loss': 0.45291715884794953, 'Total loss': 0.45291715884794953}
2022-11-28 04:57:52,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:52,690 INFO:     Epoch: 61
2022-11-28 04:57:53,345 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4838653352371482, 'Total loss': 0.4838653352371482} | train loss {'Reaction outcome loss': 0.446613182542754, 'Total loss': 0.446613182542754}
2022-11-28 04:57:53,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:53,345 INFO:     Epoch: 62
2022-11-28 04:57:54,000 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46644077138152235, 'Total loss': 0.46644077138152235} | train loss {'Reaction outcome loss': 0.4508753936798846, 'Total loss': 0.4508753936798846}
2022-11-28 04:57:54,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:54,000 INFO:     Epoch: 63
2022-11-28 04:57:54,653 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.485371297875116, 'Total loss': 0.485371297875116} | train loss {'Reaction outcome loss': 0.4586054320584555, 'Total loss': 0.4586054320584555}
2022-11-28 04:57:54,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:54,653 INFO:     Epoch: 64
2022-11-28 04:57:55,308 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4639379063317942, 'Total loss': 0.4639379063317942} | train loss {'Reaction outcome loss': 0.4557857653278796, 'Total loss': 0.4557857653278796}
2022-11-28 04:57:55,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:55,308 INFO:     Epoch: 65
2022-11-28 04:57:55,963 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4909968909829162, 'Total loss': 0.4909968909829162} | train loss {'Reaction outcome loss': 0.4544337322538505, 'Total loss': 0.4544337322538505}
2022-11-28 04:57:55,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:55,964 INFO:     Epoch: 66
2022-11-28 04:57:56,618 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48138517626496247, 'Total loss': 0.48138517626496247} | train loss {'Reaction outcome loss': 0.4470636596689459, 'Total loss': 0.4470636596689459}
2022-11-28 04:57:56,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:56,618 INFO:     Epoch: 67
2022-11-28 04:57:57,271 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5852179395598035, 'Total loss': 0.5852179395598035} | train loss {'Reaction outcome loss': 0.45469582114429746, 'Total loss': 0.45469582114429746}
2022-11-28 04:57:57,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:57,271 INFO:     Epoch: 68
2022-11-28 04:57:57,923 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.507864911888921, 'Total loss': 0.507864911888921} | train loss {'Reaction outcome loss': 0.45169038661435, 'Total loss': 0.45169038661435}
2022-11-28 04:57:57,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:57,923 INFO:     Epoch: 69
2022-11-28 04:57:58,575 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4818857755771903, 'Total loss': 0.4818857755771903} | train loss {'Reaction outcome loss': 0.45383245711688136, 'Total loss': 0.45383245711688136}
2022-11-28 04:57:58,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:58,575 INFO:     Epoch: 70
2022-11-28 04:57:59,227 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48521907558274824, 'Total loss': 0.48521907558274824} | train loss {'Reaction outcome loss': 0.4464960552019174, 'Total loss': 0.4464960552019174}
2022-11-28 04:57:59,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:59,227 INFO:     Epoch: 71
2022-11-28 04:57:59,879 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47363196001496427, 'Total loss': 0.47363196001496427} | train loss {'Reaction outcome loss': 0.45455380003960405, 'Total loss': 0.45455380003960405}
2022-11-28 04:57:59,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:57:59,879 INFO:     Epoch: 72
2022-11-28 04:58:00,535 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4713969604913579, 'Total loss': 0.4713969604913579} | train loss {'Reaction outcome loss': 0.45182560970548724, 'Total loss': 0.45182560970548724}
2022-11-28 04:58:00,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:00,535 INFO:     Epoch: 73
2022-11-28 04:58:01,190 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4823007465795029, 'Total loss': 0.4823007465795029} | train loss {'Reaction outcome loss': 0.45465888675363336, 'Total loss': 0.45465888675363336}
2022-11-28 04:58:01,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:01,190 INFO:     Epoch: 74
2022-11-28 04:58:01,846 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48230269689892613, 'Total loss': 0.48230269689892613} | train loss {'Reaction outcome loss': 0.4565051801380564, 'Total loss': 0.4565051801380564}
2022-11-28 04:58:01,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:01,846 INFO:     Epoch: 75
2022-11-28 04:58:02,499 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47410490831663443, 'Total loss': 0.47410490831663443} | train loss {'Reaction outcome loss': 0.45057489533649114, 'Total loss': 0.45057489533649114}
2022-11-28 04:58:02,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:02,500 INFO:     Epoch: 76
2022-11-28 04:58:03,154 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47387559746587, 'Total loss': 0.47387559746587} | train loss {'Reaction outcome loss': 0.44882366110066896, 'Total loss': 0.44882366110066896}
2022-11-28 04:58:03,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:03,155 INFO:     Epoch: 77
2022-11-28 04:58:03,808 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49270968520364095, 'Total loss': 0.49270968520364095} | train loss {'Reaction outcome loss': 0.4560272468284505, 'Total loss': 0.4560272468284505}
2022-11-28 04:58:03,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:03,808 INFO:     Epoch: 78
2022-11-28 04:58:04,465 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4661717900010042, 'Total loss': 0.4661717900010042} | train loss {'Reaction outcome loss': 0.45756127306672395, 'Total loss': 0.45756127306672395}
2022-11-28 04:58:04,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:04,465 INFO:     Epoch: 79
2022-11-28 04:58:05,119 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49672725935314976, 'Total loss': 0.49672725935314976} | train loss {'Reaction outcome loss': 0.45880416542535923, 'Total loss': 0.45880416542535923}
2022-11-28 04:58:05,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:05,119 INFO:     Epoch: 80
2022-11-28 04:58:05,772 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4645131282335104, 'Total loss': 0.4645131282335104} | train loss {'Reaction outcome loss': 0.4522336344616335, 'Total loss': 0.4522336344616335}
2022-11-28 04:58:05,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:05,773 INFO:     Epoch: 81
2022-11-28 04:58:06,425 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.453493477300156, 'Total loss': 0.453493477300156} | train loss {'Reaction outcome loss': 0.4561729032363071, 'Total loss': 0.4561729032363071}
2022-11-28 04:58:06,426 INFO:     Found new best model at epoch 81
2022-11-28 04:58:06,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:06,426 INFO:     Epoch: 82
2022-11-28 04:58:07,079 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48193299908970677, 'Total loss': 0.48193299908970677} | train loss {'Reaction outcome loss': 0.45012378014746257, 'Total loss': 0.45012378014746257}
2022-11-28 04:58:07,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:07,080 INFO:     Epoch: 83
2022-11-28 04:58:07,732 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.484152595317641, 'Total loss': 0.484152595317641} | train loss {'Reaction outcome loss': 0.451711219720176, 'Total loss': 0.451711219720176}
2022-11-28 04:58:07,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:07,732 INFO:     Epoch: 84
2022-11-28 04:58:08,381 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4789988914894503, 'Total loss': 0.4789988914894503} | train loss {'Reaction outcome loss': 0.4577568424102224, 'Total loss': 0.4577568424102224}
2022-11-28 04:58:08,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:08,382 INFO:     Epoch: 85
2022-11-28 04:58:09,033 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5076184272766113, 'Total loss': 0.5076184272766113} | train loss {'Reaction outcome loss': 0.45160638437163636, 'Total loss': 0.45160638437163636}
2022-11-28 04:58:09,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:09,033 INFO:     Epoch: 86
2022-11-28 04:58:09,683 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46618805791056434, 'Total loss': 0.46618805791056434} | train loss {'Reaction outcome loss': 0.4488882030375668, 'Total loss': 0.4488882030375668}
2022-11-28 04:58:09,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:09,683 INFO:     Epoch: 87
2022-11-28 04:58:10,337 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4927941810253055, 'Total loss': 0.4927941810253055} | train loss {'Reaction outcome loss': 0.4630928412690514, 'Total loss': 0.4630928412690514}
2022-11-28 04:58:10,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:10,338 INFO:     Epoch: 88
2022-11-28 04:58:10,992 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48261203599530594, 'Total loss': 0.48261203599530594} | train loss {'Reaction outcome loss': 0.447585649483028, 'Total loss': 0.447585649483028}
2022-11-28 04:58:10,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:10,992 INFO:     Epoch: 89
2022-11-28 04:58:11,646 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47144183793733285, 'Total loss': 0.47144183793733285} | train loss {'Reaction outcome loss': 0.4560074960721321, 'Total loss': 0.4560074960721321}
2022-11-28 04:58:11,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:11,647 INFO:     Epoch: 90
2022-11-28 04:58:12,301 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4607707362535388, 'Total loss': 0.4607707362535388} | train loss {'Reaction outcome loss': 0.4554841905282658, 'Total loss': 0.4554841905282658}
2022-11-28 04:58:12,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:12,301 INFO:     Epoch: 91
2022-11-28 04:58:12,955 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49524392915326493, 'Total loss': 0.49524392915326493} | train loss {'Reaction outcome loss': 0.4507464702378531, 'Total loss': 0.4507464702378531}
2022-11-28 04:58:12,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:12,955 INFO:     Epoch: 92
2022-11-28 04:58:13,611 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.459813910861348, 'Total loss': 0.459813910861348} | train loss {'Reaction outcome loss': 0.45723560641779276, 'Total loss': 0.45723560641779276}
2022-11-28 04:58:13,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:13,612 INFO:     Epoch: 93
2022-11-28 04:58:14,268 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5051260257876197, 'Total loss': 0.5051260257876197} | train loss {'Reaction outcome loss': 0.45515269609015496, 'Total loss': 0.45515269609015496}
2022-11-28 04:58:14,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:14,269 INFO:     Epoch: 94
2022-11-28 04:58:14,924 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4987408726714378, 'Total loss': 0.4987408726714378} | train loss {'Reaction outcome loss': 0.4465117240171941, 'Total loss': 0.4465117240171941}
2022-11-28 04:58:14,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:14,925 INFO:     Epoch: 95
2022-11-28 04:58:15,576 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4966952253219693, 'Total loss': 0.4966952253219693} | train loss {'Reaction outcome loss': 0.45076379073081446, 'Total loss': 0.45076379073081446}
2022-11-28 04:58:15,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:15,576 INFO:     Epoch: 96
2022-11-28 04:58:16,232 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4709174587976101, 'Total loss': 0.4709174587976101} | train loss {'Reaction outcome loss': 0.4538240858399477, 'Total loss': 0.4538240858399477}
2022-11-28 04:58:16,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:16,232 INFO:     Epoch: 97
2022-11-28 04:58:16,887 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4860697679741438, 'Total loss': 0.4860697679741438} | train loss {'Reaction outcome loss': 0.4534265289663291, 'Total loss': 0.4534265289663291}
2022-11-28 04:58:16,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:16,887 INFO:     Epoch: 98
2022-11-28 04:58:17,543 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45862669411093687, 'Total loss': 0.45862669411093687} | train loss {'Reaction outcome loss': 0.4497893333557199, 'Total loss': 0.4497893333557199}
2022-11-28 04:58:17,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:17,543 INFO:     Epoch: 99
2022-11-28 04:58:18,197 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4621505674927734, 'Total loss': 0.4621505674927734} | train loss {'Reaction outcome loss': 0.4531775565176714, 'Total loss': 0.4531775565176714}
2022-11-28 04:58:18,197 INFO:     Best model found after epoch 82 of 100.
2022-11-28 04:58:18,197 INFO:   Done with stage: TRAINING
2022-11-28 04:58:18,197 INFO:   Starting stage: EVALUATION
2022-11-28 04:58:18,325 INFO:   Done with stage: EVALUATION
2022-11-28 04:58:18,325 INFO:   Leaving out SEQ value Fold_3
2022-11-28 04:58:18,338 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 04:58:18,338 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:58:18,977 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:58:18,977 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:58:19,047 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:58:19,048 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:58:19,048 INFO:     No hyperparam tuning for this model
2022-11-28 04:58:19,048 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:58:19,048 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:58:19,048 INFO:     None feature selector for col prot
2022-11-28 04:58:19,049 INFO:     None feature selector for col prot
2022-11-28 04:58:19,049 INFO:     None feature selector for col prot
2022-11-28 04:58:19,049 INFO:     None feature selector for col chem
2022-11-28 04:58:19,049 INFO:     None feature selector for col chem
2022-11-28 04:58:19,049 INFO:     None feature selector for col chem
2022-11-28 04:58:19,049 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:58:19,049 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:58:19,051 INFO:     Number of params in model 169651
2022-11-28 04:58:19,054 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:58:19,054 INFO:   Starting stage: TRAINING
2022-11-28 04:58:19,105 INFO:     Val loss before train {'Reaction outcome loss': 0.9890043003992601, 'Total loss': 0.9890043003992601}
2022-11-28 04:58:19,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:19,105 INFO:     Epoch: 0
2022-11-28 04:58:19,759 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6256715594367548, 'Total loss': 0.6256715594367548} | train loss {'Reaction outcome loss': 0.6928050375106384, 'Total loss': 0.6928050375106384}
2022-11-28 04:58:19,759 INFO:     Found new best model at epoch 0
2022-11-28 04:58:19,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:19,760 INFO:     Epoch: 1
2022-11-28 04:58:20,416 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.565460049293258, 'Total loss': 0.565460049293258} | train loss {'Reaction outcome loss': 0.5841090452914335, 'Total loss': 0.5841090452914335}
2022-11-28 04:58:20,416 INFO:     Found new best model at epoch 1
2022-11-28 04:58:20,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:20,417 INFO:     Epoch: 2
2022-11-28 04:58:21,075 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5686411884698, 'Total loss': 0.5686411884698} | train loss {'Reaction outcome loss': 0.5572227523643143, 'Total loss': 0.5572227523643143}
2022-11-28 04:58:21,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:21,076 INFO:     Epoch: 3
2022-11-28 04:58:21,731 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5656971470876173, 'Total loss': 0.5656971470876173} | train loss {'Reaction outcome loss': 0.540591765119105, 'Total loss': 0.540591765119105}
2022-11-28 04:58:21,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:21,731 INFO:     Epoch: 4
2022-11-28 04:58:22,384 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5222756117582321, 'Total loss': 0.5222756117582321} | train loss {'Reaction outcome loss': 0.5169892173336477, 'Total loss': 0.5169892173336477}
2022-11-28 04:58:22,384 INFO:     Found new best model at epoch 4
2022-11-28 04:58:22,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:22,385 INFO:     Epoch: 5
2022-11-28 04:58:23,041 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4830961941995404, 'Total loss': 0.4830961941995404} | train loss {'Reaction outcome loss': 0.5190315637661487, 'Total loss': 0.5190315637661487}
2022-11-28 04:58:23,041 INFO:     Found new best model at epoch 5
2022-11-28 04:58:23,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:23,042 INFO:     Epoch: 6
2022-11-28 04:58:23,695 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5196524252268401, 'Total loss': 0.5196524252268401} | train loss {'Reaction outcome loss': 0.5145116438062823, 'Total loss': 0.5145116438062823}
2022-11-28 04:58:23,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:23,695 INFO:     Epoch: 7
2022-11-28 04:58:24,353 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5307309180498123, 'Total loss': 0.5307309180498123} | train loss {'Reaction outcome loss': 0.5003147038878227, 'Total loss': 0.5003147038878227}
2022-11-28 04:58:24,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:24,354 INFO:     Epoch: 8
2022-11-28 04:58:25,009 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5520401332866062, 'Total loss': 0.5520401332866062} | train loss {'Reaction outcome loss': 0.5026942939782629, 'Total loss': 0.5026942939782629}
2022-11-28 04:58:25,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:25,009 INFO:     Epoch: 9
2022-11-28 04:58:25,669 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5042043782093308, 'Total loss': 0.5042043782093308} | train loss {'Reaction outcome loss': 0.4927502931988969, 'Total loss': 0.4927502931988969}
2022-11-28 04:58:25,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:25,669 INFO:     Epoch: 10
2022-11-28 04:58:26,325 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5055405836213719, 'Total loss': 0.5055405836213719} | train loss {'Reaction outcome loss': 0.4829845454011645, 'Total loss': 0.4829845454011645}
2022-11-28 04:58:26,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:26,325 INFO:     Epoch: 11
2022-11-28 04:58:26,979 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4956407066095959, 'Total loss': 0.4956407066095959} | train loss {'Reaction outcome loss': 0.4887778682976353, 'Total loss': 0.4887778682976353}
2022-11-28 04:58:26,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:26,980 INFO:     Epoch: 12
2022-11-28 04:58:27,636 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49802834405140445, 'Total loss': 0.49802834405140445} | train loss {'Reaction outcome loss': 0.49466857453998253, 'Total loss': 0.49466857453998253}
2022-11-28 04:58:27,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:27,637 INFO:     Epoch: 13
2022-11-28 04:58:28,290 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5250195088711652, 'Total loss': 0.5250195088711652} | train loss {'Reaction outcome loss': 0.4837380577715076, 'Total loss': 0.4837380577715076}
2022-11-28 04:58:28,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:28,291 INFO:     Epoch: 14
2022-11-28 04:58:28,945 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4855394106019627, 'Total loss': 0.4855394106019627} | train loss {'Reaction outcome loss': 0.48223464057153587, 'Total loss': 0.48223464057153587}
2022-11-28 04:58:28,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:28,946 INFO:     Epoch: 15
2022-11-28 04:58:29,597 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49042717028747906, 'Total loss': 0.49042717028747906} | train loss {'Reaction outcome loss': 0.47835390342741596, 'Total loss': 0.47835390342741596}
2022-11-28 04:58:29,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:29,597 INFO:     Epoch: 16
2022-11-28 04:58:30,251 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49081106585535134, 'Total loss': 0.49081106585535134} | train loss {'Reaction outcome loss': 0.48272542545990066, 'Total loss': 0.48272542545990066}
2022-11-28 04:58:30,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:30,251 INFO:     Epoch: 17
2022-11-28 04:58:30,903 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4766249893741174, 'Total loss': 0.4766249893741174} | train loss {'Reaction outcome loss': 0.4821702021117113, 'Total loss': 0.4821702021117113}
2022-11-28 04:58:30,903 INFO:     Found new best model at epoch 17
2022-11-28 04:58:30,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:30,904 INFO:     Epoch: 18
2022-11-28 04:58:31,556 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4781680418686433, 'Total loss': 0.4781680418686433} | train loss {'Reaction outcome loss': 0.4761327939982317, 'Total loss': 0.4761327939982317}
2022-11-28 04:58:31,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:31,556 INFO:     Epoch: 19
2022-11-28 04:58:32,207 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47589839825576, 'Total loss': 0.47589839825576} | train loss {'Reaction outcome loss': 0.4800281262519408, 'Total loss': 0.4800281262519408}
2022-11-28 04:58:32,208 INFO:     Found new best model at epoch 19
2022-11-28 04:58:32,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:32,208 INFO:     Epoch: 20
2022-11-28 04:58:32,859 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4785993180491708, 'Total loss': 0.4785993180491708} | train loss {'Reaction outcome loss': 0.47934606154354253, 'Total loss': 0.47934606154354253}
2022-11-28 04:58:32,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:32,859 INFO:     Epoch: 21
2022-11-28 04:58:33,514 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4931982196867466, 'Total loss': 0.4931982196867466} | train loss {'Reaction outcome loss': 0.4661709180900029, 'Total loss': 0.4661709180900029}
2022-11-28 04:58:33,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:33,514 INFO:     Epoch: 22
2022-11-28 04:58:34,167 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4589744792743163, 'Total loss': 0.4589744792743163} | train loss {'Reaction outcome loss': 0.4779319116655661, 'Total loss': 0.4779319116655661}
2022-11-28 04:58:34,167 INFO:     Found new best model at epoch 22
2022-11-28 04:58:34,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:34,168 INFO:     Epoch: 23
2022-11-28 04:58:34,822 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48599912564862857, 'Total loss': 0.48599912564862857} | train loss {'Reaction outcome loss': 0.4828257226822328, 'Total loss': 0.4828257226822328}
2022-11-28 04:58:34,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:34,822 INFO:     Epoch: 24
2022-11-28 04:58:35,474 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4627719955010848, 'Total loss': 0.4627719955010848} | train loss {'Reaction outcome loss': 0.4791229889709122, 'Total loss': 0.4791229889709122}
2022-11-28 04:58:35,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:35,475 INFO:     Epoch: 25
2022-11-28 04:58:36,131 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4789446602490815, 'Total loss': 0.4789446602490815} | train loss {'Reaction outcome loss': 0.4802545781646456, 'Total loss': 0.4802545781646456}
2022-11-28 04:58:36,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:36,131 INFO:     Epoch: 26
2022-11-28 04:58:36,783 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4904952702874487, 'Total loss': 0.4904952702874487} | train loss {'Reaction outcome loss': 0.48422118169920786, 'Total loss': 0.48422118169920786}
2022-11-28 04:58:36,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:36,784 INFO:     Epoch: 27
2022-11-28 04:58:37,440 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.469333406876434, 'Total loss': 0.469333406876434} | train loss {'Reaction outcome loss': 0.4705261678111797, 'Total loss': 0.4705261678111797}
2022-11-28 04:58:37,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:37,440 INFO:     Epoch: 28
2022-11-28 04:58:38,095 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47471165284514427, 'Total loss': 0.47471165284514427} | train loss {'Reaction outcome loss': 0.4771375418925772, 'Total loss': 0.4771375418925772}
2022-11-28 04:58:38,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:38,095 INFO:     Epoch: 29
2022-11-28 04:58:38,752 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48672540147196164, 'Total loss': 0.48672540147196164} | train loss {'Reaction outcome loss': 0.4681908075298582, 'Total loss': 0.4681908075298582}
2022-11-28 04:58:38,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:38,752 INFO:     Epoch: 30
2022-11-28 04:58:39,412 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48742890103974124, 'Total loss': 0.48742890103974124} | train loss {'Reaction outcome loss': 0.4765942455554495, 'Total loss': 0.4765942455554495}
2022-11-28 04:58:39,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:39,412 INFO:     Epoch: 31
2022-11-28 04:58:40,069 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.493975025347688, 'Total loss': 0.493975025347688} | train loss {'Reaction outcome loss': 0.4772030318878135, 'Total loss': 0.4772030318878135}
2022-11-28 04:58:40,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:40,070 INFO:     Epoch: 32
2022-11-28 04:58:40,726 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4690969174050472, 'Total loss': 0.4690969174050472} | train loss {'Reaction outcome loss': 0.4702155590665584, 'Total loss': 0.4702155590665584}
2022-11-28 04:58:40,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:40,726 INFO:     Epoch: 33
2022-11-28 04:58:41,379 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45855852419679816, 'Total loss': 0.45855852419679816} | train loss {'Reaction outcome loss': 0.47785332221157695, 'Total loss': 0.47785332221157695}
2022-11-28 04:58:41,379 INFO:     Found new best model at epoch 33
2022-11-28 04:58:41,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:41,380 INFO:     Epoch: 34
2022-11-28 04:58:42,034 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.49882402406497434, 'Total loss': 0.49882402406497434} | train loss {'Reaction outcome loss': 0.4663892248455359, 'Total loss': 0.4663892248455359}
2022-11-28 04:58:42,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:42,034 INFO:     Epoch: 35
2022-11-28 04:58:42,690 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46918713132088835, 'Total loss': 0.46918713132088835} | train loss {'Reaction outcome loss': 0.46607920472719233, 'Total loss': 0.46607920472719233}
2022-11-28 04:58:42,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:42,690 INFO:     Epoch: 36
2022-11-28 04:58:43,344 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4609110091220249, 'Total loss': 0.4609110091220249} | train loss {'Reaction outcome loss': 0.4725122029684028, 'Total loss': 0.4725122029684028}
2022-11-28 04:58:43,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:43,345 INFO:     Epoch: 37
2022-11-28 04:58:44,000 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4564026404510845, 'Total loss': 0.4564026404510845} | train loss {'Reaction outcome loss': 0.48062698725534947, 'Total loss': 0.48062698725534947}
2022-11-28 04:58:44,000 INFO:     Found new best model at epoch 37
2022-11-28 04:58:44,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:44,001 INFO:     Epoch: 38
2022-11-28 04:58:44,659 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46217898990620265, 'Total loss': 0.46217898990620265} | train loss {'Reaction outcome loss': 0.47287744356661426, 'Total loss': 0.47287744356661426}
2022-11-28 04:58:44,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:44,659 INFO:     Epoch: 39
2022-11-28 04:58:45,315 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46213306757536804, 'Total loss': 0.46213306757536804} | train loss {'Reaction outcome loss': 0.4740601143666676, 'Total loss': 0.4740601143666676}
2022-11-28 04:58:45,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:45,316 INFO:     Epoch: 40
2022-11-28 04:58:45,971 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.49584893916140904, 'Total loss': 0.49584893916140904} | train loss {'Reaction outcome loss': 0.4768395936002537, 'Total loss': 0.4768395936002537}
2022-11-28 04:58:45,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:45,972 INFO:     Epoch: 41
2022-11-28 04:58:46,630 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45084616812792694, 'Total loss': 0.45084616812792694} | train loss {'Reaction outcome loss': 0.47035460022031045, 'Total loss': 0.47035460022031045}
2022-11-28 04:58:46,630 INFO:     Found new best model at epoch 41
2022-11-28 04:58:46,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:46,631 INFO:     Epoch: 42
2022-11-28 04:58:47,289 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4750585894693028, 'Total loss': 0.4750585894693028} | train loss {'Reaction outcome loss': 0.4815390352083712, 'Total loss': 0.4815390352083712}
2022-11-28 04:58:47,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:47,289 INFO:     Epoch: 43
2022-11-28 04:58:47,951 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4656386971473694, 'Total loss': 0.4656386971473694} | train loss {'Reaction outcome loss': 0.46573137686568866, 'Total loss': 0.46573137686568866}
2022-11-28 04:58:47,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:47,951 INFO:     Epoch: 44
2022-11-28 04:58:48,611 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46728619594465604, 'Total loss': 0.46728619594465604} | train loss {'Reaction outcome loss': 0.47395037728912975, 'Total loss': 0.47395037728912975}
2022-11-28 04:58:48,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:48,612 INFO:     Epoch: 45
2022-11-28 04:58:49,273 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47328447381203825, 'Total loss': 0.47328447381203825} | train loss {'Reaction outcome loss': 0.47790511198798, 'Total loss': 0.47790511198798}
2022-11-28 04:58:49,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:49,273 INFO:     Epoch: 46
2022-11-28 04:58:49,933 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4393448887223547, 'Total loss': 0.4393448887223547} | train loss {'Reaction outcome loss': 0.473204374799923, 'Total loss': 0.473204374799923}
2022-11-28 04:58:49,933 INFO:     Found new best model at epoch 46
2022-11-28 04:58:49,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:49,934 INFO:     Epoch: 47
2022-11-28 04:58:50,595 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4675765393132513, 'Total loss': 0.4675765393132513} | train loss {'Reaction outcome loss': 0.46449091623024064, 'Total loss': 0.46449091623024064}
2022-11-28 04:58:50,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:50,595 INFO:     Epoch: 48
2022-11-28 04:58:51,255 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4898335432464426, 'Total loss': 0.4898335432464426} | train loss {'Reaction outcome loss': 0.4760290366654493, 'Total loss': 0.4760290366654493}
2022-11-28 04:58:51,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:51,256 INFO:     Epoch: 49
2022-11-28 04:58:51,917 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4660105686634779, 'Total loss': 0.4660105686634779} | train loss {'Reaction outcome loss': 0.47861820830374346, 'Total loss': 0.47861820830374346}
2022-11-28 04:58:51,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:51,917 INFO:     Epoch: 50
2022-11-28 04:58:52,582 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48681935837323015, 'Total loss': 0.48681935837323015} | train loss {'Reaction outcome loss': 0.4769793690467367, 'Total loss': 0.4769793690467367}
2022-11-28 04:58:52,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:52,582 INFO:     Epoch: 51
2022-11-28 04:58:53,242 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4925388179042123, 'Total loss': 0.4925388179042123} | train loss {'Reaction outcome loss': 0.47135053313508324, 'Total loss': 0.47135053313508324}
2022-11-28 04:58:53,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:53,242 INFO:     Epoch: 52
2022-11-28 04:58:53,903 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.473498173058033, 'Total loss': 0.473498173058033} | train loss {'Reaction outcome loss': 0.47461036370725046, 'Total loss': 0.47461036370725046}
2022-11-28 04:58:53,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:53,903 INFO:     Epoch: 53
2022-11-28 04:58:54,563 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4754382920536128, 'Total loss': 0.4754382920536128} | train loss {'Reaction outcome loss': 0.4746911493491153, 'Total loss': 0.4746911493491153}
2022-11-28 04:58:54,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:54,563 INFO:     Epoch: 54
2022-11-28 04:58:55,225 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46521521325815807, 'Total loss': 0.46521521325815807} | train loss {'Reaction outcome loss': 0.47017988045604864, 'Total loss': 0.47017988045604864}
2022-11-28 04:58:55,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:55,225 INFO:     Epoch: 55
2022-11-28 04:58:55,889 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4609628004783934, 'Total loss': 0.4609628004783934} | train loss {'Reaction outcome loss': 0.4735270409559717, 'Total loss': 0.4735270409559717}
2022-11-28 04:58:55,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:55,889 INFO:     Epoch: 56
2022-11-28 04:58:56,550 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4640440871431069, 'Total loss': 0.4640440871431069} | train loss {'Reaction outcome loss': 0.47298720412108364, 'Total loss': 0.47298720412108364}
2022-11-28 04:58:56,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:56,550 INFO:     Epoch: 57
2022-11-28 04:58:57,207 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48634604330767284, 'Total loss': 0.48634604330767284} | train loss {'Reaction outcome loss': 0.47216135184375607, 'Total loss': 0.47216135184375607}
2022-11-28 04:58:57,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:57,208 INFO:     Epoch: 58
2022-11-28 04:58:57,868 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5007220340723341, 'Total loss': 0.5007220340723341} | train loss {'Reaction outcome loss': 0.47494541503945176, 'Total loss': 0.47494541503945176}
2022-11-28 04:58:57,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:57,869 INFO:     Epoch: 59
2022-11-28 04:58:58,529 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45403417267582635, 'Total loss': 0.45403417267582635} | train loss {'Reaction outcome loss': 0.4787714019721868, 'Total loss': 0.4787714019721868}
2022-11-28 04:58:58,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:58,529 INFO:     Epoch: 60
2022-11-28 04:58:59,190 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4646844897757877, 'Total loss': 0.4646844897757877} | train loss {'Reaction outcome loss': 0.47332819329232584, 'Total loss': 0.47332819329232584}
2022-11-28 04:58:59,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:59,190 INFO:     Epoch: 61
2022-11-28 04:58:59,850 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4482458531856537, 'Total loss': 0.4482458531856537} | train loss {'Reaction outcome loss': 0.4780089884996414, 'Total loss': 0.4780089884996414}
2022-11-28 04:58:59,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:58:59,850 INFO:     Epoch: 62
2022-11-28 04:59:00,513 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4687851924787868, 'Total loss': 0.4687851924787868} | train loss {'Reaction outcome loss': 0.46946638506286, 'Total loss': 0.46946638506286}
2022-11-28 04:59:00,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:00,513 INFO:     Epoch: 63
2022-11-28 04:59:01,174 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4669172912836075, 'Total loss': 0.4669172912836075} | train loss {'Reaction outcome loss': 0.47889043281272964, 'Total loss': 0.47889043281272964}
2022-11-28 04:59:01,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:01,174 INFO:     Epoch: 64
2022-11-28 04:59:01,835 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47003604945811356, 'Total loss': 0.47003604945811356} | train loss {'Reaction outcome loss': 0.47492206856912494, 'Total loss': 0.47492206856912494}
2022-11-28 04:59:01,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:01,836 INFO:     Epoch: 65
2022-11-28 04:59:02,498 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4743976684456522, 'Total loss': 0.4743976684456522} | train loss {'Reaction outcome loss': 0.4790248553363644, 'Total loss': 0.4790248553363644}
2022-11-28 04:59:02,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:02,499 INFO:     Epoch: 66
2022-11-28 04:59:03,164 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.474310809915716, 'Total loss': 0.474310809915716} | train loss {'Reaction outcome loss': 0.48046238696088595, 'Total loss': 0.48046238696088595}
2022-11-28 04:59:03,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:03,165 INFO:     Epoch: 67
2022-11-28 04:59:03,827 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4518121128732508, 'Total loss': 0.4518121128732508} | train loss {'Reaction outcome loss': 0.4715633935466105, 'Total loss': 0.4715633935466105}
2022-11-28 04:59:03,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:03,828 INFO:     Epoch: 68
2022-11-28 04:59:04,491 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49767046760429035, 'Total loss': 0.49767046760429035} | train loss {'Reaction outcome loss': 0.48314266709648834, 'Total loss': 0.48314266709648834}
2022-11-28 04:59:04,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:04,492 INFO:     Epoch: 69
2022-11-28 04:59:05,152 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4742599685083736, 'Total loss': 0.4742599685083736} | train loss {'Reaction outcome loss': 0.47726690094081725, 'Total loss': 0.47726690094081725}
2022-11-28 04:59:05,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:05,153 INFO:     Epoch: 70
2022-11-28 04:59:05,817 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4583886707709594, 'Total loss': 0.4583886707709594} | train loss {'Reaction outcome loss': 0.4819388941842683, 'Total loss': 0.4819388941842683}
2022-11-28 04:59:05,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:05,817 INFO:     Epoch: 71
2022-11-28 04:59:06,479 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4703550948338075, 'Total loss': 0.4703550948338075} | train loss {'Reaction outcome loss': 0.4794389263099554, 'Total loss': 0.4794389263099554}
2022-11-28 04:59:06,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:06,479 INFO:     Epoch: 72
2022-11-28 04:59:07,152 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46191611648960545, 'Total loss': 0.46191611648960545} | train loss {'Reaction outcome loss': 0.4738455821056755, 'Total loss': 0.4738455821056755}
2022-11-28 04:59:07,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:07,152 INFO:     Epoch: 73
2022-11-28 04:59:07,818 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4736626319248568, 'Total loss': 0.4736626319248568} | train loss {'Reaction outcome loss': 0.47267786650633326, 'Total loss': 0.47267786650633326}
2022-11-28 04:59:07,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:07,818 INFO:     Epoch: 74
2022-11-28 04:59:08,483 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4584849426014857, 'Total loss': 0.4584849426014857} | train loss {'Reaction outcome loss': 0.47935201002627004, 'Total loss': 0.47935201002627004}
2022-11-28 04:59:08,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:08,483 INFO:     Epoch: 75
2022-11-28 04:59:09,147 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48345913941209967, 'Total loss': 0.48345913941209967} | train loss {'Reaction outcome loss': 0.47433832488497907, 'Total loss': 0.47433832488497907}
2022-11-28 04:59:09,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:09,148 INFO:     Epoch: 76
2022-11-28 04:59:09,812 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.484929928725416, 'Total loss': 0.484929928725416} | train loss {'Reaction outcome loss': 0.4686811513438517, 'Total loss': 0.4686811513438517}
2022-11-28 04:59:09,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:09,812 INFO:     Epoch: 77
2022-11-28 04:59:10,480 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45801329951394687, 'Total loss': 0.45801329951394687} | train loss {'Reaction outcome loss': 0.4797520282013076, 'Total loss': 0.4797520282013076}
2022-11-28 04:59:10,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:10,480 INFO:     Epoch: 78
2022-11-28 04:59:11,144 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5127074962312524, 'Total loss': 0.5127074962312524} | train loss {'Reaction outcome loss': 0.4766773555351763, 'Total loss': 0.4766773555351763}
2022-11-28 04:59:11,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:11,144 INFO:     Epoch: 79
2022-11-28 04:59:11,808 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5114880817180331, 'Total loss': 0.5114880817180331} | train loss {'Reaction outcome loss': 0.473368382028171, 'Total loss': 0.473368382028171}
2022-11-28 04:59:11,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:11,808 INFO:     Epoch: 80
2022-11-28 04:59:12,472 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47689567641778424, 'Total loss': 0.47689567641778424} | train loss {'Reaction outcome loss': 0.4780440573181425, 'Total loss': 0.4780440573181425}
2022-11-28 04:59:12,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:12,472 INFO:     Epoch: 81
2022-11-28 04:59:13,135 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4688952893696048, 'Total loss': 0.4688952893696048} | train loss {'Reaction outcome loss': 0.47924731008860527, 'Total loss': 0.47924731008860527}
2022-11-28 04:59:13,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:13,135 INFO:     Epoch: 82
2022-11-28 04:59:13,802 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.501924492418766, 'Total loss': 0.501924492418766} | train loss {'Reaction outcome loss': 0.4818699289949573, 'Total loss': 0.4818699289949573}
2022-11-28 04:59:13,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:13,803 INFO:     Epoch: 83
2022-11-28 04:59:14,471 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.501104511320591, 'Total loss': 0.501104511320591} | train loss {'Reaction outcome loss': 0.47738680942934386, 'Total loss': 0.47738680942934386}
2022-11-28 04:59:14,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:14,471 INFO:     Epoch: 84
2022-11-28 04:59:15,140 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47772534598003735, 'Total loss': 0.47772534598003735} | train loss {'Reaction outcome loss': 0.4822237115125267, 'Total loss': 0.4822237115125267}
2022-11-28 04:59:15,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:15,140 INFO:     Epoch: 85
2022-11-28 04:59:15,806 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4853955649516799, 'Total loss': 0.4853955649516799} | train loss {'Reaction outcome loss': 0.4782533060835332, 'Total loss': 0.4782533060835332}
2022-11-28 04:59:15,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:15,806 INFO:     Epoch: 86
2022-11-28 04:59:16,472 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4728972055017948, 'Total loss': 0.4728972055017948} | train loss {'Reaction outcome loss': 0.4741839441717887, 'Total loss': 0.4741839441717887}
2022-11-28 04:59:16,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:16,473 INFO:     Epoch: 87
2022-11-28 04:59:17,137 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4690439419990236, 'Total loss': 0.4690439419990236} | train loss {'Reaction outcome loss': 0.4832211639199938, 'Total loss': 0.4832211639199938}
2022-11-28 04:59:17,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:17,137 INFO:     Epoch: 88
2022-11-28 04:59:17,801 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4710343055088412, 'Total loss': 0.4710343055088412} | train loss {'Reaction outcome loss': 0.4796617515233098, 'Total loss': 0.4796617515233098}
2022-11-28 04:59:17,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:17,801 INFO:     Epoch: 89
2022-11-28 04:59:18,465 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4914570484649051, 'Total loss': 0.4914570484649051} | train loss {'Reaction outcome loss': 0.47792558171311206, 'Total loss': 0.47792558171311206}
2022-11-28 04:59:18,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:18,466 INFO:     Epoch: 90
2022-11-28 04:59:19,132 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47132299772717734, 'Total loss': 0.47132299772717734} | train loss {'Reaction outcome loss': 0.4761511493094113, 'Total loss': 0.4761511493094113}
2022-11-28 04:59:19,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:19,132 INFO:     Epoch: 91
2022-11-28 04:59:19,796 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48745805583894253, 'Total loss': 0.48745805583894253} | train loss {'Reaction outcome loss': 0.47924101954820203, 'Total loss': 0.47924101954820203}
2022-11-28 04:59:19,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:19,796 INFO:     Epoch: 92
2022-11-28 04:59:20,462 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46190415356646886, 'Total loss': 0.46190415356646886} | train loss {'Reaction outcome loss': 0.4792738045964922, 'Total loss': 0.4792738045964922}
2022-11-28 04:59:20,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:20,463 INFO:     Epoch: 93
2022-11-28 04:59:21,130 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5184551054103808, 'Total loss': 0.5184551054103808} | train loss {'Reaction outcome loss': 0.479012658948801, 'Total loss': 0.479012658948801}
2022-11-28 04:59:21,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:21,130 INFO:     Epoch: 94
2022-11-28 04:59:21,795 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.50062641907822, 'Total loss': 0.50062641907822} | train loss {'Reaction outcome loss': 0.472435868272976, 'Total loss': 0.472435868272976}
2022-11-28 04:59:21,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:21,795 INFO:     Epoch: 95
2022-11-28 04:59:22,460 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4733969159424305, 'Total loss': 0.4733969159424305} | train loss {'Reaction outcome loss': 0.48320930250445193, 'Total loss': 0.48320930250445193}
2022-11-28 04:59:22,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:22,461 INFO:     Epoch: 96
2022-11-28 04:59:23,123 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4778080227022821, 'Total loss': 0.4778080227022821} | train loss {'Reaction outcome loss': 0.47746784924244395, 'Total loss': 0.47746784924244395}
2022-11-28 04:59:23,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:23,124 INFO:     Epoch: 97
2022-11-28 04:59:23,788 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4765650054270571, 'Total loss': 0.4765650054270571} | train loss {'Reaction outcome loss': 0.48109450182136226, 'Total loss': 0.48109450182136226}
2022-11-28 04:59:23,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:23,789 INFO:     Epoch: 98
2022-11-28 04:59:24,453 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4715419594537128, 'Total loss': 0.4715419594537128} | train loss {'Reaction outcome loss': 0.4799396796494114, 'Total loss': 0.4799396796494114}
2022-11-28 04:59:24,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:24,453 INFO:     Epoch: 99
2022-11-28 04:59:25,115 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47724418477578595, 'Total loss': 0.47724418477578595} | train loss {'Reaction outcome loss': 0.4810392488326345, 'Total loss': 0.4810392488326345}
2022-11-28 04:59:25,115 INFO:     Best model found after epoch 47 of 100.
2022-11-28 04:59:25,115 INFO:   Done with stage: TRAINING
2022-11-28 04:59:25,115 INFO:   Starting stage: EVALUATION
2022-11-28 04:59:25,238 INFO:   Done with stage: EVALUATION
2022-11-28 04:59:25,238 INFO:   Leaving out SEQ value Fold_4
2022-11-28 04:59:25,251 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 04:59:25,251 INFO:   Starting stage: FEATURE SCALING
2022-11-28 04:59:25,897 INFO:   Done with stage: FEATURE SCALING
2022-11-28 04:59:25,898 INFO:   Starting stage: SCALING TARGETS
2022-11-28 04:59:25,968 INFO:   Done with stage: SCALING TARGETS
2022-11-28 04:59:25,968 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:59:25,968 INFO:     No hyperparam tuning for this model
2022-11-28 04:59:25,968 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 04:59:25,968 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 04:59:25,969 INFO:     None feature selector for col prot
2022-11-28 04:59:25,969 INFO:     None feature selector for col prot
2022-11-28 04:59:25,969 INFO:     None feature selector for col prot
2022-11-28 04:59:25,970 INFO:     None feature selector for col chem
2022-11-28 04:59:25,970 INFO:     None feature selector for col chem
2022-11-28 04:59:25,970 INFO:     None feature selector for col chem
2022-11-28 04:59:25,970 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 04:59:25,970 INFO:   Starting stage: BUILD MODEL
2022-11-28 04:59:25,971 INFO:     Number of params in model 169651
2022-11-28 04:59:25,974 INFO:   Done with stage: BUILD MODEL
2022-11-28 04:59:25,974 INFO:   Starting stage: TRAINING
2022-11-28 04:59:26,026 INFO:     Val loss before train {'Reaction outcome loss': 1.0351286124099384, 'Total loss': 1.0351286124099384}
2022-11-28 04:59:26,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:26,026 INFO:     Epoch: 0
2022-11-28 04:59:26,698 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6141869032924826, 'Total loss': 0.6141869032924826} | train loss {'Reaction outcome loss': 0.6930410975990026, 'Total loss': 0.6930410975990026}
2022-11-28 04:59:26,698 INFO:     Found new best model at epoch 0
2022-11-28 04:59:26,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:26,699 INFO:     Epoch: 1
2022-11-28 04:59:27,366 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6018629842861132, 'Total loss': 0.6018629842861132} | train loss {'Reaction outcome loss': 0.5903618663911395, 'Total loss': 0.5903618663911395}
2022-11-28 04:59:27,366 INFO:     Found new best model at epoch 1
2022-11-28 04:59:27,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:27,367 INFO:     Epoch: 2
2022-11-28 04:59:28,035 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5348507640036669, 'Total loss': 0.5348507640036669} | train loss {'Reaction outcome loss': 0.573240729961318, 'Total loss': 0.573240729961318}
2022-11-28 04:59:28,035 INFO:     Found new best model at epoch 2
2022-11-28 04:59:28,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:28,036 INFO:     Epoch: 3
2022-11-28 04:59:28,703 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5186032713814215, 'Total loss': 0.5186032713814215} | train loss {'Reaction outcome loss': 0.5536686586826919, 'Total loss': 0.5536686586826919}
2022-11-28 04:59:28,703 INFO:     Found new best model at epoch 3
2022-11-28 04:59:28,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:28,704 INFO:     Epoch: 4
2022-11-28 04:59:29,372 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5526189931922338, 'Total loss': 0.5526189931922338} | train loss {'Reaction outcome loss': 0.5433596628397582, 'Total loss': 0.5433596628397582}
2022-11-28 04:59:29,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:29,372 INFO:     Epoch: 5
2022-11-28 04:59:30,040 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5545567040416327, 'Total loss': 0.5545567040416327} | train loss {'Reaction outcome loss': 0.5293006127029054, 'Total loss': 0.5293006127029054}
2022-11-28 04:59:30,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:30,040 INFO:     Epoch: 6
2022-11-28 04:59:30,707 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5076477317647501, 'Total loss': 0.5076477317647501} | train loss {'Reaction outcome loss': 0.5209135315437549, 'Total loss': 0.5209135315437549}
2022-11-28 04:59:30,707 INFO:     Found new best model at epoch 6
2022-11-28 04:59:30,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:30,708 INFO:     Epoch: 7
2022-11-28 04:59:31,377 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4898152436045083, 'Total loss': 0.4898152436045083} | train loss {'Reaction outcome loss': 0.5082251188243448, 'Total loss': 0.5082251188243448}
2022-11-28 04:59:31,377 INFO:     Found new best model at epoch 7
2022-11-28 04:59:31,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:31,378 INFO:     Epoch: 8
2022-11-28 04:59:32,048 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49470458044247195, 'Total loss': 0.49470458044247195} | train loss {'Reaction outcome loss': 0.5163984155124016, 'Total loss': 0.5163984155124016}
2022-11-28 04:59:32,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:32,049 INFO:     Epoch: 9
2022-11-28 04:59:32,716 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5114187953824346, 'Total loss': 0.5114187953824346} | train loss {'Reaction outcome loss': 0.4979537451858463, 'Total loss': 0.4979537451858463}
2022-11-28 04:59:32,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:32,717 INFO:     Epoch: 10
2022-11-28 04:59:33,386 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47647532380440016, 'Total loss': 0.47647532380440016} | train loss {'Reaction outcome loss': 0.5026177020690702, 'Total loss': 0.5026177020690702}
2022-11-28 04:59:33,386 INFO:     Found new best model at epoch 10
2022-11-28 04:59:33,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:33,387 INFO:     Epoch: 11
2022-11-28 04:59:34,056 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4913430806588043, 'Total loss': 0.4913430806588043} | train loss {'Reaction outcome loss': 0.48895008705164256, 'Total loss': 0.48895008705164256}
2022-11-28 04:59:34,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:34,056 INFO:     Epoch: 12
2022-11-28 04:59:34,727 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49974098056554794, 'Total loss': 0.49974098056554794} | train loss {'Reaction outcome loss': 0.4816225005185556, 'Total loss': 0.4816225005185556}
2022-11-28 04:59:34,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:34,727 INFO:     Epoch: 13
2022-11-28 04:59:35,394 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4919434528459202, 'Total loss': 0.4919434528459202} | train loss {'Reaction outcome loss': 0.491753167649995, 'Total loss': 0.491753167649995}
2022-11-28 04:59:35,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:35,394 INFO:     Epoch: 14
2022-11-28 04:59:36,065 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48253300244157965, 'Total loss': 0.48253300244157965} | train loss {'Reaction outcome loss': 0.4943071680392331, 'Total loss': 0.4943071680392331}
2022-11-28 04:59:36,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:36,065 INFO:     Epoch: 15
2022-11-28 04:59:36,733 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4715360836549239, 'Total loss': 0.4715360836549239} | train loss {'Reaction outcome loss': 0.4807202936515876, 'Total loss': 0.4807202936515876}
2022-11-28 04:59:36,733 INFO:     Found new best model at epoch 15
2022-11-28 04:59:36,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:36,734 INFO:     Epoch: 16
2022-11-28 04:59:37,404 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.559292854910547, 'Total loss': 0.559292854910547} | train loss {'Reaction outcome loss': 0.49013417871736803, 'Total loss': 0.49013417871736803}
2022-11-28 04:59:37,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:37,404 INFO:     Epoch: 17
2022-11-28 04:59:38,072 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4910444143143567, 'Total loss': 0.4910444143143567} | train loss {'Reaction outcome loss': 0.5000664519394941, 'Total loss': 0.5000664519394941}
2022-11-28 04:59:38,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:38,072 INFO:     Epoch: 18
2022-11-28 04:59:38,741 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48969318853183225, 'Total loss': 0.48969318853183225} | train loss {'Reaction outcome loss': 0.48959224015806124, 'Total loss': 0.48959224015806124}
2022-11-28 04:59:38,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:38,741 INFO:     Epoch: 19
2022-11-28 04:59:39,413 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49800637093457306, 'Total loss': 0.49800637093457306} | train loss {'Reaction outcome loss': 0.4821117250701254, 'Total loss': 0.4821117250701254}
2022-11-28 04:59:39,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:39,413 INFO:     Epoch: 20
2022-11-28 04:59:40,086 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.631257832727649, 'Total loss': 0.631257832727649} | train loss {'Reaction outcome loss': 0.4734382531662219, 'Total loss': 0.4734382531662219}
2022-11-28 04:59:40,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:40,087 INFO:     Epoch: 21
2022-11-28 04:59:40,758 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4670272445814176, 'Total loss': 0.4670272445814176} | train loss {'Reaction outcome loss': 0.4932886029062001, 'Total loss': 0.4932886029062001}
2022-11-28 04:59:40,758 INFO:     Found new best model at epoch 21
2022-11-28 04:59:40,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:40,759 INFO:     Epoch: 22
2022-11-28 04:59:41,429 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4869892190803181, 'Total loss': 0.4869892190803181} | train loss {'Reaction outcome loss': 0.4762861996527143, 'Total loss': 0.4762861996527143}
2022-11-28 04:59:41,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:41,430 INFO:     Epoch: 23
2022-11-28 04:59:42,100 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5051606605676088, 'Total loss': 0.5051606605676088} | train loss {'Reaction outcome loss': 0.4858579732296679, 'Total loss': 0.4858579732296679}
2022-11-28 04:59:42,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:42,101 INFO:     Epoch: 24
2022-11-28 04:59:42,769 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4846083501523191, 'Total loss': 0.4846083501523191} | train loss {'Reaction outcome loss': 0.4783851856041534, 'Total loss': 0.4783851856041534}
2022-11-28 04:59:42,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:42,769 INFO:     Epoch: 25
2022-11-28 04:59:43,436 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5119995766065337, 'Total loss': 0.5119995766065337} | train loss {'Reaction outcome loss': 0.48580960301976456, 'Total loss': 0.48580960301976456}
2022-11-28 04:59:43,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:43,436 INFO:     Epoch: 26
2022-11-28 04:59:44,102 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46830501000989566, 'Total loss': 0.46830501000989566} | train loss {'Reaction outcome loss': 0.48792443988535567, 'Total loss': 0.48792443988535567}
2022-11-28 04:59:44,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:44,103 INFO:     Epoch: 27
2022-11-28 04:59:44,770 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.517667886547067, 'Total loss': 0.517667886547067} | train loss {'Reaction outcome loss': 0.4768129695048518, 'Total loss': 0.4768129695048518}
2022-11-28 04:59:44,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:44,771 INFO:     Epoch: 28
2022-11-28 04:59:45,440 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47696310484951193, 'Total loss': 0.47696310484951193} | train loss {'Reaction outcome loss': 0.46805938052745, 'Total loss': 0.46805938052745}
2022-11-28 04:59:45,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:45,441 INFO:     Epoch: 29
2022-11-28 04:59:46,115 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47657253457741305, 'Total loss': 0.47657253457741305} | train loss {'Reaction outcome loss': 0.4786591649296795, 'Total loss': 0.4786591649296795}
2022-11-28 04:59:46,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:46,116 INFO:     Epoch: 30
2022-11-28 04:59:46,782 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4825110740282319, 'Total loss': 0.4825110740282319} | train loss {'Reaction outcome loss': 0.4768433191394999, 'Total loss': 0.4768433191394999}
2022-11-28 04:59:46,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:46,782 INFO:     Epoch: 31
2022-11-28 04:59:47,450 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4888869412243366, 'Total loss': 0.4888869412243366} | train loss {'Reaction outcome loss': 0.48017542380914996, 'Total loss': 0.48017542380914996}
2022-11-28 04:59:47,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:47,450 INFO:     Epoch: 32
2022-11-28 04:59:48,116 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4934827678582885, 'Total loss': 0.4934827678582885} | train loss {'Reaction outcome loss': 0.4810664556347407, 'Total loss': 0.4810664556347407}
2022-11-28 04:59:48,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:48,116 INFO:     Epoch: 33
2022-11-28 04:59:48,782 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46985067935152486, 'Total loss': 0.46985067935152486} | train loss {'Reaction outcome loss': 0.4784986753212778, 'Total loss': 0.4784986753212778}
2022-11-28 04:59:48,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:48,782 INFO:     Epoch: 34
2022-11-28 04:59:49,451 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47393404760143976, 'Total loss': 0.47393404760143976} | train loss {'Reaction outcome loss': 0.4742035561567361, 'Total loss': 0.4742035561567361}
2022-11-28 04:59:49,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:49,451 INFO:     Epoch: 35
2022-11-28 04:59:50,123 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5119615915146741, 'Total loss': 0.5119615915146741} | train loss {'Reaction outcome loss': 0.47624521434065786, 'Total loss': 0.47624521434065786}
2022-11-28 04:59:50,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:50,123 INFO:     Epoch: 36
2022-11-28 04:59:50,792 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45441597479988227, 'Total loss': 0.45441597479988227} | train loss {'Reaction outcome loss': 0.481580937801585, 'Total loss': 0.481580937801585}
2022-11-28 04:59:50,793 INFO:     Found new best model at epoch 36
2022-11-28 04:59:50,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:50,793 INFO:     Epoch: 37
2022-11-28 04:59:51,465 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49216782775792206, 'Total loss': 0.49216782775792206} | train loss {'Reaction outcome loss': 0.48339772037407647, 'Total loss': 0.48339772037407647}
2022-11-28 04:59:51,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:51,465 INFO:     Epoch: 38
2022-11-28 04:59:52,134 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4727367955175313, 'Total loss': 0.4727367955175313} | train loss {'Reaction outcome loss': 0.4851750778524499, 'Total loss': 0.4851750778524499}
2022-11-28 04:59:52,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:52,135 INFO:     Epoch: 39
2022-11-28 04:59:52,804 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.501072259111838, 'Total loss': 0.501072259111838} | train loss {'Reaction outcome loss': 0.47432528208066455, 'Total loss': 0.47432528208066455}
2022-11-28 04:59:52,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:52,804 INFO:     Epoch: 40
2022-11-28 04:59:53,474 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5131940025497567, 'Total loss': 0.5131940025497567} | train loss {'Reaction outcome loss': 0.4730074858436218, 'Total loss': 0.4730074858436218}
2022-11-28 04:59:53,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:53,475 INFO:     Epoch: 41
2022-11-28 04:59:54,144 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46070274541323836, 'Total loss': 0.46070274541323836} | train loss {'Reaction outcome loss': 0.47532566386437125, 'Total loss': 0.47532566386437125}
2022-11-28 04:59:54,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:54,144 INFO:     Epoch: 42
2022-11-28 04:59:54,810 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.514117761769078, 'Total loss': 0.514117761769078} | train loss {'Reaction outcome loss': 0.4809471596831735, 'Total loss': 0.4809471596831735}
2022-11-28 04:59:54,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:54,810 INFO:     Epoch: 43
2022-11-28 04:59:55,478 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5185657827691599, 'Total loss': 0.5185657827691599} | train loss {'Reaction outcome loss': 0.4942356590558643, 'Total loss': 0.4942356590558643}
2022-11-28 04:59:55,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:55,478 INFO:     Epoch: 44
2022-11-28 04:59:56,149 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4727781435305422, 'Total loss': 0.4727781435305422} | train loss {'Reaction outcome loss': 0.48468164369644906, 'Total loss': 0.48468164369644906}
2022-11-28 04:59:56,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:56,149 INFO:     Epoch: 45
2022-11-28 04:59:56,819 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.498927694152702, 'Total loss': 0.498927694152702} | train loss {'Reaction outcome loss': 0.4758439910435966, 'Total loss': 0.4758439910435966}
2022-11-28 04:59:56,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:56,820 INFO:     Epoch: 46
2022-11-28 04:59:57,489 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5542430325665257, 'Total loss': 0.5542430325665257} | train loss {'Reaction outcome loss': 0.48250820664198774, 'Total loss': 0.48250820664198774}
2022-11-28 04:59:57,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:57,489 INFO:     Epoch: 47
2022-11-28 04:59:58,156 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48989664018154144, 'Total loss': 0.48989664018154144} | train loss {'Reaction outcome loss': 0.474127638738165, 'Total loss': 0.474127638738165}
2022-11-28 04:59:58,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:58,156 INFO:     Epoch: 48
2022-11-28 04:59:58,820 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4612854007970203, 'Total loss': 0.4612854007970203} | train loss {'Reaction outcome loss': 0.4780640622284188, 'Total loss': 0.4780640622284188}
2022-11-28 04:59:58,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:58,821 INFO:     Epoch: 49
2022-11-28 04:59:59,488 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5261171385645866, 'Total loss': 0.5261171385645866} | train loss {'Reaction outcome loss': 0.4709665039893587, 'Total loss': 0.4709665039893587}
2022-11-28 04:59:59,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 04:59:59,489 INFO:     Epoch: 50
2022-11-28 05:00:00,161 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.474542380056598, 'Total loss': 0.474542380056598} | train loss {'Reaction outcome loss': 0.4817313933179446, 'Total loss': 0.4817313933179446}
2022-11-28 05:00:00,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:00,161 INFO:     Epoch: 51
2022-11-28 05:00:00,830 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47482835433699866, 'Total loss': 0.47482835433699866} | train loss {'Reaction outcome loss': 0.4848928841864049, 'Total loss': 0.4848928841864049}
2022-11-28 05:00:00,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:00,830 INFO:     Epoch: 52
2022-11-28 05:00:01,499 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5152501633221452, 'Total loss': 0.5152501633221452} | train loss {'Reaction outcome loss': 0.47768317027251245, 'Total loss': 0.47768317027251245}
2022-11-28 05:00:01,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:01,499 INFO:     Epoch: 53
2022-11-28 05:00:02,166 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5143660767511888, 'Total loss': 0.5143660767511888} | train loss {'Reaction outcome loss': 0.47428509501008853, 'Total loss': 0.47428509501008853}
2022-11-28 05:00:02,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:02,167 INFO:     Epoch: 54
2022-11-28 05:00:02,835 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.578541486100717, 'Total loss': 0.578541486100717} | train loss {'Reaction outcome loss': 0.4711148063030079, 'Total loss': 0.4711148063030079}
2022-11-28 05:00:02,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:02,835 INFO:     Epoch: 55
2022-11-28 05:00:03,503 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47395981137048115, 'Total loss': 0.47395981137048115} | train loss {'Reaction outcome loss': 0.47907462838645043, 'Total loss': 0.47907462838645043}
2022-11-28 05:00:03,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:03,503 INFO:     Epoch: 56
2022-11-28 05:00:04,171 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47275072471662, 'Total loss': 0.47275072471662} | train loss {'Reaction outcome loss': 0.4648201344346228, 'Total loss': 0.4648201344346228}
2022-11-28 05:00:04,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:04,171 INFO:     Epoch: 57
2022-11-28 05:00:04,843 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45632861622355203, 'Total loss': 0.45632861622355203} | train loss {'Reaction outcome loss': 0.47891257154314143, 'Total loss': 0.47891257154314143}
2022-11-28 05:00:04,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:04,843 INFO:     Epoch: 58
2022-11-28 05:00:05,511 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5204316533424638, 'Total loss': 0.5204316533424638} | train loss {'Reaction outcome loss': 0.47644799127269855, 'Total loss': 0.47644799127269855}
2022-11-28 05:00:05,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:05,511 INFO:     Epoch: 59
2022-11-28 05:00:06,179 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4555119953372262, 'Total loss': 0.4555119953372262} | train loss {'Reaction outcome loss': 0.4802929432497092, 'Total loss': 0.4802929432497092}
2022-11-28 05:00:06,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:06,180 INFO:     Epoch: 60
2022-11-28 05:00:06,848 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47548642415891995, 'Total loss': 0.47548642415891995} | train loss {'Reaction outcome loss': 0.47433529564967525, 'Total loss': 0.47433529564967525}
2022-11-28 05:00:06,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:06,848 INFO:     Epoch: 61
2022-11-28 05:00:07,516 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4628403095359152, 'Total loss': 0.4628403095359152} | train loss {'Reaction outcome loss': 0.48125519564277247, 'Total loss': 0.48125519564277247}
2022-11-28 05:00:07,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:07,516 INFO:     Epoch: 62
2022-11-28 05:00:08,183 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5064584917642854, 'Total loss': 0.5064584917642854} | train loss {'Reaction outcome loss': 0.48445004954753135, 'Total loss': 0.48445004954753135}
2022-11-28 05:00:08,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:08,183 INFO:     Epoch: 63
2022-11-28 05:00:08,850 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4815053455531597, 'Total loss': 0.4815053455531597} | train loss {'Reaction outcome loss': 0.5045561209502007, 'Total loss': 0.5045561209502007}
2022-11-28 05:00:08,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:08,850 INFO:     Epoch: 64
2022-11-28 05:00:09,518 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4753176353194497, 'Total loss': 0.4753176353194497} | train loss {'Reaction outcome loss': 0.47360047489321727, 'Total loss': 0.47360047489321727}
2022-11-28 05:00:09,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:09,519 INFO:     Epoch: 65
2022-11-28 05:00:10,190 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5710693889043548, 'Total loss': 0.5710693889043548} | train loss {'Reaction outcome loss': 0.47445286001995024, 'Total loss': 0.47445286001995024}
2022-11-28 05:00:10,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:10,191 INFO:     Epoch: 66
2022-11-28 05:00:10,863 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48344282839785924, 'Total loss': 0.48344282839785924} | train loss {'Reaction outcome loss': 0.47745721620933607, 'Total loss': 0.47745721620933607}
2022-11-28 05:00:10,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:10,863 INFO:     Epoch: 67
2022-11-28 05:00:11,530 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5011160529472611, 'Total loss': 0.5011160529472611} | train loss {'Reaction outcome loss': 0.47282581948317015, 'Total loss': 0.47282581948317015}
2022-11-28 05:00:11,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:11,531 INFO:     Epoch: 68
2022-11-28 05:00:12,198 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49906355481256137, 'Total loss': 0.49906355481256137} | train loss {'Reaction outcome loss': 0.4742348353691429, 'Total loss': 0.4742348353691429}
2022-11-28 05:00:12,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:12,198 INFO:     Epoch: 69
2022-11-28 05:00:12,868 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5388233336535367, 'Total loss': 0.5388233336535367} | train loss {'Reaction outcome loss': 0.4814931535527774, 'Total loss': 0.4814931535527774}
2022-11-28 05:00:12,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:12,869 INFO:     Epoch: 70
2022-11-28 05:00:13,535 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.49181956255977805, 'Total loss': 0.49181956255977805} | train loss {'Reaction outcome loss': 0.4771840140102846, 'Total loss': 0.4771840140102846}
2022-11-28 05:00:13,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:13,535 INFO:     Epoch: 71
2022-11-28 05:00:14,206 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4809546580707485, 'Total loss': 0.4809546580707485} | train loss {'Reaction outcome loss': 0.4793050840557346, 'Total loss': 0.4793050840557346}
2022-11-28 05:00:14,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:14,206 INFO:     Epoch: 72
2022-11-28 05:00:14,879 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48156489499590616, 'Total loss': 0.48156489499590616} | train loss {'Reaction outcome loss': 0.4783126028925784, 'Total loss': 0.4783126028925784}
2022-11-28 05:00:14,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:14,879 INFO:     Epoch: 73
2022-11-28 05:00:15,548 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5400643687356602, 'Total loss': 0.5400643687356602} | train loss {'Reaction outcome loss': 0.4726261730015519, 'Total loss': 0.4726261730015519}
2022-11-28 05:00:15,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:15,548 INFO:     Epoch: 74
2022-11-28 05:00:16,217 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48158109323544934, 'Total loss': 0.48158109323544934} | train loss {'Reaction outcome loss': 0.47881041105218264, 'Total loss': 0.47881041105218264}
2022-11-28 05:00:16,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:16,217 INFO:     Epoch: 75
2022-11-28 05:00:16,887 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5175392075695775, 'Total loss': 0.5175392075695775} | train loss {'Reaction outcome loss': 0.4757287221157599, 'Total loss': 0.4757287221157599}
2022-11-28 05:00:16,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:16,888 INFO:     Epoch: 76
2022-11-28 05:00:17,559 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46635584804144775, 'Total loss': 0.46635584804144775} | train loss {'Reaction outcome loss': 0.4829416231587831, 'Total loss': 0.4829416231587831}
2022-11-28 05:00:17,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:17,559 INFO:     Epoch: 77
2022-11-28 05:00:18,226 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4687515480274504, 'Total loss': 0.4687515480274504} | train loss {'Reaction outcome loss': 0.485203554755763, 'Total loss': 0.485203554755763}
2022-11-28 05:00:18,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:18,227 INFO:     Epoch: 78
2022-11-28 05:00:18,897 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4722247448834506, 'Total loss': 0.4722247448834506} | train loss {'Reaction outcome loss': 0.47202793344843996, 'Total loss': 0.47202793344843996}
2022-11-28 05:00:18,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:18,897 INFO:     Epoch: 79
2022-11-28 05:00:19,572 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4814306084405292, 'Total loss': 0.4814306084405292} | train loss {'Reaction outcome loss': 0.47786101367068196, 'Total loss': 0.47786101367068196}
2022-11-28 05:00:19,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:19,572 INFO:     Epoch: 80
2022-11-28 05:00:20,244 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46958330409093335, 'Total loss': 0.46958330409093335} | train loss {'Reaction outcome loss': 0.4820930665803824, 'Total loss': 0.4820930665803824}
2022-11-28 05:00:20,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:20,245 INFO:     Epoch: 81
2022-11-28 05:00:20,916 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48290866308591585, 'Total loss': 0.48290866308591585} | train loss {'Reaction outcome loss': 0.4823396893044715, 'Total loss': 0.4823396893044715}
2022-11-28 05:00:20,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:20,916 INFO:     Epoch: 82
2022-11-28 05:00:21,583 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45978439125147735, 'Total loss': 0.45978439125147735} | train loss {'Reaction outcome loss': 0.47683842584249464, 'Total loss': 0.47683842584249464}
2022-11-28 05:00:21,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:21,583 INFO:     Epoch: 83
2022-11-28 05:00:22,248 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4787094122306867, 'Total loss': 0.4787094122306867} | train loss {'Reaction outcome loss': 0.4801129354880406, 'Total loss': 0.4801129354880406}
2022-11-28 05:00:22,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:22,248 INFO:     Epoch: 84
2022-11-28 05:00:22,918 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47442941638556396, 'Total loss': 0.47442941638556396} | train loss {'Reaction outcome loss': 0.478326131880042, 'Total loss': 0.478326131880042}
2022-11-28 05:00:22,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:22,918 INFO:     Epoch: 85
2022-11-28 05:00:23,590 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4627837230536071, 'Total loss': 0.4627837230536071} | train loss {'Reaction outcome loss': 0.47443325818527626, 'Total loss': 0.47443325818527626}
2022-11-28 05:00:23,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:23,590 INFO:     Epoch: 86
2022-11-28 05:00:24,260 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47167720476334746, 'Total loss': 0.47167720476334746} | train loss {'Reaction outcome loss': 0.4766803050210119, 'Total loss': 0.4766803050210119}
2022-11-28 05:00:24,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:24,261 INFO:     Epoch: 87
2022-11-28 05:00:24,928 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4731574552980336, 'Total loss': 0.4731574552980336} | train loss {'Reaction outcome loss': 0.47885907951154205, 'Total loss': 0.47885907951154205}
2022-11-28 05:00:24,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:24,929 INFO:     Epoch: 88
2022-11-28 05:00:25,597 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4953653599050912, 'Total loss': 0.4953653599050912} | train loss {'Reaction outcome loss': 0.4809623397434289, 'Total loss': 0.4809623397434289}
2022-11-28 05:00:25,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:25,597 INFO:     Epoch: 89
2022-11-28 05:00:26,265 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4934467090801759, 'Total loss': 0.4934467090801759} | train loss {'Reaction outcome loss': 0.4785744742101986, 'Total loss': 0.4785744742101986}
2022-11-28 05:00:26,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:26,265 INFO:     Epoch: 90
2022-11-28 05:00:26,932 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4583249921825799, 'Total loss': 0.4583249921825799} | train loss {'Reaction outcome loss': 0.47634367460784643, 'Total loss': 0.47634367460784643}
2022-11-28 05:00:26,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:26,932 INFO:     Epoch: 91
2022-11-28 05:00:27,601 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49072432484139095, 'Total loss': 0.49072432484139095} | train loss {'Reaction outcome loss': 0.47968185762403465, 'Total loss': 0.47968185762403465}
2022-11-28 05:00:27,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:27,601 INFO:     Epoch: 92
2022-11-28 05:00:28,271 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4884187054227699, 'Total loss': 0.4884187054227699} | train loss {'Reaction outcome loss': 0.4858238007496243, 'Total loss': 0.4858238007496243}
2022-11-28 05:00:28,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:28,271 INFO:     Epoch: 93
2022-11-28 05:00:28,940 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4727560715241866, 'Total loss': 0.4727560715241866} | train loss {'Reaction outcome loss': 0.4793488020115053, 'Total loss': 0.4793488020115053}
2022-11-28 05:00:28,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:28,940 INFO:     Epoch: 94
2022-11-28 05:00:29,611 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45523981987075374, 'Total loss': 0.45523981987075374} | train loss {'Reaction outcome loss': 0.477922731625889, 'Total loss': 0.477922731625889}
2022-11-28 05:00:29,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:29,611 INFO:     Epoch: 95
2022-11-28 05:00:30,279 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5261817601594058, 'Total loss': 0.5261817601594058} | train loss {'Reaction outcome loss': 0.4715526308487301, 'Total loss': 0.4715526308487301}
2022-11-28 05:00:30,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:30,279 INFO:     Epoch: 96
2022-11-28 05:00:30,951 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5058231360533021, 'Total loss': 0.5058231360533021} | train loss {'Reaction outcome loss': 0.4824195650485363, 'Total loss': 0.4824195650485363}
2022-11-28 05:00:30,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:30,952 INFO:     Epoch: 97
2022-11-28 05:00:31,623 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49444095688787376, 'Total loss': 0.49444095688787376} | train loss {'Reaction outcome loss': 0.4748456298339705, 'Total loss': 0.4748456298339705}
2022-11-28 05:00:31,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:31,624 INFO:     Epoch: 98
2022-11-28 05:00:32,294 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47532610392028635, 'Total loss': 0.47532610392028635} | train loss {'Reaction outcome loss': 0.47515052660304286, 'Total loss': 0.47515052660304286}
2022-11-28 05:00:32,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:32,295 INFO:     Epoch: 99
2022-11-28 05:00:32,963 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5364887673746456, 'Total loss': 0.5364887673746456} | train loss {'Reaction outcome loss': 0.4714404623427613, 'Total loss': 0.4714404623427613}
2022-11-28 05:00:32,963 INFO:     Best model found after epoch 37 of 100.
2022-11-28 05:00:32,963 INFO:   Done with stage: TRAINING
2022-11-28 05:00:32,963 INFO:   Starting stage: EVALUATION
2022-11-28 05:00:33,081 INFO:   Done with stage: EVALUATION
2022-11-28 05:00:33,081 INFO:   Leaving out SEQ value Fold_5
2022-11-28 05:00:33,094 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 05:00:33,094 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:00:33,756 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:00:33,756 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:00:33,826 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:00:33,826 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:00:33,826 INFO:     No hyperparam tuning for this model
2022-11-28 05:00:33,826 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:00:33,827 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:00:33,827 INFO:     None feature selector for col prot
2022-11-28 05:00:33,827 INFO:     None feature selector for col prot
2022-11-28 05:00:33,827 INFO:     None feature selector for col prot
2022-11-28 05:00:33,828 INFO:     None feature selector for col chem
2022-11-28 05:00:33,828 INFO:     None feature selector for col chem
2022-11-28 05:00:33,828 INFO:     None feature selector for col chem
2022-11-28 05:00:33,828 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:00:33,828 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:00:33,830 INFO:     Number of params in model 169651
2022-11-28 05:00:33,833 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:00:33,833 INFO:   Starting stage: TRAINING
2022-11-28 05:00:33,885 INFO:     Val loss before train {'Reaction outcome loss': 0.949120626530864, 'Total loss': 0.949120626530864}
2022-11-28 05:00:33,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:33,885 INFO:     Epoch: 0
2022-11-28 05:00:34,558 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5787379856814038, 'Total loss': 0.5787379856814038} | train loss {'Reaction outcome loss': 0.6936895806462534, 'Total loss': 0.6936895806462534}
2022-11-28 05:00:34,558 INFO:     Found new best model at epoch 0
2022-11-28 05:00:34,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:34,558 INFO:     Epoch: 1
2022-11-28 05:00:35,230 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5658256621523337, 'Total loss': 0.5658256621523337} | train loss {'Reaction outcome loss': 0.5804280319040821, 'Total loss': 0.5804280319040821}
2022-11-28 05:00:35,230 INFO:     Found new best model at epoch 1
2022-11-28 05:00:35,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:35,231 INFO:     Epoch: 2
2022-11-28 05:00:35,908 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5255866362289949, 'Total loss': 0.5255866362289949} | train loss {'Reaction outcome loss': 0.5607352230337358, 'Total loss': 0.5607352230337358}
2022-11-28 05:00:35,908 INFO:     Found new best model at epoch 2
2022-11-28 05:00:35,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:35,909 INFO:     Epoch: 3
2022-11-28 05:00:36,583 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5348360416564074, 'Total loss': 0.5348360416564074} | train loss {'Reaction outcome loss': 0.5302274499328867, 'Total loss': 0.5302274499328867}
2022-11-28 05:00:36,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:36,583 INFO:     Epoch: 4
2022-11-28 05:00:37,256 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5243882506408475, 'Total loss': 0.5243882506408475} | train loss {'Reaction outcome loss': 0.5206993233051992, 'Total loss': 0.5206993233051992}
2022-11-28 05:00:37,256 INFO:     Found new best model at epoch 4
2022-11-28 05:00:37,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:37,257 INFO:     Epoch: 5
2022-11-28 05:00:37,933 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5138975429263982, 'Total loss': 0.5138975429263982} | train loss {'Reaction outcome loss': 0.5093422889589302, 'Total loss': 0.5093422889589302}
2022-11-28 05:00:37,933 INFO:     Found new best model at epoch 5
2022-11-28 05:00:37,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:37,934 INFO:     Epoch: 6
2022-11-28 05:00:38,605 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4986704703081738, 'Total loss': 0.4986704703081738} | train loss {'Reaction outcome loss': 0.507883635860297, 'Total loss': 0.507883635860297}
2022-11-28 05:00:38,605 INFO:     Found new best model at epoch 6
2022-11-28 05:00:38,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:38,606 INFO:     Epoch: 7
2022-11-28 05:00:39,281 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.473567761819471, 'Total loss': 0.473567761819471} | train loss {'Reaction outcome loss': 0.4960450323959512, 'Total loss': 0.4960450323959512}
2022-11-28 05:00:39,281 INFO:     Found new best model at epoch 7
2022-11-28 05:00:39,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:39,282 INFO:     Epoch: 8
2022-11-28 05:00:39,955 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5071198811585252, 'Total loss': 0.5071198811585252} | train loss {'Reaction outcome loss': 0.497932814482239, 'Total loss': 0.497932814482239}
2022-11-28 05:00:39,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:39,955 INFO:     Epoch: 9
2022-11-28 05:00:40,629 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5014270103790543, 'Total loss': 0.5014270103790543} | train loss {'Reaction outcome loss': 0.49437714392139065, 'Total loss': 0.49437714392139065}
2022-11-28 05:00:40,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:40,629 INFO:     Epoch: 10
2022-11-28 05:00:41,301 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4774357419122349, 'Total loss': 0.4774357419122349} | train loss {'Reaction outcome loss': 0.4878832677439336, 'Total loss': 0.4878832677439336}
2022-11-28 05:00:41,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:41,301 INFO:     Epoch: 11
2022-11-28 05:00:41,971 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49208527261560614, 'Total loss': 0.49208527261560614} | train loss {'Reaction outcome loss': 0.48544951155781746, 'Total loss': 0.48544951155781746}
2022-11-28 05:00:41,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:41,972 INFO:     Epoch: 12
2022-11-28 05:00:42,641 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48840501328760927, 'Total loss': 0.48840501328760927} | train loss {'Reaction outcome loss': 0.4842667254589258, 'Total loss': 0.4842667254589258}
2022-11-28 05:00:42,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:42,641 INFO:     Epoch: 13
2022-11-28 05:00:43,312 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.537727106701244, 'Total loss': 0.537727106701244} | train loss {'Reaction outcome loss': 0.48608347304886385, 'Total loss': 0.48608347304886385}
2022-11-28 05:00:43,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:43,313 INFO:     Epoch: 14
2022-11-28 05:00:43,986 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5073984675109386, 'Total loss': 0.5073984675109386} | train loss {'Reaction outcome loss': 0.47929032429331736, 'Total loss': 0.47929032429331736}
2022-11-28 05:00:43,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:43,986 INFO:     Epoch: 15
2022-11-28 05:00:44,660 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48705232617529953, 'Total loss': 0.48705232617529953} | train loss {'Reaction outcome loss': 0.48810652898804796, 'Total loss': 0.48810652898804796}
2022-11-28 05:00:44,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:44,660 INFO:     Epoch: 16
2022-11-28 05:00:45,339 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48497259413654153, 'Total loss': 0.48497259413654153} | train loss {'Reaction outcome loss': 0.4901260530215598, 'Total loss': 0.4901260530215598}
2022-11-28 05:00:45,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:45,339 INFO:     Epoch: 17
2022-11-28 05:00:46,015 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4993352788415822, 'Total loss': 0.4993352788415822} | train loss {'Reaction outcome loss': 0.48216383630830434, 'Total loss': 0.48216383630830434}
2022-11-28 05:00:46,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:46,016 INFO:     Epoch: 18
2022-11-28 05:00:46,690 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49807594276287337, 'Total loss': 0.49807594276287337} | train loss {'Reaction outcome loss': 0.47308598014135517, 'Total loss': 0.47308598014135517}
2022-11-28 05:00:46,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:46,690 INFO:     Epoch: 19
2022-11-28 05:00:47,361 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48801261626861314, 'Total loss': 0.48801261626861314} | train loss {'Reaction outcome loss': 0.4786092083180143, 'Total loss': 0.4786092083180143}
2022-11-28 05:00:47,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:47,361 INFO:     Epoch: 20
2022-11-28 05:00:48,033 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4864597774364732, 'Total loss': 0.4864597774364732} | train loss {'Reaction outcome loss': 0.4771382245685785, 'Total loss': 0.4771382245685785}
2022-11-28 05:00:48,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:48,033 INFO:     Epoch: 21
2022-11-28 05:00:48,704 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49329330772161484, 'Total loss': 0.49329330772161484} | train loss {'Reaction outcome loss': 0.47672807671610384, 'Total loss': 0.47672807671610384}
2022-11-28 05:00:48,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:48,704 INFO:     Epoch: 22
2022-11-28 05:00:49,377 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46400434557687154, 'Total loss': 0.46400434557687154} | train loss {'Reaction outcome loss': 0.48227737786909264, 'Total loss': 0.48227737786909264}
2022-11-28 05:00:49,377 INFO:     Found new best model at epoch 22
2022-11-28 05:00:49,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:49,378 INFO:     Epoch: 23
2022-11-28 05:00:50,051 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5062052976678718, 'Total loss': 0.5062052976678718} | train loss {'Reaction outcome loss': 0.4775788084033035, 'Total loss': 0.4775788084033035}
2022-11-28 05:00:50,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:50,051 INFO:     Epoch: 24
2022-11-28 05:00:50,726 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4774961820380254, 'Total loss': 0.4774961820380254} | train loss {'Reaction outcome loss': 0.47662190323875797, 'Total loss': 0.47662190323875797}
2022-11-28 05:00:50,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:50,727 INFO:     Epoch: 25
2022-11-28 05:00:51,398 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.474857743490826, 'Total loss': 0.474857743490826} | train loss {'Reaction outcome loss': 0.4770296115668551, 'Total loss': 0.4770296115668551}
2022-11-28 05:00:51,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:51,398 INFO:     Epoch: 26
2022-11-28 05:00:52,070 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47492134604941716, 'Total loss': 0.47492134604941716} | train loss {'Reaction outcome loss': 0.46996772223182265, 'Total loss': 0.46996772223182265}
2022-11-28 05:00:52,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:52,071 INFO:     Epoch: 27
2022-11-28 05:00:52,742 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4856199005788023, 'Total loss': 0.4856199005788023} | train loss {'Reaction outcome loss': 0.47844462036605806, 'Total loss': 0.47844462036605806}
2022-11-28 05:00:52,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:52,743 INFO:     Epoch: 28
2022-11-28 05:00:53,414 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48440947383642197, 'Total loss': 0.48440947383642197} | train loss {'Reaction outcome loss': 0.4668818515755476, 'Total loss': 0.4668818515755476}
2022-11-28 05:00:53,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:53,415 INFO:     Epoch: 29
2022-11-28 05:00:54,086 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4960359761660749, 'Total loss': 0.4960359761660749} | train loss {'Reaction outcome loss': 0.4695659031070048, 'Total loss': 0.4695659031070048}
2022-11-28 05:00:54,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:54,086 INFO:     Epoch: 30
2022-11-28 05:00:54,756 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48864229158921674, 'Total loss': 0.48864229158921674} | train loss {'Reaction outcome loss': 0.4704199253070739, 'Total loss': 0.4704199253070739}
2022-11-28 05:00:54,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:54,757 INFO:     Epoch: 31
2022-11-28 05:00:55,430 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4635695982724428, 'Total loss': 0.4635695982724428} | train loss {'Reaction outcome loss': 0.4659359170905044, 'Total loss': 0.4659359170905044}
2022-11-28 05:00:55,431 INFO:     Found new best model at epoch 31
2022-11-28 05:00:55,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:55,432 INFO:     Epoch: 32
2022-11-28 05:00:56,106 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5211936489424922, 'Total loss': 0.5211936489424922} | train loss {'Reaction outcome loss': 0.4646754310195965, 'Total loss': 0.4646754310195965}
2022-11-28 05:00:56,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:56,106 INFO:     Epoch: 33
2022-11-28 05:00:56,779 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47801127115433867, 'Total loss': 0.47801127115433867} | train loss {'Reaction outcome loss': 0.47623145592308813, 'Total loss': 0.47623145592308813}
2022-11-28 05:00:56,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:56,779 INFO:     Epoch: 34
2022-11-28 05:00:57,450 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4984469413757324, 'Total loss': 0.4984469413757324} | train loss {'Reaction outcome loss': 0.4643337646078679, 'Total loss': 0.4643337646078679}
2022-11-28 05:00:57,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:57,450 INFO:     Epoch: 35
2022-11-28 05:00:58,119 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47312971678647125, 'Total loss': 0.47312971678647125} | train loss {'Reaction outcome loss': 0.4563296266621159, 'Total loss': 0.4563296266621159}
2022-11-28 05:00:58,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:58,119 INFO:     Epoch: 36
2022-11-28 05:00:58,789 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47137346321886237, 'Total loss': 0.47137346321886237} | train loss {'Reaction outcome loss': 0.4769115131949225, 'Total loss': 0.4769115131949225}
2022-11-28 05:00:58,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:58,789 INFO:     Epoch: 37
2022-11-28 05:00:59,461 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48078626462004403, 'Total loss': 0.48078626462004403} | train loss {'Reaction outcome loss': 0.4655378815387526, 'Total loss': 0.4655378815387526}
2022-11-28 05:00:59,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:00:59,462 INFO:     Epoch: 38
2022-11-28 05:01:00,134 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5443846637552435, 'Total loss': 0.5443846637552435} | train loss {'Reaction outcome loss': 0.4728806782513857, 'Total loss': 0.4728806782513857}
2022-11-28 05:01:00,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:00,135 INFO:     Epoch: 39
2022-11-28 05:01:00,803 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4954424710436301, 'Total loss': 0.4954424710436301} | train loss {'Reaction outcome loss': 0.46815731562674046, 'Total loss': 0.46815731562674046}
2022-11-28 05:01:00,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:00,803 INFO:     Epoch: 40
2022-11-28 05:01:01,472 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5111525021493435, 'Total loss': 0.5111525021493435} | train loss {'Reaction outcome loss': 0.4754213551359792, 'Total loss': 0.4754213551359792}
2022-11-28 05:01:01,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:01,473 INFO:     Epoch: 41
2022-11-28 05:01:02,147 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48465053737163544, 'Total loss': 0.48465053737163544} | train loss {'Reaction outcome loss': 0.4579431525461616, 'Total loss': 0.4579431525461616}
2022-11-28 05:01:02,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:02,147 INFO:     Epoch: 42
2022-11-28 05:01:02,826 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47553208538077096, 'Total loss': 0.47553208538077096} | train loss {'Reaction outcome loss': 0.4598203258168313, 'Total loss': 0.4598203258168313}
2022-11-28 05:01:02,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:02,826 INFO:     Epoch: 43
2022-11-28 05:01:03,502 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4740393493663181, 'Total loss': 0.4740393493663181} | train loss {'Reaction outcome loss': 0.4570116729986283, 'Total loss': 0.4570116729986283}
2022-11-28 05:01:03,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:03,503 INFO:     Epoch: 44
2022-11-28 05:01:04,179 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47169605778022244, 'Total loss': 0.47169605778022244} | train loss {'Reaction outcome loss': 0.46076596816701276, 'Total loss': 0.46076596816701276}
2022-11-28 05:01:04,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:04,179 INFO:     Epoch: 45
2022-11-28 05:01:04,859 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5408381779085506, 'Total loss': 0.5408381779085506} | train loss {'Reaction outcome loss': 0.46040710698693027, 'Total loss': 0.46040710698693027}
2022-11-28 05:01:04,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:04,859 INFO:     Epoch: 46
2022-11-28 05:01:05,536 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5010154311629859, 'Total loss': 0.5010154311629859} | train loss {'Reaction outcome loss': 0.46537030725589684, 'Total loss': 0.46537030725589684}
2022-11-28 05:01:05,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:05,536 INFO:     Epoch: 47
2022-11-28 05:01:06,211 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45715547691692004, 'Total loss': 0.45715547691692004} | train loss {'Reaction outcome loss': 0.4612810498163585, 'Total loss': 0.4612810498163585}
2022-11-28 05:01:06,211 INFO:     Found new best model at epoch 47
2022-11-28 05:01:06,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:06,212 INFO:     Epoch: 48
2022-11-28 05:01:06,884 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4610551981763406, 'Total loss': 0.4610551981763406} | train loss {'Reaction outcome loss': 0.4660345958245377, 'Total loss': 0.4660345958245377}
2022-11-28 05:01:06,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:06,884 INFO:     Epoch: 49
2022-11-28 05:01:07,563 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5029209130866961, 'Total loss': 0.5029209130866961} | train loss {'Reaction outcome loss': 0.45669826654897583, 'Total loss': 0.45669826654897583}
2022-11-28 05:01:07,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:07,563 INFO:     Epoch: 50
2022-11-28 05:01:08,236 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46585541861978447, 'Total loss': 0.46585541861978447} | train loss {'Reaction outcome loss': 0.46487828018143773, 'Total loss': 0.46487828018143773}
2022-11-28 05:01:08,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:08,237 INFO:     Epoch: 51
2022-11-28 05:01:08,912 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4631773695688356, 'Total loss': 0.4631773695688356} | train loss {'Reaction outcome loss': 0.47480273396978456, 'Total loss': 0.47480273396978456}
2022-11-28 05:01:08,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:08,912 INFO:     Epoch: 52
2022-11-28 05:01:09,586 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48807326941327617, 'Total loss': 0.48807326941327617} | train loss {'Reaction outcome loss': 0.46440839064457723, 'Total loss': 0.46440839064457723}
2022-11-28 05:01:09,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:09,587 INFO:     Epoch: 53
2022-11-28 05:01:10,262 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.508113166486675, 'Total loss': 0.508113166486675} | train loss {'Reaction outcome loss': 0.4695559197496022, 'Total loss': 0.4695559197496022}
2022-11-28 05:01:10,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:10,262 INFO:     Epoch: 54
2022-11-28 05:01:10,941 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47371482171795587, 'Total loss': 0.47371482171795587} | train loss {'Reaction outcome loss': 0.45635232882153604, 'Total loss': 0.45635232882153604}
2022-11-28 05:01:10,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:10,941 INFO:     Epoch: 55
2022-11-28 05:01:11,619 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4856140445917845, 'Total loss': 0.4856140445917845} | train loss {'Reaction outcome loss': 0.47483666187092183, 'Total loss': 0.47483666187092183}
2022-11-28 05:01:11,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:11,620 INFO:     Epoch: 56
2022-11-28 05:01:12,295 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4934654862365939, 'Total loss': 0.4934654862365939} | train loss {'Reaction outcome loss': 0.4608773628189679, 'Total loss': 0.4608773628189679}
2022-11-28 05:01:12,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:12,295 INFO:     Epoch: 57
2022-11-28 05:01:12,971 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.501797541975975, 'Total loss': 0.501797541975975} | train loss {'Reaction outcome loss': 0.4642850523514132, 'Total loss': 0.4642850523514132}
2022-11-28 05:01:12,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:12,971 INFO:     Epoch: 58
2022-11-28 05:01:13,645 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4903681088577617, 'Total loss': 0.4903681088577617} | train loss {'Reaction outcome loss': 0.45942687555666895, 'Total loss': 0.45942687555666895}
2022-11-28 05:01:13,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:13,646 INFO:     Epoch: 59
2022-11-28 05:01:14,321 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4706980386240916, 'Total loss': 0.4706980386240916} | train loss {'Reaction outcome loss': 0.46242319654312825, 'Total loss': 0.46242319654312825}
2022-11-28 05:01:14,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:14,321 INFO:     Epoch: 60
2022-11-28 05:01:14,995 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4763697148724036, 'Total loss': 0.4763697148724036} | train loss {'Reaction outcome loss': 0.46803294215351343, 'Total loss': 0.46803294215351343}
2022-11-28 05:01:14,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:14,996 INFO:     Epoch: 61
2022-11-28 05:01:15,668 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4478829702870412, 'Total loss': 0.4478829702870412} | train loss {'Reaction outcome loss': 0.46774535445917037, 'Total loss': 0.46774535445917037}
2022-11-28 05:01:15,668 INFO:     Found new best model at epoch 61
2022-11-28 05:01:15,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:15,669 INFO:     Epoch: 62
2022-11-28 05:01:16,341 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46549478647383774, 'Total loss': 0.46549478647383774} | train loss {'Reaction outcome loss': 0.46983192055936784, 'Total loss': 0.46983192055936784}
2022-11-28 05:01:16,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:16,341 INFO:     Epoch: 63
2022-11-28 05:01:17,015 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4793663549829613, 'Total loss': 0.4793663549829613} | train loss {'Reaction outcome loss': 0.46343764987203384, 'Total loss': 0.46343764987203384}
2022-11-28 05:01:17,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:17,015 INFO:     Epoch: 64
2022-11-28 05:01:17,691 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4552145818756385, 'Total loss': 0.4552145818756385} | train loss {'Reaction outcome loss': 0.4655592914129938, 'Total loss': 0.4655592914129938}
2022-11-28 05:01:17,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:17,691 INFO:     Epoch: 65
2022-11-28 05:01:18,363 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44586867602034047, 'Total loss': 0.44586867602034047} | train loss {'Reaction outcome loss': 0.46578344510447595, 'Total loss': 0.46578344510447595}
2022-11-28 05:01:18,363 INFO:     Found new best model at epoch 65
2022-11-28 05:01:18,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:18,364 INFO:     Epoch: 66
2022-11-28 05:01:19,034 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5366653393615376, 'Total loss': 0.5366653393615376} | train loss {'Reaction outcome loss': 0.4593984946728714, 'Total loss': 0.4593984946728714}
2022-11-28 05:01:19,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:19,034 INFO:     Epoch: 67
2022-11-28 05:01:19,709 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46357775547287683, 'Total loss': 0.46357775547287683} | train loss {'Reaction outcome loss': 0.46913056315914275, 'Total loss': 0.46913056315914275}
2022-11-28 05:01:19,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:19,710 INFO:     Epoch: 68
2022-11-28 05:01:20,387 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4979699982160872, 'Total loss': 0.4979699982160872} | train loss {'Reaction outcome loss': 0.46042394983552154, 'Total loss': 0.46042394983552154}
2022-11-28 05:01:20,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:20,387 INFO:     Epoch: 69
2022-11-28 05:01:21,055 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4810326959599148, 'Total loss': 0.4810326959599148} | train loss {'Reaction outcome loss': 0.4626898193551648, 'Total loss': 0.4626898193551648}
2022-11-28 05:01:21,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:21,055 INFO:     Epoch: 70
2022-11-28 05:01:21,726 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4740479522469369, 'Total loss': 0.4740479522469369} | train loss {'Reaction outcome loss': 0.4685609016206957, 'Total loss': 0.4685609016206957}
2022-11-28 05:01:21,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:21,726 INFO:     Epoch: 71
2022-11-28 05:01:22,399 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46559140797365794, 'Total loss': 0.46559140797365794} | train loss {'Reaction outcome loss': 0.4606571307165488, 'Total loss': 0.4606571307165488}
2022-11-28 05:01:22,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:22,399 INFO:     Epoch: 72
2022-11-28 05:01:23,071 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46191694858399307, 'Total loss': 0.46191694858399307} | train loss {'Reaction outcome loss': 0.46012400904850614, 'Total loss': 0.46012400904850614}
2022-11-28 05:01:23,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:23,071 INFO:     Epoch: 73
2022-11-28 05:01:23,738 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4923590259118514, 'Total loss': 0.4923590259118514} | train loss {'Reaction outcome loss': 0.4665759595171098, 'Total loss': 0.4665759595171098}
2022-11-28 05:01:23,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:23,739 INFO:     Epoch: 74
2022-11-28 05:01:24,408 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4521314354444092, 'Total loss': 0.4521314354444092} | train loss {'Reaction outcome loss': 0.4598346336955024, 'Total loss': 0.4598346336955024}
2022-11-28 05:01:24,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:24,408 INFO:     Epoch: 75
2022-11-28 05:01:25,081 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5032629523087632, 'Total loss': 0.5032629523087632} | train loss {'Reaction outcome loss': 0.4679113892658103, 'Total loss': 0.4679113892658103}
2022-11-28 05:01:25,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:25,081 INFO:     Epoch: 76
2022-11-28 05:01:25,751 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4720652279528705, 'Total loss': 0.4720652279528705} | train loss {'Reaction outcome loss': 0.46870647569096857, 'Total loss': 0.46870647569096857}
2022-11-28 05:01:25,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:25,751 INFO:     Epoch: 77
2022-11-28 05:01:26,421 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.499956225129691, 'Total loss': 0.499956225129691} | train loss {'Reaction outcome loss': 0.4637077390666931, 'Total loss': 0.4637077390666931}
2022-11-28 05:01:26,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:26,422 INFO:     Epoch: 78
2022-11-28 05:01:27,098 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4420165368779139, 'Total loss': 0.4420165368779139} | train loss {'Reaction outcome loss': 0.46272950691561543, 'Total loss': 0.46272950691561543}
2022-11-28 05:01:27,098 INFO:     Found new best model at epoch 78
2022-11-28 05:01:27,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:27,099 INFO:     Epoch: 79
2022-11-28 05:01:27,771 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45576094260269945, 'Total loss': 0.45576094260269945} | train loss {'Reaction outcome loss': 0.4653925962986485, 'Total loss': 0.4653925962986485}
2022-11-28 05:01:27,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:27,771 INFO:     Epoch: 80
2022-11-28 05:01:28,441 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48725751347162505, 'Total loss': 0.48725751347162505} | train loss {'Reaction outcome loss': 0.4688868177904477, 'Total loss': 0.4688868177904477}
2022-11-28 05:01:28,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:28,441 INFO:     Epoch: 81
2022-11-28 05:01:29,112 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4425400664860552, 'Total loss': 0.4425400664860552} | train loss {'Reaction outcome loss': 0.46521090800243037, 'Total loss': 0.46521090800243037}
2022-11-28 05:01:29,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:29,112 INFO:     Epoch: 82
2022-11-28 05:01:29,782 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46574918451634323, 'Total loss': 0.46574918451634323} | train loss {'Reaction outcome loss': 0.46667164425936436, 'Total loss': 0.46667164425936436}
2022-11-28 05:01:29,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:29,782 INFO:     Epoch: 83
2022-11-28 05:01:30,452 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47265293245965784, 'Total loss': 0.47265293245965784} | train loss {'Reaction outcome loss': 0.4651924201677884, 'Total loss': 0.4651924201677884}
2022-11-28 05:01:30,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:30,452 INFO:     Epoch: 84
2022-11-28 05:01:31,122 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4678153913806785, 'Total loss': 0.4678153913806785} | train loss {'Reaction outcome loss': 0.465950827564924, 'Total loss': 0.465950827564924}
2022-11-28 05:01:31,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:31,122 INFO:     Epoch: 85
2022-11-28 05:01:31,789 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4711367924782363, 'Total loss': 0.4711367924782363} | train loss {'Reaction outcome loss': 0.46440082641258357, 'Total loss': 0.46440082641258357}
2022-11-28 05:01:31,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:31,789 INFO:     Epoch: 86
2022-11-28 05:01:32,457 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5096226212653246, 'Total loss': 0.5096226212653246} | train loss {'Reaction outcome loss': 0.47047417490713056, 'Total loss': 0.47047417490713056}
2022-11-28 05:01:32,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:32,458 INFO:     Epoch: 87
2022-11-28 05:01:33,128 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47794870524243876, 'Total loss': 0.47794870524243876} | train loss {'Reaction outcome loss': 0.46348029597392004, 'Total loss': 0.46348029597392004}
2022-11-28 05:01:33,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:33,128 INFO:     Epoch: 88
2022-11-28 05:01:33,798 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46494940837675874, 'Total loss': 0.46494940837675874} | train loss {'Reaction outcome loss': 0.46343969538687696, 'Total loss': 0.46343969538687696}
2022-11-28 05:01:33,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:33,798 INFO:     Epoch: 89
2022-11-28 05:01:34,468 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45211963389407506, 'Total loss': 0.45211963389407506} | train loss {'Reaction outcome loss': 0.4617321456391965, 'Total loss': 0.4617321456391965}
2022-11-28 05:01:34,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:34,468 INFO:     Epoch: 90
2022-11-28 05:01:35,144 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46523095294833183, 'Total loss': 0.46523095294833183} | train loss {'Reaction outcome loss': 0.46359372823949785, 'Total loss': 0.46359372823949785}
2022-11-28 05:01:35,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:35,145 INFO:     Epoch: 91
2022-11-28 05:01:35,818 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49533268538388336, 'Total loss': 0.49533268538388336} | train loss {'Reaction outcome loss': 0.4691485478392532, 'Total loss': 0.4691485478392532}
2022-11-28 05:01:35,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:35,818 INFO:     Epoch: 92
2022-11-28 05:01:36,492 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4675142751498656, 'Total loss': 0.4675142751498656} | train loss {'Reaction outcome loss': 0.46186371634323753, 'Total loss': 0.46186371634323753}
2022-11-28 05:01:36,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:36,492 INFO:     Epoch: 93
2022-11-28 05:01:37,162 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4831586999988014, 'Total loss': 0.4831586999988014} | train loss {'Reaction outcome loss': 0.4726176802669802, 'Total loss': 0.4726176802669802}
2022-11-28 05:01:37,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:37,162 INFO:     Epoch: 94
2022-11-28 05:01:37,834 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5198879926042124, 'Total loss': 0.5198879926042124} | train loss {'Reaction outcome loss': 0.4651534612020177, 'Total loss': 0.4651534612020177}
2022-11-28 05:01:37,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:37,834 INFO:     Epoch: 95
2022-11-28 05:01:38,508 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47047257728197356, 'Total loss': 0.47047257728197356} | train loss {'Reaction outcome loss': 0.4715772895442863, 'Total loss': 0.4715772895442863}
2022-11-28 05:01:38,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:38,508 INFO:     Epoch: 96
2022-11-28 05:01:39,179 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4858968183398247, 'Total loss': 0.4858968183398247} | train loss {'Reaction outcome loss': 0.4535295787537771, 'Total loss': 0.4535295787537771}
2022-11-28 05:01:39,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:39,180 INFO:     Epoch: 97
2022-11-28 05:01:39,851 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.435955732722174, 'Total loss': 0.435955732722174} | train loss {'Reaction outcome loss': 0.4653813550549169, 'Total loss': 0.4653813550549169}
2022-11-28 05:01:39,851 INFO:     Found new best model at epoch 97
2022-11-28 05:01:39,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:39,852 INFO:     Epoch: 98
2022-11-28 05:01:40,521 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5065578926693309, 'Total loss': 0.5065578926693309} | train loss {'Reaction outcome loss': 0.46081119775772095, 'Total loss': 0.46081119775772095}
2022-11-28 05:01:40,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:40,521 INFO:     Epoch: 99
2022-11-28 05:01:41,191 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45683169297196646, 'Total loss': 0.45683169297196646} | train loss {'Reaction outcome loss': 0.47872497637065187, 'Total loss': 0.47872497637065187}
2022-11-28 05:01:41,191 INFO:     Best model found after epoch 98 of 100.
2022-11-28 05:01:41,192 INFO:   Done with stage: TRAINING
2022-11-28 05:01:41,192 INFO:   Starting stage: EVALUATION
2022-11-28 05:01:41,303 INFO:   Done with stage: EVALUATION
2022-11-28 05:01:41,304 INFO:   Leaving out SEQ value Fold_6
2022-11-28 05:01:41,316 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 05:01:41,316 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:01:41,961 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:01:41,961 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:01:42,031 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:01:42,031 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:01:42,031 INFO:     No hyperparam tuning for this model
2022-11-28 05:01:42,031 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:01:42,031 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:01:42,032 INFO:     None feature selector for col prot
2022-11-28 05:01:42,032 INFO:     None feature selector for col prot
2022-11-28 05:01:42,032 INFO:     None feature selector for col prot
2022-11-28 05:01:42,033 INFO:     None feature selector for col chem
2022-11-28 05:01:42,033 INFO:     None feature selector for col chem
2022-11-28 05:01:42,033 INFO:     None feature selector for col chem
2022-11-28 05:01:42,033 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:01:42,033 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:01:42,035 INFO:     Number of params in model 169651
2022-11-28 05:01:42,038 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:01:42,038 INFO:   Starting stage: TRAINING
2022-11-28 05:01:42,089 INFO:     Val loss before train {'Reaction outcome loss': 0.997610795226964, 'Total loss': 0.997610795226964}
2022-11-28 05:01:42,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:42,090 INFO:     Epoch: 0
2022-11-28 05:01:42,754 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5837303281507709, 'Total loss': 0.5837303281507709} | train loss {'Reaction outcome loss': 0.6857607009459515, 'Total loss': 0.6857607009459515}
2022-11-28 05:01:42,754 INFO:     Found new best model at epoch 0
2022-11-28 05:01:42,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:42,755 INFO:     Epoch: 1
2022-11-28 05:01:43,418 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5126861956986514, 'Total loss': 0.5126861956986514} | train loss {'Reaction outcome loss': 0.5860912330904785, 'Total loss': 0.5860912330904785}
2022-11-28 05:01:43,418 INFO:     Found new best model at epoch 1
2022-11-28 05:01:43,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:43,419 INFO:     Epoch: 2
2022-11-28 05:01:44,082 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5606007095087658, 'Total loss': 0.5606007095087658} | train loss {'Reaction outcome loss': 0.5589678690141561, 'Total loss': 0.5589678690141561}
2022-11-28 05:01:44,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:44,082 INFO:     Epoch: 3
2022-11-28 05:01:44,744 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5023751329969276, 'Total loss': 0.5023751329969276} | train loss {'Reaction outcome loss': 0.5338946038971142, 'Total loss': 0.5338946038971142}
2022-11-28 05:01:44,745 INFO:     Found new best model at epoch 3
2022-11-28 05:01:44,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:44,746 INFO:     Epoch: 4
2022-11-28 05:01:45,410 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4602211944081567, 'Total loss': 0.4602211944081567} | train loss {'Reaction outcome loss': 0.5272101267868159, 'Total loss': 0.5272101267868159}
2022-11-28 05:01:45,410 INFO:     Found new best model at epoch 4
2022-11-28 05:01:45,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:45,411 INFO:     Epoch: 5
2022-11-28 05:01:46,088 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4780377129262144, 'Total loss': 0.4780377129262144} | train loss {'Reaction outcome loss': 0.5128919398298069, 'Total loss': 0.5128919398298069}
2022-11-28 05:01:46,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:46,088 INFO:     Epoch: 6
2022-11-28 05:01:46,750 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4801967096599666, 'Total loss': 0.4801967096599666} | train loss {'Reaction outcome loss': 0.5049334532144119, 'Total loss': 0.5049334532144119}
2022-11-28 05:01:46,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:46,751 INFO:     Epoch: 7
2022-11-28 05:01:47,413 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4763033945452083, 'Total loss': 0.4763033945452083} | train loss {'Reaction outcome loss': 0.49481877045972006, 'Total loss': 0.49481877045972006}
2022-11-28 05:01:47,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:47,414 INFO:     Epoch: 8
2022-11-28 05:01:48,075 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4432346099479632, 'Total loss': 0.4432346099479632} | train loss {'Reaction outcome loss': 0.4980033735535583, 'Total loss': 0.4980033735535583}
2022-11-28 05:01:48,075 INFO:     Found new best model at epoch 8
2022-11-28 05:01:48,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:48,076 INFO:     Epoch: 9
2022-11-28 05:01:48,740 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46916114674373105, 'Total loss': 0.46916114674373105} | train loss {'Reaction outcome loss': 0.49118623842998427, 'Total loss': 0.49118623842998427}
2022-11-28 05:01:48,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:48,741 INFO:     Epoch: 10
2022-11-28 05:01:49,407 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4673839028586041, 'Total loss': 0.4673839028586041} | train loss {'Reaction outcome loss': 0.48622167000965194, 'Total loss': 0.48622167000965194}
2022-11-28 05:01:49,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:49,407 INFO:     Epoch: 11
2022-11-28 05:01:50,067 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.489080546931787, 'Total loss': 0.489080546931787} | train loss {'Reaction outcome loss': 0.4845908416777241, 'Total loss': 0.4845908416777241}
2022-11-28 05:01:50,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:50,067 INFO:     Epoch: 12
2022-11-28 05:01:50,730 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4824105697599324, 'Total loss': 0.4824105697599324} | train loss {'Reaction outcome loss': 0.47997282849890843, 'Total loss': 0.47997282849890843}
2022-11-28 05:01:50,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:50,730 INFO:     Epoch: 13
2022-11-28 05:01:51,395 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4613579498095946, 'Total loss': 0.4613579498095946} | train loss {'Reaction outcome loss': 0.48357463728408423, 'Total loss': 0.48357463728408423}
2022-11-28 05:01:51,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:51,395 INFO:     Epoch: 14
2022-11-28 05:01:52,057 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4604249711741101, 'Total loss': 0.4604249711741101} | train loss {'Reaction outcome loss': 0.47452992608352584, 'Total loss': 0.47452992608352584}
2022-11-28 05:01:52,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:52,057 INFO:     Epoch: 15
2022-11-28 05:01:52,720 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4481987844813954, 'Total loss': 0.4481987844813954} | train loss {'Reaction outcome loss': 0.4838633116410703, 'Total loss': 0.4838633116410703}
2022-11-28 05:01:52,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:52,720 INFO:     Epoch: 16
2022-11-28 05:01:53,382 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43804819136857986, 'Total loss': 0.43804819136857986} | train loss {'Reaction outcome loss': 0.47867972729157426, 'Total loss': 0.47867972729157426}
2022-11-28 05:01:53,382 INFO:     Found new best model at epoch 16
2022-11-28 05:01:53,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:53,383 INFO:     Epoch: 17
2022-11-28 05:01:54,047 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44891867955977266, 'Total loss': 0.44891867955977266} | train loss {'Reaction outcome loss': 0.47419278867998904, 'Total loss': 0.47419278867998904}
2022-11-28 05:01:54,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:54,047 INFO:     Epoch: 18
2022-11-28 05:01:54,712 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44684314321387897, 'Total loss': 0.44684314321387897} | train loss {'Reaction outcome loss': 0.4764006164000959, 'Total loss': 0.4764006164000959}
2022-11-28 05:01:54,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:54,712 INFO:     Epoch: 19
2022-11-28 05:01:55,373 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4607975638725541, 'Total loss': 0.4607975638725541} | train loss {'Reaction outcome loss': 0.469731098960857, 'Total loss': 0.469731098960857}
2022-11-28 05:01:55,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:55,373 INFO:     Epoch: 20
2022-11-28 05:01:56,035 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4627403908155181, 'Total loss': 0.4627403908155181} | train loss {'Reaction outcome loss': 0.4707316064104742, 'Total loss': 0.4707316064104742}
2022-11-28 05:01:56,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:56,035 INFO:     Epoch: 21
2022-11-28 05:01:56,695 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4350081597539512, 'Total loss': 0.4350081597539512} | train loss {'Reaction outcome loss': 0.47421308713299887, 'Total loss': 0.47421308713299887}
2022-11-28 05:01:56,695 INFO:     Found new best model at epoch 21
2022-11-28 05:01:56,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:56,696 INFO:     Epoch: 22
2022-11-28 05:01:57,360 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4759218686006286, 'Total loss': 0.4759218686006286} | train loss {'Reaction outcome loss': 0.4698583999458624, 'Total loss': 0.4698583999458624}
2022-11-28 05:01:57,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:57,360 INFO:     Epoch: 23
2022-11-28 05:01:58,022 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4353058785200119, 'Total loss': 0.4353058785200119} | train loss {'Reaction outcome loss': 0.46964772294978707, 'Total loss': 0.46964772294978707}
2022-11-28 05:01:58,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:58,024 INFO:     Epoch: 24
2022-11-28 05:01:58,684 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45549305934797635, 'Total loss': 0.45549305934797635} | train loss {'Reaction outcome loss': 0.46845899400662405, 'Total loss': 0.46845899400662405}
2022-11-28 05:01:58,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:58,684 INFO:     Epoch: 25
2022-11-28 05:01:59,347 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4724666682833975, 'Total loss': 0.4724666682833975} | train loss {'Reaction outcome loss': 0.46166568666088337, 'Total loss': 0.46166568666088337}
2022-11-28 05:01:59,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:01:59,348 INFO:     Epoch: 26
2022-11-28 05:02:00,008 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4401888624680313, 'Total loss': 0.4401888624680313} | train loss {'Reaction outcome loss': 0.4658031129715394, 'Total loss': 0.4658031129715394}
2022-11-28 05:02:00,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:00,008 INFO:     Epoch: 27
2022-11-28 05:02:00,668 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49927622215314343, 'Total loss': 0.49927622215314343} | train loss {'Reaction outcome loss': 0.46591476907535473, 'Total loss': 0.46591476907535473}
2022-11-28 05:02:00,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:00,669 INFO:     Epoch: 28
2022-11-28 05:02:01,331 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4474292133342136, 'Total loss': 0.4474292133342136} | train loss {'Reaction outcome loss': 0.46571778150237336, 'Total loss': 0.46571778150237336}
2022-11-28 05:02:01,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:01,331 INFO:     Epoch: 29
2022-11-28 05:02:01,995 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44264074753631244, 'Total loss': 0.44264074753631244} | train loss {'Reaction outcome loss': 0.4670011469904257, 'Total loss': 0.4670011469904257}
2022-11-28 05:02:01,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:01,995 INFO:     Epoch: 30
2022-11-28 05:02:02,653 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4611698328094049, 'Total loss': 0.4611698328094049} | train loss {'Reaction outcome loss': 0.46776017437175826, 'Total loss': 0.46776017437175826}
2022-11-28 05:02:02,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:02,654 INFO:     Epoch: 31
2022-11-28 05:02:03,312 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5041722303087061, 'Total loss': 0.5041722303087061} | train loss {'Reaction outcome loss': 0.46699126758137527, 'Total loss': 0.46699126758137527}
2022-11-28 05:02:03,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:03,312 INFO:     Epoch: 32
2022-11-28 05:02:03,976 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44536401907151396, 'Total loss': 0.44536401907151396} | train loss {'Reaction outcome loss': 0.4622635360274996, 'Total loss': 0.4622635360274996}
2022-11-28 05:02:03,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:03,976 INFO:     Epoch: 33
2022-11-28 05:02:04,640 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4240893116220832, 'Total loss': 0.4240893116220832} | train loss {'Reaction outcome loss': 0.45576857632520246, 'Total loss': 0.45576857632520246}
2022-11-28 05:02:04,641 INFO:     Found new best model at epoch 33
2022-11-28 05:02:04,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:04,641 INFO:     Epoch: 34
2022-11-28 05:02:05,305 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.474517052823847, 'Total loss': 0.474517052823847} | train loss {'Reaction outcome loss': 0.4622658336649136, 'Total loss': 0.4622658336649136}
2022-11-28 05:02:05,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:05,305 INFO:     Epoch: 35
2022-11-28 05:02:05,966 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4304779986427589, 'Total loss': 0.4304779986427589} | train loss {'Reaction outcome loss': 0.4584719070366451, 'Total loss': 0.4584719070366451}
2022-11-28 05:02:05,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:05,966 INFO:     Epoch: 36
2022-11-28 05:02:06,627 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42363737066361035, 'Total loss': 0.42363737066361035} | train loss {'Reaction outcome loss': 0.46504210556040004, 'Total loss': 0.46504210556040004}
2022-11-28 05:02:06,627 INFO:     Found new best model at epoch 36
2022-11-28 05:02:06,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:06,628 INFO:     Epoch: 37
2022-11-28 05:02:07,292 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4270768284120343, 'Total loss': 0.4270768284120343} | train loss {'Reaction outcome loss': 0.46911974713510396, 'Total loss': 0.46911974713510396}
2022-11-28 05:02:07,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:07,292 INFO:     Epoch: 38
2022-11-28 05:02:07,954 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5030762519348752, 'Total loss': 0.5030762519348752} | train loss {'Reaction outcome loss': 0.462865745352239, 'Total loss': 0.462865745352239}
2022-11-28 05:02:07,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:07,954 INFO:     Epoch: 39
2022-11-28 05:02:08,613 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4404529382220723, 'Total loss': 0.4404529382220723} | train loss {'Reaction outcome loss': 0.4568164518293069, 'Total loss': 0.4568164518293069}
2022-11-28 05:02:08,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:08,613 INFO:     Epoch: 40
2022-11-28 05:02:09,273 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47329714047637855, 'Total loss': 0.47329714047637855} | train loss {'Reaction outcome loss': 0.4571274920993922, 'Total loss': 0.4571274920993922}
2022-11-28 05:02:09,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:09,273 INFO:     Epoch: 41
2022-11-28 05:02:09,931 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4448411319066178, 'Total loss': 0.4448411319066178} | train loss {'Reaction outcome loss': 0.4721341518115024, 'Total loss': 0.4721341518115024}
2022-11-28 05:02:09,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:09,931 INFO:     Epoch: 42
2022-11-28 05:02:10,590 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4457423155280677, 'Total loss': 0.4457423155280677} | train loss {'Reaction outcome loss': 0.4655463641395374, 'Total loss': 0.4655463641395374}
2022-11-28 05:02:10,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:10,591 INFO:     Epoch: 43
2022-11-28 05:02:11,253 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4467544762248343, 'Total loss': 0.4467544762248343} | train loss {'Reaction outcome loss': 0.4597873737617415, 'Total loss': 0.4597873737617415}
2022-11-28 05:02:11,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:11,253 INFO:     Epoch: 44
2022-11-28 05:02:11,915 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43003263663161884, 'Total loss': 0.43003263663161884} | train loss {'Reaction outcome loss': 0.4636388832817272, 'Total loss': 0.4636388832817272}
2022-11-28 05:02:11,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:11,915 INFO:     Epoch: 45
2022-11-28 05:02:12,576 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4370589716867967, 'Total loss': 0.4370589716867967} | train loss {'Reaction outcome loss': 0.4580930378972268, 'Total loss': 0.4580930378972268}
2022-11-28 05:02:12,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:12,576 INFO:     Epoch: 46
2022-11-28 05:02:13,237 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4343001178719781, 'Total loss': 0.4343001178719781} | train loss {'Reaction outcome loss': 0.4624955352471799, 'Total loss': 0.4624955352471799}
2022-11-28 05:02:13,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:13,237 INFO:     Epoch: 47
2022-11-28 05:02:13,898 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45007462494752626, 'Total loss': 0.45007462494752626} | train loss {'Reaction outcome loss': 0.4627035477027601, 'Total loss': 0.4627035477027601}
2022-11-28 05:02:13,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:13,899 INFO:     Epoch: 48
2022-11-28 05:02:14,559 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4286411614580588, 'Total loss': 0.4286411614580588} | train loss {'Reaction outcome loss': 0.4637510858628215, 'Total loss': 0.4637510858628215}
2022-11-28 05:02:14,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:14,559 INFO:     Epoch: 49
2022-11-28 05:02:15,214 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48002400960434566, 'Total loss': 0.48002400960434566} | train loss {'Reaction outcome loss': 0.46324936051149757, 'Total loss': 0.46324936051149757}
2022-11-28 05:02:15,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:15,214 INFO:     Epoch: 50
2022-11-28 05:02:15,873 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48577229847962206, 'Total loss': 0.48577229847962206} | train loss {'Reaction outcome loss': 0.46058305824289514, 'Total loss': 0.46058305824289514}
2022-11-28 05:02:15,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:15,873 INFO:     Epoch: 51
2022-11-28 05:02:16,536 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4573116837577386, 'Total loss': 0.4573116837577386} | train loss {'Reaction outcome loss': 0.4610108521519875, 'Total loss': 0.4610108521519875}
2022-11-28 05:02:16,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:16,536 INFO:     Epoch: 52
2022-11-28 05:02:17,194 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45706518400799145, 'Total loss': 0.45706518400799145} | train loss {'Reaction outcome loss': 0.46438651647494766, 'Total loss': 0.46438651647494766}
2022-11-28 05:02:17,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:17,195 INFO:     Epoch: 53
2022-11-28 05:02:17,852 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5051598210226406, 'Total loss': 0.5051598210226406} | train loss {'Reaction outcome loss': 0.45777454406631235, 'Total loss': 0.45777454406631235}
2022-11-28 05:02:17,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:17,853 INFO:     Epoch: 54
2022-11-28 05:02:18,512 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4356954380531203, 'Total loss': 0.4356954380531203} | train loss {'Reaction outcome loss': 0.46585851530639494, 'Total loss': 0.46585851530639494}
2022-11-28 05:02:18,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:18,512 INFO:     Epoch: 55
2022-11-28 05:02:19,172 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4759760004552928, 'Total loss': 0.4759760004552928} | train loss {'Reaction outcome loss': 0.46381578609651447, 'Total loss': 0.46381578609651447}
2022-11-28 05:02:19,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:19,172 INFO:     Epoch: 56
2022-11-28 05:02:19,831 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45783939043229277, 'Total loss': 0.45783939043229277} | train loss {'Reaction outcome loss': 0.46233181132345785, 'Total loss': 0.46233181132345785}
2022-11-28 05:02:19,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:19,831 INFO:     Epoch: 57
2022-11-28 05:02:20,492 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4765844013203274, 'Total loss': 0.4765844013203274} | train loss {'Reaction outcome loss': 0.4658770667046917, 'Total loss': 0.4658770667046917}
2022-11-28 05:02:20,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:20,493 INFO:     Epoch: 58
2022-11-28 05:02:21,153 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.451980916952545, 'Total loss': 0.451980916952545} | train loss {'Reaction outcome loss': 0.4617477539850741, 'Total loss': 0.4617477539850741}
2022-11-28 05:02:21,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:21,154 INFO:     Epoch: 59
2022-11-28 05:02:21,811 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4499577514149926, 'Total loss': 0.4499577514149926} | train loss {'Reaction outcome loss': 0.4558883858578546, 'Total loss': 0.4558883858578546}
2022-11-28 05:02:21,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:21,811 INFO:     Epoch: 60
2022-11-28 05:02:22,470 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4538203054531054, 'Total loss': 0.4538203054531054} | train loss {'Reaction outcome loss': 0.4569501919405801, 'Total loss': 0.4569501919405801}
2022-11-28 05:02:22,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:22,471 INFO:     Epoch: 61
2022-11-28 05:02:23,133 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4505438381298022, 'Total loss': 0.4505438381298022} | train loss {'Reaction outcome loss': 0.460554695555142, 'Total loss': 0.460554695555142}
2022-11-28 05:02:23,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:23,133 INFO:     Epoch: 62
2022-11-28 05:02:23,793 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4623014635660432, 'Total loss': 0.4623014635660432} | train loss {'Reaction outcome loss': 0.4548868579523904, 'Total loss': 0.4548868579523904}
2022-11-28 05:02:23,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:23,793 INFO:     Epoch: 63
2022-11-28 05:02:24,455 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4370352290570736, 'Total loss': 0.4370352290570736} | train loss {'Reaction outcome loss': 0.4665061510947286, 'Total loss': 0.4665061510947286}
2022-11-28 05:02:24,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:24,455 INFO:     Epoch: 64
2022-11-28 05:02:25,118 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43900408189405093, 'Total loss': 0.43900408189405093} | train loss {'Reaction outcome loss': 0.4544793444628618, 'Total loss': 0.4544793444628618}
2022-11-28 05:02:25,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:25,118 INFO:     Epoch: 65
2022-11-28 05:02:25,781 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42857324721460993, 'Total loss': 0.42857324721460993} | train loss {'Reaction outcome loss': 0.46279479660549944, 'Total loss': 0.46279479660549944}
2022-11-28 05:02:25,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:25,782 INFO:     Epoch: 66
2022-11-28 05:02:26,447 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4580565867098895, 'Total loss': 0.4580565867098895} | train loss {'Reaction outcome loss': 0.45229583933037154, 'Total loss': 0.45229583933037154}
2022-11-28 05:02:26,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:26,447 INFO:     Epoch: 67
2022-11-28 05:02:27,109 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45752688632770017, 'Total loss': 0.45752688632770017} | train loss {'Reaction outcome loss': 0.4562573479450479, 'Total loss': 0.4562573479450479}
2022-11-28 05:02:27,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:27,109 INFO:     Epoch: 68
2022-11-28 05:02:27,770 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4763011844320731, 'Total loss': 0.4763011844320731} | train loss {'Reaction outcome loss': 0.4592890333764407, 'Total loss': 0.4592890333764407}
2022-11-28 05:02:27,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:27,770 INFO:     Epoch: 69
2022-11-28 05:02:28,432 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4493059366941452, 'Total loss': 0.4493059366941452} | train loss {'Reaction outcome loss': 0.45861782808693086, 'Total loss': 0.45861782808693086}
2022-11-28 05:02:28,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:28,432 INFO:     Epoch: 70
2022-11-28 05:02:29,097 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45027264952659607, 'Total loss': 0.45027264952659607} | train loss {'Reaction outcome loss': 0.46243638967981143, 'Total loss': 0.46243638967981143}
2022-11-28 05:02:29,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:29,098 INFO:     Epoch: 71
2022-11-28 05:02:29,757 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4492374716157263, 'Total loss': 0.4492374716157263} | train loss {'Reaction outcome loss': 0.45568967686623946, 'Total loss': 0.45568967686623946}
2022-11-28 05:02:29,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:29,757 INFO:     Epoch: 72
2022-11-28 05:02:30,418 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46487558870152995, 'Total loss': 0.46487558870152995} | train loss {'Reaction outcome loss': 0.4584020874634081, 'Total loss': 0.4584020874634081}
2022-11-28 05:02:30,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:30,418 INFO:     Epoch: 73
2022-11-28 05:02:31,078 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43352055007761175, 'Total loss': 0.43352055007761175} | train loss {'Reaction outcome loss': 0.45846690660228534, 'Total loss': 0.45846690660228534}
2022-11-28 05:02:31,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:31,079 INFO:     Epoch: 74
2022-11-28 05:02:31,739 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4557613171637058, 'Total loss': 0.4557613171637058} | train loss {'Reaction outcome loss': 0.45536271421885005, 'Total loss': 0.45536271421885005}
2022-11-28 05:02:31,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:31,739 INFO:     Epoch: 75
2022-11-28 05:02:32,400 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46305427564816043, 'Total loss': 0.46305427564816043} | train loss {'Reaction outcome loss': 0.45980610461259375, 'Total loss': 0.45980610461259375}
2022-11-28 05:02:32,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:32,400 INFO:     Epoch: 76
2022-11-28 05:02:33,060 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4975740686058998, 'Total loss': 0.4975740686058998} | train loss {'Reaction outcome loss': 0.458935340752407, 'Total loss': 0.458935340752407}
2022-11-28 05:02:33,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:33,061 INFO:     Epoch: 77
2022-11-28 05:02:33,722 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42871224152093584, 'Total loss': 0.42871224152093584} | train loss {'Reaction outcome loss': 0.46281464294511443, 'Total loss': 0.46281464294511443}
2022-11-28 05:02:33,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:33,722 INFO:     Epoch: 78
2022-11-28 05:02:34,378 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43893836032260547, 'Total loss': 0.43893836032260547} | train loss {'Reaction outcome loss': 0.46039408749463606, 'Total loss': 0.46039408749463606}
2022-11-28 05:02:34,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:34,379 INFO:     Epoch: 79
2022-11-28 05:02:35,041 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44778436151417816, 'Total loss': 0.44778436151417816} | train loss {'Reaction outcome loss': 0.4525077630366598, 'Total loss': 0.4525077630366598}
2022-11-28 05:02:35,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:35,042 INFO:     Epoch: 80
2022-11-28 05:02:35,708 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46579813821749255, 'Total loss': 0.46579813821749255} | train loss {'Reaction outcome loss': 0.4718365174775221, 'Total loss': 0.4718365174775221}
2022-11-28 05:02:35,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:35,709 INFO:     Epoch: 81
2022-11-28 05:02:36,371 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4767711961811239, 'Total loss': 0.4767711961811239} | train loss {'Reaction outcome loss': 0.46062327221948274, 'Total loss': 0.46062327221948274}
2022-11-28 05:02:36,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:36,371 INFO:     Epoch: 82
2022-11-28 05:02:37,032 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4757717573507266, 'Total loss': 0.4757717573507266} | train loss {'Reaction outcome loss': 0.4599956517316857, 'Total loss': 0.4599956517316857}
2022-11-28 05:02:37,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:37,033 INFO:     Epoch: 83
2022-11-28 05:02:37,694 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4663591598245231, 'Total loss': 0.4663591598245231} | train loss {'Reaction outcome loss': 0.46305688747337886, 'Total loss': 0.46305688747337886}
2022-11-28 05:02:37,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:37,695 INFO:     Epoch: 84
2022-11-28 05:02:38,354 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4907005988061428, 'Total loss': 0.4907005988061428} | train loss {'Reaction outcome loss': 0.4570482398782458, 'Total loss': 0.4570482398782458}
2022-11-28 05:02:38,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:38,354 INFO:     Epoch: 85
2022-11-28 05:02:39,012 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43825760917653417, 'Total loss': 0.43825760917653417} | train loss {'Reaction outcome loss': 0.4614803221760964, 'Total loss': 0.4614803221760964}
2022-11-28 05:02:39,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:39,012 INFO:     Epoch: 86
2022-11-28 05:02:39,667 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4556118876419284, 'Total loss': 0.4556118876419284} | train loss {'Reaction outcome loss': 0.4648179441690445, 'Total loss': 0.4648179441690445}
2022-11-28 05:02:39,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:39,667 INFO:     Epoch: 87
2022-11-28 05:02:40,324 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44488166966898873, 'Total loss': 0.44488166966898873} | train loss {'Reaction outcome loss': 0.4642599121648438, 'Total loss': 0.4642599121648438}
2022-11-28 05:02:40,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:40,325 INFO:     Epoch: 88
2022-11-28 05:02:40,977 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4646446013992483, 'Total loss': 0.4646446013992483} | train loss {'Reaction outcome loss': 0.4632825562540366, 'Total loss': 0.4632825562540366}
2022-11-28 05:02:40,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:40,977 INFO:     Epoch: 89
2022-11-28 05:02:41,629 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4262556474317204, 'Total loss': 0.4262556474317204} | train loss {'Reaction outcome loss': 0.4670158233873698, 'Total loss': 0.4670158233873698}
2022-11-28 05:02:41,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:41,629 INFO:     Epoch: 90
2022-11-28 05:02:42,290 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44677277959205886, 'Total loss': 0.44677277959205886} | train loss {'Reaction outcome loss': 0.4569093428095993, 'Total loss': 0.4569093428095993}
2022-11-28 05:02:42,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:42,290 INFO:     Epoch: 91
2022-11-28 05:02:42,946 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44880043833770533, 'Total loss': 0.44880043833770533} | train loss {'Reaction outcome loss': 0.45640430620738437, 'Total loss': 0.45640430620738437}
2022-11-28 05:02:42,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:42,946 INFO:     Epoch: 92
2022-11-28 05:02:43,603 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5226048220964995, 'Total loss': 0.5226048220964995} | train loss {'Reaction outcome loss': 0.4593156394909839, 'Total loss': 0.4593156394909839}
2022-11-28 05:02:43,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:43,604 INFO:     Epoch: 93
2022-11-28 05:02:44,260 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4838710037822073, 'Total loss': 0.4838710037822073} | train loss {'Reaction outcome loss': 0.4652146612503091, 'Total loss': 0.4652146612503091}
2022-11-28 05:02:44,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:44,260 INFO:     Epoch: 94
2022-11-28 05:02:44,915 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.438563772900538, 'Total loss': 0.438563772900538} | train loss {'Reaction outcome loss': 0.461114696093968, 'Total loss': 0.461114696093968}
2022-11-28 05:02:44,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:44,915 INFO:     Epoch: 95
2022-11-28 05:02:45,569 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4207891703329303, 'Total loss': 0.4207891703329303} | train loss {'Reaction outcome loss': 0.4626810624891398, 'Total loss': 0.4626810624891398}
2022-11-28 05:02:45,569 INFO:     Found new best model at epoch 95
2022-11-28 05:02:45,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:45,570 INFO:     Epoch: 96
2022-11-28 05:02:46,225 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4683235111561688, 'Total loss': 0.4683235111561688} | train loss {'Reaction outcome loss': 0.46524325150008106, 'Total loss': 0.46524325150008106}
2022-11-28 05:02:46,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:46,225 INFO:     Epoch: 97
2022-11-28 05:02:46,885 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45496933737939055, 'Total loss': 0.45496933737939055} | train loss {'Reaction outcome loss': 0.45838335570023986, 'Total loss': 0.45838335570023986}
2022-11-28 05:02:46,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:46,886 INFO:     Epoch: 98
2022-11-28 05:02:47,549 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4688322141089223, 'Total loss': 0.4688322141089223} | train loss {'Reaction outcome loss': 0.46194737000124797, 'Total loss': 0.46194737000124797}
2022-11-28 05:02:47,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:47,549 INFO:     Epoch: 99
2022-11-28 05:02:48,211 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4519300948489796, 'Total loss': 0.4519300948489796} | train loss {'Reaction outcome loss': 0.454182379525535, 'Total loss': 0.454182379525535}
2022-11-28 05:02:48,212 INFO:     Best model found after epoch 96 of 100.
2022-11-28 05:02:48,212 INFO:   Done with stage: TRAINING
2022-11-28 05:02:48,212 INFO:   Starting stage: EVALUATION
2022-11-28 05:02:48,335 INFO:   Done with stage: EVALUATION
2022-11-28 05:02:48,335 INFO:   Leaving out SEQ value Fold_7
2022-11-28 05:02:48,348 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 05:02:48,348 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:02:49,007 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:02:49,007 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:02:49,077 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:02:49,077 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:02:49,077 INFO:     No hyperparam tuning for this model
2022-11-28 05:02:49,077 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:02:49,077 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:02:49,078 INFO:     None feature selector for col prot
2022-11-28 05:02:49,078 INFO:     None feature selector for col prot
2022-11-28 05:02:49,078 INFO:     None feature selector for col prot
2022-11-28 05:02:49,078 INFO:     None feature selector for col chem
2022-11-28 05:02:49,078 INFO:     None feature selector for col chem
2022-11-28 05:02:49,078 INFO:     None feature selector for col chem
2022-11-28 05:02:49,079 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:02:49,079 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:02:49,080 INFO:     Number of params in model 169651
2022-11-28 05:02:49,083 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:02:49,083 INFO:   Starting stage: TRAINING
2022-11-28 05:02:49,134 INFO:     Val loss before train {'Reaction outcome loss': 1.052966219457713, 'Total loss': 1.052966219457713}
2022-11-28 05:02:49,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:49,134 INFO:     Epoch: 0
2022-11-28 05:02:49,798 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6288212436166677, 'Total loss': 0.6288212436166677} | train loss {'Reaction outcome loss': 0.6795651814159082, 'Total loss': 0.6795651814159082}
2022-11-28 05:02:49,799 INFO:     Found new best model at epoch 0
2022-11-28 05:02:49,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:49,799 INFO:     Epoch: 1
2022-11-28 05:02:50,461 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5674893392927267, 'Total loss': 0.5674893392927267} | train loss {'Reaction outcome loss': 0.5863149939751139, 'Total loss': 0.5863149939751139}
2022-11-28 05:02:50,462 INFO:     Found new best model at epoch 1
2022-11-28 05:02:50,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:50,462 INFO:     Epoch: 2
2022-11-28 05:02:51,124 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5780179771510038, 'Total loss': 0.5780179771510038} | train loss {'Reaction outcome loss': 0.5548640044976254, 'Total loss': 0.5548640044976254}
2022-11-28 05:02:51,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:51,124 INFO:     Epoch: 3
2022-11-28 05:02:51,786 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5270168760960753, 'Total loss': 0.5270168760960753} | train loss {'Reaction outcome loss': 0.5194732374074508, 'Total loss': 0.5194732374074508}
2022-11-28 05:02:51,786 INFO:     Found new best model at epoch 3
2022-11-28 05:02:51,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:51,787 INFO:     Epoch: 4
2022-11-28 05:02:52,450 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5372220697728071, 'Total loss': 0.5372220697728071} | train loss {'Reaction outcome loss': 0.5185833625647487, 'Total loss': 0.5185833625647487}
2022-11-28 05:02:52,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:52,451 INFO:     Epoch: 5
2022-11-28 05:02:53,111 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5042151642793958, 'Total loss': 0.5042151642793958} | train loss {'Reaction outcome loss': 0.5032598395128639, 'Total loss': 0.5032598395128639}
2022-11-28 05:02:53,111 INFO:     Found new best model at epoch 5
2022-11-28 05:02:53,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:53,112 INFO:     Epoch: 6
2022-11-28 05:02:53,775 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5914905453947458, 'Total loss': 0.5914905453947458} | train loss {'Reaction outcome loss': 0.5074897073361339, 'Total loss': 0.5074897073361339}
2022-11-28 05:02:53,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:53,775 INFO:     Epoch: 7
2022-11-28 05:02:54,436 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5104542503302748, 'Total loss': 0.5104542503302748} | train loss {'Reaction outcome loss': 0.4980268500897349, 'Total loss': 0.4980268500897349}
2022-11-28 05:02:54,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:54,436 INFO:     Epoch: 8
2022-11-28 05:02:55,098 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5450998598879034, 'Total loss': 0.5450998598879034} | train loss {'Reaction outcome loss': 0.490066426171332, 'Total loss': 0.490066426171332}
2022-11-28 05:02:55,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:55,098 INFO:     Epoch: 9
2022-11-28 05:02:55,764 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5090948908843778, 'Total loss': 0.5090948908843778} | train loss {'Reaction outcome loss': 0.482198697815136, 'Total loss': 0.482198697815136}
2022-11-28 05:02:55,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:55,764 INFO:     Epoch: 10
2022-11-28 05:02:56,428 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5231271870434284, 'Total loss': 0.5231271870434284} | train loss {'Reaction outcome loss': 0.47921089101202635, 'Total loss': 0.47921089101202635}
2022-11-28 05:02:56,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:56,429 INFO:     Epoch: 11
2022-11-28 05:02:57,090 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5106474110348658, 'Total loss': 0.5106474110348658} | train loss {'Reaction outcome loss': 0.48668102159792065, 'Total loss': 0.48668102159792065}
2022-11-28 05:02:57,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:57,090 INFO:     Epoch: 12
2022-11-28 05:02:57,752 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49215357208793814, 'Total loss': 0.49215357208793814} | train loss {'Reaction outcome loss': 0.4652593353573157, 'Total loss': 0.4652593353573157}
2022-11-28 05:02:57,752 INFO:     Found new best model at epoch 12
2022-11-28 05:02:57,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:57,753 INFO:     Epoch: 13
2022-11-28 05:02:58,414 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5011993462050502, 'Total loss': 0.5011993462050502} | train loss {'Reaction outcome loss': 0.4790274500846863, 'Total loss': 0.4790274500846863}
2022-11-28 05:02:58,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:58,414 INFO:     Epoch: 14
2022-11-28 05:02:59,074 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5072929087010297, 'Total loss': 0.5072929087010297} | train loss {'Reaction outcome loss': 0.4810719351379239, 'Total loss': 0.4810719351379239}
2022-11-28 05:02:59,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:59,074 INFO:     Epoch: 15
2022-11-28 05:02:59,734 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5346729098395868, 'Total loss': 0.5346729098395868} | train loss {'Reaction outcome loss': 0.4774997035459596, 'Total loss': 0.4774997035459596}
2022-11-28 05:02:59,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:02:59,735 INFO:     Epoch: 16
2022-11-28 05:03:00,398 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5058191980827939, 'Total loss': 0.5058191980827939} | train loss {'Reaction outcome loss': 0.47147240200821233, 'Total loss': 0.47147240200821233}
2022-11-28 05:03:00,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:00,398 INFO:     Epoch: 17
2022-11-28 05:03:01,060 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5174596126783978, 'Total loss': 0.5174596126783978} | train loss {'Reaction outcome loss': 0.4722632229936366, 'Total loss': 0.4722632229936366}
2022-11-28 05:03:01,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:01,060 INFO:     Epoch: 18
2022-11-28 05:03:01,724 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48937754637815734, 'Total loss': 0.48937754637815734} | train loss {'Reaction outcome loss': 0.4745715137647123, 'Total loss': 0.4745715137647123}
2022-11-28 05:03:01,724 INFO:     Found new best model at epoch 18
2022-11-28 05:03:01,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:01,725 INFO:     Epoch: 19
2022-11-28 05:03:02,389 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5279206931591034, 'Total loss': 0.5279206931591034} | train loss {'Reaction outcome loss': 0.47043944323549464, 'Total loss': 0.47043944323549464}
2022-11-28 05:03:02,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:02,389 INFO:     Epoch: 20
2022-11-28 05:03:03,046 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5099814986302094, 'Total loss': 0.5099814986302094} | train loss {'Reaction outcome loss': 0.4741055325585969, 'Total loss': 0.4741055325585969}
2022-11-28 05:03:03,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:03,047 INFO:     Epoch: 21
2022-11-28 05:03:03,705 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49220669879154727, 'Total loss': 0.49220669879154727} | train loss {'Reaction outcome loss': 0.4663855309997286, 'Total loss': 0.4663855309997286}
2022-11-28 05:03:03,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:03,705 INFO:     Epoch: 22
2022-11-28 05:03:04,363 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49340025267817755, 'Total loss': 0.49340025267817755} | train loss {'Reaction outcome loss': 0.4597312036825686, 'Total loss': 0.4597312036825686}
2022-11-28 05:03:04,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:04,363 INFO:     Epoch: 23
2022-11-28 05:03:05,021 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5154407518831167, 'Total loss': 0.5154407518831167} | train loss {'Reaction outcome loss': 0.46995157715009184, 'Total loss': 0.46995157715009184}
2022-11-28 05:03:05,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:05,021 INFO:     Epoch: 24
2022-11-28 05:03:05,680 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5162016641009938, 'Total loss': 0.5162016641009938} | train loss {'Reaction outcome loss': 0.47465653802667346, 'Total loss': 0.47465653802667346}
2022-11-28 05:03:05,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:05,680 INFO:     Epoch: 25
2022-11-28 05:03:06,342 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5131605386056683, 'Total loss': 0.5131605386056683} | train loss {'Reaction outcome loss': 0.4736924332623579, 'Total loss': 0.4736924332623579}
2022-11-28 05:03:06,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:06,343 INFO:     Epoch: 26
2022-11-28 05:03:07,006 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4994462457570163, 'Total loss': 0.4994462457570163} | train loss {'Reaction outcome loss': 0.46955324405310106, 'Total loss': 0.46955324405310106}
2022-11-28 05:03:07,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:07,006 INFO:     Epoch: 27
2022-11-28 05:03:07,670 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5052187246355143, 'Total loss': 0.5052187246355143} | train loss {'Reaction outcome loss': 0.46834085924284796, 'Total loss': 0.46834085924284796}
2022-11-28 05:03:07,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:07,670 INFO:     Epoch: 28
2022-11-28 05:03:08,331 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5258301543918523, 'Total loss': 0.5258301543918523} | train loss {'Reaction outcome loss': 0.46733789194603353, 'Total loss': 0.46733789194603353}
2022-11-28 05:03:08,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:08,331 INFO:     Epoch: 29
2022-11-28 05:03:08,994 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5207519155334343, 'Total loss': 0.5207519155334343} | train loss {'Reaction outcome loss': 0.4651732883891281, 'Total loss': 0.4651732883891281}
2022-11-28 05:03:08,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:08,995 INFO:     Epoch: 30
2022-11-28 05:03:09,654 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5119344991716471, 'Total loss': 0.5119344991716471} | train loss {'Reaction outcome loss': 0.4661414022348365, 'Total loss': 0.4661414022348365}
2022-11-28 05:03:09,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:09,654 INFO:     Epoch: 31
2022-11-28 05:03:10,314 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5112191567366774, 'Total loss': 0.5112191567366774} | train loss {'Reaction outcome loss': 0.46891335397958755, 'Total loss': 0.46891335397958755}
2022-11-28 05:03:10,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:10,314 INFO:     Epoch: 32
2022-11-28 05:03:10,974 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5252970247106119, 'Total loss': 0.5252970247106119} | train loss {'Reaction outcome loss': 0.4710931694629241, 'Total loss': 0.4710931694629241}
2022-11-28 05:03:10,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:10,975 INFO:     Epoch: 33
2022-11-28 05:03:11,634 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49409817633303726, 'Total loss': 0.49409817633303726} | train loss {'Reaction outcome loss': 0.46813202512507535, 'Total loss': 0.46813202512507535}
2022-11-28 05:03:11,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:11,635 INFO:     Epoch: 34
2022-11-28 05:03:12,290 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5406227044083856, 'Total loss': 0.5406227044083856} | train loss {'Reaction outcome loss': 0.46565084256687944, 'Total loss': 0.46565084256687944}
2022-11-28 05:03:12,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:12,290 INFO:     Epoch: 35
2022-11-28 05:03:12,951 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49925592744892294, 'Total loss': 0.49925592744892294} | train loss {'Reaction outcome loss': 0.4653745990626666, 'Total loss': 0.4653745990626666}
2022-11-28 05:03:12,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:12,951 INFO:     Epoch: 36
2022-11-28 05:03:13,612 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5087161975150759, 'Total loss': 0.5087161975150759} | train loss {'Reaction outcome loss': 0.4667821537475197, 'Total loss': 0.4667821537475197}
2022-11-28 05:03:13,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:13,612 INFO:     Epoch: 37
2022-11-28 05:03:14,269 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49237180230292404, 'Total loss': 0.49237180230292404} | train loss {'Reaction outcome loss': 0.4611810803413391, 'Total loss': 0.4611810803413391}
2022-11-28 05:03:14,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:14,270 INFO:     Epoch: 38
2022-11-28 05:03:14,927 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.509872667491436, 'Total loss': 0.509872667491436} | train loss {'Reaction outcome loss': 0.461314816043085, 'Total loss': 0.461314816043085}
2022-11-28 05:03:14,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:14,927 INFO:     Epoch: 39
2022-11-28 05:03:15,583 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5130371012809601, 'Total loss': 0.5130371012809601} | train loss {'Reaction outcome loss': 0.4654605403846624, 'Total loss': 0.4654605403846624}
2022-11-28 05:03:15,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:15,583 INFO:     Epoch: 40
2022-11-28 05:03:16,240 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5095787857743826, 'Total loss': 0.5095787857743826} | train loss {'Reaction outcome loss': 0.4681936574833734, 'Total loss': 0.4681936574833734}
2022-11-28 05:03:16,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:16,240 INFO:     Epoch: 41
2022-11-28 05:03:16,900 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5220319723541086, 'Total loss': 0.5220319723541086} | train loss {'Reaction outcome loss': 0.4641137409575131, 'Total loss': 0.4641137409575131}
2022-11-28 05:03:16,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:16,900 INFO:     Epoch: 42
2022-11-28 05:03:17,558 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5325630723752759, 'Total loss': 0.5325630723752759} | train loss {'Reaction outcome loss': 0.4650369554758072, 'Total loss': 0.4650369554758072}
2022-11-28 05:03:17,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:17,559 INFO:     Epoch: 43
2022-11-28 05:03:18,214 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5065547729080374, 'Total loss': 0.5065547729080374} | train loss {'Reaction outcome loss': 0.46591956141043683, 'Total loss': 0.46591956141043683}
2022-11-28 05:03:18,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:18,215 INFO:     Epoch: 44
2022-11-28 05:03:18,869 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5047002289105545, 'Total loss': 0.5047002289105545} | train loss {'Reaction outcome loss': 0.46079587595803395, 'Total loss': 0.46079587595803395}
2022-11-28 05:03:18,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:18,870 INFO:     Epoch: 45
2022-11-28 05:03:19,528 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4903727331283418, 'Total loss': 0.4903727331283418} | train loss {'Reaction outcome loss': 0.4659222237309631, 'Total loss': 0.4659222237309631}
2022-11-28 05:03:19,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:19,529 INFO:     Epoch: 46
2022-11-28 05:03:20,183 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5212606875733896, 'Total loss': 0.5212606875733896} | train loss {'Reaction outcome loss': 0.4678110124505296, 'Total loss': 0.4678110124505296}
2022-11-28 05:03:20,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:20,183 INFO:     Epoch: 47
2022-11-28 05:03:20,835 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.472724261270328, 'Total loss': 0.472724261270328} | train loss {'Reaction outcome loss': 0.47047123312950134, 'Total loss': 0.47047123312950134}
2022-11-28 05:03:20,835 INFO:     Found new best model at epoch 47
2022-11-28 05:03:20,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:20,836 INFO:     Epoch: 48
2022-11-28 05:03:21,492 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5052315152504228, 'Total loss': 0.5052315152504228} | train loss {'Reaction outcome loss': 0.45564501449769856, 'Total loss': 0.45564501449769856}
2022-11-28 05:03:21,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:21,492 INFO:     Epoch: 49
2022-11-28 05:03:22,148 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5118988759138368, 'Total loss': 0.5118988759138368} | train loss {'Reaction outcome loss': 0.46306851828584866, 'Total loss': 0.46306851828584866}
2022-11-28 05:03:22,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:22,148 INFO:     Epoch: 50
2022-11-28 05:03:22,803 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5651835392821919, 'Total loss': 0.5651835392821919} | train loss {'Reaction outcome loss': 0.4527898558852624, 'Total loss': 0.4527898558852624}
2022-11-28 05:03:22,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:22,803 INFO:     Epoch: 51
2022-11-28 05:03:23,457 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5275873369113966, 'Total loss': 0.5275873369113966} | train loss {'Reaction outcome loss': 0.46028796081640283, 'Total loss': 0.46028796081640283}
2022-11-28 05:03:23,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:23,457 INFO:     Epoch: 52
2022-11-28 05:03:24,112 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4910191111266613, 'Total loss': 0.4910191111266613} | train loss {'Reaction outcome loss': 0.46104399428075676, 'Total loss': 0.46104399428075676}
2022-11-28 05:03:24,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:24,112 INFO:     Epoch: 53
2022-11-28 05:03:24,768 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5390124503861774, 'Total loss': 0.5390124503861774} | train loss {'Reaction outcome loss': 0.46255790128999824, 'Total loss': 0.46255790128999824}
2022-11-28 05:03:24,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:24,768 INFO:     Epoch: 54
2022-11-28 05:03:25,425 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49872128055854276, 'Total loss': 0.49872128055854276} | train loss {'Reaction outcome loss': 0.4710097930261067, 'Total loss': 0.4710097930261067}
2022-11-28 05:03:25,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:25,425 INFO:     Epoch: 55
2022-11-28 05:03:26,083 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4925849928774617, 'Total loss': 0.4925849928774617} | train loss {'Reaction outcome loss': 0.45764390151111445, 'Total loss': 0.45764390151111445}
2022-11-28 05:03:26,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:26,083 INFO:     Epoch: 56
2022-11-28 05:03:26,742 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49505223774097185, 'Total loss': 0.49505223774097185} | train loss {'Reaction outcome loss': 0.46413892037710364, 'Total loss': 0.46413892037710364}
2022-11-28 05:03:26,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:26,743 INFO:     Epoch: 57
2022-11-28 05:03:27,400 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4771186296235431, 'Total loss': 0.4771186296235431} | train loss {'Reaction outcome loss': 0.461198652824577, 'Total loss': 0.461198652824577}
2022-11-28 05:03:27,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:27,400 INFO:     Epoch: 58
2022-11-28 05:03:28,057 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4745830531147393, 'Total loss': 0.4745830531147393} | train loss {'Reaction outcome loss': 0.4611420209310493, 'Total loss': 0.4611420209310493}
2022-11-28 05:03:28,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:28,057 INFO:     Epoch: 59
2022-11-28 05:03:28,716 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4939111623574387, 'Total loss': 0.4939111623574387} | train loss {'Reaction outcome loss': 0.4598753420978176, 'Total loss': 0.4598753420978176}
2022-11-28 05:03:28,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:28,717 INFO:     Epoch: 60
2022-11-28 05:03:29,372 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4826369932429357, 'Total loss': 0.4826369932429357} | train loss {'Reaction outcome loss': 0.4635598094487677, 'Total loss': 0.4635598094487677}
2022-11-28 05:03:29,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:29,372 INFO:     Epoch: 61
2022-11-28 05:03:30,028 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5715653408657421, 'Total loss': 0.5715653408657421} | train loss {'Reaction outcome loss': 0.4599526285516972, 'Total loss': 0.4599526285516972}
2022-11-28 05:03:30,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:30,028 INFO:     Epoch: 62
2022-11-28 05:03:30,684 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46798031065951695, 'Total loss': 0.46798031065951695} | train loss {'Reaction outcome loss': 0.4613898065017194, 'Total loss': 0.4613898065017194}
2022-11-28 05:03:30,685 INFO:     Found new best model at epoch 62
2022-11-28 05:03:30,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:30,685 INFO:     Epoch: 63
2022-11-28 05:03:31,345 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5056522210890596, 'Total loss': 0.5056522210890596} | train loss {'Reaction outcome loss': 0.46575067025058126, 'Total loss': 0.46575067025058126}
2022-11-28 05:03:31,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:31,346 INFO:     Epoch: 64
2022-11-28 05:03:32,003 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5051866542886604, 'Total loss': 0.5051866542886604} | train loss {'Reaction outcome loss': 0.4620586583200766, 'Total loss': 0.4620586583200766}
2022-11-28 05:03:32,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:32,004 INFO:     Epoch: 65
2022-11-28 05:03:32,660 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5177507075396451, 'Total loss': 0.5177507075396451} | train loss {'Reaction outcome loss': 0.45649880511420116, 'Total loss': 0.45649880511420116}
2022-11-28 05:03:32,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:32,660 INFO:     Epoch: 66
2022-11-28 05:03:33,315 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4887586842206391, 'Total loss': 0.4887586842206391} | train loss {'Reaction outcome loss': 0.4577983913372974, 'Total loss': 0.4577983913372974}
2022-11-28 05:03:33,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:33,316 INFO:     Epoch: 67
2022-11-28 05:03:33,970 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49055338447744196, 'Total loss': 0.49055338447744196} | train loss {'Reaction outcome loss': 0.4663515527941743, 'Total loss': 0.4663515527941743}
2022-11-28 05:03:33,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:33,971 INFO:     Epoch: 68
2022-11-28 05:03:34,627 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4806542088362304, 'Total loss': 0.4806542088362304} | train loss {'Reaction outcome loss': 0.4589135696085132, 'Total loss': 0.4589135696085132}
2022-11-28 05:03:34,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:34,628 INFO:     Epoch: 69
2022-11-28 05:03:35,289 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49678458578207274, 'Total loss': 0.49678458578207274} | train loss {'Reaction outcome loss': 0.46781214919625497, 'Total loss': 0.46781214919625497}
2022-11-28 05:03:35,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:35,289 INFO:     Epoch: 70
2022-11-28 05:03:35,948 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4894887906583873, 'Total loss': 0.4894887906583873} | train loss {'Reaction outcome loss': 0.46686085347010164, 'Total loss': 0.46686085347010164}
2022-11-28 05:03:35,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:35,948 INFO:     Epoch: 71
2022-11-28 05:03:36,610 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4986842552369291, 'Total loss': 0.4986842552369291} | train loss {'Reaction outcome loss': 0.46093779072469593, 'Total loss': 0.46093779072469593}
2022-11-28 05:03:36,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:36,611 INFO:     Epoch: 72
2022-11-28 05:03:37,264 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49963639744303445, 'Total loss': 0.49963639744303445} | train loss {'Reaction outcome loss': 0.46754093760130355, 'Total loss': 0.46754093760130355}
2022-11-28 05:03:37,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:37,265 INFO:     Epoch: 73
2022-11-28 05:03:37,923 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49752635339444334, 'Total loss': 0.49752635339444334} | train loss {'Reaction outcome loss': 0.46202683305861997, 'Total loss': 0.46202683305861997}
2022-11-28 05:03:37,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:37,924 INFO:     Epoch: 74
2022-11-28 05:03:38,581 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4982825673439286, 'Total loss': 0.4982825673439286} | train loss {'Reaction outcome loss': 0.4583766714954863, 'Total loss': 0.4583766714954863}
2022-11-28 05:03:38,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:38,581 INFO:     Epoch: 75
2022-11-28 05:03:39,236 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49308494004336273, 'Total loss': 0.49308494004336273} | train loss {'Reaction outcome loss': 0.4674786175392112, 'Total loss': 0.4674786175392112}
2022-11-28 05:03:39,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:39,236 INFO:     Epoch: 76
2022-11-28 05:03:39,892 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49375925077633426, 'Total loss': 0.49375925077633426} | train loss {'Reaction outcome loss': 0.4658054656520182, 'Total loss': 0.4658054656520182}
2022-11-28 05:03:39,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:39,892 INFO:     Epoch: 77
2022-11-28 05:03:40,548 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5021211030808362, 'Total loss': 0.5021211030808362} | train loss {'Reaction outcome loss': 0.4629770057237878, 'Total loss': 0.4629770057237878}
2022-11-28 05:03:40,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:40,548 INFO:     Epoch: 78
2022-11-28 05:03:41,209 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5242346247488802, 'Total loss': 0.5242346247488802} | train loss {'Reaction outcome loss': 0.4613439687052552, 'Total loss': 0.4613439687052552}
2022-11-28 05:03:41,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:41,210 INFO:     Epoch: 79
2022-11-28 05:03:41,866 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4893314012072303, 'Total loss': 0.4893314012072303} | train loss {'Reaction outcome loss': 0.4557782854960889, 'Total loss': 0.4557782854960889}
2022-11-28 05:03:41,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:41,867 INFO:     Epoch: 80
2022-11-28 05:03:42,524 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47558532045646146, 'Total loss': 0.47558532045646146} | train loss {'Reaction outcome loss': 0.4633000094063428, 'Total loss': 0.4633000094063428}
2022-11-28 05:03:42,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:42,524 INFO:     Epoch: 81
2022-11-28 05:03:43,180 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.470928931100802, 'Total loss': 0.470928931100802} | train loss {'Reaction outcome loss': 0.46027022594091843, 'Total loss': 0.46027022594091843}
2022-11-28 05:03:43,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:43,180 INFO:     Epoch: 82
2022-11-28 05:03:43,836 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4977257014675574, 'Total loss': 0.4977257014675574} | train loss {'Reaction outcome loss': 0.46393351287257917, 'Total loss': 0.46393351287257917}
2022-11-28 05:03:43,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:43,836 INFO:     Epoch: 83
2022-11-28 05:03:44,493 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4960940537804907, 'Total loss': 0.4960940537804907} | train loss {'Reaction outcome loss': 0.4599158335096982, 'Total loss': 0.4599158335096982}
2022-11-28 05:03:44,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:44,493 INFO:     Epoch: 84
2022-11-28 05:03:45,151 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47980866145173257, 'Total loss': 0.47980866145173257} | train loss {'Reaction outcome loss': 0.46547521729858554, 'Total loss': 0.46547521729858554}
2022-11-28 05:03:45,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:45,151 INFO:     Epoch: 85
2022-11-28 05:03:45,808 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49294091524048284, 'Total loss': 0.49294091524048284} | train loss {'Reaction outcome loss': 0.4594705034883655, 'Total loss': 0.4594705034883655}
2022-11-28 05:03:45,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:45,808 INFO:     Epoch: 86
2022-11-28 05:03:46,465 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5225499946285378, 'Total loss': 0.5225499946285378} | train loss {'Reaction outcome loss': 0.46127181287322727, 'Total loss': 0.46127181287322727}
2022-11-28 05:03:46,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:46,465 INFO:     Epoch: 87
2022-11-28 05:03:47,124 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5007725405422124, 'Total loss': 0.5007725405422124} | train loss {'Reaction outcome loss': 0.45647313722542354, 'Total loss': 0.45647313722542354}
2022-11-28 05:03:47,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:47,124 INFO:     Epoch: 88
2022-11-28 05:03:47,780 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48611294105648994, 'Total loss': 0.48611294105648994} | train loss {'Reaction outcome loss': 0.4648775335477323, 'Total loss': 0.4648775335477323}
2022-11-28 05:03:47,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:47,780 INFO:     Epoch: 89
2022-11-28 05:03:48,441 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5174926499074156, 'Total loss': 0.5174926499074156} | train loss {'Reaction outcome loss': 0.46367909154113457, 'Total loss': 0.46367909154113457}
2022-11-28 05:03:48,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:48,441 INFO:     Epoch: 90
2022-11-28 05:03:49,099 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4926162599162622, 'Total loss': 0.4926162599162622} | train loss {'Reaction outcome loss': 0.4672788248986614, 'Total loss': 0.4672788248986614}
2022-11-28 05:03:49,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:49,100 INFO:     Epoch: 91
2022-11-28 05:03:49,753 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5124654099345207, 'Total loss': 0.5124654099345207} | train loss {'Reaction outcome loss': 0.4571934890078039, 'Total loss': 0.4571934890078039}
2022-11-28 05:03:49,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:49,753 INFO:     Epoch: 92
2022-11-28 05:03:50,409 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5017102208327163, 'Total loss': 0.5017102208327163} | train loss {'Reaction outcome loss': 0.47442255768240715, 'Total loss': 0.47442255768240715}
2022-11-28 05:03:50,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:50,410 INFO:     Epoch: 93
2022-11-28 05:03:51,069 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49045546987855976, 'Total loss': 0.49045546987855976} | train loss {'Reaction outcome loss': 0.46872427816293677, 'Total loss': 0.46872427816293677}
2022-11-28 05:03:51,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:51,070 INFO:     Epoch: 94
2022-11-28 05:03:51,730 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49984461204572156, 'Total loss': 0.49984461204572156} | train loss {'Reaction outcome loss': 0.46498402916655246, 'Total loss': 0.46498402916655246}
2022-11-28 05:03:51,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:51,730 INFO:     Epoch: 95
2022-11-28 05:03:52,383 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5087313503026962, 'Total loss': 0.5087313503026962} | train loss {'Reaction outcome loss': 0.46395511286599295, 'Total loss': 0.46395511286599295}
2022-11-28 05:03:52,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:52,384 INFO:     Epoch: 96
2022-11-28 05:03:53,039 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5107688802209768, 'Total loss': 0.5107688802209768} | train loss {'Reaction outcome loss': 0.46845906218703914, 'Total loss': 0.46845906218703914}
2022-11-28 05:03:53,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:53,040 INFO:     Epoch: 97
2022-11-28 05:03:53,696 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5170970003713261, 'Total loss': 0.5170970003713261} | train loss {'Reaction outcome loss': 0.4641061798650391, 'Total loss': 0.4641061798650391}
2022-11-28 05:03:53,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:53,697 INFO:     Epoch: 98
2022-11-28 05:03:54,355 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5052688900719989, 'Total loss': 0.5052688900719989} | train loss {'Reaction outcome loss': 0.4667220327318931, 'Total loss': 0.4667220327318931}
2022-11-28 05:03:54,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:54,356 INFO:     Epoch: 99
2022-11-28 05:03:55,010 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4875501719388095, 'Total loss': 0.4875501719388095} | train loss {'Reaction outcome loss': 0.4652974500035753, 'Total loss': 0.4652974500035753}
2022-11-28 05:03:55,010 INFO:     Best model found after epoch 63 of 100.
2022-11-28 05:03:55,010 INFO:   Done with stage: TRAINING
2022-11-28 05:03:55,010 INFO:   Starting stage: EVALUATION
2022-11-28 05:03:55,133 INFO:   Done with stage: EVALUATION
2022-11-28 05:03:55,133 INFO:   Leaving out SEQ value Fold_8
2022-11-28 05:03:55,146 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 05:03:55,146 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:03:55,792 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:03:55,792 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:03:55,862 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:03:55,863 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:03:55,863 INFO:     No hyperparam tuning for this model
2022-11-28 05:03:55,863 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:03:55,863 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:03:55,863 INFO:     None feature selector for col prot
2022-11-28 05:03:55,863 INFO:     None feature selector for col prot
2022-11-28 05:03:55,864 INFO:     None feature selector for col prot
2022-11-28 05:03:55,864 INFO:     None feature selector for col chem
2022-11-28 05:03:55,864 INFO:     None feature selector for col chem
2022-11-28 05:03:55,864 INFO:     None feature selector for col chem
2022-11-28 05:03:55,864 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:03:55,864 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:03:55,866 INFO:     Number of params in model 169651
2022-11-28 05:03:55,869 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:03:55,869 INFO:   Starting stage: TRAINING
2022-11-28 05:03:55,919 INFO:     Val loss before train {'Reaction outcome loss': 0.9771296029741113, 'Total loss': 0.9771296029741113}
2022-11-28 05:03:55,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:55,919 INFO:     Epoch: 0
2022-11-28 05:03:56,579 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5749198597940531, 'Total loss': 0.5749198597940531} | train loss {'Reaction outcome loss': 0.6877775367709899, 'Total loss': 0.6877775367709899}
2022-11-28 05:03:56,580 INFO:     Found new best model at epoch 0
2022-11-28 05:03:56,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:56,580 INFO:     Epoch: 1
2022-11-28 05:03:57,241 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.558905919844454, 'Total loss': 0.558905919844454} | train loss {'Reaction outcome loss': 0.5841577035645323, 'Total loss': 0.5841577035645323}
2022-11-28 05:03:57,241 INFO:     Found new best model at epoch 1
2022-11-28 05:03:57,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:57,242 INFO:     Epoch: 2
2022-11-28 05:03:57,906 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5611030594869093, 'Total loss': 0.5611030594869093} | train loss {'Reaction outcome loss': 0.5690441689183635, 'Total loss': 0.5690441689183635}
2022-11-28 05:03:57,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:57,906 INFO:     Epoch: 3
2022-11-28 05:03:58,570 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5518329339948568, 'Total loss': 0.5518329339948568} | train loss {'Reaction outcome loss': 0.5543451945507719, 'Total loss': 0.5543451945507719}
2022-11-28 05:03:58,570 INFO:     Found new best model at epoch 3
2022-11-28 05:03:58,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:58,571 INFO:     Epoch: 4
2022-11-28 05:03:59,232 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5343370187011632, 'Total loss': 0.5343370187011632} | train loss {'Reaction outcome loss': 0.5283096972252092, 'Total loss': 0.5283096972252092}
2022-11-28 05:03:59,232 INFO:     Found new best model at epoch 4
2022-11-28 05:03:59,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:59,233 INFO:     Epoch: 5
2022-11-28 05:03:59,895 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5078137642280622, 'Total loss': 0.5078137642280622} | train loss {'Reaction outcome loss': 0.5279158267282671, 'Total loss': 0.5279158267282671}
2022-11-28 05:03:59,895 INFO:     Found new best model at epoch 5
2022-11-28 05:03:59,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:03:59,895 INFO:     Epoch: 6
2022-11-28 05:04:00,557 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.526800196279179, 'Total loss': 0.526800196279179} | train loss {'Reaction outcome loss': 0.4998283838672984, 'Total loss': 0.4998283838672984}
2022-11-28 05:04:00,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:00,558 INFO:     Epoch: 7
2022-11-28 05:04:01,222 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5168213221159849, 'Total loss': 0.5168213221159849} | train loss {'Reaction outcome loss': 0.49960097916904955, 'Total loss': 0.49960097916904955}
2022-11-28 05:04:01,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:01,222 INFO:     Epoch: 8
2022-11-28 05:04:01,888 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.515580378472805, 'Total loss': 0.515580378472805} | train loss {'Reaction outcome loss': 0.5048238400129541, 'Total loss': 0.5048238400129541}
2022-11-28 05:04:01,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:01,889 INFO:     Epoch: 9
2022-11-28 05:04:02,552 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5170310366560112, 'Total loss': 0.5170310366560112} | train loss {'Reaction outcome loss': 0.4984815391080995, 'Total loss': 0.4984815391080995}
2022-11-28 05:04:02,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:02,553 INFO:     Epoch: 10
2022-11-28 05:04:03,217 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5402365699410439, 'Total loss': 0.5402365699410439} | train loss {'Reaction outcome loss': 0.48141059501757544, 'Total loss': 0.48141059501757544}
2022-11-28 05:04:03,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:03,217 INFO:     Epoch: 11
2022-11-28 05:04:03,881 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48357678204774857, 'Total loss': 0.48357678204774857} | train loss {'Reaction outcome loss': 0.4925421583916872, 'Total loss': 0.4925421583916872}
2022-11-28 05:04:03,882 INFO:     Found new best model at epoch 11
2022-11-28 05:04:03,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:03,882 INFO:     Epoch: 12
2022-11-28 05:04:04,543 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5182456743310798, 'Total loss': 0.5182456743310798} | train loss {'Reaction outcome loss': 0.48505734003359274, 'Total loss': 0.48505734003359274}
2022-11-28 05:04:04,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:04,544 INFO:     Epoch: 13
2022-11-28 05:04:05,209 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4988913911987435, 'Total loss': 0.4988913911987435} | train loss {'Reaction outcome loss': 0.4838048741071215, 'Total loss': 0.4838048741071215}
2022-11-28 05:04:05,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:05,210 INFO:     Epoch: 14
2022-11-28 05:04:05,875 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5077061893587763, 'Total loss': 0.5077061893587763} | train loss {'Reaction outcome loss': 0.4774496518075466, 'Total loss': 0.4774496518075466}
2022-11-28 05:04:05,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:05,875 INFO:     Epoch: 15
2022-11-28 05:04:06,538 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5108464590527795, 'Total loss': 0.5108464590527795} | train loss {'Reaction outcome loss': 0.48534876672971633, 'Total loss': 0.48534876672971633}
2022-11-28 05:04:06,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:06,538 INFO:     Epoch: 16
2022-11-28 05:04:07,201 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.499010253358971, 'Total loss': 0.499010253358971} | train loss {'Reaction outcome loss': 0.4757016924239935, 'Total loss': 0.4757016924239935}
2022-11-28 05:04:07,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:07,201 INFO:     Epoch: 17
2022-11-28 05:04:07,866 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4999753260477023, 'Total loss': 0.4999753260477023} | train loss {'Reaction outcome loss': 0.48116317733881936, 'Total loss': 0.48116317733881936}
2022-11-28 05:04:07,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:07,866 INFO:     Epoch: 18
2022-11-28 05:04:08,529 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4891455126079646, 'Total loss': 0.4891455126079646} | train loss {'Reaction outcome loss': 0.46899696866110446, 'Total loss': 0.46899696866110446}
2022-11-28 05:04:08,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:08,530 INFO:     Epoch: 19
2022-11-28 05:04:09,194 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49952534857121383, 'Total loss': 0.49952534857121383} | train loss {'Reaction outcome loss': 0.470107322708974, 'Total loss': 0.470107322708974}
2022-11-28 05:04:09,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:09,194 INFO:     Epoch: 20
2022-11-28 05:04:09,857 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47556709396568214, 'Total loss': 0.47556709396568214} | train loss {'Reaction outcome loss': 0.4804942174063575, 'Total loss': 0.4804942174063575}
2022-11-28 05:04:09,858 INFO:     Found new best model at epoch 20
2022-11-28 05:04:09,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:09,858 INFO:     Epoch: 21
2022-11-28 05:04:10,524 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4852090769193389, 'Total loss': 0.4852090769193389} | train loss {'Reaction outcome loss': 0.4729775278678825, 'Total loss': 0.4729775278678825}
2022-11-28 05:04:10,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:10,524 INFO:     Epoch: 22
2022-11-28 05:04:11,188 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47053389522162353, 'Total loss': 0.47053389522162353} | train loss {'Reaction outcome loss': 0.4717668677650152, 'Total loss': 0.4717668677650152}
2022-11-28 05:04:11,189 INFO:     Found new best model at epoch 22
2022-11-28 05:04:11,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:11,189 INFO:     Epoch: 23
2022-11-28 05:04:11,853 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5367894240401008, 'Total loss': 0.5367894240401008} | train loss {'Reaction outcome loss': 0.4691774733665009, 'Total loss': 0.4691774733665009}
2022-11-28 05:04:11,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:11,853 INFO:     Epoch: 24
2022-11-28 05:04:12,517 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.49882262403314764, 'Total loss': 0.49882262403314764} | train loss {'Reaction outcome loss': 0.470495720363913, 'Total loss': 0.470495720363913}
2022-11-28 05:04:12,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:12,518 INFO:     Epoch: 25
2022-11-28 05:04:13,185 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5014131001450799, 'Total loss': 0.5014131001450799} | train loss {'Reaction outcome loss': 0.47879592626686057, 'Total loss': 0.47879592626686057}
2022-11-28 05:04:13,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:13,185 INFO:     Epoch: 26
2022-11-28 05:04:13,851 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5246622833338651, 'Total loss': 0.5246622833338651} | train loss {'Reaction outcome loss': 0.48077960892189897, 'Total loss': 0.48077960892189897}
2022-11-28 05:04:13,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:13,851 INFO:     Epoch: 27
2022-11-28 05:04:14,515 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4806283874945207, 'Total loss': 0.4806283874945207} | train loss {'Reaction outcome loss': 0.4748474240543381, 'Total loss': 0.4748474240543381}
2022-11-28 05:04:14,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:14,516 INFO:     Epoch: 28
2022-11-28 05:04:15,181 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46980814703486184, 'Total loss': 0.46980814703486184} | train loss {'Reaction outcome loss': 0.4699865014803025, 'Total loss': 0.4699865014803025}
2022-11-28 05:04:15,181 INFO:     Found new best model at epoch 28
2022-11-28 05:04:15,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:15,182 INFO:     Epoch: 29
2022-11-28 05:04:15,848 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49251237003640697, 'Total loss': 0.49251237003640697} | train loss {'Reaction outcome loss': 0.4700844886021749, 'Total loss': 0.4700844886021749}
2022-11-28 05:04:15,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:15,849 INFO:     Epoch: 30
2022-11-28 05:04:16,515 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4942492686889388, 'Total loss': 0.4942492686889388} | train loss {'Reaction outcome loss': 0.4761588768132271, 'Total loss': 0.4761588768132271}
2022-11-28 05:04:16,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:16,515 INFO:     Epoch: 31
2022-11-28 05:04:17,181 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.491474795747887, 'Total loss': 0.491474795747887} | train loss {'Reaction outcome loss': 0.4667489199989265, 'Total loss': 0.4667489199989265}
2022-11-28 05:04:17,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:17,181 INFO:     Epoch: 32
2022-11-28 05:04:17,843 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4742719949307767, 'Total loss': 0.4742719949307767} | train loss {'Reaction outcome loss': 0.47534495754347694, 'Total loss': 0.47534495754347694}
2022-11-28 05:04:17,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:17,843 INFO:     Epoch: 33
2022-11-28 05:04:18,508 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48276951333338564, 'Total loss': 0.48276951333338564} | train loss {'Reaction outcome loss': 0.47438052020245985, 'Total loss': 0.47438052020245985}
2022-11-28 05:04:18,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:18,508 INFO:     Epoch: 34
2022-11-28 05:04:19,174 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47255572033199394, 'Total loss': 0.47255572033199394} | train loss {'Reaction outcome loss': 0.45976035308934027, 'Total loss': 0.45976035308934027}
2022-11-28 05:04:19,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:19,174 INFO:     Epoch: 35
2022-11-28 05:04:19,846 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5215218856253407, 'Total loss': 0.5215218856253407} | train loss {'Reaction outcome loss': 0.47247206774209777, 'Total loss': 0.47247206774209777}
2022-11-28 05:04:19,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:19,846 INFO:     Epoch: 36
2022-11-28 05:04:20,512 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4740431146188216, 'Total loss': 0.4740431146188216} | train loss {'Reaction outcome loss': 0.465858603587314, 'Total loss': 0.465858603587314}
2022-11-28 05:04:20,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:20,512 INFO:     Epoch: 37
2022-11-28 05:04:21,177 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47076057202436705, 'Total loss': 0.47076057202436705} | train loss {'Reaction outcome loss': 0.4716801518394101, 'Total loss': 0.4716801518394101}
2022-11-28 05:04:21,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:21,178 INFO:     Epoch: 38
2022-11-28 05:04:21,841 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46805123205889354, 'Total loss': 0.46805123205889354} | train loss {'Reaction outcome loss': 0.4678345497757677, 'Total loss': 0.4678345497757677}
2022-11-28 05:04:21,841 INFO:     Found new best model at epoch 38
2022-11-28 05:04:21,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:21,842 INFO:     Epoch: 39
2022-11-28 05:04:22,506 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5496891222216866, 'Total loss': 0.5496891222216866} | train loss {'Reaction outcome loss': 0.4634622569165884, 'Total loss': 0.4634622569165884}
2022-11-28 05:04:22,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:22,506 INFO:     Epoch: 40
2022-11-28 05:04:23,171 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5481540967117656, 'Total loss': 0.5481540967117656} | train loss {'Reaction outcome loss': 0.46526701772405255, 'Total loss': 0.46526701772405255}
2022-11-28 05:04:23,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:23,171 INFO:     Epoch: 41
2022-11-28 05:04:23,836 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4769648262722926, 'Total loss': 0.4769648262722926} | train loss {'Reaction outcome loss': 0.4680332013616158, 'Total loss': 0.4680332013616158}
2022-11-28 05:04:23,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:23,837 INFO:     Epoch: 42
2022-11-28 05:04:24,500 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5013088363815438, 'Total loss': 0.5013088363815438} | train loss {'Reaction outcome loss': 0.46971926297391614, 'Total loss': 0.46971926297391614}
2022-11-28 05:04:24,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:24,501 INFO:     Epoch: 43
2022-11-28 05:04:25,163 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48863264986059884, 'Total loss': 0.48863264986059884} | train loss {'Reaction outcome loss': 0.47092385361752204, 'Total loss': 0.47092385361752204}
2022-11-28 05:04:25,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:25,163 INFO:     Epoch: 44
2022-11-28 05:04:25,826 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4638572514734485, 'Total loss': 0.4638572514734485} | train loss {'Reaction outcome loss': 0.46229113181752546, 'Total loss': 0.46229113181752546}
2022-11-28 05:04:25,826 INFO:     Found new best model at epoch 44
2022-11-28 05:04:25,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:25,827 INFO:     Epoch: 45
2022-11-28 05:04:26,492 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4956561956893314, 'Total loss': 0.4956561956893314} | train loss {'Reaction outcome loss': 0.4663764877064574, 'Total loss': 0.4663764877064574}
2022-11-28 05:04:26,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:26,492 INFO:     Epoch: 46
2022-11-28 05:04:27,161 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4647542407566851, 'Total loss': 0.4647542407566851} | train loss {'Reaction outcome loss': 0.4648210414114498, 'Total loss': 0.4648210414114498}
2022-11-28 05:04:27,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:27,162 INFO:     Epoch: 47
2022-11-28 05:04:27,831 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47431823069399054, 'Total loss': 0.47431823069399054} | train loss {'Reaction outcome loss': 0.4665456379673654, 'Total loss': 0.4665456379673654}
2022-11-28 05:04:27,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:27,831 INFO:     Epoch: 48
2022-11-28 05:04:28,495 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4876846745610237, 'Total loss': 0.4876846745610237} | train loss {'Reaction outcome loss': 0.4701885959554103, 'Total loss': 0.4701885959554103}
2022-11-28 05:04:28,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:28,495 INFO:     Epoch: 49
2022-11-28 05:04:29,160 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4682622460479086, 'Total loss': 0.4682622460479086} | train loss {'Reaction outcome loss': 0.4708283655946293, 'Total loss': 0.4708283655946293}
2022-11-28 05:04:29,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:29,160 INFO:     Epoch: 50
2022-11-28 05:04:29,825 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4870857779275287, 'Total loss': 0.4870857779275287} | train loss {'Reaction outcome loss': 0.4624675109742149, 'Total loss': 0.4624675109742149}
2022-11-28 05:04:29,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:29,825 INFO:     Epoch: 51
2022-11-28 05:04:30,493 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4717978164553642, 'Total loss': 0.4717978164553642} | train loss {'Reaction outcome loss': 0.46241524761482594, 'Total loss': 0.46241524761482594}
2022-11-28 05:04:30,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:30,493 INFO:     Epoch: 52
2022-11-28 05:04:31,159 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49117347530343314, 'Total loss': 0.49117347530343314} | train loss {'Reaction outcome loss': 0.4679644389618789, 'Total loss': 0.4679644389618789}
2022-11-28 05:04:31,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:31,159 INFO:     Epoch: 53
2022-11-28 05:04:31,825 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5204678966917775, 'Total loss': 0.5204678966917775} | train loss {'Reaction outcome loss': 0.4628214847536818, 'Total loss': 0.4628214847536818}
2022-11-28 05:04:31,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:31,825 INFO:     Epoch: 54
2022-11-28 05:04:32,492 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47884840992364014, 'Total loss': 0.47884840992364014} | train loss {'Reaction outcome loss': 0.46252086380076024, 'Total loss': 0.46252086380076024}
2022-11-28 05:04:32,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:32,492 INFO:     Epoch: 55
2022-11-28 05:04:33,156 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5347306816415354, 'Total loss': 0.5347306816415354} | train loss {'Reaction outcome loss': 0.4607852352482657, 'Total loss': 0.4607852352482657}
2022-11-28 05:04:33,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:33,157 INFO:     Epoch: 56
2022-11-28 05:04:33,824 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4895219870588996, 'Total loss': 0.4895219870588996} | train loss {'Reaction outcome loss': 0.46616537844942463, 'Total loss': 0.46616537844942463}
2022-11-28 05:04:33,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:33,824 INFO:     Epoch: 57
2022-11-28 05:04:34,493 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46687546982006595, 'Total loss': 0.46687546982006595} | train loss {'Reaction outcome loss': 0.46414387646702027, 'Total loss': 0.46414387646702027}
2022-11-28 05:04:34,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:34,493 INFO:     Epoch: 58
2022-11-28 05:04:35,166 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49343846196478064, 'Total loss': 0.49343846196478064} | train loss {'Reaction outcome loss': 0.4622605434588848, 'Total loss': 0.4622605434588848}
2022-11-28 05:04:35,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:35,166 INFO:     Epoch: 59
2022-11-28 05:04:35,832 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4618131758814508, 'Total loss': 0.4618131758814508} | train loss {'Reaction outcome loss': 0.4670891216505439, 'Total loss': 0.4670891216505439}
2022-11-28 05:04:35,832 INFO:     Found new best model at epoch 59
2022-11-28 05:04:35,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:35,833 INFO:     Epoch: 60
2022-11-28 05:04:36,499 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5029706849970601, 'Total loss': 0.5029706849970601} | train loss {'Reaction outcome loss': 0.46491079392933077, 'Total loss': 0.46491079392933077}
2022-11-28 05:04:36,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:36,499 INFO:     Epoch: 61
2022-11-28 05:04:37,164 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4805815741419792, 'Total loss': 0.4805815741419792} | train loss {'Reaction outcome loss': 0.4695651344354114, 'Total loss': 0.4695651344354114}
2022-11-28 05:04:37,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:37,164 INFO:     Epoch: 62
2022-11-28 05:04:37,828 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5022003298456018, 'Total loss': 0.5022003298456018} | train loss {'Reaction outcome loss': 0.4642147041496731, 'Total loss': 0.4642147041496731}
2022-11-28 05:04:37,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:37,828 INFO:     Epoch: 63
2022-11-28 05:04:38,494 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47660731625827873, 'Total loss': 0.47660731625827873} | train loss {'Reaction outcome loss': 0.4722840638170319, 'Total loss': 0.4722840638170319}
2022-11-28 05:04:38,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:38,495 INFO:     Epoch: 64
2022-11-28 05:04:39,164 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4993672736666419, 'Total loss': 0.4993672736666419} | train loss {'Reaction outcome loss': 0.4623312648505934, 'Total loss': 0.4623312648505934}
2022-11-28 05:04:39,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:39,165 INFO:     Epoch: 65
2022-11-28 05:04:39,829 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5013289187442173, 'Total loss': 0.5013289187442173} | train loss {'Reaction outcome loss': 0.4620363562698326, 'Total loss': 0.4620363562698326}
2022-11-28 05:04:39,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:39,829 INFO:     Epoch: 66
2022-11-28 05:04:40,494 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47129319980740547, 'Total loss': 0.47129319980740547} | train loss {'Reaction outcome loss': 0.4719883049688032, 'Total loss': 0.4719883049688032}
2022-11-28 05:04:40,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:40,494 INFO:     Epoch: 67
2022-11-28 05:04:41,160 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45273154736919835, 'Total loss': 0.45273154736919835} | train loss {'Reaction outcome loss': 0.466461984200343, 'Total loss': 0.466461984200343}
2022-11-28 05:04:41,160 INFO:     Found new best model at epoch 67
2022-11-28 05:04:41,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:41,161 INFO:     Epoch: 68
2022-11-28 05:04:41,827 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4738569219004024, 'Total loss': 0.4738569219004024} | train loss {'Reaction outcome loss': 0.4669874864480188, 'Total loss': 0.4669874864480188}
2022-11-28 05:04:41,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:41,827 INFO:     Epoch: 69
2022-11-28 05:04:42,495 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45430783521045337, 'Total loss': 0.45430783521045337} | train loss {'Reaction outcome loss': 0.4706143189461962, 'Total loss': 0.4706143189461962}
2022-11-28 05:04:42,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:42,495 INFO:     Epoch: 70
2022-11-28 05:04:43,167 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48398716713894496, 'Total loss': 0.48398716713894496} | train loss {'Reaction outcome loss': 0.46608706134101074, 'Total loss': 0.46608706134101074}
2022-11-28 05:04:43,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:43,168 INFO:     Epoch: 71
2022-11-28 05:04:43,837 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48597909831865266, 'Total loss': 0.48597909831865266} | train loss {'Reaction outcome loss': 0.4610032549188022, 'Total loss': 0.4610032549188022}
2022-11-28 05:04:43,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:43,837 INFO:     Epoch: 72
2022-11-28 05:04:44,501 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5064604505896568, 'Total loss': 0.5064604505896568} | train loss {'Reaction outcome loss': 0.47188444105127164, 'Total loss': 0.47188444105127164}
2022-11-28 05:04:44,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:44,502 INFO:     Epoch: 73
2022-11-28 05:04:45,170 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4769101982766932, 'Total loss': 0.4769101982766932} | train loss {'Reaction outcome loss': 0.4705887803988111, 'Total loss': 0.4705887803988111}
2022-11-28 05:04:45,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:45,170 INFO:     Epoch: 74
2022-11-28 05:04:45,836 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47321283749558707, 'Total loss': 0.47321283749558707} | train loss {'Reaction outcome loss': 0.4679412323861353, 'Total loss': 0.4679412323861353}
2022-11-28 05:04:45,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:45,837 INFO:     Epoch: 75
2022-11-28 05:04:46,506 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48234891620549286, 'Total loss': 0.48234891620549286} | train loss {'Reaction outcome loss': 0.4688504401954912, 'Total loss': 0.4688504401954912}
2022-11-28 05:04:46,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:46,507 INFO:     Epoch: 76
2022-11-28 05:04:47,171 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4852697090669112, 'Total loss': 0.4852697090669112} | train loss {'Reaction outcome loss': 0.46712717047381785, 'Total loss': 0.46712717047381785}
2022-11-28 05:04:47,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:47,172 INFO:     Epoch: 77
2022-11-28 05:04:47,835 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4699559486047788, 'Total loss': 0.4699559486047788} | train loss {'Reaction outcome loss': 0.46529496094632533, 'Total loss': 0.46529496094632533}
2022-11-28 05:04:47,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:47,836 INFO:     Epoch: 78
2022-11-28 05:04:48,497 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48138365759090945, 'Total loss': 0.48138365759090945} | train loss {'Reaction outcome loss': 0.4712694886951677, 'Total loss': 0.4712694886951677}
2022-11-28 05:04:48,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:48,497 INFO:     Epoch: 79
2022-11-28 05:04:49,167 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4802609939466823, 'Total loss': 0.4802609939466823} | train loss {'Reaction outcome loss': 0.46420897903942293, 'Total loss': 0.46420897903942293}
2022-11-28 05:04:49,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:49,168 INFO:     Epoch: 80
2022-11-28 05:04:49,835 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4977998594668778, 'Total loss': 0.4977998594668778} | train loss {'Reaction outcome loss': 0.47008472560874875, 'Total loss': 0.47008472560874875}
2022-11-28 05:04:49,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:49,835 INFO:     Epoch: 81
2022-11-28 05:04:50,503 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5031058493662964, 'Total loss': 0.5031058493662964} | train loss {'Reaction outcome loss': 0.46104422109501975, 'Total loss': 0.46104422109501975}
2022-11-28 05:04:50,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:50,503 INFO:     Epoch: 82
2022-11-28 05:04:51,168 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4782700945030559, 'Total loss': 0.4782700945030559} | train loss {'Reaction outcome loss': 0.46825217311420747, 'Total loss': 0.46825217311420747}
2022-11-28 05:04:51,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:51,168 INFO:     Epoch: 83
2022-11-28 05:04:51,834 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4829817255112258, 'Total loss': 0.4829817255112258} | train loss {'Reaction outcome loss': 0.46245921361109904, 'Total loss': 0.46245921361109904}
2022-11-28 05:04:51,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:51,834 INFO:     Epoch: 84
2022-11-28 05:04:52,498 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47341964597051794, 'Total loss': 0.47341964597051794} | train loss {'Reaction outcome loss': 0.4625646457556755, 'Total loss': 0.4625646457556755}
2022-11-28 05:04:52,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:52,498 INFO:     Epoch: 85
2022-11-28 05:04:53,164 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5253457579423081, 'Total loss': 0.5253457579423081} | train loss {'Reaction outcome loss': 0.4638180687062202, 'Total loss': 0.4638180687062202}
2022-11-28 05:04:53,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:53,165 INFO:     Epoch: 86
2022-11-28 05:04:53,829 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4607755812731656, 'Total loss': 0.4607755812731656} | train loss {'Reaction outcome loss': 0.46857406643609845, 'Total loss': 0.46857406643609845}
2022-11-28 05:04:53,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:53,830 INFO:     Epoch: 87
2022-11-28 05:04:54,493 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4610295393927531, 'Total loss': 0.4610295393927531} | train loss {'Reaction outcome loss': 0.46198233427299606, 'Total loss': 0.46198233427299606}
2022-11-28 05:04:54,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:54,493 INFO:     Epoch: 88
2022-11-28 05:04:55,157 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4667467413978143, 'Total loss': 0.4667467413978143} | train loss {'Reaction outcome loss': 0.46310094846112115, 'Total loss': 0.46310094846112115}
2022-11-28 05:04:55,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:55,157 INFO:     Epoch: 89
2022-11-28 05:04:55,825 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47543219426138833, 'Total loss': 0.47543219426138833} | train loss {'Reaction outcome loss': 0.4688225307712151, 'Total loss': 0.4688225307712151}
2022-11-28 05:04:55,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:55,825 INFO:     Epoch: 90
2022-11-28 05:04:56,490 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49563029408454895, 'Total loss': 0.49563029408454895} | train loss {'Reaction outcome loss': 0.45829572228174054, 'Total loss': 0.45829572228174054}
2022-11-28 05:04:56,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:56,490 INFO:     Epoch: 91
2022-11-28 05:04:57,154 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4795727130364288, 'Total loss': 0.4795727130364288} | train loss {'Reaction outcome loss': 0.46217147140733655, 'Total loss': 0.46217147140733655}
2022-11-28 05:04:57,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:57,154 INFO:     Epoch: 92
2022-11-28 05:04:57,817 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5000613010065122, 'Total loss': 0.5000613010065122} | train loss {'Reaction outcome loss': 0.4656878655716296, 'Total loss': 0.4656878655716296}
2022-11-28 05:04:57,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:57,817 INFO:     Epoch: 93
2022-11-28 05:04:58,481 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4761776930906556, 'Total loss': 0.4761776930906556} | train loss {'Reaction outcome loss': 0.46576110027249784, 'Total loss': 0.46576110027249784}
2022-11-28 05:04:58,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:58,481 INFO:     Epoch: 94
2022-11-28 05:04:59,146 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.467781269245527, 'Total loss': 0.467781269245527} | train loss {'Reaction outcome loss': 0.4576741204026245, 'Total loss': 0.4576741204026245}
2022-11-28 05:04:59,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:59,146 INFO:     Epoch: 95
2022-11-28 05:04:59,811 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4921636405316266, 'Total loss': 0.4921636405316266} | train loss {'Reaction outcome loss': 0.4607501967900222, 'Total loss': 0.4607501967900222}
2022-11-28 05:04:59,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:04:59,812 INFO:     Epoch: 96
2022-11-28 05:05:00,477 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4517198729921471, 'Total loss': 0.4517198729921471} | train loss {'Reaction outcome loss': 0.4677936819291884, 'Total loss': 0.4677936819291884}
2022-11-28 05:05:00,477 INFO:     Found new best model at epoch 96
2022-11-28 05:05:00,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:00,478 INFO:     Epoch: 97
2022-11-28 05:05:01,139 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4587701884183017, 'Total loss': 0.4587701884183017} | train loss {'Reaction outcome loss': 0.46029069100416475, 'Total loss': 0.46029069100416475}
2022-11-28 05:05:01,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:01,139 INFO:     Epoch: 98
2022-11-28 05:05:01,802 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49148269065401773, 'Total loss': 0.49148269065401773} | train loss {'Reaction outcome loss': 0.4675993415256662, 'Total loss': 0.4675993415256662}
2022-11-28 05:05:01,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:01,802 INFO:     Epoch: 99
2022-11-28 05:05:02,463 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48575484041463246, 'Total loss': 0.48575484041463246} | train loss {'Reaction outcome loss': 0.4729156121010742, 'Total loss': 0.4729156121010742}
2022-11-28 05:05:02,463 INFO:     Best model found after epoch 97 of 100.
2022-11-28 05:05:02,463 INFO:   Done with stage: TRAINING
2022-11-28 05:05:02,463 INFO:   Starting stage: EVALUATION
2022-11-28 05:05:02,575 INFO:   Done with stage: EVALUATION
2022-11-28 05:05:02,576 INFO:   Leaving out SEQ value Fold_9
2022-11-28 05:05:02,588 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 05:05:02,588 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:05:03,223 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:05:03,223 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:05:03,292 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:05:03,293 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:05:03,293 INFO:     No hyperparam tuning for this model
2022-11-28 05:05:03,293 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:05:03,293 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:05:03,293 INFO:     None feature selector for col prot
2022-11-28 05:05:03,294 INFO:     None feature selector for col prot
2022-11-28 05:05:03,294 INFO:     None feature selector for col prot
2022-11-28 05:05:03,294 INFO:     None feature selector for col chem
2022-11-28 05:05:03,294 INFO:     None feature selector for col chem
2022-11-28 05:05:03,294 INFO:     None feature selector for col chem
2022-11-28 05:05:03,294 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:05:03,294 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:05:03,296 INFO:     Number of params in model 169651
2022-11-28 05:05:03,299 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:05:03,299 INFO:   Starting stage: TRAINING
2022-11-28 05:05:03,350 INFO:     Val loss before train {'Reaction outcome loss': 1.0240188837051392, 'Total loss': 1.0240188837051392}
2022-11-28 05:05:03,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:03,350 INFO:     Epoch: 0
2022-11-28 05:05:04,008 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5864302739501, 'Total loss': 0.5864302739501} | train loss {'Reaction outcome loss': 0.6708116294778124, 'Total loss': 0.6708116294778124}
2022-11-28 05:05:04,008 INFO:     Found new best model at epoch 0
2022-11-28 05:05:04,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:04,009 INFO:     Epoch: 1
2022-11-28 05:05:04,666 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5799930373376067, 'Total loss': 0.5799930373376067} | train loss {'Reaction outcome loss': 0.5798490751762779, 'Total loss': 0.5798490751762779}
2022-11-28 05:05:04,667 INFO:     Found new best model at epoch 1
2022-11-28 05:05:04,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:04,668 INFO:     Epoch: 2
2022-11-28 05:05:05,327 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.619816782799634, 'Total loss': 0.619816782799634} | train loss {'Reaction outcome loss': 0.5474797348890986, 'Total loss': 0.5474797348890986}
2022-11-28 05:05:05,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:05,327 INFO:     Epoch: 3
2022-11-28 05:05:05,986 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5534363598986105, 'Total loss': 0.5534363598986105} | train loss {'Reaction outcome loss': 0.532447327886309, 'Total loss': 0.532447327886309}
2022-11-28 05:05:05,986 INFO:     Found new best model at epoch 3
2022-11-28 05:05:05,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:05,987 INFO:     Epoch: 4
2022-11-28 05:05:06,643 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.562678495591337, 'Total loss': 0.562678495591337} | train loss {'Reaction outcome loss': 0.511017181617873, 'Total loss': 0.511017181617873}
2022-11-28 05:05:06,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:06,644 INFO:     Epoch: 5
2022-11-28 05:05:07,302 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5726633495227857, 'Total loss': 0.5726633495227857} | train loss {'Reaction outcome loss': 0.5149393379080053, 'Total loss': 0.5149393379080053}
2022-11-28 05:05:07,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:07,302 INFO:     Epoch: 6
2022-11-28 05:05:07,969 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5702305632558736, 'Total loss': 0.5702305632558736} | train loss {'Reaction outcome loss': 0.4999595117812254, 'Total loss': 0.4999595117812254}
2022-11-28 05:05:07,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:07,969 INFO:     Epoch: 7
2022-11-28 05:05:08,630 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5479728721759536, 'Total loss': 0.5479728721759536} | train loss {'Reaction outcome loss': 0.49425945148176076, 'Total loss': 0.49425945148176076}
2022-11-28 05:05:08,630 INFO:     Found new best model at epoch 7
2022-11-28 05:05:08,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:08,631 INFO:     Epoch: 8
2022-11-28 05:05:09,292 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5580454102971337, 'Total loss': 0.5580454102971337} | train loss {'Reaction outcome loss': 0.4772537520041271, 'Total loss': 0.4772537520041271}
2022-11-28 05:05:09,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:09,292 INFO:     Epoch: 9
2022-11-28 05:05:09,954 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4872327313165773, 'Total loss': 0.4872327313165773} | train loss {'Reaction outcome loss': 0.4756313542322237, 'Total loss': 0.4756313542322237}
2022-11-28 05:05:09,955 INFO:     Found new best model at epoch 9
2022-11-28 05:05:09,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:09,955 INFO:     Epoch: 10
2022-11-28 05:05:10,616 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5060264122757044, 'Total loss': 0.5060264122757044} | train loss {'Reaction outcome loss': 0.47678105721668324, 'Total loss': 0.47678105721668324}
2022-11-28 05:05:10,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:10,616 INFO:     Epoch: 11
2022-11-28 05:05:11,282 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4891056199981408, 'Total loss': 0.4891056199981408} | train loss {'Reaction outcome loss': 0.4765740115423592, 'Total loss': 0.4765740115423592}
2022-11-28 05:05:11,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:11,283 INFO:     Epoch: 12
2022-11-28 05:05:11,943 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5465030124918981, 'Total loss': 0.5465030124918981} | train loss {'Reaction outcome loss': 0.46983941288626924, 'Total loss': 0.46983941288626924}
2022-11-28 05:05:11,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:11,944 INFO:     Epoch: 13
2022-11-28 05:05:12,601 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5272412338209423, 'Total loss': 0.5272412338209423} | train loss {'Reaction outcome loss': 0.4687301123628811, 'Total loss': 0.4687301123628811}
2022-11-28 05:05:12,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:12,601 INFO:     Epoch: 14
2022-11-28 05:05:13,262 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5047374902801081, 'Total loss': 0.5047374902801081} | train loss {'Reaction outcome loss': 0.462860830645172, 'Total loss': 0.462860830645172}
2022-11-28 05:05:13,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:13,262 INFO:     Epoch: 15
2022-11-28 05:05:13,921 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.6016706902195107, 'Total loss': 0.6016706902195107} | train loss {'Reaction outcome loss': 0.46366372595028, 'Total loss': 0.46366372595028}
2022-11-28 05:05:13,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:13,921 INFO:     Epoch: 16
2022-11-28 05:05:14,579 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5106643458658998, 'Total loss': 0.5106643458658998} | train loss {'Reaction outcome loss': 0.4640884354406474, 'Total loss': 0.4640884354406474}
2022-11-28 05:05:14,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:14,579 INFO:     Epoch: 17
2022-11-28 05:05:15,240 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49721781232140283, 'Total loss': 0.49721781232140283} | train loss {'Reaction outcome loss': 0.4639009194714682, 'Total loss': 0.4639009194714682}
2022-11-28 05:05:15,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:15,240 INFO:     Epoch: 18
2022-11-28 05:05:15,897 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5067674206061796, 'Total loss': 0.5067674206061796} | train loss {'Reaction outcome loss': 0.46397571484653316, 'Total loss': 0.46397571484653316}
2022-11-28 05:05:15,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:15,898 INFO:     Epoch: 19
2022-11-28 05:05:16,555 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4988670816475695, 'Total loss': 0.4988670816475695} | train loss {'Reaction outcome loss': 0.45960281771056505, 'Total loss': 0.45960281771056505}
2022-11-28 05:05:16,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:16,556 INFO:     Epoch: 20
2022-11-28 05:05:17,210 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49792624332688074, 'Total loss': 0.49792624332688074} | train loss {'Reaction outcome loss': 0.4666736477491807, 'Total loss': 0.4666736477491807}
2022-11-28 05:05:17,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:17,210 INFO:     Epoch: 21
2022-11-28 05:05:17,866 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5156685662540522, 'Total loss': 0.5156685662540522} | train loss {'Reaction outcome loss': 0.45592654116299686, 'Total loss': 0.45592654116299686}
2022-11-28 05:05:17,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:17,866 INFO:     Epoch: 22
2022-11-28 05:05:18,524 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5186252878470854, 'Total loss': 0.5186252878470854} | train loss {'Reaction outcome loss': 0.4604695286069598, 'Total loss': 0.4604695286069598}
2022-11-28 05:05:18,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:18,525 INFO:     Epoch: 23
2022-11-28 05:05:19,182 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5195492319762707, 'Total loss': 0.5195492319762707} | train loss {'Reaction outcome loss': 0.4622775461600751, 'Total loss': 0.4622775461600751}
2022-11-28 05:05:19,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:19,182 INFO:     Epoch: 24
2022-11-28 05:05:19,843 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5037867152555422, 'Total loss': 0.5037867152555422} | train loss {'Reaction outcome loss': 0.46256443633108724, 'Total loss': 0.46256443633108724}
2022-11-28 05:05:19,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:19,843 INFO:     Epoch: 25
2022-11-28 05:05:20,501 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4904937671328133, 'Total loss': 0.4904937671328133} | train loss {'Reaction outcome loss': 0.4565650916829401, 'Total loss': 0.4565650916829401}
2022-11-28 05:05:20,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:20,501 INFO:     Epoch: 26
2022-11-28 05:05:21,162 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.504460833966732, 'Total loss': 0.504460833966732} | train loss {'Reaction outcome loss': 0.4591405040755564, 'Total loss': 0.4591405040755564}
2022-11-28 05:05:21,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:21,162 INFO:     Epoch: 27
2022-11-28 05:05:21,820 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5077710256657817, 'Total loss': 0.5077710256657817} | train loss {'Reaction outcome loss': 0.4592671202153576, 'Total loss': 0.4592671202153576}
2022-11-28 05:05:21,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:21,820 INFO:     Epoch: 28
2022-11-28 05:05:22,479 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5139317685230211, 'Total loss': 0.5139317685230211} | train loss {'Reaction outcome loss': 0.45721030703612736, 'Total loss': 0.45721030703612736}
2022-11-28 05:05:22,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:22,479 INFO:     Epoch: 29
2022-11-28 05:05:23,139 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5110069432041862, 'Total loss': 0.5110069432041862} | train loss {'Reaction outcome loss': 0.45835115641963725, 'Total loss': 0.45835115641963725}
2022-11-28 05:05:23,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:23,139 INFO:     Epoch: 30
2022-11-28 05:05:23,793 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5474501516331326, 'Total loss': 0.5474501516331326} | train loss {'Reaction outcome loss': 0.4580739882831671, 'Total loss': 0.4580739882831671}
2022-11-28 05:05:23,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:23,793 INFO:     Epoch: 31
2022-11-28 05:05:24,450 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4771908047524365, 'Total loss': 0.4771908047524365} | train loss {'Reaction outcome loss': 0.45590419884847133, 'Total loss': 0.45590419884847133}
2022-11-28 05:05:24,451 INFO:     Found new best model at epoch 31
2022-11-28 05:05:24,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:24,451 INFO:     Epoch: 32
2022-11-28 05:05:25,110 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49070085043256934, 'Total loss': 0.49070085043256934} | train loss {'Reaction outcome loss': 0.45401481037237207, 'Total loss': 0.45401481037237207}
2022-11-28 05:05:25,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:25,110 INFO:     Epoch: 33
2022-11-28 05:05:25,770 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5039316117763519, 'Total loss': 0.5039316117763519} | train loss {'Reaction outcome loss': 0.4547519346280974, 'Total loss': 0.4547519346280974}
2022-11-28 05:05:25,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:25,770 INFO:     Epoch: 34
2022-11-28 05:05:26,427 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4861458756706931, 'Total loss': 0.4861458756706931} | train loss {'Reaction outcome loss': 0.45639925003051757, 'Total loss': 0.45639925003051757}
2022-11-28 05:05:26,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:26,428 INFO:     Epoch: 35
2022-11-28 05:05:27,088 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5159208700060844, 'Total loss': 0.5159208700060844} | train loss {'Reaction outcome loss': 0.45292570870749804, 'Total loss': 0.45292570870749804}
2022-11-28 05:05:27,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:27,088 INFO:     Epoch: 36
2022-11-28 05:05:27,750 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5652234408665787, 'Total loss': 0.5652234408665787} | train loss {'Reaction outcome loss': 0.45947916848318915, 'Total loss': 0.45947916848318915}
2022-11-28 05:05:27,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:27,750 INFO:     Epoch: 37
2022-11-28 05:05:28,406 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5141197659752585, 'Total loss': 0.5141197659752585} | train loss {'Reaction outcome loss': 0.4600435023405114, 'Total loss': 0.4600435023405114}
2022-11-28 05:05:28,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:28,407 INFO:     Epoch: 38
2022-11-28 05:05:29,064 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4650331058285453, 'Total loss': 0.4650331058285453} | train loss {'Reaction outcome loss': 0.4569355368005986, 'Total loss': 0.4569355368005986}
2022-11-28 05:05:29,064 INFO:     Found new best model at epoch 38
2022-11-28 05:05:29,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:29,065 INFO:     Epoch: 39
2022-11-28 05:05:29,721 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5022275400432673, 'Total loss': 0.5022275400432673} | train loss {'Reaction outcome loss': 0.4494894989291016, 'Total loss': 0.4494894989291016}
2022-11-28 05:05:29,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:29,721 INFO:     Epoch: 40
2022-11-28 05:05:30,380 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5241066369820725, 'Total loss': 0.5241066369820725} | train loss {'Reaction outcome loss': 0.45198983981901286, 'Total loss': 0.45198983981901286}
2022-11-28 05:05:30,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:30,381 INFO:     Epoch: 41
2022-11-28 05:05:31,035 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4805961445989934, 'Total loss': 0.4805961445989934} | train loss {'Reaction outcome loss': 0.4491222643730592, 'Total loss': 0.4491222643730592}
2022-11-28 05:05:31,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:31,035 INFO:     Epoch: 42
2022-11-28 05:05:31,693 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.508348152380098, 'Total loss': 0.508348152380098} | train loss {'Reaction outcome loss': 0.45553075932726567, 'Total loss': 0.45553075932726567}
2022-11-28 05:05:31,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:31,693 INFO:     Epoch: 43
2022-11-28 05:05:32,348 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46570015529339964, 'Total loss': 0.46570015529339964} | train loss {'Reaction outcome loss': 0.44776026278125997, 'Total loss': 0.44776026278125997}
2022-11-28 05:05:32,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:32,348 INFO:     Epoch: 44
2022-11-28 05:05:33,004 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.52008821408857, 'Total loss': 0.52008821408857} | train loss {'Reaction outcome loss': 0.4486444483910288, 'Total loss': 0.4486444483910288}
2022-11-28 05:05:33,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:33,005 INFO:     Epoch: 45
2022-11-28 05:05:33,662 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4964952746575529, 'Total loss': 0.4964952746575529} | train loss {'Reaction outcome loss': 0.4577709801038917, 'Total loss': 0.4577709801038917}
2022-11-28 05:05:33,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:33,662 INFO:     Epoch: 46
2022-11-28 05:05:34,319 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4960718158293854, 'Total loss': 0.4960718158293854} | train loss {'Reaction outcome loss': 0.45162663605748393, 'Total loss': 0.45162663605748393}
2022-11-28 05:05:34,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:34,319 INFO:     Epoch: 47
2022-11-28 05:05:34,979 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.49570076540112495, 'Total loss': 0.49570076540112495} | train loss {'Reaction outcome loss': 0.457893822722289, 'Total loss': 0.457893822722289}
2022-11-28 05:05:34,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:34,979 INFO:     Epoch: 48
2022-11-28 05:05:35,638 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47522192482243886, 'Total loss': 0.47522192482243886} | train loss {'Reaction outcome loss': 0.4563716681027899, 'Total loss': 0.4563716681027899}
2022-11-28 05:05:35,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:35,639 INFO:     Epoch: 49
2022-11-28 05:05:36,296 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5287457873875444, 'Total loss': 0.5287457873875444} | train loss {'Reaction outcome loss': 0.45225547333152927, 'Total loss': 0.45225547333152927}
2022-11-28 05:05:36,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:36,297 INFO:     Epoch: 50
2022-11-28 05:05:36,951 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5531083308160305, 'Total loss': 0.5531083308160305} | train loss {'Reaction outcome loss': 0.45055596536519577, 'Total loss': 0.45055596536519577}
2022-11-28 05:05:36,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:36,951 INFO:     Epoch: 51
2022-11-28 05:05:37,610 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4879622374745933, 'Total loss': 0.4879622374745933} | train loss {'Reaction outcome loss': 0.45281584287176324, 'Total loss': 0.45281584287176324}
2022-11-28 05:05:37,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:37,610 INFO:     Epoch: 52
2022-11-28 05:05:38,268 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5150068114427003, 'Total loss': 0.5150068114427003} | train loss {'Reaction outcome loss': 0.4501634167773383, 'Total loss': 0.4501634167773383}
2022-11-28 05:05:38,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:38,268 INFO:     Epoch: 53
2022-11-28 05:05:38,923 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5196487266908992, 'Total loss': 0.5196487266908992} | train loss {'Reaction outcome loss': 0.454384982129749, 'Total loss': 0.454384982129749}
2022-11-28 05:05:38,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:38,924 INFO:     Epoch: 54
2022-11-28 05:05:39,582 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47167704931714316, 'Total loss': 0.47167704931714316} | train loss {'Reaction outcome loss': 0.45353370783280356, 'Total loss': 0.45353370783280356}
2022-11-28 05:05:39,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:39,582 INFO:     Epoch: 55
2022-11-28 05:05:40,239 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4856342954391783, 'Total loss': 0.4856342954391783} | train loss {'Reaction outcome loss': 0.45294327261496564, 'Total loss': 0.45294327261496564}
2022-11-28 05:05:40,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:40,239 INFO:     Epoch: 56
2022-11-28 05:05:40,895 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4777514008297162, 'Total loss': 0.4777514008297162} | train loss {'Reaction outcome loss': 0.45320458497319904, 'Total loss': 0.45320458497319904}
2022-11-28 05:05:40,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:40,895 INFO:     Epoch: 57
2022-11-28 05:05:41,552 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5454543910243295, 'Total loss': 0.5454543910243295} | train loss {'Reaction outcome loss': 0.4539081589908016, 'Total loss': 0.4539081589908016}
2022-11-28 05:05:41,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:41,552 INFO:     Epoch: 58
2022-11-28 05:05:42,209 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5302806818349795, 'Total loss': 0.5302806818349795} | train loss {'Reaction outcome loss': 0.44823709464803035, 'Total loss': 0.44823709464803035}
2022-11-28 05:05:42,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:42,210 INFO:     Epoch: 59
2022-11-28 05:05:42,867 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5499015606262467, 'Total loss': 0.5499015606262467} | train loss {'Reaction outcome loss': 0.44988679642579993, 'Total loss': 0.44988679642579993}
2022-11-28 05:05:42,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:42,867 INFO:     Epoch: 60
2022-11-28 05:05:43,522 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.490206183696335, 'Total loss': 0.490206183696335} | train loss {'Reaction outcome loss': 0.4621901463489143, 'Total loss': 0.4621901463489143}
2022-11-28 05:05:43,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:43,523 INFO:     Epoch: 61
2022-11-28 05:05:44,177 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47137912295081397, 'Total loss': 0.47137912295081397} | train loss {'Reaction outcome loss': 0.45257327179519496, 'Total loss': 0.45257327179519496}
2022-11-28 05:05:44,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:44,177 INFO:     Epoch: 62
2022-11-28 05:05:44,832 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4595587212931026, 'Total loss': 0.4595587212931026} | train loss {'Reaction outcome loss': 0.4476568085502605, 'Total loss': 0.4476568085502605}
2022-11-28 05:05:44,832 INFO:     Found new best model at epoch 62
2022-11-28 05:05:44,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:44,833 INFO:     Epoch: 63
2022-11-28 05:05:45,490 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4877766018564051, 'Total loss': 0.4877766018564051} | train loss {'Reaction outcome loss': 0.4571713054666714, 'Total loss': 0.4571713054666714}
2022-11-28 05:05:45,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:45,490 INFO:     Epoch: 64
2022-11-28 05:05:46,148 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47145498408512637, 'Total loss': 0.47145498408512637} | train loss {'Reaction outcome loss': 0.4543434555129129, 'Total loss': 0.4543434555129129}
2022-11-28 05:05:46,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:46,148 INFO:     Epoch: 65
2022-11-28 05:05:46,805 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5180969878353856, 'Total loss': 0.5180969878353856} | train loss {'Reaction outcome loss': 0.4527626539979662, 'Total loss': 0.4527626539979662}
2022-11-28 05:05:46,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:46,805 INFO:     Epoch: 66
2022-11-28 05:05:47,461 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45857296139001846, 'Total loss': 0.45857296139001846} | train loss {'Reaction outcome loss': 0.4524121485194381, 'Total loss': 0.4524121485194381}
2022-11-28 05:05:47,461 INFO:     Found new best model at epoch 66
2022-11-28 05:05:47,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:47,462 INFO:     Epoch: 67
2022-11-28 05:05:48,120 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5351719090884383, 'Total loss': 0.5351719090884383} | train loss {'Reaction outcome loss': 0.4483958996680318, 'Total loss': 0.4483958996680318}
2022-11-28 05:05:48,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:48,120 INFO:     Epoch: 68
2022-11-28 05:05:48,776 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49101239849220624, 'Total loss': 0.49101239849220624} | train loss {'Reaction outcome loss': 0.45432865637905745, 'Total loss': 0.45432865637905745}
2022-11-28 05:05:48,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:48,776 INFO:     Epoch: 69
2022-11-28 05:05:49,431 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48694887791167607, 'Total loss': 0.48694887791167607} | train loss {'Reaction outcome loss': 0.45159655900634066, 'Total loss': 0.45159655900634066}
2022-11-28 05:05:49,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:49,432 INFO:     Epoch: 70
2022-11-28 05:05:50,089 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46251815726811235, 'Total loss': 0.46251815726811235} | train loss {'Reaction outcome loss': 0.4509585601030564, 'Total loss': 0.4509585601030564}
2022-11-28 05:05:50,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:50,089 INFO:     Epoch: 71
2022-11-28 05:05:50,746 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4951851290058006, 'Total loss': 0.4951851290058006} | train loss {'Reaction outcome loss': 0.44888109467467485, 'Total loss': 0.44888109467467485}
2022-11-28 05:05:50,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:50,746 INFO:     Epoch: 72
2022-11-28 05:05:51,404 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48556665602055465, 'Total loss': 0.48556665602055465} | train loss {'Reaction outcome loss': 0.4424131777821755, 'Total loss': 0.4424131777821755}
2022-11-28 05:05:51,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:51,404 INFO:     Epoch: 73
2022-11-28 05:05:52,063 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47618928653272713, 'Total loss': 0.47618928653272713} | train loss {'Reaction outcome loss': 0.4471766595633663, 'Total loss': 0.4471766595633663}
2022-11-28 05:05:52,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:52,063 INFO:     Epoch: 74
2022-11-28 05:05:52,719 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4845726009119641, 'Total loss': 0.4845726009119641} | train loss {'Reaction outcome loss': 0.4454906734885002, 'Total loss': 0.4454906734885002}
2022-11-28 05:05:52,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:52,719 INFO:     Epoch: 75
2022-11-28 05:05:53,378 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47271511635997077, 'Total loss': 0.47271511635997077} | train loss {'Reaction outcome loss': 0.45222640445037765, 'Total loss': 0.45222640445037765}
2022-11-28 05:05:53,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:53,378 INFO:     Epoch: 76
2022-11-28 05:05:54,034 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5203116034919565, 'Total loss': 0.5203116034919565} | train loss {'Reaction outcome loss': 0.4475821597843754, 'Total loss': 0.4475821597843754}
2022-11-28 05:05:54,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:54,034 INFO:     Epoch: 77
2022-11-28 05:05:54,691 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4694343439557336, 'Total loss': 0.4694343439557336} | train loss {'Reaction outcome loss': 0.44802937474177806, 'Total loss': 0.44802937474177806}
2022-11-28 05:05:54,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:54,692 INFO:     Epoch: 78
2022-11-28 05:05:55,351 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5067020031538877, 'Total loss': 0.5067020031538877} | train loss {'Reaction outcome loss': 0.44731969955016154, 'Total loss': 0.44731969955016154}
2022-11-28 05:05:55,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:55,351 INFO:     Epoch: 79
2022-11-28 05:05:56,010 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4989370514046062, 'Total loss': 0.4989370514046062} | train loss {'Reaction outcome loss': 0.44711083119012873, 'Total loss': 0.44711083119012873}
2022-11-28 05:05:56,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:56,010 INFO:     Epoch: 80
2022-11-28 05:05:56,667 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49822428077459335, 'Total loss': 0.49822428077459335} | train loss {'Reaction outcome loss': 0.4464115903085592, 'Total loss': 0.4464115903085592}
2022-11-28 05:05:56,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:56,667 INFO:     Epoch: 81
2022-11-28 05:05:57,322 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5217305547134443, 'Total loss': 0.5217305547134443} | train loss {'Reaction outcome loss': 0.4607395553467225, 'Total loss': 0.4607395553467225}
2022-11-28 05:05:57,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:57,322 INFO:     Epoch: 82
2022-11-28 05:05:57,979 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4819503937932578, 'Total loss': 0.4819503937932578} | train loss {'Reaction outcome loss': 0.4523094155046405, 'Total loss': 0.4523094155046405}
2022-11-28 05:05:57,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:57,979 INFO:     Epoch: 83
2022-11-28 05:05:58,638 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5044207173314962, 'Total loss': 0.5044207173314962} | train loss {'Reaction outcome loss': 0.4470361467526883, 'Total loss': 0.4470361467526883}
2022-11-28 05:05:58,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:58,638 INFO:     Epoch: 84
2022-11-28 05:05:59,296 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4895515888929367, 'Total loss': 0.4895515888929367} | train loss {'Reaction outcome loss': 0.44400989747777275, 'Total loss': 0.44400989747777275}
2022-11-28 05:05:59,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:59,297 INFO:     Epoch: 85
2022-11-28 05:05:59,955 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4579355606639927, 'Total loss': 0.4579355606639927} | train loss {'Reaction outcome loss': 0.45388061057548135, 'Total loss': 0.45388061057548135}
2022-11-28 05:05:59,955 INFO:     Found new best model at epoch 85
2022-11-28 05:05:59,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:05:59,956 INFO:     Epoch: 86
2022-11-28 05:06:00,614 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47780834578654985, 'Total loss': 0.47780834578654985} | train loss {'Reaction outcome loss': 0.4502008647334819, 'Total loss': 0.4502008647334819}
2022-11-28 05:06:00,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:00,615 INFO:     Epoch: 87
2022-11-28 05:06:01,272 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5024923387576233, 'Total loss': 0.5024923387576233} | train loss {'Reaction outcome loss': 0.4494656463666838, 'Total loss': 0.4494656463666838}
2022-11-28 05:06:01,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:01,272 INFO:     Epoch: 88
2022-11-28 05:06:01,930 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48757626014676964, 'Total loss': 0.48757626014676964} | train loss {'Reaction outcome loss': 0.4496551889546063, 'Total loss': 0.4496551889546063}
2022-11-28 05:06:01,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:01,930 INFO:     Epoch: 89
2022-11-28 05:06:02,588 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5168266787447713, 'Total loss': 0.5168266787447713} | train loss {'Reaction outcome loss': 0.45327061937779795, 'Total loss': 0.45327061937779795}
2022-11-28 05:06:02,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:02,588 INFO:     Epoch: 90
2022-11-28 05:06:03,242 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4893795272166079, 'Total loss': 0.4893795272166079} | train loss {'Reaction outcome loss': 0.4485657716283993, 'Total loss': 0.4485657716283993}
2022-11-28 05:06:03,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:03,242 INFO:     Epoch: 91
2022-11-28 05:06:03,901 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5157923539253798, 'Total loss': 0.5157923539253798} | train loss {'Reaction outcome loss': 0.44845649216856276, 'Total loss': 0.44845649216856276}
2022-11-28 05:06:03,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:03,901 INFO:     Epoch: 92
2022-11-28 05:06:04,561 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48601376231421123, 'Total loss': 0.48601376231421123} | train loss {'Reaction outcome loss': 0.44931507524178954, 'Total loss': 0.44931507524178954}
2022-11-28 05:06:04,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:04,561 INFO:     Epoch: 93
2022-11-28 05:06:05,217 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48637355254455045, 'Total loss': 0.48637355254455045} | train loss {'Reaction outcome loss': 0.44414089243022764, 'Total loss': 0.44414089243022764}
2022-11-28 05:06:05,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:05,217 INFO:     Epoch: 94
2022-11-28 05:06:05,873 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49750771949237044, 'Total loss': 0.49750771949237044} | train loss {'Reaction outcome loss': 0.4497262409146951, 'Total loss': 0.4497262409146951}
2022-11-28 05:06:05,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:05,873 INFO:     Epoch: 95
2022-11-28 05:06:06,531 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5206102945587852, 'Total loss': 0.5206102945587852} | train loss {'Reaction outcome loss': 0.4488622275846345, 'Total loss': 0.4488622275846345}
2022-11-28 05:06:06,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:06,532 INFO:     Epoch: 96
2022-11-28 05:06:07,190 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4618141921237111, 'Total loss': 0.4618141921237111} | train loss {'Reaction outcome loss': 0.4526302071250215, 'Total loss': 0.4526302071250215}
2022-11-28 05:06:07,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:07,191 INFO:     Epoch: 97
2022-11-28 05:06:07,850 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5361263521692969, 'Total loss': 0.5361263521692969} | train loss {'Reaction outcome loss': 0.44435610138640114, 'Total loss': 0.44435610138640114}
2022-11-28 05:06:07,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:07,851 INFO:     Epoch: 98
2022-11-28 05:06:08,510 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47062795846299693, 'Total loss': 0.47062795846299693} | train loss {'Reaction outcome loss': 0.45005399823492886, 'Total loss': 0.45005399823492886}
2022-11-28 05:06:08,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:08,510 INFO:     Epoch: 99
2022-11-28 05:06:09,167 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.552472397685051, 'Total loss': 0.552472397685051} | train loss {'Reaction outcome loss': 0.4466952862180009, 'Total loss': 0.4466952862180009}
2022-11-28 05:06:09,167 INFO:     Best model found after epoch 86 of 100.
2022-11-28 05:06:09,167 INFO:   Done with stage: TRAINING
2022-11-28 05:06:09,167 INFO:   Starting stage: EVALUATION
2022-11-28 05:06:09,290 INFO:   Done with stage: EVALUATION
2022-11-28 05:06:09,298 INFO:   Leaving out SEQ value Fold_0
2022-11-28 05:06:09,311 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 05:06:09,311 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:06:09,947 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:06:09,947 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:06:10,015 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:06:10,015 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:06:10,015 INFO:     No hyperparam tuning for this model
2022-11-28 05:06:10,015 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:06:10,016 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:06:10,016 INFO:     None feature selector for col prot
2022-11-28 05:06:10,016 INFO:     None feature selector for col prot
2022-11-28 05:06:10,016 INFO:     None feature selector for col prot
2022-11-28 05:06:10,017 INFO:     None feature selector for col chem
2022-11-28 05:06:10,017 INFO:     None feature selector for col chem
2022-11-28 05:06:10,017 INFO:     None feature selector for col chem
2022-11-28 05:06:10,017 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:06:10,017 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:06:10,019 INFO:     Number of params in model 169651
2022-11-28 05:06:10,022 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:06:10,022 INFO:   Starting stage: TRAINING
2022-11-28 05:06:10,071 INFO:     Val loss before train {'Reaction outcome loss': 1.0313717653585035, 'Total loss': 1.0313717653585035}
2022-11-28 05:06:10,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:10,072 INFO:     Epoch: 0
2022-11-28 05:06:10,725 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.614368982786356, 'Total loss': 0.614368982786356} | train loss {'Reaction outcome loss': 0.6791844963416701, 'Total loss': 0.6791844963416701}
2022-11-28 05:06:10,725 INFO:     Found new best model at epoch 0
2022-11-28 05:06:10,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:10,726 INFO:     Epoch: 1
2022-11-28 05:06:11,381 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5971965477910153, 'Total loss': 0.5971965477910153} | train loss {'Reaction outcome loss': 0.5745329650454833, 'Total loss': 0.5745329650454833}
2022-11-28 05:06:11,382 INFO:     Found new best model at epoch 1
2022-11-28 05:06:11,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:11,382 INFO:     Epoch: 2
2022-11-28 05:06:12,038 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5417174080083537, 'Total loss': 0.5417174080083537} | train loss {'Reaction outcome loss': 0.540325607310553, 'Total loss': 0.540325607310553}
2022-11-28 05:06:12,038 INFO:     Found new best model at epoch 2
2022-11-28 05:06:12,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:12,039 INFO:     Epoch: 3
2022-11-28 05:06:12,695 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5785188266011172, 'Total loss': 0.5785188266011172} | train loss {'Reaction outcome loss': 0.5294333766596239, 'Total loss': 0.5294333766596239}
2022-11-28 05:06:12,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:12,695 INFO:     Epoch: 4
2022-11-28 05:06:13,351 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.55956480877344, 'Total loss': 0.55956480877344} | train loss {'Reaction outcome loss': 0.5182146163748913, 'Total loss': 0.5182146163748913}
2022-11-28 05:06:13,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:13,352 INFO:     Epoch: 5
2022-11-28 05:06:14,006 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5104391796644344, 'Total loss': 0.5104391796644344} | train loss {'Reaction outcome loss': 0.5014828769642798, 'Total loss': 0.5014828769642798}
2022-11-28 05:06:14,007 INFO:     Found new best model at epoch 5
2022-11-28 05:06:14,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:14,007 INFO:     Epoch: 6
2022-11-28 05:06:14,658 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5698026668193729, 'Total loss': 0.5698026668193729} | train loss {'Reaction outcome loss': 0.5141638685323175, 'Total loss': 0.5141638685323175}
2022-11-28 05:06:14,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:14,658 INFO:     Epoch: 7
2022-11-28 05:06:15,310 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5350569264833317, 'Total loss': 0.5350569264833317} | train loss {'Reaction outcome loss': 0.49056131527072094, 'Total loss': 0.49056131527072094}
2022-11-28 05:06:15,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:15,310 INFO:     Epoch: 8
2022-11-28 05:06:15,962 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49538886339165444, 'Total loss': 0.49538886339165444} | train loss {'Reaction outcome loss': 0.4853757962462355, 'Total loss': 0.4853757962462355}
2022-11-28 05:06:15,962 INFO:     Found new best model at epoch 8
2022-11-28 05:06:15,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:15,963 INFO:     Epoch: 9
2022-11-28 05:06:16,621 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48691714572352035, 'Total loss': 0.48691714572352035} | train loss {'Reaction outcome loss': 0.4887536817276087, 'Total loss': 0.4887536817276087}
2022-11-28 05:06:16,621 INFO:     Found new best model at epoch 9
2022-11-28 05:06:16,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:16,622 INFO:     Epoch: 10
2022-11-28 05:06:17,274 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48657183522401853, 'Total loss': 0.48657183522401853} | train loss {'Reaction outcome loss': 0.4770359791448859, 'Total loss': 0.4770359791448859}
2022-11-28 05:06:17,275 INFO:     Found new best model at epoch 10
2022-11-28 05:06:17,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:17,275 INFO:     Epoch: 11
2022-11-28 05:06:17,931 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48310563730639083, 'Total loss': 0.48310563730639083} | train loss {'Reaction outcome loss': 0.4785904611964695, 'Total loss': 0.4785904611964695}
2022-11-28 05:06:17,931 INFO:     Found new best model at epoch 11
2022-11-28 05:06:17,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:17,932 INFO:     Epoch: 12
2022-11-28 05:06:18,589 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5337331755909809, 'Total loss': 0.5337331755909809} | train loss {'Reaction outcome loss': 0.4772039281784511, 'Total loss': 0.4772039281784511}
2022-11-28 05:06:18,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:18,589 INFO:     Epoch: 13
2022-11-28 05:06:19,241 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5109262241180553, 'Total loss': 0.5109262241180553} | train loss {'Reaction outcome loss': 0.47694128531901564, 'Total loss': 0.47694128531901564}
2022-11-28 05:06:19,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:19,241 INFO:     Epoch: 14
2022-11-28 05:06:19,894 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48817904813345087, 'Total loss': 0.48817904813345087} | train loss {'Reaction outcome loss': 0.47826262807748354, 'Total loss': 0.47826262807748354}
2022-11-28 05:06:19,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:19,894 INFO:     Epoch: 15
2022-11-28 05:06:20,549 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4890605897404427, 'Total loss': 0.4890605897404427} | train loss {'Reaction outcome loss': 0.47113509885356075, 'Total loss': 0.47113509885356075}
2022-11-28 05:06:20,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:20,549 INFO:     Epoch: 16
2022-11-28 05:06:21,205 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5098867312420247, 'Total loss': 0.5098867312420247} | train loss {'Reaction outcome loss': 0.48028347867189863, 'Total loss': 0.48028347867189863}
2022-11-28 05:06:21,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:21,205 INFO:     Epoch: 17
2022-11-28 05:06:21,861 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5011549093002496, 'Total loss': 0.5011549093002496} | train loss {'Reaction outcome loss': 0.4705790728330612, 'Total loss': 0.4705790728330612}
2022-11-28 05:06:21,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:21,861 INFO:     Epoch: 18
2022-11-28 05:06:22,519 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5169590531393539, 'Total loss': 0.5169590531393539} | train loss {'Reaction outcome loss': 0.47032259966506335, 'Total loss': 0.47032259966506335}
2022-11-28 05:06:22,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:22,519 INFO:     Epoch: 19
2022-11-28 05:06:23,180 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48933261113111365, 'Total loss': 0.48933261113111365} | train loss {'Reaction outcome loss': 0.46459703074126946, 'Total loss': 0.46459703074126946}
2022-11-28 05:06:23,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:23,180 INFO:     Epoch: 20
2022-11-28 05:06:23,837 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.488544225692749, 'Total loss': 0.488544225692749} | train loss {'Reaction outcome loss': 0.46756825785412165, 'Total loss': 0.46756825785412165}
2022-11-28 05:06:23,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:23,837 INFO:     Epoch: 21
2022-11-28 05:06:24,491 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5062930230484453, 'Total loss': 0.5062930230484453} | train loss {'Reaction outcome loss': 0.4670014626911429, 'Total loss': 0.4670014626911429}
2022-11-28 05:06:24,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:24,492 INFO:     Epoch: 22
2022-11-28 05:06:25,148 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4962203703647436, 'Total loss': 0.4962203703647436} | train loss {'Reaction outcome loss': 0.4710201837244581, 'Total loss': 0.4710201837244581}
2022-11-28 05:06:25,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:25,148 INFO:     Epoch: 23
2022-11-28 05:06:25,807 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.508525704921678, 'Total loss': 0.508525704921678} | train loss {'Reaction outcome loss': 0.4676902220263833, 'Total loss': 0.4676902220263833}
2022-11-28 05:06:25,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:25,808 INFO:     Epoch: 24
2022-11-28 05:06:26,470 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5036961058544558, 'Total loss': 0.5036961058544558} | train loss {'Reaction outcome loss': 0.46518331924911405, 'Total loss': 0.46518331924911405}
2022-11-28 05:06:26,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:26,470 INFO:     Epoch: 25
2022-11-28 05:06:27,126 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4963741884675137, 'Total loss': 0.4963741884675137} | train loss {'Reaction outcome loss': 0.46346039270035555, 'Total loss': 0.46346039270035555}
2022-11-28 05:06:27,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:27,127 INFO:     Epoch: 26
2022-11-28 05:06:27,783 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4851998187774836, 'Total loss': 0.4851998187774836} | train loss {'Reaction outcome loss': 0.47092273196236034, 'Total loss': 0.47092273196236034}
2022-11-28 05:06:27,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:27,784 INFO:     Epoch: 27
2022-11-28 05:06:28,440 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5009490071341048, 'Total loss': 0.5009490071341048} | train loss {'Reaction outcome loss': 0.46393579537751245, 'Total loss': 0.46393579537751245}
2022-11-28 05:06:28,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:28,440 INFO:     Epoch: 28
2022-11-28 05:06:29,097 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4926835908446201, 'Total loss': 0.4926835908446201} | train loss {'Reaction outcome loss': 0.4669847750395048, 'Total loss': 0.4669847750395048}
2022-11-28 05:06:29,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:29,097 INFO:     Epoch: 29
2022-11-28 05:06:29,759 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5635053418403448, 'Total loss': 0.5635053418403448} | train loss {'Reaction outcome loss': 0.46874586337047525, 'Total loss': 0.46874586337047525}
2022-11-28 05:06:29,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:29,759 INFO:     Epoch: 30
2022-11-28 05:06:30,419 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.49036706568196764, 'Total loss': 0.49036706568196764} | train loss {'Reaction outcome loss': 0.4716124844233521, 'Total loss': 0.4716124844233521}
2022-11-28 05:06:30,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:30,419 INFO:     Epoch: 31
2022-11-28 05:06:31,080 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4863984681839167, 'Total loss': 0.4863984681839167} | train loss {'Reaction outcome loss': 0.46629936727466154, 'Total loss': 0.46629936727466154}
2022-11-28 05:06:31,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:31,081 INFO:     Epoch: 32
2022-11-28 05:06:31,742 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48063697163448776, 'Total loss': 0.48063697163448776} | train loss {'Reaction outcome loss': 0.4697976737115227, 'Total loss': 0.4697976737115227}
2022-11-28 05:06:31,742 INFO:     Found new best model at epoch 32
2022-11-28 05:06:31,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:31,743 INFO:     Epoch: 33
2022-11-28 05:06:32,397 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5349046102789945, 'Total loss': 0.5349046102789945} | train loss {'Reaction outcome loss': 0.4620465900687898, 'Total loss': 0.4620465900687898}
2022-11-28 05:06:32,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:32,397 INFO:     Epoch: 34
2022-11-28 05:06:33,049 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47395931912022965, 'Total loss': 0.47395931912022965} | train loss {'Reaction outcome loss': 0.46358379538430544, 'Total loss': 0.46358379538430544}
2022-11-28 05:06:33,049 INFO:     Found new best model at epoch 34
2022-11-28 05:06:33,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:33,050 INFO:     Epoch: 35
2022-11-28 05:06:33,705 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5089444199273753, 'Total loss': 0.5089444199273753} | train loss {'Reaction outcome loss': 0.469071807431393, 'Total loss': 0.469071807431393}
2022-11-28 05:06:33,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:33,706 INFO:     Epoch: 36
2022-11-28 05:06:34,362 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4830024176558783, 'Total loss': 0.4830024176558783} | train loss {'Reaction outcome loss': 0.4617420202884518, 'Total loss': 0.4617420202884518}
2022-11-28 05:06:34,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:34,362 INFO:     Epoch: 37
2022-11-28 05:06:35,017 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4986788315135379, 'Total loss': 0.4986788315135379} | train loss {'Reaction outcome loss': 0.46682595260074883, 'Total loss': 0.46682595260074883}
2022-11-28 05:06:35,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:35,018 INFO:     Epoch: 38
2022-11-28 05:06:35,669 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4768976648879606, 'Total loss': 0.4768976648879606} | train loss {'Reaction outcome loss': 0.4686836327013911, 'Total loss': 0.4686836327013911}
2022-11-28 05:06:35,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:35,669 INFO:     Epoch: 39
2022-11-28 05:06:36,319 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48945361029270085, 'Total loss': 0.48945361029270085} | train loss {'Reaction outcome loss': 0.467502339880486, 'Total loss': 0.467502339880486}
2022-11-28 05:06:36,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:36,319 INFO:     Epoch: 40
2022-11-28 05:06:36,975 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48953548870807473, 'Total loss': 0.48953548870807473} | train loss {'Reaction outcome loss': 0.46587491670592884, 'Total loss': 0.46587491670592884}
2022-11-28 05:06:36,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:36,975 INFO:     Epoch: 41
2022-11-28 05:06:37,630 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5604239352220712, 'Total loss': 0.5604239352220712} | train loss {'Reaction outcome loss': 0.46693303356649446, 'Total loss': 0.46693303356649446}
2022-11-28 05:06:37,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:37,630 INFO:     Epoch: 42
2022-11-28 05:06:38,282 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5006512452003568, 'Total loss': 0.5006512452003568} | train loss {'Reaction outcome loss': 0.4710141723883934, 'Total loss': 0.4710141723883934}
2022-11-28 05:06:38,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:38,284 INFO:     Epoch: 43
2022-11-28 05:06:38,933 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48491426054821457, 'Total loss': 0.48491426054821457} | train loss {'Reaction outcome loss': 0.46334995075938157, 'Total loss': 0.46334995075938157}
2022-11-28 05:06:38,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:38,933 INFO:     Epoch: 44
2022-11-28 05:06:39,587 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.51300100774266, 'Total loss': 0.51300100774266} | train loss {'Reaction outcome loss': 0.4592860420463515, 'Total loss': 0.4592860420463515}
2022-11-28 05:06:39,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:39,587 INFO:     Epoch: 45
2022-11-28 05:06:40,240 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4865654523289481, 'Total loss': 0.4865654523289481} | train loss {'Reaction outcome loss': 0.4687084796243027, 'Total loss': 0.4687084796243027}
2022-11-28 05:06:40,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:40,240 INFO:     Epoch: 46
2022-11-28 05:06:40,891 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4939714507308117, 'Total loss': 0.4939714507308117} | train loss {'Reaction outcome loss': 0.4652824864157888, 'Total loss': 0.4652824864157888}
2022-11-28 05:06:40,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:40,891 INFO:     Epoch: 47
2022-11-28 05:06:41,547 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.49174106571563453, 'Total loss': 0.49174106571563453} | train loss {'Reaction outcome loss': 0.4629967815441186, 'Total loss': 0.4629967815441186}
2022-11-28 05:06:41,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:41,547 INFO:     Epoch: 48
2022-11-28 05:06:42,201 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5048615779987601, 'Total loss': 0.5048615779987601} | train loss {'Reaction outcome loss': 0.46922130272036694, 'Total loss': 0.46922130272036694}
2022-11-28 05:06:42,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:42,202 INFO:     Epoch: 49
2022-11-28 05:06:42,853 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4891360429830329, 'Total loss': 0.4891360429830329} | train loss {'Reaction outcome loss': 0.4612456418451716, 'Total loss': 0.4612456418451716}
2022-11-28 05:06:42,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:42,854 INFO:     Epoch: 50
2022-11-28 05:06:43,509 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5171476623346639, 'Total loss': 0.5171476623346639} | train loss {'Reaction outcome loss': 0.45763092237662095, 'Total loss': 0.45763092237662095}
2022-11-28 05:06:43,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:43,509 INFO:     Epoch: 51
2022-11-28 05:06:44,159 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5487105856801189, 'Total loss': 0.5487105856801189} | train loss {'Reaction outcome loss': 0.4556013302969151, 'Total loss': 0.4556013302969151}
2022-11-28 05:06:44,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:44,159 INFO:     Epoch: 52
2022-11-28 05:06:44,807 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46759632160497266, 'Total loss': 0.46759632160497266} | train loss {'Reaction outcome loss': 0.4612670215304758, 'Total loss': 0.4612670215304758}
2022-11-28 05:06:44,808 INFO:     Found new best model at epoch 52
2022-11-28 05:06:44,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:44,809 INFO:     Epoch: 53
2022-11-28 05:06:45,459 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47562390253987424, 'Total loss': 0.47562390253987424} | train loss {'Reaction outcome loss': 0.4604983545961927, 'Total loss': 0.4604983545961927}
2022-11-28 05:06:45,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:45,459 INFO:     Epoch: 54
2022-11-28 05:06:46,108 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4799465550932773, 'Total loss': 0.4799465550932773} | train loss {'Reaction outcome loss': 0.4627710624796445, 'Total loss': 0.4627710624796445}
2022-11-28 05:06:46,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:46,109 INFO:     Epoch: 55
2022-11-28 05:06:46,762 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48668542469656745, 'Total loss': 0.48668542469656745} | train loss {'Reaction outcome loss': 0.46329259988470156, 'Total loss': 0.46329259988470156}
2022-11-28 05:06:46,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:46,763 INFO:     Epoch: 56
2022-11-28 05:06:47,415 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.489273140596789, 'Total loss': 0.489273140596789} | train loss {'Reaction outcome loss': 0.4620424247056734, 'Total loss': 0.4620424247056734}
2022-11-28 05:06:47,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:47,415 INFO:     Epoch: 57
2022-11-28 05:06:48,067 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4725634431423143, 'Total loss': 0.4725634431423143} | train loss {'Reaction outcome loss': 0.4658669651653923, 'Total loss': 0.4658669651653923}
2022-11-28 05:06:48,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:48,067 INFO:     Epoch: 58
2022-11-28 05:06:48,718 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48844742532386337, 'Total loss': 0.48844742532386337} | train loss {'Reaction outcome loss': 0.4595622440464184, 'Total loss': 0.4595622440464184}
2022-11-28 05:06:48,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:48,718 INFO:     Epoch: 59
2022-11-28 05:06:49,370 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47704043637874516, 'Total loss': 0.47704043637874516} | train loss {'Reaction outcome loss': 0.462979025131122, 'Total loss': 0.462979025131122}
2022-11-28 05:06:49,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:49,370 INFO:     Epoch: 60
2022-11-28 05:06:50,024 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49952481201914856, 'Total loss': 0.49952481201914856} | train loss {'Reaction outcome loss': 0.46071478287826795, 'Total loss': 0.46071478287826795}
2022-11-28 05:06:50,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:50,024 INFO:     Epoch: 61
2022-11-28 05:06:50,673 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5081003183542296, 'Total loss': 0.5081003183542296} | train loss {'Reaction outcome loss': 0.4653779561402368, 'Total loss': 0.4653779561402368}
2022-11-28 05:06:50,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:50,673 INFO:     Epoch: 62
2022-11-28 05:06:51,324 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5003749447506528, 'Total loss': 0.5003749447506528} | train loss {'Reaction outcome loss': 0.46097644589474945, 'Total loss': 0.46097644589474945}
2022-11-28 05:06:51,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:51,324 INFO:     Epoch: 63
2022-11-28 05:06:51,975 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5041530894678693, 'Total loss': 0.5041530894678693} | train loss {'Reaction outcome loss': 0.4602129620606782, 'Total loss': 0.4602129620606782}
2022-11-28 05:06:51,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:51,976 INFO:     Epoch: 64
2022-11-28 05:06:52,625 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4877866610538128, 'Total loss': 0.4877866610538128} | train loss {'Reaction outcome loss': 0.4635237414450919, 'Total loss': 0.4635237414450919}
2022-11-28 05:06:52,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:52,625 INFO:     Epoch: 65
2022-11-28 05:06:53,277 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5246877739595812, 'Total loss': 0.5246877739595812} | train loss {'Reaction outcome loss': 0.4632217754594615, 'Total loss': 0.4632217754594615}
2022-11-28 05:06:53,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:53,278 INFO:     Epoch: 66
2022-11-28 05:06:53,929 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5010703226854635, 'Total loss': 0.5010703226854635} | train loss {'Reaction outcome loss': 0.46072099876941225, 'Total loss': 0.46072099876941225}
2022-11-28 05:06:53,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:53,929 INFO:     Epoch: 67
2022-11-28 05:06:54,581 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5011393192202546, 'Total loss': 0.5011393192202546} | train loss {'Reaction outcome loss': 0.4652128888935339, 'Total loss': 0.4652128888935339}
2022-11-28 05:06:54,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:54,582 INFO:     Epoch: 68
2022-11-28 05:06:55,234 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48984642188216365, 'Total loss': 0.48984642188216365} | train loss {'Reaction outcome loss': 0.4618250896207622, 'Total loss': 0.4618250896207622}
2022-11-28 05:06:55,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:55,234 INFO:     Epoch: 69
2022-11-28 05:06:55,883 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5320738664893216, 'Total loss': 0.5320738664893216} | train loss {'Reaction outcome loss': 0.45812522369574327, 'Total loss': 0.45812522369574327}
2022-11-28 05:06:55,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:55,883 INFO:     Epoch: 70
2022-11-28 05:06:56,540 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.506181443846503, 'Total loss': 0.506181443846503} | train loss {'Reaction outcome loss': 0.46524393057725466, 'Total loss': 0.46524393057725466}
2022-11-28 05:06:56,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:56,540 INFO:     Epoch: 71
2022-11-28 05:06:57,196 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5489099296026452, 'Total loss': 0.5489099296026452} | train loss {'Reaction outcome loss': 0.45716287592639687, 'Total loss': 0.45716287592639687}
2022-11-28 05:06:57,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:57,197 INFO:     Epoch: 72
2022-11-28 05:06:57,852 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4921398311853409, 'Total loss': 0.4921398311853409} | train loss {'Reaction outcome loss': 0.46421443780914684, 'Total loss': 0.46421443780914684}
2022-11-28 05:06:57,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:57,852 INFO:     Epoch: 73
2022-11-28 05:06:58,510 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48440590188946836, 'Total loss': 0.48440590188946836} | train loss {'Reaction outcome loss': 0.46768600252441694, 'Total loss': 0.46768600252441694}
2022-11-28 05:06:58,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:58,510 INFO:     Epoch: 74
2022-11-28 05:06:59,167 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4964946716330772, 'Total loss': 0.4964946716330772} | train loss {'Reaction outcome loss': 0.46610347346448505, 'Total loss': 0.46610347346448505}
2022-11-28 05:06:59,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:59,167 INFO:     Epoch: 75
2022-11-28 05:06:59,822 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4911857878052911, 'Total loss': 0.4911857878052911} | train loss {'Reaction outcome loss': 0.4567962916659527, 'Total loss': 0.4567962916659527}
2022-11-28 05:06:59,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:06:59,822 INFO:     Epoch: 76
2022-11-28 05:07:00,475 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5118433084598807, 'Total loss': 0.5118433084598807} | train loss {'Reaction outcome loss': 0.46045732809627643, 'Total loss': 0.46045732809627643}
2022-11-28 05:07:00,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:00,475 INFO:     Epoch: 77
2022-11-28 05:07:01,127 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4890526318272879, 'Total loss': 0.4890526318272879} | train loss {'Reaction outcome loss': 0.45960834512456517, 'Total loss': 0.45960834512456517}
2022-11-28 05:07:01,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:01,127 INFO:     Epoch: 78
2022-11-28 05:07:01,778 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49241662510605744, 'Total loss': 0.49241662510605744} | train loss {'Reaction outcome loss': 0.45963129181353773, 'Total loss': 0.45963129181353773}
2022-11-28 05:07:01,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:01,779 INFO:     Epoch: 79
2022-11-28 05:07:02,431 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4858423117981401, 'Total loss': 0.4858423117981401} | train loss {'Reaction outcome loss': 0.46075620471698336, 'Total loss': 0.46075620471698336}
2022-11-28 05:07:02,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:02,431 INFO:     Epoch: 80
2022-11-28 05:07:03,082 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48983507794003156, 'Total loss': 0.48983507794003156} | train loss {'Reaction outcome loss': 0.4622507371374818, 'Total loss': 0.4622507371374818}
2022-11-28 05:07:03,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:03,082 INFO:     Epoch: 81
2022-11-28 05:07:03,735 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5023118416930354, 'Total loss': 0.5023118416930354} | train loss {'Reaction outcome loss': 0.46728625863057666, 'Total loss': 0.46728625863057666}
2022-11-28 05:07:03,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:03,736 INFO:     Epoch: 82
2022-11-28 05:07:04,388 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5132322276747504, 'Total loss': 0.5132322276747504} | train loss {'Reaction outcome loss': 0.4702144885038743, 'Total loss': 0.4702144885038743}
2022-11-28 05:07:04,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:04,388 INFO:     Epoch: 83
2022-11-28 05:07:05,040 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5044898584831593, 'Total loss': 0.5044898584831593} | train loss {'Reaction outcome loss': 0.46272155892897826, 'Total loss': 0.46272155892897826}
2022-11-28 05:07:05,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:05,040 INFO:     Epoch: 84
2022-11-28 05:07:05,693 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4766318330238032, 'Total loss': 0.4766318330238032} | train loss {'Reaction outcome loss': 0.45694791696599274, 'Total loss': 0.45694791696599274}
2022-11-28 05:07:05,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:05,693 INFO:     Epoch: 85
2022-11-28 05:07:06,345 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49313051340191866, 'Total loss': 0.49313051340191866} | train loss {'Reaction outcome loss': 0.46635233635296586, 'Total loss': 0.46635233635296586}
2022-11-28 05:07:06,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:06,345 INFO:     Epoch: 86
2022-11-28 05:07:06,996 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5015534484802291, 'Total loss': 0.5015534484802291} | train loss {'Reaction outcome loss': 0.46375465393066406, 'Total loss': 0.46375465393066406}
2022-11-28 05:07:06,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:06,997 INFO:     Epoch: 87
2022-11-28 05:07:07,653 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4923434001068736, 'Total loss': 0.4923434001068736} | train loss {'Reaction outcome loss': 0.46356256629844184, 'Total loss': 0.46356256629844184}
2022-11-28 05:07:07,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:07,653 INFO:     Epoch: 88
2022-11-28 05:07:08,301 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4756101314411607, 'Total loss': 0.4756101314411607} | train loss {'Reaction outcome loss': 0.46356041204245363, 'Total loss': 0.46356041204245363}
2022-11-28 05:07:08,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:08,302 INFO:     Epoch: 89
2022-11-28 05:07:08,950 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5026038018769996, 'Total loss': 0.5026038018769996} | train loss {'Reaction outcome loss': 0.4580018612571427, 'Total loss': 0.4580018612571427}
2022-11-28 05:07:08,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:08,952 INFO:     Epoch: 90
2022-11-28 05:07:09,600 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4772398950055588, 'Total loss': 0.4772398950055588} | train loss {'Reaction outcome loss': 0.46154649647288637, 'Total loss': 0.46154649647288637}
2022-11-28 05:07:09,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:09,601 INFO:     Epoch: 91
2022-11-28 05:07:10,250 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5121006321075351, 'Total loss': 0.5121006321075351} | train loss {'Reaction outcome loss': 0.46188871492250044, 'Total loss': 0.46188871492250044}
2022-11-28 05:07:10,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:10,250 INFO:     Epoch: 92
2022-11-28 05:07:10,906 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.506152001924293, 'Total loss': 0.506152001924293} | train loss {'Reaction outcome loss': 0.4608743828339655, 'Total loss': 0.4608743828339655}
2022-11-28 05:07:10,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:10,906 INFO:     Epoch: 93
2022-11-28 05:07:11,561 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5441467671893364, 'Total loss': 0.5441467671893364} | train loss {'Reaction outcome loss': 0.46141206503647275, 'Total loss': 0.46141206503647275}
2022-11-28 05:07:11,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:11,561 INFO:     Epoch: 94
2022-11-28 05:07:12,213 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48600072569625324, 'Total loss': 0.48600072569625324} | train loss {'Reaction outcome loss': 0.4653294058363946, 'Total loss': 0.4653294058363946}
2022-11-28 05:07:12,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:12,213 INFO:     Epoch: 95
2022-11-28 05:07:12,867 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4868471068005229, 'Total loss': 0.4868471068005229} | train loss {'Reaction outcome loss': 0.4560727945483122, 'Total loss': 0.4560727945483122}
2022-11-28 05:07:12,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:12,867 INFO:     Epoch: 96
2022-11-28 05:07:13,518 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4975445821534756, 'Total loss': 0.4975445821534756} | train loss {'Reaction outcome loss': 0.46145748786750385, 'Total loss': 0.46145748786750385}
2022-11-28 05:07:13,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:13,518 INFO:     Epoch: 97
2022-11-28 05:07:14,166 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49880212094894677, 'Total loss': 0.49880212094894677} | train loss {'Reaction outcome loss': 0.46789103465490656, 'Total loss': 0.46789103465490656}
2022-11-28 05:07:14,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:14,167 INFO:     Epoch: 98
2022-11-28 05:07:14,819 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49595331036767293, 'Total loss': 0.49595331036767293} | train loss {'Reaction outcome loss': 0.46014339018796313, 'Total loss': 0.46014339018796313}
2022-11-28 05:07:14,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:14,819 INFO:     Epoch: 99
2022-11-28 05:07:15,474 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5167352522528449, 'Total loss': 0.5167352522528449} | train loss {'Reaction outcome loss': 0.4558257751899665, 'Total loss': 0.4558257751899665}
2022-11-28 05:07:15,475 INFO:     Best model found after epoch 53 of 100.
2022-11-28 05:07:15,475 INFO:   Done with stage: TRAINING
2022-11-28 05:07:15,475 INFO:   Starting stage: EVALUATION
2022-11-28 05:07:15,603 INFO:   Done with stage: EVALUATION
2022-11-28 05:07:15,603 INFO:   Leaving out SEQ value Fold_1
2022-11-28 05:07:15,616 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 05:07:15,616 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:07:16,245 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:07:16,245 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:07:16,314 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:07:16,314 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:07:16,314 INFO:     No hyperparam tuning for this model
2022-11-28 05:07:16,314 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:07:16,314 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:07:16,315 INFO:     None feature selector for col prot
2022-11-28 05:07:16,315 INFO:     None feature selector for col prot
2022-11-28 05:07:16,315 INFO:     None feature selector for col prot
2022-11-28 05:07:16,316 INFO:     None feature selector for col chem
2022-11-28 05:07:16,316 INFO:     None feature selector for col chem
2022-11-28 05:07:16,316 INFO:     None feature selector for col chem
2022-11-28 05:07:16,316 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:07:16,316 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:07:16,317 INFO:     Number of params in model 169651
2022-11-28 05:07:16,320 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:07:16,320 INFO:   Starting stage: TRAINING
2022-11-28 05:07:16,370 INFO:     Val loss before train {'Reaction outcome loss': 1.0016521391543476, 'Total loss': 1.0016521391543476}
2022-11-28 05:07:16,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:16,370 INFO:     Epoch: 0
2022-11-28 05:07:17,025 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5879226526753469, 'Total loss': 0.5879226526753469} | train loss {'Reaction outcome loss': 0.6915186261644168, 'Total loss': 0.6915186261644168}
2022-11-28 05:07:17,025 INFO:     Found new best model at epoch 0
2022-11-28 05:07:17,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:17,026 INFO:     Epoch: 1
2022-11-28 05:07:17,679 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5965012061324987, 'Total loss': 0.5965012061324987} | train loss {'Reaction outcome loss': 0.5895997200693402, 'Total loss': 0.5895997200693402}
2022-11-28 05:07:17,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:17,679 INFO:     Epoch: 2
2022-11-28 05:07:18,331 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.57111681625247, 'Total loss': 0.57111681625247} | train loss {'Reaction outcome loss': 0.5578179846004564, 'Total loss': 0.5578179846004564}
2022-11-28 05:07:18,331 INFO:     Found new best model at epoch 2
2022-11-28 05:07:18,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:18,332 INFO:     Epoch: 3
2022-11-28 05:07:18,986 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5103633183647286, 'Total loss': 0.5103633183647286} | train loss {'Reaction outcome loss': 0.541901382864738, 'Total loss': 0.541901382864738}
2022-11-28 05:07:18,986 INFO:     Found new best model at epoch 3
2022-11-28 05:07:18,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:18,987 INFO:     Epoch: 4
2022-11-28 05:07:19,637 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5401005636562001, 'Total loss': 0.5401005636562001} | train loss {'Reaction outcome loss': 0.5224023842689942, 'Total loss': 0.5224023842689942}
2022-11-28 05:07:19,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:19,637 INFO:     Epoch: 5
2022-11-28 05:07:20,289 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4993373673747886, 'Total loss': 0.4993373673747886} | train loss {'Reaction outcome loss': 0.5140192226487763, 'Total loss': 0.5140192226487763}
2022-11-28 05:07:20,289 INFO:     Found new best model at epoch 5
2022-11-28 05:07:20,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:20,289 INFO:     Epoch: 6
2022-11-28 05:07:20,942 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5341883000325073, 'Total loss': 0.5341883000325073} | train loss {'Reaction outcome loss': 0.5084496104595613, 'Total loss': 0.5084496104595613}
2022-11-28 05:07:20,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:20,942 INFO:     Epoch: 7
2022-11-28 05:07:21,595 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5459078618071296, 'Total loss': 0.5459078618071296} | train loss {'Reaction outcome loss': 0.5041934647122208, 'Total loss': 0.5041934647122208}
2022-11-28 05:07:21,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:21,595 INFO:     Epoch: 8
2022-11-28 05:07:22,246 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5332480520009995, 'Total loss': 0.5332480520009995} | train loss {'Reaction outcome loss': 0.5102883676485139, 'Total loss': 0.5102883676485139}
2022-11-28 05:07:22,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:22,246 INFO:     Epoch: 9
2022-11-28 05:07:22,903 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5360680283470587, 'Total loss': 0.5360680283470587} | train loss {'Reaction outcome loss': 0.4979966453751739, 'Total loss': 0.4979966453751739}
2022-11-28 05:07:22,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:22,903 INFO:     Epoch: 10
2022-11-28 05:07:23,561 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4639996649189429, 'Total loss': 0.4639996649189429} | train loss {'Reaction outcome loss': 0.49629844962334146, 'Total loss': 0.49629844962334146}
2022-11-28 05:07:23,561 INFO:     Found new best model at epoch 10
2022-11-28 05:07:23,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:23,562 INFO:     Epoch: 11
2022-11-28 05:07:24,221 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4948131408203732, 'Total loss': 0.4948131408203732} | train loss {'Reaction outcome loss': 0.48946231214367614, 'Total loss': 0.48946231214367614}
2022-11-28 05:07:24,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:24,221 INFO:     Epoch: 12
2022-11-28 05:07:24,874 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5229612091048197, 'Total loss': 0.5229612091048197} | train loss {'Reaction outcome loss': 0.491663720291488, 'Total loss': 0.491663720291488}
2022-11-28 05:07:24,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:24,875 INFO:     Epoch: 13
2022-11-28 05:07:25,531 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49593950740315695, 'Total loss': 0.49593950740315695} | train loss {'Reaction outcome loss': 0.4826666101509211, 'Total loss': 0.4826666101509211}
2022-11-28 05:07:25,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:25,531 INFO:     Epoch: 14
2022-11-28 05:07:26,186 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4811795123598792, 'Total loss': 0.4811795123598792} | train loss {'Reaction outcome loss': 0.4887556802253334, 'Total loss': 0.4887556802253334}
2022-11-28 05:07:26,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:26,186 INFO:     Epoch: 15
2022-11-28 05:07:26,849 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4885655123401772, 'Total loss': 0.4885655123401772} | train loss {'Reaction outcome loss': 0.49207242033919507, 'Total loss': 0.49207242033919507}
2022-11-28 05:07:26,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:26,849 INFO:     Epoch: 16
2022-11-28 05:07:27,509 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5231991582973436, 'Total loss': 0.5231991582973436} | train loss {'Reaction outcome loss': 0.4879040467495821, 'Total loss': 0.4879040467495821}
2022-11-28 05:07:27,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:27,510 INFO:     Epoch: 17
2022-11-28 05:07:28,172 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4513231607323343, 'Total loss': 0.4513231607323343} | train loss {'Reaction outcome loss': 0.4868015690117466, 'Total loss': 0.4868015690117466}
2022-11-28 05:07:28,172 INFO:     Found new best model at epoch 17
2022-11-28 05:07:28,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:28,173 INFO:     Epoch: 18
2022-11-28 05:07:28,831 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49574816768819635, 'Total loss': 0.49574816768819635} | train loss {'Reaction outcome loss': 0.4934039904146778, 'Total loss': 0.4934039904146778}
2022-11-28 05:07:28,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:28,831 INFO:     Epoch: 19
2022-11-28 05:07:29,490 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47235655479810457, 'Total loss': 0.47235655479810457} | train loss {'Reaction outcome loss': 0.4875751357905719, 'Total loss': 0.4875751357905719}
2022-11-28 05:07:29,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:29,491 INFO:     Epoch: 20
2022-11-28 05:07:30,150 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4829159121621739, 'Total loss': 0.4829159121621739} | train loss {'Reaction outcome loss': 0.4820372701907644, 'Total loss': 0.4820372701907644}
2022-11-28 05:07:30,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:30,151 INFO:     Epoch: 21
2022-11-28 05:07:30,811 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5138538798147981, 'Total loss': 0.5138538798147981} | train loss {'Reaction outcome loss': 0.48470734905223456, 'Total loss': 0.48470734905223456}
2022-11-28 05:07:30,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:30,811 INFO:     Epoch: 22
2022-11-28 05:07:31,470 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5060595328157599, 'Total loss': 0.5060595328157599} | train loss {'Reaction outcome loss': 0.4800819172542922, 'Total loss': 0.4800819172542922}
2022-11-28 05:07:31,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:31,470 INFO:     Epoch: 23
2022-11-28 05:07:32,130 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4598950137468902, 'Total loss': 0.4598950137468902} | train loss {'Reaction outcome loss': 0.48472084792292847, 'Total loss': 0.48472084792292847}
2022-11-28 05:07:32,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:32,130 INFO:     Epoch: 24
2022-11-28 05:07:32,789 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5031465674665841, 'Total loss': 0.5031465674665841} | train loss {'Reaction outcome loss': 0.48119875216970637, 'Total loss': 0.48119875216970637}
2022-11-28 05:07:32,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:32,789 INFO:     Epoch: 25
2022-11-28 05:07:33,445 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4764487181197513, 'Total loss': 0.4764487181197513} | train loss {'Reaction outcome loss': 0.4805280325972304, 'Total loss': 0.4805280325972304}
2022-11-28 05:07:33,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:33,445 INFO:     Epoch: 26
2022-11-28 05:07:34,103 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48702742430296814, 'Total loss': 0.48702742430296814} | train loss {'Reaction outcome loss': 0.4802066230044073, 'Total loss': 0.4802066230044073}
2022-11-28 05:07:34,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:34,103 INFO:     Epoch: 27
2022-11-28 05:07:34,762 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5023825717243281, 'Total loss': 0.5023825717243281} | train loss {'Reaction outcome loss': 0.4831724030630929, 'Total loss': 0.4831724030630929}
2022-11-28 05:07:34,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:34,763 INFO:     Epoch: 28
2022-11-28 05:07:35,425 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4790890839120204, 'Total loss': 0.4790890839120204} | train loss {'Reaction outcome loss': 0.4854876962851505, 'Total loss': 0.4854876962851505}
2022-11-28 05:07:35,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:35,425 INFO:     Epoch: 29
2022-11-28 05:07:36,085 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5094747120006518, 'Total loss': 0.5094747120006518} | train loss {'Reaction outcome loss': 0.47928179532897713, 'Total loss': 0.47928179532897713}
2022-11-28 05:07:36,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:36,085 INFO:     Epoch: 30
2022-11-28 05:07:36,744 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46800555424256757, 'Total loss': 0.46800555424256757} | train loss {'Reaction outcome loss': 0.4769128283067625, 'Total loss': 0.4769128283067625}
2022-11-28 05:07:36,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:36,745 INFO:     Epoch: 31
2022-11-28 05:07:37,403 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46149175410920923, 'Total loss': 0.46149175410920923} | train loss {'Reaction outcome loss': 0.48701630094829873, 'Total loss': 0.48701630094829873}
2022-11-28 05:07:37,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:37,403 INFO:     Epoch: 32
2022-11-28 05:07:38,059 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48532655157826166, 'Total loss': 0.48532655157826166} | train loss {'Reaction outcome loss': 0.47605076669430246, 'Total loss': 0.47605076669430246}
2022-11-28 05:07:38,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:38,059 INFO:     Epoch: 33
2022-11-28 05:07:38,716 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4667951451106505, 'Total loss': 0.4667951451106505} | train loss {'Reaction outcome loss': 0.4782976575651947, 'Total loss': 0.4782976575651947}
2022-11-28 05:07:38,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:38,717 INFO:     Epoch: 34
2022-11-28 05:07:39,380 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45891961082816124, 'Total loss': 0.45891961082816124} | train loss {'Reaction outcome loss': 0.48545569619353934, 'Total loss': 0.48545569619353934}
2022-11-28 05:07:39,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:39,381 INFO:     Epoch: 35
2022-11-28 05:07:40,042 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4800733652981845, 'Total loss': 0.4800733652981845} | train loss {'Reaction outcome loss': 0.4863565320871314, 'Total loss': 0.4863565320871314}
2022-11-28 05:07:40,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:40,042 INFO:     Epoch: 36
2022-11-28 05:07:40,703 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4883849434554577, 'Total loss': 0.4883849434554577} | train loss {'Reaction outcome loss': 0.48656633027962276, 'Total loss': 0.48656633027962276}
2022-11-28 05:07:40,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:40,703 INFO:     Epoch: 37
2022-11-28 05:07:41,366 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4856015714732083, 'Total loss': 0.4856015714732083} | train loss {'Reaction outcome loss': 0.47800993511871415, 'Total loss': 0.47800993511871415}
2022-11-28 05:07:41,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:41,366 INFO:     Epoch: 38
2022-11-28 05:07:42,027 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4891121912408959, 'Total loss': 0.4891121912408959} | train loss {'Reaction outcome loss': 0.48238794681977254, 'Total loss': 0.48238794681977254}
2022-11-28 05:07:42,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:42,027 INFO:     Epoch: 39
2022-11-28 05:07:42,687 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4793925810266625, 'Total loss': 0.4793925810266625} | train loss {'Reaction outcome loss': 0.481599864971881, 'Total loss': 0.481599864971881}
2022-11-28 05:07:42,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:42,687 INFO:     Epoch: 40
2022-11-28 05:07:43,350 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.49667487835342233, 'Total loss': 0.49667487835342233} | train loss {'Reaction outcome loss': 0.48162160686084204, 'Total loss': 0.48162160686084204}
2022-11-28 05:07:43,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:43,350 INFO:     Epoch: 41
2022-11-28 05:07:44,012 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4670639329335906, 'Total loss': 0.4670639329335906} | train loss {'Reaction outcome loss': 0.4800072363444737, 'Total loss': 0.4800072363444737}
2022-11-28 05:07:44,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:44,013 INFO:     Epoch: 42
2022-11-28 05:07:44,673 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46914817223494704, 'Total loss': 0.46914817223494704} | train loss {'Reaction outcome loss': 0.48229704657379463, 'Total loss': 0.48229704657379463}
2022-11-28 05:07:44,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:44,673 INFO:     Epoch: 43
2022-11-28 05:07:45,339 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46418558281253686, 'Total loss': 0.46418558281253686} | train loss {'Reaction outcome loss': 0.48231121809506905, 'Total loss': 0.48231121809506905}
2022-11-28 05:07:45,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:45,340 INFO:     Epoch: 44
2022-11-28 05:07:46,005 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4681475921110673, 'Total loss': 0.4681475921110673} | train loss {'Reaction outcome loss': 0.48071318384335965, 'Total loss': 0.48071318384335965}
2022-11-28 05:07:46,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:46,006 INFO:     Epoch: 45
2022-11-28 05:07:46,666 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4784021336923946, 'Total loss': 0.4784021336923946} | train loss {'Reaction outcome loss': 0.47298000728597445, 'Total loss': 0.47298000728597445}
2022-11-28 05:07:46,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:46,667 INFO:     Epoch: 46
2022-11-28 05:07:47,333 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5069812827489593, 'Total loss': 0.5069812827489593} | train loss {'Reaction outcome loss': 0.4813722081330358, 'Total loss': 0.4813722081330358}
2022-11-28 05:07:47,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:47,333 INFO:     Epoch: 47
2022-11-28 05:07:47,996 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4815849763425914, 'Total loss': 0.4815849763425914} | train loss {'Reaction outcome loss': 0.4781521944367156, 'Total loss': 0.4781521944367156}
2022-11-28 05:07:47,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:47,996 INFO:     Epoch: 48
2022-11-28 05:07:48,659 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48470061577179213, 'Total loss': 0.48470061577179213} | train loss {'Reaction outcome loss': 0.47845604006125003, 'Total loss': 0.47845604006125003}
2022-11-28 05:07:48,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:48,659 INFO:     Epoch: 49
2022-11-28 05:07:49,323 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48410063507882034, 'Total loss': 0.48410063507882034} | train loss {'Reaction outcome loss': 0.48407282367044563, 'Total loss': 0.48407282367044563}
2022-11-28 05:07:49,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:49,323 INFO:     Epoch: 50
2022-11-28 05:07:49,987 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.538657870651646, 'Total loss': 0.538657870651646} | train loss {'Reaction outcome loss': 0.4823174150622621, 'Total loss': 0.4823174150622621}
2022-11-28 05:07:49,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:49,987 INFO:     Epoch: 51
2022-11-28 05:07:50,646 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48067371445623314, 'Total loss': 0.48067371445623314} | train loss {'Reaction outcome loss': 0.4863682729249098, 'Total loss': 0.4863682729249098}
2022-11-28 05:07:50,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:50,647 INFO:     Epoch: 52
2022-11-28 05:07:51,309 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4686841419474645, 'Total loss': 0.4686841419474645} | train loss {'Reaction outcome loss': 0.48376364768767843, 'Total loss': 0.48376364768767843}
2022-11-28 05:07:51,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:51,309 INFO:     Epoch: 53
2022-11-28 05:07:51,971 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4695154475894841, 'Total loss': 0.4695154475894841} | train loss {'Reaction outcome loss': 0.48389442398840066, 'Total loss': 0.48389442398840066}
2022-11-28 05:07:51,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:51,971 INFO:     Epoch: 54
2022-11-28 05:07:52,635 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48253083567727695, 'Total loss': 0.48253083567727695} | train loss {'Reaction outcome loss': 0.47534920220472376, 'Total loss': 0.47534920220472376}
2022-11-28 05:07:52,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:52,635 INFO:     Epoch: 55
2022-11-28 05:07:53,303 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46547386778349226, 'Total loss': 0.46547386778349226} | train loss {'Reaction outcome loss': 0.4791699147954279, 'Total loss': 0.4791699147954279}
2022-11-28 05:07:53,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:53,304 INFO:     Epoch: 56
2022-11-28 05:07:53,968 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47113753110170364, 'Total loss': 0.47113753110170364} | train loss {'Reaction outcome loss': 0.4787290279962579, 'Total loss': 0.4787290279962579}
2022-11-28 05:07:53,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:53,968 INFO:     Epoch: 57
2022-11-28 05:07:54,630 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5195776505226438, 'Total loss': 0.5195776505226438} | train loss {'Reaction outcome loss': 0.4731000630223021, 'Total loss': 0.4731000630223021}
2022-11-28 05:07:54,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:54,630 INFO:     Epoch: 58
2022-11-28 05:07:55,296 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4691686694594947, 'Total loss': 0.4691686694594947} | train loss {'Reaction outcome loss': 0.4804344621848087, 'Total loss': 0.4804344621848087}
2022-11-28 05:07:55,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:55,297 INFO:     Epoch: 59
2022-11-28 05:07:55,960 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4654508832503449, 'Total loss': 0.4654508832503449} | train loss {'Reaction outcome loss': 0.48288372219825276, 'Total loss': 0.48288372219825276}
2022-11-28 05:07:55,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:55,960 INFO:     Epoch: 60
2022-11-28 05:07:56,622 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49971370094201784, 'Total loss': 0.49971370094201784} | train loss {'Reaction outcome loss': 0.47820502033039014, 'Total loss': 0.47820502033039014}
2022-11-28 05:07:56,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:56,623 INFO:     Epoch: 61
2022-11-28 05:07:57,287 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47008956697854126, 'Total loss': 0.47008956697854126} | train loss {'Reaction outcome loss': 0.48181124049790053, 'Total loss': 0.48181124049790053}
2022-11-28 05:07:57,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:57,288 INFO:     Epoch: 62
2022-11-28 05:07:57,951 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5046393918720159, 'Total loss': 0.5046393918720159} | train loss {'Reaction outcome loss': 0.4788680473152472, 'Total loss': 0.4788680473152472}
2022-11-28 05:07:57,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:57,951 INFO:     Epoch: 63
2022-11-28 05:07:58,612 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4998842410065911, 'Total loss': 0.4998842410065911} | train loss {'Reaction outcome loss': 0.4744161336397638, 'Total loss': 0.4744161336397638}
2022-11-28 05:07:58,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:58,613 INFO:     Epoch: 64
2022-11-28 05:07:59,277 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.458681209012866, 'Total loss': 0.458681209012866} | train loss {'Reaction outcome loss': 0.48500623368487067, 'Total loss': 0.48500623368487067}
2022-11-28 05:07:59,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:59,277 INFO:     Epoch: 65
2022-11-28 05:07:59,941 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47234922512011096, 'Total loss': 0.47234922512011096} | train loss {'Reaction outcome loss': 0.48321815808208624, 'Total loss': 0.48321815808208624}
2022-11-28 05:07:59,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:07:59,942 INFO:     Epoch: 66
2022-11-28 05:08:00,611 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4595991024239497, 'Total loss': 0.4595991024239497} | train loss {'Reaction outcome loss': 0.47585404186832664, 'Total loss': 0.47585404186832664}
2022-11-28 05:08:00,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:00,611 INFO:     Epoch: 67
2022-11-28 05:08:01,281 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47282628816637123, 'Total loss': 0.47282628816637123} | train loss {'Reaction outcome loss': 0.4844966189593685, 'Total loss': 0.4844966189593685}
2022-11-28 05:08:01,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:01,282 INFO:     Epoch: 68
2022-11-28 05:08:01,949 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4863085484301502, 'Total loss': 0.4863085484301502} | train loss {'Reaction outcome loss': 0.48239581688326233, 'Total loss': 0.48239581688326233}
2022-11-28 05:08:01,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:01,949 INFO:     Epoch: 69
2022-11-28 05:08:02,614 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47495410963892937, 'Total loss': 0.47495410963892937} | train loss {'Reaction outcome loss': 0.4802240516458239, 'Total loss': 0.4802240516458239}
2022-11-28 05:08:02,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:02,614 INFO:     Epoch: 70
2022-11-28 05:08:03,279 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44992571798237885, 'Total loss': 0.44992571798237885} | train loss {'Reaction outcome loss': 0.47568483608109613, 'Total loss': 0.47568483608109613}
2022-11-28 05:08:03,279 INFO:     Found new best model at epoch 70
2022-11-28 05:08:03,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:03,280 INFO:     Epoch: 71
2022-11-28 05:08:03,944 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49385758692568, 'Total loss': 0.49385758692568} | train loss {'Reaction outcome loss': 0.4713284811195062, 'Total loss': 0.4713284811195062}
2022-11-28 05:08:03,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:03,944 INFO:     Epoch: 72
2022-11-28 05:08:04,609 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4940593411976641, 'Total loss': 0.4940593411976641} | train loss {'Reaction outcome loss': 0.48593470356902296, 'Total loss': 0.48593470356902296}
2022-11-28 05:08:04,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:04,609 INFO:     Epoch: 73
2022-11-28 05:08:05,275 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.469712687486952, 'Total loss': 0.469712687486952} | train loss {'Reaction outcome loss': 0.4777508432767829, 'Total loss': 0.4777508432767829}
2022-11-28 05:08:05,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:05,275 INFO:     Epoch: 74
2022-11-28 05:08:05,941 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45488038726828317, 'Total loss': 0.45488038726828317} | train loss {'Reaction outcome loss': 0.4823199823802831, 'Total loss': 0.4823199823802831}
2022-11-28 05:08:05,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:05,941 INFO:     Epoch: 75
2022-11-28 05:08:06,605 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47444320063699374, 'Total loss': 0.47444320063699374} | train loss {'Reaction outcome loss': 0.47691494579217875, 'Total loss': 0.47691494579217875}
2022-11-28 05:08:06,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:06,606 INFO:     Epoch: 76
2022-11-28 05:08:07,271 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4750405421311205, 'Total loss': 0.4750405421311205} | train loss {'Reaction outcome loss': 0.4855936184829595, 'Total loss': 0.4855936184829595}
2022-11-28 05:08:07,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:07,271 INFO:     Epoch: 77
2022-11-28 05:08:07,928 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5203835115852681, 'Total loss': 0.5203835115852681} | train loss {'Reaction outcome loss': 0.478994393014178, 'Total loss': 0.478994393014178}
2022-11-28 05:08:07,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:07,929 INFO:     Epoch: 78
2022-11-28 05:08:08,592 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5331074297428131, 'Total loss': 0.5331074297428131} | train loss {'Reaction outcome loss': 0.4851864124439201, 'Total loss': 0.4851864124439201}
2022-11-28 05:08:08,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:08,592 INFO:     Epoch: 79
2022-11-28 05:08:09,256 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45924203436483035, 'Total loss': 0.45924203436483035} | train loss {'Reaction outcome loss': 0.4813043231258587, 'Total loss': 0.4813043231258587}
2022-11-28 05:08:09,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:09,257 INFO:     Epoch: 80
2022-11-28 05:08:09,917 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4767937497659163, 'Total loss': 0.4767937497659163} | train loss {'Reaction outcome loss': 0.47427626112285926, 'Total loss': 0.47427626112285926}
2022-11-28 05:08:09,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:09,917 INFO:     Epoch: 81
2022-11-28 05:08:10,578 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47006414424289356, 'Total loss': 0.47006414424289356} | train loss {'Reaction outcome loss': 0.48352221876991036, 'Total loss': 0.48352221876991036}
2022-11-28 05:08:10,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:10,578 INFO:     Epoch: 82
2022-11-28 05:08:11,243 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4694548892703923, 'Total loss': 0.4694548892703923} | train loss {'Reaction outcome loss': 0.47256323451898535, 'Total loss': 0.47256323451898535}
2022-11-28 05:08:11,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:11,244 INFO:     Epoch: 83
2022-11-28 05:08:11,908 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47890057042241096, 'Total loss': 0.47890057042241096} | train loss {'Reaction outcome loss': 0.4799186595240418, 'Total loss': 0.4799186595240418}
2022-11-28 05:08:11,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:11,909 INFO:     Epoch: 84
2022-11-28 05:08:12,572 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4989961131729863, 'Total loss': 0.4989961131729863} | train loss {'Reaction outcome loss': 0.47919552265381327, 'Total loss': 0.47919552265381327}
2022-11-28 05:08:12,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:12,572 INFO:     Epoch: 85
2022-11-28 05:08:13,237 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46804899925535376, 'Total loss': 0.46804899925535376} | train loss {'Reaction outcome loss': 0.4750861368617233, 'Total loss': 0.4750861368617233}
2022-11-28 05:08:13,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:13,237 INFO:     Epoch: 86
2022-11-28 05:08:13,903 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4702596894719384, 'Total loss': 0.4702596894719384} | train loss {'Reaction outcome loss': 0.47743379789955764, 'Total loss': 0.47743379789955764}
2022-11-28 05:08:13,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:13,903 INFO:     Epoch: 87
2022-11-28 05:08:14,568 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4901863326403228, 'Total loss': 0.4901863326403228} | train loss {'Reaction outcome loss': 0.4784152671998861, 'Total loss': 0.4784152671998861}
2022-11-28 05:08:14,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:14,568 INFO:     Epoch: 88
2022-11-28 05:08:15,233 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47685094753449614, 'Total loss': 0.47685094753449614} | train loss {'Reaction outcome loss': 0.4771758184141042, 'Total loss': 0.4771758184141042}
2022-11-28 05:08:15,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:15,233 INFO:     Epoch: 89
2022-11-28 05:08:15,896 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48230427131056786, 'Total loss': 0.48230427131056786} | train loss {'Reaction outcome loss': 0.48323124041970894, 'Total loss': 0.48323124041970894}
2022-11-28 05:08:15,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:15,896 INFO:     Epoch: 90
2022-11-28 05:08:16,561 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4775182854765179, 'Total loss': 0.4775182854765179} | train loss {'Reaction outcome loss': 0.4743289024854193, 'Total loss': 0.4743289024854193}
2022-11-28 05:08:16,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:16,562 INFO:     Epoch: 91
2022-11-28 05:08:17,225 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5262363370169293, 'Total loss': 0.5262363370169293} | train loss {'Reaction outcome loss': 0.4787110720970193, 'Total loss': 0.4787110720970193}
2022-11-28 05:08:17,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:17,226 INFO:     Epoch: 92
2022-11-28 05:08:17,885 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4907958670095964, 'Total loss': 0.4907958670095964} | train loss {'Reaction outcome loss': 0.4784719578465637, 'Total loss': 0.4784719578465637}
2022-11-28 05:08:17,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:17,886 INFO:     Epoch: 93
2022-11-28 05:08:18,552 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4668901694769209, 'Total loss': 0.4668901694769209} | train loss {'Reaction outcome loss': 0.4790946444078368, 'Total loss': 0.4790946444078368}
2022-11-28 05:08:18,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:18,552 INFO:     Epoch: 94
2022-11-28 05:08:19,218 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48066533323038707, 'Total loss': 0.48066533323038707} | train loss {'Reaction outcome loss': 0.4776336289790212, 'Total loss': 0.4776336289790212}
2022-11-28 05:08:19,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:19,218 INFO:     Epoch: 95
2022-11-28 05:08:19,887 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46930376372554083, 'Total loss': 0.46930376372554083} | train loss {'Reaction outcome loss': 0.4760527351376962, 'Total loss': 0.4760527351376962}
2022-11-28 05:08:19,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:19,887 INFO:     Epoch: 96
2022-11-28 05:08:20,552 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4635330800983039, 'Total loss': 0.4635330800983039} | train loss {'Reaction outcome loss': 0.48226806995820026, 'Total loss': 0.48226806995820026}
2022-11-28 05:08:20,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:20,553 INFO:     Epoch: 97
2022-11-28 05:08:21,216 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46489875424991955, 'Total loss': 0.46489875424991955} | train loss {'Reaction outcome loss': 0.4785375807358294, 'Total loss': 0.4785375807358294}
2022-11-28 05:08:21,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:21,216 INFO:     Epoch: 98
2022-11-28 05:08:21,879 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4792434402148832, 'Total loss': 0.4792434402148832} | train loss {'Reaction outcome loss': 0.4802786384310041, 'Total loss': 0.4802786384310041}
2022-11-28 05:08:21,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:21,880 INFO:     Epoch: 99
2022-11-28 05:08:22,544 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46710784462365235, 'Total loss': 0.46710784462365235} | train loss {'Reaction outcome loss': 0.4805618230177432, 'Total loss': 0.4805618230177432}
2022-11-28 05:08:22,544 INFO:     Best model found after epoch 71 of 100.
2022-11-28 05:08:22,545 INFO:   Done with stage: TRAINING
2022-11-28 05:08:22,545 INFO:   Starting stage: EVALUATION
2022-11-28 05:08:22,667 INFO:   Done with stage: EVALUATION
2022-11-28 05:08:22,667 INFO:   Leaving out SEQ value Fold_2
2022-11-28 05:08:22,680 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 05:08:22,681 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:08:23,329 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:08:23,329 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:08:23,398 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:08:23,399 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:08:23,399 INFO:     No hyperparam tuning for this model
2022-11-28 05:08:23,399 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:08:23,399 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:08:23,399 INFO:     None feature selector for col prot
2022-11-28 05:08:23,400 INFO:     None feature selector for col prot
2022-11-28 05:08:23,400 INFO:     None feature selector for col prot
2022-11-28 05:08:23,400 INFO:     None feature selector for col chem
2022-11-28 05:08:23,400 INFO:     None feature selector for col chem
2022-11-28 05:08:23,400 INFO:     None feature selector for col chem
2022-11-28 05:08:23,400 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:08:23,401 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:08:23,402 INFO:     Number of params in model 169651
2022-11-28 05:08:23,405 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:08:23,405 INFO:   Starting stage: TRAINING
2022-11-28 05:08:23,455 INFO:     Val loss before train {'Reaction outcome loss': 0.9792421564113262, 'Total loss': 0.9792421564113262}
2022-11-28 05:08:23,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:23,456 INFO:     Epoch: 0
2022-11-28 05:08:24,118 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5575760540574096, 'Total loss': 0.5575760540574096} | train loss {'Reaction outcome loss': 0.7008795685699729, 'Total loss': 0.7008795685699729}
2022-11-28 05:08:24,118 INFO:     Found new best model at epoch 0
2022-11-28 05:08:24,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:24,119 INFO:     Epoch: 1
2022-11-28 05:08:24,779 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5163506851639859, 'Total loss': 0.5163506851639859} | train loss {'Reaction outcome loss': 0.5901399205942623, 'Total loss': 0.5901399205942623}
2022-11-28 05:08:24,779 INFO:     Found new best model at epoch 1
2022-11-28 05:08:24,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:24,779 INFO:     Epoch: 2
2022-11-28 05:08:25,439 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.554944894688074, 'Total loss': 0.554944894688074} | train loss {'Reaction outcome loss': 0.5569670037290112, 'Total loss': 0.5569670037290112}
2022-11-28 05:08:25,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:25,439 INFO:     Epoch: 3
2022-11-28 05:08:26,099 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5232731828162837, 'Total loss': 0.5232731828162837} | train loss {'Reaction outcome loss': 0.5294440578608239, 'Total loss': 0.5294440578608239}
2022-11-28 05:08:26,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:26,099 INFO:     Epoch: 4
2022-11-28 05:08:26,760 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4938960006070692, 'Total loss': 0.4938960006070692} | train loss {'Reaction outcome loss': 0.5234936005512222, 'Total loss': 0.5234936005512222}
2022-11-28 05:08:26,760 INFO:     Found new best model at epoch 4
2022-11-28 05:08:26,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:26,761 INFO:     Epoch: 5
2022-11-28 05:08:27,419 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47509199415528497, 'Total loss': 0.47509199415528497} | train loss {'Reaction outcome loss': 0.5121730445105521, 'Total loss': 0.5121730445105521}
2022-11-28 05:08:27,419 INFO:     Found new best model at epoch 5
2022-11-28 05:08:27,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:27,420 INFO:     Epoch: 6
2022-11-28 05:08:28,081 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4997328103974808, 'Total loss': 0.4997328103974808} | train loss {'Reaction outcome loss': 0.5042427787404569, 'Total loss': 0.5042427787404569}
2022-11-28 05:08:28,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:28,081 INFO:     Epoch: 7
2022-11-28 05:08:28,737 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48547129991442656, 'Total loss': 0.48547129991442656} | train loss {'Reaction outcome loss': 0.49835991102163907, 'Total loss': 0.49835991102163907}
2022-11-28 05:08:28,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:28,737 INFO:     Epoch: 8
2022-11-28 05:08:29,398 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49185689521390336, 'Total loss': 0.49185689521390336} | train loss {'Reaction outcome loss': 0.48423262905390535, 'Total loss': 0.48423262905390535}
2022-11-28 05:08:29,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:29,399 INFO:     Epoch: 9
2022-11-28 05:08:30,056 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4694201093773509, 'Total loss': 0.4694201093773509} | train loss {'Reaction outcome loss': 0.4847589849082173, 'Total loss': 0.4847589849082173}
2022-11-28 05:08:30,057 INFO:     Found new best model at epoch 9
2022-11-28 05:08:30,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:30,058 INFO:     Epoch: 10
2022-11-28 05:08:30,717 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5153783920199372, 'Total loss': 0.5153783920199372} | train loss {'Reaction outcome loss': 0.4811372304426842, 'Total loss': 0.4811372304426842}
2022-11-28 05:08:30,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:30,717 INFO:     Epoch: 11
2022-11-28 05:08:31,376 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5223399948242099, 'Total loss': 0.5223399948242099} | train loss {'Reaction outcome loss': 0.4792974854468322, 'Total loss': 0.4792974854468322}
2022-11-28 05:08:31,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:31,376 INFO:     Epoch: 12
2022-11-28 05:08:32,036 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5024842910988386, 'Total loss': 0.5024842910988386} | train loss {'Reaction outcome loss': 0.48340151477299753, 'Total loss': 0.48340151477299753}
2022-11-28 05:08:32,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:32,036 INFO:     Epoch: 13
2022-11-28 05:08:32,695 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48420643875765246, 'Total loss': 0.48420643875765246} | train loss {'Reaction outcome loss': 0.4772698711909232, 'Total loss': 0.4772698711909232}
2022-11-28 05:08:32,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:32,695 INFO:     Epoch: 14
2022-11-28 05:08:33,356 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4629441416540811, 'Total loss': 0.4629441416540811} | train loss {'Reaction outcome loss': 0.47769855732311967, 'Total loss': 0.47769855732311967}
2022-11-28 05:08:33,356 INFO:     Found new best model at epoch 14
2022-11-28 05:08:33,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:33,357 INFO:     Epoch: 15
2022-11-28 05:08:34,022 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.459215477455494, 'Total loss': 0.459215477455494} | train loss {'Reaction outcome loss': 0.4737374063459088, 'Total loss': 0.4737374063459088}
2022-11-28 05:08:34,022 INFO:     Found new best model at epoch 15
2022-11-28 05:08:34,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:34,023 INFO:     Epoch: 16
2022-11-28 05:08:34,686 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.443715468395588, 'Total loss': 0.443715468395588} | train loss {'Reaction outcome loss': 0.4781780661557053, 'Total loss': 0.4781780661557053}
2022-11-28 05:08:34,686 INFO:     Found new best model at epoch 16
2022-11-28 05:08:34,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:34,687 INFO:     Epoch: 17
2022-11-28 05:08:35,348 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4874621962392053, 'Total loss': 0.4874621962392053} | train loss {'Reaction outcome loss': 0.46860938039837313, 'Total loss': 0.46860938039837313}
2022-11-28 05:08:35,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:35,348 INFO:     Epoch: 18
2022-11-28 05:08:36,008 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44425764714562616, 'Total loss': 0.44425764714562616} | train loss {'Reaction outcome loss': 0.47791381821524903, 'Total loss': 0.47791381821524903}
2022-11-28 05:08:36,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:36,008 INFO:     Epoch: 19
2022-11-28 05:08:36,666 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4521515691696211, 'Total loss': 0.4521515691696211} | train loss {'Reaction outcome loss': 0.46897774516436896, 'Total loss': 0.46897774516436896}
2022-11-28 05:08:36,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:36,666 INFO:     Epoch: 20
2022-11-28 05:08:37,321 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44818727741407793, 'Total loss': 0.44818727741407793} | train loss {'Reaction outcome loss': 0.46883856212017966, 'Total loss': 0.46883856212017966}
2022-11-28 05:08:37,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:37,321 INFO:     Epoch: 21
2022-11-28 05:08:37,981 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44927254475133366, 'Total loss': 0.44927254475133366} | train loss {'Reaction outcome loss': 0.472212016399278, 'Total loss': 0.472212016399278}
2022-11-28 05:08:37,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:37,981 INFO:     Epoch: 22
2022-11-28 05:08:38,640 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48207632261653277, 'Total loss': 0.48207632261653277} | train loss {'Reaction outcome loss': 0.4717341806189936, 'Total loss': 0.4717341806189936}
2022-11-28 05:08:38,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:38,640 INFO:     Epoch: 23
2022-11-28 05:08:39,298 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.49604066582613215, 'Total loss': 0.49604066582613215} | train loss {'Reaction outcome loss': 0.4644744678354654, 'Total loss': 0.4644744678354654}
2022-11-28 05:08:39,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:39,299 INFO:     Epoch: 24
2022-11-28 05:08:39,955 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.434639134725859, 'Total loss': 0.434639134725859} | train loss {'Reaction outcome loss': 0.47012518834872324, 'Total loss': 0.47012518834872324}
2022-11-28 05:08:39,955 INFO:     Found new best model at epoch 24
2022-11-28 05:08:39,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:39,956 INFO:     Epoch: 25
2022-11-28 05:08:40,615 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44458367796831355, 'Total loss': 0.44458367796831355} | train loss {'Reaction outcome loss': 0.4714169165150064, 'Total loss': 0.4714169165150064}
2022-11-28 05:08:40,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:40,615 INFO:     Epoch: 26
2022-11-28 05:08:41,275 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.470633334545202, 'Total loss': 0.470633334545202} | train loss {'Reaction outcome loss': 0.46990532739484897, 'Total loss': 0.46990532739484897}
2022-11-28 05:08:41,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:41,275 INFO:     Epoch: 27
2022-11-28 05:08:41,935 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4723414137612942, 'Total loss': 0.4723414137612942} | train loss {'Reaction outcome loss': 0.46718496456742287, 'Total loss': 0.46718496456742287}
2022-11-28 05:08:41,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:41,936 INFO:     Epoch: 28
2022-11-28 05:08:42,593 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4608721622200899, 'Total loss': 0.4608721622200899} | train loss {'Reaction outcome loss': 0.4685320256919157, 'Total loss': 0.4685320256919157}
2022-11-28 05:08:42,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:42,593 INFO:     Epoch: 29
2022-11-28 05:08:43,252 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.455511235913565, 'Total loss': 0.455511235913565} | train loss {'Reaction outcome loss': 0.47089603182966594, 'Total loss': 0.47089603182966594}
2022-11-28 05:08:43,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:43,252 INFO:     Epoch: 30
2022-11-28 05:08:43,911 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47236913130726926, 'Total loss': 0.47236913130726926} | train loss {'Reaction outcome loss': 0.4660427425606329, 'Total loss': 0.4660427425606329}
2022-11-28 05:08:43,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:43,912 INFO:     Epoch: 31
2022-11-28 05:08:44,570 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4412709841894549, 'Total loss': 0.4412709841894549} | train loss {'Reaction outcome loss': 0.4689659169707142, 'Total loss': 0.4689659169707142}
2022-11-28 05:08:44,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:44,570 INFO:     Epoch: 32
2022-11-28 05:08:45,228 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4507373488226602, 'Total loss': 0.4507373488226602} | train loss {'Reaction outcome loss': 0.47033250838762425, 'Total loss': 0.47033250838762425}
2022-11-28 05:08:45,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:45,228 INFO:     Epoch: 33
2022-11-28 05:08:45,887 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4628736362900845, 'Total loss': 0.4628736362900845} | train loss {'Reaction outcome loss': 0.467804276613427, 'Total loss': 0.467804276613427}
2022-11-28 05:08:45,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:45,887 INFO:     Epoch: 34
2022-11-28 05:08:46,546 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43993754962155984, 'Total loss': 0.43993754962155984} | train loss {'Reaction outcome loss': 0.4747533780507377, 'Total loss': 0.4747533780507377}
2022-11-28 05:08:46,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:46,546 INFO:     Epoch: 35
2022-11-28 05:08:47,205 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4507905203242635, 'Total loss': 0.4507905203242635} | train loss {'Reaction outcome loss': 0.4694439661918116, 'Total loss': 0.4694439661918116}
2022-11-28 05:08:47,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:47,205 INFO:     Epoch: 36
2022-11-28 05:08:47,860 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4517922186574271, 'Total loss': 0.4517922186574271} | train loss {'Reaction outcome loss': 0.46805381371838145, 'Total loss': 0.46805381371838145}
2022-11-28 05:08:47,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:47,861 INFO:     Epoch: 37
2022-11-28 05:08:48,518 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49021370604980824, 'Total loss': 0.49021370604980824} | train loss {'Reaction outcome loss': 0.47112000642008467, 'Total loss': 0.47112000642008467}
2022-11-28 05:08:48,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:48,519 INFO:     Epoch: 38
2022-11-28 05:08:49,179 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4797452168409215, 'Total loss': 0.4797452168409215} | train loss {'Reaction outcome loss': 0.465338054372639, 'Total loss': 0.465338054372639}
2022-11-28 05:08:49,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:49,179 INFO:     Epoch: 39
2022-11-28 05:08:49,836 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4648730713267659, 'Total loss': 0.4648730713267659} | train loss {'Reaction outcome loss': 0.47050261808956256, 'Total loss': 0.47050261808956256}
2022-11-28 05:08:49,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:49,836 INFO:     Epoch: 40
2022-11-28 05:08:50,496 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43991085921609124, 'Total loss': 0.43991085921609124} | train loss {'Reaction outcome loss': 0.47533009662369236, 'Total loss': 0.47533009662369236}
2022-11-28 05:08:50,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:50,496 INFO:     Epoch: 41
2022-11-28 05:08:51,155 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.470204005061194, 'Total loss': 0.470204005061194} | train loss {'Reaction outcome loss': 0.4717797838212525, 'Total loss': 0.4717797838212525}
2022-11-28 05:08:51,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:51,155 INFO:     Epoch: 42
2022-11-28 05:08:51,814 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45051446349121804, 'Total loss': 0.45051446349121804} | train loss {'Reaction outcome loss': 0.47113246916503204, 'Total loss': 0.47113246916503204}
2022-11-28 05:08:51,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:51,814 INFO:     Epoch: 43
2022-11-28 05:08:52,469 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47956351831901906, 'Total loss': 0.47956351831901906} | train loss {'Reaction outcome loss': 0.47735961059444265, 'Total loss': 0.47735961059444265}
2022-11-28 05:08:52,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:52,469 INFO:     Epoch: 44
2022-11-28 05:08:53,126 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43765822676725163, 'Total loss': 0.43765822676725163} | train loss {'Reaction outcome loss': 0.46908871114986844, 'Total loss': 0.46908871114986844}
2022-11-28 05:08:53,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:53,126 INFO:     Epoch: 45
2022-11-28 05:08:53,786 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4651912391878838, 'Total loss': 0.4651912391878838} | train loss {'Reaction outcome loss': 0.4724303882141582, 'Total loss': 0.4724303882141582}
2022-11-28 05:08:53,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:53,786 INFO:     Epoch: 46
2022-11-28 05:08:54,444 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4614316233715346, 'Total loss': 0.4614316233715346} | train loss {'Reaction outcome loss': 0.46973298502261523, 'Total loss': 0.46973298502261523}
2022-11-28 05:08:54,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:54,444 INFO:     Epoch: 47
2022-11-28 05:08:55,107 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4461210508679235, 'Total loss': 0.4461210508679235} | train loss {'Reaction outcome loss': 0.4715721497892356, 'Total loss': 0.4715721497892356}
2022-11-28 05:08:55,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:55,108 INFO:     Epoch: 48
2022-11-28 05:08:55,770 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4578391237314357, 'Total loss': 0.4578391237314357} | train loss {'Reaction outcome loss': 0.4708256002698765, 'Total loss': 0.4708256002698765}
2022-11-28 05:08:55,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:55,770 INFO:     Epoch: 49
2022-11-28 05:08:56,432 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48989278632541033, 'Total loss': 0.48989278632541033} | train loss {'Reaction outcome loss': 0.47141313589498646, 'Total loss': 0.47141313589498646}
2022-11-28 05:08:56,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:56,432 INFO:     Epoch: 50
2022-11-28 05:08:57,093 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44385411538356956, 'Total loss': 0.44385411538356956} | train loss {'Reaction outcome loss': 0.468227927252406, 'Total loss': 0.468227927252406}
2022-11-28 05:08:57,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:57,094 INFO:     Epoch: 51
2022-11-28 05:08:57,755 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4380410150733105, 'Total loss': 0.4380410150733105} | train loss {'Reaction outcome loss': 0.4638997474837987, 'Total loss': 0.4638997474837987}
2022-11-28 05:08:57,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:57,755 INFO:     Epoch: 52
2022-11-28 05:08:58,412 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4912085536607476, 'Total loss': 0.4912085536607476} | train loss {'Reaction outcome loss': 0.468234908202144, 'Total loss': 0.468234908202144}
2022-11-28 05:08:58,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:58,412 INFO:     Epoch: 53
2022-11-28 05:08:59,072 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4478185048630071, 'Total loss': 0.4478185048630071} | train loss {'Reaction outcome loss': 0.46334183411520036, 'Total loss': 0.46334183411520036}
2022-11-28 05:08:59,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:59,073 INFO:     Epoch: 54
2022-11-28 05:08:59,731 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44833672046661377, 'Total loss': 0.44833672046661377} | train loss {'Reaction outcome loss': 0.4735258873552084, 'Total loss': 0.4735258873552084}
2022-11-28 05:08:59,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:08:59,731 INFO:     Epoch: 55
2022-11-28 05:09:00,393 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4631229278653167, 'Total loss': 0.4631229278653167} | train loss {'Reaction outcome loss': 0.4630157546308197, 'Total loss': 0.4630157546308197}
2022-11-28 05:09:00,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:00,393 INFO:     Epoch: 56
2022-11-28 05:09:01,057 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4701790258634922, 'Total loss': 0.4701790258634922} | train loss {'Reaction outcome loss': 0.46666940136766827, 'Total loss': 0.46666940136766827}
2022-11-28 05:09:01,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:01,058 INFO:     Epoch: 57
2022-11-28 05:09:01,718 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5333097882049028, 'Total loss': 0.5333097882049028} | train loss {'Reaction outcome loss': 0.4761058943437748, 'Total loss': 0.4761058943437748}
2022-11-28 05:09:01,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:01,719 INFO:     Epoch: 58
2022-11-28 05:09:02,377 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45584153955759005, 'Total loss': 0.45584153955759005} | train loss {'Reaction outcome loss': 0.46515701021083067, 'Total loss': 0.46515701021083067}
2022-11-28 05:09:02,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:02,377 INFO:     Epoch: 59
2022-11-28 05:09:03,036 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43622688637223356, 'Total loss': 0.43622688637223356} | train loss {'Reaction outcome loss': 0.46815456449985504, 'Total loss': 0.46815456449985504}
2022-11-28 05:09:03,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:03,036 INFO:     Epoch: 60
2022-11-28 05:09:03,695 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42756296243778497, 'Total loss': 0.42756296243778497} | train loss {'Reaction outcome loss': 0.4680653071550072, 'Total loss': 0.4680653071550072}
2022-11-28 05:09:03,695 INFO:     Found new best model at epoch 60
2022-11-28 05:09:03,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:03,696 INFO:     Epoch: 61
2022-11-28 05:09:04,352 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4819060969491338, 'Total loss': 0.4819060969491338} | train loss {'Reaction outcome loss': 0.467276605426288, 'Total loss': 0.467276605426288}
2022-11-28 05:09:04,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:04,352 INFO:     Epoch: 62
2022-11-28 05:09:05,012 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5231776545907176, 'Total loss': 0.5231776545907176} | train loss {'Reaction outcome loss': 0.4627887735479191, 'Total loss': 0.4627887735479191}
2022-11-28 05:09:05,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:05,012 INFO:     Epoch: 63
2022-11-28 05:09:05,673 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4559868390476981, 'Total loss': 0.4559868390476981} | train loss {'Reaction outcome loss': 0.46899089617196654, 'Total loss': 0.46899089617196654}
2022-11-28 05:09:05,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:05,674 INFO:     Epoch: 64
2022-11-28 05:09:06,338 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4890576306470605, 'Total loss': 0.4890576306470605} | train loss {'Reaction outcome loss': 0.4686914279324109, 'Total loss': 0.4686914279324109}
2022-11-28 05:09:06,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:06,338 INFO:     Epoch: 65
2022-11-28 05:09:07,016 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44938559448996257, 'Total loss': 0.44938559448996257} | train loss {'Reaction outcome loss': 0.4658491962635126, 'Total loss': 0.4658491962635126}
2022-11-28 05:09:07,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:07,016 INFO:     Epoch: 66
2022-11-28 05:09:07,676 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4630241588104603, 'Total loss': 0.4630241588104603} | train loss {'Reaction outcome loss': 0.4702142230922081, 'Total loss': 0.4702142230922081}
2022-11-28 05:09:07,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:07,676 INFO:     Epoch: 67
2022-11-28 05:09:08,335 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4562164108420527, 'Total loss': 0.4562164108420527} | train loss {'Reaction outcome loss': 0.46817043008374387, 'Total loss': 0.46817043008374387}
2022-11-28 05:09:08,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:08,335 INFO:     Epoch: 68
2022-11-28 05:09:09,000 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44856998081817184, 'Total loss': 0.44856998081817184} | train loss {'Reaction outcome loss': 0.4723483196413908, 'Total loss': 0.4723483196413908}
2022-11-28 05:09:09,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:09,000 INFO:     Epoch: 69
2022-11-28 05:09:09,662 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4984622424425081, 'Total loss': 0.4984622424425081} | train loss {'Reaction outcome loss': 0.4680828401421914, 'Total loss': 0.4680828401421914}
2022-11-28 05:09:09,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:09,662 INFO:     Epoch: 70
2022-11-28 05:09:10,323 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4626741721186527, 'Total loss': 0.4626741721186527} | train loss {'Reaction outcome loss': 0.46251295928339486, 'Total loss': 0.46251295928339486}
2022-11-28 05:09:10,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:10,323 INFO:     Epoch: 71
2022-11-28 05:09:10,985 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46676505894161935, 'Total loss': 0.46676505894161935} | train loss {'Reaction outcome loss': 0.46380036226550087, 'Total loss': 0.46380036226550087}
2022-11-28 05:09:10,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:10,985 INFO:     Epoch: 72
2022-11-28 05:09:11,649 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44660322991914525, 'Total loss': 0.44660322991914525} | train loss {'Reaction outcome loss': 0.46511301224226836, 'Total loss': 0.46511301224226836}
2022-11-28 05:09:11,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:11,649 INFO:     Epoch: 73
2022-11-28 05:09:12,311 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4467134070257808, 'Total loss': 0.4467134070257808} | train loss {'Reaction outcome loss': 0.47171628804969007, 'Total loss': 0.47171628804969007}
2022-11-28 05:09:12,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:12,313 INFO:     Epoch: 74
2022-11-28 05:09:12,970 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46033027040403945, 'Total loss': 0.46033027040403945} | train loss {'Reaction outcome loss': 0.46546266056963653, 'Total loss': 0.46546266056963653}
2022-11-28 05:09:12,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:12,970 INFO:     Epoch: 75
2022-11-28 05:09:13,630 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4524241322001746, 'Total loss': 0.4524241322001746} | train loss {'Reaction outcome loss': 0.46555251560983113, 'Total loss': 0.46555251560983113}
2022-11-28 05:09:13,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:13,630 INFO:     Epoch: 76
2022-11-28 05:09:14,290 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4369675364605216, 'Total loss': 0.4369675364605216} | train loss {'Reaction outcome loss': 0.4687505375716041, 'Total loss': 0.4687505375716041}
2022-11-28 05:09:14,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:14,291 INFO:     Epoch: 77
2022-11-28 05:09:14,948 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44366805775221, 'Total loss': 0.44366805775221} | train loss {'Reaction outcome loss': 0.46200513143519883, 'Total loss': 0.46200513143519883}
2022-11-28 05:09:14,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:14,948 INFO:     Epoch: 78
2022-11-28 05:09:15,609 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46179718091044314, 'Total loss': 0.46179718091044314} | train loss {'Reaction outcome loss': 0.46968085111164654, 'Total loss': 0.46968085111164654}
2022-11-28 05:09:15,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:15,610 INFO:     Epoch: 79
2022-11-28 05:09:16,269 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4464564105105955, 'Total loss': 0.4464564105105955} | train loss {'Reaction outcome loss': 0.46240284190070435, 'Total loss': 0.46240284190070435}
2022-11-28 05:09:16,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:16,269 INFO:     Epoch: 80
2022-11-28 05:09:16,929 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4358812920575918, 'Total loss': 0.4358812920575918} | train loss {'Reaction outcome loss': 0.4626315360675093, 'Total loss': 0.4626315360675093}
2022-11-28 05:09:16,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:16,930 INFO:     Epoch: 81
2022-11-28 05:09:17,589 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4527051570110543, 'Total loss': 0.4527051570110543} | train loss {'Reaction outcome loss': 0.46366429212884824, 'Total loss': 0.46366429212884824}
2022-11-28 05:09:17,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:17,589 INFO:     Epoch: 82
2022-11-28 05:09:18,244 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4675794413616491, 'Total loss': 0.4675794413616491} | train loss {'Reaction outcome loss': 0.46651430751700873, 'Total loss': 0.46651430751700873}
2022-11-28 05:09:18,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:18,245 INFO:     Epoch: 83
2022-11-28 05:09:18,901 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48713263973247173, 'Total loss': 0.48713263973247173} | train loss {'Reaction outcome loss': 0.4662750049448404, 'Total loss': 0.4662750049448404}
2022-11-28 05:09:18,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:18,902 INFO:     Epoch: 84
2022-11-28 05:09:19,562 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4667653022117393, 'Total loss': 0.4667653022117393} | train loss {'Reaction outcome loss': 0.46221514321008667, 'Total loss': 0.46221514321008667}
2022-11-28 05:09:19,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:19,562 INFO:     Epoch: 85
2022-11-28 05:09:20,221 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44048179547454036, 'Total loss': 0.44048179547454036} | train loss {'Reaction outcome loss': 0.46869346859758015, 'Total loss': 0.46869346859758015}
2022-11-28 05:09:20,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:20,221 INFO:     Epoch: 86
2022-11-28 05:09:20,879 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45771013477513955, 'Total loss': 0.45771013477513955} | train loss {'Reaction outcome loss': 0.4661586962518145, 'Total loss': 0.4661586962518145}
2022-11-28 05:09:20,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:20,879 INFO:     Epoch: 87
2022-11-28 05:09:21,539 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4584559548732846, 'Total loss': 0.4584559548732846} | train loss {'Reaction outcome loss': 0.4640286448793333, 'Total loss': 0.4640286448793333}
2022-11-28 05:09:21,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:21,539 INFO:     Epoch: 88
2022-11-28 05:09:22,200 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4586967565985613, 'Total loss': 0.4586967565985613} | train loss {'Reaction outcome loss': 0.4628195516520836, 'Total loss': 0.4628195516520836}
2022-11-28 05:09:22,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:22,200 INFO:     Epoch: 89
2022-11-28 05:09:22,858 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45749803199324496, 'Total loss': 0.45749803199324496} | train loss {'Reaction outcome loss': 0.4618520157136878, 'Total loss': 0.4618520157136878}
2022-11-28 05:09:22,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:22,858 INFO:     Epoch: 90
2022-11-28 05:09:23,520 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47609898759875185, 'Total loss': 0.47609898759875185} | train loss {'Reaction outcome loss': 0.4650156326347687, 'Total loss': 0.4650156326347687}
2022-11-28 05:09:23,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:23,520 INFO:     Epoch: 91
2022-11-28 05:09:24,180 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44156036924484166, 'Total loss': 0.44156036924484166} | train loss {'Reaction outcome loss': 0.4649005389970834, 'Total loss': 0.4649005389970834}
2022-11-28 05:09:24,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:24,181 INFO:     Epoch: 92
2022-11-28 05:09:24,840 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.466577036436214, 'Total loss': 0.466577036436214} | train loss {'Reaction outcome loss': 0.4576412577059914, 'Total loss': 0.4576412577059914}
2022-11-28 05:09:24,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:24,840 INFO:     Epoch: 93
2022-11-28 05:09:25,499 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44979551642440085, 'Total loss': 0.44979551642440085} | train loss {'Reaction outcome loss': 0.46148883917781175, 'Total loss': 0.46148883917781175}
2022-11-28 05:09:25,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:25,499 INFO:     Epoch: 94
2022-11-28 05:09:26,157 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4826294696608255, 'Total loss': 0.4826294696608255} | train loss {'Reaction outcome loss': 0.4683594683521107, 'Total loss': 0.4683594683521107}
2022-11-28 05:09:26,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:26,157 INFO:     Epoch: 95
2022-11-28 05:09:26,822 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45527629311694656, 'Total loss': 0.45527629311694656} | train loss {'Reaction outcome loss': 0.4653327043672077, 'Total loss': 0.4653327043672077}
2022-11-28 05:09:26,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:26,823 INFO:     Epoch: 96
2022-11-28 05:09:27,486 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4716739484737086, 'Total loss': 0.4716739484737086} | train loss {'Reaction outcome loss': 0.46576416666512604, 'Total loss': 0.46576416666512604}
2022-11-28 05:09:27,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:27,486 INFO:     Epoch: 97
2022-11-28 05:09:28,147 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48194054704765943, 'Total loss': 0.48194054704765943} | train loss {'Reaction outcome loss': 0.4675044294324566, 'Total loss': 0.4675044294324566}
2022-11-28 05:09:28,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:28,147 INFO:     Epoch: 98
2022-11-28 05:09:28,810 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4606335471535838, 'Total loss': 0.4606335471535838} | train loss {'Reaction outcome loss': 0.46708709697742934, 'Total loss': 0.46708709697742934}
2022-11-28 05:09:28,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:28,811 INFO:     Epoch: 99
2022-11-28 05:09:29,471 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47476284309875133, 'Total loss': 0.47476284309875133} | train loss {'Reaction outcome loss': 0.4605616100254606, 'Total loss': 0.4605616100254606}
2022-11-28 05:09:29,471 INFO:     Best model found after epoch 61 of 100.
2022-11-28 05:09:29,471 INFO:   Done with stage: TRAINING
2022-11-28 05:09:29,472 INFO:   Starting stage: EVALUATION
2022-11-28 05:09:29,600 INFO:   Done with stage: EVALUATION
2022-11-28 05:09:29,600 INFO:   Leaving out SEQ value Fold_3
2022-11-28 05:09:29,613 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 05:09:29,613 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:09:30,267 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:09:30,268 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:09:30,337 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:09:30,337 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:09:30,337 INFO:     No hyperparam tuning for this model
2022-11-28 05:09:30,337 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:09:30,337 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:09:30,338 INFO:     None feature selector for col prot
2022-11-28 05:09:30,338 INFO:     None feature selector for col prot
2022-11-28 05:09:30,338 INFO:     None feature selector for col prot
2022-11-28 05:09:30,338 INFO:     None feature selector for col chem
2022-11-28 05:09:30,339 INFO:     None feature selector for col chem
2022-11-28 05:09:30,339 INFO:     None feature selector for col chem
2022-11-28 05:09:30,339 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:09:30,339 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:09:30,340 INFO:     Number of params in model 169651
2022-11-28 05:09:30,343 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:09:30,343 INFO:   Starting stage: TRAINING
2022-11-28 05:09:30,394 INFO:     Val loss before train {'Reaction outcome loss': 1.0079018331386826, 'Total loss': 1.0079018331386826}
2022-11-28 05:09:30,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:30,394 INFO:     Epoch: 0
2022-11-28 05:09:31,056 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6262407438321547, 'Total loss': 0.6262407438321547} | train loss {'Reaction outcome loss': 0.6968509365709461, 'Total loss': 0.6968509365709461}
2022-11-28 05:09:31,056 INFO:     Found new best model at epoch 0
2022-11-28 05:09:31,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:31,057 INFO:     Epoch: 1
2022-11-28 05:09:31,723 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6068172420967709, 'Total loss': 0.6068172420967709} | train loss {'Reaction outcome loss': 0.5931799321758504, 'Total loss': 0.5931799321758504}
2022-11-28 05:09:31,723 INFO:     Found new best model at epoch 1
2022-11-28 05:09:31,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:31,724 INFO:     Epoch: 2
2022-11-28 05:09:32,389 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5341979299079288, 'Total loss': 0.5341979299079288} | train loss {'Reaction outcome loss': 0.5519410121805813, 'Total loss': 0.5519410121805813}
2022-11-28 05:09:32,389 INFO:     Found new best model at epoch 2
2022-11-28 05:09:32,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:32,390 INFO:     Epoch: 3
2022-11-28 05:09:33,057 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.537157439711419, 'Total loss': 0.537157439711419} | train loss {'Reaction outcome loss': 0.5394358606362829, 'Total loss': 0.5394358606362829}
2022-11-28 05:09:33,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:33,058 INFO:     Epoch: 4
2022-11-28 05:09:33,721 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5149033103476871, 'Total loss': 0.5149033103476871} | train loss {'Reaction outcome loss': 0.5137391880458715, 'Total loss': 0.5137391880458715}
2022-11-28 05:09:33,722 INFO:     Found new best model at epoch 4
2022-11-28 05:09:33,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:33,722 INFO:     Epoch: 5
2022-11-28 05:09:34,386 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5030994941903786, 'Total loss': 0.5030994941903786} | train loss {'Reaction outcome loss': 0.5119242808040307, 'Total loss': 0.5119242808040307}
2022-11-28 05:09:34,386 INFO:     Found new best model at epoch 5
2022-11-28 05:09:34,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:34,387 INFO:     Epoch: 6
2022-11-28 05:09:35,051 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.560417696156285, 'Total loss': 0.560417696156285} | train loss {'Reaction outcome loss': 0.5036251799184449, 'Total loss': 0.5036251799184449}
2022-11-28 05:09:35,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:35,051 INFO:     Epoch: 7
2022-11-28 05:09:35,715 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5442296872762117, 'Total loss': 0.5442296872762117} | train loss {'Reaction outcome loss': 0.5034148988066888, 'Total loss': 0.5034148988066888}
2022-11-28 05:09:35,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:35,715 INFO:     Epoch: 8
2022-11-28 05:09:36,376 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5030723038044843, 'Total loss': 0.5030723038044843} | train loss {'Reaction outcome loss': 0.5101894284997668, 'Total loss': 0.5101894284997668}
2022-11-28 05:09:36,376 INFO:     Found new best model at epoch 8
2022-11-28 05:09:36,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:36,377 INFO:     Epoch: 9
2022-11-28 05:09:37,038 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5136925869367339, 'Total loss': 0.5136925869367339} | train loss {'Reaction outcome loss': 0.4976522178674231, 'Total loss': 0.4976522178674231}
2022-11-28 05:09:37,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:37,038 INFO:     Epoch: 10
2022-11-28 05:09:37,700 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4876287616789341, 'Total loss': 0.4876287616789341} | train loss {'Reaction outcome loss': 0.500555987625706, 'Total loss': 0.500555987625706}
2022-11-28 05:09:37,700 INFO:     Found new best model at epoch 10
2022-11-28 05:09:37,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:37,701 INFO:     Epoch: 11
2022-11-28 05:09:38,365 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48014656522057275, 'Total loss': 0.48014656522057275} | train loss {'Reaction outcome loss': 0.4891449315815556, 'Total loss': 0.4891449315815556}
2022-11-28 05:09:38,365 INFO:     Found new best model at epoch 11
2022-11-28 05:09:38,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:38,366 INFO:     Epoch: 12
2022-11-28 05:09:39,026 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5103084925900806, 'Total loss': 0.5103084925900806} | train loss {'Reaction outcome loss': 0.4892666045500308, 'Total loss': 0.4892666045500308}
2022-11-28 05:09:39,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:39,027 INFO:     Epoch: 13
2022-11-28 05:09:39,690 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4992388595234264, 'Total loss': 0.4992388595234264} | train loss {'Reaction outcome loss': 0.4765357582848899, 'Total loss': 0.4765357582848899}
2022-11-28 05:09:39,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:39,690 INFO:     Epoch: 14
2022-11-28 05:09:40,354 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4908085260540247, 'Total loss': 0.4908085260540247} | train loss {'Reaction outcome loss': 0.4855832246797425, 'Total loss': 0.4855832246797425}
2022-11-28 05:09:40,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:40,354 INFO:     Epoch: 15
2022-11-28 05:09:41,016 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5299093665724451, 'Total loss': 0.5299093665724451} | train loss {'Reaction outcome loss': 0.4865631281721349, 'Total loss': 0.4865631281721349}
2022-11-28 05:09:41,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:41,016 INFO:     Epoch: 16
2022-11-28 05:09:41,680 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48463909565047786, 'Total loss': 0.48463909565047786} | train loss {'Reaction outcome loss': 0.47724339621407647, 'Total loss': 0.47724339621407647}
2022-11-28 05:09:41,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:41,680 INFO:     Epoch: 17
2022-11-28 05:09:42,343 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4960597755218094, 'Total loss': 0.4960597755218094} | train loss {'Reaction outcome loss': 0.47492315465090224, 'Total loss': 0.47492315465090224}
2022-11-28 05:09:42,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:42,343 INFO:     Epoch: 18
2022-11-28 05:09:43,007 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.513159725476395, 'Total loss': 0.513159725476395} | train loss {'Reaction outcome loss': 0.47587848238799035, 'Total loss': 0.47587848238799035}
2022-11-28 05:09:43,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:43,007 INFO:     Epoch: 19
2022-11-28 05:09:43,672 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4513653540475802, 'Total loss': 0.4513653540475802} | train loss {'Reaction outcome loss': 0.4732001906450914, 'Total loss': 0.4732001906450914}
2022-11-28 05:09:43,673 INFO:     Found new best model at epoch 19
2022-11-28 05:09:43,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:43,674 INFO:     Epoch: 20
2022-11-28 05:09:44,335 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5271651104769923, 'Total loss': 0.5271651104769923} | train loss {'Reaction outcome loss': 0.4653117722394515, 'Total loss': 0.4653117722394515}
2022-11-28 05:09:44,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:44,336 INFO:     Epoch: 21
2022-11-28 05:09:44,998 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5015544258058071, 'Total loss': 0.5015544258058071} | train loss {'Reaction outcome loss': 0.477946053719034, 'Total loss': 0.477946053719034}
2022-11-28 05:09:44,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:44,998 INFO:     Epoch: 22
2022-11-28 05:09:45,661 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5035444647073746, 'Total loss': 0.5035444647073746} | train loss {'Reaction outcome loss': 0.4616647115775517, 'Total loss': 0.4616647115775517}
2022-11-28 05:09:45,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:45,661 INFO:     Epoch: 23
2022-11-28 05:09:46,336 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4849710244346749, 'Total loss': 0.4849710244346749} | train loss {'Reaction outcome loss': 0.469444391982896, 'Total loss': 0.469444391982896}
2022-11-28 05:09:46,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:46,336 INFO:     Epoch: 24
2022-11-28 05:09:46,997 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5069888816638426, 'Total loss': 0.5069888816638426} | train loss {'Reaction outcome loss': 0.47447987128885427, 'Total loss': 0.47447987128885427}
2022-11-28 05:09:46,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:46,997 INFO:     Epoch: 25
2022-11-28 05:09:47,662 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48411364819515834, 'Total loss': 0.48411364819515834} | train loss {'Reaction outcome loss': 0.4639204144477844, 'Total loss': 0.4639204144477844}
2022-11-28 05:09:47,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:47,662 INFO:     Epoch: 26
2022-11-28 05:09:48,323 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44583468240770424, 'Total loss': 0.44583468240770424} | train loss {'Reaction outcome loss': 0.4691280530119429, 'Total loss': 0.4691280530119429}
2022-11-28 05:09:48,323 INFO:     Found new best model at epoch 26
2022-11-28 05:09:48,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:48,324 INFO:     Epoch: 27
2022-11-28 05:09:48,982 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48714316297661175, 'Total loss': 0.48714316297661175} | train loss {'Reaction outcome loss': 0.45821631599445733, 'Total loss': 0.45821631599445733}
2022-11-28 05:09:48,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:48,982 INFO:     Epoch: 28
2022-11-28 05:09:49,642 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4875445592809807, 'Total loss': 0.4875445592809807} | train loss {'Reaction outcome loss': 0.4710798960559222, 'Total loss': 0.4710798960559222}
2022-11-28 05:09:49,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:49,642 INFO:     Epoch: 29
2022-11-28 05:09:50,303 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46462257291105663, 'Total loss': 0.46462257291105663} | train loss {'Reaction outcome loss': 0.46515801804406304, 'Total loss': 0.46515801804406304}
2022-11-28 05:09:50,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:50,304 INFO:     Epoch: 30
2022-11-28 05:09:50,960 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4733586765148423, 'Total loss': 0.4733586765148423} | train loss {'Reaction outcome loss': 0.4714140274086777, 'Total loss': 0.4714140274086777}
2022-11-28 05:09:50,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:50,960 INFO:     Epoch: 31
2022-11-28 05:09:51,618 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4613216333091259, 'Total loss': 0.4613216333091259} | train loss {'Reaction outcome loss': 0.4661160732410392, 'Total loss': 0.4661160732410392}
2022-11-28 05:09:51,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:51,618 INFO:     Epoch: 32
2022-11-28 05:09:52,276 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4870396717028184, 'Total loss': 0.4870396717028184} | train loss {'Reaction outcome loss': 0.4609384784284903, 'Total loss': 0.4609384784284903}
2022-11-28 05:09:52,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:52,276 INFO:     Epoch: 33
2022-11-28 05:09:52,933 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4970490343191407, 'Total loss': 0.4970490343191407} | train loss {'Reaction outcome loss': 0.46454237614359173, 'Total loss': 0.46454237614359173}
2022-11-28 05:09:52,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:52,933 INFO:     Epoch: 34
2022-11-28 05:09:53,592 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4893708950416608, 'Total loss': 0.4893708950416608} | train loss {'Reaction outcome loss': 0.4602772394005133, 'Total loss': 0.4602772394005133}
2022-11-28 05:09:53,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:53,592 INFO:     Epoch: 35
2022-11-28 05:09:54,252 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4629071265120398, 'Total loss': 0.4629071265120398} | train loss {'Reaction outcome loss': 0.4604814481370303, 'Total loss': 0.4604814481370303}
2022-11-28 05:09:54,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:54,253 INFO:     Epoch: 36
2022-11-28 05:09:54,909 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4742775410413742, 'Total loss': 0.4742775410413742} | train loss {'Reaction outcome loss': 0.4649657130849605, 'Total loss': 0.4649657130849605}
2022-11-28 05:09:54,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:54,909 INFO:     Epoch: 37
2022-11-28 05:09:55,567 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49627602540633897, 'Total loss': 0.49627602540633897} | train loss {'Reaction outcome loss': 0.4547441922280253, 'Total loss': 0.4547441922280253}
2022-11-28 05:09:55,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:55,567 INFO:     Epoch: 38
2022-11-28 05:09:56,224 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46966160126877105, 'Total loss': 0.46966160126877105} | train loss {'Reaction outcome loss': 0.46860185946737015, 'Total loss': 0.46860185946737015}
2022-11-28 05:09:56,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:56,224 INFO:     Epoch: 39
2022-11-28 05:09:56,880 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47167766534469346, 'Total loss': 0.47167766534469346} | train loss {'Reaction outcome loss': 0.45756121709638714, 'Total loss': 0.45756121709638714}
2022-11-28 05:09:56,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:56,880 INFO:     Epoch: 40
2022-11-28 05:09:57,541 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4916951354931701, 'Total loss': 0.4916951354931701} | train loss {'Reaction outcome loss': 0.4600649912138374, 'Total loss': 0.4600649912138374}
2022-11-28 05:09:57,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:57,541 INFO:     Epoch: 41
2022-11-28 05:09:58,204 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4803318533707749, 'Total loss': 0.4803318533707749} | train loss {'Reaction outcome loss': 0.45902625723760954, 'Total loss': 0.45902625723760954}
2022-11-28 05:09:58,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:58,204 INFO:     Epoch: 42
2022-11-28 05:09:58,865 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4536637128754096, 'Total loss': 0.4536637128754096} | train loss {'Reaction outcome loss': 0.4567100155110262, 'Total loss': 0.4567100155110262}
2022-11-28 05:09:58,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:58,865 INFO:     Epoch: 43
2022-11-28 05:09:59,525 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44671043499626895, 'Total loss': 0.44671043499626895} | train loss {'Reaction outcome loss': 0.45981561474654137, 'Total loss': 0.45981561474654137}
2022-11-28 05:09:59,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:09:59,526 INFO:     Epoch: 44
2022-11-28 05:10:00,187 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5056329769167033, 'Total loss': 0.5056329769167033} | train loss {'Reaction outcome loss': 0.45578147805466945, 'Total loss': 0.45578147805466945}
2022-11-28 05:10:00,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:00,187 INFO:     Epoch: 45
2022-11-28 05:10:00,850 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.508498190478845, 'Total loss': 0.508498190478845} | train loss {'Reaction outcome loss': 0.46120893347020053, 'Total loss': 0.46120893347020053}
2022-11-28 05:10:00,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:00,850 INFO:     Epoch: 46
2022-11-28 05:10:01,512 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45277370112440124, 'Total loss': 0.45277370112440124} | train loss {'Reaction outcome loss': 0.46107550585756496, 'Total loss': 0.46107550585756496}
2022-11-28 05:10:01,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:01,512 INFO:     Epoch: 47
2022-11-28 05:10:02,172 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48825603046200494, 'Total loss': 0.48825603046200494} | train loss {'Reaction outcome loss': 0.4563435512537859, 'Total loss': 0.4563435512537859}
2022-11-28 05:10:02,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:02,172 INFO:     Epoch: 48
2022-11-28 05:10:02,836 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46681820025498216, 'Total loss': 0.46681820025498216} | train loss {'Reaction outcome loss': 0.4524393682577172, 'Total loss': 0.4524393682577172}
2022-11-28 05:10:02,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:02,837 INFO:     Epoch: 49
2022-11-28 05:10:03,496 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47254097123037686, 'Total loss': 0.47254097123037686} | train loss {'Reaction outcome loss': 0.457374793351913, 'Total loss': 0.457374793351913}
2022-11-28 05:10:03,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:03,496 INFO:     Epoch: 50
2022-11-28 05:10:04,160 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47156238183379173, 'Total loss': 0.47156238183379173} | train loss {'Reaction outcome loss': 0.4646914309688977, 'Total loss': 0.4646914309688977}
2022-11-28 05:10:04,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:04,160 INFO:     Epoch: 51
2022-11-28 05:10:04,820 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4868128604509614, 'Total loss': 0.4868128604509614} | train loss {'Reaction outcome loss': 0.45650896381358713, 'Total loss': 0.45650896381358713}
2022-11-28 05:10:04,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:04,820 INFO:     Epoch: 52
2022-11-28 05:10:05,480 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45353051681410184, 'Total loss': 0.45353051681410184} | train loss {'Reaction outcome loss': 0.4596458081536147, 'Total loss': 0.4596458081536147}
2022-11-28 05:10:05,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:05,480 INFO:     Epoch: 53
2022-11-28 05:10:06,140 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43342857740142127, 'Total loss': 0.43342857740142127} | train loss {'Reaction outcome loss': 0.46164751049815395, 'Total loss': 0.46164751049815395}
2022-11-28 05:10:06,140 INFO:     Found new best model at epoch 53
2022-11-28 05:10:06,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:06,141 INFO:     Epoch: 54
2022-11-28 05:10:06,802 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47218145870349626, 'Total loss': 0.47218145870349626} | train loss {'Reaction outcome loss': 0.4596904318551628, 'Total loss': 0.4596904318551628}
2022-11-28 05:10:06,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:06,802 INFO:     Epoch: 55
2022-11-28 05:10:07,460 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4818416346203197, 'Total loss': 0.4818416346203197} | train loss {'Reaction outcome loss': 0.4569514486254478, 'Total loss': 0.4569514486254478}
2022-11-28 05:10:07,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:07,461 INFO:     Epoch: 56
2022-11-28 05:10:08,121 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49669691547751427, 'Total loss': 0.49669691547751427} | train loss {'Reaction outcome loss': 0.45550024789206833, 'Total loss': 0.45550024789206833}
2022-11-28 05:10:08,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:08,121 INFO:     Epoch: 57
2022-11-28 05:10:08,779 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4946027411655946, 'Total loss': 0.4946027411655946} | train loss {'Reaction outcome loss': 0.44713128355084636, 'Total loss': 0.44713128355084636}
2022-11-28 05:10:08,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:08,779 INFO:     Epoch: 58
2022-11-28 05:10:09,435 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49610949104482477, 'Total loss': 0.49610949104482477} | train loss {'Reaction outcome loss': 0.4525790748243429, 'Total loss': 0.4525790748243429}
2022-11-28 05:10:09,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:09,436 INFO:     Epoch: 59
2022-11-28 05:10:10,092 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4672106291082772, 'Total loss': 0.4672106291082772} | train loss {'Reaction outcome loss': 0.4555961092819973, 'Total loss': 0.4555961092819973}
2022-11-28 05:10:10,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:10,093 INFO:     Epoch: 60
2022-11-28 05:10:10,751 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4669875560159033, 'Total loss': 0.4669875560159033} | train loss {'Reaction outcome loss': 0.45752019964310586, 'Total loss': 0.45752019964310586}
2022-11-28 05:10:10,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:10,751 INFO:     Epoch: 61
2022-11-28 05:10:11,410 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4501324749805711, 'Total loss': 0.4501324749805711} | train loss {'Reaction outcome loss': 0.458847683576905, 'Total loss': 0.458847683576905}
2022-11-28 05:10:11,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:11,410 INFO:     Epoch: 62
2022-11-28 05:10:12,065 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45370350913567975, 'Total loss': 0.45370350913567975} | train loss {'Reaction outcome loss': 0.4687237895873128, 'Total loss': 0.4687237895873128}
2022-11-28 05:10:12,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:12,065 INFO:     Epoch: 63
2022-11-28 05:10:12,724 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4534249949184331, 'Total loss': 0.4534249949184331} | train loss {'Reaction outcome loss': 0.44886502787774923, 'Total loss': 0.44886502787774923}
2022-11-28 05:10:12,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:12,724 INFO:     Epoch: 64
2022-11-28 05:10:13,382 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4589731303805655, 'Total loss': 0.4589731303805655} | train loss {'Reaction outcome loss': 0.45369358683119015, 'Total loss': 0.45369358683119015}
2022-11-28 05:10:13,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:13,382 INFO:     Epoch: 65
2022-11-28 05:10:14,038 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45819792794910347, 'Total loss': 0.45819792794910347} | train loss {'Reaction outcome loss': 0.4518390391554151, 'Total loss': 0.4518390391554151}
2022-11-28 05:10:14,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:14,038 INFO:     Epoch: 66
2022-11-28 05:10:14,700 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4941660203039646, 'Total loss': 0.4941660203039646} | train loss {'Reaction outcome loss': 0.4584622214035112, 'Total loss': 0.4584622214035112}
2022-11-28 05:10:14,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:14,700 INFO:     Epoch: 67
2022-11-28 05:10:15,362 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44274169646880845, 'Total loss': 0.44274169646880845} | train loss {'Reaction outcome loss': 0.45327837911187385, 'Total loss': 0.45327837911187385}
2022-11-28 05:10:15,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:15,363 INFO:     Epoch: 68
2022-11-28 05:10:16,023 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5055018551647663, 'Total loss': 0.5055018551647663} | train loss {'Reaction outcome loss': 0.4674530252510188, 'Total loss': 0.4674530252510188}
2022-11-28 05:10:16,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:16,023 INFO:     Epoch: 69
2022-11-28 05:10:16,682 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4827436427162452, 'Total loss': 0.4827436427162452} | train loss {'Reaction outcome loss': 0.45550120174884795, 'Total loss': 0.45550120174884795}
2022-11-28 05:10:16,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:16,682 INFO:     Epoch: 70
2022-11-28 05:10:17,340 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4513908872296187, 'Total loss': 0.4513908872296187} | train loss {'Reaction outcome loss': 0.4546360287739306, 'Total loss': 0.4546360287739306}
2022-11-28 05:10:17,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:17,341 INFO:     Epoch: 71
2022-11-28 05:10:17,997 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49436699226498604, 'Total loss': 0.49436699226498604} | train loss {'Reaction outcome loss': 0.4502048238199584, 'Total loss': 0.4502048238199584}
2022-11-28 05:10:17,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:17,997 INFO:     Epoch: 72
2022-11-28 05:10:18,651 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4448636956512928, 'Total loss': 0.4448636956512928} | train loss {'Reaction outcome loss': 0.4632885337484126, 'Total loss': 0.4632885337484126}
2022-11-28 05:10:18,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:18,651 INFO:     Epoch: 73
2022-11-28 05:10:19,308 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46394460986961017, 'Total loss': 0.46394460986961017} | train loss {'Reaction outcome loss': 0.45429886226751365, 'Total loss': 0.45429886226751365}
2022-11-28 05:10:19,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:19,309 INFO:     Epoch: 74
2022-11-28 05:10:19,968 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4756484173915603, 'Total loss': 0.4756484173915603} | train loss {'Reaction outcome loss': 0.45375035405159, 'Total loss': 0.45375035405159}
2022-11-28 05:10:19,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:19,968 INFO:     Epoch: 75
2022-11-28 05:10:20,623 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44288841262459755, 'Total loss': 0.44288841262459755} | train loss {'Reaction outcome loss': 0.4507759322013174, 'Total loss': 0.4507759322013174}
2022-11-28 05:10:20,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:20,624 INFO:     Epoch: 76
2022-11-28 05:10:21,280 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.438161519610069, 'Total loss': 0.438161519610069} | train loss {'Reaction outcome loss': 0.4513451361534547, 'Total loss': 0.4513451361534547}
2022-11-28 05:10:21,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:21,280 INFO:     Epoch: 77
2022-11-28 05:10:21,936 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4602315940640189, 'Total loss': 0.4602315940640189} | train loss {'Reaction outcome loss': 0.45608485444467894, 'Total loss': 0.45608485444467894}
2022-11-28 05:10:21,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:21,937 INFO:     Epoch: 78
2022-11-28 05:10:22,594 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4628380587832494, 'Total loss': 0.4628380587832494} | train loss {'Reaction outcome loss': 0.4592412913940391, 'Total loss': 0.4592412913940391}
2022-11-28 05:10:22,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:22,594 INFO:     Epoch: 79
2022-11-28 05:10:23,250 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4452839727428826, 'Total loss': 0.4452839727428826} | train loss {'Reaction outcome loss': 0.4560708109821592, 'Total loss': 0.4560708109821592}
2022-11-28 05:10:23,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:23,250 INFO:     Epoch: 80
2022-11-28 05:10:23,910 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5449070625684478, 'Total loss': 0.5449070625684478} | train loss {'Reaction outcome loss': 0.45305683345210795, 'Total loss': 0.45305683345210795}
2022-11-28 05:10:23,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:23,911 INFO:     Epoch: 81
2022-11-28 05:10:24,572 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4675614901564338, 'Total loss': 0.4675614901564338} | train loss {'Reaction outcome loss': 0.4606440455329662, 'Total loss': 0.4606440455329662}
2022-11-28 05:10:24,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:24,572 INFO:     Epoch: 82
2022-11-28 05:10:25,226 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49840892444957385, 'Total loss': 0.49840892444957385} | train loss {'Reaction outcome loss': 0.45711297940234746, 'Total loss': 0.45711297940234746}
2022-11-28 05:10:25,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:25,226 INFO:     Epoch: 83
2022-11-28 05:10:25,882 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.477859478443861, 'Total loss': 0.477859478443861} | train loss {'Reaction outcome loss': 0.4496059061009057, 'Total loss': 0.4496059061009057}
2022-11-28 05:10:25,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:25,882 INFO:     Epoch: 84
2022-11-28 05:10:26,541 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46556446531956847, 'Total loss': 0.46556446531956847} | train loss {'Reaction outcome loss': 0.4485832401380247, 'Total loss': 0.4485832401380247}
2022-11-28 05:10:26,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:26,541 INFO:     Epoch: 85
2022-11-28 05:10:27,201 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4385224021971226, 'Total loss': 0.4385224021971226} | train loss {'Reaction outcome loss': 0.4664807226584882, 'Total loss': 0.4664807226584882}
2022-11-28 05:10:27,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:27,201 INFO:     Epoch: 86
2022-11-28 05:10:27,858 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46119504557414487, 'Total loss': 0.46119504557414487} | train loss {'Reaction outcome loss': 0.4501018532684871, 'Total loss': 0.4501018532684871}
2022-11-28 05:10:27,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:27,858 INFO:     Epoch: 87
2022-11-28 05:10:28,519 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45249804854393005, 'Total loss': 0.45249804854393005} | train loss {'Reaction outcome loss': 0.45990177724434406, 'Total loss': 0.45990177724434406}
2022-11-28 05:10:28,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:28,519 INFO:     Epoch: 88
2022-11-28 05:10:29,177 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48990257626230066, 'Total loss': 0.48990257626230066} | train loss {'Reaction outcome loss': 0.4581198483705521, 'Total loss': 0.4581198483705521}
2022-11-28 05:10:29,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:29,177 INFO:     Epoch: 89
2022-11-28 05:10:29,831 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.545433605259115, 'Total loss': 0.545433605259115} | train loss {'Reaction outcome loss': 0.4635481283372762, 'Total loss': 0.4635481283372762}
2022-11-28 05:10:29,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:29,832 INFO:     Epoch: 90
2022-11-28 05:10:30,488 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4695482530038465, 'Total loss': 0.4695482530038465} | train loss {'Reaction outcome loss': 0.4602775854723794, 'Total loss': 0.4602775854723794}
2022-11-28 05:10:30,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:30,488 INFO:     Epoch: 91
2022-11-28 05:10:31,145 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46659004044803704, 'Total loss': 0.46659004044803704} | train loss {'Reaction outcome loss': 0.45099957378543154, 'Total loss': 0.45099957378543154}
2022-11-28 05:10:31,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:31,145 INFO:     Epoch: 92
2022-11-28 05:10:31,800 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4347916458818046, 'Total loss': 0.4347916458818046} | train loss {'Reaction outcome loss': 0.45864522964978705, 'Total loss': 0.45864522964978705}
2022-11-28 05:10:31,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:31,800 INFO:     Epoch: 93
2022-11-28 05:10:32,457 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4622068764133887, 'Total loss': 0.4622068764133887} | train loss {'Reaction outcome loss': 0.4455123529446368, 'Total loss': 0.4455123529446368}
2022-11-28 05:10:32,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:32,457 INFO:     Epoch: 94
2022-11-28 05:10:33,112 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46422402594577183, 'Total loss': 0.46422402594577183} | train loss {'Reaction outcome loss': 0.45836867829974814, 'Total loss': 0.45836867829974814}
2022-11-28 05:10:33,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:33,112 INFO:     Epoch: 95
2022-11-28 05:10:33,768 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47484017366712744, 'Total loss': 0.47484017366712744} | train loss {'Reaction outcome loss': 0.4585937635630977, 'Total loss': 0.4585937635630977}
2022-11-28 05:10:33,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:33,769 INFO:     Epoch: 96
2022-11-28 05:10:34,426 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4555170505561612, 'Total loss': 0.4555170505561612} | train loss {'Reaction outcome loss': 0.4595414834971331, 'Total loss': 0.4595414834971331}
2022-11-28 05:10:34,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:34,427 INFO:     Epoch: 97
2022-11-28 05:10:35,083 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5326040116223422, 'Total loss': 0.5326040116223422} | train loss {'Reaction outcome loss': 0.4592213811314836, 'Total loss': 0.4592213811314836}
2022-11-28 05:10:35,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:35,083 INFO:     Epoch: 98
2022-11-28 05:10:35,739 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46769070625305176, 'Total loss': 0.46769070625305176} | train loss {'Reaction outcome loss': 0.4598859434833332, 'Total loss': 0.4598859434833332}
2022-11-28 05:10:35,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:35,740 INFO:     Epoch: 99
2022-11-28 05:10:36,398 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45499874956228514, 'Total loss': 0.45499874956228514} | train loss {'Reaction outcome loss': 0.4533686944416591, 'Total loss': 0.4533686944416591}
2022-11-28 05:10:36,398 INFO:     Best model found after epoch 54 of 100.
2022-11-28 05:10:36,398 INFO:   Done with stage: TRAINING
2022-11-28 05:10:36,398 INFO:   Starting stage: EVALUATION
2022-11-28 05:10:36,522 INFO:   Done with stage: EVALUATION
2022-11-28 05:10:36,522 INFO:   Leaving out SEQ value Fold_4
2022-11-28 05:10:36,535 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 05:10:36,535 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:10:37,187 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:10:37,187 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:10:37,257 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:10:37,257 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:10:37,257 INFO:     No hyperparam tuning for this model
2022-11-28 05:10:37,257 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:10:37,257 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:10:37,258 INFO:     None feature selector for col prot
2022-11-28 05:10:37,258 INFO:     None feature selector for col prot
2022-11-28 05:10:37,258 INFO:     None feature selector for col prot
2022-11-28 05:10:37,259 INFO:     None feature selector for col chem
2022-11-28 05:10:37,259 INFO:     None feature selector for col chem
2022-11-28 05:10:37,259 INFO:     None feature selector for col chem
2022-11-28 05:10:37,259 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:10:37,259 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:10:37,260 INFO:     Number of params in model 169651
2022-11-28 05:10:37,263 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:10:37,264 INFO:   Starting stage: TRAINING
2022-11-28 05:10:37,315 INFO:     Val loss before train {'Reaction outcome loss': 0.9685080728747628, 'Total loss': 0.9685080728747628}
2022-11-28 05:10:37,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:37,315 INFO:     Epoch: 0
2022-11-28 05:10:37,975 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5908067138357596, 'Total loss': 0.5908067138357596} | train loss {'Reaction outcome loss': 0.6871029121974702, 'Total loss': 0.6871029121974702}
2022-11-28 05:10:37,975 INFO:     Found new best model at epoch 0
2022-11-28 05:10:37,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:37,976 INFO:     Epoch: 1
2022-11-28 05:10:38,636 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5641689408909191, 'Total loss': 0.5641689408909191} | train loss {'Reaction outcome loss': 0.5906007917303788, 'Total loss': 0.5906007917303788}
2022-11-28 05:10:38,636 INFO:     Found new best model at epoch 1
2022-11-28 05:10:38,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:38,637 INFO:     Epoch: 2
2022-11-28 05:10:39,298 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5504717941988598, 'Total loss': 0.5504717941988598} | train loss {'Reaction outcome loss': 0.5587790355025998, 'Total loss': 0.5587790355025998}
2022-11-28 05:10:39,298 INFO:     Found new best model at epoch 2
2022-11-28 05:10:39,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:39,299 INFO:     Epoch: 3
2022-11-28 05:10:39,961 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5419608537446369, 'Total loss': 0.5419608537446369} | train loss {'Reaction outcome loss': 0.5494646161553348, 'Total loss': 0.5494646161553348}
2022-11-28 05:10:39,961 INFO:     Found new best model at epoch 3
2022-11-28 05:10:39,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:39,962 INFO:     Epoch: 4
2022-11-28 05:10:40,623 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5328222228722139, 'Total loss': 0.5328222228722139} | train loss {'Reaction outcome loss': 0.5214958862375151, 'Total loss': 0.5214958862375151}
2022-11-28 05:10:40,623 INFO:     Found new best model at epoch 4
2022-11-28 05:10:40,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:40,624 INFO:     Epoch: 5
2022-11-28 05:10:41,281 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4887987873093648, 'Total loss': 0.4887987873093648} | train loss {'Reaction outcome loss': 0.5132513720134975, 'Total loss': 0.5132513720134975}
2022-11-28 05:10:41,282 INFO:     Found new best model at epoch 5
2022-11-28 05:10:41,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:41,282 INFO:     Epoch: 6
2022-11-28 05:10:41,941 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4922023229300976, 'Total loss': 0.4922023229300976} | train loss {'Reaction outcome loss': 0.5072488012584114, 'Total loss': 0.5072488012584114}
2022-11-28 05:10:41,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:41,941 INFO:     Epoch: 7
2022-11-28 05:10:42,601 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4862434278157624, 'Total loss': 0.4862434278157624} | train loss {'Reaction outcome loss': 0.4947238447076758, 'Total loss': 0.4947238447076758}
2022-11-28 05:10:42,602 INFO:     Found new best model at epoch 7
2022-11-28 05:10:42,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:42,602 INFO:     Epoch: 8
2022-11-28 05:10:43,263 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5353966443376108, 'Total loss': 0.5353966443376108} | train loss {'Reaction outcome loss': 0.486948055686497, 'Total loss': 0.486948055686497}
2022-11-28 05:10:43,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:43,263 INFO:     Epoch: 9
2022-11-28 05:10:43,927 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5411700816317038, 'Total loss': 0.5411700816317038} | train loss {'Reaction outcome loss': 0.4870313571290931, 'Total loss': 0.4870313571290931}
2022-11-28 05:10:43,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:43,927 INFO:     Epoch: 10
2022-11-28 05:10:44,587 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.492585417221893, 'Total loss': 0.492585417221893} | train loss {'Reaction outcome loss': 0.485403945993798, 'Total loss': 0.485403945993798}
2022-11-28 05:10:44,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:44,587 INFO:     Epoch: 11
2022-11-28 05:10:45,248 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4858539388938384, 'Total loss': 0.4858539388938384} | train loss {'Reaction outcome loss': 0.4821132365086301, 'Total loss': 0.4821132365086301}
2022-11-28 05:10:45,248 INFO:     Found new best model at epoch 11
2022-11-28 05:10:45,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:45,249 INFO:     Epoch: 12
2022-11-28 05:10:45,911 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5116609235040166, 'Total loss': 0.5116609235040166} | train loss {'Reaction outcome loss': 0.48486902754799077, 'Total loss': 0.48486902754799077}
2022-11-28 05:10:45,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:45,912 INFO:     Epoch: 13
2022-11-28 05:10:46,579 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4752762774852189, 'Total loss': 0.4752762774852189} | train loss {'Reaction outcome loss': 0.4825344974936744, 'Total loss': 0.4825344974936744}
2022-11-28 05:10:46,579 INFO:     Found new best model at epoch 13
2022-11-28 05:10:46,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:46,580 INFO:     Epoch: 14
2022-11-28 05:10:47,242 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47223288836804306, 'Total loss': 0.47223288836804306} | train loss {'Reaction outcome loss': 0.4841307519901137, 'Total loss': 0.4841307519901137}
2022-11-28 05:10:47,243 INFO:     Found new best model at epoch 14
2022-11-28 05:10:47,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:47,243 INFO:     Epoch: 15
2022-11-28 05:10:47,911 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4791912256994031, 'Total loss': 0.4791912256994031} | train loss {'Reaction outcome loss': 0.4836190189065238, 'Total loss': 0.4836190189065238}
2022-11-28 05:10:47,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:47,911 INFO:     Epoch: 16
2022-11-28 05:10:48,580 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46941338818181644, 'Total loss': 0.46941338818181644} | train loss {'Reaction outcome loss': 0.4854131723162134, 'Total loss': 0.4854131723162134}
2022-11-28 05:10:48,580 INFO:     Found new best model at epoch 16
2022-11-28 05:10:48,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:48,581 INFO:     Epoch: 17
2022-11-28 05:10:49,253 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4931499761613933, 'Total loss': 0.4931499761613933} | train loss {'Reaction outcome loss': 0.47360168074762926, 'Total loss': 0.47360168074762926}
2022-11-28 05:10:49,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:49,253 INFO:     Epoch: 18
2022-11-28 05:10:49,918 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46795770255002106, 'Total loss': 0.46795770255002106} | train loss {'Reaction outcome loss': 0.47384891764407877, 'Total loss': 0.47384891764407877}
2022-11-28 05:10:49,919 INFO:     Found new best model at epoch 18
2022-11-28 05:10:49,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:49,919 INFO:     Epoch: 19
2022-11-28 05:10:50,582 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48903904922983865, 'Total loss': 0.48903904922983865} | train loss {'Reaction outcome loss': 0.4711913274533232, 'Total loss': 0.4711913274533232}
2022-11-28 05:10:50,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:50,582 INFO:     Epoch: 20
2022-11-28 05:10:51,245 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.511706022376364, 'Total loss': 0.511706022376364} | train loss {'Reaction outcome loss': 0.46589346194587017, 'Total loss': 0.46589346194587017}
2022-11-28 05:10:51,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:51,246 INFO:     Epoch: 21
2022-11-28 05:10:51,910 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4799226972867142, 'Total loss': 0.4799226972867142} | train loss {'Reaction outcome loss': 0.472245140536594, 'Total loss': 0.472245140536594}
2022-11-28 05:10:51,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:51,911 INFO:     Epoch: 22
2022-11-28 05:10:52,575 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5387261814691804, 'Total loss': 0.5387261814691804} | train loss {'Reaction outcome loss': 0.47005488660171446, 'Total loss': 0.47005488660171446}
2022-11-28 05:10:52,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:52,575 INFO:     Epoch: 23
2022-11-28 05:10:53,238 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5177740193903446, 'Total loss': 0.5177740193903446} | train loss {'Reaction outcome loss': 0.47947678585284154, 'Total loss': 0.47947678585284154}
2022-11-28 05:10:53,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:53,238 INFO:     Epoch: 24
2022-11-28 05:10:53,902 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4651660607619719, 'Total loss': 0.4651660607619719} | train loss {'Reaction outcome loss': 0.4804713006790252, 'Total loss': 0.4804713006790252}
2022-11-28 05:10:53,902 INFO:     Found new best model at epoch 24
2022-11-28 05:10:53,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:53,903 INFO:     Epoch: 25
2022-11-28 05:10:54,566 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5080006769434973, 'Total loss': 0.5080006769434973} | train loss {'Reaction outcome loss': 0.4640355423877114, 'Total loss': 0.4640355423877114}
2022-11-28 05:10:54,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:54,566 INFO:     Epoch: 26
2022-11-28 05:10:55,232 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4871685322035443, 'Total loss': 0.4871685322035443} | train loss {'Reaction outcome loss': 0.47104272418297255, 'Total loss': 0.47104272418297255}
2022-11-28 05:10:55,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:55,232 INFO:     Epoch: 27
2022-11-28 05:10:55,896 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5160596567121419, 'Total loss': 0.5160596567121419} | train loss {'Reaction outcome loss': 0.48954476021335797, 'Total loss': 0.48954476021335797}
2022-11-28 05:10:55,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:55,896 INFO:     Epoch: 28
2022-11-28 05:10:56,560 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4944431016390974, 'Total loss': 0.4944431016390974} | train loss {'Reaction outcome loss': 0.4680835270447287, 'Total loss': 0.4680835270447287}
2022-11-28 05:10:56,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:56,560 INFO:     Epoch: 29
2022-11-28 05:10:57,224 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5536455075171861, 'Total loss': 0.5536455075171861} | train loss {'Reaction outcome loss': 0.4712961136329512, 'Total loss': 0.4712961136329512}
2022-11-28 05:10:57,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:57,224 INFO:     Epoch: 30
2022-11-28 05:10:57,887 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46087631447748706, 'Total loss': 0.46087631447748706} | train loss {'Reaction outcome loss': 0.4855232449316303, 'Total loss': 0.4855232449316303}
2022-11-28 05:10:57,887 INFO:     Found new best model at epoch 30
2022-11-28 05:10:57,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:57,888 INFO:     Epoch: 31
2022-11-28 05:10:58,550 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.466098776595159, 'Total loss': 0.466098776595159} | train loss {'Reaction outcome loss': 0.47807502910977434, 'Total loss': 0.47807502910977434}
2022-11-28 05:10:58,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:58,550 INFO:     Epoch: 32
2022-11-28 05:10:59,212 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5127726996486838, 'Total loss': 0.5127726996486838} | train loss {'Reaction outcome loss': 0.4724633573641179, 'Total loss': 0.4724633573641179}
2022-11-28 05:10:59,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:59,212 INFO:     Epoch: 33
2022-11-28 05:10:59,875 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4949541220610792, 'Total loss': 0.4949541220610792} | train loss {'Reaction outcome loss': 0.47469873683383834, 'Total loss': 0.47469873683383834}
2022-11-28 05:10:59,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:10:59,875 INFO:     Epoch: 34
2022-11-28 05:11:00,535 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5069782974367792, 'Total loss': 0.5069782974367792} | train loss {'Reaction outcome loss': 0.46929846390297536, 'Total loss': 0.46929846390297536}
2022-11-28 05:11:00,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:00,536 INFO:     Epoch: 35
2022-11-28 05:11:01,197 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4947725595398383, 'Total loss': 0.4947725595398383} | train loss {'Reaction outcome loss': 0.46571297219649016, 'Total loss': 0.46571297219649016}
2022-11-28 05:11:01,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:01,197 INFO:     Epoch: 36
2022-11-28 05:11:01,858 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47116154161366547, 'Total loss': 0.47116154161366547} | train loss {'Reaction outcome loss': 0.4734404494605114, 'Total loss': 0.4734404494605114}
2022-11-28 05:11:01,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:01,858 INFO:     Epoch: 37
2022-11-28 05:11:02,523 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49180152436549013, 'Total loss': 0.49180152436549013} | train loss {'Reaction outcome loss': 0.46789382503703536, 'Total loss': 0.46789382503703536}
2022-11-28 05:11:02,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:02,523 INFO:     Epoch: 38
2022-11-28 05:11:03,184 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4967348805882714, 'Total loss': 0.4967348805882714} | train loss {'Reaction outcome loss': 0.4714872412353392, 'Total loss': 0.4714872412353392}
2022-11-28 05:11:03,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:03,184 INFO:     Epoch: 39
2022-11-28 05:11:03,845 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4671955308453603, 'Total loss': 0.4671955308453603} | train loss {'Reaction outcome loss': 0.4688831357820797, 'Total loss': 0.4688831357820797}
2022-11-28 05:11:03,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:03,846 INFO:     Epoch: 40
2022-11-28 05:11:04,506 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4984053505415266, 'Total loss': 0.4984053505415266} | train loss {'Reaction outcome loss': 0.47905450594811305, 'Total loss': 0.47905450594811305}
2022-11-28 05:11:04,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:04,507 INFO:     Epoch: 41
2022-11-28 05:11:05,165 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4881382215429436, 'Total loss': 0.4881382215429436} | train loss {'Reaction outcome loss': 0.4704955330020503, 'Total loss': 0.4704955330020503}
2022-11-28 05:11:05,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:05,166 INFO:     Epoch: 42
2022-11-28 05:11:05,826 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5389604490589012, 'Total loss': 0.5389604490589012} | train loss {'Reaction outcome loss': 0.46540584747004604, 'Total loss': 0.46540584747004604}
2022-11-28 05:11:05,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:05,826 INFO:     Epoch: 43
2022-11-28 05:11:06,489 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4677979949523102, 'Total loss': 0.4677979949523102} | train loss {'Reaction outcome loss': 0.46337450537001074, 'Total loss': 0.46337450537001074}
2022-11-28 05:11:06,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:06,489 INFO:     Epoch: 44
2022-11-28 05:11:07,152 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4835790399123322, 'Total loss': 0.4835790399123322} | train loss {'Reaction outcome loss': 0.4703889927762723, 'Total loss': 0.4703889927762723}
2022-11-28 05:11:07,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:07,152 INFO:     Epoch: 45
2022-11-28 05:11:07,815 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.480222687125206, 'Total loss': 0.480222687125206} | train loss {'Reaction outcome loss': 0.4749251511777461, 'Total loss': 0.4749251511777461}
2022-11-28 05:11:07,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:07,816 INFO:     Epoch: 46
2022-11-28 05:11:08,480 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47887667742642487, 'Total loss': 0.47887667742642487} | train loss {'Reaction outcome loss': 0.48489242746883077, 'Total loss': 0.48489242746883077}
2022-11-28 05:11:08,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:08,480 INFO:     Epoch: 47
2022-11-28 05:11:09,142 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4795563383535905, 'Total loss': 0.4795563383535905} | train loss {'Reaction outcome loss': 0.46705910847013293, 'Total loss': 0.46705910847013293}
2022-11-28 05:11:09,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:09,142 INFO:     Epoch: 48
2022-11-28 05:11:09,809 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5192409743639556, 'Total loss': 0.5192409743639556} | train loss {'Reaction outcome loss': 0.4720594792773849, 'Total loss': 0.4720594792773849}
2022-11-28 05:11:09,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:09,810 INFO:     Epoch: 49
2022-11-28 05:11:10,471 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5219705084508116, 'Total loss': 0.5219705084508116} | train loss {'Reaction outcome loss': 0.4847601109489738, 'Total loss': 0.4847601109489738}
2022-11-28 05:11:10,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:10,472 INFO:     Epoch: 50
2022-11-28 05:11:11,138 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46756216477264056, 'Total loss': 0.46756216477264056} | train loss {'Reaction outcome loss': 0.47729043105262736, 'Total loss': 0.47729043105262736}
2022-11-28 05:11:11,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:11,138 INFO:     Epoch: 51
2022-11-28 05:11:11,808 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48429176448421046, 'Total loss': 0.48429176448421046} | train loss {'Reaction outcome loss': 0.48346245005304517, 'Total loss': 0.48346245005304517}
2022-11-28 05:11:11,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:11,808 INFO:     Epoch: 52
2022-11-28 05:11:12,478 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.528743486512791, 'Total loss': 0.528743486512791} | train loss {'Reaction outcome loss': 0.48195874362218716, 'Total loss': 0.48195874362218716}
2022-11-28 05:11:12,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:12,478 INFO:     Epoch: 53
2022-11-28 05:11:13,150 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4743917984041301, 'Total loss': 0.4743917984041301} | train loss {'Reaction outcome loss': 0.4753794297877594, 'Total loss': 0.4753794297877594}
2022-11-28 05:11:13,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:13,150 INFO:     Epoch: 54
2022-11-28 05:11:13,817 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5201994966376912, 'Total loss': 0.5201994966376912} | train loss {'Reaction outcome loss': 0.46887527041321975, 'Total loss': 0.46887527041321975}
2022-11-28 05:11:13,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:13,817 INFO:     Epoch: 55
2022-11-28 05:11:14,485 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46860515055331314, 'Total loss': 0.46860515055331314} | train loss {'Reaction outcome loss': 0.46569562615894594, 'Total loss': 0.46569562615894594}
2022-11-28 05:11:14,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:14,486 INFO:     Epoch: 56
2022-11-28 05:11:15,150 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4748222753405571, 'Total loss': 0.4748222753405571} | train loss {'Reaction outcome loss': 0.4823314782216964, 'Total loss': 0.4823314782216964}
2022-11-28 05:11:15,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:15,151 INFO:     Epoch: 57
2022-11-28 05:11:15,816 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48048166321082547, 'Total loss': 0.48048166321082547} | train loss {'Reaction outcome loss': 0.4673800789392911, 'Total loss': 0.4673800789392911}
2022-11-28 05:11:15,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:15,817 INFO:     Epoch: 58
2022-11-28 05:11:16,478 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4729023687541485, 'Total loss': 0.4729023687541485} | train loss {'Reaction outcome loss': 0.4681965784520393, 'Total loss': 0.4681965784520393}
2022-11-28 05:11:16,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:16,479 INFO:     Epoch: 59
2022-11-28 05:11:17,143 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4711293283511292, 'Total loss': 0.4711293283511292} | train loss {'Reaction outcome loss': 0.4696921582526041, 'Total loss': 0.4696921582526041}
2022-11-28 05:11:17,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:17,144 INFO:     Epoch: 60
2022-11-28 05:11:17,809 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4575565735047514, 'Total loss': 0.4575565735047514} | train loss {'Reaction outcome loss': 0.47763358518058957, 'Total loss': 0.47763358518058957}
2022-11-28 05:11:17,809 INFO:     Found new best model at epoch 60
2022-11-28 05:11:17,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:17,810 INFO:     Epoch: 61
2022-11-28 05:11:18,473 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4998354336077517, 'Total loss': 0.4998354336077517} | train loss {'Reaction outcome loss': 0.47998612871778157, 'Total loss': 0.47998612871778157}
2022-11-28 05:11:18,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:18,473 INFO:     Epoch: 62
2022-11-28 05:11:19,135 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4869233461266214, 'Total loss': 0.4869233461266214} | train loss {'Reaction outcome loss': 0.46402129443430223, 'Total loss': 0.46402129443430223}
2022-11-28 05:11:19,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:19,135 INFO:     Epoch: 63
2022-11-28 05:11:19,798 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49202136288989673, 'Total loss': 0.49202136288989673} | train loss {'Reaction outcome loss': 0.46891145685665037, 'Total loss': 0.46891145685665037}
2022-11-28 05:11:19,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:19,798 INFO:     Epoch: 64
2022-11-28 05:11:20,462 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4749084037135948, 'Total loss': 0.4749084037135948} | train loss {'Reaction outcome loss': 0.47648359786884986, 'Total loss': 0.47648359786884986}
2022-11-28 05:11:20,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:20,463 INFO:     Epoch: 65
2022-11-28 05:11:21,128 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4657950574024157, 'Total loss': 0.4657950574024157} | train loss {'Reaction outcome loss': 0.47440935641165205, 'Total loss': 0.47440935641165205}
2022-11-28 05:11:21,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:21,128 INFO:     Epoch: 66
2022-11-28 05:11:21,790 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47910146889361466, 'Total loss': 0.47910146889361466} | train loss {'Reaction outcome loss': 0.4850735896651592, 'Total loss': 0.4850735896651592}
2022-11-28 05:11:21,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:21,791 INFO:     Epoch: 67
2022-11-28 05:11:22,455 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4698868715627627, 'Total loss': 0.4698868715627627} | train loss {'Reaction outcome loss': 0.4651624383800757, 'Total loss': 0.4651624383800757}
2022-11-28 05:11:22,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:22,456 INFO:     Epoch: 68
2022-11-28 05:11:23,120 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49284040656956757, 'Total loss': 0.49284040656956757} | train loss {'Reaction outcome loss': 0.46799073232571603, 'Total loss': 0.46799073232571603}
2022-11-28 05:11:23,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:23,120 INFO:     Epoch: 69
2022-11-28 05:11:23,784 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48585816167972307, 'Total loss': 0.48585816167972307} | train loss {'Reaction outcome loss': 0.48187818550146544, 'Total loss': 0.48187818550146544}
2022-11-28 05:11:23,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:23,785 INFO:     Epoch: 70
2022-11-28 05:11:24,451 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4838061454621228, 'Total loss': 0.4838061454621228} | train loss {'Reaction outcome loss': 0.47579750180365105, 'Total loss': 0.47579750180365105}
2022-11-28 05:11:24,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:24,451 INFO:     Epoch: 71
2022-11-28 05:11:25,114 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5129257159476931, 'Total loss': 0.5129257159476931} | train loss {'Reaction outcome loss': 0.46743207271041176, 'Total loss': 0.46743207271041176}
2022-11-28 05:11:25,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:25,114 INFO:     Epoch: 72
2022-11-28 05:11:25,779 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47454901242798025, 'Total loss': 0.47454901242798025} | train loss {'Reaction outcome loss': 0.4720090329647064, 'Total loss': 0.4720090329647064}
2022-11-28 05:11:25,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:25,780 INFO:     Epoch: 73
2022-11-28 05:11:26,444 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48163219609043817, 'Total loss': 0.48163219609043817} | train loss {'Reaction outcome loss': 0.46588779666163177, 'Total loss': 0.46588779666163177}
2022-11-28 05:11:26,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:26,444 INFO:     Epoch: 74
2022-11-28 05:11:27,108 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47921082241968677, 'Total loss': 0.47921082241968677} | train loss {'Reaction outcome loss': 0.47238839541369604, 'Total loss': 0.47238839541369604}
2022-11-28 05:11:27,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:27,108 INFO:     Epoch: 75
2022-11-28 05:11:27,777 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4633040807463906, 'Total loss': 0.4633040807463906} | train loss {'Reaction outcome loss': 0.4701246297673175, 'Total loss': 0.4701246297673175}
2022-11-28 05:11:27,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:27,777 INFO:     Epoch: 76
2022-11-28 05:11:28,440 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4857429513199763, 'Total loss': 0.4857429513199763} | train loss {'Reaction outcome loss': 0.4689888947526453, 'Total loss': 0.4689888947526453}
2022-11-28 05:11:28,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:28,440 INFO:     Epoch: 77
2022-11-28 05:11:29,104 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4956465922296047, 'Total loss': 0.4956465922296047} | train loss {'Reaction outcome loss': 0.46343054842611076, 'Total loss': 0.46343054842611076}
2022-11-28 05:11:29,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:29,104 INFO:     Epoch: 78
2022-11-28 05:11:29,767 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5130271850661798, 'Total loss': 0.5130271850661798} | train loss {'Reaction outcome loss': 0.4723852391728023, 'Total loss': 0.4723852391728023}
2022-11-28 05:11:29,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:29,767 INFO:     Epoch: 79
2022-11-28 05:11:30,430 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4773123907771977, 'Total loss': 0.4773123907771977} | train loss {'Reaction outcome loss': 0.46962909997716124, 'Total loss': 0.46962909997716124}
2022-11-28 05:11:30,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:30,430 INFO:     Epoch: 80
2022-11-28 05:11:31,097 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4826854226941412, 'Total loss': 0.4826854226941412} | train loss {'Reaction outcome loss': 0.47146847910485284, 'Total loss': 0.47146847910485284}
2022-11-28 05:11:31,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:31,097 INFO:     Epoch: 81
2022-11-28 05:11:31,758 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5605116398497061, 'Total loss': 0.5605116398497061} | train loss {'Reaction outcome loss': 0.4707646132239446, 'Total loss': 0.4707646132239446}
2022-11-28 05:11:31,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:31,758 INFO:     Epoch: 82
2022-11-28 05:11:32,417 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4875888062471693, 'Total loss': 0.4875888062471693} | train loss {'Reaction outcome loss': 0.48431737646309714, 'Total loss': 0.48431737646309714}
2022-11-28 05:11:32,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:32,417 INFO:     Epoch: 83
2022-11-28 05:11:33,077 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4794662185013294, 'Total loss': 0.4794662185013294} | train loss {'Reaction outcome loss': 0.4683616345951914, 'Total loss': 0.4683616345951914}
2022-11-28 05:11:33,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:33,077 INFO:     Epoch: 84
2022-11-28 05:11:33,738 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5017545111477375, 'Total loss': 0.5017545111477375} | train loss {'Reaction outcome loss': 0.47349213492049863, 'Total loss': 0.47349213492049863}
2022-11-28 05:11:33,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:33,739 INFO:     Epoch: 85
2022-11-28 05:11:34,397 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4840612018650228, 'Total loss': 0.4840612018650228} | train loss {'Reaction outcome loss': 0.46123903413653855, 'Total loss': 0.46123903413653855}
2022-11-28 05:11:34,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:34,397 INFO:     Epoch: 86
2022-11-28 05:11:35,058 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4926365871321071, 'Total loss': 0.4926365871321071} | train loss {'Reaction outcome loss': 0.4697571015362496, 'Total loss': 0.4697571015362496}
2022-11-28 05:11:35,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:35,059 INFO:     Epoch: 87
2022-11-28 05:11:35,724 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48009860718792136, 'Total loss': 0.48009860718792136} | train loss {'Reaction outcome loss': 0.4776416456530451, 'Total loss': 0.4776416456530451}
2022-11-28 05:11:35,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:35,725 INFO:     Epoch: 88
2022-11-28 05:11:36,383 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4736906357786872, 'Total loss': 0.4736906357786872} | train loss {'Reaction outcome loss': 0.4790077293932679, 'Total loss': 0.4790077293932679}
2022-11-28 05:11:36,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:36,383 INFO:     Epoch: 89
2022-11-28 05:11:37,043 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4857571724463593, 'Total loss': 0.4857571724463593} | train loss {'Reaction outcome loss': 0.4701535899629477, 'Total loss': 0.4701535899629477}
2022-11-28 05:11:37,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:37,044 INFO:     Epoch: 90
2022-11-28 05:11:37,704 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47858847796239634, 'Total loss': 0.47858847796239634} | train loss {'Reaction outcome loss': 0.4632471637528857, 'Total loss': 0.4632471637528857}
2022-11-28 05:11:37,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:37,704 INFO:     Epoch: 91
2022-11-28 05:11:38,363 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5154176164757122, 'Total loss': 0.5154176164757122} | train loss {'Reaction outcome loss': 0.46636321404684894, 'Total loss': 0.46636321404684894}
2022-11-28 05:11:38,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:38,363 INFO:     Epoch: 92
2022-11-28 05:11:39,022 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5130467844957655, 'Total loss': 0.5130467844957655} | train loss {'Reaction outcome loss': 0.469248298340692, 'Total loss': 0.469248298340692}
2022-11-28 05:11:39,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:39,022 INFO:     Epoch: 93
2022-11-28 05:11:39,684 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5299798781898889, 'Total loss': 0.5299798781898889} | train loss {'Reaction outcome loss': 0.4779400965462812, 'Total loss': 0.4779400965462812}
2022-11-28 05:11:39,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:39,684 INFO:     Epoch: 94
2022-11-28 05:11:40,348 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5012258220125329, 'Total loss': 0.5012258220125329} | train loss {'Reaction outcome loss': 0.503788839467624, 'Total loss': 0.503788839467624}
2022-11-28 05:11:40,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:40,349 INFO:     Epoch: 95
2022-11-28 05:11:41,011 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48105296153913846, 'Total loss': 0.48105296153913846} | train loss {'Reaction outcome loss': 0.47753826706756947, 'Total loss': 0.47753826706756947}
2022-11-28 05:11:41,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:41,011 INFO:     Epoch: 96
2022-11-28 05:11:41,672 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4772874291308902, 'Total loss': 0.4772874291308902} | train loss {'Reaction outcome loss': 0.4782728452522021, 'Total loss': 0.4782728452522021}
2022-11-28 05:11:41,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:41,672 INFO:     Epoch: 97
2022-11-28 05:11:42,337 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49382712014696817, 'Total loss': 0.49382712014696817} | train loss {'Reaction outcome loss': 0.46832735960745075, 'Total loss': 0.46832735960745075}
2022-11-28 05:11:42,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:42,338 INFO:     Epoch: 98
2022-11-28 05:11:43,000 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5061894154006784, 'Total loss': 0.5061894154006784} | train loss {'Reaction outcome loss': 0.4708148250695665, 'Total loss': 0.4708148250695665}
2022-11-28 05:11:43,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:43,000 INFO:     Epoch: 99
2022-11-28 05:11:43,664 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5266494209116156, 'Total loss': 0.5266494209116156} | train loss {'Reaction outcome loss': 0.4709822151221727, 'Total loss': 0.4709822151221727}
2022-11-28 05:11:43,664 INFO:     Best model found after epoch 61 of 100.
2022-11-28 05:11:43,664 INFO:   Done with stage: TRAINING
2022-11-28 05:11:43,664 INFO:   Starting stage: EVALUATION
2022-11-28 05:11:43,781 INFO:   Done with stage: EVALUATION
2022-11-28 05:11:43,781 INFO:   Leaving out SEQ value Fold_5
2022-11-28 05:11:43,794 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 05:11:43,794 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:11:44,452 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:11:44,453 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:11:44,523 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:11:44,523 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:11:44,523 INFO:     No hyperparam tuning for this model
2022-11-28 05:11:44,523 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:11:44,523 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:11:44,524 INFO:     None feature selector for col prot
2022-11-28 05:11:44,524 INFO:     None feature selector for col prot
2022-11-28 05:11:44,524 INFO:     None feature selector for col prot
2022-11-28 05:11:44,525 INFO:     None feature selector for col chem
2022-11-28 05:11:44,525 INFO:     None feature selector for col chem
2022-11-28 05:11:44,525 INFO:     None feature selector for col chem
2022-11-28 05:11:44,525 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:11:44,525 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:11:44,526 INFO:     Number of params in model 169651
2022-11-28 05:11:44,529 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:11:44,530 INFO:   Starting stage: TRAINING
2022-11-28 05:11:44,580 INFO:     Val loss before train {'Reaction outcome loss': 1.014178486710245, 'Total loss': 1.014178486710245}
2022-11-28 05:11:44,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:44,581 INFO:     Epoch: 0
2022-11-28 05:11:45,243 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5884216529401866, 'Total loss': 0.5884216529401866} | train loss {'Reaction outcome loss': 0.6721689956119428, 'Total loss': 0.6721689956119428}
2022-11-28 05:11:45,243 INFO:     Found new best model at epoch 0
2022-11-28 05:11:45,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:45,244 INFO:     Epoch: 1
2022-11-28 05:11:45,911 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5966104357080027, 'Total loss': 0.5966104357080027} | train loss {'Reaction outcome loss': 0.57201312397897, 'Total loss': 0.57201312397897}
2022-11-28 05:11:45,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:45,911 INFO:     Epoch: 2
2022-11-28 05:11:46,573 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6154654019258239, 'Total loss': 0.6154654019258239} | train loss {'Reaction outcome loss': 0.5522684120094246, 'Total loss': 0.5522684120094246}
2022-11-28 05:11:46,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:46,573 INFO:     Epoch: 3
2022-11-28 05:11:47,236 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5524299788204107, 'Total loss': 0.5524299788204107} | train loss {'Reaction outcome loss': 0.5475900286680412, 'Total loss': 0.5475900286680412}
2022-11-28 05:11:47,237 INFO:     Found new best model at epoch 3
2022-11-28 05:11:47,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:47,237 INFO:     Epoch: 4
2022-11-28 05:11:47,901 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.588416981764815, 'Total loss': 0.588416981764815} | train loss {'Reaction outcome loss': 0.5189670903480005, 'Total loss': 0.5189670903480005}
2022-11-28 05:11:47,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:47,902 INFO:     Epoch: 5
2022-11-28 05:11:48,562 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5720417343757369, 'Total loss': 0.5720417343757369} | train loss {'Reaction outcome loss': 0.5196893109189655, 'Total loss': 0.5196893109189655}
2022-11-28 05:11:48,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:48,564 INFO:     Epoch: 6
2022-11-28 05:11:49,224 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5241494720632379, 'Total loss': 0.5241494720632379} | train loss {'Reaction outcome loss': 0.506378362053319, 'Total loss': 0.506378362053319}
2022-11-28 05:11:49,224 INFO:     Found new best model at epoch 6
2022-11-28 05:11:49,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:49,225 INFO:     Epoch: 7
2022-11-28 05:11:49,890 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5071737590161237, 'Total loss': 0.5071737590161237} | train loss {'Reaction outcome loss': 0.5031817395556794, 'Total loss': 0.5031817395556794}
2022-11-28 05:11:49,890 INFO:     Found new best model at epoch 7
2022-11-28 05:11:49,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:49,891 INFO:     Epoch: 8
2022-11-28 05:11:50,554 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5002700432457707, 'Total loss': 0.5002700432457707} | train loss {'Reaction outcome loss': 0.5046360880015832, 'Total loss': 0.5046360880015832}
2022-11-28 05:11:50,554 INFO:     Found new best model at epoch 8
2022-11-28 05:11:50,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:50,555 INFO:     Epoch: 9
2022-11-28 05:11:51,224 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5247134037993171, 'Total loss': 0.5247134037993171} | train loss {'Reaction outcome loss': 0.48716474487351985, 'Total loss': 0.48716474487351985}
2022-11-28 05:11:51,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:51,224 INFO:     Epoch: 10
2022-11-28 05:11:51,890 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45113095742734993, 'Total loss': 0.45113095742734993} | train loss {'Reaction outcome loss': 0.49619898954142444, 'Total loss': 0.49619898954142444}
2022-11-28 05:11:51,890 INFO:     Found new best model at epoch 10
2022-11-28 05:11:51,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:51,891 INFO:     Epoch: 11
2022-11-28 05:11:52,556 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4732369275932962, 'Total loss': 0.4732369275932962} | train loss {'Reaction outcome loss': 0.4965214149551353, 'Total loss': 0.4965214149551353}
2022-11-28 05:11:52,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:52,556 INFO:     Epoch: 12
2022-11-28 05:11:53,221 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5132609771733935, 'Total loss': 0.5132609771733935} | train loss {'Reaction outcome loss': 0.5036488663450427, 'Total loss': 0.5036488663450427}
2022-11-28 05:11:53,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:53,221 INFO:     Epoch: 13
2022-11-28 05:11:53,883 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4470505482432517, 'Total loss': 0.4470505482432517} | train loss {'Reaction outcome loss': 0.488883951052963, 'Total loss': 0.488883951052963}
2022-11-28 05:11:53,883 INFO:     Found new best model at epoch 13
2022-11-28 05:11:53,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:53,884 INFO:     Epoch: 14
2022-11-28 05:11:54,544 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47606471384113486, 'Total loss': 0.47606471384113486} | train loss {'Reaction outcome loss': 0.48525033610673085, 'Total loss': 0.48525033610673085}
2022-11-28 05:11:54,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:54,544 INFO:     Epoch: 15
2022-11-28 05:11:55,205 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.475256357003342, 'Total loss': 0.475256357003342} | train loss {'Reaction outcome loss': 0.47615202338348034, 'Total loss': 0.47615202338348034}
2022-11-28 05:11:55,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:55,206 INFO:     Epoch: 16
2022-11-28 05:11:55,868 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46691975302316924, 'Total loss': 0.46691975302316924} | train loss {'Reaction outcome loss': 0.47945019264935484, 'Total loss': 0.47945019264935484}
2022-11-28 05:11:55,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:55,869 INFO:     Epoch: 17
2022-11-28 05:11:56,527 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4532955918799747, 'Total loss': 0.4532955918799747} | train loss {'Reaction outcome loss': 0.4700794471314682, 'Total loss': 0.4700794471314682}
2022-11-28 05:11:56,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:56,527 INFO:     Epoch: 18
2022-11-28 05:11:57,187 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49073903025551274, 'Total loss': 0.49073903025551274} | train loss {'Reaction outcome loss': 0.47124918788550835, 'Total loss': 0.47124918788550835}
2022-11-28 05:11:57,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:57,187 INFO:     Epoch: 19
2022-11-28 05:11:57,848 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45303901555863296, 'Total loss': 0.45303901555863296} | train loss {'Reaction outcome loss': 0.4720896922866343, 'Total loss': 0.4720896922866343}
2022-11-28 05:11:57,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:57,848 INFO:     Epoch: 20
2022-11-28 05:11:58,507 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4616861329837279, 'Total loss': 0.4616861329837279} | train loss {'Reaction outcome loss': 0.4739032202223052, 'Total loss': 0.4739032202223052}
2022-11-28 05:11:58,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:58,508 INFO:     Epoch: 21
2022-11-28 05:11:59,168 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.501360800455917, 'Total loss': 0.501360800455917} | train loss {'Reaction outcome loss': 0.474355617176123, 'Total loss': 0.474355617176123}
2022-11-28 05:11:59,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:59,168 INFO:     Epoch: 22
2022-11-28 05:11:59,834 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44439267604188487, 'Total loss': 0.44439267604188487} | train loss {'Reaction outcome loss': 0.47132671874785714, 'Total loss': 0.47132671874785714}
2022-11-28 05:11:59,834 INFO:     Found new best model at epoch 22
2022-11-28 05:11:59,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:11:59,835 INFO:     Epoch: 23
2022-11-28 05:12:00,499 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4903308247978037, 'Total loss': 0.4903308247978037} | train loss {'Reaction outcome loss': 0.4695144576823663, 'Total loss': 0.4695144576823663}
2022-11-28 05:12:00,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:00,500 INFO:     Epoch: 24
2022-11-28 05:12:01,165 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.49856039407578384, 'Total loss': 0.49856039407578384} | train loss {'Reaction outcome loss': 0.47595160192082286, 'Total loss': 0.47595160192082286}
2022-11-28 05:12:01,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:01,165 INFO:     Epoch: 25
2022-11-28 05:12:01,830 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.510952692817558, 'Total loss': 0.510952692817558} | train loss {'Reaction outcome loss': 0.4852372595535116, 'Total loss': 0.4852372595535116}
2022-11-28 05:12:01,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:01,830 INFO:     Epoch: 26
2022-11-28 05:12:02,495 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4672027431767095, 'Total loss': 0.4672027431767095} | train loss {'Reaction outcome loss': 0.49039957180679566, 'Total loss': 0.49039957180679566}
2022-11-28 05:12:02,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:02,495 INFO:     Epoch: 27
2022-11-28 05:12:03,160 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45249274813316087, 'Total loss': 0.45249274813316087} | train loss {'Reaction outcome loss': 0.47033613805587476, 'Total loss': 0.47033613805587476}
2022-11-28 05:12:03,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:03,160 INFO:     Epoch: 28
2022-11-28 05:12:03,822 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46660548550161446, 'Total loss': 0.46660548550161446} | train loss {'Reaction outcome loss': 0.46871620823859206, 'Total loss': 0.46871620823859206}
2022-11-28 05:12:03,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:03,822 INFO:     Epoch: 29
2022-11-28 05:12:04,483 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48619888655164023, 'Total loss': 0.48619888655164023} | train loss {'Reaction outcome loss': 0.4680737707658335, 'Total loss': 0.4680737707658335}
2022-11-28 05:12:04,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:04,483 INFO:     Epoch: 30
2022-11-28 05:12:05,146 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4910765527324243, 'Total loss': 0.4910765527324243} | train loss {'Reaction outcome loss': 0.469390210774746, 'Total loss': 0.469390210774746}
2022-11-28 05:12:05,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:05,146 INFO:     Epoch: 31
2022-11-28 05:12:05,807 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4670023626901887, 'Total loss': 0.4670023626901887} | train loss {'Reaction outcome loss': 0.4699306313235026, 'Total loss': 0.4699306313235026}
2022-11-28 05:12:05,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:05,807 INFO:     Epoch: 32
2022-11-28 05:12:06,473 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.465111145241694, 'Total loss': 0.465111145241694} | train loss {'Reaction outcome loss': 0.47597140284926304, 'Total loss': 0.47597140284926304}
2022-11-28 05:12:06,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:06,473 INFO:     Epoch: 33
2022-11-28 05:12:07,140 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47692144255746494, 'Total loss': 0.47692144255746494} | train loss {'Reaction outcome loss': 0.476550557322589, 'Total loss': 0.476550557322589}
2022-11-28 05:12:07,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:07,140 INFO:     Epoch: 34
2022-11-28 05:12:07,805 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4575627293776382, 'Total loss': 0.4575627293776382} | train loss {'Reaction outcome loss': 0.4752218814996573, 'Total loss': 0.4752218814996573}
2022-11-28 05:12:07,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:07,806 INFO:     Epoch: 35
2022-11-28 05:12:08,467 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45036219162019814, 'Total loss': 0.45036219162019814} | train loss {'Reaction outcome loss': 0.47392206388687796, 'Total loss': 0.47392206388687796}
2022-11-28 05:12:08,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:08,467 INFO:     Epoch: 36
2022-11-28 05:12:09,132 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44944483922286466, 'Total loss': 0.44944483922286466} | train loss {'Reaction outcome loss': 0.4692932029484737, 'Total loss': 0.4692932029484737}
2022-11-28 05:12:09,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:09,132 INFO:     Epoch: 37
2022-11-28 05:12:09,797 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.471716913648627, 'Total loss': 0.471716913648627} | train loss {'Reaction outcome loss': 0.47191361165963686, 'Total loss': 0.47191361165963686}
2022-11-28 05:12:09,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:09,798 INFO:     Epoch: 38
2022-11-28 05:12:10,460 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4921310435641896, 'Total loss': 0.4921310435641896} | train loss {'Reaction outcome loss': 0.47186652911819427, 'Total loss': 0.47186652911819427}
2022-11-28 05:12:10,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:10,461 INFO:     Epoch: 39
2022-11-28 05:12:11,124 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47098286856304517, 'Total loss': 0.47098286856304517} | train loss {'Reaction outcome loss': 0.47657142802771285, 'Total loss': 0.47657142802771285}
2022-11-28 05:12:11,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:11,124 INFO:     Epoch: 40
2022-11-28 05:12:11,789 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45564432645385916, 'Total loss': 0.45564432645385916} | train loss {'Reaction outcome loss': 0.4880472246693213, 'Total loss': 0.4880472246693213}
2022-11-28 05:12:11,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:11,789 INFO:     Epoch: 41
2022-11-28 05:12:12,451 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46930026330731134, 'Total loss': 0.46930026330731134} | train loss {'Reaction outcome loss': 0.4703369032033542, 'Total loss': 0.4703369032033542}
2022-11-28 05:12:12,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:12,451 INFO:     Epoch: 42
2022-11-28 05:12:13,117 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45953596112403, 'Total loss': 0.45953596112403} | train loss {'Reaction outcome loss': 0.47412396466683765, 'Total loss': 0.47412396466683765}
2022-11-28 05:12:13,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:13,117 INFO:     Epoch: 43
2022-11-28 05:12:13,784 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48092394186691806, 'Total loss': 0.48092394186691806} | train loss {'Reaction outcome loss': 0.4646445600851345, 'Total loss': 0.4646445600851345}
2022-11-28 05:12:13,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:13,784 INFO:     Epoch: 44
2022-11-28 05:12:14,451 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4652474634349346, 'Total loss': 0.4652474634349346} | train loss {'Reaction outcome loss': 0.47503834027751735, 'Total loss': 0.47503834027751735}
2022-11-28 05:12:14,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:14,452 INFO:     Epoch: 45
2022-11-28 05:12:15,113 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4441576467996294, 'Total loss': 0.4441576467996294} | train loss {'Reaction outcome loss': 0.47124138444300123, 'Total loss': 0.47124138444300123}
2022-11-28 05:12:15,113 INFO:     Found new best model at epoch 45
2022-11-28 05:12:15,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:15,114 INFO:     Epoch: 46
2022-11-28 05:12:15,778 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46419838815927505, 'Total loss': 0.46419838815927505} | train loss {'Reaction outcome loss': 0.4668448164998761, 'Total loss': 0.4668448164998761}
2022-11-28 05:12:15,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:15,778 INFO:     Epoch: 47
2022-11-28 05:12:16,444 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4814750552177429, 'Total loss': 0.4814750552177429} | train loss {'Reaction outcome loss': 0.46708241925548444, 'Total loss': 0.46708241925548444}
2022-11-28 05:12:16,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:16,444 INFO:     Epoch: 48
2022-11-28 05:12:17,109 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44807052409107034, 'Total loss': 0.44807052409107034} | train loss {'Reaction outcome loss': 0.4649145281326916, 'Total loss': 0.4649145281326916}
2022-11-28 05:12:17,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:17,109 INFO:     Epoch: 49
2022-11-28 05:12:17,778 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4582340527664531, 'Total loss': 0.4582340527664531} | train loss {'Reaction outcome loss': 0.4616479669143314, 'Total loss': 0.4616479669143314}
2022-11-28 05:12:17,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:17,779 INFO:     Epoch: 50
2022-11-28 05:12:18,444 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4542790780013258, 'Total loss': 0.4542790780013258} | train loss {'Reaction outcome loss': 0.47590415313206463, 'Total loss': 0.47590415313206463}
2022-11-28 05:12:18,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:18,444 INFO:     Epoch: 51
2022-11-28 05:12:19,113 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5037383396517147, 'Total loss': 0.5037383396517147} | train loss {'Reaction outcome loss': 0.4675514147228558, 'Total loss': 0.4675514147228558}
2022-11-28 05:12:19,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:19,114 INFO:     Epoch: 52
2022-11-28 05:12:19,781 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45948206091468985, 'Total loss': 0.45948206091468985} | train loss {'Reaction outcome loss': 0.4813073335388894, 'Total loss': 0.4813073335388894}
2022-11-28 05:12:19,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:19,781 INFO:     Epoch: 53
2022-11-28 05:12:20,446 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46424647691574966, 'Total loss': 0.46424647691574966} | train loss {'Reaction outcome loss': 0.4735727333105527, 'Total loss': 0.4735727333105527}
2022-11-28 05:12:20,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:20,447 INFO:     Epoch: 54
2022-11-28 05:12:21,114 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45273617722771387, 'Total loss': 0.45273617722771387} | train loss {'Reaction outcome loss': 0.46347900383506224, 'Total loss': 0.46347900383506224}
2022-11-28 05:12:21,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:21,115 INFO:     Epoch: 55
2022-11-28 05:12:21,778 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45521530746058986, 'Total loss': 0.45521530746058986} | train loss {'Reaction outcome loss': 0.47081729344390183, 'Total loss': 0.47081729344390183}
2022-11-28 05:12:21,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:21,778 INFO:     Epoch: 56
2022-11-28 05:12:22,436 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46770541911775415, 'Total loss': 0.46770541911775415} | train loss {'Reaction outcome loss': 0.47202264130570804, 'Total loss': 0.47202264130570804}
2022-11-28 05:12:22,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:22,436 INFO:     Epoch: 57
2022-11-28 05:12:23,091 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4615208635276014, 'Total loss': 0.4615208635276014} | train loss {'Reaction outcome loss': 0.45881362912444934, 'Total loss': 0.45881362912444934}
2022-11-28 05:12:23,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:23,091 INFO:     Epoch: 58
2022-11-28 05:12:23,745 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44321392476558685, 'Total loss': 0.44321392476558685} | train loss {'Reaction outcome loss': 0.4622680606991656, 'Total loss': 0.4622680606991656}
2022-11-28 05:12:23,746 INFO:     Found new best model at epoch 58
2022-11-28 05:12:23,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:23,746 INFO:     Epoch: 59
2022-11-28 05:12:24,408 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5057423487305641, 'Total loss': 0.5057423487305641} | train loss {'Reaction outcome loss': 0.47508211620906104, 'Total loss': 0.47508211620906104}
2022-11-28 05:12:24,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:24,408 INFO:     Epoch: 60
2022-11-28 05:12:25,070 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4684355543418364, 'Total loss': 0.4684355543418364} | train loss {'Reaction outcome loss': 0.4790063368888036, 'Total loss': 0.4790063368888036}
2022-11-28 05:12:25,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:25,070 INFO:     Epoch: 61
2022-11-28 05:12:25,728 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.441801307214932, 'Total loss': 0.441801307214932} | train loss {'Reaction outcome loss': 0.472036762879445, 'Total loss': 0.472036762879445}
2022-11-28 05:12:25,728 INFO:     Found new best model at epoch 61
2022-11-28 05:12:25,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:25,729 INFO:     Epoch: 62
2022-11-28 05:12:26,386 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4643614085560495, 'Total loss': 0.4643614085560495} | train loss {'Reaction outcome loss': 0.47200971243993534, 'Total loss': 0.47200971243993534}
2022-11-28 05:12:26,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:26,386 INFO:     Epoch: 63
2022-11-28 05:12:27,042 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4687743437561122, 'Total loss': 0.4687743437561122} | train loss {'Reaction outcome loss': 0.4779173364402794, 'Total loss': 0.4779173364402794}
2022-11-28 05:12:27,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:27,042 INFO:     Epoch: 64
2022-11-28 05:12:27,697 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44454780322584236, 'Total loss': 0.44454780322584236} | train loss {'Reaction outcome loss': 0.5003449832681219, 'Total loss': 0.5003449832681219}
2022-11-28 05:12:27,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:27,697 INFO:     Epoch: 65
2022-11-28 05:12:28,355 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45145105570554733, 'Total loss': 0.45145105570554733} | train loss {'Reaction outcome loss': 0.4820903278887272, 'Total loss': 0.4820903278887272}
2022-11-28 05:12:28,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:28,356 INFO:     Epoch: 66
2022-11-28 05:12:29,014 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44263679297132924, 'Total loss': 0.44263679297132924} | train loss {'Reaction outcome loss': 0.47865981219509834, 'Total loss': 0.47865981219509834}
2022-11-28 05:12:29,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:29,014 INFO:     Epoch: 67
2022-11-28 05:12:29,668 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44801809604872356, 'Total loss': 0.44801809604872356} | train loss {'Reaction outcome loss': 0.4799552813534312, 'Total loss': 0.4799552813534312}
2022-11-28 05:12:29,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:29,669 INFO:     Epoch: 68
2022-11-28 05:12:30,326 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4517948173663833, 'Total loss': 0.4517948173663833} | train loss {'Reaction outcome loss': 0.467357762972353, 'Total loss': 0.467357762972353}
2022-11-28 05:12:30,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:30,326 INFO:     Epoch: 69
2022-11-28 05:12:30,986 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45602005042813043, 'Total loss': 0.45602005042813043} | train loss {'Reaction outcome loss': 0.4751502864273936, 'Total loss': 0.4751502864273936}
2022-11-28 05:12:30,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:30,986 INFO:     Epoch: 70
2022-11-28 05:12:31,644 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47833005914633925, 'Total loss': 0.47833005914633925} | train loss {'Reaction outcome loss': 0.47505474669730613, 'Total loss': 0.47505474669730613}
2022-11-28 05:12:31,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:31,645 INFO:     Epoch: 71
2022-11-28 05:12:32,302 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4851001897318797, 'Total loss': 0.4851001897318797} | train loss {'Reaction outcome loss': 0.4720705094245764, 'Total loss': 0.4720705094245764}
2022-11-28 05:12:32,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:32,303 INFO:     Epoch: 72
2022-11-28 05:12:32,960 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4896441847085953, 'Total loss': 0.4896441847085953} | train loss {'Reaction outcome loss': 0.48968588081207354, 'Total loss': 0.48968588081207354}
2022-11-28 05:12:32,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:32,960 INFO:     Epoch: 73
2022-11-28 05:12:33,617 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4427302770993926, 'Total loss': 0.4427302770993926} | train loss {'Reaction outcome loss': 0.49691192027528275, 'Total loss': 0.49691192027528275}
2022-11-28 05:12:33,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:33,617 INFO:     Epoch: 74
2022-11-28 05:12:34,274 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45341013270345604, 'Total loss': 0.45341013270345604} | train loss {'Reaction outcome loss': 0.47126422026138076, 'Total loss': 0.47126422026138076}
2022-11-28 05:12:34,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:34,275 INFO:     Epoch: 75
2022-11-28 05:12:34,931 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4859844258224422, 'Total loss': 0.4859844258224422} | train loss {'Reaction outcome loss': 0.4618036533415559, 'Total loss': 0.4618036533415559}
2022-11-28 05:12:34,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:34,931 INFO:     Epoch: 76
2022-11-28 05:12:35,589 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47134378112175246, 'Total loss': 0.47134378112175246} | train loss {'Reaction outcome loss': 0.4736301673308528, 'Total loss': 0.4736301673308528}
2022-11-28 05:12:35,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:35,589 INFO:     Epoch: 77
2022-11-28 05:12:36,246 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46482590958476067, 'Total loss': 0.46482590958476067} | train loss {'Reaction outcome loss': 0.46897583975369933, 'Total loss': 0.46897583975369933}
2022-11-28 05:12:36,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:36,247 INFO:     Epoch: 78
2022-11-28 05:12:36,906 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49138499999588187, 'Total loss': 0.49138499999588187} | train loss {'Reaction outcome loss': 0.46930043999603405, 'Total loss': 0.46930043999603405}
2022-11-28 05:12:36,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:36,906 INFO:     Epoch: 79
2022-11-28 05:12:37,563 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47727514803409576, 'Total loss': 0.47727514803409576} | train loss {'Reaction outcome loss': 0.47685406130817737, 'Total loss': 0.47685406130817737}
2022-11-28 05:12:37,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:37,563 INFO:     Epoch: 80
2022-11-28 05:12:38,221 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47307428378950467, 'Total loss': 0.47307428378950467} | train loss {'Reaction outcome loss': 0.473642158706631, 'Total loss': 0.473642158706631}
2022-11-28 05:12:38,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:38,222 INFO:     Epoch: 81
2022-11-28 05:12:38,879 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45260781794786453, 'Total loss': 0.45260781794786453} | train loss {'Reaction outcome loss': 0.46813205291747084, 'Total loss': 0.46813205291747084}
2022-11-28 05:12:38,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:38,879 INFO:     Epoch: 82
2022-11-28 05:12:39,538 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46876008808612823, 'Total loss': 0.46876008808612823} | train loss {'Reaction outcome loss': 0.46545585438699616, 'Total loss': 0.46545585438699616}
2022-11-28 05:12:39,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:39,538 INFO:     Epoch: 83
2022-11-28 05:12:40,199 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45339933850548486, 'Total loss': 0.45339933850548486} | train loss {'Reaction outcome loss': 0.4652413536270379, 'Total loss': 0.4652413536270379}
2022-11-28 05:12:40,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:40,199 INFO:     Epoch: 84
2022-11-28 05:12:40,862 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46284796026619995, 'Total loss': 0.46284796026619995} | train loss {'Reaction outcome loss': 0.4668511592062861, 'Total loss': 0.4668511592062861}
2022-11-28 05:12:40,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:40,863 INFO:     Epoch: 85
2022-11-28 05:12:41,521 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5150786214931444, 'Total loss': 0.5150786214931444} | train loss {'Reaction outcome loss': 0.47680905530689216, 'Total loss': 0.47680905530689216}
2022-11-28 05:12:41,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:41,521 INFO:     Epoch: 86
2022-11-28 05:12:42,180 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46092271127484064, 'Total loss': 0.46092271127484064} | train loss {'Reaction outcome loss': 0.4753198029722279, 'Total loss': 0.4753198029722279}
2022-11-28 05:12:42,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:42,181 INFO:     Epoch: 87
2022-11-28 05:12:42,844 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4993409091098742, 'Total loss': 0.4993409091098742} | train loss {'Reaction outcome loss': 0.4730917043109172, 'Total loss': 0.4730917043109172}
2022-11-28 05:12:42,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:42,844 INFO:     Epoch: 88
2022-11-28 05:12:43,506 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44506883688948373, 'Total loss': 0.44506883688948373} | train loss {'Reaction outcome loss': 0.48341547604273205, 'Total loss': 0.48341547604273205}
2022-11-28 05:12:43,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:43,506 INFO:     Epoch: 89
2022-11-28 05:12:44,166 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4520834783430804, 'Total loss': 0.4520834783430804} | train loss {'Reaction outcome loss': 0.47535055550003824, 'Total loss': 0.47535055550003824}
2022-11-28 05:12:44,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:44,167 INFO:     Epoch: 90
2022-11-28 05:12:44,824 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44902287728407164, 'Total loss': 0.44902287728407164} | train loss {'Reaction outcome loss': 0.4788922335092838, 'Total loss': 0.4788922335092838}
2022-11-28 05:12:44,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:44,824 INFO:     Epoch: 91
2022-11-28 05:12:45,484 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4970847209068862, 'Total loss': 0.4970847209068862} | train loss {'Reaction outcome loss': 0.4652400561853459, 'Total loss': 0.4652400561853459}
2022-11-28 05:12:45,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:45,484 INFO:     Epoch: 92
2022-11-28 05:12:46,144 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4483479796485467, 'Total loss': 0.4483479796485467} | train loss {'Reaction outcome loss': 0.4817730559088923, 'Total loss': 0.4817730559088923}
2022-11-28 05:12:46,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:46,145 INFO:     Epoch: 93
2022-11-28 05:12:46,807 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4355616376481273, 'Total loss': 0.4355616376481273} | train loss {'Reaction outcome loss': 0.46658691962962207, 'Total loss': 0.46658691962962207}
2022-11-28 05:12:46,807 INFO:     Found new best model at epoch 93
2022-11-28 05:12:46,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:46,808 INFO:     Epoch: 94
2022-11-28 05:12:47,467 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45285921763967385, 'Total loss': 0.45285921763967385} | train loss {'Reaction outcome loss': 0.47404319560720853, 'Total loss': 0.47404319560720853}
2022-11-28 05:12:47,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:47,467 INFO:     Epoch: 95
2022-11-28 05:12:48,120 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4343006871640682, 'Total loss': 0.4343006871640682} | train loss {'Reaction outcome loss': 0.4866908915371065, 'Total loss': 0.4866908915371065}
2022-11-28 05:12:48,121 INFO:     Found new best model at epoch 95
2022-11-28 05:12:48,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:48,121 INFO:     Epoch: 96
2022-11-28 05:12:48,778 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4572247341275215, 'Total loss': 0.4572247341275215} | train loss {'Reaction outcome loss': 0.4796447102781687, 'Total loss': 0.4796447102781687}
2022-11-28 05:12:48,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:48,779 INFO:     Epoch: 97
2022-11-28 05:12:49,434 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44707163355567237, 'Total loss': 0.44707163355567237} | train loss {'Reaction outcome loss': 0.467105137017416, 'Total loss': 0.467105137017416}
2022-11-28 05:12:49,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:49,435 INFO:     Epoch: 98
2022-11-28 05:12:50,089 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44192581048065965, 'Total loss': 0.44192581048065965} | train loss {'Reaction outcome loss': 0.47850209776206537, 'Total loss': 0.47850209776206537}
2022-11-28 05:12:50,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:50,089 INFO:     Epoch: 99
2022-11-28 05:12:50,747 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4638512229377573, 'Total loss': 0.4638512229377573} | train loss {'Reaction outcome loss': 0.4749954616733891, 'Total loss': 0.4749954616733891}
2022-11-28 05:12:50,748 INFO:     Best model found after epoch 96 of 100.
2022-11-28 05:12:50,748 INFO:   Done with stage: TRAINING
2022-11-28 05:12:50,748 INFO:   Starting stage: EVALUATION
2022-11-28 05:12:50,865 INFO:   Done with stage: EVALUATION
2022-11-28 05:12:50,865 INFO:   Leaving out SEQ value Fold_6
2022-11-28 05:12:50,877 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 05:12:50,877 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:12:51,512 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:12:51,512 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:12:51,581 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:12:51,581 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:12:51,581 INFO:     No hyperparam tuning for this model
2022-11-28 05:12:51,581 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:12:51,581 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:12:51,582 INFO:     None feature selector for col prot
2022-11-28 05:12:51,582 INFO:     None feature selector for col prot
2022-11-28 05:12:51,582 INFO:     None feature selector for col prot
2022-11-28 05:12:51,583 INFO:     None feature selector for col chem
2022-11-28 05:12:51,583 INFO:     None feature selector for col chem
2022-11-28 05:12:51,583 INFO:     None feature selector for col chem
2022-11-28 05:12:51,583 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:12:51,583 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:12:51,584 INFO:     Number of params in model 169651
2022-11-28 05:12:51,587 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:12:51,587 INFO:   Starting stage: TRAINING
2022-11-28 05:12:51,638 INFO:     Val loss before train {'Reaction outcome loss': 0.9807013042948463, 'Total loss': 0.9807013042948463}
2022-11-28 05:12:51,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:51,638 INFO:     Epoch: 0
2022-11-28 05:12:52,297 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6105429862033237, 'Total loss': 0.6105429862033237} | train loss {'Reaction outcome loss': 0.6800724052854122, 'Total loss': 0.6800724052854122}
2022-11-28 05:12:52,297 INFO:     Found new best model at epoch 0
2022-11-28 05:12:52,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:52,298 INFO:     Epoch: 1
2022-11-28 05:12:52,956 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6098505305972967, 'Total loss': 0.6098505305972967} | train loss {'Reaction outcome loss': 0.5878262909189347, 'Total loss': 0.5878262909189347}
2022-11-28 05:12:52,956 INFO:     Found new best model at epoch 1
2022-11-28 05:12:52,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:52,957 INFO:     Epoch: 2
2022-11-28 05:12:53,614 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.609455285424536, 'Total loss': 0.609455285424536} | train loss {'Reaction outcome loss': 0.5562657390631014, 'Total loss': 0.5562657390631014}
2022-11-28 05:12:53,615 INFO:     Found new best model at epoch 2
2022-11-28 05:12:53,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:53,615 INFO:     Epoch: 3
2022-11-28 05:12:54,272 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5851445408029989, 'Total loss': 0.5851445408029989} | train loss {'Reaction outcome loss': 0.5365093415302615, 'Total loss': 0.5365093415302615}
2022-11-28 05:12:54,272 INFO:     Found new best model at epoch 3
2022-11-28 05:12:54,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:54,273 INFO:     Epoch: 4
2022-11-28 05:12:54,929 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5429200902581215, 'Total loss': 0.5429200902581215} | train loss {'Reaction outcome loss': 0.5305497059898991, 'Total loss': 0.5305497059898991}
2022-11-28 05:12:54,929 INFO:     Found new best model at epoch 4
2022-11-28 05:12:54,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:54,930 INFO:     Epoch: 5
2022-11-28 05:12:55,590 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5332936881618067, 'Total loss': 0.5332936881618067} | train loss {'Reaction outcome loss': 0.5117648023991815, 'Total loss': 0.5117648023991815}
2022-11-28 05:12:55,590 INFO:     Found new best model at epoch 5
2022-11-28 05:12:55,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:55,591 INFO:     Epoch: 6
2022-11-28 05:12:56,254 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5413068055429242, 'Total loss': 0.5413068055429242} | train loss {'Reaction outcome loss': 0.5197117022809482, 'Total loss': 0.5197117022809482}
2022-11-28 05:12:56,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:56,254 INFO:     Epoch: 7
2022-11-28 05:12:56,914 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5434061343019659, 'Total loss': 0.5434061343019659} | train loss {'Reaction outcome loss': 0.5038087179944399, 'Total loss': 0.5038087179944399}
2022-11-28 05:12:56,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:56,915 INFO:     Epoch: 8
2022-11-28 05:12:57,579 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5567254407162016, 'Total loss': 0.5567254407162016} | train loss {'Reaction outcome loss': 0.5065895154351189, 'Total loss': 0.5065895154351189}
2022-11-28 05:12:57,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:57,580 INFO:     Epoch: 9
2022-11-28 05:12:58,237 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5185738023031842, 'Total loss': 0.5185738023031842} | train loss {'Reaction outcome loss': 0.5059098957346813, 'Total loss': 0.5059098957346813}
2022-11-28 05:12:58,237 INFO:     Found new best model at epoch 9
2022-11-28 05:12:58,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:58,238 INFO:     Epoch: 10
2022-11-28 05:12:58,895 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5491561097177592, 'Total loss': 0.5491561097177592} | train loss {'Reaction outcome loss': 0.48995292192745593, 'Total loss': 0.48995292192745593}
2022-11-28 05:12:58,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:58,896 INFO:     Epoch: 11
2022-11-28 05:12:59,558 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.508873834867369, 'Total loss': 0.508873834867369} | train loss {'Reaction outcome loss': 0.4959163095561727, 'Total loss': 0.4959163095561727}
2022-11-28 05:12:59,559 INFO:     Found new best model at epoch 11
2022-11-28 05:12:59,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:12:59,559 INFO:     Epoch: 12
2022-11-28 05:13:00,221 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5034516941417347, 'Total loss': 0.5034516941417347} | train loss {'Reaction outcome loss': 0.4920681016219239, 'Total loss': 0.4920681016219239}
2022-11-28 05:13:00,221 INFO:     Found new best model at epoch 12
2022-11-28 05:13:00,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:00,221 INFO:     Epoch: 13
2022-11-28 05:13:00,880 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5028717991980639, 'Total loss': 0.5028717991980639} | train loss {'Reaction outcome loss': 0.4889500275734932, 'Total loss': 0.4889500275734932}
2022-11-28 05:13:00,880 INFO:     Found new best model at epoch 13
2022-11-28 05:13:00,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:00,881 INFO:     Epoch: 14
2022-11-28 05:13:01,541 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4967333149503578, 'Total loss': 0.4967333149503578} | train loss {'Reaction outcome loss': 0.48302771373381537, 'Total loss': 0.48302771373381537}
2022-11-28 05:13:01,541 INFO:     Found new best model at epoch 14
2022-11-28 05:13:01,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:01,542 INFO:     Epoch: 15
2022-11-28 05:13:02,203 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.529558390378952, 'Total loss': 0.529558390378952} | train loss {'Reaction outcome loss': 0.4869382861520975, 'Total loss': 0.4869382861520975}
2022-11-28 05:13:02,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:02,204 INFO:     Epoch: 16
2022-11-28 05:13:02,863 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4982237995348193, 'Total loss': 0.4982237995348193} | train loss {'Reaction outcome loss': 0.48570565098235685, 'Total loss': 0.48570565098235685}
2022-11-28 05:13:02,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:02,863 INFO:     Epoch: 17
2022-11-28 05:13:03,521 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4999670176343484, 'Total loss': 0.4999670176343484} | train loss {'Reaction outcome loss': 0.4806124559573589, 'Total loss': 0.4806124559573589}
2022-11-28 05:13:03,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:03,521 INFO:     Epoch: 18
2022-11-28 05:13:04,180 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49889658628539607, 'Total loss': 0.49889658628539607} | train loss {'Reaction outcome loss': 0.4780168559161886, 'Total loss': 0.4780168559161886}
2022-11-28 05:13:04,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:04,180 INFO:     Epoch: 19
2022-11-28 05:13:04,839 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.540318017656153, 'Total loss': 0.540318017656153} | train loss {'Reaction outcome loss': 0.4840188614062725, 'Total loss': 0.4840188614062725}
2022-11-28 05:13:04,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:04,839 INFO:     Epoch: 20
2022-11-28 05:13:05,499 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5044193403287367, 'Total loss': 0.5044193403287367} | train loss {'Reaction outcome loss': 0.47917328047896585, 'Total loss': 0.47917328047896585}
2022-11-28 05:13:05,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:05,499 INFO:     Epoch: 21
2022-11-28 05:13:06,160 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5015627542002634, 'Total loss': 0.5015627542002634} | train loss {'Reaction outcome loss': 0.47368534684421554, 'Total loss': 0.47368534684421554}
2022-11-28 05:13:06,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:06,160 INFO:     Epoch: 22
2022-11-28 05:13:06,816 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4859488464214585, 'Total loss': 0.4859488464214585} | train loss {'Reaction outcome loss': 0.4738588460510777, 'Total loss': 0.4738588460510777}
2022-11-28 05:13:06,816 INFO:     Found new best model at epoch 22
2022-11-28 05:13:06,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:06,817 INFO:     Epoch: 23
2022-11-28 05:13:07,476 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5020597482269461, 'Total loss': 0.5020597482269461} | train loss {'Reaction outcome loss': 0.47579951398074627, 'Total loss': 0.47579951398074627}
2022-11-28 05:13:07,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:07,477 INFO:     Epoch: 24
2022-11-28 05:13:08,136 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.533583177761598, 'Total loss': 0.533583177761598} | train loss {'Reaction outcome loss': 0.4817093454541699, 'Total loss': 0.4817093454541699}
2022-11-28 05:13:08,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:08,137 INFO:     Epoch: 25
2022-11-28 05:13:08,795 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.549605998464606, 'Total loss': 0.549605998464606} | train loss {'Reaction outcome loss': 0.47599529240640903, 'Total loss': 0.47599529240640903}
2022-11-28 05:13:08,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:08,795 INFO:     Epoch: 26
2022-11-28 05:13:09,456 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48586913164366374, 'Total loss': 0.48586913164366374} | train loss {'Reaction outcome loss': 0.46936175909133687, 'Total loss': 0.46936175909133687}
2022-11-28 05:13:09,457 INFO:     Found new best model at epoch 26
2022-11-28 05:13:09,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:09,458 INFO:     Epoch: 27
2022-11-28 05:13:10,122 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5841211507266219, 'Total loss': 0.5841211507266219} | train loss {'Reaction outcome loss': 0.4709675808947894, 'Total loss': 0.4709675808947894}
2022-11-28 05:13:10,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:10,122 INFO:     Epoch: 28
2022-11-28 05:13:10,785 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.49845072559335013, 'Total loss': 0.49845072559335013} | train loss {'Reaction outcome loss': 0.4814349687508037, 'Total loss': 0.4814349687508037}
2022-11-28 05:13:10,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:10,785 INFO:     Epoch: 29
2022-11-28 05:13:11,446 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5086189630356702, 'Total loss': 0.5086189630356702} | train loss {'Reaction outcome loss': 0.4787766794043203, 'Total loss': 0.4787766794043203}
2022-11-28 05:13:11,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:11,446 INFO:     Epoch: 30
2022-11-28 05:13:12,110 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.494029262187806, 'Total loss': 0.494029262187806} | train loss {'Reaction outcome loss': 0.47887460725201714, 'Total loss': 0.47887460725201714}
2022-11-28 05:13:12,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:12,110 INFO:     Epoch: 31
2022-11-28 05:13:12,777 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4994519285180352, 'Total loss': 0.4994519285180352} | train loss {'Reaction outcome loss': 0.4723910284378836, 'Total loss': 0.4723910284378836}
2022-11-28 05:13:12,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:12,777 INFO:     Epoch: 32
2022-11-28 05:13:13,440 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5032854466275736, 'Total loss': 0.5032854466275736} | train loss {'Reaction outcome loss': 0.46719408149440445, 'Total loss': 0.46719408149440445}
2022-11-28 05:13:13,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:13,440 INFO:     Epoch: 33
2022-11-28 05:13:14,103 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48347741094502533, 'Total loss': 0.48347741094502533} | train loss {'Reaction outcome loss': 0.47117611699767653, 'Total loss': 0.47117611699767653}
2022-11-28 05:13:14,103 INFO:     Found new best model at epoch 33
2022-11-28 05:13:14,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:14,104 INFO:     Epoch: 34
2022-11-28 05:13:14,769 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.540808327157389, 'Total loss': 0.540808327157389} | train loss {'Reaction outcome loss': 0.47607677279701155, 'Total loss': 0.47607677279701155}
2022-11-28 05:13:14,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:14,769 INFO:     Epoch: 35
2022-11-28 05:13:15,434 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5084722570397637, 'Total loss': 0.5084722570397637} | train loss {'Reaction outcome loss': 0.4700397673032938, 'Total loss': 0.4700397673032938}
2022-11-28 05:13:15,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:15,435 INFO:     Epoch: 36
2022-11-28 05:13:16,099 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5183825398033316, 'Total loss': 0.5183825398033316} | train loss {'Reaction outcome loss': 0.4665188132034194, 'Total loss': 0.4665188132034194}
2022-11-28 05:13:16,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:16,099 INFO:     Epoch: 37
2022-11-28 05:13:16,764 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48857313936406915, 'Total loss': 0.48857313936406915} | train loss {'Reaction outcome loss': 0.46929269392163525, 'Total loss': 0.46929269392163525}
2022-11-28 05:13:16,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:16,765 INFO:     Epoch: 38
2022-11-28 05:13:17,429 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5048952840945937, 'Total loss': 0.5048952840945937} | train loss {'Reaction outcome loss': 0.46359393451242675, 'Total loss': 0.46359393451242675}
2022-11-28 05:13:17,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:17,429 INFO:     Epoch: 39
2022-11-28 05:13:18,095 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4672395241531459, 'Total loss': 0.4672395241531459} | train loss {'Reaction outcome loss': 0.45860662203161945, 'Total loss': 0.45860662203161945}
2022-11-28 05:13:18,095 INFO:     Found new best model at epoch 39
2022-11-28 05:13:18,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:18,096 INFO:     Epoch: 40
2022-11-28 05:13:18,759 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48717106133699417, 'Total loss': 0.48717106133699417} | train loss {'Reaction outcome loss': 0.46353969013979357, 'Total loss': 0.46353969013979357}
2022-11-28 05:13:18,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:18,759 INFO:     Epoch: 41
2022-11-28 05:13:19,426 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49549284916032443, 'Total loss': 0.49549284916032443} | train loss {'Reaction outcome loss': 0.4632651774032462, 'Total loss': 0.4632651774032462}
2022-11-28 05:13:19,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:19,426 INFO:     Epoch: 42
2022-11-28 05:13:20,093 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46936227652159607, 'Total loss': 0.46936227652159607} | train loss {'Reaction outcome loss': 0.46298334531245694, 'Total loss': 0.46298334531245694}
2022-11-28 05:13:20,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:20,093 INFO:     Epoch: 43
2022-11-28 05:13:20,762 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5493244115601886, 'Total loss': 0.5493244115601886} | train loss {'Reaction outcome loss': 0.46949361757405345, 'Total loss': 0.46949361757405345}
2022-11-28 05:13:20,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:20,762 INFO:     Epoch: 44
2022-11-28 05:13:21,431 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47870956056497316, 'Total loss': 0.47870956056497316} | train loss {'Reaction outcome loss': 0.4634369986071702, 'Total loss': 0.4634369986071702}
2022-11-28 05:13:21,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:21,432 INFO:     Epoch: 45
2022-11-28 05:13:22,095 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49500769579952414, 'Total loss': 0.49500769579952414} | train loss {'Reaction outcome loss': 0.45455584176365404, 'Total loss': 0.45455584176365404}
2022-11-28 05:13:22,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:22,096 INFO:     Epoch: 46
2022-11-28 05:13:22,762 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5213315077126026, 'Total loss': 0.5213315077126026} | train loss {'Reaction outcome loss': 0.4577749451442111, 'Total loss': 0.4577749451442111}
2022-11-28 05:13:22,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:22,762 INFO:     Epoch: 47
2022-11-28 05:13:23,426 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48255158215761185, 'Total loss': 0.48255158215761185} | train loss {'Reaction outcome loss': 0.4601931656680761, 'Total loss': 0.4601931656680761}
2022-11-28 05:13:23,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:23,426 INFO:     Epoch: 48
2022-11-28 05:13:24,089 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47700684517621994, 'Total loss': 0.47700684517621994} | train loss {'Reaction outcome loss': 0.45634078757176477, 'Total loss': 0.45634078757176477}
2022-11-28 05:13:24,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:24,089 INFO:     Epoch: 49
2022-11-28 05:13:24,755 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5040055228905245, 'Total loss': 0.5040055228905245} | train loss {'Reaction outcome loss': 0.45877626544285205, 'Total loss': 0.45877626544285205}
2022-11-28 05:13:24,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:24,755 INFO:     Epoch: 50
2022-11-28 05:13:25,421 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48097879642790015, 'Total loss': 0.48097879642790015} | train loss {'Reaction outcome loss': 0.4595233086015909, 'Total loss': 0.4595233086015909}
2022-11-28 05:13:25,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:25,421 INFO:     Epoch: 51
2022-11-28 05:13:26,088 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5082531176846136, 'Total loss': 0.5082531176846136} | train loss {'Reaction outcome loss': 0.4637008799360164, 'Total loss': 0.4637008799360164}
2022-11-28 05:13:26,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:26,089 INFO:     Epoch: 52
2022-11-28 05:13:26,755 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47945442694154655, 'Total loss': 0.47945442694154655} | train loss {'Reaction outcome loss': 0.4675184071304337, 'Total loss': 0.4675184071304337}
2022-11-28 05:13:26,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:26,756 INFO:     Epoch: 53
2022-11-28 05:13:27,423 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4831526367501779, 'Total loss': 0.4831526367501779} | train loss {'Reaction outcome loss': 0.4604402710233004, 'Total loss': 0.4604402710233004}
2022-11-28 05:13:27,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:27,423 INFO:     Epoch: 54
2022-11-28 05:13:28,089 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4798111461780288, 'Total loss': 0.4798111461780288} | train loss {'Reaction outcome loss': 0.4547201439497932, 'Total loss': 0.4547201439497932}
2022-11-28 05:13:28,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:28,090 INFO:     Epoch: 55
2022-11-28 05:13:28,759 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5057566494426944, 'Total loss': 0.5057566494426944} | train loss {'Reaction outcome loss': 0.46438635140657425, 'Total loss': 0.46438635140657425}
2022-11-28 05:13:28,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:28,759 INFO:     Epoch: 56
2022-11-28 05:13:29,428 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4726742688905109, 'Total loss': 0.4726742688905109} | train loss {'Reaction outcome loss': 0.4590581600223818, 'Total loss': 0.4590581600223818}
2022-11-28 05:13:29,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:29,428 INFO:     Epoch: 57
2022-11-28 05:13:30,091 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5217117047445341, 'Total loss': 0.5217117047445341} | train loss {'Reaction outcome loss': 0.46480185015788, 'Total loss': 0.46480185015788}
2022-11-28 05:13:30,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:30,091 INFO:     Epoch: 58
2022-11-28 05:13:30,758 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5133357813412492, 'Total loss': 0.5133357813412492} | train loss {'Reaction outcome loss': 0.46610036684620765, 'Total loss': 0.46610036684620765}
2022-11-28 05:13:30,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:30,758 INFO:     Epoch: 59
2022-11-28 05:13:31,423 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5266408114270731, 'Total loss': 0.5266408114270731} | train loss {'Reaction outcome loss': 0.4651517664052306, 'Total loss': 0.4651517664052306}
2022-11-28 05:13:31,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:31,424 INFO:     Epoch: 60
2022-11-28 05:13:32,086 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4972273111343384, 'Total loss': 0.4972273111343384} | train loss {'Reaction outcome loss': 0.46473917377091223, 'Total loss': 0.46473917377091223}
2022-11-28 05:13:32,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:32,086 INFO:     Epoch: 61
2022-11-28 05:13:32,749 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4918259924108332, 'Total loss': 0.4918259924108332} | train loss {'Reaction outcome loss': 0.4626292181651919, 'Total loss': 0.4626292181651919}
2022-11-28 05:13:32,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:32,749 INFO:     Epoch: 62
2022-11-28 05:13:33,415 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5795003331520341, 'Total loss': 0.5795003331520341} | train loss {'Reaction outcome loss': 0.45958700842194017, 'Total loss': 0.45958700842194017}
2022-11-28 05:13:33,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:33,416 INFO:     Epoch: 63
2022-11-28 05:13:34,080 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49233536286787555, 'Total loss': 0.49233536286787555} | train loss {'Reaction outcome loss': 0.45556104222252486, 'Total loss': 0.45556104222252486}
2022-11-28 05:13:34,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:34,080 INFO:     Epoch: 64
2022-11-28 05:13:34,742 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46795762127096, 'Total loss': 0.46795762127096} | train loss {'Reaction outcome loss': 0.4563616460129138, 'Total loss': 0.4563616460129138}
2022-11-28 05:13:34,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:34,743 INFO:     Epoch: 65
2022-11-28 05:13:35,409 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48735709149729123, 'Total loss': 0.48735709149729123} | train loss {'Reaction outcome loss': 0.46716873612134685, 'Total loss': 0.46716873612134685}
2022-11-28 05:13:35,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:35,409 INFO:     Epoch: 66
2022-11-28 05:13:36,077 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5108975652943958, 'Total loss': 0.5108975652943958} | train loss {'Reaction outcome loss': 0.46016106946814445, 'Total loss': 0.46016106946814445}
2022-11-28 05:13:36,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:36,077 INFO:     Epoch: 67
2022-11-28 05:13:36,747 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4803645099428567, 'Total loss': 0.4803645099428567} | train loss {'Reaction outcome loss': 0.4581529207287296, 'Total loss': 0.4581529207287296}
2022-11-28 05:13:36,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:36,747 INFO:     Epoch: 68
2022-11-28 05:13:37,412 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4954552193256942, 'Total loss': 0.4954552193256942} | train loss {'Reaction outcome loss': 0.45576373319472036, 'Total loss': 0.45576373319472036}
2022-11-28 05:13:37,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:37,412 INFO:     Epoch: 69
2022-11-28 05:13:38,079 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48486486686901614, 'Total loss': 0.48486486686901614} | train loss {'Reaction outcome loss': 0.4583330770293551, 'Total loss': 0.4583330770293551}
2022-11-28 05:13:38,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:38,079 INFO:     Epoch: 70
2022-11-28 05:13:38,744 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4947495802559636, 'Total loss': 0.4947495802559636} | train loss {'Reaction outcome loss': 0.45974683055594084, 'Total loss': 0.45974683055594084}
2022-11-28 05:13:38,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:38,745 INFO:     Epoch: 71
2022-11-28 05:13:39,408 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47710868648507376, 'Total loss': 0.47710868648507376} | train loss {'Reaction outcome loss': 0.4629007381717524, 'Total loss': 0.4629007381717524}
2022-11-28 05:13:39,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:39,408 INFO:     Epoch: 72
2022-11-28 05:13:40,071 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4955803785811771, 'Total loss': 0.4955803785811771} | train loss {'Reaction outcome loss': 0.4534938150956746, 'Total loss': 0.4534938150956746}
2022-11-28 05:13:40,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:40,071 INFO:     Epoch: 73
2022-11-28 05:13:40,735 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.476625551215627, 'Total loss': 0.476625551215627} | train loss {'Reaction outcome loss': 0.46206203926234474, 'Total loss': 0.46206203926234474}
2022-11-28 05:13:40,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:40,736 INFO:     Epoch: 74
2022-11-28 05:13:41,398 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4888812449168075, 'Total loss': 0.4888812449168075} | train loss {'Reaction outcome loss': 0.46748139054304166, 'Total loss': 0.46748139054304166}
2022-11-28 05:13:41,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:41,398 INFO:     Epoch: 75
2022-11-28 05:13:42,061 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46928406235846604, 'Total loss': 0.46928406235846604} | train loss {'Reaction outcome loss': 0.45710656281200146, 'Total loss': 0.45710656281200146}
2022-11-28 05:13:42,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:42,061 INFO:     Epoch: 76
2022-11-28 05:13:42,725 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4948599548502402, 'Total loss': 0.4948599548502402} | train loss {'Reaction outcome loss': 0.4638170488779583, 'Total loss': 0.4638170488779583}
2022-11-28 05:13:42,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:42,725 INFO:     Epoch: 77
2022-11-28 05:13:43,387 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5023195062848654, 'Total loss': 0.5023195062848654} | train loss {'Reaction outcome loss': 0.4637567890928157, 'Total loss': 0.4637567890928157}
2022-11-28 05:13:43,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:43,387 INFO:     Epoch: 78
2022-11-28 05:13:44,054 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5062596256082709, 'Total loss': 0.5062596256082709} | train loss {'Reaction outcome loss': 0.4575436529553225, 'Total loss': 0.4575436529553225}
2022-11-28 05:13:44,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:44,054 INFO:     Epoch: 79
2022-11-28 05:13:44,719 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.475712562487884, 'Total loss': 0.475712562487884} | train loss {'Reaction outcome loss': 0.4690850464807403, 'Total loss': 0.4690850464807403}
2022-11-28 05:13:44,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:44,719 INFO:     Epoch: 80
2022-11-28 05:13:45,388 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49270070818337525, 'Total loss': 0.49270070818337525} | train loss {'Reaction outcome loss': 0.4605841582881347, 'Total loss': 0.4605841582881347}
2022-11-28 05:13:45,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:45,388 INFO:     Epoch: 81
2022-11-28 05:13:46,053 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48823966593904927, 'Total loss': 0.48823966593904927} | train loss {'Reaction outcome loss': 0.463819925222666, 'Total loss': 0.463819925222666}
2022-11-28 05:13:46,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:46,053 INFO:     Epoch: 82
2022-11-28 05:13:46,716 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49287237091497943, 'Total loss': 0.49287237091497943} | train loss {'Reaction outcome loss': 0.46496803580873436, 'Total loss': 0.46496803580873436}
2022-11-28 05:13:46,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:46,716 INFO:     Epoch: 83
2022-11-28 05:13:47,383 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.504744449799711, 'Total loss': 0.504744449799711} | train loss {'Reaction outcome loss': 0.46069835426826633, 'Total loss': 0.46069835426826633}
2022-11-28 05:13:47,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:47,383 INFO:     Epoch: 84
2022-11-28 05:13:48,049 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5119555873627012, 'Total loss': 0.5119555873627012} | train loss {'Reaction outcome loss': 0.4648946163755271, 'Total loss': 0.4648946163755271}
2022-11-28 05:13:48,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:48,049 INFO:     Epoch: 85
2022-11-28 05:13:48,712 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4944332130253315, 'Total loss': 0.4944332130253315} | train loss {'Reaction outcome loss': 0.46048367239775195, 'Total loss': 0.46048367239775195}
2022-11-28 05:13:48,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:48,713 INFO:     Epoch: 86
2022-11-28 05:13:49,376 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5128947560760108, 'Total loss': 0.5128947560760108} | train loss {'Reaction outcome loss': 0.466904308767088, 'Total loss': 0.466904308767088}
2022-11-28 05:13:49,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:49,376 INFO:     Epoch: 87
2022-11-28 05:13:50,040 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48688865757801314, 'Total loss': 0.48688865757801314} | train loss {'Reaction outcome loss': 0.45475210255432513, 'Total loss': 0.45475210255432513}
2022-11-28 05:13:50,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:50,041 INFO:     Epoch: 88
2022-11-28 05:13:50,700 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5198473063382235, 'Total loss': 0.5198473063382235} | train loss {'Reaction outcome loss': 0.46636153385043144, 'Total loss': 0.46636153385043144}
2022-11-28 05:13:50,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:50,700 INFO:     Epoch: 89
2022-11-28 05:13:51,362 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4947471442547711, 'Total loss': 0.4947471442547711} | train loss {'Reaction outcome loss': 0.4636987879151298, 'Total loss': 0.4636987879151298}
2022-11-28 05:13:51,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:51,362 INFO:     Epoch: 90
2022-11-28 05:13:52,024 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49123250218954956, 'Total loss': 0.49123250218954956} | train loss {'Reaction outcome loss': 0.4582918834902586, 'Total loss': 0.4582918834902586}
2022-11-28 05:13:52,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:52,024 INFO:     Epoch: 91
2022-11-28 05:13:52,689 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4836398573084311, 'Total loss': 0.4836398573084311} | train loss {'Reaction outcome loss': 0.4647870683862317, 'Total loss': 0.4647870683862317}
2022-11-28 05:13:52,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:52,690 INFO:     Epoch: 92
2022-11-28 05:13:53,352 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47336621971970255, 'Total loss': 0.47336621971970255} | train loss {'Reaction outcome loss': 0.459411216599326, 'Total loss': 0.459411216599326}
2022-11-28 05:13:53,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:53,352 INFO:     Epoch: 93
2022-11-28 05:13:54,016 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4957274713299491, 'Total loss': 0.4957274713299491} | train loss {'Reaction outcome loss': 0.4554287571339838, 'Total loss': 0.4554287571339838}
2022-11-28 05:13:54,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:54,016 INFO:     Epoch: 94
2022-11-28 05:13:54,679 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.518979992040179, 'Total loss': 0.518979992040179} | train loss {'Reaction outcome loss': 0.46418099628100473, 'Total loss': 0.46418099628100473}
2022-11-28 05:13:54,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:54,680 INFO:     Epoch: 95
2022-11-28 05:13:55,343 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48735278844833374, 'Total loss': 0.48735278844833374} | train loss {'Reaction outcome loss': 0.4624292616762461, 'Total loss': 0.4624292616762461}
2022-11-28 05:13:55,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:55,343 INFO:     Epoch: 96
2022-11-28 05:13:56,007 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5214785378087651, 'Total loss': 0.5214785378087651} | train loss {'Reaction outcome loss': 0.4681210058230546, 'Total loss': 0.4681210058230546}
2022-11-28 05:13:56,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:56,007 INFO:     Epoch: 97
2022-11-28 05:13:56,673 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5590004748241468, 'Total loss': 0.5590004748241468} | train loss {'Reaction outcome loss': 0.4560488586223895, 'Total loss': 0.4560488586223895}
2022-11-28 05:13:56,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:56,673 INFO:     Epoch: 98
2022-11-28 05:13:57,338 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4868886182931336, 'Total loss': 0.4868886182931336} | train loss {'Reaction outcome loss': 0.46775844116364756, 'Total loss': 0.46775844116364756}
2022-11-28 05:13:57,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:57,338 INFO:     Epoch: 99
2022-11-28 05:13:58,002 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.506383901969953, 'Total loss': 0.506383901969953} | train loss {'Reaction outcome loss': 0.46239125103719775, 'Total loss': 0.46239125103719775}
2022-11-28 05:13:58,003 INFO:     Best model found after epoch 40 of 100.
2022-11-28 05:13:58,003 INFO:   Done with stage: TRAINING
2022-11-28 05:13:58,003 INFO:   Starting stage: EVALUATION
2022-11-28 05:13:58,115 INFO:   Done with stage: EVALUATION
2022-11-28 05:13:58,115 INFO:   Leaving out SEQ value Fold_7
2022-11-28 05:13:58,128 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 05:13:58,128 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:13:58,771 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:13:58,772 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:13:58,842 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:13:58,842 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:13:58,842 INFO:     No hyperparam tuning for this model
2022-11-28 05:13:58,842 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:13:58,842 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:13:58,843 INFO:     None feature selector for col prot
2022-11-28 05:13:58,843 INFO:     None feature selector for col prot
2022-11-28 05:13:58,843 INFO:     None feature selector for col prot
2022-11-28 05:13:58,844 INFO:     None feature selector for col chem
2022-11-28 05:13:58,844 INFO:     None feature selector for col chem
2022-11-28 05:13:58,844 INFO:     None feature selector for col chem
2022-11-28 05:13:58,844 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:13:58,844 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:13:58,845 INFO:     Number of params in model 169651
2022-11-28 05:13:58,848 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:13:58,848 INFO:   Starting stage: TRAINING
2022-11-28 05:13:58,900 INFO:     Val loss before train {'Reaction outcome loss': 1.0203223540024324, 'Total loss': 1.0203223540024324}
2022-11-28 05:13:58,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:58,901 INFO:     Epoch: 0
2022-11-28 05:13:59,568 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5913622792471539, 'Total loss': 0.5913622792471539} | train loss {'Reaction outcome loss': 0.6776023076306428, 'Total loss': 0.6776023076306428}
2022-11-28 05:13:59,568 INFO:     Found new best model at epoch 0
2022-11-28 05:13:59,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:13:59,569 INFO:     Epoch: 1
2022-11-28 05:14:00,234 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5488620478321206, 'Total loss': 0.5488620478321206} | train loss {'Reaction outcome loss': 0.5839870164711629, 'Total loss': 0.5839870164711629}
2022-11-28 05:14:00,234 INFO:     Found new best model at epoch 1
2022-11-28 05:14:00,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:00,235 INFO:     Epoch: 2
2022-11-28 05:14:00,898 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5663889998739416, 'Total loss': 0.5663889998739416} | train loss {'Reaction outcome loss': 0.5571368851007954, 'Total loss': 0.5571368851007954}
2022-11-28 05:14:00,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:00,899 INFO:     Epoch: 3
2022-11-28 05:14:01,563 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5326861244711009, 'Total loss': 0.5326861244711009} | train loss {'Reaction outcome loss': 0.5343940538624602, 'Total loss': 0.5343940538624602}
2022-11-28 05:14:01,564 INFO:     Found new best model at epoch 3
2022-11-28 05:14:01,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:01,564 INFO:     Epoch: 4
2022-11-28 05:14:02,230 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5380363606593825, 'Total loss': 0.5380363606593825} | train loss {'Reaction outcome loss': 0.5245256883002096, 'Total loss': 0.5245256883002096}
2022-11-28 05:14:02,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:02,230 INFO:     Epoch: 5
2022-11-28 05:14:02,893 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5020592785017057, 'Total loss': 0.5020592785017057} | train loss {'Reaction outcome loss': 0.5109928826981734, 'Total loss': 0.5109928826981734}
2022-11-28 05:14:02,893 INFO:     Found new best model at epoch 5
2022-11-28 05:14:02,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:02,894 INFO:     Epoch: 6
2022-11-28 05:14:03,556 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.467997496439652, 'Total loss': 0.467997496439652} | train loss {'Reaction outcome loss': 0.5026412758555624, 'Total loss': 0.5026412758555624}
2022-11-28 05:14:03,557 INFO:     Found new best model at epoch 6
2022-11-28 05:14:03,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:03,557 INFO:     Epoch: 7
2022-11-28 05:14:04,224 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4836477864195, 'Total loss': 0.4836477864195} | train loss {'Reaction outcome loss': 0.4882138010354773, 'Total loss': 0.4882138010354773}
2022-11-28 05:14:04,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:04,224 INFO:     Epoch: 8
2022-11-28 05:14:04,888 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4621850787238641, 'Total loss': 0.4621850787238641} | train loss {'Reaction outcome loss': 0.49334933746966625, 'Total loss': 0.49334933746966625}
2022-11-28 05:14:04,888 INFO:     Found new best model at epoch 8
2022-11-28 05:14:04,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:04,889 INFO:     Epoch: 9
2022-11-28 05:14:05,552 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5001439797607335, 'Total loss': 0.5001439797607335} | train loss {'Reaction outcome loss': 0.4858345379151644, 'Total loss': 0.4858345379151644}
2022-11-28 05:14:05,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:05,552 INFO:     Epoch: 10
2022-11-28 05:14:06,216 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5055195397951386, 'Total loss': 0.5055195397951386} | train loss {'Reaction outcome loss': 0.48398991115391254, 'Total loss': 0.48398991115391254}
2022-11-28 05:14:06,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:06,216 INFO:     Epoch: 11
2022-11-28 05:14:06,881 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5038275783034888, 'Total loss': 0.5038275783034888} | train loss {'Reaction outcome loss': 0.48390338404644884, 'Total loss': 0.48390338404644884}
2022-11-28 05:14:06,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:06,881 INFO:     Epoch: 12
2022-11-28 05:14:07,548 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4830936508422548, 'Total loss': 0.4830936508422548} | train loss {'Reaction outcome loss': 0.4843091917855124, 'Total loss': 0.4843091917855124}
2022-11-28 05:14:07,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:07,548 INFO:     Epoch: 13
2022-11-28 05:14:08,211 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4762371378866109, 'Total loss': 0.4762371378866109} | train loss {'Reaction outcome loss': 0.479219734909073, 'Total loss': 0.479219734909073}
2022-11-28 05:14:08,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:08,211 INFO:     Epoch: 14
2022-11-28 05:14:08,879 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47619234499606217, 'Total loss': 0.47619234499606217} | train loss {'Reaction outcome loss': 0.47977828102246406, 'Total loss': 0.47977828102246406}
2022-11-28 05:14:08,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:08,880 INFO:     Epoch: 15
2022-11-28 05:14:09,549 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4466174238107421, 'Total loss': 0.4466174238107421} | train loss {'Reaction outcome loss': 0.47805273613982624, 'Total loss': 0.47805273613982624}
2022-11-28 05:14:09,549 INFO:     Found new best model at epoch 15
2022-11-28 05:14:09,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:09,549 INFO:     Epoch: 16
2022-11-28 05:14:10,215 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47143754972652957, 'Total loss': 0.47143754972652957} | train loss {'Reaction outcome loss': 0.4761450559862198, 'Total loss': 0.4761450559862198}
2022-11-28 05:14:10,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:10,215 INFO:     Epoch: 17
2022-11-28 05:14:10,878 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4678226672112942, 'Total loss': 0.4678226672112942} | train loss {'Reaction outcome loss': 0.46941006417957043, 'Total loss': 0.46941006417957043}
2022-11-28 05:14:10,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:10,879 INFO:     Epoch: 18
2022-11-28 05:14:11,541 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5048346336592328, 'Total loss': 0.5048346336592328} | train loss {'Reaction outcome loss': 0.4757768174693469, 'Total loss': 0.4757768174693469}
2022-11-28 05:14:11,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:11,542 INFO:     Epoch: 19
2022-11-28 05:14:12,205 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47417121278968727, 'Total loss': 0.47417121278968727} | train loss {'Reaction outcome loss': 0.4720759955985892, 'Total loss': 0.4720759955985892}
2022-11-28 05:14:12,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:12,205 INFO:     Epoch: 20
2022-11-28 05:14:12,871 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4472486353055997, 'Total loss': 0.4472486353055997} | train loss {'Reaction outcome loss': 0.4666062471486868, 'Total loss': 0.4666062471486868}
2022-11-28 05:14:12,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:12,871 INFO:     Epoch: 21
2022-11-28 05:14:13,540 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4659996154633435, 'Total loss': 0.4659996154633435} | train loss {'Reaction outcome loss': 0.4673198016300317, 'Total loss': 0.4673198016300317}
2022-11-28 05:14:13,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:13,540 INFO:     Epoch: 22
2022-11-28 05:14:14,209 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47426044703884557, 'Total loss': 0.47426044703884557} | train loss {'Reaction outcome loss': 0.46147807498252197, 'Total loss': 0.46147807498252197}
2022-11-28 05:14:14,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:14,209 INFO:     Epoch: 23
2022-11-28 05:14:14,873 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46858222308483993, 'Total loss': 0.46858222308483993} | train loss {'Reaction outcome loss': 0.46916709137299367, 'Total loss': 0.46916709137299367}
2022-11-28 05:14:14,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:14,873 INFO:     Epoch: 24
2022-11-28 05:14:15,536 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47570788352326915, 'Total loss': 0.47570788352326915} | train loss {'Reaction outcome loss': 0.4729809833149756, 'Total loss': 0.4729809833149756}
2022-11-28 05:14:15,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:15,536 INFO:     Epoch: 25
2022-11-28 05:14:16,200 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4700271930884231, 'Total loss': 0.4700271930884231} | train loss {'Reaction outcome loss': 0.4717257261095989, 'Total loss': 0.4717257261095989}
2022-11-28 05:14:16,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:16,200 INFO:     Epoch: 26
2022-11-28 05:14:16,862 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45331365141001617, 'Total loss': 0.45331365141001617} | train loss {'Reaction outcome loss': 0.46358529934960024, 'Total loss': 0.46358529934960024}
2022-11-28 05:14:16,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:16,862 INFO:     Epoch: 27
2022-11-28 05:14:17,529 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4457361853935502, 'Total loss': 0.4457361853935502} | train loss {'Reaction outcome loss': 0.46534692330826677, 'Total loss': 0.46534692330826677}
2022-11-28 05:14:17,529 INFO:     Found new best model at epoch 27
2022-11-28 05:14:17,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:17,530 INFO:     Epoch: 28
2022-11-28 05:14:18,196 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4690484038808129, 'Total loss': 0.4690484038808129} | train loss {'Reaction outcome loss': 0.46308679097602445, 'Total loss': 0.46308679097602445}
2022-11-28 05:14:18,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:18,196 INFO:     Epoch: 29
2022-11-28 05:14:18,861 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4445346343246373, 'Total loss': 0.4445346343246373} | train loss {'Reaction outcome loss': 0.46240270711601744, 'Total loss': 0.46240270711601744}
2022-11-28 05:14:18,861 INFO:     Found new best model at epoch 29
2022-11-28 05:14:18,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:18,862 INFO:     Epoch: 30
2022-11-28 05:14:19,525 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47040951387448743, 'Total loss': 0.47040951387448743} | train loss {'Reaction outcome loss': 0.46565499348986533, 'Total loss': 0.46565499348986533}
2022-11-28 05:14:19,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:19,526 INFO:     Epoch: 31
2022-11-28 05:14:20,189 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46208102256059647, 'Total loss': 0.46208102256059647} | train loss {'Reaction outcome loss': 0.4647192257426439, 'Total loss': 0.4647192257426439}
2022-11-28 05:14:20,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:20,189 INFO:     Epoch: 32
2022-11-28 05:14:20,853 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4640672809698365, 'Total loss': 0.4640672809698365} | train loss {'Reaction outcome loss': 0.4629177791216681, 'Total loss': 0.4629177791216681}
2022-11-28 05:14:20,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:20,854 INFO:     Epoch: 33
2022-11-28 05:14:21,517 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46596158092672174, 'Total loss': 0.46596158092672174} | train loss {'Reaction outcome loss': 0.4628386910884611, 'Total loss': 0.4628386910884611}
2022-11-28 05:14:21,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:21,517 INFO:     Epoch: 34
2022-11-28 05:14:22,181 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4771062203428962, 'Total loss': 0.4771062203428962} | train loss {'Reaction outcome loss': 0.4733308519747469, 'Total loss': 0.4733308519747469}
2022-11-28 05:14:22,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:22,181 INFO:     Epoch: 35
2022-11-28 05:14:22,845 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46784754503857007, 'Total loss': 0.46784754503857007} | train loss {'Reaction outcome loss': 0.4641574722444338, 'Total loss': 0.4641574722444338}
2022-11-28 05:14:22,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:22,846 INFO:     Epoch: 36
2022-11-28 05:14:23,512 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.464499293403192, 'Total loss': 0.464499293403192} | train loss {'Reaction outcome loss': 0.4607430595544077, 'Total loss': 0.4607430595544077}
2022-11-28 05:14:23,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:23,512 INFO:     Epoch: 37
2022-11-28 05:14:24,177 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4768000783568079, 'Total loss': 0.4768000783568079} | train loss {'Reaction outcome loss': 0.4641405576539616, 'Total loss': 0.4641405576539616}
2022-11-28 05:14:24,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:24,178 INFO:     Epoch: 38
2022-11-28 05:14:24,840 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5058492411943999, 'Total loss': 0.5058492411943999} | train loss {'Reaction outcome loss': 0.46192174413872344, 'Total loss': 0.46192174413872344}
2022-11-28 05:14:24,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:24,840 INFO:     Epoch: 39
2022-11-28 05:14:25,504 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45986000245267694, 'Total loss': 0.45986000245267694} | train loss {'Reaction outcome loss': 0.46032591647798976, 'Total loss': 0.46032591647798976}
2022-11-28 05:14:25,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:25,504 INFO:     Epoch: 40
2022-11-28 05:14:26,171 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5254520672288808, 'Total loss': 0.5254520672288808} | train loss {'Reaction outcome loss': 0.4633008290923411, 'Total loss': 0.4633008290923411}
2022-11-28 05:14:26,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:26,171 INFO:     Epoch: 41
2022-11-28 05:14:26,837 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4735979881476272, 'Total loss': 0.4735979881476272} | train loss {'Reaction outcome loss': 0.46667896448484353, 'Total loss': 0.46667896448484353}
2022-11-28 05:14:26,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:26,838 INFO:     Epoch: 42
2022-11-28 05:14:27,503 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.49229730293154716, 'Total loss': 0.49229730293154716} | train loss {'Reaction outcome loss': 0.46888572542417434, 'Total loss': 0.46888572542417434}
2022-11-28 05:14:27,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:27,503 INFO:     Epoch: 43
2022-11-28 05:14:28,169 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47783414443785494, 'Total loss': 0.47783414443785494} | train loss {'Reaction outcome loss': 0.4597640855297927, 'Total loss': 0.4597640855297927}
2022-11-28 05:14:28,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:28,169 INFO:     Epoch: 44
2022-11-28 05:14:28,836 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4606568857350133, 'Total loss': 0.4606568857350133} | train loss {'Reaction outcome loss': 0.4704382783703266, 'Total loss': 0.4704382783703266}
2022-11-28 05:14:28,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:28,836 INFO:     Epoch: 45
2022-11-28 05:14:29,502 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4746959480372342, 'Total loss': 0.4746959480372342} | train loss {'Reaction outcome loss': 0.45689495058069307, 'Total loss': 0.45689495058069307}
2022-11-28 05:14:29,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:29,503 INFO:     Epoch: 46
2022-11-28 05:14:30,169 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4593674862249331, 'Total loss': 0.4593674862249331} | train loss {'Reaction outcome loss': 0.4623496259051946, 'Total loss': 0.4623496259051946}
2022-11-28 05:14:30,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:30,170 INFO:     Epoch: 47
2022-11-28 05:14:30,835 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44089836424047296, 'Total loss': 0.44089836424047296} | train loss {'Reaction outcome loss': 0.46186615199211145, 'Total loss': 0.46186615199211145}
2022-11-28 05:14:30,836 INFO:     Found new best model at epoch 47
2022-11-28 05:14:30,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:30,836 INFO:     Epoch: 48
2022-11-28 05:14:31,500 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45742077786814084, 'Total loss': 0.45742077786814084} | train loss {'Reaction outcome loss': 0.464283587771558, 'Total loss': 0.464283587771558}
2022-11-28 05:14:31,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:31,500 INFO:     Epoch: 49
2022-11-28 05:14:32,166 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.465306934307922, 'Total loss': 0.465306934307922} | train loss {'Reaction outcome loss': 0.463376855537776, 'Total loss': 0.463376855537776}
2022-11-28 05:14:32,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:32,166 INFO:     Epoch: 50
2022-11-28 05:14:32,830 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4610568897967989, 'Total loss': 0.4610568897967989} | train loss {'Reaction outcome loss': 0.46012682275426003, 'Total loss': 0.46012682275426003}
2022-11-28 05:14:32,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:32,830 INFO:     Epoch: 51
2022-11-28 05:14:33,495 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4530795134434646, 'Total loss': 0.4530795134434646} | train loss {'Reaction outcome loss': 0.4571683282753633, 'Total loss': 0.4571683282753633}
2022-11-28 05:14:33,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:33,495 INFO:     Epoch: 52
2022-11-28 05:14:34,162 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4849752949720079, 'Total loss': 0.4849752949720079} | train loss {'Reaction outcome loss': 0.4678573022866922, 'Total loss': 0.4678573022866922}
2022-11-28 05:14:34,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:34,163 INFO:     Epoch: 53
2022-11-28 05:14:34,825 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4582695493643934, 'Total loss': 0.4582695493643934} | train loss {'Reaction outcome loss': 0.45536035912171485, 'Total loss': 0.45536035912171485}
2022-11-28 05:14:34,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:34,825 INFO:     Epoch: 54
2022-11-28 05:14:35,490 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44577540999109094, 'Total loss': 0.44577540999109094} | train loss {'Reaction outcome loss': 0.4546589907859602, 'Total loss': 0.4546589907859602}
2022-11-28 05:14:35,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:35,490 INFO:     Epoch: 55
2022-11-28 05:14:36,156 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5185912163420157, 'Total loss': 0.5185912163420157} | train loss {'Reaction outcome loss': 0.4704973591912177, 'Total loss': 0.4704973591912177}
2022-11-28 05:14:36,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:36,156 INFO:     Epoch: 56
2022-11-28 05:14:36,820 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48830226639455016, 'Total loss': 0.48830226639455016} | train loss {'Reaction outcome loss': 0.4572466222509261, 'Total loss': 0.4572466222509261}
2022-11-28 05:14:36,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:36,820 INFO:     Epoch: 57
2022-11-28 05:14:37,488 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4696366847916083, 'Total loss': 0.4696366847916083} | train loss {'Reaction outcome loss': 0.456886904524459, 'Total loss': 0.456886904524459}
2022-11-28 05:14:37,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:37,489 INFO:     Epoch: 58
2022-11-28 05:14:38,155 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46283589980819007, 'Total loss': 0.46283589980819007} | train loss {'Reaction outcome loss': 0.46314260333536134, 'Total loss': 0.46314260333536134}
2022-11-28 05:14:38,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:38,155 INFO:     Epoch: 59
2022-11-28 05:14:38,822 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44836091554977675, 'Total loss': 0.44836091554977675} | train loss {'Reaction outcome loss': 0.46167970424698246, 'Total loss': 0.46167970424698246}
2022-11-28 05:14:38,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:38,822 INFO:     Epoch: 60
2022-11-28 05:14:39,489 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46936308592557907, 'Total loss': 0.46936308592557907} | train loss {'Reaction outcome loss': 0.4575615038854941, 'Total loss': 0.4575615038854941}
2022-11-28 05:14:39,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:39,489 INFO:     Epoch: 61
2022-11-28 05:14:40,158 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4642187255350026, 'Total loss': 0.4642187255350026} | train loss {'Reaction outcome loss': 0.45588220511713334, 'Total loss': 0.45588220511713334}
2022-11-28 05:14:40,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:40,158 INFO:     Epoch: 62
2022-11-28 05:14:40,824 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.457315382971005, 'Total loss': 0.457315382971005} | train loss {'Reaction outcome loss': 0.45899735439208245, 'Total loss': 0.45899735439208245}
2022-11-28 05:14:40,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:40,824 INFO:     Epoch: 63
2022-11-28 05:14:41,493 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4837181442840533, 'Total loss': 0.4837181442840533} | train loss {'Reaction outcome loss': 0.4697754009356422, 'Total loss': 0.4697754009356422}
2022-11-28 05:14:41,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:41,493 INFO:     Epoch: 64
2022-11-28 05:14:42,157 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4604598314247348, 'Total loss': 0.4604598314247348} | train loss {'Reaction outcome loss': 0.46099160611629486, 'Total loss': 0.46099160611629486}
2022-11-28 05:14:42,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:42,157 INFO:     Epoch: 65
2022-11-28 05:14:42,823 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4443770850246603, 'Total loss': 0.4443770850246603} | train loss {'Reaction outcome loss': 0.4571910222030936, 'Total loss': 0.4571910222030936}
2022-11-28 05:14:42,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:42,823 INFO:     Epoch: 66
2022-11-28 05:14:43,490 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4811020104045218, 'Total loss': 0.4811020104045218} | train loss {'Reaction outcome loss': 0.4515513337006973, 'Total loss': 0.4515513337006973}
2022-11-28 05:14:43,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:43,491 INFO:     Epoch: 67
2022-11-28 05:14:44,157 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4576487673277205, 'Total loss': 0.4576487673277205} | train loss {'Reaction outcome loss': 0.4579514636387748, 'Total loss': 0.4579514636387748}
2022-11-28 05:14:44,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:44,157 INFO:     Epoch: 68
2022-11-28 05:14:44,822 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4641480635512959, 'Total loss': 0.4641480635512959} | train loss {'Reaction outcome loss': 0.4613941205485213, 'Total loss': 0.4613941205485213}
2022-11-28 05:14:44,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:44,823 INFO:     Epoch: 69
2022-11-28 05:14:45,487 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4448976642028852, 'Total loss': 0.4448976642028852} | train loss {'Reaction outcome loss': 0.45438909392443394, 'Total loss': 0.45438909392443394}
2022-11-28 05:14:45,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:45,487 INFO:     Epoch: 70
2022-11-28 05:14:46,153 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4644111532040618, 'Total loss': 0.4644111532040618} | train loss {'Reaction outcome loss': 0.46152667418843313, 'Total loss': 0.46152667418843313}
2022-11-28 05:14:46,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:46,153 INFO:     Epoch: 71
2022-11-28 05:14:46,816 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45504706928675825, 'Total loss': 0.45504706928675825} | train loss {'Reaction outcome loss': 0.4575959863441606, 'Total loss': 0.4575959863441606}
2022-11-28 05:14:46,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:46,817 INFO:     Epoch: 72
2022-11-28 05:14:47,484 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48480476371266623, 'Total loss': 0.48480476371266623} | train loss {'Reaction outcome loss': 0.459089950207741, 'Total loss': 0.459089950207741}
2022-11-28 05:14:47,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:47,485 INFO:     Epoch: 73
2022-11-28 05:14:48,153 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4682746651497754, 'Total loss': 0.4682746651497754} | train loss {'Reaction outcome loss': 0.4595456017151235, 'Total loss': 0.4595456017151235}
2022-11-28 05:14:48,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:48,154 INFO:     Epoch: 74
2022-11-28 05:14:48,822 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47017194906418974, 'Total loss': 0.47017194906418974} | train loss {'Reaction outcome loss': 0.45649519917224685, 'Total loss': 0.45649519917224685}
2022-11-28 05:14:48,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:48,822 INFO:     Epoch: 75
2022-11-28 05:14:49,495 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4421636545183984, 'Total loss': 0.4421636545183984} | train loss {'Reaction outcome loss': 0.45006480230198753, 'Total loss': 0.45006480230198753}
2022-11-28 05:14:49,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:49,495 INFO:     Epoch: 76
2022-11-28 05:14:50,161 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4614771702750163, 'Total loss': 0.4614771702750163} | train loss {'Reaction outcome loss': 0.45788548147726443, 'Total loss': 0.45788548147726443}
2022-11-28 05:14:50,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:50,161 INFO:     Epoch: 77
2022-11-28 05:14:50,829 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4530630223453045, 'Total loss': 0.4530630223453045} | train loss {'Reaction outcome loss': 0.45667330019416347, 'Total loss': 0.45667330019416347}
2022-11-28 05:14:50,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:50,829 INFO:     Epoch: 78
2022-11-28 05:14:51,495 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4647707793522965, 'Total loss': 0.4647707793522965} | train loss {'Reaction outcome loss': 0.46360252863697465, 'Total loss': 0.46360252863697465}
2022-11-28 05:14:51,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:51,495 INFO:     Epoch: 79
2022-11-28 05:14:52,165 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46150099994106725, 'Total loss': 0.46150099994106725} | train loss {'Reaction outcome loss': 0.46509582248906933, 'Total loss': 0.46509582248906933}
2022-11-28 05:14:52,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:52,166 INFO:     Epoch: 80
2022-11-28 05:14:52,833 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44197581572966144, 'Total loss': 0.44197581572966144} | train loss {'Reaction outcome loss': 0.4654221637474914, 'Total loss': 0.4654221637474914}
2022-11-28 05:14:52,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:52,833 INFO:     Epoch: 81
2022-11-28 05:14:53,502 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44500390169295395, 'Total loss': 0.44500390169295395} | train loss {'Reaction outcome loss': 0.4548507981723355, 'Total loss': 0.4548507981723355}
2022-11-28 05:14:53,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:53,503 INFO:     Epoch: 82
2022-11-28 05:14:54,173 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4549491263248704, 'Total loss': 0.4549491263248704} | train loss {'Reaction outcome loss': 0.4586047230048045, 'Total loss': 0.4586047230048045}
2022-11-28 05:14:54,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:54,174 INFO:     Epoch: 83
2022-11-28 05:14:54,839 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45521741631356155, 'Total loss': 0.45521741631356155} | train loss {'Reaction outcome loss': 0.46407018115203225, 'Total loss': 0.46407018115203225}
2022-11-28 05:14:54,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:54,840 INFO:     Epoch: 84
2022-11-28 05:14:55,506 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4385271509262649, 'Total loss': 0.4385271509262649} | train loss {'Reaction outcome loss': 0.45920276515666514, 'Total loss': 0.45920276515666514}
2022-11-28 05:14:55,506 INFO:     Found new best model at epoch 84
2022-11-28 05:14:55,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:55,507 INFO:     Epoch: 85
2022-11-28 05:14:56,173 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4679334217851812, 'Total loss': 0.4679334217851812} | train loss {'Reaction outcome loss': 0.45652628924337124, 'Total loss': 0.45652628924337124}
2022-11-28 05:14:56,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:56,174 INFO:     Epoch: 86
2022-11-28 05:14:56,842 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4615935168483041, 'Total loss': 0.4615935168483041} | train loss {'Reaction outcome loss': 0.4627520893249781, 'Total loss': 0.4627520893249781}
2022-11-28 05:14:56,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:56,843 INFO:     Epoch: 87
2022-11-28 05:14:57,509 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47822155397046695, 'Total loss': 0.47822155397046695} | train loss {'Reaction outcome loss': 0.45753022739964144, 'Total loss': 0.45753022739964144}
2022-11-28 05:14:57,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:57,510 INFO:     Epoch: 88
2022-11-28 05:14:58,175 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5101243528452787, 'Total loss': 0.5101243528452787} | train loss {'Reaction outcome loss': 0.4605886552843355, 'Total loss': 0.4605886552843355}
2022-11-28 05:14:58,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:58,176 INFO:     Epoch: 89
2022-11-28 05:14:58,841 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48215213451873173, 'Total loss': 0.48215213451873173} | train loss {'Reaction outcome loss': 0.4583024543619925, 'Total loss': 0.4583024543619925}
2022-11-28 05:14:58,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:58,841 INFO:     Epoch: 90
2022-11-28 05:14:59,506 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44741805405779317, 'Total loss': 0.44741805405779317} | train loss {'Reaction outcome loss': 0.4521596034568164, 'Total loss': 0.4521596034568164}
2022-11-28 05:14:59,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:14:59,506 INFO:     Epoch: 91
2022-11-28 05:15:00,169 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4544488022273237, 'Total loss': 0.4544488022273237} | train loss {'Reaction outcome loss': 0.45745070681216254, 'Total loss': 0.45745070681216254}
2022-11-28 05:15:00,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:00,169 INFO:     Epoch: 92
2022-11-28 05:15:00,834 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4656452861699191, 'Total loss': 0.4656452861699191} | train loss {'Reaction outcome loss': 0.45186080056573114, 'Total loss': 0.45186080056573114}
2022-11-28 05:15:00,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:00,835 INFO:     Epoch: 93
2022-11-28 05:15:01,503 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4589358280328187, 'Total loss': 0.4589358280328187} | train loss {'Reaction outcome loss': 0.4591191144239518, 'Total loss': 0.4591191144239518}
2022-11-28 05:15:01,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:01,503 INFO:     Epoch: 94
2022-11-28 05:15:02,166 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4575717571106824, 'Total loss': 0.4575717571106824} | train loss {'Reaction outcome loss': 0.45639743172233144, 'Total loss': 0.45639743172233144}
2022-11-28 05:15:02,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:02,167 INFO:     Epoch: 95
2022-11-28 05:15:02,834 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4916318929330869, 'Total loss': 0.4916318929330869} | train loss {'Reaction outcome loss': 0.4624687254789375, 'Total loss': 0.4624687254789375}
2022-11-28 05:15:02,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:02,834 INFO:     Epoch: 96
2022-11-28 05:15:03,501 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4565310667861592, 'Total loss': 0.4565310667861592} | train loss {'Reaction outcome loss': 0.4618050198881857, 'Total loss': 0.4618050198881857}
2022-11-28 05:15:03,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:03,501 INFO:     Epoch: 97
2022-11-28 05:15:04,170 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44647191058505664, 'Total loss': 0.44647191058505664} | train loss {'Reaction outcome loss': 0.4586205517031973, 'Total loss': 0.4586205517031973}
2022-11-28 05:15:04,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:04,170 INFO:     Epoch: 98
2022-11-28 05:15:04,834 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4634528017856858, 'Total loss': 0.4634528017856858} | train loss {'Reaction outcome loss': 0.45794063962755666, 'Total loss': 0.45794063962755666}
2022-11-28 05:15:04,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:04,834 INFO:     Epoch: 99
2022-11-28 05:15:05,505 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5232762430201877, 'Total loss': 0.5232762430201877} | train loss {'Reaction outcome loss': 0.4564135218219411, 'Total loss': 0.4564135218219411}
2022-11-28 05:15:05,505 INFO:     Best model found after epoch 85 of 100.
2022-11-28 05:15:05,505 INFO:   Done with stage: TRAINING
2022-11-28 05:15:05,505 INFO:   Starting stage: EVALUATION
2022-11-28 05:15:05,618 INFO:   Done with stage: EVALUATION
2022-11-28 05:15:05,618 INFO:   Leaving out SEQ value Fold_8
2022-11-28 05:15:05,631 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 05:15:05,631 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:15:06,283 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:15:06,283 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:15:06,353 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:15:06,353 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:15:06,353 INFO:     No hyperparam tuning for this model
2022-11-28 05:15:06,353 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:15:06,353 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:15:06,354 INFO:     None feature selector for col prot
2022-11-28 05:15:06,354 INFO:     None feature selector for col prot
2022-11-28 05:15:06,354 INFO:     None feature selector for col prot
2022-11-28 05:15:06,355 INFO:     None feature selector for col chem
2022-11-28 05:15:06,355 INFO:     None feature selector for col chem
2022-11-28 05:15:06,355 INFO:     None feature selector for col chem
2022-11-28 05:15:06,355 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:15:06,355 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:15:06,356 INFO:     Number of params in model 169651
2022-11-28 05:15:06,359 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:15:06,360 INFO:   Starting stage: TRAINING
2022-11-28 05:15:06,411 INFO:     Val loss before train {'Reaction outcome loss': 0.9851969074119221, 'Total loss': 0.9851969074119221}
2022-11-28 05:15:06,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:06,411 INFO:     Epoch: 0
2022-11-28 05:15:07,075 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5721747238527645, 'Total loss': 0.5721747238527645} | train loss {'Reaction outcome loss': 0.6915960059531273, 'Total loss': 0.6915960059531273}
2022-11-28 05:15:07,075 INFO:     Found new best model at epoch 0
2022-11-28 05:15:07,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:07,076 INFO:     Epoch: 1
2022-11-28 05:15:07,737 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5793573808940974, 'Total loss': 0.5793573808940974} | train loss {'Reaction outcome loss': 0.5888289529229364, 'Total loss': 0.5888289529229364}
2022-11-28 05:15:07,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:07,737 INFO:     Epoch: 2
2022-11-28 05:15:08,399 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5292542702095075, 'Total loss': 0.5292542702095075} | train loss {'Reaction outcome loss': 0.5652215132009117, 'Total loss': 0.5652215132009117}
2022-11-28 05:15:08,399 INFO:     Found new best model at epoch 2
2022-11-28 05:15:08,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:08,400 INFO:     Epoch: 3
2022-11-28 05:15:09,063 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5254098305648024, 'Total loss': 0.5254098305648024} | train loss {'Reaction outcome loss': 0.54439827607524, 'Total loss': 0.54439827607524}
2022-11-28 05:15:09,063 INFO:     Found new best model at epoch 3
2022-11-28 05:15:09,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:09,064 INFO:     Epoch: 4
2022-11-28 05:15:09,725 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5119712542403828, 'Total loss': 0.5119712542403828} | train loss {'Reaction outcome loss': 0.5452956824052718, 'Total loss': 0.5452956824052718}
2022-11-28 05:15:09,725 INFO:     Found new best model at epoch 4
2022-11-28 05:15:09,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:09,726 INFO:     Epoch: 5
2022-11-28 05:15:10,390 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49645987864245067, 'Total loss': 0.49645987864245067} | train loss {'Reaction outcome loss': 0.5292259087605823, 'Total loss': 0.5292259087605823}
2022-11-28 05:15:10,390 INFO:     Found new best model at epoch 5
2022-11-28 05:15:10,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:10,391 INFO:     Epoch: 6
2022-11-28 05:15:11,055 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5360172418030825, 'Total loss': 0.5360172418030825} | train loss {'Reaction outcome loss': 0.5156457017987005, 'Total loss': 0.5156457017987005}
2022-11-28 05:15:11,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:11,056 INFO:     Epoch: 7
2022-11-28 05:15:11,724 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5023634921420704, 'Total loss': 0.5023634921420704} | train loss {'Reaction outcome loss': 0.5073822582921674, 'Total loss': 0.5073822582921674}
2022-11-28 05:15:11,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:11,725 INFO:     Epoch: 8
2022-11-28 05:15:12,391 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5203255760398778, 'Total loss': 0.5203255760398778} | train loss {'Reaction outcome loss': 0.5057031935261141, 'Total loss': 0.5057031935261141}
2022-11-28 05:15:12,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:12,391 INFO:     Epoch: 9
2022-11-28 05:15:13,058 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4843729185787114, 'Total loss': 0.4843729185787114} | train loss {'Reaction outcome loss': 0.4985193344013345, 'Total loss': 0.4985193344013345}
2022-11-28 05:15:13,058 INFO:     Found new best model at epoch 9
2022-11-28 05:15:13,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:13,059 INFO:     Epoch: 10
2022-11-28 05:15:13,721 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5465663624080744, 'Total loss': 0.5465663624080744} | train loss {'Reaction outcome loss': 0.4956069412611185, 'Total loss': 0.4956069412611185}
2022-11-28 05:15:13,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:13,722 INFO:     Epoch: 11
2022-11-28 05:15:14,385 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48601263998584315, 'Total loss': 0.48601263998584315} | train loss {'Reaction outcome loss': 0.4855303653185406, 'Total loss': 0.4855303653185406}
2022-11-28 05:15:14,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:14,385 INFO:     Epoch: 12
2022-11-28 05:15:15,048 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5003201819278977, 'Total loss': 0.5003201819278977} | train loss {'Reaction outcome loss': 0.48751411544940165, 'Total loss': 0.48751411544940165}
2022-11-28 05:15:15,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:15,048 INFO:     Epoch: 13
2022-11-28 05:15:15,713 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5137004649097269, 'Total loss': 0.5137004649097269} | train loss {'Reaction outcome loss': 0.4797975077263771, 'Total loss': 0.4797975077263771}
2022-11-28 05:15:15,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:15,713 INFO:     Epoch: 14
2022-11-28 05:15:16,376 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48348337276415393, 'Total loss': 0.48348337276415393} | train loss {'Reaction outcome loss': 0.4802561915449558, 'Total loss': 0.4802561915449558}
2022-11-28 05:15:16,376 INFO:     Found new best model at epoch 14
2022-11-28 05:15:16,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:16,377 INFO:     Epoch: 15
2022-11-28 05:15:17,038 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4712824425236745, 'Total loss': 0.4712824425236745} | train loss {'Reaction outcome loss': 0.4788121644167169, 'Total loss': 0.4788121644167169}
2022-11-28 05:15:17,038 INFO:     Found new best model at epoch 15
2022-11-28 05:15:17,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:17,039 INFO:     Epoch: 16
2022-11-28 05:15:17,702 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48587647994810884, 'Total loss': 0.48587647994810884} | train loss {'Reaction outcome loss': 0.48706657517581214, 'Total loss': 0.48706657517581214}
2022-11-28 05:15:17,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:17,702 INFO:     Epoch: 17
2022-11-28 05:15:18,369 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4790500429543582, 'Total loss': 0.4790500429543582} | train loss {'Reaction outcome loss': 0.48106000085751854, 'Total loss': 0.48106000085751854}
2022-11-28 05:15:18,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:18,369 INFO:     Epoch: 18
2022-11-28 05:15:19,035 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5068006440997124, 'Total loss': 0.5068006440997124} | train loss {'Reaction outcome loss': 0.48233153244420407, 'Total loss': 0.48233153244420407}
2022-11-28 05:15:19,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:19,035 INFO:     Epoch: 19
2022-11-28 05:15:19,703 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48208956115625123, 'Total loss': 0.48208956115625123} | train loss {'Reaction outcome loss': 0.47644446315544264, 'Total loss': 0.47644446315544264}
2022-11-28 05:15:19,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:19,703 INFO:     Epoch: 20
2022-11-28 05:15:20,364 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.475372182035988, 'Total loss': 0.475372182035988} | train loss {'Reaction outcome loss': 0.47852928930472943, 'Total loss': 0.47852928930472943}
2022-11-28 05:15:20,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:20,364 INFO:     Epoch: 21
2022-11-28 05:15:21,031 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4824367311190475, 'Total loss': 0.4824367311190475} | train loss {'Reaction outcome loss': 0.48379365625160353, 'Total loss': 0.48379365625160353}
2022-11-28 05:15:21,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:21,031 INFO:     Epoch: 22
2022-11-28 05:15:21,692 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4935915114527399, 'Total loss': 0.4935915114527399} | train loss {'Reaction outcome loss': 0.4752870635880578, 'Total loss': 0.4752870635880578}
2022-11-28 05:15:21,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:21,692 INFO:     Epoch: 23
2022-11-28 05:15:22,358 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4614958895201033, 'Total loss': 0.4614958895201033} | train loss {'Reaction outcome loss': 0.47565183734461186, 'Total loss': 0.47565183734461186}
2022-11-28 05:15:22,359 INFO:     Found new best model at epoch 23
2022-11-28 05:15:22,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:22,359 INFO:     Epoch: 24
2022-11-28 05:15:23,027 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46551209180192515, 'Total loss': 0.46551209180192515} | train loss {'Reaction outcome loss': 0.4767592242888866, 'Total loss': 0.4767592242888866}
2022-11-28 05:15:23,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:23,027 INFO:     Epoch: 25
2022-11-28 05:15:23,693 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4620876092125069, 'Total loss': 0.4620876092125069} | train loss {'Reaction outcome loss': 0.47680449551872667, 'Total loss': 0.47680449551872667}
2022-11-28 05:15:23,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:23,694 INFO:     Epoch: 26
2022-11-28 05:15:24,362 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4731364720924334, 'Total loss': 0.4731364720924334} | train loss {'Reaction outcome loss': 0.4817315001761721, 'Total loss': 0.4817315001761721}
2022-11-28 05:15:24,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:24,362 INFO:     Epoch: 27
2022-11-28 05:15:25,026 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48260766741904343, 'Total loss': 0.48260766741904343} | train loss {'Reaction outcome loss': 0.48142066633989733, 'Total loss': 0.48142066633989733}
2022-11-28 05:15:25,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:25,027 INFO:     Epoch: 28
2022-11-28 05:15:25,694 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47122491760687396, 'Total loss': 0.47122491760687396} | train loss {'Reaction outcome loss': 0.4757988003473128, 'Total loss': 0.4757988003473128}
2022-11-28 05:15:25,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:25,694 INFO:     Epoch: 29
2022-11-28 05:15:26,362 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4565805494785309, 'Total loss': 0.4565805494785309} | train loss {'Reaction outcome loss': 0.4746302655267139, 'Total loss': 0.4746302655267139}
2022-11-28 05:15:26,363 INFO:     Found new best model at epoch 29
2022-11-28 05:15:26,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:26,364 INFO:     Epoch: 30
2022-11-28 05:15:27,035 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5041139586405321, 'Total loss': 0.5041139586405321} | train loss {'Reaction outcome loss': 0.47394364543499484, 'Total loss': 0.47394364543499484}
2022-11-28 05:15:27,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:27,035 INFO:     Epoch: 31
2022-11-28 05:15:27,704 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4809772887013175, 'Total loss': 0.4809772887013175} | train loss {'Reaction outcome loss': 0.47413621686639323, 'Total loss': 0.47413621686639323}
2022-11-28 05:15:27,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:27,705 INFO:     Epoch: 32
2022-11-28 05:15:28,365 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47191163287921384, 'Total loss': 0.47191163287921384} | train loss {'Reaction outcome loss': 0.4782950399263251, 'Total loss': 0.4782950399263251}
2022-11-28 05:15:28,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:28,365 INFO:     Epoch: 33
2022-11-28 05:15:29,028 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5077199150215496, 'Total loss': 0.5077199150215496} | train loss {'Reaction outcome loss': 0.4736086001860038, 'Total loss': 0.4736086001860038}
2022-11-28 05:15:29,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:29,028 INFO:     Epoch: 34
2022-11-28 05:15:29,691 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47262985191561957, 'Total loss': 0.47262985191561957} | train loss {'Reaction outcome loss': 0.4786596817355002, 'Total loss': 0.4786596817355002}
2022-11-28 05:15:29,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:29,691 INFO:     Epoch: 35
2022-11-28 05:15:30,356 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4502019655298103, 'Total loss': 0.4502019655298103} | train loss {'Reaction outcome loss': 0.47663562624685224, 'Total loss': 0.47663562624685224}
2022-11-28 05:15:30,356 INFO:     Found new best model at epoch 35
2022-11-28 05:15:30,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:30,357 INFO:     Epoch: 36
2022-11-28 05:15:31,025 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49419502981684427, 'Total loss': 0.49419502981684427} | train loss {'Reaction outcome loss': 0.47574091636605803, 'Total loss': 0.47574091636605803}
2022-11-28 05:15:31,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:31,026 INFO:     Epoch: 37
2022-11-28 05:15:31,690 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46197437596592034, 'Total loss': 0.46197437596592034} | train loss {'Reaction outcome loss': 0.48227246892788717, 'Total loss': 0.48227246892788717}
2022-11-28 05:15:31,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:31,691 INFO:     Epoch: 38
2022-11-28 05:15:32,356 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4700870950790969, 'Total loss': 0.4700870950790969} | train loss {'Reaction outcome loss': 0.4838217573180314, 'Total loss': 0.4838217573180314}
2022-11-28 05:15:32,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:32,357 INFO:     Epoch: 39
2022-11-28 05:15:33,025 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5047697672112421, 'Total loss': 0.5047697672112421} | train loss {'Reaction outcome loss': 0.47818459885855835, 'Total loss': 0.47818459885855835}
2022-11-28 05:15:33,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:33,026 INFO:     Epoch: 40
2022-11-28 05:15:33,693 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46414097906513646, 'Total loss': 0.46414097906513646} | train loss {'Reaction outcome loss': 0.4741282830795934, 'Total loss': 0.4741282830795934}
2022-11-28 05:15:33,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:33,693 INFO:     Epoch: 41
2022-11-28 05:15:34,358 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47140614552931354, 'Total loss': 0.47140614552931354} | train loss {'Reaction outcome loss': 0.4822356420298738, 'Total loss': 0.4822356420298738}
2022-11-28 05:15:34,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:34,358 INFO:     Epoch: 42
2022-11-28 05:15:35,025 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47176384688778356, 'Total loss': 0.47176384688778356} | train loss {'Reaction outcome loss': 0.4788813713577486, 'Total loss': 0.4788813713577486}
2022-11-28 05:15:35,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:35,025 INFO:     Epoch: 43
2022-11-28 05:15:35,686 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5410002571615306, 'Total loss': 0.5410002571615306} | train loss {'Reaction outcome loss': 0.47760009555326355, 'Total loss': 0.47760009555326355}
2022-11-28 05:15:35,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:35,686 INFO:     Epoch: 44
2022-11-28 05:15:36,349 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4978955462574959, 'Total loss': 0.4978955462574959} | train loss {'Reaction outcome loss': 0.4801935491662833, 'Total loss': 0.4801935491662833}
2022-11-28 05:15:36,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:36,350 INFO:     Epoch: 45
2022-11-28 05:15:37,013 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5020850111137737, 'Total loss': 0.5020850111137737} | train loss {'Reaction outcome loss': 0.4771084800482758, 'Total loss': 0.4771084800482758}
2022-11-28 05:15:37,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:37,013 INFO:     Epoch: 46
2022-11-28 05:15:37,679 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48223269053480844, 'Total loss': 0.48223269053480844} | train loss {'Reaction outcome loss': 0.47762918141820737, 'Total loss': 0.47762918141820737}
2022-11-28 05:15:37,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:37,680 INFO:     Epoch: 47
2022-11-28 05:15:38,348 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4810749217867851, 'Total loss': 0.4810749217867851} | train loss {'Reaction outcome loss': 0.474645214095231, 'Total loss': 0.474645214095231}
2022-11-28 05:15:38,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:38,349 INFO:     Epoch: 48
2022-11-28 05:15:39,015 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49625648896802554, 'Total loss': 0.49625648896802554} | train loss {'Reaction outcome loss': 0.4771422531696097, 'Total loss': 0.4771422531696097}
2022-11-28 05:15:39,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:39,015 INFO:     Epoch: 49
2022-11-28 05:15:39,677 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4855964376845143, 'Total loss': 0.4855964376845143} | train loss {'Reaction outcome loss': 0.48532504366049845, 'Total loss': 0.48532504366049845}
2022-11-28 05:15:39,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:39,677 INFO:     Epoch: 50
2022-11-28 05:15:40,337 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.473590281537988, 'Total loss': 0.473590281537988} | train loss {'Reaction outcome loss': 0.48433153223126163, 'Total loss': 0.48433153223126163}
2022-11-28 05:15:40,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:40,337 INFO:     Epoch: 51
2022-11-28 05:15:41,003 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4716267700899731, 'Total loss': 0.4716267700899731} | train loss {'Reaction outcome loss': 0.4743225490073523, 'Total loss': 0.4743225490073523}
2022-11-28 05:15:41,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:41,003 INFO:     Epoch: 52
2022-11-28 05:15:41,665 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5034500963308595, 'Total loss': 0.5034500963308595} | train loss {'Reaction outcome loss': 0.47677592329320406, 'Total loss': 0.47677592329320406}
2022-11-28 05:15:41,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:41,666 INFO:     Epoch: 53
2022-11-28 05:15:42,327 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4796805517240004, 'Total loss': 0.4796805517240004} | train loss {'Reaction outcome loss': 0.4789800844605892, 'Total loss': 0.4789800844605892}
2022-11-28 05:15:42,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:42,327 INFO:     Epoch: 54
2022-11-28 05:15:42,993 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48112981055270543, 'Total loss': 0.48112981055270543} | train loss {'Reaction outcome loss': 0.4760190226257809, 'Total loss': 0.4760190226257809}
2022-11-28 05:15:42,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:42,994 INFO:     Epoch: 55
2022-11-28 05:15:43,661 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45707993107763206, 'Total loss': 0.45707993107763206} | train loss {'Reaction outcome loss': 0.4764377300387188, 'Total loss': 0.4764377300387188}
2022-11-28 05:15:43,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:43,661 INFO:     Epoch: 56
2022-11-28 05:15:44,321 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4975062534213066, 'Total loss': 0.4975062534213066} | train loss {'Reaction outcome loss': 0.4772101088817562, 'Total loss': 0.4772101088817562}
2022-11-28 05:15:44,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:44,321 INFO:     Epoch: 57
2022-11-28 05:15:44,986 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4669287587431344, 'Total loss': 0.4669287587431344} | train loss {'Reaction outcome loss': 0.47691627946351806, 'Total loss': 0.47691627946351806}
2022-11-28 05:15:44,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:44,986 INFO:     Epoch: 58
2022-11-28 05:15:45,656 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46770102700049226, 'Total loss': 0.46770102700049226} | train loss {'Reaction outcome loss': 0.4768183810576316, 'Total loss': 0.4768183810576316}
2022-11-28 05:15:45,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:45,657 INFO:     Epoch: 59
2022-11-28 05:15:46,322 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4686641449278051, 'Total loss': 0.4686641449278051} | train loss {'Reaction outcome loss': 0.47756866780259916, 'Total loss': 0.47756866780259916}
2022-11-28 05:15:46,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:46,322 INFO:     Epoch: 60
2022-11-28 05:15:46,990 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5113262127746235, 'Total loss': 0.5113262127746235} | train loss {'Reaction outcome loss': 0.47548860924378517, 'Total loss': 0.47548860924378517}
2022-11-28 05:15:46,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:46,991 INFO:     Epoch: 61
2022-11-28 05:15:47,653 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4752198119055141, 'Total loss': 0.4752198119055141} | train loss {'Reaction outcome loss': 0.4799148552420159, 'Total loss': 0.4799148552420159}
2022-11-28 05:15:47,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:47,653 INFO:     Epoch: 62
2022-11-28 05:15:48,317 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.476024637168104, 'Total loss': 0.476024637168104} | train loss {'Reaction outcome loss': 0.4854689265691465, 'Total loss': 0.4854689265691465}
2022-11-28 05:15:48,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:48,317 INFO:     Epoch: 63
2022-11-28 05:15:48,980 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45897105878049677, 'Total loss': 0.45897105878049677} | train loss {'Reaction outcome loss': 0.47563612503149816, 'Total loss': 0.47563612503149816}
2022-11-28 05:15:48,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:48,980 INFO:     Epoch: 64
2022-11-28 05:15:49,644 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4944475069642067, 'Total loss': 0.4944475069642067} | train loss {'Reaction outcome loss': 0.47695645176234747, 'Total loss': 0.47695645176234747}
2022-11-28 05:15:49,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:49,644 INFO:     Epoch: 65
2022-11-28 05:15:50,308 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4616695141250437, 'Total loss': 0.4616695141250437} | train loss {'Reaction outcome loss': 0.47734989907832875, 'Total loss': 0.47734989907832875}
2022-11-28 05:15:50,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:50,308 INFO:     Epoch: 66
2022-11-28 05:15:50,971 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4723923070864244, 'Total loss': 0.4723923070864244} | train loss {'Reaction outcome loss': 0.48565759888339427, 'Total loss': 0.48565759888339427}
2022-11-28 05:15:50,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:50,972 INFO:     Epoch: 67
2022-11-28 05:15:51,636 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48532829840074887, 'Total loss': 0.48532829840074887} | train loss {'Reaction outcome loss': 0.4808063853171564, 'Total loss': 0.4808063853171564}
2022-11-28 05:15:51,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:51,637 INFO:     Epoch: 68
2022-11-28 05:15:52,301 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47160771827806125, 'Total loss': 0.47160771827806125} | train loss {'Reaction outcome loss': 0.4839064484882739, 'Total loss': 0.4839064484882739}
2022-11-28 05:15:52,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:52,301 INFO:     Epoch: 69
2022-11-28 05:15:52,964 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45700272477485915, 'Total loss': 0.45700272477485915} | train loss {'Reaction outcome loss': 0.47677195225391655, 'Total loss': 0.47677195225391655}
2022-11-28 05:15:52,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:52,964 INFO:     Epoch: 70
2022-11-28 05:15:53,629 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.49913136423988774, 'Total loss': 0.49913136423988774} | train loss {'Reaction outcome loss': 0.4719500283320104, 'Total loss': 0.4719500283320104}
2022-11-28 05:15:53,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:53,629 INFO:     Epoch: 71
2022-11-28 05:15:54,293 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48597237501632085, 'Total loss': 0.48597237501632085} | train loss {'Reaction outcome loss': 0.485522476355395, 'Total loss': 0.485522476355395}
2022-11-28 05:15:54,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:54,294 INFO:     Epoch: 72
2022-11-28 05:15:54,958 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4641068841923367, 'Total loss': 0.4641068841923367} | train loss {'Reaction outcome loss': 0.48480273795224005, 'Total loss': 0.48480273795224005}
2022-11-28 05:15:54,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:54,958 INFO:     Epoch: 73
2022-11-28 05:15:55,623 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46581943096085027, 'Total loss': 0.46581943096085027} | train loss {'Reaction outcome loss': 0.47856748668897536, 'Total loss': 0.47856748668897536}
2022-11-28 05:15:55,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:55,623 INFO:     Epoch: 74
2022-11-28 05:15:56,291 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4656405834989114, 'Total loss': 0.4656405834989114} | train loss {'Reaction outcome loss': 0.4784674574771235, 'Total loss': 0.4784674574771235}
2022-11-28 05:15:56,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:56,291 INFO:     Epoch: 75
2022-11-28 05:15:56,957 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5300589915026318, 'Total loss': 0.5300589915026318} | train loss {'Reaction outcome loss': 0.475967415217911, 'Total loss': 0.475967415217911}
2022-11-28 05:15:56,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:56,958 INFO:     Epoch: 76
2022-11-28 05:15:57,625 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4969816231592135, 'Total loss': 0.4969816231592135} | train loss {'Reaction outcome loss': 0.4785277780385748, 'Total loss': 0.4785277780385748}
2022-11-28 05:15:57,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:57,625 INFO:     Epoch: 77
2022-11-28 05:15:58,287 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.461938853290948, 'Total loss': 0.461938853290948} | train loss {'Reaction outcome loss': 0.4778152101583058, 'Total loss': 0.4778152101583058}
2022-11-28 05:15:58,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:58,288 INFO:     Epoch: 78
2022-11-28 05:15:58,952 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4925291436639699, 'Total loss': 0.4925291436639699} | train loss {'Reaction outcome loss': 0.4789498411118984, 'Total loss': 0.4789498411118984}
2022-11-28 05:15:58,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:58,952 INFO:     Epoch: 79
2022-11-28 05:15:59,617 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47524639015847986, 'Total loss': 0.47524639015847986} | train loss {'Reaction outcome loss': 0.4775941763073206, 'Total loss': 0.4775941763073206}
2022-11-28 05:15:59,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:15:59,617 INFO:     Epoch: 80
2022-11-28 05:16:00,281 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4836686412719163, 'Total loss': 0.4836686412719163} | train loss {'Reaction outcome loss': 0.4784113899954865, 'Total loss': 0.4784113899954865}
2022-11-28 05:16:00,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:00,281 INFO:     Epoch: 81
2022-11-28 05:16:00,941 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5195872472091154, 'Total loss': 0.5195872472091154} | train loss {'Reaction outcome loss': 0.4816374647761545, 'Total loss': 0.4816374647761545}
2022-11-28 05:16:00,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:00,941 INFO:     Epoch: 82
2022-11-28 05:16:01,606 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5350492576306517, 'Total loss': 0.5350492576306517} | train loss {'Reaction outcome loss': 0.48339522089208325, 'Total loss': 0.48339522089208325}
2022-11-28 05:16:01,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:01,606 INFO:     Epoch: 83
2022-11-28 05:16:02,269 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46722532605583017, 'Total loss': 0.46722532605583017} | train loss {'Reaction outcome loss': 0.48635629738771147, 'Total loss': 0.48635629738771147}
2022-11-28 05:16:02,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:02,270 INFO:     Epoch: 84
2022-11-28 05:16:02,933 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4752819971604781, 'Total loss': 0.4752819971604781} | train loss {'Reaction outcome loss': 0.4799991708489195, 'Total loss': 0.4799991708489195}
2022-11-28 05:16:02,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:02,933 INFO:     Epoch: 85
2022-11-28 05:16:03,597 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4893385354768146, 'Total loss': 0.4893385354768146} | train loss {'Reaction outcome loss': 0.47641464106498227, 'Total loss': 0.47641464106498227}
2022-11-28 05:16:03,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:03,598 INFO:     Epoch: 86
2022-11-28 05:16:04,261 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4669714370234446, 'Total loss': 0.4669714370234446} | train loss {'Reaction outcome loss': 0.4791772473723658, 'Total loss': 0.4791772473723658}
2022-11-28 05:16:04,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:04,261 INFO:     Epoch: 87
2022-11-28 05:16:04,926 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47879488427530636, 'Total loss': 0.47879488427530636} | train loss {'Reaction outcome loss': 0.4746186075311515, 'Total loss': 0.4746186075311515}
2022-11-28 05:16:04,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:04,926 INFO:     Epoch: 88
2022-11-28 05:16:05,592 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4746077592399987, 'Total loss': 0.4746077592399987} | train loss {'Reaction outcome loss': 0.4853548465837394, 'Total loss': 0.4853548465837394}
2022-11-28 05:16:05,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:05,592 INFO:     Epoch: 89
2022-11-28 05:16:06,254 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48869121819734573, 'Total loss': 0.48869121819734573} | train loss {'Reaction outcome loss': 0.47206354669986234, 'Total loss': 0.47206354669986234}
2022-11-28 05:16:06,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:06,254 INFO:     Epoch: 90
2022-11-28 05:16:06,918 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4702187674966725, 'Total loss': 0.4702187674966725} | train loss {'Reaction outcome loss': 0.4781529609594614, 'Total loss': 0.4781529609594614}
2022-11-28 05:16:06,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:06,918 INFO:     Epoch: 91
2022-11-28 05:16:07,584 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4920813126320189, 'Total loss': 0.4920813126320189} | train loss {'Reaction outcome loss': 0.4748241876161868, 'Total loss': 0.4748241876161868}
2022-11-28 05:16:07,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:07,584 INFO:     Epoch: 92
2022-11-28 05:16:08,250 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47535314614122565, 'Total loss': 0.47535314614122565} | train loss {'Reaction outcome loss': 0.4781760545447469, 'Total loss': 0.4781760545447469}
2022-11-28 05:16:08,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:08,250 INFO:     Epoch: 93
2022-11-28 05:16:08,913 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4550777284259146, 'Total loss': 0.4550777284259146} | train loss {'Reaction outcome loss': 0.4766537292349723, 'Total loss': 0.4766537292349723}
2022-11-28 05:16:08,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:08,913 INFO:     Epoch: 94
2022-11-28 05:16:09,581 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4612432745369998, 'Total loss': 0.4612432745369998} | train loss {'Reaction outcome loss': 0.4805619288836756, 'Total loss': 0.4805619288836756}
2022-11-28 05:16:09,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:09,581 INFO:     Epoch: 95
2022-11-28 05:16:10,249 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4719733487476002, 'Total loss': 0.4719733487476002} | train loss {'Reaction outcome loss': 0.47259572286519314, 'Total loss': 0.47259572286519314}
2022-11-28 05:16:10,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:10,249 INFO:     Epoch: 96
2022-11-28 05:16:10,913 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.473531113429503, 'Total loss': 0.473531113429503} | train loss {'Reaction outcome loss': 0.47963853697142295, 'Total loss': 0.47963853697142295}
2022-11-28 05:16:10,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:10,913 INFO:     Epoch: 97
2022-11-28 05:16:11,581 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47604259848594666, 'Total loss': 0.47604259848594666} | train loss {'Reaction outcome loss': 0.48232383887854313, 'Total loss': 0.48232383887854313}
2022-11-28 05:16:11,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:11,581 INFO:     Epoch: 98
2022-11-28 05:16:12,247 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48143443058837543, 'Total loss': 0.48143443058837543} | train loss {'Reaction outcome loss': 0.4841002212056229, 'Total loss': 0.4841002212056229}
2022-11-28 05:16:12,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:12,248 INFO:     Epoch: 99
2022-11-28 05:16:12,914 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4695674777030945, 'Total loss': 0.4695674777030945} | train loss {'Reaction outcome loss': 0.47575674308163507, 'Total loss': 0.47575674308163507}
2022-11-28 05:16:12,914 INFO:     Best model found after epoch 36 of 100.
2022-11-28 05:16:12,914 INFO:   Done with stage: TRAINING
2022-11-28 05:16:12,914 INFO:   Starting stage: EVALUATION
2022-11-28 05:16:13,026 INFO:   Done with stage: EVALUATION
2022-11-28 05:16:13,027 INFO:   Leaving out SEQ value Fold_9
2022-11-28 05:16:13,039 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 05:16:13,039 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:16:13,680 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:16:13,681 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:16:13,750 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:16:13,750 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:16:13,750 INFO:     No hyperparam tuning for this model
2022-11-28 05:16:13,750 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:16:13,750 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:16:13,751 INFO:     None feature selector for col prot
2022-11-28 05:16:13,751 INFO:     None feature selector for col prot
2022-11-28 05:16:13,751 INFO:     None feature selector for col prot
2022-11-28 05:16:13,751 INFO:     None feature selector for col chem
2022-11-28 05:16:13,752 INFO:     None feature selector for col chem
2022-11-28 05:16:13,752 INFO:     None feature selector for col chem
2022-11-28 05:16:13,752 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:16:13,752 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:16:13,753 INFO:     Number of params in model 169651
2022-11-28 05:16:13,756 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:16:13,756 INFO:   Starting stage: TRAINING
2022-11-28 05:16:13,808 INFO:     Val loss before train {'Reaction outcome loss': 1.0628213713114911, 'Total loss': 1.0628213713114911}
2022-11-28 05:16:13,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:13,808 INFO:     Epoch: 0
2022-11-28 05:16:14,470 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6419954503124411, 'Total loss': 0.6419954503124411} | train loss {'Reaction outcome loss': 0.6871913723799647, 'Total loss': 0.6871913723799647}
2022-11-28 05:16:14,471 INFO:     Found new best model at epoch 0
2022-11-28 05:16:14,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:14,471 INFO:     Epoch: 1
2022-11-28 05:16:15,133 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5604225295511159, 'Total loss': 0.5604225295511159} | train loss {'Reaction outcome loss': 0.5958553572090305, 'Total loss': 0.5958553572090305}
2022-11-28 05:16:15,133 INFO:     Found new best model at epoch 1
2022-11-28 05:16:15,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:15,134 INFO:     Epoch: 2
2022-11-28 05:16:15,800 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5504823716526682, 'Total loss': 0.5504823716526682} | train loss {'Reaction outcome loss': 0.5449839247732746, 'Total loss': 0.5449839247732746}
2022-11-28 05:16:15,801 INFO:     Found new best model at epoch 2
2022-11-28 05:16:15,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:15,802 INFO:     Epoch: 3
2022-11-28 05:16:16,466 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5760973942550746, 'Total loss': 0.5760973942550746} | train loss {'Reaction outcome loss': 0.5361717503289787, 'Total loss': 0.5361717503289787}
2022-11-28 05:16:16,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:16,466 INFO:     Epoch: 4
2022-11-28 05:16:17,129 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5176751132715832, 'Total loss': 0.5176751132715832} | train loss {'Reaction outcome loss': 0.5109339051708883, 'Total loss': 0.5109339051708883}
2022-11-28 05:16:17,129 INFO:     Found new best model at epoch 4
2022-11-28 05:16:17,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:17,130 INFO:     Epoch: 5
2022-11-28 05:16:17,789 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.519876645708626, 'Total loss': 0.519876645708626} | train loss {'Reaction outcome loss': 0.5022508328666493, 'Total loss': 0.5022508328666493}
2022-11-28 05:16:17,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:17,789 INFO:     Epoch: 6
2022-11-28 05:16:18,449 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5042832602154125, 'Total loss': 0.5042832602154125} | train loss {'Reaction outcome loss': 0.506091145714935, 'Total loss': 0.506091145714935}
2022-11-28 05:16:18,450 INFO:     Found new best model at epoch 6
2022-11-28 05:16:18,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:18,450 INFO:     Epoch: 7
2022-11-28 05:16:19,112 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48528627170757815, 'Total loss': 0.48528627170757815} | train loss {'Reaction outcome loss': 0.4908830463886261, 'Total loss': 0.4908830463886261}
2022-11-28 05:16:19,112 INFO:     Found new best model at epoch 7
2022-11-28 05:16:19,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:19,113 INFO:     Epoch: 8
2022-11-28 05:16:19,777 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4881451824171977, 'Total loss': 0.4881451824171977} | train loss {'Reaction outcome loss': 0.48447174673177756, 'Total loss': 0.48447174673177756}
2022-11-28 05:16:19,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:19,777 INFO:     Epoch: 9
2022-11-28 05:16:20,433 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49195128272880206, 'Total loss': 0.49195128272880206} | train loss {'Reaction outcome loss': 0.48723812194503086, 'Total loss': 0.48723812194503086}
2022-11-28 05:16:20,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:20,433 INFO:     Epoch: 10
2022-11-28 05:16:21,089 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.492433005774563, 'Total loss': 0.492433005774563} | train loss {'Reaction outcome loss': 0.484932101076963, 'Total loss': 0.484932101076963}
2022-11-28 05:16:21,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:21,089 INFO:     Epoch: 11
2022-11-28 05:16:21,746 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4875707484104417, 'Total loss': 0.4875707484104417} | train loss {'Reaction outcome loss': 0.4815641295544955, 'Total loss': 0.4815641295544955}
2022-11-28 05:16:21,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:21,747 INFO:     Epoch: 12
2022-11-28 05:16:22,403 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47433051229877904, 'Total loss': 0.47433051229877904} | train loss {'Reaction outcome loss': 0.4786961932571567, 'Total loss': 0.4786961932571567}
2022-11-28 05:16:22,403 INFO:     Found new best model at epoch 12
2022-11-28 05:16:22,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:22,404 INFO:     Epoch: 13
2022-11-28 05:16:23,061 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4987759820439599, 'Total loss': 0.4987759820439599} | train loss {'Reaction outcome loss': 0.4760532413210188, 'Total loss': 0.4760532413210188}
2022-11-28 05:16:23,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:23,061 INFO:     Epoch: 14
2022-11-28 05:16:23,720 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.513958515049043, 'Total loss': 0.513958515049043} | train loss {'Reaction outcome loss': 0.48228635660239627, 'Total loss': 0.48228635660239627}
2022-11-28 05:16:23,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:23,720 INFO:     Epoch: 15
2022-11-28 05:16:24,378 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48543568497354334, 'Total loss': 0.48543568497354334} | train loss {'Reaction outcome loss': 0.4665511314662135, 'Total loss': 0.4665511314662135}
2022-11-28 05:16:24,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:24,378 INFO:     Epoch: 16
2022-11-28 05:16:25,036 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5238250775093382, 'Total loss': 0.5238250775093382} | train loss {'Reaction outcome loss': 0.4686783777815955, 'Total loss': 0.4686783777815955}
2022-11-28 05:16:25,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:25,036 INFO:     Epoch: 17
2022-11-28 05:16:25,693 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5229428112506866, 'Total loss': 0.5229428112506866} | train loss {'Reaction outcome loss': 0.4715457640132126, 'Total loss': 0.4715457640132126}
2022-11-28 05:16:25,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:25,693 INFO:     Epoch: 18
2022-11-28 05:16:26,348 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48543718948282977, 'Total loss': 0.48543718948282977} | train loss {'Reaction outcome loss': 0.47254299843797876, 'Total loss': 0.47254299843797876}
2022-11-28 05:16:26,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:26,348 INFO:     Epoch: 19
2022-11-28 05:16:27,002 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4731198681349104, 'Total loss': 0.4731198681349104} | train loss {'Reaction outcome loss': 0.46495249666729754, 'Total loss': 0.46495249666729754}
2022-11-28 05:16:27,002 INFO:     Found new best model at epoch 19
2022-11-28 05:16:27,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:27,003 INFO:     Epoch: 20
2022-11-28 05:16:27,659 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48506617546081543, 'Total loss': 0.48506617546081543} | train loss {'Reaction outcome loss': 0.4737416123553198, 'Total loss': 0.4737416123553198}
2022-11-28 05:16:27,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:27,659 INFO:     Epoch: 21
2022-11-28 05:16:28,313 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5014771331440319, 'Total loss': 0.5014771331440319} | train loss {'Reaction outcome loss': 0.4686092307372969, 'Total loss': 0.4686092307372969}
2022-11-28 05:16:28,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:28,314 INFO:     Epoch: 22
2022-11-28 05:16:28,968 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4561256617307663, 'Total loss': 0.4561256617307663} | train loss {'Reaction outcome loss': 0.46906930536639935, 'Total loss': 0.46906930536639935}
2022-11-28 05:16:28,968 INFO:     Found new best model at epoch 22
2022-11-28 05:16:28,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:28,969 INFO:     Epoch: 23
2022-11-28 05:16:29,626 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4937034902924841, 'Total loss': 0.4937034902924841} | train loss {'Reaction outcome loss': 0.4644085403607816, 'Total loss': 0.4644085403607816}
2022-11-28 05:16:29,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:29,626 INFO:     Epoch: 24
2022-11-28 05:16:30,282 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47731551053849136, 'Total loss': 0.47731551053849136} | train loss {'Reaction outcome loss': 0.47029925232030906, 'Total loss': 0.47029925232030906}
2022-11-28 05:16:30,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:30,282 INFO:     Epoch: 25
2022-11-28 05:16:30,939 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5172542848370292, 'Total loss': 0.5172542848370292} | train loss {'Reaction outcome loss': 0.45947402314263946, 'Total loss': 0.45947402314263946}
2022-11-28 05:16:30,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:30,939 INFO:     Epoch: 26
2022-11-28 05:16:31,598 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46123300966891373, 'Total loss': 0.46123300966891373} | train loss {'Reaction outcome loss': 0.47413542964020555, 'Total loss': 0.47413542964020555}
2022-11-28 05:16:31,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:31,599 INFO:     Epoch: 27
2022-11-28 05:16:32,256 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47003283961252734, 'Total loss': 0.47003283961252734} | train loss {'Reaction outcome loss': 0.46774452827414686, 'Total loss': 0.46774452827414686}
2022-11-28 05:16:32,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:32,256 INFO:     Epoch: 28
2022-11-28 05:16:32,912 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4708791727369482, 'Total loss': 0.4708791727369482} | train loss {'Reaction outcome loss': 0.46509231943257, 'Total loss': 0.46509231943257}
2022-11-28 05:16:32,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:32,912 INFO:     Epoch: 29
2022-11-28 05:16:33,568 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4717638980258595, 'Total loss': 0.4717638980258595} | train loss {'Reaction outcome loss': 0.4600550836446334, 'Total loss': 0.4600550836446334}
2022-11-28 05:16:33,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:33,568 INFO:     Epoch: 30
2022-11-28 05:16:34,223 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45658897947181354, 'Total loss': 0.45658897947181354} | train loss {'Reaction outcome loss': 0.4639909758859751, 'Total loss': 0.4639909758859751}
2022-11-28 05:16:34,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:34,223 INFO:     Epoch: 31
2022-11-28 05:16:34,876 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46557842973958363, 'Total loss': 0.46557842973958363} | train loss {'Reaction outcome loss': 0.45791218998480815, 'Total loss': 0.45791218998480815}
2022-11-28 05:16:34,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:34,877 INFO:     Epoch: 32
2022-11-28 05:16:35,530 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4872690280052749, 'Total loss': 0.4872690280052749} | train loss {'Reaction outcome loss': 0.4640219084462341, 'Total loss': 0.4640219084462341}
2022-11-28 05:16:35,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:35,530 INFO:     Epoch: 33
2022-11-28 05:16:36,185 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5317727222361348, 'Total loss': 0.5317727222361348} | train loss {'Reaction outcome loss': 0.4641263456977144, 'Total loss': 0.4641263456977144}
2022-11-28 05:16:36,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:36,185 INFO:     Epoch: 34
2022-11-28 05:16:36,840 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.505113924768838, 'Total loss': 0.505113924768838} | train loss {'Reaction outcome loss': 0.4673680861993712, 'Total loss': 0.4673680861993712}
2022-11-28 05:16:36,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:36,841 INFO:     Epoch: 35
2022-11-28 05:16:37,496 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46562286195429886, 'Total loss': 0.46562286195429886} | train loss {'Reaction outcome loss': 0.45406652804540126, 'Total loss': 0.45406652804540126}
2022-11-28 05:16:37,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:37,497 INFO:     Epoch: 36
2022-11-28 05:16:38,153 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4605196592482654, 'Total loss': 0.4605196592482654} | train loss {'Reaction outcome loss': 0.45866579206622377, 'Total loss': 0.45866579206622377}
2022-11-28 05:16:38,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:38,154 INFO:     Epoch: 37
2022-11-28 05:16:38,809 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47418295084075496, 'Total loss': 0.47418295084075496} | train loss {'Reaction outcome loss': 0.46007907667330333, 'Total loss': 0.46007907667330333}
2022-11-28 05:16:38,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:38,809 INFO:     Epoch: 38
2022-11-28 05:16:39,465 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4933836859735576, 'Total loss': 0.4933836859735576} | train loss {'Reaction outcome loss': 0.4544509063569867, 'Total loss': 0.4544509063569867}
2022-11-28 05:16:39,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:39,465 INFO:     Epoch: 39
2022-11-28 05:16:40,117 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46313970298929646, 'Total loss': 0.46313970298929646} | train loss {'Reaction outcome loss': 0.4578074239346446, 'Total loss': 0.4578074239346446}
2022-11-28 05:16:40,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:40,118 INFO:     Epoch: 40
2022-11-28 05:16:40,771 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.505300032144243, 'Total loss': 0.505300032144243} | train loss {'Reaction outcome loss': 0.45645524603979926, 'Total loss': 0.45645524603979926}
2022-11-28 05:16:40,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:40,771 INFO:     Epoch: 41
2022-11-28 05:16:41,425 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47198386185548524, 'Total loss': 0.47198386185548524} | train loss {'Reaction outcome loss': 0.45611304823233156, 'Total loss': 0.45611304823233156}
2022-11-28 05:16:41,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:41,426 INFO:     Epoch: 42
2022-11-28 05:16:42,081 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48786557906053285, 'Total loss': 0.48786557906053285} | train loss {'Reaction outcome loss': 0.4605864980391094, 'Total loss': 0.4605864980391094}
2022-11-28 05:16:42,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:42,081 INFO:     Epoch: 43
2022-11-28 05:16:42,738 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.487216153266755, 'Total loss': 0.487216153266755} | train loss {'Reaction outcome loss': 0.45768837874033014, 'Total loss': 0.45768837874033014}
2022-11-28 05:16:42,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:42,738 INFO:     Epoch: 44
2022-11-28 05:16:43,393 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4550162513147701, 'Total loss': 0.4550162513147701} | train loss {'Reaction outcome loss': 0.4638108680442888, 'Total loss': 0.4638108680442888}
2022-11-28 05:16:43,393 INFO:     Found new best model at epoch 44
2022-11-28 05:16:43,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:43,394 INFO:     Epoch: 45
2022-11-28 05:16:44,048 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4970052492889491, 'Total loss': 0.4970052492889491} | train loss {'Reaction outcome loss': 0.4541199154391581, 'Total loss': 0.4541199154391581}
2022-11-28 05:16:44,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:44,048 INFO:     Epoch: 46
2022-11-28 05:16:44,698 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4656391272490675, 'Total loss': 0.4656391272490675} | train loss {'Reaction outcome loss': 0.4591020373057346, 'Total loss': 0.4591020373057346}
2022-11-28 05:16:44,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:44,698 INFO:     Epoch: 47
2022-11-28 05:16:45,352 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43185584899038076, 'Total loss': 0.43185584899038076} | train loss {'Reaction outcome loss': 0.4567016973179214, 'Total loss': 0.4567016973179214}
2022-11-28 05:16:45,352 INFO:     Found new best model at epoch 47
2022-11-28 05:16:45,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:45,353 INFO:     Epoch: 48
2022-11-28 05:16:46,010 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4647230929271741, 'Total loss': 0.4647230929271741} | train loss {'Reaction outcome loss': 0.45882250502401467, 'Total loss': 0.45882250502401467}
2022-11-28 05:16:46,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:46,010 INFO:     Epoch: 49
2022-11-28 05:16:46,664 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4516693268987266, 'Total loss': 0.4516693268987266} | train loss {'Reaction outcome loss': 0.4617009305224127, 'Total loss': 0.4617009305224127}
2022-11-28 05:16:46,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:46,664 INFO:     Epoch: 50
2022-11-28 05:16:47,317 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4861091252162375, 'Total loss': 0.4861091252162375} | train loss {'Reaction outcome loss': 0.4571693962934066, 'Total loss': 0.4571693962934066}
2022-11-28 05:16:47,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:47,318 INFO:     Epoch: 51
2022-11-28 05:16:47,970 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47860751986842265, 'Total loss': 0.47860751986842265} | train loss {'Reaction outcome loss': 0.45493636538787763, 'Total loss': 0.45493636538787763}
2022-11-28 05:16:47,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:47,971 INFO:     Epoch: 52
2022-11-28 05:16:48,624 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4503454335711219, 'Total loss': 0.4503454335711219} | train loss {'Reaction outcome loss': 0.45895436533859796, 'Total loss': 0.45895436533859796}
2022-11-28 05:16:48,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:48,624 INFO:     Epoch: 53
2022-11-28 05:16:49,273 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48425371233712544, 'Total loss': 0.48425371233712544} | train loss {'Reaction outcome loss': 0.456393760686018, 'Total loss': 0.456393760686018}
2022-11-28 05:16:49,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:49,273 INFO:     Epoch: 54
2022-11-28 05:16:49,925 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48831798474897037, 'Total loss': 0.48831798474897037} | train loss {'Reaction outcome loss': 0.4549150063067066, 'Total loss': 0.4549150063067066}
2022-11-28 05:16:49,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:49,926 INFO:     Epoch: 55
2022-11-28 05:16:50,578 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5124072696674954, 'Total loss': 0.5124072696674954} | train loss {'Reaction outcome loss': 0.45531606330555313, 'Total loss': 0.45531606330555313}
2022-11-28 05:16:50,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:50,579 INFO:     Epoch: 56
2022-11-28 05:16:51,229 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46615184911272745, 'Total loss': 0.46615184911272745} | train loss {'Reaction outcome loss': 0.45477914664210106, 'Total loss': 0.45477914664210106}
2022-11-28 05:16:51,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:51,229 INFO:     Epoch: 57
2022-11-28 05:16:51,884 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4668264275586063, 'Total loss': 0.4668264275586063} | train loss {'Reaction outcome loss': 0.4503400941588441, 'Total loss': 0.4503400941588441}
2022-11-28 05:16:51,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:51,885 INFO:     Epoch: 58
2022-11-28 05:16:52,540 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4767858794128353, 'Total loss': 0.4767858794128353} | train loss {'Reaction outcome loss': 0.456406810575602, 'Total loss': 0.456406810575602}
2022-11-28 05:16:52,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:52,540 INFO:     Epoch: 59
2022-11-28 05:16:53,193 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5066134296357632, 'Total loss': 0.5066134296357632} | train loss {'Reaction outcome loss': 0.45599880169849005, 'Total loss': 0.45599880169849005}
2022-11-28 05:16:53,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:53,194 INFO:     Epoch: 60
2022-11-28 05:16:53,848 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4642506685446609, 'Total loss': 0.4642506685446609} | train loss {'Reaction outcome loss': 0.4554274158818381, 'Total loss': 0.4554274158818381}
2022-11-28 05:16:53,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:53,848 INFO:     Epoch: 61
2022-11-28 05:16:54,504 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.463757858696309, 'Total loss': 0.463757858696309} | train loss {'Reaction outcome loss': 0.4603032171118016, 'Total loss': 0.4603032171118016}
2022-11-28 05:16:54,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:54,504 INFO:     Epoch: 62
2022-11-28 05:16:55,157 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4939179498363625, 'Total loss': 0.4939179498363625} | train loss {'Reaction outcome loss': 0.45012228239555746, 'Total loss': 0.45012228239555746}
2022-11-28 05:16:55,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:55,157 INFO:     Epoch: 63
2022-11-28 05:16:55,813 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46100247075611894, 'Total loss': 0.46100247075611894} | train loss {'Reaction outcome loss': 0.4549917531256773, 'Total loss': 0.4549917531256773}
2022-11-28 05:16:55,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:55,813 INFO:     Epoch: 64
2022-11-28 05:16:56,469 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4771714373068376, 'Total loss': 0.4771714373068376} | train loss {'Reaction outcome loss': 0.45588394008120714, 'Total loss': 0.45588394008120714}
2022-11-28 05:16:56,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:56,469 INFO:     Epoch: 65
2022-11-28 05:16:57,125 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4819191260771318, 'Total loss': 0.4819191260771318} | train loss {'Reaction outcome loss': 0.45035645061609697, 'Total loss': 0.45035645061609697}
2022-11-28 05:16:57,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:57,125 INFO:     Epoch: 66
2022-11-28 05:16:57,781 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4920706268061291, 'Total loss': 0.4920706268061291} | train loss {'Reaction outcome loss': 0.4527959009822534, 'Total loss': 0.4527959009822534}
2022-11-28 05:16:57,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:57,782 INFO:     Epoch: 67
2022-11-28 05:16:58,439 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4886172671209682, 'Total loss': 0.4886172671209682} | train loss {'Reaction outcome loss': 0.4668074311650529, 'Total loss': 0.4668074311650529}
2022-11-28 05:16:58,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:58,439 INFO:     Epoch: 68
2022-11-28 05:16:59,094 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4825750992379405, 'Total loss': 0.4825750992379405} | train loss {'Reaction outcome loss': 0.4591236475170875, 'Total loss': 0.4591236475170875}
2022-11-28 05:16:59,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:59,095 INFO:     Epoch: 69
2022-11-28 05:16:59,752 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4764835082671859, 'Total loss': 0.4764835082671859} | train loss {'Reaction outcome loss': 0.4550936515233955, 'Total loss': 0.4550936515233955}
2022-11-28 05:16:59,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:16:59,753 INFO:     Epoch: 70
2022-11-28 05:17:00,407 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4782127734612335, 'Total loss': 0.4782127734612335} | train loss {'Reaction outcome loss': 0.46688422737072927, 'Total loss': 0.46688422737072927}
2022-11-28 05:17:00,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:00,408 INFO:     Epoch: 71
2022-11-28 05:17:01,066 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46240904249928216, 'Total loss': 0.46240904249928216} | train loss {'Reaction outcome loss': 0.45254958059106554, 'Total loss': 0.45254958059106554}
2022-11-28 05:17:01,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:01,066 INFO:     Epoch: 72
2022-11-28 05:17:01,722 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4701166579669172, 'Total loss': 0.4701166579669172} | train loss {'Reaction outcome loss': 0.45487346789058375, 'Total loss': 0.45487346789058375}
2022-11-28 05:17:01,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:01,722 INFO:     Epoch: 73
2022-11-28 05:17:02,381 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47961769930341025, 'Total loss': 0.47961769930341025} | train loss {'Reaction outcome loss': 0.4574831496087872, 'Total loss': 0.4574831496087872}
2022-11-28 05:17:02,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:02,381 INFO:     Epoch: 74
2022-11-28 05:17:03,036 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4742539951747114, 'Total loss': 0.4742539951747114} | train loss {'Reaction outcome loss': 0.4621089276610589, 'Total loss': 0.4621089276610589}
2022-11-28 05:17:03,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:03,037 INFO:     Epoch: 75
2022-11-28 05:17:03,689 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48028132353316655, 'Total loss': 0.48028132353316655} | train loss {'Reaction outcome loss': 0.4504091435245105, 'Total loss': 0.4504091435245105}
2022-11-28 05:17:03,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:03,689 INFO:     Epoch: 76
2022-11-28 05:17:04,343 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47256667319346557, 'Total loss': 0.47256667319346557} | train loss {'Reaction outcome loss': 0.44986579588481357, 'Total loss': 0.44986579588481357}
2022-11-28 05:17:04,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:04,344 INFO:     Epoch: 77
2022-11-28 05:17:05,000 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4732105803718282, 'Total loss': 0.4732105803718282} | train loss {'Reaction outcome loss': 0.4577563539147377, 'Total loss': 0.4577563539147377}
2022-11-28 05:17:05,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:05,000 INFO:     Epoch: 78
2022-11-28 05:17:05,655 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49573959003795276, 'Total loss': 0.49573959003795276} | train loss {'Reaction outcome loss': 0.4567169396548855, 'Total loss': 0.4567169396548855}
2022-11-28 05:17:05,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:05,656 INFO:     Epoch: 79
2022-11-28 05:17:06,312 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4485959590158679, 'Total loss': 0.4485959590158679} | train loss {'Reaction outcome loss': 0.4481666139802154, 'Total loss': 0.4481666139802154}
2022-11-28 05:17:06,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:06,313 INFO:     Epoch: 80
2022-11-28 05:17:06,972 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.469497697935863, 'Total loss': 0.469497697935863} | train loss {'Reaction outcome loss': 0.4529249038927409, 'Total loss': 0.4529249038927409}
2022-11-28 05:17:06,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:06,972 INFO:     Epoch: 81
2022-11-28 05:17:07,631 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4884624366055835, 'Total loss': 0.4884624366055835} | train loss {'Reaction outcome loss': 0.4521580606090779, 'Total loss': 0.4521580606090779}
2022-11-28 05:17:07,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:07,631 INFO:     Epoch: 82
2022-11-28 05:17:08,288 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.509795181453228, 'Total loss': 0.509795181453228} | train loss {'Reaction outcome loss': 0.4536003938438941, 'Total loss': 0.4536003938438941}
2022-11-28 05:17:08,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:08,288 INFO:     Epoch: 83
2022-11-28 05:17:08,944 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4958983338014646, 'Total loss': 0.4958983338014646} | train loss {'Reaction outcome loss': 0.45453466444599383, 'Total loss': 0.45453466444599383}
2022-11-28 05:17:08,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:08,945 INFO:     Epoch: 84
2022-11-28 05:17:09,596 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49964210628108546, 'Total loss': 0.49964210628108546} | train loss {'Reaction outcome loss': 0.4576979573892087, 'Total loss': 0.4576979573892087}
2022-11-28 05:17:09,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:09,596 INFO:     Epoch: 85
2022-11-28 05:17:10,250 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48739987679503183, 'Total loss': 0.48739987679503183} | train loss {'Reaction outcome loss': 0.45047017116935884, 'Total loss': 0.45047017116935884}
2022-11-28 05:17:10,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:10,250 INFO:     Epoch: 86
2022-11-28 05:17:10,908 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46697481179779227, 'Total loss': 0.46697481179779227} | train loss {'Reaction outcome loss': 0.4518270640957112, 'Total loss': 0.4518270640957112}
2022-11-28 05:17:10,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:10,908 INFO:     Epoch: 87
2022-11-28 05:17:11,568 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47429855879057536, 'Total loss': 0.47429855879057536} | train loss {'Reaction outcome loss': 0.4595964136780525, 'Total loss': 0.4595964136780525}
2022-11-28 05:17:11,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:11,568 INFO:     Epoch: 88
2022-11-28 05:17:12,227 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4761387441645969, 'Total loss': 0.4761387441645969} | train loss {'Reaction outcome loss': 0.45511825023865216, 'Total loss': 0.45511825023865216}
2022-11-28 05:17:12,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:12,228 INFO:     Epoch: 89
2022-11-28 05:17:12,885 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4551986818286506, 'Total loss': 0.4551986818286506} | train loss {'Reaction outcome loss': 0.4570602460783355, 'Total loss': 0.4570602460783355}
2022-11-28 05:17:12,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:12,885 INFO:     Epoch: 90
2022-11-28 05:17:13,540 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4492930895225568, 'Total loss': 0.4492930895225568} | train loss {'Reaction outcome loss': 0.4546823905438793, 'Total loss': 0.4546823905438793}
2022-11-28 05:17:13,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:13,540 INFO:     Epoch: 91
2022-11-28 05:17:14,194 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48516481098803604, 'Total loss': 0.48516481098803604} | train loss {'Reaction outcome loss': 0.4487069121733004, 'Total loss': 0.4487069121733004}
2022-11-28 05:17:14,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:14,194 INFO:     Epoch: 92
2022-11-28 05:17:14,850 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5261292444034056, 'Total loss': 0.5261292444034056} | train loss {'Reaction outcome loss': 0.446543095914685, 'Total loss': 0.446543095914685}
2022-11-28 05:17:14,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:14,851 INFO:     Epoch: 93
2022-11-28 05:17:15,510 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49629749289967795, 'Total loss': 0.49629749289967795} | train loss {'Reaction outcome loss': 0.45565094187551614, 'Total loss': 0.45565094187551614}
2022-11-28 05:17:15,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:15,510 INFO:     Epoch: 94
2022-11-28 05:17:16,172 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4719334491951899, 'Total loss': 0.4719334491951899} | train loss {'Reaction outcome loss': 0.4480626149445164, 'Total loss': 0.4480626149445164}
2022-11-28 05:17:16,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:16,172 INFO:     Epoch: 95
2022-11-28 05:17:16,830 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5338735041970556, 'Total loss': 0.5338735041970556} | train loss {'Reaction outcome loss': 0.4582387435801175, 'Total loss': 0.4582387435801175}
2022-11-28 05:17:16,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:16,830 INFO:     Epoch: 96
2022-11-28 05:17:17,483 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4683616544035348, 'Total loss': 0.4683616544035348} | train loss {'Reaction outcome loss': 0.45729579037549545, 'Total loss': 0.45729579037549545}
2022-11-28 05:17:17,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:17,483 INFO:     Epoch: 97
2022-11-28 05:17:18,138 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4709407047114589, 'Total loss': 0.4709407047114589} | train loss {'Reaction outcome loss': 0.4432442894395517, 'Total loss': 0.4432442894395517}
2022-11-28 05:17:18,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:18,139 INFO:     Epoch: 98
2022-11-28 05:17:18,796 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4799077043479139, 'Total loss': 0.4799077043479139} | train loss {'Reaction outcome loss': 0.45935356528783333, 'Total loss': 0.45935356528783333}
2022-11-28 05:17:18,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:18,796 INFO:     Epoch: 99
2022-11-28 05:17:19,455 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4774273478172042, 'Total loss': 0.4774273478172042} | train loss {'Reaction outcome loss': 0.45502635325704305, 'Total loss': 0.45502635325704305}
2022-11-28 05:17:19,455 INFO:     Best model found after epoch 48 of 100.
2022-11-28 05:17:19,455 INFO:   Done with stage: TRAINING
2022-11-28 05:17:19,455 INFO:   Starting stage: EVALUATION
2022-11-28 05:17:19,578 INFO:   Done with stage: EVALUATION
2022-11-28 05:17:19,586 INFO:   Leaving out SEQ value Fold_0
2022-11-28 05:17:19,599 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 05:17:19,599 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:17:20,237 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:17:20,237 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:17:20,308 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:17:20,308 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:17:20,308 INFO:     No hyperparam tuning for this model
2022-11-28 05:17:20,308 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:17:20,308 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:17:20,309 INFO:     None feature selector for col prot
2022-11-28 05:17:20,309 INFO:     None feature selector for col prot
2022-11-28 05:17:20,309 INFO:     None feature selector for col prot
2022-11-28 05:17:20,309 INFO:     None feature selector for col chem
2022-11-28 05:17:20,309 INFO:     None feature selector for col chem
2022-11-28 05:17:20,309 INFO:     None feature selector for col chem
2022-11-28 05:17:20,310 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:17:20,310 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:17:20,311 INFO:     Number of params in model 169651
2022-11-28 05:17:20,314 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:17:20,314 INFO:   Starting stage: TRAINING
2022-11-28 05:17:20,365 INFO:     Val loss before train {'Reaction outcome loss': 0.940924081612717, 'Total loss': 0.940924081612717}
2022-11-28 05:17:20,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:20,365 INFO:     Epoch: 0
2022-11-28 05:17:21,023 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5744359791278839, 'Total loss': 0.5744359791278839} | train loss {'Reaction outcome loss': 0.6791868372839325, 'Total loss': 0.6791868372839325}
2022-11-28 05:17:21,023 INFO:     Found new best model at epoch 0
2022-11-28 05:17:21,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:21,023 INFO:     Epoch: 1
2022-11-28 05:17:21,683 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6142749935388565, 'Total loss': 0.6142749935388565} | train loss {'Reaction outcome loss': 0.5718950618894733, 'Total loss': 0.5718950618894733}
2022-11-28 05:17:21,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:21,683 INFO:     Epoch: 2
2022-11-28 05:17:22,341 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5519630472091112, 'Total loss': 0.5519630472091112} | train loss {'Reaction outcome loss': 0.538496454881162, 'Total loss': 0.538496454881162}
2022-11-28 05:17:22,342 INFO:     Found new best model at epoch 2
2022-11-28 05:17:22,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:22,342 INFO:     Epoch: 3
2022-11-28 05:17:22,998 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5271041941913691, 'Total loss': 0.5271041941913691} | train loss {'Reaction outcome loss': 0.5255185369326144, 'Total loss': 0.5255185369326144}
2022-11-28 05:17:22,998 INFO:     Found new best model at epoch 3
2022-11-28 05:17:22,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:22,999 INFO:     Epoch: 4
2022-11-28 05:17:23,652 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5824815346436067, 'Total loss': 0.5824815346436067} | train loss {'Reaction outcome loss': 0.5138190937893731, 'Total loss': 0.5138190937893731}
2022-11-28 05:17:23,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:23,652 INFO:     Epoch: 5
2022-11-28 05:17:24,306 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5192389240996405, 'Total loss': 0.5192389240996405} | train loss {'Reaction outcome loss': 0.507407782515701, 'Total loss': 0.507407782515701}
2022-11-28 05:17:24,306 INFO:     Found new best model at epoch 5
2022-11-28 05:17:24,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:24,307 INFO:     Epoch: 6
2022-11-28 05:17:24,962 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5122244730591774, 'Total loss': 0.5122244730591774} | train loss {'Reaction outcome loss': 0.4963211706706456, 'Total loss': 0.4963211706706456}
2022-11-28 05:17:24,963 INFO:     Found new best model at epoch 6
2022-11-28 05:17:24,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:24,963 INFO:     Epoch: 7
2022-11-28 05:17:25,616 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5201389046216552, 'Total loss': 0.5201389046216552} | train loss {'Reaction outcome loss': 0.49317312100712135, 'Total loss': 0.49317312100712135}
2022-11-28 05:17:25,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:25,616 INFO:     Epoch: 8
2022-11-28 05:17:26,272 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5521489727226171, 'Total loss': 0.5521489727226171} | train loss {'Reaction outcome loss': 0.48701191629682267, 'Total loss': 0.48701191629682267}
2022-11-28 05:17:26,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:26,272 INFO:     Epoch: 9
2022-11-28 05:17:26,927 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5351764559745789, 'Total loss': 0.5351764559745789} | train loss {'Reaction outcome loss': 0.471219623392942, 'Total loss': 0.471219623392942}
2022-11-28 05:17:26,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:26,928 INFO:     Epoch: 10
2022-11-28 05:17:27,587 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5143473178825595, 'Total loss': 0.5143473178825595} | train loss {'Reaction outcome loss': 0.4774014907832048, 'Total loss': 0.4774014907832048}
2022-11-28 05:17:27,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:27,587 INFO:     Epoch: 11
2022-11-28 05:17:28,242 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5132530433210459, 'Total loss': 0.5132530433210459} | train loss {'Reaction outcome loss': 0.47362121690292747, 'Total loss': 0.47362121690292747}
2022-11-28 05:17:28,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:28,242 INFO:     Epoch: 12
2022-11-28 05:17:28,898 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5223485021428629, 'Total loss': 0.5223485021428629} | train loss {'Reaction outcome loss': 0.46966217610300803, 'Total loss': 0.46966217610300803}
2022-11-28 05:17:28,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:28,898 INFO:     Epoch: 13
2022-11-28 05:17:29,552 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5189563015645201, 'Total loss': 0.5189563015645201} | train loss {'Reaction outcome loss': 0.4747142115417792, 'Total loss': 0.4747142115417792}
2022-11-28 05:17:29,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:29,554 INFO:     Epoch: 14
2022-11-28 05:17:30,207 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4807823435826735, 'Total loss': 0.4807823435826735} | train loss {'Reaction outcome loss': 0.4710210607368119, 'Total loss': 0.4710210607368119}
2022-11-28 05:17:30,207 INFO:     Found new best model at epoch 14
2022-11-28 05:17:30,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:30,208 INFO:     Epoch: 15
2022-11-28 05:17:30,868 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5053128728812392, 'Total loss': 0.5053128728812392} | train loss {'Reaction outcome loss': 0.46672371042018035, 'Total loss': 0.46672371042018035}
2022-11-28 05:17:30,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:30,868 INFO:     Epoch: 16
2022-11-28 05:17:31,531 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4825440977107395, 'Total loss': 0.4825440977107395} | train loss {'Reaction outcome loss': 0.45957614949771336, 'Total loss': 0.45957614949771336}
2022-11-28 05:17:31,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:31,531 INFO:     Epoch: 17
2022-11-28 05:17:32,187 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49819107963280246, 'Total loss': 0.49819107963280246} | train loss {'Reaction outcome loss': 0.4596882885816146, 'Total loss': 0.4596882885816146}
2022-11-28 05:17:32,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:32,187 INFO:     Epoch: 18
2022-11-28 05:17:32,844 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5182591195810925, 'Total loss': 0.5182591195810925} | train loss {'Reaction outcome loss': 0.4626581580663214, 'Total loss': 0.4626581580663214}
2022-11-28 05:17:32,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:32,844 INFO:     Epoch: 19
2022-11-28 05:17:33,497 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4925536550581455, 'Total loss': 0.4925536550581455} | train loss {'Reaction outcome loss': 0.4601663085270901, 'Total loss': 0.4601663085270901}
2022-11-28 05:17:33,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:33,497 INFO:     Epoch: 20
2022-11-28 05:17:34,149 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5313434472138231, 'Total loss': 0.5313434472138231} | train loss {'Reaction outcome loss': 0.4581573195603429, 'Total loss': 0.4581573195603429}
2022-11-28 05:17:34,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:34,149 INFO:     Epoch: 21
2022-11-28 05:17:34,803 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48009082810445264, 'Total loss': 0.48009082810445264} | train loss {'Reaction outcome loss': 0.45588823988729593, 'Total loss': 0.45588823988729593}
2022-11-28 05:17:34,803 INFO:     Found new best model at epoch 21
2022-11-28 05:17:34,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:34,804 INFO:     Epoch: 22
2022-11-28 05:17:35,459 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5098546665500511, 'Total loss': 0.5098546665500511} | train loss {'Reaction outcome loss': 0.4590706724293378, 'Total loss': 0.4590706724293378}
2022-11-28 05:17:35,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:35,459 INFO:     Epoch: 23
2022-11-28 05:17:36,115 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4942040436647155, 'Total loss': 0.4942040436647155} | train loss {'Reaction outcome loss': 0.45465054530270244, 'Total loss': 0.45465054530270244}
2022-11-28 05:17:36,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:36,116 INFO:     Epoch: 24
2022-11-28 05:17:36,775 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5111569223756139, 'Total loss': 0.5111569223756139} | train loss {'Reaction outcome loss': 0.45695709172560245, 'Total loss': 0.45695709172560245}
2022-11-28 05:17:36,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:36,775 INFO:     Epoch: 25
2022-11-28 05:17:37,432 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5166551365771077, 'Total loss': 0.5166551365771077} | train loss {'Reaction outcome loss': 0.44563962583030975, 'Total loss': 0.44563962583030975}
2022-11-28 05:17:37,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:37,432 INFO:     Epoch: 26
2022-11-28 05:17:38,087 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5216470049186186, 'Total loss': 0.5216470049186186} | train loss {'Reaction outcome loss': 0.44738073862937033, 'Total loss': 0.44738073862937033}
2022-11-28 05:17:38,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:38,087 INFO:     Epoch: 27
2022-11-28 05:17:38,742 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5037219216200438, 'Total loss': 0.5037219216200438} | train loss {'Reaction outcome loss': 0.4468161661405953, 'Total loss': 0.4468161661405953}
2022-11-28 05:17:38,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:38,742 INFO:     Epoch: 28
2022-11-28 05:17:39,395 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4763637659224597, 'Total loss': 0.4763637659224597} | train loss {'Reaction outcome loss': 0.44779783073736695, 'Total loss': 0.44779783073736695}
2022-11-28 05:17:39,395 INFO:     Found new best model at epoch 28
2022-11-28 05:17:39,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:39,396 INFO:     Epoch: 29
2022-11-28 05:17:40,051 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4911063631827181, 'Total loss': 0.4911063631827181} | train loss {'Reaction outcome loss': 0.45700188516354073, 'Total loss': 0.45700188516354073}
2022-11-28 05:17:40,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:40,051 INFO:     Epoch: 30
2022-11-28 05:17:40,708 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4958256828514012, 'Total loss': 0.4958256828514012} | train loss {'Reaction outcome loss': 0.44550565833948097, 'Total loss': 0.44550565833948097}
2022-11-28 05:17:40,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:40,708 INFO:     Epoch: 31
2022-11-28 05:17:41,365 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5444017333740537, 'Total loss': 0.5444017333740537} | train loss {'Reaction outcome loss': 0.45249456562558, 'Total loss': 0.45249456562558}
2022-11-28 05:17:41,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:41,366 INFO:     Epoch: 32
2022-11-28 05:17:42,022 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5020531063730066, 'Total loss': 0.5020531063730066} | train loss {'Reaction outcome loss': 0.4479061927722425, 'Total loss': 0.4479061927722425}
2022-11-28 05:17:42,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:42,023 INFO:     Epoch: 33
2022-11-28 05:17:42,679 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4888519325759262, 'Total loss': 0.4888519325759262} | train loss {'Reaction outcome loss': 0.44950128626458496, 'Total loss': 0.44950128626458496}
2022-11-28 05:17:42,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:42,679 INFO:     Epoch: 34
2022-11-28 05:17:43,335 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5132490635256876, 'Total loss': 0.5132490635256876} | train loss {'Reaction outcome loss': 0.45251788089469985, 'Total loss': 0.45251788089469985}
2022-11-28 05:17:43,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:43,335 INFO:     Epoch: 35
2022-11-28 05:17:43,995 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48148525946519594, 'Total loss': 0.48148525946519594} | train loss {'Reaction outcome loss': 0.44759373810826514, 'Total loss': 0.44759373810826514}
2022-11-28 05:17:43,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:43,995 INFO:     Epoch: 36
2022-11-28 05:17:44,653 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4633928080174056, 'Total loss': 0.4633928080174056} | train loss {'Reaction outcome loss': 0.45409647150307286, 'Total loss': 0.45409647150307286}
2022-11-28 05:17:44,654 INFO:     Found new best model at epoch 36
2022-11-28 05:17:44,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:44,654 INFO:     Epoch: 37
2022-11-28 05:17:45,315 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45866044373674825, 'Total loss': 0.45866044373674825} | train loss {'Reaction outcome loss': 0.4571947322816265, 'Total loss': 0.4571947322816265}
2022-11-28 05:17:45,316 INFO:     Found new best model at epoch 37
2022-11-28 05:17:45,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:45,316 INFO:     Epoch: 38
2022-11-28 05:17:45,975 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5007828221741047, 'Total loss': 0.5007828221741047} | train loss {'Reaction outcome loss': 0.44460413401224175, 'Total loss': 0.44460413401224175}
2022-11-28 05:17:45,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:45,976 INFO:     Epoch: 39
2022-11-28 05:17:46,633 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.492068464783105, 'Total loss': 0.492068464783105} | train loss {'Reaction outcome loss': 0.45729268947426155, 'Total loss': 0.45729268947426155}
2022-11-28 05:17:46,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:46,634 INFO:     Epoch: 40
2022-11-28 05:17:47,289 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4918486743488095, 'Total loss': 0.4918486743488095} | train loss {'Reaction outcome loss': 0.44717475829684006, 'Total loss': 0.44717475829684006}
2022-11-28 05:17:47,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:47,290 INFO:     Epoch: 41
2022-11-28 05:17:47,944 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5329145003448833, 'Total loss': 0.5329145003448833} | train loss {'Reaction outcome loss': 0.45274069351809365, 'Total loss': 0.45274069351809365}
2022-11-28 05:17:47,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:47,944 INFO:     Epoch: 42
2022-11-28 05:17:48,602 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5167366452515125, 'Total loss': 0.5167366452515125} | train loss {'Reaction outcome loss': 0.4556852809628662, 'Total loss': 0.4556852809628662}
2022-11-28 05:17:48,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:48,603 INFO:     Epoch: 43
2022-11-28 05:17:49,259 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4917558668689294, 'Total loss': 0.4917558668689294} | train loss {'Reaction outcome loss': 0.4505743475592866, 'Total loss': 0.4505743475592866}
2022-11-28 05:17:49,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:49,259 INFO:     Epoch: 44
2022-11-28 05:17:49,914 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5224727768112313, 'Total loss': 0.5224727768112313} | train loss {'Reaction outcome loss': 0.44743874596089733, 'Total loss': 0.44743874596089733}
2022-11-28 05:17:49,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:49,915 INFO:     Epoch: 45
2022-11-28 05:17:50,573 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49460120837796817, 'Total loss': 0.49460120837796817} | train loss {'Reaction outcome loss': 0.45480385094272846, 'Total loss': 0.45480385094272846}
2022-11-28 05:17:50,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:50,573 INFO:     Epoch: 46
2022-11-28 05:17:51,231 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5170393538745967, 'Total loss': 0.5170393538745967} | train loss {'Reaction outcome loss': 0.454743529400047, 'Total loss': 0.454743529400047}
2022-11-28 05:17:51,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:51,231 INFO:     Epoch: 47
2022-11-28 05:17:51,893 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5072214705022898, 'Total loss': 0.5072214705022898} | train loss {'Reaction outcome loss': 0.4538754884685789, 'Total loss': 0.4538754884685789}
2022-11-28 05:17:51,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:51,893 INFO:     Epoch: 48
2022-11-28 05:17:52,554 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5100893158126961, 'Total loss': 0.5100893158126961} | train loss {'Reaction outcome loss': 0.46000145102033807, 'Total loss': 0.46000145102033807}
2022-11-28 05:17:52,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:52,555 INFO:     Epoch: 49
2022-11-28 05:17:53,212 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48998294601386244, 'Total loss': 0.48998294601386244} | train loss {'Reaction outcome loss': 0.4545431439365659, 'Total loss': 0.4545431439365659}
2022-11-28 05:17:53,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:53,212 INFO:     Epoch: 50
2022-11-28 05:17:53,869 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4753926115279848, 'Total loss': 0.4753926115279848} | train loss {'Reaction outcome loss': 0.4496531629440736, 'Total loss': 0.4496531629440736}
2022-11-28 05:17:53,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:53,869 INFO:     Epoch: 51
2022-11-28 05:17:54,526 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48468180373311043, 'Total loss': 0.48468180373311043} | train loss {'Reaction outcome loss': 0.4620392459387682, 'Total loss': 0.4620392459387682}
2022-11-28 05:17:54,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:54,526 INFO:     Epoch: 52
2022-11-28 05:17:55,181 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5545560758222233, 'Total loss': 0.5545560758222233} | train loss {'Reaction outcome loss': 0.44836723673708584, 'Total loss': 0.44836723673708584}
2022-11-28 05:17:55,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:55,181 INFO:     Epoch: 53
2022-11-28 05:17:55,835 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48768322271379555, 'Total loss': 0.48768322271379555} | train loss {'Reaction outcome loss': 0.4487231467451368, 'Total loss': 0.4487231467451368}
2022-11-28 05:17:55,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:55,835 INFO:     Epoch: 54
2022-11-28 05:17:56,492 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5030767301266844, 'Total loss': 0.5030767301266844} | train loss {'Reaction outcome loss': 0.45503759797738524, 'Total loss': 0.45503759797738524}
2022-11-28 05:17:56,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:56,492 INFO:     Epoch: 55
2022-11-28 05:17:57,149 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.516904054717584, 'Total loss': 0.516904054717584} | train loss {'Reaction outcome loss': 0.4544298682285815, 'Total loss': 0.4544298682285815}
2022-11-28 05:17:57,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:57,149 INFO:     Epoch: 56
2022-11-28 05:17:57,805 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4814882298762148, 'Total loss': 0.4814882298762148} | train loss {'Reaction outcome loss': 0.4565041621728819, 'Total loss': 0.4565041621728819}
2022-11-28 05:17:57,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:57,806 INFO:     Epoch: 57
2022-11-28 05:17:58,463 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4972104247320782, 'Total loss': 0.4972104247320782} | train loss {'Reaction outcome loss': 0.4550201853927301, 'Total loss': 0.4550201853927301}
2022-11-28 05:17:58,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:58,463 INFO:     Epoch: 58
2022-11-28 05:17:59,122 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5126828009432013, 'Total loss': 0.5126828009432013} | train loss {'Reaction outcome loss': 0.45101349736963, 'Total loss': 0.45101349736963}
2022-11-28 05:17:59,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:59,122 INFO:     Epoch: 59
2022-11-28 05:17:59,781 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4974270070141012, 'Total loss': 0.4974270070141012} | train loss {'Reaction outcome loss': 0.45290649060388, 'Total loss': 0.45290649060388}
2022-11-28 05:17:59,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:17:59,781 INFO:     Epoch: 60
2022-11-28 05:18:00,441 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5029676333069801, 'Total loss': 0.5029676333069801} | train loss {'Reaction outcome loss': 0.45942891510773676, 'Total loss': 0.45942891510773676}
2022-11-28 05:18:00,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:00,441 INFO:     Epoch: 61
2022-11-28 05:18:01,101 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.496563656763597, 'Total loss': 0.496563656763597} | train loss {'Reaction outcome loss': 0.45821389479904756, 'Total loss': 0.45821389479904756}
2022-11-28 05:18:01,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:01,103 INFO:     Epoch: 62
2022-11-28 05:18:01,764 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5079431730237874, 'Total loss': 0.5079431730237874} | train loss {'Reaction outcome loss': 0.4505863642205997, 'Total loss': 0.4505863642205997}
2022-11-28 05:18:01,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:01,764 INFO:     Epoch: 63
2022-11-28 05:18:02,425 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48348232020031323, 'Total loss': 0.48348232020031323} | train loss {'Reaction outcome loss': 0.45663873547193956, 'Total loss': 0.45663873547193956}
2022-11-28 05:18:02,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:02,426 INFO:     Epoch: 64
2022-11-28 05:18:03,083 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48021032017740334, 'Total loss': 0.48021032017740334} | train loss {'Reaction outcome loss': 0.46020961829594204, 'Total loss': 0.46020961829594204}
2022-11-28 05:18:03,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:03,083 INFO:     Epoch: 65
2022-11-28 05:18:03,743 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5045094686475667, 'Total loss': 0.5045094686475667} | train loss {'Reaction outcome loss': 0.45955542119181886, 'Total loss': 0.45955542119181886}
2022-11-28 05:18:03,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:03,744 INFO:     Epoch: 66
2022-11-28 05:18:04,401 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.503462780605663, 'Total loss': 0.503462780605663} | train loss {'Reaction outcome loss': 0.4562803997068989, 'Total loss': 0.4562803997068989}
2022-11-28 05:18:04,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:04,402 INFO:     Epoch: 67
2022-11-28 05:18:05,064 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5258873081342741, 'Total loss': 0.5258873081342741} | train loss {'Reaction outcome loss': 0.4513051265356492, 'Total loss': 0.4513051265356492}
2022-11-28 05:18:05,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:05,064 INFO:     Epoch: 68
2022-11-28 05:18:05,723 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49879254773259163, 'Total loss': 0.49879254773259163} | train loss {'Reaction outcome loss': 0.4579169054420627, 'Total loss': 0.4579169054420627}
2022-11-28 05:18:05,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:05,723 INFO:     Epoch: 69
2022-11-28 05:18:06,382 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4991978752342137, 'Total loss': 0.4991978752342137} | train loss {'Reaction outcome loss': 0.4529497534036636, 'Total loss': 0.4529497534036636}
2022-11-28 05:18:06,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:06,383 INFO:     Epoch: 70
2022-11-28 05:18:07,042 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4858836064284498, 'Total loss': 0.4858836064284498} | train loss {'Reaction outcome loss': 0.4640183255380514, 'Total loss': 0.4640183255380514}
2022-11-28 05:18:07,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:07,042 INFO:     Epoch: 71
2022-11-28 05:18:07,701 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5038420192219994, 'Total loss': 0.5038420192219994} | train loss {'Reaction outcome loss': 0.4608681974362354, 'Total loss': 0.4608681974362354}
2022-11-28 05:18:07,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:07,702 INFO:     Epoch: 72
2022-11-28 05:18:08,369 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4897687550295483, 'Total loss': 0.4897687550295483} | train loss {'Reaction outcome loss': 0.4476534789922286, 'Total loss': 0.4476534789922286}
2022-11-28 05:18:08,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:08,370 INFO:     Epoch: 73
2022-11-28 05:18:09,030 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.483154981481758, 'Total loss': 0.483154981481758} | train loss {'Reaction outcome loss': 0.4583521162368813, 'Total loss': 0.4583521162368813}
2022-11-28 05:18:09,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:09,030 INFO:     Epoch: 74
2022-11-28 05:18:09,693 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5204465473917398, 'Total loss': 0.5204465473917398} | train loss {'Reaction outcome loss': 0.4628354115145547, 'Total loss': 0.4628354115145547}
2022-11-28 05:18:09,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:09,694 INFO:     Epoch: 75
2022-11-28 05:18:10,355 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4871575784954158, 'Total loss': 0.4871575784954158} | train loss {'Reaction outcome loss': 0.4540051925547269, 'Total loss': 0.4540051925547269}
2022-11-28 05:18:10,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:10,355 INFO:     Epoch: 76
2022-11-28 05:18:11,012 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5289209329269149, 'Total loss': 0.5289209329269149} | train loss {'Reaction outcome loss': 0.45217844929013934, 'Total loss': 0.45217844929013934}
2022-11-28 05:18:11,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:11,012 INFO:     Epoch: 77
2022-11-28 05:18:11,670 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49284194240515883, 'Total loss': 0.49284194240515883} | train loss {'Reaction outcome loss': 0.4611977493276401, 'Total loss': 0.4611977493276401}
2022-11-28 05:18:11,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:11,670 INFO:     Epoch: 78
2022-11-28 05:18:12,329 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5133400230922482, 'Total loss': 0.5133400230922482} | train loss {'Reaction outcome loss': 0.4527250677955394, 'Total loss': 0.4527250677955394}
2022-11-28 05:18:12,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:12,329 INFO:     Epoch: 79
2022-11-28 05:18:12,993 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4789233773269437, 'Total loss': 0.4789233773269437} | train loss {'Reaction outcome loss': 0.4523942955294434, 'Total loss': 0.4523942955294434}
2022-11-28 05:18:12,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:12,993 INFO:     Epoch: 80
2022-11-28 05:18:13,651 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.562501771883531, 'Total loss': 0.562501771883531} | train loss {'Reaction outcome loss': 0.45105688346891987, 'Total loss': 0.45105688346891987}
2022-11-28 05:18:13,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:13,651 INFO:     Epoch: 81
2022-11-28 05:18:14,309 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5005754428831014, 'Total loss': 0.5005754428831014} | train loss {'Reaction outcome loss': 0.4601476436975051, 'Total loss': 0.4601476436975051}
2022-11-28 05:18:14,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:14,310 INFO:     Epoch: 82
2022-11-28 05:18:14,964 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5252350087870251, 'Total loss': 0.5252350087870251} | train loss {'Reaction outcome loss': 0.4548315678324018, 'Total loss': 0.4548315678324018}
2022-11-28 05:18:14,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:14,964 INFO:     Epoch: 83
2022-11-28 05:18:15,624 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49853089248592203, 'Total loss': 0.49853089248592203} | train loss {'Reaction outcome loss': 0.46045315107520746, 'Total loss': 0.46045315107520746}
2022-11-28 05:18:15,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:15,625 INFO:     Epoch: 84
2022-11-28 05:18:16,283 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5014658482237295, 'Total loss': 0.5014658482237295} | train loss {'Reaction outcome loss': 0.45059385454776335, 'Total loss': 0.45059385454776335}
2022-11-28 05:18:16,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:16,284 INFO:     Epoch: 85
2022-11-28 05:18:16,939 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48737567392262543, 'Total loss': 0.48737567392262543} | train loss {'Reaction outcome loss': 0.4521749064022181, 'Total loss': 0.4521749064022181}
2022-11-28 05:18:16,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:16,940 INFO:     Epoch: 86
2022-11-28 05:18:17,599 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4973829747600989, 'Total loss': 0.4973829747600989} | train loss {'Reaction outcome loss': 0.45364682266906814, 'Total loss': 0.45364682266906814}
2022-11-28 05:18:17,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:17,599 INFO:     Epoch: 87
2022-11-28 05:18:18,255 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48457377310842276, 'Total loss': 0.48457377310842276} | train loss {'Reaction outcome loss': 0.4561436294901128, 'Total loss': 0.4561436294901128}
2022-11-28 05:18:18,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:18,255 INFO:     Epoch: 88
2022-11-28 05:18:18,910 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5269045389511369, 'Total loss': 0.5269045389511369} | train loss {'Reaction outcome loss': 0.4617187733552894, 'Total loss': 0.4617187733552894}
2022-11-28 05:18:18,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:18,910 INFO:     Epoch: 89
2022-11-28 05:18:19,567 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49572630497542297, 'Total loss': 0.49572630497542297} | train loss {'Reaction outcome loss': 0.45759444388808035, 'Total loss': 0.45759444388808035}
2022-11-28 05:18:19,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:19,567 INFO:     Epoch: 90
2022-11-28 05:18:20,225 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48461207341064105, 'Total loss': 0.48461207341064105} | train loss {'Reaction outcome loss': 0.46148506336066186, 'Total loss': 0.46148506336066186}
2022-11-28 05:18:20,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:20,226 INFO:     Epoch: 91
2022-11-28 05:18:20,886 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4928568560968746, 'Total loss': 0.4928568560968746} | train loss {'Reaction outcome loss': 0.45050572698213615, 'Total loss': 0.45050572698213615}
2022-11-28 05:18:20,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:20,886 INFO:     Epoch: 92
2022-11-28 05:18:21,542 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4802956079894846, 'Total loss': 0.4802956079894846} | train loss {'Reaction outcome loss': 0.4627961760880996, 'Total loss': 0.4627961760880996}
2022-11-28 05:18:21,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:21,542 INFO:     Epoch: 93
2022-11-28 05:18:22,198 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4775393649258397, 'Total loss': 0.4775393649258397} | train loss {'Reaction outcome loss': 0.45335711009648383, 'Total loss': 0.45335711009648383}
2022-11-28 05:18:22,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:22,199 INFO:     Epoch: 94
2022-11-28 05:18:22,855 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4813432647761973, 'Total loss': 0.4813432647761973} | train loss {'Reaction outcome loss': 0.4541792446861462, 'Total loss': 0.4541792446861462}
2022-11-28 05:18:22,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:22,856 INFO:     Epoch: 95
2022-11-28 05:18:23,512 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5447845357385549, 'Total loss': 0.5447845357385549} | train loss {'Reaction outcome loss': 0.45149009568350656, 'Total loss': 0.45149009568350656}
2022-11-28 05:18:23,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:23,512 INFO:     Epoch: 96
2022-11-28 05:18:24,167 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5023876415057615, 'Total loss': 0.5023876415057615} | train loss {'Reaction outcome loss': 0.4580360429019344, 'Total loss': 0.4580360429019344}
2022-11-28 05:18:24,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:24,167 INFO:     Epoch: 97
2022-11-28 05:18:24,822 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49242445233870635, 'Total loss': 0.49242445233870635} | train loss {'Reaction outcome loss': 0.45113237098771697, 'Total loss': 0.45113237098771697}
2022-11-28 05:18:24,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:24,823 INFO:     Epoch: 98
2022-11-28 05:18:25,481 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46746913479133084, 'Total loss': 0.46746913479133084} | train loss {'Reaction outcome loss': 0.45853982379241864, 'Total loss': 0.45853982379241864}
2022-11-28 05:18:25,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:25,482 INFO:     Epoch: 99
2022-11-28 05:18:26,139 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5128540738739751, 'Total loss': 0.5128540738739751} | train loss {'Reaction outcome loss': 0.453453444218149, 'Total loss': 0.453453444218149}
2022-11-28 05:18:26,139 INFO:     Best model found after epoch 38 of 100.
2022-11-28 05:18:26,139 INFO:   Done with stage: TRAINING
2022-11-28 05:18:26,139 INFO:   Starting stage: EVALUATION
2022-11-28 05:18:26,262 INFO:   Done with stage: EVALUATION
2022-11-28 05:18:26,262 INFO:   Leaving out SEQ value Fold_1
2022-11-28 05:18:26,275 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 05:18:26,275 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:18:26,921 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:18:26,921 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:18:26,991 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:18:26,991 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:18:26,991 INFO:     No hyperparam tuning for this model
2022-11-28 05:18:26,991 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:18:26,991 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:18:26,991 INFO:     None feature selector for col prot
2022-11-28 05:18:26,992 INFO:     None feature selector for col prot
2022-11-28 05:18:26,992 INFO:     None feature selector for col prot
2022-11-28 05:18:26,992 INFO:     None feature selector for col chem
2022-11-28 05:18:26,992 INFO:     None feature selector for col chem
2022-11-28 05:18:26,992 INFO:     None feature selector for col chem
2022-11-28 05:18:26,992 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:18:26,993 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:18:26,994 INFO:     Number of params in model 169651
2022-11-28 05:18:26,997 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:18:26,997 INFO:   Starting stage: TRAINING
2022-11-28 05:18:27,047 INFO:     Val loss before train {'Reaction outcome loss': 0.9975852126424963, 'Total loss': 0.9975852126424963}
2022-11-28 05:18:27,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:27,047 INFO:     Epoch: 0
2022-11-28 05:18:27,706 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6096724691716108, 'Total loss': 0.6096724691716108} | train loss {'Reaction outcome loss': 0.6845487545316036, 'Total loss': 0.6845487545316036}
2022-11-28 05:18:27,706 INFO:     Found new best model at epoch 0
2022-11-28 05:18:27,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:27,707 INFO:     Epoch: 1
2022-11-28 05:18:28,365 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5394540364769372, 'Total loss': 0.5394540364769372} | train loss {'Reaction outcome loss': 0.5736848589349614, 'Total loss': 0.5736848589349614}
2022-11-28 05:18:28,366 INFO:     Found new best model at epoch 1
2022-11-28 05:18:28,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:28,366 INFO:     Epoch: 2
2022-11-28 05:18:29,030 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5122452398592775, 'Total loss': 0.5122452398592775} | train loss {'Reaction outcome loss': 0.5405131771496916, 'Total loss': 0.5405131771496916}
2022-11-28 05:18:29,030 INFO:     Found new best model at epoch 2
2022-11-28 05:18:29,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:29,031 INFO:     Epoch: 3
2022-11-28 05:18:29,695 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5382628877731886, 'Total loss': 0.5382628877731886} | train loss {'Reaction outcome loss': 0.5298847037891627, 'Total loss': 0.5298847037891627}
2022-11-28 05:18:29,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:29,695 INFO:     Epoch: 4
2022-11-28 05:18:30,358 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5039027228274129, 'Total loss': 0.5039027228274129} | train loss {'Reaction outcome loss': 0.5310389296969904, 'Total loss': 0.5310389296969904}
2022-11-28 05:18:30,358 INFO:     Found new best model at epoch 4
2022-11-28 05:18:30,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:30,359 INFO:     Epoch: 5
2022-11-28 05:18:31,024 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5765604634176601, 'Total loss': 0.5765604634176601} | train loss {'Reaction outcome loss': 0.511767484096863, 'Total loss': 0.511767484096863}
2022-11-28 05:18:31,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:31,024 INFO:     Epoch: 6
2022-11-28 05:18:31,685 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49764435670592566, 'Total loss': 0.49764435670592566} | train loss {'Reaction outcome loss': 0.5131089245440507, 'Total loss': 0.5131089245440507}
2022-11-28 05:18:31,686 INFO:     Found new best model at epoch 6
2022-11-28 05:18:31,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:31,686 INFO:     Epoch: 7
2022-11-28 05:18:32,348 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5298432071100582, 'Total loss': 0.5298432071100582} | train loss {'Reaction outcome loss': 0.5084993092395999, 'Total loss': 0.5084993092395999}
2022-11-28 05:18:32,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:32,349 INFO:     Epoch: 8
2022-11-28 05:18:33,007 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47366609932346776, 'Total loss': 0.47366609932346776} | train loss {'Reaction outcome loss': 0.5038838712611662, 'Total loss': 0.5038838712611662}
2022-11-28 05:18:33,007 INFO:     Found new best model at epoch 8
2022-11-28 05:18:33,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:33,008 INFO:     Epoch: 9
2022-11-28 05:18:33,670 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49071904068643396, 'Total loss': 0.49071904068643396} | train loss {'Reaction outcome loss': 0.48372046657751205, 'Total loss': 0.48372046657751205}
2022-11-28 05:18:33,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:33,670 INFO:     Epoch: 10
2022-11-28 05:18:34,333 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49375294284387067, 'Total loss': 0.49375294284387067} | train loss {'Reaction outcome loss': 0.49718392166772835, 'Total loss': 0.49718392166772835}
2022-11-28 05:18:34,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:34,333 INFO:     Epoch: 11
2022-11-28 05:18:34,993 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5299806520342827, 'Total loss': 0.5299806520342827} | train loss {'Reaction outcome loss': 0.4815880266519693, 'Total loss': 0.4815880266519693}
2022-11-28 05:18:34,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:34,994 INFO:     Epoch: 12
2022-11-28 05:18:35,656 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4791785671629689, 'Total loss': 0.4791785671629689} | train loss {'Reaction outcome loss': 0.48578859919961165, 'Total loss': 0.48578859919961165}
2022-11-28 05:18:35,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:35,656 INFO:     Epoch: 13
2022-11-28 05:18:36,316 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5119372856887904, 'Total loss': 0.5119372856887904} | train loss {'Reaction outcome loss': 0.4818570359123622, 'Total loss': 0.4818570359123622}
2022-11-28 05:18:36,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:36,316 INFO:     Epoch: 14
2022-11-28 05:18:36,982 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4759786647151817, 'Total loss': 0.4759786647151817} | train loss {'Reaction outcome loss': 0.4798274013677589, 'Total loss': 0.4798274013677589}
2022-11-28 05:18:36,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:36,982 INFO:     Epoch: 15
2022-11-28 05:18:37,643 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47940895638682623, 'Total loss': 0.47940895638682623} | train loss {'Reaction outcome loss': 0.48963268499384044, 'Total loss': 0.48963268499384044}
2022-11-28 05:18:37,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:37,644 INFO:     Epoch: 16
2022-11-28 05:18:38,304 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4932110360400243, 'Total loss': 0.4932110360400243} | train loss {'Reaction outcome loss': 0.489580417119781, 'Total loss': 0.489580417119781}
2022-11-28 05:18:38,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:38,305 INFO:     Epoch: 17
2022-11-28 05:18:38,964 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4914532872763547, 'Total loss': 0.4914532872763547} | train loss {'Reaction outcome loss': 0.4793645745361986, 'Total loss': 0.4793645745361986}
2022-11-28 05:18:38,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:38,964 INFO:     Epoch: 18
2022-11-28 05:18:39,627 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5201385593549772, 'Total loss': 0.5201385593549772} | train loss {'Reaction outcome loss': 0.481542874806323, 'Total loss': 0.481542874806323}
2022-11-28 05:18:39,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:39,627 INFO:     Epoch: 19
2022-11-28 05:18:40,289 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49051146683367813, 'Total loss': 0.49051146683367813} | train loss {'Reaction outcome loss': 0.4789833262080123, 'Total loss': 0.4789833262080123}
2022-11-28 05:18:40,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:40,289 INFO:     Epoch: 20
2022-11-28 05:18:40,955 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48410786307332193, 'Total loss': 0.48410786307332193} | train loss {'Reaction outcome loss': 0.4764392202331681, 'Total loss': 0.4764392202331681}
2022-11-28 05:18:40,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:40,955 INFO:     Epoch: 21
2022-11-28 05:18:41,619 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4486099376597188, 'Total loss': 0.4486099376597188} | train loss {'Reaction outcome loss': 0.4743072778469155, 'Total loss': 0.4743072778469155}
2022-11-28 05:18:41,619 INFO:     Found new best model at epoch 21
2022-11-28 05:18:41,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:41,620 INFO:     Epoch: 22
2022-11-28 05:18:42,281 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.483451860872182, 'Total loss': 0.483451860872182} | train loss {'Reaction outcome loss': 0.477637064360414, 'Total loss': 0.477637064360414}
2022-11-28 05:18:42,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:42,281 INFO:     Epoch: 23
2022-11-28 05:18:42,944 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4723013263534416, 'Total loss': 0.4723013263534416} | train loss {'Reaction outcome loss': 0.4923173387945905, 'Total loss': 0.4923173387945905}
2022-11-28 05:18:42,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:42,944 INFO:     Epoch: 24
2022-11-28 05:18:43,607 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5105082893913443, 'Total loss': 0.5105082893913443} | train loss {'Reaction outcome loss': 0.4830296473343845, 'Total loss': 0.4830296473343845}
2022-11-28 05:18:43,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:43,607 INFO:     Epoch: 25
2022-11-28 05:18:44,271 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4790372648699717, 'Total loss': 0.4790372648699717} | train loss {'Reaction outcome loss': 0.4923451563366029, 'Total loss': 0.4923451563366029}
2022-11-28 05:18:44,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:44,271 INFO:     Epoch: 26
2022-11-28 05:18:44,931 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4811852086674083, 'Total loss': 0.4811852086674083} | train loss {'Reaction outcome loss': 0.48058647605843147, 'Total loss': 0.48058647605843147}
2022-11-28 05:18:44,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:44,931 INFO:     Epoch: 27
2022-11-28 05:18:45,592 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5051920752633702, 'Total loss': 0.5051920752633702} | train loss {'Reaction outcome loss': 0.47690067011938403, 'Total loss': 0.47690067011938403}
2022-11-28 05:18:45,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:45,593 INFO:     Epoch: 28
2022-11-28 05:18:46,256 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4590497887270017, 'Total loss': 0.4590497887270017} | train loss {'Reaction outcome loss': 0.4746528943314364, 'Total loss': 0.4746528943314364}
2022-11-28 05:18:46,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:46,256 INFO:     Epoch: 29
2022-11-28 05:18:46,918 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5070675753734328, 'Total loss': 0.5070675753734328} | train loss {'Reaction outcome loss': 0.4707484474548927, 'Total loss': 0.4707484474548927}
2022-11-28 05:18:46,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:46,919 INFO:     Epoch: 30
2022-11-28 05:18:47,585 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4718668982386589, 'Total loss': 0.4718668982386589} | train loss {'Reaction outcome loss': 0.4758897456623282, 'Total loss': 0.4758897456623282}
2022-11-28 05:18:47,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:47,586 INFO:     Epoch: 31
2022-11-28 05:18:48,247 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47644907710227097, 'Total loss': 0.47644907710227097} | train loss {'Reaction outcome loss': 0.4795146799280576, 'Total loss': 0.4795146799280576}
2022-11-28 05:18:48,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:48,247 INFO:     Epoch: 32
2022-11-28 05:18:48,908 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4705334657972509, 'Total loss': 0.4705334657972509} | train loss {'Reaction outcome loss': 0.47318631989753196, 'Total loss': 0.47318631989753196}
2022-11-28 05:18:48,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:48,909 INFO:     Epoch: 33
2022-11-28 05:18:49,572 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5660857680169019, 'Total loss': 0.5660857680169019} | train loss {'Reaction outcome loss': 0.47087324475153136, 'Total loss': 0.47087324475153136}
2022-11-28 05:18:49,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:49,572 INFO:     Epoch: 34
2022-11-28 05:18:50,233 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4548908041959459, 'Total loss': 0.4548908041959459} | train loss {'Reaction outcome loss': 0.46726653574087357, 'Total loss': 0.46726653574087357}
2022-11-28 05:18:50,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:50,233 INFO:     Epoch: 35
2022-11-28 05:18:50,895 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5410970625552264, 'Total loss': 0.5410970625552264} | train loss {'Reaction outcome loss': 0.4833359390135236, 'Total loss': 0.4833359390135236}
2022-11-28 05:18:50,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:50,896 INFO:     Epoch: 36
2022-11-28 05:18:51,561 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4740047878162427, 'Total loss': 0.4740047878162427} | train loss {'Reaction outcome loss': 0.4986710801780948, 'Total loss': 0.4986710801780948}
2022-11-28 05:18:51,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:51,561 INFO:     Epoch: 37
2022-11-28 05:18:52,221 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4925533895465461, 'Total loss': 0.4925533895465461} | train loss {'Reaction outcome loss': 0.47844128591208324, 'Total loss': 0.47844128591208324}
2022-11-28 05:18:52,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:52,221 INFO:     Epoch: 38
2022-11-28 05:18:52,881 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4794670207933946, 'Total loss': 0.4794670207933946} | train loss {'Reaction outcome loss': 0.47366589995530933, 'Total loss': 0.47366589995530933}
2022-11-28 05:18:52,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:52,881 INFO:     Epoch: 39
2022-11-28 05:18:53,542 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4703481837429784, 'Total loss': 0.4703481837429784} | train loss {'Reaction outcome loss': 0.4763990188779136, 'Total loss': 0.4763990188779136}
2022-11-28 05:18:53,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:53,542 INFO:     Epoch: 40
2022-11-28 05:18:54,200 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4956493228673935, 'Total loss': 0.4956493228673935} | train loss {'Reaction outcome loss': 0.4752820403379226, 'Total loss': 0.4752820403379226}
2022-11-28 05:18:54,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:54,200 INFO:     Epoch: 41
2022-11-28 05:18:54,859 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.451579156585715, 'Total loss': 0.451579156585715} | train loss {'Reaction outcome loss': 0.4724449497847422, 'Total loss': 0.4724449497847422}
2022-11-28 05:18:54,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:54,859 INFO:     Epoch: 42
2022-11-28 05:18:55,520 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4926205477253957, 'Total loss': 0.4926205477253957} | train loss {'Reaction outcome loss': 0.47400271307360303, 'Total loss': 0.47400271307360303}
2022-11-28 05:18:55,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:55,521 INFO:     Epoch: 43
2022-11-28 05:18:56,182 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4827657667073337, 'Total loss': 0.4827657667073337} | train loss {'Reaction outcome loss': 0.46742782277254924, 'Total loss': 0.46742782277254924}
2022-11-28 05:18:56,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:56,183 INFO:     Epoch: 44
2022-11-28 05:18:56,845 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46278977461836557, 'Total loss': 0.46278977461836557} | train loss {'Reaction outcome loss': 0.46974733089537996, 'Total loss': 0.46974733089537996}
2022-11-28 05:18:56,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:56,846 INFO:     Epoch: 45
2022-11-28 05:18:57,509 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46250258081338624, 'Total loss': 0.46250258081338624} | train loss {'Reaction outcome loss': 0.46725226787903046, 'Total loss': 0.46725226787903046}
2022-11-28 05:18:57,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:57,509 INFO:     Epoch: 46
2022-11-28 05:18:58,171 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5185957043008371, 'Total loss': 0.5185957043008371} | train loss {'Reaction outcome loss': 0.47697798509588124, 'Total loss': 0.47697798509588124}
2022-11-28 05:18:58,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:58,171 INFO:     Epoch: 47
2022-11-28 05:18:58,836 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4441963464699008, 'Total loss': 0.4441963464699008} | train loss {'Reaction outcome loss': 0.4755405479597177, 'Total loss': 0.4755405479597177}
2022-11-28 05:18:58,836 INFO:     Found new best model at epoch 47
2022-11-28 05:18:58,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:58,837 INFO:     Epoch: 48
2022-11-28 05:18:59,497 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.487334206700325, 'Total loss': 0.487334206700325} | train loss {'Reaction outcome loss': 0.4665959237316842, 'Total loss': 0.4665959237316842}
2022-11-28 05:18:59,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:18:59,497 INFO:     Epoch: 49
2022-11-28 05:19:00,157 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5094367204741999, 'Total loss': 0.5094367204741999} | train loss {'Reaction outcome loss': 0.5062802468354886, 'Total loss': 0.5062802468354886}
2022-11-28 05:19:00,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:00,157 INFO:     Epoch: 50
2022-11-28 05:19:00,820 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48906774751164694, 'Total loss': 0.48906774751164694} | train loss {'Reaction outcome loss': 0.5031839767207018, 'Total loss': 0.5031839767207018}
2022-11-28 05:19:00,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:00,820 INFO:     Epoch: 51
2022-11-28 05:19:01,483 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46366788006641646, 'Total loss': 0.46366788006641646} | train loss {'Reaction outcome loss': 0.4661269736634605, 'Total loss': 0.4661269736634605}
2022-11-28 05:19:01,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:01,483 INFO:     Epoch: 52
2022-11-28 05:19:02,146 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48431476002389734, 'Total loss': 0.48431476002389734} | train loss {'Reaction outcome loss': 0.46784454216117316, 'Total loss': 0.46784454216117316}
2022-11-28 05:19:02,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:02,146 INFO:     Epoch: 53
2022-11-28 05:19:02,809 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4925336783582514, 'Total loss': 0.4925336783582514} | train loss {'Reaction outcome loss': 0.47293927071065556, 'Total loss': 0.47293927071065556}
2022-11-28 05:19:02,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:02,809 INFO:     Epoch: 54
2022-11-28 05:19:03,470 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.486274083906954, 'Total loss': 0.486274083906954} | train loss {'Reaction outcome loss': 0.46388820082190546, 'Total loss': 0.46388820082190546}
2022-11-28 05:19:03,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:03,471 INFO:     Epoch: 55
2022-11-28 05:19:04,135 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47653416341001337, 'Total loss': 0.47653416341001337} | train loss {'Reaction outcome loss': 0.4668474967180476, 'Total loss': 0.4668474967180476}
2022-11-28 05:19:04,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:04,135 INFO:     Epoch: 56
2022-11-28 05:19:04,796 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4946670156310905, 'Total loss': 0.4946670156310905} | train loss {'Reaction outcome loss': 0.4637991159490728, 'Total loss': 0.4637991159490728}
2022-11-28 05:19:04,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:04,796 INFO:     Epoch: 57
2022-11-28 05:19:05,455 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4678472863002257, 'Total loss': 0.4678472863002257} | train loss {'Reaction outcome loss': 0.46666685748196807, 'Total loss': 0.46666685748196807}
2022-11-28 05:19:05,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:05,456 INFO:     Epoch: 58
2022-11-28 05:19:06,116 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4730369624766437, 'Total loss': 0.4730369624766437} | train loss {'Reaction outcome loss': 0.4762134410229772, 'Total loss': 0.4762134410229772}
2022-11-28 05:19:06,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:06,116 INFO:     Epoch: 59
2022-11-28 05:19:06,775 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4837766479362141, 'Total loss': 0.4837766479362141} | train loss {'Reaction outcome loss': 0.4667734505028015, 'Total loss': 0.4667734505028015}
2022-11-28 05:19:06,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:06,775 INFO:     Epoch: 60
2022-11-28 05:19:07,430 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47505178505724127, 'Total loss': 0.47505178505724127} | train loss {'Reaction outcome loss': 0.4659390237921404, 'Total loss': 0.4659390237921404}
2022-11-28 05:19:07,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:07,430 INFO:     Epoch: 61
2022-11-28 05:19:08,091 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4526129239662127, 'Total loss': 0.4526129239662127} | train loss {'Reaction outcome loss': 0.4734082742620576, 'Total loss': 0.4734082742620576}
2022-11-28 05:19:08,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:08,091 INFO:     Epoch: 62
2022-11-28 05:19:08,750 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46186467666517605, 'Total loss': 0.46186467666517605} | train loss {'Reaction outcome loss': 0.48446460387967377, 'Total loss': 0.48446460387967377}
2022-11-28 05:19:08,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:08,751 INFO:     Epoch: 63
2022-11-28 05:19:09,410 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5012856427241456, 'Total loss': 0.5012856427241456} | train loss {'Reaction outcome loss': 0.46325200838357333, 'Total loss': 0.46325200838357333}
2022-11-28 05:19:09,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:09,410 INFO:     Epoch: 64
2022-11-28 05:19:10,070 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4628436023538763, 'Total loss': 0.4628436023538763} | train loss {'Reaction outcome loss': 0.47790643023817164, 'Total loss': 0.47790643023817164}
2022-11-28 05:19:10,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:10,071 INFO:     Epoch: 65
2022-11-28 05:19:10,733 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4498429386453195, 'Total loss': 0.4498429386453195} | train loss {'Reaction outcome loss': 0.478349276248984, 'Total loss': 0.478349276248984}
2022-11-28 05:19:10,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:10,734 INFO:     Epoch: 66
2022-11-28 05:19:11,395 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4404649433087219, 'Total loss': 0.4404649433087219} | train loss {'Reaction outcome loss': 0.469625925361028, 'Total loss': 0.469625925361028}
2022-11-28 05:19:11,395 INFO:     Found new best model at epoch 66
2022-11-28 05:19:11,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:11,396 INFO:     Epoch: 67
2022-11-28 05:19:12,054 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4529312649233775, 'Total loss': 0.4529312649233775} | train loss {'Reaction outcome loss': 0.4714987828482983, 'Total loss': 0.4714987828482983}
2022-11-28 05:19:12,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:12,054 INFO:     Epoch: 68
2022-11-28 05:19:12,716 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5242645191875371, 'Total loss': 0.5242645191875371} | train loss {'Reaction outcome loss': 0.46781658912115254, 'Total loss': 0.46781658912115254}
2022-11-28 05:19:12,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:12,717 INFO:     Epoch: 69
2022-11-28 05:19:13,375 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4624645466154272, 'Total loss': 0.4624645466154272} | train loss {'Reaction outcome loss': 0.4738941350687853, 'Total loss': 0.4738941350687853}
2022-11-28 05:19:13,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:13,376 INFO:     Epoch: 70
2022-11-28 05:19:14,039 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5495234141972932, 'Total loss': 0.5495234141972932} | train loss {'Reaction outcome loss': 0.46761552926514915, 'Total loss': 0.46761552926514915}
2022-11-28 05:19:14,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:14,039 INFO:     Epoch: 71
2022-11-28 05:19:14,704 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46469234184108, 'Total loss': 0.46469234184108} | train loss {'Reaction outcome loss': 0.467998474637925, 'Total loss': 0.467998474637925}
2022-11-28 05:19:14,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:14,704 INFO:     Epoch: 72
2022-11-28 05:19:15,367 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.6362056176770817, 'Total loss': 0.6362056176770817} | train loss {'Reaction outcome loss': 0.46685013241372125, 'Total loss': 0.46685013241372125}
2022-11-28 05:19:15,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:15,367 INFO:     Epoch: 73
2022-11-28 05:19:16,027 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47965876351703296, 'Total loss': 0.47965876351703296} | train loss {'Reaction outcome loss': 0.47429751877782317, 'Total loss': 0.47429751877782317}
2022-11-28 05:19:16,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:16,027 INFO:     Epoch: 74
2022-11-28 05:19:16,688 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4531101428649642, 'Total loss': 0.4531101428649642} | train loss {'Reaction outcome loss': 0.4719278189214135, 'Total loss': 0.4719278189214135}
2022-11-28 05:19:16,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:16,688 INFO:     Epoch: 75
2022-11-28 05:19:17,351 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46691581877795135, 'Total loss': 0.46691581877795135} | train loss {'Reaction outcome loss': 0.4569833315758087, 'Total loss': 0.4569833315758087}
2022-11-28 05:19:17,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:17,351 INFO:     Epoch: 76
2022-11-28 05:19:18,012 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46193350140344014, 'Total loss': 0.46193350140344014} | train loss {'Reaction outcome loss': 0.46740720965541327, 'Total loss': 0.46740720965541327}
2022-11-28 05:19:18,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:18,012 INFO:     Epoch: 77
2022-11-28 05:19:18,673 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5164893994277174, 'Total loss': 0.5164893994277174} | train loss {'Reaction outcome loss': 0.46532410636604554, 'Total loss': 0.46532410636604554}
2022-11-28 05:19:18,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:18,674 INFO:     Epoch: 78
2022-11-28 05:19:19,334 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.50229206986048, 'Total loss': 0.50229206986048} | train loss {'Reaction outcome loss': 0.4759473860686125, 'Total loss': 0.4759473860686125}
2022-11-28 05:19:19,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:19,334 INFO:     Epoch: 79
2022-11-28 05:19:19,994 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47158339026976714, 'Total loss': 0.47158339026976714} | train loss {'Reaction outcome loss': 0.47615314607964715, 'Total loss': 0.47615314607964715}
2022-11-28 05:19:19,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:19,994 INFO:     Epoch: 80
2022-11-28 05:19:20,653 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44275477731769736, 'Total loss': 0.44275477731769736} | train loss {'Reaction outcome loss': 0.46044573397092853, 'Total loss': 0.46044573397092853}
2022-11-28 05:19:20,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:20,653 INFO:     Epoch: 81
2022-11-28 05:19:21,312 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47394140742041846, 'Total loss': 0.47394140742041846} | train loss {'Reaction outcome loss': 0.4701151901993689, 'Total loss': 0.4701151901993689}
2022-11-28 05:19:21,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:21,312 INFO:     Epoch: 82
2022-11-28 05:19:21,973 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45793951505964453, 'Total loss': 0.45793951505964453} | train loss {'Reaction outcome loss': 0.45955602885016544, 'Total loss': 0.45955602885016544}
2022-11-28 05:19:21,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:21,973 INFO:     Epoch: 83
2022-11-28 05:19:22,636 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4886311102997173, 'Total loss': 0.4886311102997173} | train loss {'Reaction outcome loss': 0.4611068625862782, 'Total loss': 0.4611068625862782}
2022-11-28 05:19:22,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:22,637 INFO:     Epoch: 84
2022-11-28 05:19:23,301 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44807831079445104, 'Total loss': 0.44807831079445104} | train loss {'Reaction outcome loss': 0.48011783616021575, 'Total loss': 0.48011783616021575}
2022-11-28 05:19:23,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:23,301 INFO:     Epoch: 85
2022-11-28 05:19:23,961 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47297416695139627, 'Total loss': 0.47297416695139627} | train loss {'Reaction outcome loss': 0.4595479881881099, 'Total loss': 0.4595479881881099}
2022-11-28 05:19:23,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:23,961 INFO:     Epoch: 86
2022-11-28 05:19:24,621 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46688656881451607, 'Total loss': 0.46688656881451607} | train loss {'Reaction outcome loss': 0.4656414899688501, 'Total loss': 0.4656414899688501}
2022-11-28 05:19:24,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:24,622 INFO:     Epoch: 87
2022-11-28 05:19:25,278 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4569515216756951, 'Total loss': 0.4569515216756951} | train loss {'Reaction outcome loss': 0.47054479823180057, 'Total loss': 0.47054479823180057}
2022-11-28 05:19:25,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:25,278 INFO:     Epoch: 88
2022-11-28 05:19:25,939 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5015922612087294, 'Total loss': 0.5015922612087294} | train loss {'Reaction outcome loss': 0.47601119570645245, 'Total loss': 0.47601119570645245}
2022-11-28 05:19:25,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:25,939 INFO:     Epoch: 89
2022-11-28 05:19:26,600 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5239801467819647, 'Total loss': 0.5239801467819647} | train loss {'Reaction outcome loss': 0.477990371397572, 'Total loss': 0.477990371397572}
2022-11-28 05:19:26,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:26,601 INFO:     Epoch: 90
2022-11-28 05:19:27,257 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4786454706706784, 'Total loss': 0.4786454706706784} | train loss {'Reaction outcome loss': 0.4680294202044908, 'Total loss': 0.4680294202044908}
2022-11-28 05:19:27,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:27,257 INFO:     Epoch: 91
2022-11-28 05:19:27,916 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45804582265290344, 'Total loss': 0.45804582265290344} | train loss {'Reaction outcome loss': 0.46332989440031863, 'Total loss': 0.46332989440031863}
2022-11-28 05:19:27,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:27,917 INFO:     Epoch: 92
2022-11-28 05:19:28,579 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47799740155989473, 'Total loss': 0.47799740155989473} | train loss {'Reaction outcome loss': 0.46449665203388885, 'Total loss': 0.46449665203388885}
2022-11-28 05:19:28,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:28,580 INFO:     Epoch: 93
2022-11-28 05:19:29,236 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49746621975844557, 'Total loss': 0.49746621975844557} | train loss {'Reaction outcome loss': 0.46092455797953163, 'Total loss': 0.46092455797953163}
2022-11-28 05:19:29,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:29,236 INFO:     Epoch: 94
2022-11-28 05:19:29,895 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4596224325624379, 'Total loss': 0.4596224325624379} | train loss {'Reaction outcome loss': 0.4704615536790628, 'Total loss': 0.4704615536790628}
2022-11-28 05:19:29,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:29,895 INFO:     Epoch: 95
2022-11-28 05:19:30,555 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4839809943329204, 'Total loss': 0.4839809943329204} | train loss {'Reaction outcome loss': 0.4625513170532852, 'Total loss': 0.4625513170532852}
2022-11-28 05:19:30,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:30,556 INFO:     Epoch: 96
2022-11-28 05:19:31,213 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4545749185437506, 'Total loss': 0.4545749185437506} | train loss {'Reaction outcome loss': 0.4654468631424643, 'Total loss': 0.4654468631424643}
2022-11-28 05:19:31,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:31,214 INFO:     Epoch: 97
2022-11-28 05:19:31,869 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47010990807955916, 'Total loss': 0.47010990807955916} | train loss {'Reaction outcome loss': 0.4652212168644314, 'Total loss': 0.4652212168644314}
2022-11-28 05:19:31,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:31,870 INFO:     Epoch: 98
2022-11-28 05:19:32,529 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.500026285648346, 'Total loss': 0.500026285648346} | train loss {'Reaction outcome loss': 0.47184766388615135, 'Total loss': 0.47184766388615135}
2022-11-28 05:19:32,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:32,529 INFO:     Epoch: 99
2022-11-28 05:19:33,190 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4709533056752248, 'Total loss': 0.4709533056752248} | train loss {'Reaction outcome loss': 0.461407907518298, 'Total loss': 0.461407907518298}
2022-11-28 05:19:33,191 INFO:     Best model found after epoch 67 of 100.
2022-11-28 05:19:33,191 INFO:   Done with stage: TRAINING
2022-11-28 05:19:33,191 INFO:   Starting stage: EVALUATION
2022-11-28 05:19:33,308 INFO:   Done with stage: EVALUATION
2022-11-28 05:19:33,308 INFO:   Leaving out SEQ value Fold_2
2022-11-28 05:19:33,321 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 05:19:33,321 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:19:33,961 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:19:33,962 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:19:34,033 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:19:34,033 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:19:34,033 INFO:     No hyperparam tuning for this model
2022-11-28 05:19:34,033 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:19:34,033 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:19:34,034 INFO:     None feature selector for col prot
2022-11-28 05:19:34,034 INFO:     None feature selector for col prot
2022-11-28 05:19:34,034 INFO:     None feature selector for col prot
2022-11-28 05:19:34,035 INFO:     None feature selector for col chem
2022-11-28 05:19:34,035 INFO:     None feature selector for col chem
2022-11-28 05:19:34,035 INFO:     None feature selector for col chem
2022-11-28 05:19:34,035 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:19:34,035 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:19:34,037 INFO:     Number of params in model 169651
2022-11-28 05:19:34,040 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:19:34,040 INFO:   Starting stage: TRAINING
2022-11-28 05:19:34,091 INFO:     Val loss before train {'Reaction outcome loss': 0.9986447583545338, 'Total loss': 0.9986447583545338}
2022-11-28 05:19:34,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:34,091 INFO:     Epoch: 0
2022-11-28 05:19:34,750 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5766009891575034, 'Total loss': 0.5766009891575034} | train loss {'Reaction outcome loss': 0.692381000640441, 'Total loss': 0.692381000640441}
2022-11-28 05:19:34,750 INFO:     Found new best model at epoch 0
2022-11-28 05:19:34,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:34,751 INFO:     Epoch: 1
2022-11-28 05:19:35,407 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5873205228285356, 'Total loss': 0.5873205228285356} | train loss {'Reaction outcome loss': 0.5780193344670899, 'Total loss': 0.5780193344670899}
2022-11-28 05:19:35,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:35,408 INFO:     Epoch: 2
2022-11-28 05:19:36,063 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5224619406190786, 'Total loss': 0.5224619406190786} | train loss {'Reaction outcome loss': 0.5478909825792118, 'Total loss': 0.5478909825792118}
2022-11-28 05:19:36,063 INFO:     Found new best model at epoch 2
2022-11-28 05:19:36,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:36,064 INFO:     Epoch: 3
2022-11-28 05:19:36,719 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5297708352181044, 'Total loss': 0.5297708352181044} | train loss {'Reaction outcome loss': 0.5273422563562588, 'Total loss': 0.5273422563562588}
2022-11-28 05:19:36,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:36,720 INFO:     Epoch: 4
2022-11-28 05:19:37,378 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.536317780952562, 'Total loss': 0.536317780952562} | train loss {'Reaction outcome loss': 0.5211496290503715, 'Total loss': 0.5211496290503715}
2022-11-28 05:19:37,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:37,379 INFO:     Epoch: 5
2022-11-28 05:19:38,036 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49445237625728955, 'Total loss': 0.49445237625728955} | train loss {'Reaction outcome loss': 0.5197793314651568, 'Total loss': 0.5197793314651568}
2022-11-28 05:19:38,036 INFO:     Found new best model at epoch 5
2022-11-28 05:19:38,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:38,037 INFO:     Epoch: 6
2022-11-28 05:19:38,691 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47446956870738755, 'Total loss': 0.47446956870738755} | train loss {'Reaction outcome loss': 0.501027072753225, 'Total loss': 0.501027072753225}
2022-11-28 05:19:38,691 INFO:     Found new best model at epoch 6
2022-11-28 05:19:38,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:38,692 INFO:     Epoch: 7
2022-11-28 05:19:39,346 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4767573902552778, 'Total loss': 0.4767573902552778} | train loss {'Reaction outcome loss': 0.4892548036210391, 'Total loss': 0.4892548036210391}
2022-11-28 05:19:39,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:39,346 INFO:     Epoch: 8
2022-11-28 05:19:39,999 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46349915726618335, 'Total loss': 0.46349915726618335} | train loss {'Reaction outcome loss': 0.4985976554909531, 'Total loss': 0.4985976554909531}
2022-11-28 05:19:40,000 INFO:     Found new best model at epoch 8
2022-11-28 05:19:40,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:40,001 INFO:     Epoch: 9
2022-11-28 05:19:40,654 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46260792084715585, 'Total loss': 0.46260792084715585} | train loss {'Reaction outcome loss': 0.4897645559846138, 'Total loss': 0.4897645559846138}
2022-11-28 05:19:40,654 INFO:     Found new best model at epoch 9
2022-11-28 05:19:40,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:40,655 INFO:     Epoch: 10
2022-11-28 05:19:41,309 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44120080972259695, 'Total loss': 0.44120080972259695} | train loss {'Reaction outcome loss': 0.48870342185302657, 'Total loss': 0.48870342185302657}
2022-11-28 05:19:41,309 INFO:     Found new best model at epoch 10
2022-11-28 05:19:41,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:41,310 INFO:     Epoch: 11
2022-11-28 05:19:41,964 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47219621525569394, 'Total loss': 0.47219621525569394} | train loss {'Reaction outcome loss': 0.4842690311524333, 'Total loss': 0.4842690311524333}
2022-11-28 05:19:41,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:41,965 INFO:     Epoch: 12
2022-11-28 05:19:42,618 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46701423078775406, 'Total loss': 0.46701423078775406} | train loss {'Reaction outcome loss': 0.48891600613691366, 'Total loss': 0.48891600613691366}
2022-11-28 05:19:42,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:42,618 INFO:     Epoch: 13
2022-11-28 05:19:43,268 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48242812493646686, 'Total loss': 0.48242812493646686} | train loss {'Reaction outcome loss': 0.48287520578929355, 'Total loss': 0.48287520578929355}
2022-11-28 05:19:43,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:43,268 INFO:     Epoch: 14
2022-11-28 05:19:43,922 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4409350339661945, 'Total loss': 0.4409350339661945} | train loss {'Reaction outcome loss': 0.4800198270350086, 'Total loss': 0.4800198270350086}
2022-11-28 05:19:43,922 INFO:     Found new best model at epoch 14
2022-11-28 05:19:43,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:43,923 INFO:     Epoch: 15
2022-11-28 05:19:44,580 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5200380469587716, 'Total loss': 0.5200380469587716} | train loss {'Reaction outcome loss': 0.48257889781071217, 'Total loss': 0.48257889781071217}
2022-11-28 05:19:44,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:44,580 INFO:     Epoch: 16
2022-11-28 05:19:45,235 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49438546801155264, 'Total loss': 0.49438546801155264} | train loss {'Reaction outcome loss': 0.48276161630542913, 'Total loss': 0.48276161630542913}
2022-11-28 05:19:45,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:45,235 INFO:     Epoch: 17
2022-11-28 05:19:45,890 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4797500104389407, 'Total loss': 0.4797500104389407} | train loss {'Reaction outcome loss': 0.47943625048715244, 'Total loss': 0.47943625048715244}
2022-11-28 05:19:45,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:45,890 INFO:     Epoch: 18
2022-11-28 05:19:46,544 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46175509555773303, 'Total loss': 0.46175509555773303} | train loss {'Reaction outcome loss': 0.47609895942162495, 'Total loss': 0.47609895942162495}
2022-11-28 05:19:46,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:46,544 INFO:     Epoch: 19
2022-11-28 05:19:47,197 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44117061218077486, 'Total loss': 0.44117061218077486} | train loss {'Reaction outcome loss': 0.4780018823487418, 'Total loss': 0.4780018823487418}
2022-11-28 05:19:47,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:47,197 INFO:     Epoch: 20
2022-11-28 05:19:47,850 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49196781421249564, 'Total loss': 0.49196781421249564} | train loss {'Reaction outcome loss': 0.47003237526027525, 'Total loss': 0.47003237526027525}
2022-11-28 05:19:47,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:47,851 INFO:     Epoch: 21
2022-11-28 05:19:48,504 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4809021164070476, 'Total loss': 0.4809021164070476} | train loss {'Reaction outcome loss': 0.470692690233795, 'Total loss': 0.470692690233795}
2022-11-28 05:19:48,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:48,504 INFO:     Epoch: 22
2022-11-28 05:19:49,157 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4163826595653187, 'Total loss': 0.4163826595653187} | train loss {'Reaction outcome loss': 0.4776171735354832, 'Total loss': 0.4776171735354832}
2022-11-28 05:19:49,158 INFO:     Found new best model at epoch 22
2022-11-28 05:19:49,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:49,158 INFO:     Epoch: 23
2022-11-28 05:19:49,812 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4812238839539615, 'Total loss': 0.4812238839539615} | train loss {'Reaction outcome loss': 0.47324279364274474, 'Total loss': 0.47324279364274474}
2022-11-28 05:19:49,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:49,813 INFO:     Epoch: 24
2022-11-28 05:19:50,467 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44268024137074297, 'Total loss': 0.44268024137074297} | train loss {'Reaction outcome loss': 0.47787476510417704, 'Total loss': 0.47787476510417704}
2022-11-28 05:19:50,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:50,468 INFO:     Epoch: 25
2022-11-28 05:19:51,121 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4634550220587037, 'Total loss': 0.4634550220587037} | train loss {'Reaction outcome loss': 0.474184828692553, 'Total loss': 0.474184828692553}
2022-11-28 05:19:51,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:51,121 INFO:     Epoch: 26
2022-11-28 05:19:51,778 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45095306770368054, 'Total loss': 0.45095306770368054} | train loss {'Reaction outcome loss': 0.4754586551262408, 'Total loss': 0.4754586551262408}
2022-11-28 05:19:51,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:51,778 INFO:     Epoch: 27
2022-11-28 05:19:52,431 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4311268021437255, 'Total loss': 0.4311268021437255} | train loss {'Reaction outcome loss': 0.47410868892864305, 'Total loss': 0.47410868892864305}
2022-11-28 05:19:52,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:52,432 INFO:     Epoch: 28
2022-11-28 05:19:53,085 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4958244115114212, 'Total loss': 0.4958244115114212} | train loss {'Reaction outcome loss': 0.47452557962767933, 'Total loss': 0.47452557962767933}
2022-11-28 05:19:53,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:53,085 INFO:     Epoch: 29
2022-11-28 05:19:53,743 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4491036500443112, 'Total loss': 0.4491036500443112} | train loss {'Reaction outcome loss': 0.4742391987722747, 'Total loss': 0.4742391987722747}
2022-11-28 05:19:53,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:53,743 INFO:     Epoch: 30
2022-11-28 05:19:54,400 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4433681954714385, 'Total loss': 0.4433681954714385} | train loss {'Reaction outcome loss': 0.4686851256355947, 'Total loss': 0.4686851256355947}
2022-11-28 05:19:54,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:54,400 INFO:     Epoch: 31
2022-11-28 05:19:55,057 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44362541169605474, 'Total loss': 0.44362541169605474} | train loss {'Reaction outcome loss': 0.46909453342763746, 'Total loss': 0.46909453342763746}
2022-11-28 05:19:55,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:55,057 INFO:     Epoch: 32
2022-11-28 05:19:55,714 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4588776643980633, 'Total loss': 0.4588776643980633} | train loss {'Reaction outcome loss': 0.4739901431969234, 'Total loss': 0.4739901431969234}
2022-11-28 05:19:55,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:55,714 INFO:     Epoch: 33
2022-11-28 05:19:56,369 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42588927486742084, 'Total loss': 0.42588927486742084} | train loss {'Reaction outcome loss': 0.47004062819237613, 'Total loss': 0.47004062819237613}
2022-11-28 05:19:56,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:56,370 INFO:     Epoch: 34
2022-11-28 05:19:57,026 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48380356620658527, 'Total loss': 0.48380356620658527} | train loss {'Reaction outcome loss': 0.4666793591513926, 'Total loss': 0.4666793591513926}
2022-11-28 05:19:57,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:57,026 INFO:     Epoch: 35
2022-11-28 05:19:57,684 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4492642100561749, 'Total loss': 0.4492642100561749} | train loss {'Reaction outcome loss': 0.4769089047397886, 'Total loss': 0.4769089047397886}
2022-11-28 05:19:57,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:57,684 INFO:     Epoch: 36
2022-11-28 05:19:58,342 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4851179378615184, 'Total loss': 0.4851179378615184} | train loss {'Reaction outcome loss': 0.4663228100051685, 'Total loss': 0.4663228100051685}
2022-11-28 05:19:58,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:58,342 INFO:     Epoch: 37
2022-11-28 05:19:59,002 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4541686468503692, 'Total loss': 0.4541686468503692} | train loss {'Reaction outcome loss': 0.4756875794761035, 'Total loss': 0.4756875794761035}
2022-11-28 05:19:59,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:59,002 INFO:     Epoch: 38
2022-11-28 05:19:59,660 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4840239394794811, 'Total loss': 0.4840239394794811} | train loss {'Reaction outcome loss': 0.4692630399246605, 'Total loss': 0.4692630399246605}
2022-11-28 05:19:59,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:19:59,661 INFO:     Epoch: 39
2022-11-28 05:20:00,315 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46850322694941, 'Total loss': 0.46850322694941} | train loss {'Reaction outcome loss': 0.46539161229620174, 'Total loss': 0.46539161229620174}
2022-11-28 05:20:00,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:00,316 INFO:     Epoch: 40
2022-11-28 05:20:00,973 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46835469894788484, 'Total loss': 0.46835469894788484} | train loss {'Reaction outcome loss': 0.4655449297355146, 'Total loss': 0.4655449297355146}
2022-11-28 05:20:00,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:00,973 INFO:     Epoch: 41
2022-11-28 05:20:01,629 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46836211159825325, 'Total loss': 0.46836211159825325} | train loss {'Reaction outcome loss': 0.4724871565492786, 'Total loss': 0.4724871565492786}
2022-11-28 05:20:01,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:01,629 INFO:     Epoch: 42
2022-11-28 05:20:02,286 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44456253573298454, 'Total loss': 0.44456253573298454} | train loss {'Reaction outcome loss': 0.468621139684502, 'Total loss': 0.468621139684502}
2022-11-28 05:20:02,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:02,286 INFO:     Epoch: 43
2022-11-28 05:20:02,943 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4294885995967144, 'Total loss': 0.4294885995967144} | train loss {'Reaction outcome loss': 0.47256826612414143, 'Total loss': 0.47256826612414143}
2022-11-28 05:20:02,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:02,943 INFO:     Epoch: 44
2022-11-28 05:20:03,599 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44093144380233507, 'Total loss': 0.44093144380233507} | train loss {'Reaction outcome loss': 0.4680673372076482, 'Total loss': 0.4680673372076482}
2022-11-28 05:20:03,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:03,600 INFO:     Epoch: 45
2022-11-28 05:20:04,255 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4565600315955552, 'Total loss': 0.4565600315955552} | train loss {'Reaction outcome loss': 0.4680602771287062, 'Total loss': 0.4680602771287062}
2022-11-28 05:20:04,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:04,256 INFO:     Epoch: 46
2022-11-28 05:20:04,913 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45283054797486827, 'Total loss': 0.45283054797486827} | train loss {'Reaction outcome loss': 0.4664447618990528, 'Total loss': 0.4664447618990528}
2022-11-28 05:20:04,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:04,914 INFO:     Epoch: 47
2022-11-28 05:20:05,569 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43879134580492973, 'Total loss': 0.43879134580492973} | train loss {'Reaction outcome loss': 0.4706500578291562, 'Total loss': 0.4706500578291562}
2022-11-28 05:20:05,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:05,569 INFO:     Epoch: 48
2022-11-28 05:20:06,226 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4640952267430045, 'Total loss': 0.4640952267430045} | train loss {'Reaction outcome loss': 0.46910525900976996, 'Total loss': 0.46910525900976996}
2022-11-28 05:20:06,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:06,226 INFO:     Epoch: 49
2022-11-28 05:20:06,881 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4317644956437024, 'Total loss': 0.4317644956437024} | train loss {'Reaction outcome loss': 0.4762212170630085, 'Total loss': 0.4762212170630085}
2022-11-28 05:20:06,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:06,881 INFO:     Epoch: 50
2022-11-28 05:20:07,537 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4706711376255209, 'Total loss': 0.4706711376255209} | train loss {'Reaction outcome loss': 0.4665588405059308, 'Total loss': 0.4665588405059308}
2022-11-28 05:20:07,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:07,537 INFO:     Epoch: 51
2022-11-28 05:20:08,194 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46614447032863443, 'Total loss': 0.46614447032863443} | train loss {'Reaction outcome loss': 0.46613325093473706, 'Total loss': 0.46613325093473706}
2022-11-28 05:20:08,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:08,194 INFO:     Epoch: 52
2022-11-28 05:20:08,850 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4339266365224665, 'Total loss': 0.4339266365224665} | train loss {'Reaction outcome loss': 0.4661950343117422, 'Total loss': 0.4661950343117422}
2022-11-28 05:20:08,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:08,850 INFO:     Epoch: 53
2022-11-28 05:20:09,512 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43900543823838234, 'Total loss': 0.43900543823838234} | train loss {'Reaction outcome loss': 0.4675061599332459, 'Total loss': 0.4675061599332459}
2022-11-28 05:20:09,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:09,513 INFO:     Epoch: 54
2022-11-28 05:20:10,174 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4322130720723759, 'Total loss': 0.4322130720723759} | train loss {'Reaction outcome loss': 0.46766094607966285, 'Total loss': 0.46766094607966285}
2022-11-28 05:20:10,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:10,174 INFO:     Epoch: 55
2022-11-28 05:20:10,828 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4381530854681676, 'Total loss': 0.4381530854681676} | train loss {'Reaction outcome loss': 0.47295589860604736, 'Total loss': 0.47295589860604736}
2022-11-28 05:20:10,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:10,828 INFO:     Epoch: 56
2022-11-28 05:20:11,484 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4399329708381133, 'Total loss': 0.4399329708381133} | train loss {'Reaction outcome loss': 0.47604499976245723, 'Total loss': 0.47604499976245723}
2022-11-28 05:20:11,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:11,485 INFO:     Epoch: 57
2022-11-28 05:20:12,141 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4285470789129084, 'Total loss': 0.4285470789129084} | train loss {'Reaction outcome loss': 0.4753765437675982, 'Total loss': 0.4753765437675982}
2022-11-28 05:20:12,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:12,141 INFO:     Epoch: 58
2022-11-28 05:20:12,799 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45025860450484534, 'Total loss': 0.45025860450484534} | train loss {'Reaction outcome loss': 0.4716104267203078, 'Total loss': 0.4716104267203078}
2022-11-28 05:20:12,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:12,800 INFO:     Epoch: 59
2022-11-28 05:20:13,456 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4583121778612787, 'Total loss': 0.4583121778612787} | train loss {'Reaction outcome loss': 0.47442029994361257, 'Total loss': 0.47442029994361257}
2022-11-28 05:20:13,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:13,456 INFO:     Epoch: 60
2022-11-28 05:20:14,113 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42391095750711183, 'Total loss': 0.42391095750711183} | train loss {'Reaction outcome loss': 0.47411431274851973, 'Total loss': 0.47411431274851973}
2022-11-28 05:20:14,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:14,113 INFO:     Epoch: 61
2022-11-28 05:20:14,770 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4519073580476371, 'Total loss': 0.4519073580476371} | train loss {'Reaction outcome loss': 0.4673292478128355, 'Total loss': 0.4673292478128355}
2022-11-28 05:20:14,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:14,771 INFO:     Epoch: 62
2022-11-28 05:20:15,432 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4351706657220017, 'Total loss': 0.4351706657220017} | train loss {'Reaction outcome loss': 0.4775655820053451, 'Total loss': 0.4775655820053451}
2022-11-28 05:20:15,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:15,432 INFO:     Epoch: 63
2022-11-28 05:20:16,087 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4455807747488672, 'Total loss': 0.4455807747488672} | train loss {'Reaction outcome loss': 0.47411869113542593, 'Total loss': 0.47411869113542593}
2022-11-28 05:20:16,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:16,088 INFO:     Epoch: 64
2022-11-28 05:20:16,743 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.506480494683439, 'Total loss': 0.506480494683439} | train loss {'Reaction outcome loss': 0.46830978618592634, 'Total loss': 0.46830978618592634}
2022-11-28 05:20:16,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:16,743 INFO:     Epoch: 65
2022-11-28 05:20:17,400 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44044817780906503, 'Total loss': 0.44044817780906503} | train loss {'Reaction outcome loss': 0.4662507926322976, 'Total loss': 0.4662507926322976}
2022-11-28 05:20:17,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:17,400 INFO:     Epoch: 66
2022-11-28 05:20:18,058 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4447516643188216, 'Total loss': 0.4447516643188216} | train loss {'Reaction outcome loss': 0.46927338406747704, 'Total loss': 0.46927338406747704}
2022-11-28 05:20:18,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:18,059 INFO:     Epoch: 67
2022-11-28 05:20:18,720 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4455685922029344, 'Total loss': 0.4455685922029344} | train loss {'Reaction outcome loss': 0.4661652459173786, 'Total loss': 0.4661652459173786}
2022-11-28 05:20:18,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:18,720 INFO:     Epoch: 68
2022-11-28 05:20:19,381 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4547740525820039, 'Total loss': 0.4547740525820039} | train loss {'Reaction outcome loss': 0.46322807389862686, 'Total loss': 0.46322807389862686}
2022-11-28 05:20:19,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:19,381 INFO:     Epoch: 69
2022-11-28 05:20:20,039 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4825997074896639, 'Total loss': 0.4825997074896639} | train loss {'Reaction outcome loss': 0.4706703449998583, 'Total loss': 0.4706703449998583}
2022-11-28 05:20:20,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:20,039 INFO:     Epoch: 70
2022-11-28 05:20:20,694 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44655081731351937, 'Total loss': 0.44655081731351937} | train loss {'Reaction outcome loss': 0.4640353721623518, 'Total loss': 0.4640353721623518}
2022-11-28 05:20:20,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:20,694 INFO:     Epoch: 71
2022-11-28 05:20:21,351 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45981069789691403, 'Total loss': 0.45981069789691403} | train loss {'Reaction outcome loss': 0.4658675276503271, 'Total loss': 0.4658675276503271}
2022-11-28 05:20:21,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:21,352 INFO:     Epoch: 72
2022-11-28 05:20:22,009 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.458114874295213, 'Total loss': 0.458114874295213} | train loss {'Reaction outcome loss': 0.46383287322764494, 'Total loss': 0.46383287322764494}
2022-11-28 05:20:22,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:22,009 INFO:     Epoch: 73
2022-11-28 05:20:22,668 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4524177455089309, 'Total loss': 0.4524177455089309} | train loss {'Reaction outcome loss': 0.4708060364333951, 'Total loss': 0.4708060364333951}
2022-11-28 05:20:22,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:22,668 INFO:     Epoch: 74
2022-11-28 05:20:23,324 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4192687899551608, 'Total loss': 0.4192687899551608} | train loss {'Reaction outcome loss': 0.47143463796498825, 'Total loss': 0.47143463796498825}
2022-11-28 05:20:23,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:23,324 INFO:     Epoch: 75
2022-11-28 05:20:23,978 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4296351833776994, 'Total loss': 0.4296351833776994} | train loss {'Reaction outcome loss': 0.46962853645791813, 'Total loss': 0.46962853645791813}
2022-11-28 05:20:23,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:23,978 INFO:     Epoch: 76
2022-11-28 05:20:24,634 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4520668966526335, 'Total loss': 0.4520668966526335} | train loss {'Reaction outcome loss': 0.46391335731866407, 'Total loss': 0.46391335731866407}
2022-11-28 05:20:24,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:24,635 INFO:     Epoch: 77
2022-11-28 05:20:25,291 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4303831999952143, 'Total loss': 0.4303831999952143} | train loss {'Reaction outcome loss': 0.46735003791293317, 'Total loss': 0.46735003791293317}
2022-11-28 05:20:25,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:25,291 INFO:     Epoch: 78
2022-11-28 05:20:25,944 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4180577297440984, 'Total loss': 0.4180577297440984} | train loss {'Reaction outcome loss': 0.4668048780487508, 'Total loss': 0.4668048780487508}
2022-11-28 05:20:25,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:25,944 INFO:     Epoch: 79
2022-11-28 05:20:26,601 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4525800161063671, 'Total loss': 0.4525800161063671} | train loss {'Reaction outcome loss': 0.4645151357869713, 'Total loss': 0.4645151357869713}
2022-11-28 05:20:26,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:26,601 INFO:     Epoch: 80
2022-11-28 05:20:27,257 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5082560638812456, 'Total loss': 0.5082560638812456} | train loss {'Reaction outcome loss': 0.45900254775674976, 'Total loss': 0.45900254775674976}
2022-11-28 05:20:27,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:27,257 INFO:     Epoch: 81
2022-11-28 05:20:27,913 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4695860201662237, 'Total loss': 0.4695860201662237} | train loss {'Reaction outcome loss': 0.4705770803957569, 'Total loss': 0.4705770803957569}
2022-11-28 05:20:27,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:27,913 INFO:     Epoch: 82
2022-11-28 05:20:28,571 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46946337074041367, 'Total loss': 0.46946337074041367} | train loss {'Reaction outcome loss': 0.46501970087387123, 'Total loss': 0.46501970087387123}
2022-11-28 05:20:28,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:28,571 INFO:     Epoch: 83
2022-11-28 05:20:29,229 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.427318699657917, 'Total loss': 0.427318699657917} | train loss {'Reaction outcome loss': 0.4681457967174297, 'Total loss': 0.4681457967174297}
2022-11-28 05:20:29,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:29,229 INFO:     Epoch: 84
2022-11-28 05:20:29,887 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4486707164482637, 'Total loss': 0.4486707164482637} | train loss {'Reaction outcome loss': 0.46652260690319297, 'Total loss': 0.46652260690319297}
2022-11-28 05:20:29,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:29,888 INFO:     Epoch: 85
2022-11-28 05:20:30,544 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46104082287373865, 'Total loss': 0.46104082287373865} | train loss {'Reaction outcome loss': 0.4680763599519827, 'Total loss': 0.4680763599519827}
2022-11-28 05:20:30,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:30,544 INFO:     Epoch: 86
2022-11-28 05:20:31,203 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48773592100902036, 'Total loss': 0.48773592100902036} | train loss {'Reaction outcome loss': 0.4656945142818957, 'Total loss': 0.4656945142818957}
2022-11-28 05:20:31,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:31,203 INFO:     Epoch: 87
2022-11-28 05:20:31,861 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4437836835330183, 'Total loss': 0.4437836835330183} | train loss {'Reaction outcome loss': 0.4663297549194219, 'Total loss': 0.4663297549194219}
2022-11-28 05:20:31,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:31,862 INFO:     Epoch: 88
2022-11-28 05:20:32,522 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42495324835181236, 'Total loss': 0.42495324835181236} | train loss {'Reaction outcome loss': 0.46861677133307167, 'Total loss': 0.46861677133307167}
2022-11-28 05:20:32,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:32,522 INFO:     Epoch: 89
2022-11-28 05:20:33,182 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42905556749213825, 'Total loss': 0.42905556749213825} | train loss {'Reaction outcome loss': 0.4686098641887003, 'Total loss': 0.4686098641887003}
2022-11-28 05:20:33,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:33,182 INFO:     Epoch: 90
2022-11-28 05:20:33,838 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4410051666200161, 'Total loss': 0.4410051666200161} | train loss {'Reaction outcome loss': 0.4722394226156935, 'Total loss': 0.4722394226156935}
2022-11-28 05:20:33,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:33,839 INFO:     Epoch: 91
2022-11-28 05:20:34,492 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4453813122077422, 'Total loss': 0.4453813122077422} | train loss {'Reaction outcome loss': 0.4716222254597411, 'Total loss': 0.4716222254597411}
2022-11-28 05:20:34,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:34,492 INFO:     Epoch: 92
2022-11-28 05:20:35,148 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42297717387026007, 'Total loss': 0.42297717387026007} | train loss {'Reaction outcome loss': 0.4657340631801255, 'Total loss': 0.4657340631801255}
2022-11-28 05:20:35,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:35,149 INFO:     Epoch: 93
2022-11-28 05:20:35,805 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42423518950288946, 'Total loss': 0.42423518950288946} | train loss {'Reaction outcome loss': 0.47139745263420807, 'Total loss': 0.47139745263420807}
2022-11-28 05:20:35,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:35,805 INFO:     Epoch: 94
2022-11-28 05:20:36,461 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44654693928631867, 'Total loss': 0.44654693928631867} | train loss {'Reaction outcome loss': 0.4725190325659149, 'Total loss': 0.4725190325659149}
2022-11-28 05:20:36,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:36,462 INFO:     Epoch: 95
2022-11-28 05:20:37,123 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46200793371959165, 'Total loss': 0.46200793371959165} | train loss {'Reaction outcome loss': 0.4709948144396957, 'Total loss': 0.4709948144396957}
2022-11-28 05:20:37,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:37,123 INFO:     Epoch: 96
2022-11-28 05:20:37,781 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.434658675708554, 'Total loss': 0.434658675708554} | train loss {'Reaction outcome loss': 0.46647372993887687, 'Total loss': 0.46647372993887687}
2022-11-28 05:20:37,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:37,781 INFO:     Epoch: 97
2022-11-28 05:20:38,439 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44163793189959094, 'Total loss': 0.44163793189959094} | train loss {'Reaction outcome loss': 0.4730533113284987, 'Total loss': 0.4730533113284987}
2022-11-28 05:20:38,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:38,439 INFO:     Epoch: 98
2022-11-28 05:20:39,096 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4484955973245881, 'Total loss': 0.4484955973245881} | train loss {'Reaction outcome loss': 0.46323968190319686, 'Total loss': 0.46323968190319686}
2022-11-28 05:20:39,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:39,096 INFO:     Epoch: 99
2022-11-28 05:20:39,751 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4370661001991142, 'Total loss': 0.4370661001991142} | train loss {'Reaction outcome loss': 0.47045104321168396, 'Total loss': 0.47045104321168396}
2022-11-28 05:20:39,752 INFO:     Best model found after epoch 23 of 100.
2022-11-28 05:20:39,752 INFO:   Done with stage: TRAINING
2022-11-28 05:20:39,752 INFO:   Starting stage: EVALUATION
2022-11-28 05:20:39,875 INFO:   Done with stage: EVALUATION
2022-11-28 05:20:39,875 INFO:   Leaving out SEQ value Fold_3
2022-11-28 05:20:39,888 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 05:20:39,888 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:20:40,523 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:20:40,523 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:20:40,593 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:20:40,593 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:20:40,593 INFO:     No hyperparam tuning for this model
2022-11-28 05:20:40,593 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:20:40,593 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:20:40,594 INFO:     None feature selector for col prot
2022-11-28 05:20:40,594 INFO:     None feature selector for col prot
2022-11-28 05:20:40,594 INFO:     None feature selector for col prot
2022-11-28 05:20:40,594 INFO:     None feature selector for col chem
2022-11-28 05:20:40,594 INFO:     None feature selector for col chem
2022-11-28 05:20:40,595 INFO:     None feature selector for col chem
2022-11-28 05:20:40,595 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:20:40,595 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:20:40,596 INFO:     Number of params in model 169651
2022-11-28 05:20:40,599 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:20:40,599 INFO:   Starting stage: TRAINING
2022-11-28 05:20:40,649 INFO:     Val loss before train {'Reaction outcome loss': 1.0300361791322397, 'Total loss': 1.0300361791322397}
2022-11-28 05:20:40,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:40,649 INFO:     Epoch: 0
2022-11-28 05:20:41,302 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6300489237142164, 'Total loss': 0.6300489237142164} | train loss {'Reaction outcome loss': 0.6917219983993984, 'Total loss': 0.6917219983993984}
2022-11-28 05:20:41,302 INFO:     Found new best model at epoch 0
2022-11-28 05:20:41,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:41,303 INFO:     Epoch: 1
2022-11-28 05:20:41,956 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6225075797979222, 'Total loss': 0.6225075797979222} | train loss {'Reaction outcome loss': 0.5875414575709671, 'Total loss': 0.5875414575709671}
2022-11-28 05:20:41,956 INFO:     Found new best model at epoch 1
2022-11-28 05:20:41,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:41,957 INFO:     Epoch: 2
2022-11-28 05:20:42,613 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5649538691653762, 'Total loss': 0.5649538691653762} | train loss {'Reaction outcome loss': 0.5531256522861172, 'Total loss': 0.5531256522861172}
2022-11-28 05:20:42,614 INFO:     Found new best model at epoch 2
2022-11-28 05:20:42,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:42,614 INFO:     Epoch: 3
2022-11-28 05:20:43,268 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5544590402481168, 'Total loss': 0.5544590402481168} | train loss {'Reaction outcome loss': 0.5354402047566703, 'Total loss': 0.5354402047566703}
2022-11-28 05:20:43,268 INFO:     Found new best model at epoch 3
2022-11-28 05:20:43,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:43,269 INFO:     Epoch: 4
2022-11-28 05:20:43,921 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5560886887616889, 'Total loss': 0.5560886887616889} | train loss {'Reaction outcome loss': 0.5112077415172682, 'Total loss': 0.5112077415172682}
2022-11-28 05:20:43,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:43,922 INFO:     Epoch: 5
2022-11-28 05:20:44,576 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5453407286211501, 'Total loss': 0.5453407286211501} | train loss {'Reaction outcome loss': 0.5138881036736926, 'Total loss': 0.5138881036736926}
2022-11-28 05:20:44,576 INFO:     Found new best model at epoch 5
2022-11-28 05:20:44,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:44,577 INFO:     Epoch: 6
2022-11-28 05:20:45,229 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5252884279849918, 'Total loss': 0.5252884279849918} | train loss {'Reaction outcome loss': 0.5057260988921416, 'Total loss': 0.5057260988921416}
2022-11-28 05:20:45,229 INFO:     Found new best model at epoch 6
2022-11-28 05:20:45,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:45,230 INFO:     Epoch: 7
2022-11-28 05:20:45,883 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5153627527314563, 'Total loss': 0.5153627527314563} | train loss {'Reaction outcome loss': 0.49777732203241254, 'Total loss': 0.49777732203241254}
2022-11-28 05:20:45,883 INFO:     Found new best model at epoch 7
2022-11-28 05:20:45,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:45,884 INFO:     Epoch: 8
2022-11-28 05:20:46,537 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5365860978531283, 'Total loss': 0.5365860978531283} | train loss {'Reaction outcome loss': 0.49553275486973464, 'Total loss': 0.49553275486973464}
2022-11-28 05:20:46,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:46,537 INFO:     Epoch: 9
2022-11-28 05:20:47,192 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5292696938958279, 'Total loss': 0.5292696938958279} | train loss {'Reaction outcome loss': 0.49128649603636537, 'Total loss': 0.49128649603636537}
2022-11-28 05:20:47,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:47,192 INFO:     Epoch: 10
2022-11-28 05:20:47,848 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5133732321650483, 'Total loss': 0.5133732321650483} | train loss {'Reaction outcome loss': 0.48537153402557137, 'Total loss': 0.48537153402557137}
2022-11-28 05:20:47,848 INFO:     Found new best model at epoch 10
2022-11-28 05:20:47,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:47,849 INFO:     Epoch: 11
2022-11-28 05:20:48,507 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.520937979221344, 'Total loss': 0.520937979221344} | train loss {'Reaction outcome loss': 0.4890185640972169, 'Total loss': 0.4890185640972169}
2022-11-28 05:20:48,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:48,507 INFO:     Epoch: 12
2022-11-28 05:20:49,162 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48871810734272003, 'Total loss': 0.48871810734272003} | train loss {'Reaction outcome loss': 0.47882645961935405, 'Total loss': 0.47882645961935405}
2022-11-28 05:20:49,163 INFO:     Found new best model at epoch 12
2022-11-28 05:20:49,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:49,163 INFO:     Epoch: 13
2022-11-28 05:20:49,818 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5326150610696437, 'Total loss': 0.5326150610696437} | train loss {'Reaction outcome loss': 0.4692125851135762, 'Total loss': 0.4692125851135762}
2022-11-28 05:20:49,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:49,818 INFO:     Epoch: 14
2022-11-28 05:20:50,471 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5204186557337295, 'Total loss': 0.5204186557337295} | train loss {'Reaction outcome loss': 0.4757407734506443, 'Total loss': 0.4757407734506443}
2022-11-28 05:20:50,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:50,472 INFO:     Epoch: 15
2022-11-28 05:20:51,127 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5016952063455138, 'Total loss': 0.5016952063455138} | train loss {'Reaction outcome loss': 0.47706122235318676, 'Total loss': 0.47706122235318676}
2022-11-28 05:20:51,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:51,127 INFO:     Epoch: 16
2022-11-28 05:20:51,782 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4976326168276543, 'Total loss': 0.4976326168276543} | train loss {'Reaction outcome loss': 0.47277824806629637, 'Total loss': 0.47277824806629637}
2022-11-28 05:20:51,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:51,782 INFO:     Epoch: 17
2022-11-28 05:20:52,436 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49661089445269385, 'Total loss': 0.49661089445269385} | train loss {'Reaction outcome loss': 0.46100420431524025, 'Total loss': 0.46100420431524025}
2022-11-28 05:20:52,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:52,436 INFO:     Epoch: 18
2022-11-28 05:20:53,092 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5112720017516336, 'Total loss': 0.5112720017516336} | train loss {'Reaction outcome loss': 0.47069669914905166, 'Total loss': 0.47069669914905166}
2022-11-28 05:20:53,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:53,092 INFO:     Epoch: 19
2022-11-28 05:20:53,750 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5164554638918056, 'Total loss': 0.5164554638918056} | train loss {'Reaction outcome loss': 0.4768174582573234, 'Total loss': 0.4768174582573234}
2022-11-28 05:20:53,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:53,750 INFO:     Epoch: 20
2022-11-28 05:20:54,407 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49464251898055855, 'Total loss': 0.49464251898055855} | train loss {'Reaction outcome loss': 0.47858699020303663, 'Total loss': 0.47858699020303663}
2022-11-28 05:20:54,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:54,407 INFO:     Epoch: 21
2022-11-28 05:20:55,061 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5081434783547424, 'Total loss': 0.5081434783547424} | train loss {'Reaction outcome loss': 0.46031995862722397, 'Total loss': 0.46031995862722397}
2022-11-28 05:20:55,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:55,062 INFO:     Epoch: 22
2022-11-28 05:20:55,720 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5239316415648128, 'Total loss': 0.5239316415648128} | train loss {'Reaction outcome loss': 0.46858919222579626, 'Total loss': 0.46858919222579626}
2022-11-28 05:20:55,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:55,720 INFO:     Epoch: 23
2022-11-28 05:20:56,376 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4973645331554635, 'Total loss': 0.4973645331554635} | train loss {'Reaction outcome loss': 0.47036522461986935, 'Total loss': 0.47036522461986935}
2022-11-28 05:20:56,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:56,376 INFO:     Epoch: 24
2022-11-28 05:20:57,028 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5040282315986101, 'Total loss': 0.5040282315986101} | train loss {'Reaction outcome loss': 0.4691796444478582, 'Total loss': 0.4691796444478582}
2022-11-28 05:20:57,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:57,028 INFO:     Epoch: 25
2022-11-28 05:20:57,683 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5140377421711766, 'Total loss': 0.5140377421711766} | train loss {'Reaction outcome loss': 0.46263196478124524, 'Total loss': 0.46263196478124524}
2022-11-28 05:20:57,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:57,684 INFO:     Epoch: 26
2022-11-28 05:20:58,340 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48712531979693924, 'Total loss': 0.48712531979693924} | train loss {'Reaction outcome loss': 0.463868508145946, 'Total loss': 0.463868508145946}
2022-11-28 05:20:58,340 INFO:     Found new best model at epoch 26
2022-11-28 05:20:58,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:58,341 INFO:     Epoch: 27
2022-11-28 05:20:59,000 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46999038062816445, 'Total loss': 0.46999038062816445} | train loss {'Reaction outcome loss': 0.4665070760567657, 'Total loss': 0.4665070760567657}
2022-11-28 05:20:59,001 INFO:     Found new best model at epoch 27
2022-11-28 05:20:59,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:59,001 INFO:     Epoch: 28
2022-11-28 05:20:59,658 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5126574580059495, 'Total loss': 0.5126574580059495} | train loss {'Reaction outcome loss': 0.468765830376842, 'Total loss': 0.468765830376842}
2022-11-28 05:20:59,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:20:59,658 INFO:     Epoch: 29
2022-11-28 05:21:00,314 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4933337946963865, 'Total loss': 0.4933337946963865} | train loss {'Reaction outcome loss': 0.4698894191533327, 'Total loss': 0.4698894191533327}
2022-11-28 05:21:00,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:00,314 INFO:     Epoch: 30
2022-11-28 05:21:00,969 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5383881715147995, 'Total loss': 0.5383881715147995} | train loss {'Reaction outcome loss': 0.46583012448715383, 'Total loss': 0.46583012448715383}
2022-11-28 05:21:00,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:00,970 INFO:     Epoch: 31
2022-11-28 05:21:01,621 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5052538437898769, 'Total loss': 0.5052538437898769} | train loss {'Reaction outcome loss': 0.46468089163669796, 'Total loss': 0.46468089163669796}
2022-11-28 05:21:01,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:01,621 INFO:     Epoch: 32
2022-11-28 05:21:02,274 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5477920240441034, 'Total loss': 0.5477920240441034} | train loss {'Reaction outcome loss': 0.47117804424440274, 'Total loss': 0.47117804424440274}
2022-11-28 05:21:02,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:02,274 INFO:     Epoch: 33
2022-11-28 05:21:02,927 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4797127135964327, 'Total loss': 0.4797127135964327} | train loss {'Reaction outcome loss': 0.46774871934388507, 'Total loss': 0.46774871934388507}
2022-11-28 05:21:02,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:02,927 INFO:     Epoch: 34
2022-11-28 05:21:03,578 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5051359180794206, 'Total loss': 0.5051359180794206} | train loss {'Reaction outcome loss': 0.46284853660913766, 'Total loss': 0.46284853660913766}
2022-11-28 05:21:03,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:03,579 INFO:     Epoch: 35
2022-11-28 05:21:04,232 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4949899184149365, 'Total loss': 0.4949899184149365} | train loss {'Reaction outcome loss': 0.4671546709952784, 'Total loss': 0.4671546709952784}
2022-11-28 05:21:04,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:04,233 INFO:     Epoch: 36
2022-11-28 05:21:04,886 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48081346514613127, 'Total loss': 0.48081346514613127} | train loss {'Reaction outcome loss': 0.46108544642319443, 'Total loss': 0.46108544642319443}
2022-11-28 05:21:04,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:04,886 INFO:     Epoch: 37
2022-11-28 05:21:05,537 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.517274830923524, 'Total loss': 0.517274830923524} | train loss {'Reaction outcome loss': 0.46601034816904147, 'Total loss': 0.46601034816904147}
2022-11-28 05:21:05,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:05,538 INFO:     Epoch: 38
2022-11-28 05:21:06,196 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4996163560900577, 'Total loss': 0.4996163560900577} | train loss {'Reaction outcome loss': 0.4662142326353026, 'Total loss': 0.4662142326353026}
2022-11-28 05:21:06,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:06,196 INFO:     Epoch: 39
2022-11-28 05:21:06,850 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5014488703982775, 'Total loss': 0.5014488703982775} | train loss {'Reaction outcome loss': 0.46709144756686494, 'Total loss': 0.46709144756686494}
2022-11-28 05:21:06,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:06,851 INFO:     Epoch: 40
2022-11-28 05:21:07,502 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5041407745244891, 'Total loss': 0.5041407745244891} | train loss {'Reaction outcome loss': 0.459550640377842, 'Total loss': 0.459550640377842}
2022-11-28 05:21:07,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:07,503 INFO:     Epoch: 41
2022-11-28 05:21:08,155 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5024446034154226, 'Total loss': 0.5024446034154226} | train loss {'Reaction outcome loss': 0.46427995277965656, 'Total loss': 0.46427995277965656}
2022-11-28 05:21:08,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:08,155 INFO:     Epoch: 42
2022-11-28 05:21:08,807 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5073396452637606, 'Total loss': 0.5073396452637606} | train loss {'Reaction outcome loss': 0.46151318822483545, 'Total loss': 0.46151318822483545}
2022-11-28 05:21:08,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:08,807 INFO:     Epoch: 43
2022-11-28 05:21:09,457 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5325672390849091, 'Total loss': 0.5325672390849091} | train loss {'Reaction outcome loss': 0.4631199240073806, 'Total loss': 0.4631199240073806}
2022-11-28 05:21:09,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:09,457 INFO:     Epoch: 44
2022-11-28 05:21:10,110 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49533432722091675, 'Total loss': 0.49533432722091675} | train loss {'Reaction outcome loss': 0.46285215679739344, 'Total loss': 0.46285215679739344}
2022-11-28 05:21:10,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:10,110 INFO:     Epoch: 45
2022-11-28 05:21:10,763 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4695810710274896, 'Total loss': 0.4695810710274896} | train loss {'Reaction outcome loss': 0.4665539943475704, 'Total loss': 0.4665539943475704}
2022-11-28 05:21:10,763 INFO:     Found new best model at epoch 45
2022-11-28 05:21:10,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:10,764 INFO:     Epoch: 46
2022-11-28 05:21:11,418 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4709142086117767, 'Total loss': 0.4709142086117767} | train loss {'Reaction outcome loss': 0.46104621575748334, 'Total loss': 0.46104621575748334}
2022-11-28 05:21:11,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:11,419 INFO:     Epoch: 47
2022-11-28 05:21:12,076 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5090191821719325, 'Total loss': 0.5090191821719325} | train loss {'Reaction outcome loss': 0.46547825622265454, 'Total loss': 0.46547825622265454}
2022-11-28 05:21:12,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:12,076 INFO:     Epoch: 48
2022-11-28 05:21:12,732 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5135895963325057, 'Total loss': 0.5135895963325057} | train loss {'Reaction outcome loss': 0.4644304026437343, 'Total loss': 0.4644304026437343}
2022-11-28 05:21:12,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:12,733 INFO:     Epoch: 49
2022-11-28 05:21:13,384 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5272038267102352, 'Total loss': 0.5272038267102352} | train loss {'Reaction outcome loss': 0.461969186658742, 'Total loss': 0.461969186658742}
2022-11-28 05:21:13,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:13,384 INFO:     Epoch: 50
2022-11-28 05:21:14,037 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.501283966871195, 'Total loss': 0.501283966871195} | train loss {'Reaction outcome loss': 0.4626268554539954, 'Total loss': 0.4626268554539954}
2022-11-28 05:21:14,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:14,037 INFO:     Epoch: 51
2022-11-28 05:21:14,693 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4956162232299184, 'Total loss': 0.4956162232299184} | train loss {'Reaction outcome loss': 0.46552876767809276, 'Total loss': 0.46552876767809276}
2022-11-28 05:21:14,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:14,694 INFO:     Epoch: 52
2022-11-28 05:21:15,346 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.509889830683553, 'Total loss': 0.509889830683553} | train loss {'Reaction outcome loss': 0.4648554850919325, 'Total loss': 0.4648554850919325}
2022-11-28 05:21:15,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:15,346 INFO:     Epoch: 53
2022-11-28 05:21:15,999 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5015251948389896, 'Total loss': 0.5015251948389896} | train loss {'Reaction outcome loss': 0.46520174477921156, 'Total loss': 0.46520174477921156}
2022-11-28 05:21:15,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:15,999 INFO:     Epoch: 54
2022-11-28 05:21:16,651 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5486608799113784, 'Total loss': 0.5486608799113784} | train loss {'Reaction outcome loss': 0.46176603155546503, 'Total loss': 0.46176603155546503}
2022-11-28 05:21:16,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:16,651 INFO:     Epoch: 55
2022-11-28 05:21:17,302 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4950130637301955, 'Total loss': 0.4950130637301955} | train loss {'Reaction outcome loss': 0.4663649643542337, 'Total loss': 0.4663649643542337}
2022-11-28 05:21:17,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:17,302 INFO:     Epoch: 56
2022-11-28 05:21:17,957 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4875337478033332, 'Total loss': 0.4875337478033332} | train loss {'Reaction outcome loss': 0.4661026106628238, 'Total loss': 0.4661026106628238}
2022-11-28 05:21:17,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:17,957 INFO:     Epoch: 57
2022-11-28 05:21:18,611 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5100931916819063, 'Total loss': 0.5100931916819063} | train loss {'Reaction outcome loss': 0.4585412347414454, 'Total loss': 0.4585412347414454}
2022-11-28 05:21:18,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:18,611 INFO:     Epoch: 58
2022-11-28 05:21:19,265 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5325003328711487, 'Total loss': 0.5325003328711487} | train loss {'Reaction outcome loss': 0.46009740105173624, 'Total loss': 0.46009740105173624}
2022-11-28 05:21:19,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:19,265 INFO:     Epoch: 59
2022-11-28 05:21:19,918 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47007439857305483, 'Total loss': 0.47007439857305483} | train loss {'Reaction outcome loss': 0.4615522587641341, 'Total loss': 0.4615522587641341}
2022-11-28 05:21:19,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:19,919 INFO:     Epoch: 60
2022-11-28 05:21:20,574 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4879726133374281, 'Total loss': 0.4879726133374281} | train loss {'Reaction outcome loss': 0.46537598143102693, 'Total loss': 0.46537598143102693}
2022-11-28 05:21:20,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:20,575 INFO:     Epoch: 61
2022-11-28 05:21:21,230 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47505874897158423, 'Total loss': 0.47505874897158423} | train loss {'Reaction outcome loss': 0.46280651765524367, 'Total loss': 0.46280651765524367}
2022-11-28 05:21:21,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:21,231 INFO:     Epoch: 62
2022-11-28 05:21:21,884 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4950249794610711, 'Total loss': 0.4950249794610711} | train loss {'Reaction outcome loss': 0.46800549474895975, 'Total loss': 0.46800549474895975}
2022-11-28 05:21:21,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:21,884 INFO:     Epoch: 63
2022-11-28 05:21:22,538 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4955129782820857, 'Total loss': 0.4955129782820857} | train loss {'Reaction outcome loss': 0.46244740208275004, 'Total loss': 0.46244740208275004}
2022-11-28 05:21:22,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:22,538 INFO:     Epoch: 64
2022-11-28 05:21:23,191 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.485641403600227, 'Total loss': 0.485641403600227} | train loss {'Reaction outcome loss': 0.46234009219486205, 'Total loss': 0.46234009219486205}
2022-11-28 05:21:23,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:23,191 INFO:     Epoch: 65
2022-11-28 05:21:23,848 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4794105312158895, 'Total loss': 0.4794105312158895} | train loss {'Reaction outcome loss': 0.46099184838230495, 'Total loss': 0.46099184838230495}
2022-11-28 05:21:23,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:23,848 INFO:     Epoch: 66
2022-11-28 05:21:24,504 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4870686122151308, 'Total loss': 0.4870686122151308} | train loss {'Reaction outcome loss': 0.4572489700417538, 'Total loss': 0.4572489700417538}
2022-11-28 05:21:24,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:24,504 INFO:     Epoch: 67
2022-11-28 05:21:25,157 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49048552280941676, 'Total loss': 0.49048552280941676} | train loss {'Reaction outcome loss': 0.46149628102535106, 'Total loss': 0.46149628102535106}
2022-11-28 05:21:25,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:25,157 INFO:     Epoch: 68
2022-11-28 05:21:25,812 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5302360258823218, 'Total loss': 0.5302360258823218} | train loss {'Reaction outcome loss': 0.4629657350663767, 'Total loss': 0.4629657350663767}
2022-11-28 05:21:25,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:25,812 INFO:     Epoch: 69
2022-11-28 05:21:26,465 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5027240126631981, 'Total loss': 0.5027240126631981} | train loss {'Reaction outcome loss': 0.464107230549953, 'Total loss': 0.464107230549953}
2022-11-28 05:21:26,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:26,466 INFO:     Epoch: 70
2022-11-28 05:21:27,121 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4902583107698795, 'Total loss': 0.4902583107698795} | train loss {'Reaction outcome loss': 0.46040806015495395, 'Total loss': 0.46040806015495395}
2022-11-28 05:21:27,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:27,121 INFO:     Epoch: 71
2022-11-28 05:21:27,776 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4935051067623981, 'Total loss': 0.4935051067623981} | train loss {'Reaction outcome loss': 0.4662848515588729, 'Total loss': 0.4662848515588729}
2022-11-28 05:21:27,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:27,776 INFO:     Epoch: 72
2022-11-28 05:21:28,429 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5080980457538782, 'Total loss': 0.5080980457538782} | train loss {'Reaction outcome loss': 0.46088252350932263, 'Total loss': 0.46088252350932263}
2022-11-28 05:21:28,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:28,430 INFO:     Epoch: 73
2022-11-28 05:21:29,081 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4915077117986457, 'Total loss': 0.4915077117986457} | train loss {'Reaction outcome loss': 0.4652716630123189, 'Total loss': 0.4652716630123189}
2022-11-28 05:21:29,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:29,081 INFO:     Epoch: 74
2022-11-28 05:21:29,731 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48999126671358595, 'Total loss': 0.48999126671358595} | train loss {'Reaction outcome loss': 0.4669229935427181, 'Total loss': 0.4669229935427181}
2022-11-28 05:21:29,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:29,731 INFO:     Epoch: 75
2022-11-28 05:21:30,385 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.495165306121804, 'Total loss': 0.495165306121804} | train loss {'Reaction outcome loss': 0.45980255898149286, 'Total loss': 0.45980255898149286}
2022-11-28 05:21:30,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:30,385 INFO:     Epoch: 76
2022-11-28 05:21:31,039 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49118546968282656, 'Total loss': 0.49118546968282656} | train loss {'Reaction outcome loss': 0.4654579187025789, 'Total loss': 0.4654579187025789}
2022-11-28 05:21:31,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:31,039 INFO:     Epoch: 77
2022-11-28 05:21:31,691 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4982479997845583, 'Total loss': 0.4982479997845583} | train loss {'Reaction outcome loss': 0.46767699425337744, 'Total loss': 0.46767699425337744}
2022-11-28 05:21:31,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:31,691 INFO:     Epoch: 78
2022-11-28 05:21:32,345 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4833567035059596, 'Total loss': 0.4833567035059596} | train loss {'Reaction outcome loss': 0.46365852999027635, 'Total loss': 0.46365852999027635}
2022-11-28 05:21:32,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:32,345 INFO:     Epoch: 79
2022-11-28 05:21:33,002 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.533857163301734, 'Total loss': 0.533857163301734} | train loss {'Reaction outcome loss': 0.4625391696320205, 'Total loss': 0.4625391696320205}
2022-11-28 05:21:33,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:33,002 INFO:     Epoch: 80
2022-11-28 05:21:33,660 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5345896829006284, 'Total loss': 0.5345896829006284} | train loss {'Reaction outcome loss': 0.4632447024227166, 'Total loss': 0.4632447024227166}
2022-11-28 05:21:33,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:33,660 INFO:     Epoch: 81
2022-11-28 05:21:34,316 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4799897816292075, 'Total loss': 0.4799897816292075} | train loss {'Reaction outcome loss': 0.4588340203293034, 'Total loss': 0.4588340203293034}
2022-11-28 05:21:34,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:34,317 INFO:     Epoch: 82
2022-11-28 05:21:34,973 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48864026922126147, 'Total loss': 0.48864026922126147} | train loss {'Reaction outcome loss': 0.4650598913125816, 'Total loss': 0.4650598913125816}
2022-11-28 05:21:34,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:34,973 INFO:     Epoch: 83
2022-11-28 05:21:35,624 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4897812445496404, 'Total loss': 0.4897812445496404} | train loss {'Reaction outcome loss': 0.4663385057241702, 'Total loss': 0.4663385057241702}
2022-11-28 05:21:35,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:35,625 INFO:     Epoch: 84
2022-11-28 05:21:36,278 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4989576887252719, 'Total loss': 0.4989576887252719} | train loss {'Reaction outcome loss': 0.4641142875322553, 'Total loss': 0.4641142875322553}
2022-11-28 05:21:36,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:36,278 INFO:     Epoch: 85
2022-11-28 05:21:36,935 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4746769807019899, 'Total loss': 0.4746769807019899} | train loss {'Reaction outcome loss': 0.46578333441351283, 'Total loss': 0.46578333441351283}
2022-11-28 05:21:36,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:36,935 INFO:     Epoch: 86
2022-11-28 05:21:37,594 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48516023124373236, 'Total loss': 0.48516023124373236} | train loss {'Reaction outcome loss': 0.463140958889586, 'Total loss': 0.463140958889586}
2022-11-28 05:21:37,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:37,594 INFO:     Epoch: 87
2022-11-28 05:21:38,249 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4914377816887789, 'Total loss': 0.4914377816887789} | train loss {'Reaction outcome loss': 0.4576996242719107, 'Total loss': 0.4576996242719107}
2022-11-28 05:21:38,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:38,250 INFO:     Epoch: 88
2022-11-28 05:21:38,907 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4971249664938727, 'Total loss': 0.4971249664938727} | train loss {'Reaction outcome loss': 0.4584035311260673, 'Total loss': 0.4584035311260673}
2022-11-28 05:21:38,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:38,907 INFO:     Epoch: 89
2022-11-28 05:21:39,561 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4971865460623142, 'Total loss': 0.4971865460623142} | train loss {'Reaction outcome loss': 0.46565891558029615, 'Total loss': 0.46565891558029615}
2022-11-28 05:21:39,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:39,561 INFO:     Epoch: 90
2022-11-28 05:21:40,215 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5210952254575353, 'Total loss': 0.5210952254575353} | train loss {'Reaction outcome loss': 0.45896995360734033, 'Total loss': 0.45896995360734033}
2022-11-28 05:21:40,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:40,216 INFO:     Epoch: 91
2022-11-28 05:21:40,870 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5023795875699021, 'Total loss': 0.5023795875699021} | train loss {'Reaction outcome loss': 0.46371454733317014, 'Total loss': 0.46371454733317014}
2022-11-28 05:21:40,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:40,871 INFO:     Epoch: 92
2022-11-28 05:21:41,523 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49244358546512074, 'Total loss': 0.49244358546512074} | train loss {'Reaction outcome loss': 0.4634887560224924, 'Total loss': 0.4634887560224924}
2022-11-28 05:21:41,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:41,523 INFO:     Epoch: 93
2022-11-28 05:21:42,177 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48517009200051775, 'Total loss': 0.48517009200051775} | train loss {'Reaction outcome loss': 0.4552872000170536, 'Total loss': 0.4552872000170536}
2022-11-28 05:21:42,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:42,178 INFO:     Epoch: 94
2022-11-28 05:21:42,833 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4776478056297746, 'Total loss': 0.4776478056297746} | train loss {'Reaction outcome loss': 0.46081776214671916, 'Total loss': 0.46081776214671916}
2022-11-28 05:21:42,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:42,833 INFO:     Epoch: 95
2022-11-28 05:21:43,488 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4976823548244875, 'Total loss': 0.4976823548244875} | train loss {'Reaction outcome loss': 0.46424905619904644, 'Total loss': 0.46424905619904644}
2022-11-28 05:21:43,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:43,489 INFO:     Epoch: 96
2022-11-28 05:21:44,149 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48242031245730643, 'Total loss': 0.48242031245730643} | train loss {'Reaction outcome loss': 0.45315180725005805, 'Total loss': 0.45315180725005805}
2022-11-28 05:21:44,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:44,149 INFO:     Epoch: 97
2022-11-28 05:21:44,803 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4818555653788323, 'Total loss': 0.4818555653788323} | train loss {'Reaction outcome loss': 0.4572153104255434, 'Total loss': 0.4572153104255434}
2022-11-28 05:21:44,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:44,804 INFO:     Epoch: 98
2022-11-28 05:21:45,461 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48103473283523734, 'Total loss': 0.48103473283523734} | train loss {'Reaction outcome loss': 0.45786926309104825, 'Total loss': 0.45786926309104825}
2022-11-28 05:21:45,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:45,462 INFO:     Epoch: 99
2022-11-28 05:21:46,125 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5060262108264968, 'Total loss': 0.5060262108264968} | train loss {'Reaction outcome loss': 0.4596127962052334, 'Total loss': 0.4596127962052334}
2022-11-28 05:21:46,125 INFO:     Best model found after epoch 46 of 100.
2022-11-28 05:21:46,125 INFO:   Done with stage: TRAINING
2022-11-28 05:21:46,125 INFO:   Starting stage: EVALUATION
2022-11-28 05:21:46,255 INFO:   Done with stage: EVALUATION
2022-11-28 05:21:46,255 INFO:   Leaving out SEQ value Fold_4
2022-11-28 05:21:46,268 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 05:21:46,268 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:21:46,907 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:21:46,907 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:21:46,977 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:21:46,978 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:21:46,978 INFO:     No hyperparam tuning for this model
2022-11-28 05:21:46,978 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:21:46,978 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:21:46,978 INFO:     None feature selector for col prot
2022-11-28 05:21:46,979 INFO:     None feature selector for col prot
2022-11-28 05:21:46,979 INFO:     None feature selector for col prot
2022-11-28 05:21:46,979 INFO:     None feature selector for col chem
2022-11-28 05:21:46,979 INFO:     None feature selector for col chem
2022-11-28 05:21:46,979 INFO:     None feature selector for col chem
2022-11-28 05:21:46,979 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:21:46,979 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:21:46,981 INFO:     Number of params in model 169651
2022-11-28 05:21:46,984 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:21:46,984 INFO:   Starting stage: TRAINING
2022-11-28 05:21:47,035 INFO:     Val loss before train {'Reaction outcome loss': 1.0745343633673408, 'Total loss': 1.0745343633673408}
2022-11-28 05:21:47,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:47,036 INFO:     Epoch: 0
2022-11-28 05:21:47,701 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6771111115813255, 'Total loss': 0.6771111115813255} | train loss {'Reaction outcome loss': 0.6906003550237972, 'Total loss': 0.6906003550237972}
2022-11-28 05:21:47,701 INFO:     Found new best model at epoch 0
2022-11-28 05:21:47,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:47,702 INFO:     Epoch: 1
2022-11-28 05:21:48,362 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.663297712802887, 'Total loss': 0.663297712802887} | train loss {'Reaction outcome loss': 0.605754913166467, 'Total loss': 0.605754913166467}
2022-11-28 05:21:48,362 INFO:     Found new best model at epoch 1
2022-11-28 05:21:48,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:48,363 INFO:     Epoch: 2
2022-11-28 05:21:49,021 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6052047830413688, 'Total loss': 0.6052047830413688} | train loss {'Reaction outcome loss': 0.5469043397831048, 'Total loss': 0.5469043397831048}
2022-11-28 05:21:49,021 INFO:     Found new best model at epoch 2
2022-11-28 05:21:49,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:49,022 INFO:     Epoch: 3
2022-11-28 05:21:49,676 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5732341378249906, 'Total loss': 0.5732341378249906} | train loss {'Reaction outcome loss': 0.5294285376786221, 'Total loss': 0.5294285376786221}
2022-11-28 05:21:49,676 INFO:     Found new best model at epoch 3
2022-11-28 05:21:49,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:49,677 INFO:     Epoch: 4
2022-11-28 05:21:50,337 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5898364409804344, 'Total loss': 0.5898364409804344} | train loss {'Reaction outcome loss': 0.5262694598933463, 'Total loss': 0.5262694598933463}
2022-11-28 05:21:50,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:50,337 INFO:     Epoch: 5
2022-11-28 05:21:50,996 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5777646418322216, 'Total loss': 0.5777646418322216} | train loss {'Reaction outcome loss': 0.5107651797711457, 'Total loss': 0.5107651797711457}
2022-11-28 05:21:50,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:50,996 INFO:     Epoch: 6
2022-11-28 05:21:51,659 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5604024820707061, 'Total loss': 0.5604024820707061} | train loss {'Reaction outcome loss': 0.5110026937023349, 'Total loss': 0.5110026937023349}
2022-11-28 05:21:51,660 INFO:     Found new best model at epoch 6
2022-11-28 05:21:51,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:51,660 INFO:     Epoch: 7
2022-11-28 05:21:52,318 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.620517374439673, 'Total loss': 0.620517374439673} | train loss {'Reaction outcome loss': 0.5134075744612979, 'Total loss': 0.5134075744612979}
2022-11-28 05:21:52,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:52,318 INFO:     Epoch: 8
2022-11-28 05:21:52,979 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5784510431641882, 'Total loss': 0.5784510431641882} | train loss {'Reaction outcome loss': 0.48940778618701075, 'Total loss': 0.48940778618701075}
2022-11-28 05:21:52,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:52,979 INFO:     Epoch: 9
2022-11-28 05:21:53,638 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5811514773152091, 'Total loss': 0.5811514773152091} | train loss {'Reaction outcome loss': 0.4740101142941035, 'Total loss': 0.4740101142941035}
2022-11-28 05:21:53,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:53,638 INFO:     Epoch: 10
2022-11-28 05:21:54,295 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5676049732349135, 'Total loss': 0.5676049732349135} | train loss {'Reaction outcome loss': 0.4808049776293488, 'Total loss': 0.4808049776293488}
2022-11-28 05:21:54,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:54,296 INFO:     Epoch: 11
2022-11-28 05:21:54,957 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5531840368428014, 'Total loss': 0.5531840368428014} | train loss {'Reaction outcome loss': 0.47435308031375834, 'Total loss': 0.47435308031375834}
2022-11-28 05:21:54,958 INFO:     Found new best model at epoch 11
2022-11-28 05:21:54,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:54,958 INFO:     Epoch: 12
2022-11-28 05:21:55,616 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5743568173863671, 'Total loss': 0.5743568173863671} | train loss {'Reaction outcome loss': 0.46980089563046873, 'Total loss': 0.46980089563046873}
2022-11-28 05:21:55,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:55,616 INFO:     Epoch: 13
2022-11-28 05:21:56,276 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5362554151903499, 'Total loss': 0.5362554151903499} | train loss {'Reaction outcome loss': 0.469250353754532, 'Total loss': 0.469250353754532}
2022-11-28 05:21:56,276 INFO:     Found new best model at epoch 13
2022-11-28 05:21:56,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:56,277 INFO:     Epoch: 14
2022-11-28 05:21:56,940 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5391415459188548, 'Total loss': 0.5391415459188548} | train loss {'Reaction outcome loss': 0.4678390005580809, 'Total loss': 0.4678390005580809}
2022-11-28 05:21:56,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:56,941 INFO:     Epoch: 15
2022-11-28 05:21:57,604 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5226027112115513, 'Total loss': 0.5226027112115513} | train loss {'Reaction outcome loss': 0.4781154238502024, 'Total loss': 0.4781154238502024}
2022-11-28 05:21:57,605 INFO:     Found new best model at epoch 15
2022-11-28 05:21:57,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:57,605 INFO:     Epoch: 16
2022-11-28 05:21:58,266 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5290180844339457, 'Total loss': 0.5290180844339457} | train loss {'Reaction outcome loss': 0.46667623404707564, 'Total loss': 0.46667623404707564}
2022-11-28 05:21:58,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:58,266 INFO:     Epoch: 17
2022-11-28 05:21:58,928 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5294413871385835, 'Total loss': 0.5294413871385835} | train loss {'Reaction outcome loss': 0.45971721379078834, 'Total loss': 0.45971721379078834}
2022-11-28 05:21:58,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:58,929 INFO:     Epoch: 18
2022-11-28 05:21:59,588 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5275268249891021, 'Total loss': 0.5275268249891021} | train loss {'Reaction outcome loss': 0.4662176604488269, 'Total loss': 0.4662176604488269}
2022-11-28 05:21:59,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:21:59,588 INFO:     Epoch: 19
2022-11-28 05:22:00,250 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.529592655429786, 'Total loss': 0.529592655429786} | train loss {'Reaction outcome loss': 0.4622539682125273, 'Total loss': 0.4622539682125273}
2022-11-28 05:22:00,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:00,250 INFO:     Epoch: 20
2022-11-28 05:22:00,914 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5513895512981848, 'Total loss': 0.5513895512981848} | train loss {'Reaction outcome loss': 0.46500009491376065, 'Total loss': 0.46500009491376065}
2022-11-28 05:22:00,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:00,914 INFO:     Epoch: 21
2022-11-28 05:22:01,573 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5299417979337953, 'Total loss': 0.5299417979337953} | train loss {'Reaction outcome loss': 0.4676426149572921, 'Total loss': 0.4676426149572921}
2022-11-28 05:22:01,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:01,573 INFO:     Epoch: 22
2022-11-28 05:22:02,232 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5530689392577518, 'Total loss': 0.5530689392577518} | train loss {'Reaction outcome loss': 0.4602782422382581, 'Total loss': 0.4602782422382581}
2022-11-28 05:22:02,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:02,233 INFO:     Epoch: 23
2022-11-28 05:22:02,889 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5656500485810366, 'Total loss': 0.5656500485810366} | train loss {'Reaction outcome loss': 0.46312732361106257, 'Total loss': 0.46312732361106257}
2022-11-28 05:22:02,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:02,889 INFO:     Epoch: 24
2022-11-28 05:22:03,546 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.527753352441571, 'Total loss': 0.527753352441571} | train loss {'Reaction outcome loss': 0.4678027221050702, 'Total loss': 0.4678027221050702}
2022-11-28 05:22:03,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:03,546 INFO:     Epoch: 25
2022-11-28 05:22:04,204 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5453566780144518, 'Total loss': 0.5453566780144518} | train loss {'Reaction outcome loss': 0.45560969448523964, 'Total loss': 0.45560969448523964}
2022-11-28 05:22:04,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:04,205 INFO:     Epoch: 26
2022-11-28 05:22:04,863 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5130601582879369, 'Total loss': 0.5130601582879369} | train loss {'Reaction outcome loss': 0.4753798487698018, 'Total loss': 0.4753798487698018}
2022-11-28 05:22:04,863 INFO:     Found new best model at epoch 26
2022-11-28 05:22:04,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:04,864 INFO:     Epoch: 27
2022-11-28 05:22:05,520 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.552719308571382, 'Total loss': 0.552719308571382} | train loss {'Reaction outcome loss': 0.47705799769534757, 'Total loss': 0.47705799769534757}
2022-11-28 05:22:05,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:05,520 INFO:     Epoch: 28
2022-11-28 05:22:06,179 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5290284007787704, 'Total loss': 0.5290284007787704} | train loss {'Reaction outcome loss': 0.4748483504119672, 'Total loss': 0.4748483504119672}
2022-11-28 05:22:06,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:06,179 INFO:     Epoch: 29
2022-11-28 05:22:06,845 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.511768410151655, 'Total loss': 0.511768410151655} | train loss {'Reaction outcome loss': 0.45944495091916093, 'Total loss': 0.45944495091916093}
2022-11-28 05:22:06,845 INFO:     Found new best model at epoch 29
2022-11-28 05:22:06,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:06,846 INFO:     Epoch: 30
2022-11-28 05:22:07,509 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.6829510588537563, 'Total loss': 0.6829510588537563} | train loss {'Reaction outcome loss': 0.457235371203799, 'Total loss': 0.457235371203799}
2022-11-28 05:22:07,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:07,509 INFO:     Epoch: 31
2022-11-28 05:22:08,171 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5342213030565869, 'Total loss': 0.5342213030565869} | train loss {'Reaction outcome loss': 0.4662672270627632, 'Total loss': 0.4662672270627632}
2022-11-28 05:22:08,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:08,171 INFO:     Epoch: 32
2022-11-28 05:22:08,831 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5081037926402959, 'Total loss': 0.5081037926402959} | train loss {'Reaction outcome loss': 0.4629039215112505, 'Total loss': 0.4629039215112505}
2022-11-28 05:22:08,831 INFO:     Found new best model at epoch 32
2022-11-28 05:22:08,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:08,832 INFO:     Epoch: 33
2022-11-28 05:22:09,491 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5281762087886984, 'Total loss': 0.5281762087886984} | train loss {'Reaction outcome loss': 0.4685343933491572, 'Total loss': 0.4685343933491572}
2022-11-28 05:22:09,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:09,493 INFO:     Epoch: 34
2022-11-28 05:22:10,153 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5383338237350638, 'Total loss': 0.5383338237350638} | train loss {'Reaction outcome loss': 0.4670475706880392, 'Total loss': 0.4670475706880392}
2022-11-28 05:22:10,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:10,153 INFO:     Epoch: 35
2022-11-28 05:22:10,814 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.545473194935105, 'Total loss': 0.545473194935105} | train loss {'Reaction outcome loss': 0.4647218051106341, 'Total loss': 0.4647218051106341}
2022-11-28 05:22:10,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:10,814 INFO:     Epoch: 36
2022-11-28 05:22:11,477 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5470478914000771, 'Total loss': 0.5470478914000771} | train loss {'Reaction outcome loss': 0.4683622184251002, 'Total loss': 0.4683622184251002}
2022-11-28 05:22:11,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:11,477 INFO:     Epoch: 37
2022-11-28 05:22:12,135 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5284588533368978, 'Total loss': 0.5284588533368978} | train loss {'Reaction outcome loss': 0.46592290756794125, 'Total loss': 0.46592290756794125}
2022-11-28 05:22:12,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:12,136 INFO:     Epoch: 38
2022-11-28 05:22:12,795 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.545610560612245, 'Total loss': 0.545610560612245} | train loss {'Reaction outcome loss': 0.4652742672643741, 'Total loss': 0.4652742672643741}
2022-11-28 05:22:12,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:12,795 INFO:     Epoch: 39
2022-11-28 05:22:13,452 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5226843136955391, 'Total loss': 0.5226843136955391} | train loss {'Reaction outcome loss': 0.4589993972557518, 'Total loss': 0.4589993972557518}
2022-11-28 05:22:13,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:13,452 INFO:     Epoch: 40
2022-11-28 05:22:14,111 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.549633112820712, 'Total loss': 0.549633112820712} | train loss {'Reaction outcome loss': 0.46254942738092863, 'Total loss': 0.46254942738092863}
2022-11-28 05:22:14,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:14,111 INFO:     Epoch: 41
2022-11-28 05:22:14,767 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5435453189367597, 'Total loss': 0.5435453189367597} | train loss {'Reaction outcome loss': 0.46881928509063564, 'Total loss': 0.46881928509063564}
2022-11-28 05:22:14,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:14,767 INFO:     Epoch: 42
2022-11-28 05:22:15,427 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5172882821749557, 'Total loss': 0.5172882821749557} | train loss {'Reaction outcome loss': 0.46290439150111395, 'Total loss': 0.46290439150111395}
2022-11-28 05:22:15,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:15,427 INFO:     Epoch: 43
2022-11-28 05:22:16,088 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5322188931432638, 'Total loss': 0.5322188931432638} | train loss {'Reaction outcome loss': 0.47140497937496856, 'Total loss': 0.47140497937496856}
2022-11-28 05:22:16,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:16,089 INFO:     Epoch: 44
2022-11-28 05:22:16,749 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5217896327376366, 'Total loss': 0.5217896327376366} | train loss {'Reaction outcome loss': 0.4756849973588835, 'Total loss': 0.4756849973588835}
2022-11-28 05:22:16,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:16,749 INFO:     Epoch: 45
2022-11-28 05:22:17,407 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5579483156854456, 'Total loss': 0.5579483156854456} | train loss {'Reaction outcome loss': 0.4602004323411084, 'Total loss': 0.4602004323411084}
2022-11-28 05:22:17,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:17,408 INFO:     Epoch: 46
2022-11-28 05:22:18,065 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.514720500192859, 'Total loss': 0.514720500192859} | train loss {'Reaction outcome loss': 0.4782592134799069, 'Total loss': 0.4782592134799069}
2022-11-28 05:22:18,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:18,066 INFO:     Epoch: 47
2022-11-28 05:22:18,723 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5271539318967949, 'Total loss': 0.5271539318967949} | train loss {'Reaction outcome loss': 0.46965032580651733, 'Total loss': 0.46965032580651733}
2022-11-28 05:22:18,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:18,723 INFO:     Epoch: 48
2022-11-28 05:22:19,378 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5178342607210983, 'Total loss': 0.5178342607210983} | train loss {'Reaction outcome loss': 0.46937446468481453, 'Total loss': 0.46937446468481453}
2022-11-28 05:22:19,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:19,378 INFO:     Epoch: 49
2022-11-28 05:22:20,034 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5359831740233031, 'Total loss': 0.5359831740233031} | train loss {'Reaction outcome loss': 0.46848973725368137, 'Total loss': 0.46848973725368137}
2022-11-28 05:22:20,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:20,034 INFO:     Epoch: 50
2022-11-28 05:22:20,693 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.561056366020983, 'Total loss': 0.561056366020983} | train loss {'Reaction outcome loss': 0.46985592928371933, 'Total loss': 0.46985592928371933}
2022-11-28 05:22:20,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:20,693 INFO:     Epoch: 51
2022-11-28 05:22:21,349 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5335914038799026, 'Total loss': 0.5335914038799026} | train loss {'Reaction outcome loss': 0.4729324961420496, 'Total loss': 0.4729324961420496}
2022-11-28 05:22:21,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:21,349 INFO:     Epoch: 52
2022-11-28 05:22:22,008 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5270515182478861, 'Total loss': 0.5270515182478861} | train loss {'Reaction outcome loss': 0.4651009101677037, 'Total loss': 0.4651009101677037}
2022-11-28 05:22:22,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:22,008 INFO:     Epoch: 53
2022-11-28 05:22:22,667 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5310154015367682, 'Total loss': 0.5310154015367682} | train loss {'Reaction outcome loss': 0.45767882994191367, 'Total loss': 0.45767882994191367}
2022-11-28 05:22:22,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:22,667 INFO:     Epoch: 54
2022-11-28 05:22:23,323 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5301273790272799, 'Total loss': 0.5301273790272799} | train loss {'Reaction outcome loss': 0.4689215463303361, 'Total loss': 0.4689215463303361}
2022-11-28 05:22:23,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:23,323 INFO:     Epoch: 55
2022-11-28 05:22:23,981 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5347795019095595, 'Total loss': 0.5347795019095595} | train loss {'Reaction outcome loss': 0.46277979577359885, 'Total loss': 0.46277979577359885}
2022-11-28 05:22:23,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:23,981 INFO:     Epoch: 56
2022-11-28 05:22:24,641 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5499386577443643, 'Total loss': 0.5499386577443643} | train loss {'Reaction outcome loss': 0.47134964213318187, 'Total loss': 0.47134964213318187}
2022-11-28 05:22:24,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:24,642 INFO:     Epoch: 57
2022-11-28 05:22:25,299 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5213570432229475, 'Total loss': 0.5213570432229475} | train loss {'Reaction outcome loss': 0.4763334561214756, 'Total loss': 0.4763334561214756}
2022-11-28 05:22:25,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:25,299 INFO:     Epoch: 58
2022-11-28 05:22:25,957 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5595092661678791, 'Total loss': 0.5595092661678791} | train loss {'Reaction outcome loss': 0.46486791208205436, 'Total loss': 0.46486791208205436}
2022-11-28 05:22:25,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:25,957 INFO:     Epoch: 59
2022-11-28 05:22:26,615 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.53109487620267, 'Total loss': 0.53109487620267} | train loss {'Reaction outcome loss': 0.467726526925197, 'Total loss': 0.467726526925197}
2022-11-28 05:22:26,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:26,615 INFO:     Epoch: 60
2022-11-28 05:22:27,272 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5123921829191121, 'Total loss': 0.5123921829191121} | train loss {'Reaction outcome loss': 0.46275080833961124, 'Total loss': 0.46275080833961124}
2022-11-28 05:22:27,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:27,273 INFO:     Epoch: 61
2022-11-28 05:22:27,929 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5171883620999076, 'Total loss': 0.5171883620999076} | train loss {'Reaction outcome loss': 0.4621030725689552, 'Total loss': 0.4621030725689552}
2022-11-28 05:22:27,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:27,930 INFO:     Epoch: 62
2022-11-28 05:22:28,587 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5330029759894718, 'Total loss': 0.5330029759894718} | train loss {'Reaction outcome loss': 0.4717655049765158, 'Total loss': 0.4717655049765158}
2022-11-28 05:22:28,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:28,587 INFO:     Epoch: 63
2022-11-28 05:22:29,246 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5404755534096197, 'Total loss': 0.5404755534096197} | train loss {'Reaction outcome loss': 0.4658399087278859, 'Total loss': 0.4658399087278859}
2022-11-28 05:22:29,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:29,247 INFO:     Epoch: 64
2022-11-28 05:22:29,904 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5460327562283386, 'Total loss': 0.5460327562283386} | train loss {'Reaction outcome loss': 0.46498005710512036, 'Total loss': 0.46498005710512036}
2022-11-28 05:22:29,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:29,904 INFO:     Epoch: 65
2022-11-28 05:22:30,561 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.547430696812543, 'Total loss': 0.547430696812543} | train loss {'Reaction outcome loss': 0.45610791079507695, 'Total loss': 0.45610791079507695}
2022-11-28 05:22:30,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:30,561 INFO:     Epoch: 66
2022-11-28 05:22:31,221 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5688674727624113, 'Total loss': 0.5688674727624113} | train loss {'Reaction outcome loss': 0.46649377943895126, 'Total loss': 0.46649377943895126}
2022-11-28 05:22:31,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:31,221 INFO:     Epoch: 67
2022-11-28 05:22:31,880 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5245450088246302, 'Total loss': 0.5245450088246302} | train loss {'Reaction outcome loss': 0.473831269482852, 'Total loss': 0.473831269482852}
2022-11-28 05:22:31,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:31,881 INFO:     Epoch: 68
2022-11-28 05:22:32,541 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5318272025747732, 'Total loss': 0.5318272025747732} | train loss {'Reaction outcome loss': 0.45672546197690433, 'Total loss': 0.45672546197690433}
2022-11-28 05:22:32,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:32,542 INFO:     Epoch: 69
2022-11-28 05:22:33,204 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5193285820159045, 'Total loss': 0.5193285820159045} | train loss {'Reaction outcome loss': 0.4608168677457039, 'Total loss': 0.4608168677457039}
2022-11-28 05:22:33,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:33,204 INFO:     Epoch: 70
2022-11-28 05:22:33,864 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5412982929159295, 'Total loss': 0.5412982929159295} | train loss {'Reaction outcome loss': 0.45797462103820524, 'Total loss': 0.45797462103820524}
2022-11-28 05:22:33,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:33,864 INFO:     Epoch: 71
2022-11-28 05:22:34,523 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5408378548242829, 'Total loss': 0.5408378548242829} | train loss {'Reaction outcome loss': 0.4725010255992654, 'Total loss': 0.4725010255992654}
2022-11-28 05:22:34,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:34,523 INFO:     Epoch: 72
2022-11-28 05:22:35,185 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.540674686093222, 'Total loss': 0.540674686093222} | train loss {'Reaction outcome loss': 0.48011399123832765, 'Total loss': 0.48011399123832765}
2022-11-28 05:22:35,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:35,185 INFO:     Epoch: 73
2022-11-28 05:22:35,845 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5291945561766624, 'Total loss': 0.5291945561766624} | train loss {'Reaction outcome loss': 0.4599188124602623, 'Total loss': 0.4599188124602623}
2022-11-28 05:22:35,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:35,845 INFO:     Epoch: 74
2022-11-28 05:22:36,505 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5250378704883836, 'Total loss': 0.5250378704883836} | train loss {'Reaction outcome loss': 0.4659762688335559, 'Total loss': 0.4659762688335559}
2022-11-28 05:22:36,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:36,505 INFO:     Epoch: 75
2022-11-28 05:22:37,164 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.538486743515188, 'Total loss': 0.538486743515188} | train loss {'Reaction outcome loss': 0.4599291893242583, 'Total loss': 0.4599291893242583}
2022-11-28 05:22:37,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:37,164 INFO:     Epoch: 76
2022-11-28 05:22:37,822 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5227212025360628, 'Total loss': 0.5227212025360628} | train loss {'Reaction outcome loss': 0.46665640066845365, 'Total loss': 0.46665640066845365}
2022-11-28 05:22:37,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:37,822 INFO:     Epoch: 77
2022-11-28 05:22:38,477 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5473760210654952, 'Total loss': 0.5473760210654952} | train loss {'Reaction outcome loss': 0.4631515096058609, 'Total loss': 0.4631515096058609}
2022-11-28 05:22:38,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:38,478 INFO:     Epoch: 78
2022-11-28 05:22:39,138 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5575942593542013, 'Total loss': 0.5575942593542013} | train loss {'Reaction outcome loss': 0.464054490722384, 'Total loss': 0.464054490722384}
2022-11-28 05:22:39,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:39,138 INFO:     Epoch: 79
2022-11-28 05:22:39,797 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5243309194391425, 'Total loss': 0.5243309194391425} | train loss {'Reaction outcome loss': 0.47320023939194467, 'Total loss': 0.47320023939194467}
2022-11-28 05:22:39,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:39,797 INFO:     Epoch: 80
2022-11-28 05:22:40,454 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5571677075190977, 'Total loss': 0.5571677075190977} | train loss {'Reaction outcome loss': 0.4656948461103053, 'Total loss': 0.4656948461103053}
2022-11-28 05:22:40,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:40,454 INFO:     Epoch: 81
2022-11-28 05:22:41,113 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.544232618402351, 'Total loss': 0.544232618402351} | train loss {'Reaction outcome loss': 0.47186672494479037, 'Total loss': 0.47186672494479037}
2022-11-28 05:22:41,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:41,114 INFO:     Epoch: 82
2022-11-28 05:22:41,782 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5245331095700915, 'Total loss': 0.5245331095700915} | train loss {'Reaction outcome loss': 0.4655005876568753, 'Total loss': 0.4655005876568753}
2022-11-28 05:22:41,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:41,782 INFO:     Epoch: 83
2022-11-28 05:22:42,449 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5402125831354748, 'Total loss': 0.5402125831354748} | train loss {'Reaction outcome loss': 0.4598486158046645, 'Total loss': 0.4598486158046645}
2022-11-28 05:22:42,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:42,450 INFO:     Epoch: 84
2022-11-28 05:22:43,112 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5191481926224448, 'Total loss': 0.5191481926224448} | train loss {'Reaction outcome loss': 0.4638245912110395, 'Total loss': 0.4638245912110395}
2022-11-28 05:22:43,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:43,112 INFO:     Epoch: 85
2022-11-28 05:22:43,774 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5646698725494471, 'Total loss': 0.5646698725494471} | train loss {'Reaction outcome loss': 0.46270909410739236, 'Total loss': 0.46270909410739236}
2022-11-28 05:22:43,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:43,774 INFO:     Epoch: 86
2022-11-28 05:22:44,434 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5501913516358896, 'Total loss': 0.5501913516358896} | train loss {'Reaction outcome loss': 0.475228327729924, 'Total loss': 0.475228327729924}
2022-11-28 05:22:44,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:44,435 INFO:     Epoch: 87
2022-11-28 05:22:45,091 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5462221499871124, 'Total loss': 0.5462221499871124} | train loss {'Reaction outcome loss': 0.45963381635032685, 'Total loss': 0.45963381635032685}
2022-11-28 05:22:45,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:45,091 INFO:     Epoch: 88
2022-11-28 05:22:45,750 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5384586670181968, 'Total loss': 0.5384586670181968} | train loss {'Reaction outcome loss': 0.46216417381517316, 'Total loss': 0.46216417381517316}
2022-11-28 05:22:45,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:45,750 INFO:     Epoch: 89
2022-11-28 05:22:46,408 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5939149395986036, 'Total loss': 0.5939149395986036} | train loss {'Reaction outcome loss': 0.45816676400513257, 'Total loss': 0.45816676400513257}
2022-11-28 05:22:46,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:46,408 INFO:     Epoch: 90
2022-11-28 05:22:47,067 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5917810784144835, 'Total loss': 0.5917810784144835} | train loss {'Reaction outcome loss': 0.4648336242085044, 'Total loss': 0.4648336242085044}
2022-11-28 05:22:47,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:47,067 INFO:     Epoch: 91
2022-11-28 05:22:47,725 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5475956668907945, 'Total loss': 0.5475956668907945} | train loss {'Reaction outcome loss': 0.4708439701723184, 'Total loss': 0.4708439701723184}
2022-11-28 05:22:47,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:47,726 INFO:     Epoch: 92
2022-11-28 05:22:48,381 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5179898339239034, 'Total loss': 0.5179898339239034} | train loss {'Reaction outcome loss': 0.46433514187693115, 'Total loss': 0.46433514187693115}
2022-11-28 05:22:48,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:48,381 INFO:     Epoch: 93
2022-11-28 05:22:49,034 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5333724245429039, 'Total loss': 0.5333724245429039} | train loss {'Reaction outcome loss': 0.4654633080669743, 'Total loss': 0.4654633080669743}
2022-11-28 05:22:49,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:49,035 INFO:     Epoch: 94
2022-11-28 05:22:49,693 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5340712199156935, 'Total loss': 0.5340712199156935} | train loss {'Reaction outcome loss': 0.45939712448852504, 'Total loss': 0.45939712448852504}
2022-11-28 05:22:49,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:49,693 INFO:     Epoch: 95
2022-11-28 05:22:50,353 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5287865566259081, 'Total loss': 0.5287865566259081} | train loss {'Reaction outcome loss': 0.45752380706882667, 'Total loss': 0.45752380706882667}
2022-11-28 05:22:50,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:50,354 INFO:     Epoch: 96
2022-11-28 05:22:51,014 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.61276229809631, 'Total loss': 0.61276229809631} | train loss {'Reaction outcome loss': 0.4664837397061862, 'Total loss': 0.4664837397061862}
2022-11-28 05:22:51,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:51,014 INFO:     Epoch: 97
2022-11-28 05:22:51,671 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5145202560180967, 'Total loss': 0.5145202560180967} | train loss {'Reaction outcome loss': 0.47020757138005154, 'Total loss': 0.47020757138005154}
2022-11-28 05:22:51,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:51,671 INFO:     Epoch: 98
2022-11-28 05:22:52,327 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5726196538995613, 'Total loss': 0.5726196538995613} | train loss {'Reaction outcome loss': 0.4620136877423839, 'Total loss': 0.4620136877423839}
2022-11-28 05:22:52,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:52,327 INFO:     Epoch: 99
2022-11-28 05:22:52,985 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5368344736370173, 'Total loss': 0.5368344736370173} | train loss {'Reaction outcome loss': 0.4685233799431488, 'Total loss': 0.4685233799431488}
2022-11-28 05:22:52,985 INFO:     Best model found after epoch 33 of 100.
2022-11-28 05:22:52,985 INFO:   Done with stage: TRAINING
2022-11-28 05:22:52,985 INFO:   Starting stage: EVALUATION
2022-11-28 05:22:53,102 INFO:   Done with stage: EVALUATION
2022-11-28 05:22:53,102 INFO:   Leaving out SEQ value Fold_5
2022-11-28 05:22:53,115 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 05:22:53,115 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:22:53,762 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:22:53,762 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:22:53,832 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:22:53,833 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:22:53,833 INFO:     No hyperparam tuning for this model
2022-11-28 05:22:53,833 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:22:53,833 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:22:53,834 INFO:     None feature selector for col prot
2022-11-28 05:22:53,834 INFO:     None feature selector for col prot
2022-11-28 05:22:53,834 INFO:     None feature selector for col prot
2022-11-28 05:22:53,834 INFO:     None feature selector for col chem
2022-11-28 05:22:53,834 INFO:     None feature selector for col chem
2022-11-28 05:22:53,834 INFO:     None feature selector for col chem
2022-11-28 05:22:53,835 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:22:53,835 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:22:53,836 INFO:     Number of params in model 169651
2022-11-28 05:22:53,839 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:22:53,839 INFO:   Starting stage: TRAINING
2022-11-28 05:22:53,890 INFO:     Val loss before train {'Reaction outcome loss': 1.0063180632211945, 'Total loss': 1.0063180632211945}
2022-11-28 05:22:53,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:53,891 INFO:     Epoch: 0
2022-11-28 05:22:54,555 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5841494280506264, 'Total loss': 0.5841494280506264} | train loss {'Reaction outcome loss': 0.6985516749654221, 'Total loss': 0.6985516749654221}
2022-11-28 05:22:54,555 INFO:     Found new best model at epoch 0
2022-11-28 05:22:54,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:54,556 INFO:     Epoch: 1
2022-11-28 05:22:55,216 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5408159929581664, 'Total loss': 0.5408159929581664} | train loss {'Reaction outcome loss': 0.6000977602715676, 'Total loss': 0.6000977602715676}
2022-11-28 05:22:55,216 INFO:     Found new best model at epoch 1
2022-11-28 05:22:55,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:55,217 INFO:     Epoch: 2
2022-11-28 05:22:55,876 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.564171089367433, 'Total loss': 0.564171089367433} | train loss {'Reaction outcome loss': 0.56076853013473, 'Total loss': 0.56076853013473}
2022-11-28 05:22:55,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:55,876 INFO:     Epoch: 3
2022-11-28 05:22:56,537 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5016852617263794, 'Total loss': 0.5016852617263794} | train loss {'Reaction outcome loss': 0.5466746494234332, 'Total loss': 0.5466746494234332}
2022-11-28 05:22:56,537 INFO:     Found new best model at epoch 3
2022-11-28 05:22:56,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:56,538 INFO:     Epoch: 4
2022-11-28 05:22:57,196 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4758226766505025, 'Total loss': 0.4758226766505025} | train loss {'Reaction outcome loss': 0.5339719637444145, 'Total loss': 0.5339719637444145}
2022-11-28 05:22:57,196 INFO:     Found new best model at epoch 4
2022-11-28 05:22:57,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:57,197 INFO:     Epoch: 5
2022-11-28 05:22:57,858 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43825371902097354, 'Total loss': 0.43825371902097354} | train loss {'Reaction outcome loss': 0.5260402711658825, 'Total loss': 0.5260402711658825}
2022-11-28 05:22:57,858 INFO:     Found new best model at epoch 5
2022-11-28 05:22:57,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:57,859 INFO:     Epoch: 6
2022-11-28 05:22:58,519 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4519135491414504, 'Total loss': 0.4519135491414504} | train loss {'Reaction outcome loss': 0.5115709090039797, 'Total loss': 0.5115709090039797}
2022-11-28 05:22:58,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:58,520 INFO:     Epoch: 7
2022-11-28 05:22:59,182 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5371022476730022, 'Total loss': 0.5371022476730022} | train loss {'Reaction outcome loss': 0.5092127124669581, 'Total loss': 0.5092127124669581}
2022-11-28 05:22:59,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:59,183 INFO:     Epoch: 8
2022-11-28 05:22:59,840 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43761884996836836, 'Total loss': 0.43761884996836836} | train loss {'Reaction outcome loss': 0.5071547663042902, 'Total loss': 0.5071547663042902}
2022-11-28 05:22:59,841 INFO:     Found new best model at epoch 8
2022-11-28 05:22:59,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:22:59,842 INFO:     Epoch: 9
2022-11-28 05:23:00,502 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42972018231045117, 'Total loss': 0.42972018231045117} | train loss {'Reaction outcome loss': 0.49227697260843717, 'Total loss': 0.49227697260843717}
2022-11-28 05:23:00,502 INFO:     Found new best model at epoch 9
2022-11-28 05:23:00,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:00,502 INFO:     Epoch: 10
2022-11-28 05:23:01,159 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43256672674959357, 'Total loss': 0.43256672674959357} | train loss {'Reaction outcome loss': 0.4867251715226936, 'Total loss': 0.4867251715226936}
2022-11-28 05:23:01,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:01,160 INFO:     Epoch: 11
2022-11-28 05:23:01,817 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4566345533186739, 'Total loss': 0.4566345533186739} | train loss {'Reaction outcome loss': 0.5008256286382675, 'Total loss': 0.5008256286382675}
2022-11-28 05:23:01,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:01,817 INFO:     Epoch: 12
2022-11-28 05:23:02,476 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.435709554024718, 'Total loss': 0.435709554024718} | train loss {'Reaction outcome loss': 0.4954605689536222, 'Total loss': 0.4954605689536222}
2022-11-28 05:23:02,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:02,477 INFO:     Epoch: 13
2022-11-28 05:23:03,138 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43614809519865294, 'Total loss': 0.43614809519865294} | train loss {'Reaction outcome loss': 0.489162355842378, 'Total loss': 0.489162355842378}
2022-11-28 05:23:03,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:03,138 INFO:     Epoch: 14
2022-11-28 05:23:03,799 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4157561233097857, 'Total loss': 0.4157561233097857} | train loss {'Reaction outcome loss': 0.4844639449105089, 'Total loss': 0.4844639449105089}
2022-11-28 05:23:03,800 INFO:     Found new best model at epoch 14
2022-11-28 05:23:03,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:03,800 INFO:     Epoch: 15
2022-11-28 05:23:04,461 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4825017729943449, 'Total loss': 0.4825017729943449} | train loss {'Reaction outcome loss': 0.48475381551001234, 'Total loss': 0.48475381551001234}
2022-11-28 05:23:04,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:04,461 INFO:     Epoch: 16
2022-11-28 05:23:05,121 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4423757334324447, 'Total loss': 0.4423757334324447} | train loss {'Reaction outcome loss': 0.4917561892073164, 'Total loss': 0.4917561892073164}
2022-11-28 05:23:05,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:05,121 INFO:     Epoch: 17
2022-11-28 05:23:05,782 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4482987705956806, 'Total loss': 0.4482987705956806} | train loss {'Reaction outcome loss': 0.47850911883328123, 'Total loss': 0.47850911883328123}
2022-11-28 05:23:05,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:05,783 INFO:     Epoch: 18
2022-11-28 05:23:06,444 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5410400219261646, 'Total loss': 0.5410400219261646} | train loss {'Reaction outcome loss': 0.49360268348865666, 'Total loss': 0.49360268348865666}
2022-11-28 05:23:06,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:06,444 INFO:     Epoch: 19
2022-11-28 05:23:07,108 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4080627059394663, 'Total loss': 0.4080627059394663} | train loss {'Reaction outcome loss': 0.49711140450316404, 'Total loss': 0.49711140450316404}
2022-11-28 05:23:07,109 INFO:     Found new best model at epoch 19
2022-11-28 05:23:07,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:07,109 INFO:     Epoch: 20
2022-11-28 05:23:07,774 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.437465486201373, 'Total loss': 0.437465486201373} | train loss {'Reaction outcome loss': 0.4762713715494403, 'Total loss': 0.4762713715494403}
2022-11-28 05:23:07,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:07,775 INFO:     Epoch: 21
2022-11-28 05:23:08,436 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43377408012747765, 'Total loss': 0.43377408012747765} | train loss {'Reaction outcome loss': 0.477704020343374, 'Total loss': 0.477704020343374}
2022-11-28 05:23:08,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:08,436 INFO:     Epoch: 22
2022-11-28 05:23:09,099 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45145692269910465, 'Total loss': 0.45145692269910465} | train loss {'Reaction outcome loss': 0.4788209622808796, 'Total loss': 0.4788209622808796}
2022-11-28 05:23:09,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:09,100 INFO:     Epoch: 23
2022-11-28 05:23:09,764 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42363993027670815, 'Total loss': 0.42363993027670815} | train loss {'Reaction outcome loss': 0.47948109093150465, 'Total loss': 0.47948109093150465}
2022-11-28 05:23:09,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:09,764 INFO:     Epoch: 24
2022-11-28 05:23:10,431 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48142876611514523, 'Total loss': 0.48142876611514523} | train loss {'Reaction outcome loss': 0.47636986249371577, 'Total loss': 0.47636986249371577}
2022-11-28 05:23:10,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:10,431 INFO:     Epoch: 25
2022-11-28 05:23:11,099 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4663490441373803, 'Total loss': 0.4663490441373803} | train loss {'Reaction outcome loss': 0.4696804829213301, 'Total loss': 0.4696804829213301}
2022-11-28 05:23:11,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:11,100 INFO:     Epoch: 26
2022-11-28 05:23:11,765 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4204862537709149, 'Total loss': 0.4204862537709149} | train loss {'Reaction outcome loss': 0.47684013795273505, 'Total loss': 0.47684013795273505}
2022-11-28 05:23:11,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:11,766 INFO:     Epoch: 27
2022-11-28 05:23:12,429 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4158896580338478, 'Total loss': 0.4158896580338478} | train loss {'Reaction outcome loss': 0.47111815316715705, 'Total loss': 0.47111815316715705}
2022-11-28 05:23:12,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:12,429 INFO:     Epoch: 28
2022-11-28 05:23:13,091 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41578678583556955, 'Total loss': 0.41578678583556955} | train loss {'Reaction outcome loss': 0.46564248597875296, 'Total loss': 0.46564248597875296}
2022-11-28 05:23:13,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:13,091 INFO:     Epoch: 29
2022-11-28 05:23:13,754 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4529911767352711, 'Total loss': 0.4529911767352711} | train loss {'Reaction outcome loss': 0.475150011932319, 'Total loss': 0.475150011932319}
2022-11-28 05:23:13,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:13,754 INFO:     Epoch: 30
2022-11-28 05:23:14,416 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46534107862548396, 'Total loss': 0.46534107862548396} | train loss {'Reaction outcome loss': 0.47559524988114593, 'Total loss': 0.47559524988114593}
2022-11-28 05:23:14,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:14,416 INFO:     Epoch: 31
2022-11-28 05:23:15,081 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41533392295241356, 'Total loss': 0.41533392295241356} | train loss {'Reaction outcome loss': 0.46505065039101884, 'Total loss': 0.46505065039101884}
2022-11-28 05:23:15,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:15,081 INFO:     Epoch: 32
2022-11-28 05:23:15,744 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4294227734208107, 'Total loss': 0.4294227734208107} | train loss {'Reaction outcome loss': 0.467784869284765, 'Total loss': 0.467784869284765}
2022-11-28 05:23:15,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:15,744 INFO:     Epoch: 33
2022-11-28 05:23:16,409 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.513830551030961, 'Total loss': 0.513830551030961} | train loss {'Reaction outcome loss': 0.46639766667777227, 'Total loss': 0.46639766667777227}
2022-11-28 05:23:16,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:16,409 INFO:     Epoch: 34
2022-11-28 05:23:17,073 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41501518118787895, 'Total loss': 0.41501518118787895} | train loss {'Reaction outcome loss': 0.4759365311759686, 'Total loss': 0.4759365311759686}
2022-11-28 05:23:17,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:17,073 INFO:     Epoch: 35
2022-11-28 05:23:17,737 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4246975003995679, 'Total loss': 0.4246975003995679} | train loss {'Reaction outcome loss': 0.4703384480747368, 'Total loss': 0.4703384480747368}
2022-11-28 05:23:17,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:17,738 INFO:     Epoch: 36
2022-11-28 05:23:18,401 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4367672729898583, 'Total loss': 0.4367672729898583} | train loss {'Reaction outcome loss': 0.47109754039691043, 'Total loss': 0.47109754039691043}
2022-11-28 05:23:18,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:18,402 INFO:     Epoch: 37
2022-11-28 05:23:19,068 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4119330520995639, 'Total loss': 0.4119330520995639} | train loss {'Reaction outcome loss': 0.4800555169703024, 'Total loss': 0.4800555169703024}
2022-11-28 05:23:19,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:19,068 INFO:     Epoch: 38
2022-11-28 05:23:19,733 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41998372836546466, 'Total loss': 0.41998372836546466} | train loss {'Reaction outcome loss': 0.4755605929776242, 'Total loss': 0.4755605929776242}
2022-11-28 05:23:19,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:19,733 INFO:     Epoch: 39
2022-11-28 05:23:20,396 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4153477701951157, 'Total loss': 0.4153477701951157} | train loss {'Reaction outcome loss': 0.4711516817149363, 'Total loss': 0.4711516817149363}
2022-11-28 05:23:20,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:20,396 INFO:     Epoch: 40
2022-11-28 05:23:21,058 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4299327063966881, 'Total loss': 0.4299327063966881} | train loss {'Reaction outcome loss': 0.4655344943527268, 'Total loss': 0.4655344943527268}
2022-11-28 05:23:21,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:21,058 INFO:     Epoch: 41
2022-11-28 05:23:21,723 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4458688633008437, 'Total loss': 0.4458688633008437} | train loss {'Reaction outcome loss': 0.4645819403683608, 'Total loss': 0.4645819403683608}
2022-11-28 05:23:21,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:21,724 INFO:     Epoch: 42
2022-11-28 05:23:22,388 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42278103496540675, 'Total loss': 0.42278103496540675} | train loss {'Reaction outcome loss': 0.4745048540323852, 'Total loss': 0.4745048540323852}
2022-11-28 05:23:22,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:22,388 INFO:     Epoch: 43
2022-11-28 05:23:23,051 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4776593389158899, 'Total loss': 0.4776593389158899} | train loss {'Reaction outcome loss': 0.47329116905266455, 'Total loss': 0.47329116905266455}
2022-11-28 05:23:23,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:23,051 INFO:     Epoch: 44
2022-11-28 05:23:23,717 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42967631498521025, 'Total loss': 0.42967631498521025} | train loss {'Reaction outcome loss': 0.46494827567324465, 'Total loss': 0.46494827567324465}
2022-11-28 05:23:23,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:23,718 INFO:     Epoch: 45
2022-11-28 05:23:24,383 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41398982161825354, 'Total loss': 0.41398982161825354} | train loss {'Reaction outcome loss': 0.46568627033744625, 'Total loss': 0.46568627033744625}
2022-11-28 05:23:24,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:24,383 INFO:     Epoch: 46
2022-11-28 05:23:25,045 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4247745471921834, 'Total loss': 0.4247745471921834} | train loss {'Reaction outcome loss': 0.47432500558343493, 'Total loss': 0.47432500558343493}
2022-11-28 05:23:25,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:25,045 INFO:     Epoch: 47
2022-11-28 05:23:25,711 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4167455106296323, 'Total loss': 0.4167455106296323} | train loss {'Reaction outcome loss': 0.46474726548652173, 'Total loss': 0.46474726548652173}
2022-11-28 05:23:25,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:25,711 INFO:     Epoch: 48
2022-11-28 05:23:26,376 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41970489715987985, 'Total loss': 0.41970489715987985} | train loss {'Reaction outcome loss': 0.47305472309772784, 'Total loss': 0.47305472309772784}
2022-11-28 05:23:26,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:26,376 INFO:     Epoch: 49
2022-11-28 05:23:27,042 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45027638937939296, 'Total loss': 0.45027638937939296} | train loss {'Reaction outcome loss': 0.46924127065218413, 'Total loss': 0.46924127065218413}
2022-11-28 05:23:27,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:27,042 INFO:     Epoch: 50
2022-11-28 05:23:27,711 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4337840036235072, 'Total loss': 0.4337840036235072} | train loss {'Reaction outcome loss': 0.4706377565619434, 'Total loss': 0.4706377565619434}
2022-11-28 05:23:27,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:27,711 INFO:     Epoch: 51
2022-11-28 05:23:28,376 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.418767951767553, 'Total loss': 0.418767951767553} | train loss {'Reaction outcome loss': 0.4715177450297958, 'Total loss': 0.4715177450297958}
2022-11-28 05:23:28,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:28,376 INFO:     Epoch: 52
2022-11-28 05:23:29,040 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4236289012161168, 'Total loss': 0.4236289012161168} | train loss {'Reaction outcome loss': 0.4621451702949248, 'Total loss': 0.4621451702949248}
2022-11-28 05:23:29,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:29,040 INFO:     Epoch: 53
2022-11-28 05:23:29,703 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4790733944286, 'Total loss': 0.4790733944286} | train loss {'Reaction outcome loss': 0.4685929116872158, 'Total loss': 0.4685929116872158}
2022-11-28 05:23:29,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:29,703 INFO:     Epoch: 54
2022-11-28 05:23:30,367 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41900665177540347, 'Total loss': 0.41900665177540347} | train loss {'Reaction outcome loss': 0.4715958694033777, 'Total loss': 0.4715958694033777}
2022-11-28 05:23:30,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:30,367 INFO:     Epoch: 55
2022-11-28 05:23:31,031 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40347402542829514, 'Total loss': 0.40347402542829514} | train loss {'Reaction outcome loss': 0.47178238013434987, 'Total loss': 0.47178238013434987}
2022-11-28 05:23:31,032 INFO:     Found new best model at epoch 55
2022-11-28 05:23:31,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:31,032 INFO:     Epoch: 56
2022-11-28 05:23:31,697 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4427551870996302, 'Total loss': 0.4427551870996302} | train loss {'Reaction outcome loss': 0.4642164023359295, 'Total loss': 0.4642164023359295}
2022-11-28 05:23:31,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:31,698 INFO:     Epoch: 57
2022-11-28 05:23:32,367 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4103749411349947, 'Total loss': 0.4103749411349947} | train loss {'Reaction outcome loss': 0.470281930346238, 'Total loss': 0.470281930346238}
2022-11-28 05:23:32,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:32,367 INFO:     Epoch: 58
2022-11-28 05:23:33,037 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43552982637828047, 'Total loss': 0.43552982637828047} | train loss {'Reaction outcome loss': 0.4721776224702959, 'Total loss': 0.4721776224702959}
2022-11-28 05:23:33,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:33,038 INFO:     Epoch: 59
2022-11-28 05:23:33,706 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4184039238501679, 'Total loss': 0.4184039238501679} | train loss {'Reaction outcome loss': 0.46707899419040333, 'Total loss': 0.46707899419040333}
2022-11-28 05:23:33,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:33,706 INFO:     Epoch: 60
2022-11-28 05:23:34,372 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4284942729229277, 'Total loss': 0.4284942729229277} | train loss {'Reaction outcome loss': 0.46806604339767566, 'Total loss': 0.46806604339767566}
2022-11-28 05:23:34,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:34,372 INFO:     Epoch: 61
2022-11-28 05:23:35,036 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45312595096501435, 'Total loss': 0.45312595096501435} | train loss {'Reaction outcome loss': 0.47079113493805474, 'Total loss': 0.47079113493805474}
2022-11-28 05:23:35,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:35,037 INFO:     Epoch: 62
2022-11-28 05:23:35,703 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4285628291016275, 'Total loss': 0.4285628291016275} | train loss {'Reaction outcome loss': 0.4836444044287735, 'Total loss': 0.4836444044287735}
2022-11-28 05:23:35,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:35,703 INFO:     Epoch: 63
2022-11-28 05:23:36,368 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4369389479133216, 'Total loss': 0.4369389479133216} | train loss {'Reaction outcome loss': 0.4667134570930651, 'Total loss': 0.4667134570930651}
2022-11-28 05:23:36,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:36,369 INFO:     Epoch: 64
2022-11-28 05:23:37,035 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4360876191746105, 'Total loss': 0.4360876191746105} | train loss {'Reaction outcome loss': 0.47089554218628144, 'Total loss': 0.47089554218628144}
2022-11-28 05:23:37,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:37,035 INFO:     Epoch: 65
2022-11-28 05:23:37,702 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42116066813468933, 'Total loss': 0.42116066813468933} | train loss {'Reaction outcome loss': 0.4765455973172477, 'Total loss': 0.4765455973172477}
2022-11-28 05:23:37,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:37,703 INFO:     Epoch: 66
2022-11-28 05:23:38,368 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41464289955117484, 'Total loss': 0.41464289955117484} | train loss {'Reaction outcome loss': 0.4804419114561714, 'Total loss': 0.4804419114561714}
2022-11-28 05:23:38,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:38,368 INFO:     Epoch: 67
2022-11-28 05:23:39,035 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4194444678723812, 'Total loss': 0.4194444678723812} | train loss {'Reaction outcome loss': 0.4727513909279576, 'Total loss': 0.4727513909279576}
2022-11-28 05:23:39,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:39,035 INFO:     Epoch: 68
2022-11-28 05:23:39,701 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4214203584600579, 'Total loss': 0.4214203584600579} | train loss {'Reaction outcome loss': 0.466416404885617, 'Total loss': 0.466416404885617}
2022-11-28 05:23:39,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:39,701 INFO:     Epoch: 69
2022-11-28 05:23:40,366 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42378075928850606, 'Total loss': 0.42378075928850606} | train loss {'Reaction outcome loss': 0.4678079431578668, 'Total loss': 0.4678079431578668}
2022-11-28 05:23:40,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:40,366 INFO:     Epoch: 70
2022-11-28 05:23:41,030 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45100681856274605, 'Total loss': 0.45100681856274605} | train loss {'Reaction outcome loss': 0.47452685538573786, 'Total loss': 0.47452685538573786}
2022-11-28 05:23:41,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:41,030 INFO:     Epoch: 71
2022-11-28 05:23:41,697 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44644134965809906, 'Total loss': 0.44644134965809906} | train loss {'Reaction outcome loss': 0.48005333868598166, 'Total loss': 0.48005333868598166}
2022-11-28 05:23:41,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:41,697 INFO:     Epoch: 72
2022-11-28 05:23:42,365 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44022565030238847, 'Total loss': 0.44022565030238847} | train loss {'Reaction outcome loss': 0.4733282018166322, 'Total loss': 0.4733282018166322}
2022-11-28 05:23:42,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:42,365 INFO:     Epoch: 73
2022-11-28 05:23:43,028 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4276605143465779, 'Total loss': 0.4276605143465779} | train loss {'Reaction outcome loss': 0.47924639731042296, 'Total loss': 0.47924639731042296}
2022-11-28 05:23:43,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:43,029 INFO:     Epoch: 74
2022-11-28 05:23:43,697 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46190296418287535, 'Total loss': 0.46190296418287535} | train loss {'Reaction outcome loss': 0.4703913247175062, 'Total loss': 0.4703913247175062}
2022-11-28 05:23:43,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:43,697 INFO:     Epoch: 75
2022-11-28 05:23:44,365 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4441800012507222, 'Total loss': 0.4441800012507222} | train loss {'Reaction outcome loss': 0.47639445176250056, 'Total loss': 0.47639445176250056}
2022-11-28 05:23:44,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:44,365 INFO:     Epoch: 76
2022-11-28 05:23:45,033 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4250515496188944, 'Total loss': 0.4250515496188944} | train loss {'Reaction outcome loss': 0.4732757286142241, 'Total loss': 0.4732757286142241}
2022-11-28 05:23:45,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:45,033 INFO:     Epoch: 77
2022-11-28 05:23:45,701 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4245166771791198, 'Total loss': 0.4245166771791198} | train loss {'Reaction outcome loss': 0.4760023810964847, 'Total loss': 0.4760023810964847}
2022-11-28 05:23:45,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:45,701 INFO:     Epoch: 78
2022-11-28 05:23:46,365 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40571152994578535, 'Total loss': 0.40571152994578535} | train loss {'Reaction outcome loss': 0.46301337968000034, 'Total loss': 0.46301337968000034}
2022-11-28 05:23:46,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:46,366 INFO:     Epoch: 79
2022-11-28 05:23:47,031 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4134039966897531, 'Total loss': 0.4134039966897531} | train loss {'Reaction outcome loss': 0.48057671886706643, 'Total loss': 0.48057671886706643}
2022-11-28 05:23:47,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:47,032 INFO:     Epoch: 80
2022-11-28 05:23:47,697 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4861393018879674, 'Total loss': 0.4861393018879674} | train loss {'Reaction outcome loss': 0.4812778311099118, 'Total loss': 0.4812778311099118}
2022-11-28 05:23:47,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:47,697 INFO:     Epoch: 81
2022-11-28 05:23:48,363 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41174265640703117, 'Total loss': 0.41174265640703117} | train loss {'Reaction outcome loss': 0.4881007811318525, 'Total loss': 0.4881007811318525}
2022-11-28 05:23:48,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:48,363 INFO:     Epoch: 82
2022-11-28 05:23:49,029 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41093875162980775, 'Total loss': 0.41093875162980775} | train loss {'Reaction outcome loss': 0.47512274292799145, 'Total loss': 0.47512274292799145}
2022-11-28 05:23:49,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:49,030 INFO:     Epoch: 83
2022-11-28 05:23:49,696 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4277265187014233, 'Total loss': 0.4277265187014233} | train loss {'Reaction outcome loss': 0.4831685216923957, 'Total loss': 0.4831685216923957}
2022-11-28 05:23:49,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:49,696 INFO:     Epoch: 84
2022-11-28 05:23:50,364 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.403174278749661, 'Total loss': 0.403174278749661} | train loss {'Reaction outcome loss': 0.4809978875192071, 'Total loss': 0.4809978875192071}
2022-11-28 05:23:50,364 INFO:     Found new best model at epoch 84
2022-11-28 05:23:50,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:50,365 INFO:     Epoch: 85
2022-11-28 05:23:51,033 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4653299701484767, 'Total loss': 0.4653299701484767} | train loss {'Reaction outcome loss': 0.4751307037300788, 'Total loss': 0.4751307037300788}
2022-11-28 05:23:51,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:51,033 INFO:     Epoch: 86
2022-11-28 05:23:51,699 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4020615101537921, 'Total loss': 0.4020615101537921} | train loss {'Reaction outcome loss': 0.4740152270325765, 'Total loss': 0.4740152270325765}
2022-11-28 05:23:51,699 INFO:     Found new best model at epoch 86
2022-11-28 05:23:51,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:51,700 INFO:     Epoch: 87
2022-11-28 05:23:52,363 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4376601451499896, 'Total loss': 0.4376601451499896} | train loss {'Reaction outcome loss': 0.4738456626170077, 'Total loss': 0.4738456626170077}
2022-11-28 05:23:52,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:52,363 INFO:     Epoch: 88
2022-11-28 05:23:53,028 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45518922128460626, 'Total loss': 0.45518922128460626} | train loss {'Reaction outcome loss': 0.47363035769959694, 'Total loss': 0.47363035769959694}
2022-11-28 05:23:53,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:53,028 INFO:     Epoch: 89
2022-11-28 05:23:53,693 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4204567118801854, 'Total loss': 0.4204567118801854} | train loss {'Reaction outcome loss': 0.472704102816852, 'Total loss': 0.472704102816852}
2022-11-28 05:23:53,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:53,693 INFO:     Epoch: 90
2022-11-28 05:23:54,358 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4556240144778382, 'Total loss': 0.4556240144778382} | train loss {'Reaction outcome loss': 0.48374686839609493, 'Total loss': 0.48374686839609493}
2022-11-28 05:23:54,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:54,358 INFO:     Epoch: 91
2022-11-28 05:23:55,021 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44183745167472144, 'Total loss': 0.44183745167472144} | train loss {'Reaction outcome loss': 0.47696567703837806, 'Total loss': 0.47696567703837806}
2022-11-28 05:23:55,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:55,021 INFO:     Epoch: 92
2022-11-28 05:23:55,684 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41798077489842067, 'Total loss': 0.41798077489842067} | train loss {'Reaction outcome loss': 0.47515038844303564, 'Total loss': 0.47515038844303564}
2022-11-28 05:23:55,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:55,684 INFO:     Epoch: 93
2022-11-28 05:23:56,348 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4164848073639653, 'Total loss': 0.4164848073639653} | train loss {'Reaction outcome loss': 0.474592552192298, 'Total loss': 0.474592552192298}
2022-11-28 05:23:56,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:56,348 INFO:     Epoch: 94
2022-11-28 05:23:57,011 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4236148490824483, 'Total loss': 0.4236148490824483} | train loss {'Reaction outcome loss': 0.47705646408231633, 'Total loss': 0.47705646408231633}
2022-11-28 05:23:57,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:57,011 INFO:     Epoch: 95
2022-11-28 05:23:57,675 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4437751756473021, 'Total loss': 0.4437751756473021} | train loss {'Reaction outcome loss': 0.478412492072534, 'Total loss': 0.478412492072534}
2022-11-28 05:23:57,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:57,675 INFO:     Epoch: 96
2022-11-28 05:23:58,336 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4242886081337929, 'Total loss': 0.4242886081337929} | train loss {'Reaction outcome loss': 0.48426648316837034, 'Total loss': 0.48426648316837034}
2022-11-28 05:23:58,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:58,336 INFO:     Epoch: 97
2022-11-28 05:23:59,001 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41198950802738016, 'Total loss': 0.41198950802738016} | train loss {'Reaction outcome loss': 0.47914576928625224, 'Total loss': 0.47914576928625224}
2022-11-28 05:23:59,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:59,002 INFO:     Epoch: 98
2022-11-28 05:23:59,669 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4178974394771186, 'Total loss': 0.4178974394771186} | train loss {'Reaction outcome loss': 0.47331815740840155, 'Total loss': 0.47331815740840155}
2022-11-28 05:23:59,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:23:59,669 INFO:     Epoch: 99
2022-11-28 05:24:00,339 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4119724113155495, 'Total loss': 0.4119724113155495} | train loss {'Reaction outcome loss': 0.48032296437540123, 'Total loss': 0.48032296437540123}
2022-11-28 05:24:00,339 INFO:     Best model found after epoch 87 of 100.
2022-11-28 05:24:00,339 INFO:   Done with stage: TRAINING
2022-11-28 05:24:00,339 INFO:   Starting stage: EVALUATION
2022-11-28 05:24:00,457 INFO:   Done with stage: EVALUATION
2022-11-28 05:24:00,457 INFO:   Leaving out SEQ value Fold_6
2022-11-28 05:24:00,470 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 05:24:00,470 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:24:01,122 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:24:01,123 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:24:01,193 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:24:01,194 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:24:01,194 INFO:     No hyperparam tuning for this model
2022-11-28 05:24:01,194 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:24:01,194 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:24:01,194 INFO:     None feature selector for col prot
2022-11-28 05:24:01,195 INFO:     None feature selector for col prot
2022-11-28 05:24:01,195 INFO:     None feature selector for col prot
2022-11-28 05:24:01,195 INFO:     None feature selector for col chem
2022-11-28 05:24:01,195 INFO:     None feature selector for col chem
2022-11-28 05:24:01,195 INFO:     None feature selector for col chem
2022-11-28 05:24:01,196 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:24:01,196 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:24:01,197 INFO:     Number of params in model 169651
2022-11-28 05:24:01,200 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:24:01,200 INFO:   Starting stage: TRAINING
2022-11-28 05:24:01,252 INFO:     Val loss before train {'Reaction outcome loss': 1.00452513450926, 'Total loss': 1.00452513450926}
2022-11-28 05:24:01,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:01,253 INFO:     Epoch: 0
2022-11-28 05:24:01,918 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6359542120586742, 'Total loss': 0.6359542120586742} | train loss {'Reaction outcome loss': 0.7070249890388265, 'Total loss': 0.7070249890388265}
2022-11-28 05:24:01,918 INFO:     Found new best model at epoch 0
2022-11-28 05:24:01,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:01,919 INFO:     Epoch: 1
2022-11-28 05:24:02,582 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.609149035405029, 'Total loss': 0.609149035405029} | train loss {'Reaction outcome loss': 0.5944331674440669, 'Total loss': 0.5944331674440669}
2022-11-28 05:24:02,583 INFO:     Found new best model at epoch 1
2022-11-28 05:24:02,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:02,583 INFO:     Epoch: 2
2022-11-28 05:24:03,249 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5975749722935937, 'Total loss': 0.5975749722935937} | train loss {'Reaction outcome loss': 0.5694464996517429, 'Total loss': 0.5694464996517429}
2022-11-28 05:24:03,249 INFO:     Found new best model at epoch 2
2022-11-28 05:24:03,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:03,250 INFO:     Epoch: 3
2022-11-28 05:24:03,914 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5400010746988383, 'Total loss': 0.5400010746988383} | train loss {'Reaction outcome loss': 0.5486618585673421, 'Total loss': 0.5486618585673421}
2022-11-28 05:24:03,914 INFO:     Found new best model at epoch 3
2022-11-28 05:24:03,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:03,915 INFO:     Epoch: 4
2022-11-28 05:24:04,583 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.527590982277285, 'Total loss': 0.527590982277285} | train loss {'Reaction outcome loss': 0.5298392481890767, 'Total loss': 0.5298392481890767}
2022-11-28 05:24:04,583 INFO:     Found new best model at epoch 4
2022-11-28 05:24:04,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:04,584 INFO:     Epoch: 5
2022-11-28 05:24:05,248 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5273940285498445, 'Total loss': 0.5273940285498445} | train loss {'Reaction outcome loss': 0.5143648125382088, 'Total loss': 0.5143648125382088}
2022-11-28 05:24:05,248 INFO:     Found new best model at epoch 5
2022-11-28 05:24:05,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:05,249 INFO:     Epoch: 6
2022-11-28 05:24:05,913 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5034286437386816, 'Total loss': 0.5034286437386816} | train loss {'Reaction outcome loss': 0.5078541977775965, 'Total loss': 0.5078541977775965}
2022-11-28 05:24:05,913 INFO:     Found new best model at epoch 6
2022-11-28 05:24:05,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:05,914 INFO:     Epoch: 7
2022-11-28 05:24:06,580 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5151341120627794, 'Total loss': 0.5151341120627794} | train loss {'Reaction outcome loss': 0.5090242975395218, 'Total loss': 0.5090242975395218}
2022-11-28 05:24:06,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:06,580 INFO:     Epoch: 8
2022-11-28 05:24:07,247 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5567580745978788, 'Total loss': 0.5567580745978788} | train loss {'Reaction outcome loss': 0.49617949646976794, 'Total loss': 0.49617949646976794}
2022-11-28 05:24:07,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:07,247 INFO:     Epoch: 9
2022-11-28 05:24:07,916 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4833441749215126, 'Total loss': 0.4833441749215126} | train loss {'Reaction outcome loss': 0.4928663371786898, 'Total loss': 0.4928663371786898}
2022-11-28 05:24:07,916 INFO:     Found new best model at epoch 9
2022-11-28 05:24:07,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:07,917 INFO:     Epoch: 10
2022-11-28 05:24:08,582 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.6927211995829236, 'Total loss': 0.6927211995829236} | train loss {'Reaction outcome loss': 0.48532879587851074, 'Total loss': 0.48532879587851074}
2022-11-28 05:24:08,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:08,582 INFO:     Epoch: 11
2022-11-28 05:24:09,249 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49364175308834424, 'Total loss': 0.49364175308834424} | train loss {'Reaction outcome loss': 0.4996968328590818, 'Total loss': 0.4996968328590818}
2022-11-28 05:24:09,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:09,249 INFO:     Epoch: 12
2022-11-28 05:24:09,914 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.53170686181296, 'Total loss': 0.53170686181296} | train loss {'Reaction outcome loss': 0.48289292371315273, 'Total loss': 0.48289292371315273}
2022-11-28 05:24:09,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:09,915 INFO:     Epoch: 13
2022-11-28 05:24:10,581 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5131582455201582, 'Total loss': 0.5131582455201582} | train loss {'Reaction outcome loss': 0.48209272789569035, 'Total loss': 0.48209272789569035}
2022-11-28 05:24:10,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:10,581 INFO:     Epoch: 14
2022-11-28 05:24:11,244 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5224815976213325, 'Total loss': 0.5224815976213325} | train loss {'Reaction outcome loss': 0.4805201874359658, 'Total loss': 0.4805201874359658}
2022-11-28 05:24:11,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:11,244 INFO:     Epoch: 15
2022-11-28 05:24:11,907 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5059807852587916, 'Total loss': 0.5059807852587916} | train loss {'Reaction outcome loss': 0.4759704484660857, 'Total loss': 0.4759704484660857}
2022-11-28 05:24:11,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:11,907 INFO:     Epoch: 16
2022-11-28 05:24:12,567 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5021977065639063, 'Total loss': 0.5021977065639063} | train loss {'Reaction outcome loss': 0.4700412679018702, 'Total loss': 0.4700412679018702}
2022-11-28 05:24:12,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:12,567 INFO:     Epoch: 17
2022-11-28 05:24:13,225 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4789253303950483, 'Total loss': 0.4789253303950483} | train loss {'Reaction outcome loss': 0.47566276637890076, 'Total loss': 0.47566276637890076}
2022-11-28 05:24:13,225 INFO:     Found new best model at epoch 17
2022-11-28 05:24:13,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:13,225 INFO:     Epoch: 18
2022-11-28 05:24:13,886 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5058683397417719, 'Total loss': 0.5058683397417719} | train loss {'Reaction outcome loss': 0.4767264618202742, 'Total loss': 0.4767264618202742}
2022-11-28 05:24:13,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:13,886 INFO:     Epoch: 19
2022-11-28 05:24:14,546 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4969005198641257, 'Total loss': 0.4969005198641257} | train loss {'Reaction outcome loss': 0.4750882306320947, 'Total loss': 0.4750882306320947}
2022-11-28 05:24:14,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:14,547 INFO:     Epoch: 20
2022-11-28 05:24:15,205 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5196837674487721, 'Total loss': 0.5196837674487721} | train loss {'Reaction outcome loss': 0.47217853953647104, 'Total loss': 0.47217853953647104}
2022-11-28 05:24:15,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:15,206 INFO:     Epoch: 21
2022-11-28 05:24:15,865 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47255091911012476, 'Total loss': 0.47255091911012476} | train loss {'Reaction outcome loss': 0.4677195785197652, 'Total loss': 0.4677195785197652}
2022-11-28 05:24:15,865 INFO:     Found new best model at epoch 21
2022-11-28 05:24:15,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:15,866 INFO:     Epoch: 22
2022-11-28 05:24:16,522 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4706790586086837, 'Total loss': 0.4706790586086837} | train loss {'Reaction outcome loss': 0.4794178128031343, 'Total loss': 0.4794178128031343}
2022-11-28 05:24:16,522 INFO:     Found new best model at epoch 22
2022-11-28 05:24:16,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:16,522 INFO:     Epoch: 23
2022-11-28 05:24:17,179 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5187389085238631, 'Total loss': 0.5187389085238631} | train loss {'Reaction outcome loss': 0.46748939731916195, 'Total loss': 0.46748939731916195}
2022-11-28 05:24:17,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:17,179 INFO:     Epoch: 24
2022-11-28 05:24:17,837 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46382979066534474, 'Total loss': 0.46382979066534474} | train loss {'Reaction outcome loss': 0.47346532891545945, 'Total loss': 0.47346532891545945}
2022-11-28 05:24:17,837 INFO:     Found new best model at epoch 24
2022-11-28 05:24:17,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:17,838 INFO:     Epoch: 25
2022-11-28 05:24:18,494 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4891389334066348, 'Total loss': 0.4891389334066348} | train loss {'Reaction outcome loss': 0.47232538769360977, 'Total loss': 0.47232538769360977}
2022-11-28 05:24:18,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:18,495 INFO:     Epoch: 26
2022-11-28 05:24:19,151 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.598120201040398, 'Total loss': 0.598120201040398} | train loss {'Reaction outcome loss': 0.47016419399801174, 'Total loss': 0.47016419399801174}
2022-11-28 05:24:19,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:19,152 INFO:     Epoch: 27
2022-11-28 05:24:19,814 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46099787848916923, 'Total loss': 0.46099787848916923} | train loss {'Reaction outcome loss': 0.4763673389941333, 'Total loss': 0.4763673389941333}
2022-11-28 05:24:19,814 INFO:     Found new best model at epoch 27
2022-11-28 05:24:19,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:19,815 INFO:     Epoch: 28
2022-11-28 05:24:20,471 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48176047002727335, 'Total loss': 0.48176047002727335} | train loss {'Reaction outcome loss': 0.4754914606993015, 'Total loss': 0.4754914606993015}
2022-11-28 05:24:20,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:20,471 INFO:     Epoch: 29
2022-11-28 05:24:21,128 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5119034952738069, 'Total loss': 0.5119034952738069} | train loss {'Reaction outcome loss': 0.472415893425343, 'Total loss': 0.472415893425343}
2022-11-28 05:24:21,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:21,129 INFO:     Epoch: 30
2022-11-28 05:24:21,787 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48367214744741266, 'Total loss': 0.48367214744741266} | train loss {'Reaction outcome loss': 0.4816889843718726, 'Total loss': 0.4816889843718726}
2022-11-28 05:24:21,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:21,787 INFO:     Epoch: 31
2022-11-28 05:24:22,445 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5917143442414023, 'Total loss': 0.5917143442414023} | train loss {'Reaction outcome loss': 0.48244765123375033, 'Total loss': 0.48244765123375033}
2022-11-28 05:24:22,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:22,445 INFO:     Epoch: 32
2022-11-28 05:24:23,101 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48895383829420264, 'Total loss': 0.48895383829420264} | train loss {'Reaction outcome loss': 0.4827017331050958, 'Total loss': 0.4827017331050958}
2022-11-28 05:24:23,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:23,101 INFO:     Epoch: 33
2022-11-28 05:24:23,757 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5641682161526247, 'Total loss': 0.5641682161526247} | train loss {'Reaction outcome loss': 0.4818668556116853, 'Total loss': 0.4818668556116853}
2022-11-28 05:24:23,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:23,757 INFO:     Epoch: 34
2022-11-28 05:24:24,412 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48781840300018137, 'Total loss': 0.48781840300018137} | train loss {'Reaction outcome loss': 0.48379901559789656, 'Total loss': 0.48379901559789656}
2022-11-28 05:24:24,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:24,412 INFO:     Epoch: 35
2022-11-28 05:24:25,066 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.473251551728357, 'Total loss': 0.473251551728357} | train loss {'Reaction outcome loss': 0.4796184264575904, 'Total loss': 0.4796184264575904}
2022-11-28 05:24:25,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:25,067 INFO:     Epoch: 36
2022-11-28 05:24:25,723 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5096996582367204, 'Total loss': 0.5096996582367204} | train loss {'Reaction outcome loss': 0.47710327695497134, 'Total loss': 0.47710327695497134}
2022-11-28 05:24:25,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:25,723 INFO:     Epoch: 37
2022-11-28 05:24:26,378 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4788836098530076, 'Total loss': 0.4788836098530076} | train loss {'Reaction outcome loss': 0.47662015507084426, 'Total loss': 0.47662015507084426}
2022-11-28 05:24:26,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:26,378 INFO:     Epoch: 38
2022-11-28 05:24:27,030 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.509880777109753, 'Total loss': 0.509880777109753} | train loss {'Reaction outcome loss': 0.4699162642362147, 'Total loss': 0.4699162642362147}
2022-11-28 05:24:27,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:27,030 INFO:     Epoch: 39
2022-11-28 05:24:27,687 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4520946243269877, 'Total loss': 0.4520946243269877} | train loss {'Reaction outcome loss': 0.4733293073681685, 'Total loss': 0.4733293073681685}
2022-11-28 05:24:27,687 INFO:     Found new best model at epoch 39
2022-11-28 05:24:27,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:27,688 INFO:     Epoch: 40
2022-11-28 05:24:28,344 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4786798527294939, 'Total loss': 0.4786798527294939} | train loss {'Reaction outcome loss': 0.4661846215184401, 'Total loss': 0.4661846215184401}
2022-11-28 05:24:28,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:28,345 INFO:     Epoch: 41
2022-11-28 05:24:29,004 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.485071523623033, 'Total loss': 0.485071523623033} | train loss {'Reaction outcome loss': 0.47717565249817573, 'Total loss': 0.47717565249817573}
2022-11-28 05:24:29,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:29,004 INFO:     Epoch: 42
2022-11-28 05:24:29,658 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4957488738000393, 'Total loss': 0.4957488738000393} | train loss {'Reaction outcome loss': 0.47916111283698065, 'Total loss': 0.47916111283698065}
2022-11-28 05:24:29,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:29,658 INFO:     Epoch: 43
2022-11-28 05:24:30,317 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4833669733594764, 'Total loss': 0.4833669733594764} | train loss {'Reaction outcome loss': 0.47860189086497434, 'Total loss': 0.47860189086497434}
2022-11-28 05:24:30,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:30,317 INFO:     Epoch: 44
2022-11-28 05:24:30,975 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4881084195592187, 'Total loss': 0.4881084195592187} | train loss {'Reaction outcome loss': 0.468958648329842, 'Total loss': 0.468958648329842}
2022-11-28 05:24:30,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:30,975 INFO:     Epoch: 45
2022-11-28 05:24:31,639 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5016485310413621, 'Total loss': 0.5016485310413621} | train loss {'Reaction outcome loss': 0.4682121348646488, 'Total loss': 0.4682121348646488}
2022-11-28 05:24:31,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:31,639 INFO:     Epoch: 46
2022-11-28 05:24:32,297 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47477429563348944, 'Total loss': 0.47477429563348944} | train loss {'Reaction outcome loss': 0.4688143086759185, 'Total loss': 0.4688143086759185}
2022-11-28 05:24:32,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:32,297 INFO:     Epoch: 47
2022-11-28 05:24:32,957 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4831096299669959, 'Total loss': 0.4831096299669959} | train loss {'Reaction outcome loss': 0.46410556445237594, 'Total loss': 0.46410556445237594}
2022-11-28 05:24:32,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:32,957 INFO:     Epoch: 48
2022-11-28 05:24:33,619 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4945597398010167, 'Total loss': 0.4945597398010167} | train loss {'Reaction outcome loss': 0.4694851861912229, 'Total loss': 0.4694851861912229}
2022-11-28 05:24:33,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:33,620 INFO:     Epoch: 49
2022-11-28 05:24:34,278 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4662982211871581, 'Total loss': 0.4662982211871581} | train loss {'Reaction outcome loss': 0.4743431373103428, 'Total loss': 0.4743431373103428}
2022-11-28 05:24:34,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:34,278 INFO:     Epoch: 50
2022-11-28 05:24:34,934 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4971516504883766, 'Total loss': 0.4971516504883766} | train loss {'Reaction outcome loss': 0.47408127223673135, 'Total loss': 0.47408127223673135}
2022-11-28 05:24:34,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:34,935 INFO:     Epoch: 51
2022-11-28 05:24:35,592 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4909321740269661, 'Total loss': 0.4909321740269661} | train loss {'Reaction outcome loss': 0.4872084241285015, 'Total loss': 0.4872084241285015}
2022-11-28 05:24:35,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:35,592 INFO:     Epoch: 52
2022-11-28 05:24:36,250 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4879023131321777, 'Total loss': 0.4879023131321777} | train loss {'Reaction outcome loss': 0.4698001641010949, 'Total loss': 0.4698001641010949}
2022-11-28 05:24:36,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:36,251 INFO:     Epoch: 53
2022-11-28 05:24:36,909 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4724428900940852, 'Total loss': 0.4724428900940852} | train loss {'Reaction outcome loss': 0.4700219166250183, 'Total loss': 0.4700219166250183}
2022-11-28 05:24:36,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:36,909 INFO:     Epoch: 54
2022-11-28 05:24:37,567 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4813581962477077, 'Total loss': 0.4813581962477077} | train loss {'Reaction outcome loss': 0.46328075096267557, 'Total loss': 0.46328075096267557}
2022-11-28 05:24:37,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:37,567 INFO:     Epoch: 55
2022-11-28 05:24:38,223 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4664116508581422, 'Total loss': 0.4664116508581422} | train loss {'Reaction outcome loss': 0.4740102747794588, 'Total loss': 0.4740102747794588}
2022-11-28 05:24:38,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:38,223 INFO:     Epoch: 56
2022-11-28 05:24:38,880 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47396635602821, 'Total loss': 0.47396635602821} | train loss {'Reaction outcome loss': 0.4652671906267583, 'Total loss': 0.4652671906267583}
2022-11-28 05:24:38,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:38,881 INFO:     Epoch: 57
2022-11-28 05:24:39,539 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4895688776265491, 'Total loss': 0.4895688776265491} | train loss {'Reaction outcome loss': 0.4657867115880796, 'Total loss': 0.4657867115880796}
2022-11-28 05:24:39,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:39,539 INFO:     Epoch: 58
2022-11-28 05:24:40,200 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47569775784557516, 'Total loss': 0.47569775784557516} | train loss {'Reaction outcome loss': 0.47695656651668705, 'Total loss': 0.47695656651668705}
2022-11-28 05:24:40,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:40,201 INFO:     Epoch: 59
2022-11-28 05:24:40,859 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46781268681992183, 'Total loss': 0.46781268681992183} | train loss {'Reaction outcome loss': 0.47292417661863784, 'Total loss': 0.47292417661863784}
2022-11-28 05:24:40,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:40,859 INFO:     Epoch: 60
2022-11-28 05:24:41,518 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49690399623729964, 'Total loss': 0.49690399623729964} | train loss {'Reaction outcome loss': 0.4698865023943094, 'Total loss': 0.4698865023943094}
2022-11-28 05:24:41,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:41,518 INFO:     Epoch: 61
2022-11-28 05:24:42,177 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49850502474741504, 'Total loss': 0.49850502474741504} | train loss {'Reaction outcome loss': 0.47579967432659165, 'Total loss': 0.47579967432659165}
2022-11-28 05:24:42,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:42,177 INFO:     Epoch: 62
2022-11-28 05:24:42,836 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48766023462468927, 'Total loss': 0.48766023462468927} | train loss {'Reaction outcome loss': 0.4709708957898955, 'Total loss': 0.4709708957898955}
2022-11-28 05:24:42,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:42,836 INFO:     Epoch: 63
2022-11-28 05:24:43,495 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46304410391233186, 'Total loss': 0.46304410391233186} | train loss {'Reaction outcome loss': 0.4783278486506659, 'Total loss': 0.4783278486506659}
2022-11-28 05:24:43,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:43,495 INFO:     Epoch: 64
2022-11-28 05:24:44,151 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5344793403690512, 'Total loss': 0.5344793403690512} | train loss {'Reaction outcome loss': 0.47429242983520753, 'Total loss': 0.47429242983520753}
2022-11-28 05:24:44,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:44,151 INFO:     Epoch: 65
2022-11-28 05:24:44,808 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4791803393851627, 'Total loss': 0.4791803393851627} | train loss {'Reaction outcome loss': 0.4824905785758365, 'Total loss': 0.4824905785758365}
2022-11-28 05:24:44,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:44,808 INFO:     Epoch: 66
2022-11-28 05:24:45,463 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4798714816570282, 'Total loss': 0.4798714816570282} | train loss {'Reaction outcome loss': 0.45880916642273967, 'Total loss': 0.45880916642273967}
2022-11-28 05:24:45,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:45,464 INFO:     Epoch: 67
2022-11-28 05:24:46,119 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47698506577448413, 'Total loss': 0.47698506577448413} | train loss {'Reaction outcome loss': 0.4622230198581209, 'Total loss': 0.4622230198581209}
2022-11-28 05:24:46,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:46,119 INFO:     Epoch: 68
2022-11-28 05:24:46,776 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4907492202791301, 'Total loss': 0.4907492202791301} | train loss {'Reaction outcome loss': 0.4722786650649811, 'Total loss': 0.4722786650649811}
2022-11-28 05:24:46,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:46,776 INFO:     Epoch: 69
2022-11-28 05:24:47,432 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4674267541955818, 'Total loss': 0.4674267541955818} | train loss {'Reaction outcome loss': 0.46745132621724594, 'Total loss': 0.46745132621724594}
2022-11-28 05:24:47,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:47,432 INFO:     Epoch: 70
2022-11-28 05:24:48,089 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45835451815616, 'Total loss': 0.45835451815616} | train loss {'Reaction outcome loss': 0.4732071158253712, 'Total loss': 0.4732071158253712}
2022-11-28 05:24:48,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:48,089 INFO:     Epoch: 71
2022-11-28 05:24:48,747 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5443498065525835, 'Total loss': 0.5443498065525835} | train loss {'Reaction outcome loss': 0.4820932442480736, 'Total loss': 0.4820932442480736}
2022-11-28 05:24:48,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:48,748 INFO:     Epoch: 72
2022-11-28 05:24:49,404 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4662976488471031, 'Total loss': 0.4662976488471031} | train loss {'Reaction outcome loss': 0.47807723814659275, 'Total loss': 0.47807723814659275}
2022-11-28 05:24:49,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:49,405 INFO:     Epoch: 73
2022-11-28 05:24:50,060 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47876317358829756, 'Total loss': 0.47876317358829756} | train loss {'Reaction outcome loss': 0.4790639877620979, 'Total loss': 0.4790639877620979}
2022-11-28 05:24:50,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:50,060 INFO:     Epoch: 74
2022-11-28 05:24:50,716 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4525252658535134, 'Total loss': 0.4525252658535134} | train loss {'Reaction outcome loss': 0.47937292928396447, 'Total loss': 0.47937292928396447}
2022-11-28 05:24:50,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:50,716 INFO:     Epoch: 75
2022-11-28 05:24:51,371 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.509381946853616, 'Total loss': 0.509381946853616} | train loss {'Reaction outcome loss': 0.4827520438896017, 'Total loss': 0.4827520438896017}
2022-11-28 05:24:51,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:51,371 INFO:     Epoch: 76
2022-11-28 05:24:52,030 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4851364175027067, 'Total loss': 0.4851364175027067} | train loss {'Reaction outcome loss': 0.4805918881888332, 'Total loss': 0.4805918881888332}
2022-11-28 05:24:52,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:52,031 INFO:     Epoch: 77
2022-11-28 05:24:52,688 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4787422821603038, 'Total loss': 0.4787422821603038} | train loss {'Reaction outcome loss': 0.4715948816434092, 'Total loss': 0.4715948816434092}
2022-11-28 05:24:52,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:52,688 INFO:     Epoch: 78
2022-11-28 05:24:53,344 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45851558074355125, 'Total loss': 0.45851558074355125} | train loss {'Reaction outcome loss': 0.4586783753715546, 'Total loss': 0.4586783753715546}
2022-11-28 05:24:53,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:53,345 INFO:     Epoch: 79
2022-11-28 05:24:54,000 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5105184933001344, 'Total loss': 0.5105184933001344} | train loss {'Reaction outcome loss': 0.46504001409901297, 'Total loss': 0.46504001409901297}
2022-11-28 05:24:54,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:54,001 INFO:     Epoch: 80
2022-11-28 05:24:54,660 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48108095066113904, 'Total loss': 0.48108095066113904} | train loss {'Reaction outcome loss': 0.4584391707712822, 'Total loss': 0.4584391707712822}
2022-11-28 05:24:54,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:54,660 INFO:     Epoch: 81
2022-11-28 05:24:55,315 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4783164489675652, 'Total loss': 0.4783164489675652} | train loss {'Reaction outcome loss': 0.46866270742918315, 'Total loss': 0.46866270742918315}
2022-11-28 05:24:55,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:55,315 INFO:     Epoch: 82
2022-11-28 05:24:55,969 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4742429046468301, 'Total loss': 0.4742429046468301} | train loss {'Reaction outcome loss': 0.46637665894380226, 'Total loss': 0.46637665894380226}
2022-11-28 05:24:55,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:55,969 INFO:     Epoch: 83
2022-11-28 05:24:56,626 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5070629380643368, 'Total loss': 0.5070629380643368} | train loss {'Reaction outcome loss': 0.4693030559340952, 'Total loss': 0.4693030559340952}
2022-11-28 05:24:56,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:56,626 INFO:     Epoch: 84
2022-11-28 05:24:57,285 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4820220964876088, 'Total loss': 0.4820220964876088} | train loss {'Reaction outcome loss': 0.4669185057282448, 'Total loss': 0.4669185057282448}
2022-11-28 05:24:57,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:57,286 INFO:     Epoch: 85
2022-11-28 05:24:57,942 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5463895628398115, 'Total loss': 0.5463895628398115} | train loss {'Reaction outcome loss': 0.4718835020234228, 'Total loss': 0.4718835020234228}
2022-11-28 05:24:57,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:57,942 INFO:     Epoch: 86
2022-11-28 05:24:58,598 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49131122400814836, 'Total loss': 0.49131122400814836} | train loss {'Reaction outcome loss': 0.4695047396895012, 'Total loss': 0.4695047396895012}
2022-11-28 05:24:58,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:58,598 INFO:     Epoch: 87
2022-11-28 05:24:59,256 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5286348308013245, 'Total loss': 0.5286348308013245} | train loss {'Reaction outcome loss': 0.4616485586171208, 'Total loss': 0.4616485586171208}
2022-11-28 05:24:59,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:59,256 INFO:     Epoch: 88
2022-11-28 05:24:59,915 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4617601528086446, 'Total loss': 0.4617601528086446} | train loss {'Reaction outcome loss': 0.4688514832422318, 'Total loss': 0.4688514832422318}
2022-11-28 05:24:59,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:24:59,916 INFO:     Epoch: 89
2022-11-28 05:25:00,573 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4698786356232383, 'Total loss': 0.4698786356232383} | train loss {'Reaction outcome loss': 0.4622698614170194, 'Total loss': 0.4622698614170194}
2022-11-28 05:25:00,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:00,573 INFO:     Epoch: 90
2022-11-28 05:25:01,236 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.499658346853473, 'Total loss': 0.499658346853473} | train loss {'Reaction outcome loss': 0.46220808406831765, 'Total loss': 0.46220808406831765}
2022-11-28 05:25:01,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:01,236 INFO:     Epoch: 91
2022-11-28 05:25:01,892 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46861543506383896, 'Total loss': 0.46861543506383896} | train loss {'Reaction outcome loss': 0.4631690644726972, 'Total loss': 0.4631690644726972}
2022-11-28 05:25:01,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:01,892 INFO:     Epoch: 92
2022-11-28 05:25:02,546 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47299913452430203, 'Total loss': 0.47299913452430203} | train loss {'Reaction outcome loss': 0.4708370784154305, 'Total loss': 0.4708370784154305}
2022-11-28 05:25:02,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:02,546 INFO:     Epoch: 93
2022-11-28 05:25:03,202 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4446833719584075, 'Total loss': 0.4446833719584075} | train loss {'Reaction outcome loss': 0.47204401709048854, 'Total loss': 0.47204401709048854}
2022-11-28 05:25:03,202 INFO:     Found new best model at epoch 93
2022-11-28 05:25:03,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:03,203 INFO:     Epoch: 94
2022-11-28 05:25:03,861 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48214024474675005, 'Total loss': 0.48214024474675005} | train loss {'Reaction outcome loss': 0.4636687976383578, 'Total loss': 0.4636687976383578}
2022-11-28 05:25:03,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:03,861 INFO:     Epoch: 95
2022-11-28 05:25:04,518 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47653691131960263, 'Total loss': 0.47653691131960263} | train loss {'Reaction outcome loss': 0.46074599335309463, 'Total loss': 0.46074599335309463}
2022-11-28 05:25:04,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:04,519 INFO:     Epoch: 96
2022-11-28 05:25:05,179 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49825039438226004, 'Total loss': 0.49825039438226004} | train loss {'Reaction outcome loss': 0.464080444774647, 'Total loss': 0.464080444774647}
2022-11-28 05:25:05,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:05,179 INFO:     Epoch: 97
2022-11-28 05:25:05,835 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48868498985062947, 'Total loss': 0.48868498985062947} | train loss {'Reaction outcome loss': 0.4626599726406669, 'Total loss': 0.4626599726406669}
2022-11-28 05:25:05,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:05,835 INFO:     Epoch: 98
2022-11-28 05:25:06,490 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4927761104296554, 'Total loss': 0.4927761104296554} | train loss {'Reaction outcome loss': 0.4676029591063256, 'Total loss': 0.4676029591063256}
2022-11-28 05:25:06,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:06,490 INFO:     Epoch: 99
2022-11-28 05:25:07,145 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5204344679686156, 'Total loss': 0.5204344679686156} | train loss {'Reaction outcome loss': 0.46084349092684296, 'Total loss': 0.46084349092684296}
2022-11-28 05:25:07,145 INFO:     Best model found after epoch 94 of 100.
2022-11-28 05:25:07,145 INFO:   Done with stage: TRAINING
2022-11-28 05:25:07,145 INFO:   Starting stage: EVALUATION
2022-11-28 05:25:07,262 INFO:   Done with stage: EVALUATION
2022-11-28 05:25:07,263 INFO:   Leaving out SEQ value Fold_7
2022-11-28 05:25:07,275 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 05:25:07,275 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:25:07,922 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:25:07,922 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:25:07,994 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:25:07,994 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:25:07,994 INFO:     No hyperparam tuning for this model
2022-11-28 05:25:07,994 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:25:07,994 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:25:07,995 INFO:     None feature selector for col prot
2022-11-28 05:25:07,995 INFO:     None feature selector for col prot
2022-11-28 05:25:07,995 INFO:     None feature selector for col prot
2022-11-28 05:25:07,996 INFO:     None feature selector for col chem
2022-11-28 05:25:07,996 INFO:     None feature selector for col chem
2022-11-28 05:25:07,996 INFO:     None feature selector for col chem
2022-11-28 05:25:07,996 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:25:07,996 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:25:07,997 INFO:     Number of params in model 169651
2022-11-28 05:25:08,000 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:25:08,001 INFO:   Starting stage: TRAINING
2022-11-28 05:25:08,051 INFO:     Val loss before train {'Reaction outcome loss': 1.0046021721579812, 'Total loss': 1.0046021721579812}
2022-11-28 05:25:08,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:08,051 INFO:     Epoch: 0
2022-11-28 05:25:08,710 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.609049370343035, 'Total loss': 0.609049370343035} | train loss {'Reaction outcome loss': 0.6815058760825665, 'Total loss': 0.6815058760825665}
2022-11-28 05:25:08,710 INFO:     Found new best model at epoch 0
2022-11-28 05:25:08,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:08,711 INFO:     Epoch: 1
2022-11-28 05:25:09,369 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5744873021136631, 'Total loss': 0.5744873021136631} | train loss {'Reaction outcome loss': 0.5804219214065421, 'Total loss': 0.5804219214065421}
2022-11-28 05:25:09,369 INFO:     Found new best model at epoch 1
2022-11-28 05:25:09,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:09,370 INFO:     Epoch: 2
2022-11-28 05:25:10,033 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5671239623969252, 'Total loss': 0.5671239623969252} | train loss {'Reaction outcome loss': 0.556717307937722, 'Total loss': 0.556717307937722}
2022-11-28 05:25:10,033 INFO:     Found new best model at epoch 2
2022-11-28 05:25:10,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:10,034 INFO:     Epoch: 3
2022-11-28 05:25:10,691 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5251961966807192, 'Total loss': 0.5251961966807192} | train loss {'Reaction outcome loss': 0.5265728633009619, 'Total loss': 0.5265728633009619}
2022-11-28 05:25:10,691 INFO:     Found new best model at epoch 3
2022-11-28 05:25:10,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:10,692 INFO:     Epoch: 4
2022-11-28 05:25:11,353 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5435292117974975, 'Total loss': 0.5435292117974975} | train loss {'Reaction outcome loss': 0.524020446945102, 'Total loss': 0.524020446945102}
2022-11-28 05:25:11,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:11,353 INFO:     Epoch: 5
2022-11-28 05:25:12,015 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5325939933007414, 'Total loss': 0.5325939933007414} | train loss {'Reaction outcome loss': 0.5156806669528445, 'Total loss': 0.5156806669528445}
2022-11-28 05:25:12,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:12,016 INFO:     Epoch: 6
2022-11-28 05:25:12,675 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5100920823487368, 'Total loss': 0.5100920823487368} | train loss {'Reaction outcome loss': 0.5027839739115969, 'Total loss': 0.5027839739115969}
2022-11-28 05:25:12,675 INFO:     Found new best model at epoch 6
2022-11-28 05:25:12,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:12,676 INFO:     Epoch: 7
2022-11-28 05:25:13,333 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5779387314211238, 'Total loss': 0.5779387314211238} | train loss {'Reaction outcome loss': 0.49328859781305634, 'Total loss': 0.49328859781305634}
2022-11-28 05:25:13,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:13,333 INFO:     Epoch: 8
2022-11-28 05:25:13,991 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.524982806972482, 'Total loss': 0.524982806972482} | train loss {'Reaction outcome loss': 0.4974078948218976, 'Total loss': 0.4974078948218976}
2022-11-28 05:25:13,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:13,992 INFO:     Epoch: 9
2022-11-28 05:25:14,650 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.543850184164264, 'Total loss': 0.543850184164264} | train loss {'Reaction outcome loss': 0.4866380717365011, 'Total loss': 0.4866380717365011}
2022-11-28 05:25:14,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:14,650 INFO:     Epoch: 10
2022-11-28 05:25:15,309 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5062531822107055, 'Total loss': 0.5062531822107055} | train loss {'Reaction outcome loss': 0.4889537776189466, 'Total loss': 0.4889537776189466}
2022-11-28 05:25:15,309 INFO:     Found new best model at epoch 10
2022-11-28 05:25:15,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:15,309 INFO:     Epoch: 11
2022-11-28 05:25:15,976 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5847341228615154, 'Total loss': 0.5847341228615154} | train loss {'Reaction outcome loss': 0.4714031065363557, 'Total loss': 0.4714031065363557}
2022-11-28 05:25:15,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:15,977 INFO:     Epoch: 12
2022-11-28 05:25:16,648 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5076177252287214, 'Total loss': 0.5076177252287214} | train loss {'Reaction outcome loss': 0.4788458204017051, 'Total loss': 0.4788458204017051}
2022-11-28 05:25:16,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:16,648 INFO:     Epoch: 13
2022-11-28 05:25:17,319 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5385824353857473, 'Total loss': 0.5385824353857473} | train loss {'Reaction outcome loss': 0.4765213012935654, 'Total loss': 0.4765213012935654}
2022-11-28 05:25:17,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:17,319 INFO:     Epoch: 14
2022-11-28 05:25:17,990 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5797515938227827, 'Total loss': 0.5797515938227827} | train loss {'Reaction outcome loss': 0.4666116303734241, 'Total loss': 0.4666116303734241}
2022-11-28 05:25:17,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:17,990 INFO:     Epoch: 15
2022-11-28 05:25:18,658 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5432120145044543, 'Total loss': 0.5432120145044543} | train loss {'Reaction outcome loss': 0.47493408097615164, 'Total loss': 0.47493408097615164}
2022-11-28 05:25:18,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:18,659 INFO:     Epoch: 16
2022-11-28 05:25:19,329 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.494165897030722, 'Total loss': 0.494165897030722} | train loss {'Reaction outcome loss': 0.46885606412205005, 'Total loss': 0.46885606412205005}
2022-11-28 05:25:19,329 INFO:     Found new best model at epoch 16
2022-11-28 05:25:19,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:19,330 INFO:     Epoch: 17
2022-11-28 05:25:19,997 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4909901348027316, 'Total loss': 0.4909901348027316} | train loss {'Reaction outcome loss': 0.4663797357390004, 'Total loss': 0.4663797357390004}
2022-11-28 05:25:19,998 INFO:     Found new best model at epoch 17
2022-11-28 05:25:19,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:19,998 INFO:     Epoch: 18
2022-11-28 05:25:20,668 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4894677143205296, 'Total loss': 0.4894677143205296} | train loss {'Reaction outcome loss': 0.465846348193384, 'Total loss': 0.465846348193384}
2022-11-28 05:25:20,668 INFO:     Found new best model at epoch 18
2022-11-28 05:25:20,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:20,669 INFO:     Epoch: 19
2022-11-28 05:25:21,344 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4850930002602664, 'Total loss': 0.4850930002602664} | train loss {'Reaction outcome loss': 0.4728452822854442, 'Total loss': 0.4728452822854442}
2022-11-28 05:25:21,344 INFO:     Found new best model at epoch 19
2022-11-28 05:25:21,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:21,344 INFO:     Epoch: 20
2022-11-28 05:25:22,016 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5067985003644769, 'Total loss': 0.5067985003644769} | train loss {'Reaction outcome loss': 0.46750118769705296, 'Total loss': 0.46750118769705296}
2022-11-28 05:25:22,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:22,016 INFO:     Epoch: 21
2022-11-28 05:25:22,689 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5020280998538841, 'Total loss': 0.5020280998538841} | train loss {'Reaction outcome loss': 0.46370217432418176, 'Total loss': 0.46370217432418176}
2022-11-28 05:25:22,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:22,689 INFO:     Epoch: 22
2022-11-28 05:25:23,358 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49745788222009485, 'Total loss': 0.49745788222009485} | train loss {'Reaction outcome loss': 0.4547730277502729, 'Total loss': 0.4547730277502729}
2022-11-28 05:25:23,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:23,358 INFO:     Epoch: 23
2022-11-28 05:25:24,028 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4956002651967786, 'Total loss': 0.4956002651967786} | train loss {'Reaction outcome loss': 0.4626648750516676, 'Total loss': 0.4626648750516676}
2022-11-28 05:25:24,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:24,028 INFO:     Epoch: 24
2022-11-28 05:25:24,703 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5262781066650694, 'Total loss': 0.5262781066650694} | train loss {'Reaction outcome loss': 0.46673083257290626, 'Total loss': 0.46673083257290626}
2022-11-28 05:25:24,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:24,703 INFO:     Epoch: 25
2022-11-28 05:25:25,372 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4901048249819062, 'Total loss': 0.4901048249819062} | train loss {'Reaction outcome loss': 0.4651050287028474, 'Total loss': 0.4651050287028474}
2022-11-28 05:25:25,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:25,372 INFO:     Epoch: 26
2022-11-28 05:25:26,043 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5152807276357304, 'Total loss': 0.5152807276357304} | train loss {'Reaction outcome loss': 0.4614115847695258, 'Total loss': 0.4614115847695258}
2022-11-28 05:25:26,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:26,044 INFO:     Epoch: 27
2022-11-28 05:25:26,715 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4903490021824837, 'Total loss': 0.4903490021824837} | train loss {'Reaction outcome loss': 0.46238830406218767, 'Total loss': 0.46238830406218767}
2022-11-28 05:25:26,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:26,715 INFO:     Epoch: 28
2022-11-28 05:25:27,386 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.489301399751143, 'Total loss': 0.489301399751143} | train loss {'Reaction outcome loss': 0.4570077667914091, 'Total loss': 0.4570077667914091}
2022-11-28 05:25:27,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:27,387 INFO:     Epoch: 29
2022-11-28 05:25:28,057 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49526330625469034, 'Total loss': 0.49526330625469034} | train loss {'Reaction outcome loss': 0.4603879208406133, 'Total loss': 0.4603879208406133}
2022-11-28 05:25:28,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:28,057 INFO:     Epoch: 30
2022-11-28 05:25:28,728 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5023476708341729, 'Total loss': 0.5023476708341729} | train loss {'Reaction outcome loss': 0.46375306004718425, 'Total loss': 0.46375306004718425}
2022-11-28 05:25:28,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:28,729 INFO:     Epoch: 31
2022-11-28 05:25:29,402 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49050036614591425, 'Total loss': 0.49050036614591425} | train loss {'Reaction outcome loss': 0.4596543187696126, 'Total loss': 0.4596543187696126}
2022-11-28 05:25:29,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:29,402 INFO:     Epoch: 32
2022-11-28 05:25:30,074 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5023389296098189, 'Total loss': 0.5023389296098189} | train loss {'Reaction outcome loss': 0.4524212122083672, 'Total loss': 0.4524212122083672}
2022-11-28 05:25:30,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:30,074 INFO:     Epoch: 33
2022-11-28 05:25:30,744 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.6565761528909206, 'Total loss': 0.6565761528909206} | train loss {'Reaction outcome loss': 0.45729285346404197, 'Total loss': 0.45729285346404197}
2022-11-28 05:25:30,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:30,745 INFO:     Epoch: 34
2022-11-28 05:25:31,416 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47788144851272757, 'Total loss': 0.47788144851272757} | train loss {'Reaction outcome loss': 0.4774647756449638, 'Total loss': 0.4774647756449638}
2022-11-28 05:25:31,416 INFO:     Found new best model at epoch 34
2022-11-28 05:25:31,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:31,416 INFO:     Epoch: 35
2022-11-28 05:25:32,091 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48932363804091106, 'Total loss': 0.48932363804091106} | train loss {'Reaction outcome loss': 0.4614919466116736, 'Total loss': 0.4614919466116736}
2022-11-28 05:25:32,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:32,091 INFO:     Epoch: 36
2022-11-28 05:25:32,767 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4999830130149018, 'Total loss': 0.4999830130149018} | train loss {'Reaction outcome loss': 0.4654308578239814, 'Total loss': 0.4654308578239814}
2022-11-28 05:25:32,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:32,767 INFO:     Epoch: 37
2022-11-28 05:25:33,439 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4850159890272401, 'Total loss': 0.4850159890272401} | train loss {'Reaction outcome loss': 0.46121073207787927, 'Total loss': 0.46121073207787927}
2022-11-28 05:25:33,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:33,439 INFO:     Epoch: 38
2022-11-28 05:25:34,110 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47486294331875717, 'Total loss': 0.47486294331875717} | train loss {'Reaction outcome loss': 0.4629755725543345, 'Total loss': 0.4629755725543345}
2022-11-28 05:25:34,111 INFO:     Found new best model at epoch 38
2022-11-28 05:25:34,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:34,112 INFO:     Epoch: 39
2022-11-28 05:25:34,779 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5001539997756481, 'Total loss': 0.5001539997756481} | train loss {'Reaction outcome loss': 0.45778085453616035, 'Total loss': 0.45778085453616035}
2022-11-28 05:25:34,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:34,780 INFO:     Epoch: 40
2022-11-28 05:25:35,448 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46420621093023906, 'Total loss': 0.46420621093023906} | train loss {'Reaction outcome loss': 0.44822433293466607, 'Total loss': 0.44822433293466607}
2022-11-28 05:25:35,448 INFO:     Found new best model at epoch 40
2022-11-28 05:25:35,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:35,449 INFO:     Epoch: 41
2022-11-28 05:25:36,122 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47018506174737756, 'Total loss': 0.47018506174737756} | train loss {'Reaction outcome loss': 0.46498104040661165, 'Total loss': 0.46498104040661165}
2022-11-28 05:25:36,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:36,122 INFO:     Epoch: 42
2022-11-28 05:25:36,792 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48813699050383136, 'Total loss': 0.48813699050383136} | train loss {'Reaction outcome loss': 0.4506477259940678, 'Total loss': 0.4506477259940678}
2022-11-28 05:25:36,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:36,792 INFO:     Epoch: 43
2022-11-28 05:25:37,461 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46550089662725275, 'Total loss': 0.46550089662725275} | train loss {'Reaction outcome loss': 0.45972280715021396, 'Total loss': 0.45972280715021396}
2022-11-28 05:25:37,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:37,461 INFO:     Epoch: 44
2022-11-28 05:25:38,133 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4932245889847929, 'Total loss': 0.4932245889847929} | train loss {'Reaction outcome loss': 0.458425662900892, 'Total loss': 0.458425662900892}
2022-11-28 05:25:38,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:38,133 INFO:     Epoch: 45
2022-11-28 05:25:38,802 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4831947667354887, 'Total loss': 0.4831947667354887} | train loss {'Reaction outcome loss': 0.45774972877435144, 'Total loss': 0.45774972877435144}
2022-11-28 05:25:38,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:38,803 INFO:     Epoch: 46
2022-11-28 05:25:39,474 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47975926439870487, 'Total loss': 0.47975926439870487} | train loss {'Reaction outcome loss': 0.45082557664042516, 'Total loss': 0.45082557664042516}
2022-11-28 05:25:39,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:39,474 INFO:     Epoch: 47
2022-11-28 05:25:40,146 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48184785517779266, 'Total loss': 0.48184785517779266} | train loss {'Reaction outcome loss': 0.45512835176721694, 'Total loss': 0.45512835176721694}
2022-11-28 05:25:40,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:40,147 INFO:     Epoch: 48
2022-11-28 05:25:40,815 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5092874440279874, 'Total loss': 0.5092874440279874} | train loss {'Reaction outcome loss': 0.45203748201170274, 'Total loss': 0.45203748201170274}
2022-11-28 05:25:40,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:40,816 INFO:     Epoch: 49
2022-11-28 05:25:41,481 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49347030879421666, 'Total loss': 0.49347030879421666} | train loss {'Reaction outcome loss': 0.45497123677764206, 'Total loss': 0.45497123677764206}
2022-11-28 05:25:41,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:41,481 INFO:     Epoch: 50
2022-11-28 05:25:42,152 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48844578625126317, 'Total loss': 0.48844578625126317} | train loss {'Reaction outcome loss': 0.4463214445859194, 'Total loss': 0.4463214445859194}
2022-11-28 05:25:42,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:42,152 INFO:     Epoch: 51
2022-11-28 05:25:42,822 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46555235372348264, 'Total loss': 0.46555235372348264} | train loss {'Reaction outcome loss': 0.4513236660990984, 'Total loss': 0.4513236660990984}
2022-11-28 05:25:42,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:42,823 INFO:     Epoch: 52
2022-11-28 05:25:43,491 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4829325310208581, 'Total loss': 0.4829325310208581} | train loss {'Reaction outcome loss': 0.4522025830623123, 'Total loss': 0.4522025830623123}
2022-11-28 05:25:43,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:43,491 INFO:     Epoch: 53
2022-11-28 05:25:44,164 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5313219011507251, 'Total loss': 0.5313219011507251} | train loss {'Reaction outcome loss': 0.4510064598533415, 'Total loss': 0.4510064598533415}
2022-11-28 05:25:44,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:44,165 INFO:     Epoch: 54
2022-11-28 05:25:44,836 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4725009443407709, 'Total loss': 0.4725009443407709} | train loss {'Reaction outcome loss': 0.45550449535010323, 'Total loss': 0.45550449535010323}
2022-11-28 05:25:44,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:44,836 INFO:     Epoch: 55
2022-11-28 05:25:45,507 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4932918799194423, 'Total loss': 0.4932918799194423} | train loss {'Reaction outcome loss': 0.45409430287057356, 'Total loss': 0.45409430287057356}
2022-11-28 05:25:45,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:45,508 INFO:     Epoch: 56
2022-11-28 05:25:46,182 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47565795853734016, 'Total loss': 0.47565795853734016} | train loss {'Reaction outcome loss': 0.46113184064386353, 'Total loss': 0.46113184064386353}
2022-11-28 05:25:46,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:46,183 INFO:     Epoch: 57
2022-11-28 05:25:46,850 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47204721346497536, 'Total loss': 0.47204721346497536} | train loss {'Reaction outcome loss': 0.45340035050626726, 'Total loss': 0.45340035050626726}
2022-11-28 05:25:46,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:46,850 INFO:     Epoch: 58
2022-11-28 05:25:47,518 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4916202053427696, 'Total loss': 0.4916202053427696} | train loss {'Reaction outcome loss': 0.4517301443002878, 'Total loss': 0.4517301443002878}
2022-11-28 05:25:47,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:47,519 INFO:     Epoch: 59
2022-11-28 05:25:48,188 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4932167221876708, 'Total loss': 0.4932167221876708} | train loss {'Reaction outcome loss': 0.454445855872285, 'Total loss': 0.454445855872285}
2022-11-28 05:25:48,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:48,188 INFO:     Epoch: 60
2022-11-28 05:25:48,855 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5145221271298148, 'Total loss': 0.5145221271298148} | train loss {'Reaction outcome loss': 0.4558756295591593, 'Total loss': 0.4558756295591593}
2022-11-28 05:25:48,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:48,855 INFO:     Epoch: 61
2022-11-28 05:25:49,523 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4754159325225787, 'Total loss': 0.4754159325225787} | train loss {'Reaction outcome loss': 0.455922172645167, 'Total loss': 0.455922172645167}
2022-11-28 05:25:49,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:49,523 INFO:     Epoch: 62
2022-11-28 05:25:50,190 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.471010449257764, 'Total loss': 0.471010449257764} | train loss {'Reaction outcome loss': 0.45955458746081396, 'Total loss': 0.45955458746081396}
2022-11-28 05:25:50,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:50,190 INFO:     Epoch: 63
2022-11-28 05:25:50,861 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4845860647884282, 'Total loss': 0.4845860647884282} | train loss {'Reaction outcome loss': 0.45562996955648544, 'Total loss': 0.45562996955648544}
2022-11-28 05:25:50,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:50,862 INFO:     Epoch: 64
2022-11-28 05:25:51,528 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.468231634829532, 'Total loss': 0.468231634829532} | train loss {'Reaction outcome loss': 0.4493539945312565, 'Total loss': 0.4493539945312565}
2022-11-28 05:25:51,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:51,528 INFO:     Epoch: 65
2022-11-28 05:25:52,199 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5011283206668767, 'Total loss': 0.5011283206668767} | train loss {'Reaction outcome loss': 0.4627982207964505, 'Total loss': 0.4627982207964505}
2022-11-28 05:25:52,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:52,199 INFO:     Epoch: 66
2022-11-28 05:25:52,868 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5233907408334992, 'Total loss': 0.5233907408334992} | train loss {'Reaction outcome loss': 0.4620427137180682, 'Total loss': 0.4620427137180682}
2022-11-28 05:25:52,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:52,868 INFO:     Epoch: 67
2022-11-28 05:25:53,537 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.502870228480209, 'Total loss': 0.502870228480209} | train loss {'Reaction outcome loss': 0.4497482993549878, 'Total loss': 0.4497482993549878}
2022-11-28 05:25:53,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:53,538 INFO:     Epoch: 68
2022-11-28 05:25:54,205 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4719655584882606, 'Total loss': 0.4719655584882606} | train loss {'Reaction outcome loss': 0.45273694179711804, 'Total loss': 0.45273694179711804}
2022-11-28 05:25:54,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:54,205 INFO:     Epoch: 69
2022-11-28 05:25:54,874 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.474692913280292, 'Total loss': 0.474692913280292} | train loss {'Reaction outcome loss': 0.45526632173888143, 'Total loss': 0.45526632173888143}
2022-11-28 05:25:54,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:54,875 INFO:     Epoch: 70
2022-11-28 05:25:55,542 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5261255722831596, 'Total loss': 0.5261255722831596} | train loss {'Reaction outcome loss': 0.45775844201806093, 'Total loss': 0.45775844201806093}
2022-11-28 05:25:55,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:55,543 INFO:     Epoch: 71
2022-11-28 05:25:56,214 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4710424528880553, 'Total loss': 0.4710424528880553} | train loss {'Reaction outcome loss': 0.4542213558189331, 'Total loss': 0.4542213558189331}
2022-11-28 05:25:56,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:56,214 INFO:     Epoch: 72
2022-11-28 05:25:56,886 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4845098358663646, 'Total loss': 0.4845098358663646} | train loss {'Reaction outcome loss': 0.45218293188560393, 'Total loss': 0.45218293188560393}
2022-11-28 05:25:56,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:56,887 INFO:     Epoch: 73
2022-11-28 05:25:57,555 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48345646770163014, 'Total loss': 0.48345646770163014} | train loss {'Reaction outcome loss': 0.44883931548364703, 'Total loss': 0.44883931548364703}
2022-11-28 05:25:57,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:57,555 INFO:     Epoch: 74
2022-11-28 05:25:58,223 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4746088412674991, 'Total loss': 0.4746088412674991} | train loss {'Reaction outcome loss': 0.46517614521566897, 'Total loss': 0.46517614521566897}
2022-11-28 05:25:58,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:58,224 INFO:     Epoch: 75
2022-11-28 05:25:58,890 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49668031253597955, 'Total loss': 0.49668031253597955} | train loss {'Reaction outcome loss': 0.4547537828405057, 'Total loss': 0.4547537828405057}
2022-11-28 05:25:58,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:58,890 INFO:     Epoch: 76
2022-11-28 05:25:59,560 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4798766245896166, 'Total loss': 0.4798766245896166} | train loss {'Reaction outcome loss': 0.4566966830452363, 'Total loss': 0.4566966830452363}
2022-11-28 05:25:59,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:25:59,561 INFO:     Epoch: 77
2022-11-28 05:26:00,230 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4875780645419251, 'Total loss': 0.4875780645419251} | train loss {'Reaction outcome loss': 0.4548026182117962, 'Total loss': 0.4548026182117962}
2022-11-28 05:26:00,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:00,230 INFO:     Epoch: 78
2022-11-28 05:26:00,895 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5124198882417246, 'Total loss': 0.5124198882417246} | train loss {'Reaction outcome loss': 0.4482607599648257, 'Total loss': 0.4482607599648257}
2022-11-28 05:26:00,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:00,895 INFO:     Epoch: 79
2022-11-28 05:26:01,560 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4904223805801435, 'Total loss': 0.4904223805801435} | train loss {'Reaction outcome loss': 0.46089311520899495, 'Total loss': 0.46089311520899495}
2022-11-28 05:26:01,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:01,561 INFO:     Epoch: 80
2022-11-28 05:26:02,232 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5172340057112954, 'Total loss': 0.5172340057112954} | train loss {'Reaction outcome loss': 0.4535646235510226, 'Total loss': 0.4535646235510226}
2022-11-28 05:26:02,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:02,233 INFO:     Epoch: 81
2022-11-28 05:26:02,904 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48839020424268464, 'Total loss': 0.48839020424268464} | train loss {'Reaction outcome loss': 0.4501974099586087, 'Total loss': 0.4501974099586087}
2022-11-28 05:26:02,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:02,904 INFO:     Epoch: 82
2022-11-28 05:26:03,573 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4755279672416774, 'Total loss': 0.4755279672416774} | train loss {'Reaction outcome loss': 0.4569782444065617, 'Total loss': 0.4569782444065617}
2022-11-28 05:26:03,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:03,573 INFO:     Epoch: 83
2022-11-28 05:26:04,244 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47922737151384354, 'Total loss': 0.47922737151384354} | train loss {'Reaction outcome loss': 0.46025983802974224, 'Total loss': 0.46025983802974224}
2022-11-28 05:26:04,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:04,244 INFO:     Epoch: 84
2022-11-28 05:26:04,914 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4988130723888224, 'Total loss': 0.4988130723888224} | train loss {'Reaction outcome loss': 0.45009094644938746, 'Total loss': 0.45009094644938746}
2022-11-28 05:26:04,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:04,914 INFO:     Epoch: 85
2022-11-28 05:26:05,584 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4820889281955632, 'Total loss': 0.4820889281955632} | train loss {'Reaction outcome loss': 0.45263530061610285, 'Total loss': 0.45263530061610285}
2022-11-28 05:26:05,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:05,585 INFO:     Epoch: 86
2022-11-28 05:26:06,256 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48989359492605383, 'Total loss': 0.48989359492605383} | train loss {'Reaction outcome loss': 0.4547545370916205, 'Total loss': 0.4547545370916205}
2022-11-28 05:26:06,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:06,256 INFO:     Epoch: 87
2022-11-28 05:26:06,928 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47966320474039426, 'Total loss': 0.47966320474039426} | train loss {'Reaction outcome loss': 0.4544198710711733, 'Total loss': 0.4544198710711733}
2022-11-28 05:26:06,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:06,928 INFO:     Epoch: 88
2022-11-28 05:26:07,597 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4871935410933061, 'Total loss': 0.4871935410933061} | train loss {'Reaction outcome loss': 0.45825449227085036, 'Total loss': 0.45825449227085036}
2022-11-28 05:26:07,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:07,597 INFO:     Epoch: 89
2022-11-28 05:26:08,268 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48458284546028485, 'Total loss': 0.48458284546028485} | train loss {'Reaction outcome loss': 0.454176573323146, 'Total loss': 0.454176573323146}
2022-11-28 05:26:08,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:08,269 INFO:     Epoch: 90
2022-11-28 05:26:08,940 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47287081757729704, 'Total loss': 0.47287081757729704} | train loss {'Reaction outcome loss': 0.4562589557420823, 'Total loss': 0.4562589557420823}
2022-11-28 05:26:08,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:08,940 INFO:     Epoch: 91
2022-11-28 05:26:09,610 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4906884523277933, 'Total loss': 0.4906884523277933} | train loss {'Reaction outcome loss': 0.45571079489684874, 'Total loss': 0.45571079489684874}
2022-11-28 05:26:09,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:09,610 INFO:     Epoch: 92
2022-11-28 05:26:10,280 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47047652439637616, 'Total loss': 0.47047652439637616} | train loss {'Reaction outcome loss': 0.45894606465533855, 'Total loss': 0.45894606465533855}
2022-11-28 05:26:10,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:10,280 INFO:     Epoch: 93
2022-11-28 05:26:10,948 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.502447210252285, 'Total loss': 0.502447210252285} | train loss {'Reaction outcome loss': 0.457832008600235, 'Total loss': 0.457832008600235}
2022-11-28 05:26:10,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:10,948 INFO:     Epoch: 94
2022-11-28 05:26:11,615 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.469656129790978, 'Total loss': 0.469656129790978} | train loss {'Reaction outcome loss': 0.45363135716968006, 'Total loss': 0.45363135716968006}
2022-11-28 05:26:11,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:11,615 INFO:     Epoch: 95
2022-11-28 05:26:12,277 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48811196705157106, 'Total loss': 0.48811196705157106} | train loss {'Reaction outcome loss': 0.444151466231673, 'Total loss': 0.444151466231673}
2022-11-28 05:26:12,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:12,277 INFO:     Epoch: 96
2022-11-28 05:26:12,945 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4767850132828409, 'Total loss': 0.4767850132828409} | train loss {'Reaction outcome loss': 0.4551402027868936, 'Total loss': 0.4551402027868936}
2022-11-28 05:26:12,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:12,945 INFO:     Epoch: 97
2022-11-28 05:26:13,608 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4911737482656132, 'Total loss': 0.4911737482656132} | train loss {'Reaction outcome loss': 0.46023337777343487, 'Total loss': 0.46023337777343487}
2022-11-28 05:26:13,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:13,608 INFO:     Epoch: 98
2022-11-28 05:26:14,271 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46229559454050934, 'Total loss': 0.46229559454050934} | train loss {'Reaction outcome loss': 0.4508857963186118, 'Total loss': 0.4508857963186118}
2022-11-28 05:26:14,271 INFO:     Found new best model at epoch 98
2022-11-28 05:26:14,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:14,272 INFO:     Epoch: 99
2022-11-28 05:26:14,933 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4896837134252895, 'Total loss': 0.4896837134252895} | train loss {'Reaction outcome loss': 0.455766313138508, 'Total loss': 0.455766313138508}
2022-11-28 05:26:14,933 INFO:     Best model found after epoch 99 of 100.
2022-11-28 05:26:14,934 INFO:   Done with stage: TRAINING
2022-11-28 05:26:14,934 INFO:   Starting stage: EVALUATION
2022-11-28 05:26:15,046 INFO:   Done with stage: EVALUATION
2022-11-28 05:26:15,046 INFO:   Leaving out SEQ value Fold_8
2022-11-28 05:26:15,058 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 05:26:15,058 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:26:15,690 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:26:15,690 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:26:15,759 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:26:15,759 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:26:15,759 INFO:     No hyperparam tuning for this model
2022-11-28 05:26:15,759 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:26:15,759 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:26:15,760 INFO:     None feature selector for col prot
2022-11-28 05:26:15,760 INFO:     None feature selector for col prot
2022-11-28 05:26:15,760 INFO:     None feature selector for col prot
2022-11-28 05:26:15,761 INFO:     None feature selector for col chem
2022-11-28 05:26:15,761 INFO:     None feature selector for col chem
2022-11-28 05:26:15,761 INFO:     None feature selector for col chem
2022-11-28 05:26:15,761 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:26:15,761 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:26:15,762 INFO:     Number of params in model 169651
2022-11-28 05:26:15,766 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:26:15,766 INFO:   Starting stage: TRAINING
2022-11-28 05:26:15,816 INFO:     Val loss before train {'Reaction outcome loss': 0.9641043051730754, 'Total loss': 0.9641043051730754}
2022-11-28 05:26:15,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:15,817 INFO:     Epoch: 0
2022-11-28 05:26:16,474 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6480456881744917, 'Total loss': 0.6480456881744917} | train loss {'Reaction outcome loss': 0.6581976846715466, 'Total loss': 0.6581976846715466}
2022-11-28 05:26:16,474 INFO:     Found new best model at epoch 0
2022-11-28 05:26:16,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:16,475 INFO:     Epoch: 1
2022-11-28 05:26:17,126 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5163168217553649, 'Total loss': 0.5163168217553649} | train loss {'Reaction outcome loss': 0.5821821803196532, 'Total loss': 0.5821821803196532}
2022-11-28 05:26:17,126 INFO:     Found new best model at epoch 1
2022-11-28 05:26:17,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:17,127 INFO:     Epoch: 2
2022-11-28 05:26:17,784 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5047238697839338, 'Total loss': 0.5047238697839338} | train loss {'Reaction outcome loss': 0.5541079369236211, 'Total loss': 0.5541079369236211}
2022-11-28 05:26:17,784 INFO:     Found new best model at epoch 2
2022-11-28 05:26:17,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:17,785 INFO:     Epoch: 3
2022-11-28 05:26:18,438 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5559716425662817, 'Total loss': 0.5559716425662817} | train loss {'Reaction outcome loss': 0.5362690737867941, 'Total loss': 0.5362690737867941}
2022-11-28 05:26:18,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:18,440 INFO:     Epoch: 4
2022-11-28 05:26:19,094 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4631804537981056, 'Total loss': 0.4631804537981056} | train loss {'Reaction outcome loss': 0.5226322386841304, 'Total loss': 0.5226322386841304}
2022-11-28 05:26:19,094 INFO:     Found new best model at epoch 4
2022-11-28 05:26:19,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:19,095 INFO:     Epoch: 5
2022-11-28 05:26:19,744 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4669290746367255, 'Total loss': 0.4669290746367255} | train loss {'Reaction outcome loss': 0.510745599988054, 'Total loss': 0.510745599988054}
2022-11-28 05:26:19,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:19,745 INFO:     Epoch: 6
2022-11-28 05:26:20,397 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48060430724953496, 'Total loss': 0.48060430724953496} | train loss {'Reaction outcome loss': 0.49713178204952696, 'Total loss': 0.49713178204952696}
2022-11-28 05:26:20,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:20,397 INFO:     Epoch: 7
2022-11-28 05:26:21,049 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4405786672303843, 'Total loss': 0.4405786672303843} | train loss {'Reaction outcome loss': 0.49721874797441923, 'Total loss': 0.49721874797441923}
2022-11-28 05:26:21,049 INFO:     Found new best model at epoch 7
2022-11-28 05:26:21,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:21,050 INFO:     Epoch: 8
2022-11-28 05:26:21,703 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48577925493550855, 'Total loss': 0.48577925493550855} | train loss {'Reaction outcome loss': 0.48441094398254253, 'Total loss': 0.48441094398254253}
2022-11-28 05:26:21,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:21,703 INFO:     Epoch: 9
2022-11-28 05:26:22,352 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44685213614341823, 'Total loss': 0.44685213614341823} | train loss {'Reaction outcome loss': 0.4833391741773144, 'Total loss': 0.4833391741773144}
2022-11-28 05:26:22,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:22,352 INFO:     Epoch: 10
2022-11-28 05:26:23,009 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47739378033682356, 'Total loss': 0.47739378033682356} | train loss {'Reaction outcome loss': 0.48383668492563436, 'Total loss': 0.48383668492563436}
2022-11-28 05:26:23,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:23,009 INFO:     Epoch: 11
2022-11-28 05:26:23,668 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47301937743674877, 'Total loss': 0.47301937743674877} | train loss {'Reaction outcome loss': 0.4750459590529809, 'Total loss': 0.4750459590529809}
2022-11-28 05:26:23,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:23,668 INFO:     Epoch: 12
2022-11-28 05:26:24,321 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44403853007527283, 'Total loss': 0.44403853007527283} | train loss {'Reaction outcome loss': 0.4813892762558382, 'Total loss': 0.4813892762558382}
2022-11-28 05:26:24,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:24,321 INFO:     Epoch: 13
2022-11-28 05:26:24,971 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4371856932723245, 'Total loss': 0.4371856932723245} | train loss {'Reaction outcome loss': 0.47429557859164767, 'Total loss': 0.47429557859164767}
2022-11-28 05:26:24,971 INFO:     Found new best model at epoch 13
2022-11-28 05:26:24,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:24,972 INFO:     Epoch: 14
2022-11-28 05:26:25,622 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46476551821065504, 'Total loss': 0.46476551821065504} | train loss {'Reaction outcome loss': 0.4651497832697923, 'Total loss': 0.4651497832697923}
2022-11-28 05:26:25,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:25,622 INFO:     Epoch: 15
2022-11-28 05:26:26,275 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4794383423272954, 'Total loss': 0.4794383423272954} | train loss {'Reaction outcome loss': 0.47106463944569965, 'Total loss': 0.47106463944569965}
2022-11-28 05:26:26,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:26,276 INFO:     Epoch: 16
2022-11-28 05:26:26,931 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.440630697580271, 'Total loss': 0.440630697580271} | train loss {'Reaction outcome loss': 0.4791815378016136, 'Total loss': 0.4791815378016136}
2022-11-28 05:26:26,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:26,931 INFO:     Epoch: 17
2022-11-28 05:26:27,581 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4505613470493361, 'Total loss': 0.4505613470493361} | train loss {'Reaction outcome loss': 0.4697866899068238, 'Total loss': 0.4697866899068238}
2022-11-28 05:26:27,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:27,581 INFO:     Epoch: 18
2022-11-28 05:26:28,232 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49717296798561894, 'Total loss': 0.49717296798561894} | train loss {'Reaction outcome loss': 0.46974692817349906, 'Total loss': 0.46974692817349906}
2022-11-28 05:26:28,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:28,232 INFO:     Epoch: 19
2022-11-28 05:26:28,885 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46364144599714946, 'Total loss': 0.46364144599714946} | train loss {'Reaction outcome loss': 0.46250679673718625, 'Total loss': 0.46250679673718625}
2022-11-28 05:26:28,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:28,885 INFO:     Epoch: 20
2022-11-28 05:26:29,537 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4716713605232017, 'Total loss': 0.4716713605232017} | train loss {'Reaction outcome loss': 0.46750030513913904, 'Total loss': 0.46750030513913904}
2022-11-28 05:26:29,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:29,537 INFO:     Epoch: 21
2022-11-28 05:26:30,190 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44834641765716465, 'Total loss': 0.44834641765716465} | train loss {'Reaction outcome loss': 0.46055451434746875, 'Total loss': 0.46055451434746875}
2022-11-28 05:26:30,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:30,191 INFO:     Epoch: 22
2022-11-28 05:26:30,846 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4575849622488022, 'Total loss': 0.4575849622488022} | train loss {'Reaction outcome loss': 0.4678327211285712, 'Total loss': 0.4678327211285712}
2022-11-28 05:26:30,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:30,846 INFO:     Epoch: 23
2022-11-28 05:26:31,500 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4288643671329631, 'Total loss': 0.4288643671329631} | train loss {'Reaction outcome loss': 0.4588455137964643, 'Total loss': 0.4588455137964643}
2022-11-28 05:26:31,501 INFO:     Found new best model at epoch 23
2022-11-28 05:26:31,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:31,501 INFO:     Epoch: 24
2022-11-28 05:26:32,154 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4441404517653377, 'Total loss': 0.4441404517653377} | train loss {'Reaction outcome loss': 0.4634907472817624, 'Total loss': 0.4634907472817624}
2022-11-28 05:26:32,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:32,154 INFO:     Epoch: 25
2022-11-28 05:26:32,807 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4243785094383151, 'Total loss': 0.4243785094383151} | train loss {'Reaction outcome loss': 0.46280197237358717, 'Total loss': 0.46280197237358717}
2022-11-28 05:26:32,807 INFO:     Found new best model at epoch 25
2022-11-28 05:26:32,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:32,808 INFO:     Epoch: 26
2022-11-28 05:26:33,461 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44584636598132377, 'Total loss': 0.44584636598132377} | train loss {'Reaction outcome loss': 0.4576691083121495, 'Total loss': 0.4576691083121495}
2022-11-28 05:26:33,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:33,461 INFO:     Epoch: 27
2022-11-28 05:26:34,116 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4670660305161809, 'Total loss': 0.4670660305161809} | train loss {'Reaction outcome loss': 0.45493477515754155, 'Total loss': 0.45493477515754155}
2022-11-28 05:26:34,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:34,117 INFO:     Epoch: 28
2022-11-28 05:26:34,768 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4222227414680082, 'Total loss': 0.4222227414680082} | train loss {'Reaction outcome loss': 0.4597873220556095, 'Total loss': 0.4597873220556095}
2022-11-28 05:26:34,768 INFO:     Found new best model at epoch 28
2022-11-28 05:26:34,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:34,769 INFO:     Epoch: 29
2022-11-28 05:26:35,425 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4557983968840089, 'Total loss': 0.4557983968840089} | train loss {'Reaction outcome loss': 0.46346972931603914, 'Total loss': 0.46346972931603914}
2022-11-28 05:26:35,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:35,425 INFO:     Epoch: 30
2022-11-28 05:26:36,077 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4484405968078347, 'Total loss': 0.4484405968078347} | train loss {'Reaction outcome loss': 0.4575122171005265, 'Total loss': 0.4575122171005265}
2022-11-28 05:26:36,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:36,077 INFO:     Epoch: 31
2022-11-28 05:26:36,733 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.419963865779167, 'Total loss': 0.419963865779167} | train loss {'Reaction outcome loss': 0.4573245154174625, 'Total loss': 0.4573245154174625}
2022-11-28 05:26:36,733 INFO:     Found new best model at epoch 31
2022-11-28 05:26:36,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:36,734 INFO:     Epoch: 32
2022-11-28 05:26:37,389 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4366797278093737, 'Total loss': 0.4366797278093737} | train loss {'Reaction outcome loss': 0.4571949791346417, 'Total loss': 0.4571949791346417}
2022-11-28 05:26:37,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:37,390 INFO:     Epoch: 33
2022-11-28 05:26:38,044 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4402710251336874, 'Total loss': 0.4402710251336874} | train loss {'Reaction outcome loss': 0.4663453131425576, 'Total loss': 0.4663453131425576}
2022-11-28 05:26:38,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:38,044 INFO:     Epoch: 34
2022-11-28 05:26:38,703 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45208523786345195, 'Total loss': 0.45208523786345195} | train loss {'Reaction outcome loss': 0.45913768003954264, 'Total loss': 0.45913768003954264}
2022-11-28 05:26:38,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:38,703 INFO:     Epoch: 35
2022-11-28 05:26:39,360 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4560501277446747, 'Total loss': 0.4560501277446747} | train loss {'Reaction outcome loss': 0.454835303555258, 'Total loss': 0.454835303555258}
2022-11-28 05:26:39,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:39,360 INFO:     Epoch: 36
2022-11-28 05:26:40,019 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44074712485768075, 'Total loss': 0.44074712485768075} | train loss {'Reaction outcome loss': 0.4619634683992042, 'Total loss': 0.4619634683992042}
2022-11-28 05:26:40,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:40,019 INFO:     Epoch: 37
2022-11-28 05:26:40,677 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4351624693981437, 'Total loss': 0.4351624693981437} | train loss {'Reaction outcome loss': 0.4530869077158267, 'Total loss': 0.4530869077158267}
2022-11-28 05:26:40,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:40,677 INFO:     Epoch: 38
2022-11-28 05:26:41,330 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.432257097820903, 'Total loss': 0.432257097820903} | train loss {'Reaction outcome loss': 0.45952851416879015, 'Total loss': 0.45952851416879015}
2022-11-28 05:26:41,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:41,330 INFO:     Epoch: 39
2022-11-28 05:26:41,983 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42563207066336345, 'Total loss': 0.42563207066336345} | train loss {'Reaction outcome loss': 0.45572103822573284, 'Total loss': 0.45572103822573284}
2022-11-28 05:26:41,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:41,983 INFO:     Epoch: 40
2022-11-28 05:26:42,637 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4542889383643173, 'Total loss': 0.4542889383643173} | train loss {'Reaction outcome loss': 0.4583785387946934, 'Total loss': 0.4583785387946934}
2022-11-28 05:26:42,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:42,637 INFO:     Epoch: 41
2022-11-28 05:26:43,289 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44059259548436763, 'Total loss': 0.44059259548436763} | train loss {'Reaction outcome loss': 0.4588501670810043, 'Total loss': 0.4588501670810043}
2022-11-28 05:26:43,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:43,289 INFO:     Epoch: 42
2022-11-28 05:26:43,942 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4388613939978356, 'Total loss': 0.4388613939978356} | train loss {'Reaction outcome loss': 0.45490283693080064, 'Total loss': 0.45490283693080064}
2022-11-28 05:26:43,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:43,943 INFO:     Epoch: 43
2022-11-28 05:26:44,596 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4394991640434709, 'Total loss': 0.4394991640434709} | train loss {'Reaction outcome loss': 0.4551537557214987, 'Total loss': 0.4551537557214987}
2022-11-28 05:26:44,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:44,597 INFO:     Epoch: 44
2022-11-28 05:26:45,254 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4699238833299903, 'Total loss': 0.4699238833299903} | train loss {'Reaction outcome loss': 0.45955986776923546, 'Total loss': 0.45955986776923546}
2022-11-28 05:26:45,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:45,254 INFO:     Epoch: 45
2022-11-28 05:26:45,907 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4391383397024731, 'Total loss': 0.4391383397024731} | train loss {'Reaction outcome loss': 0.4543824251435819, 'Total loss': 0.4543824251435819}
2022-11-28 05:26:45,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:45,907 INFO:     Epoch: 46
2022-11-28 05:26:46,562 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44814242595850035, 'Total loss': 0.44814242595850035} | train loss {'Reaction outcome loss': 0.45363216169300624, 'Total loss': 0.45363216169300624}
2022-11-28 05:26:46,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:46,562 INFO:     Epoch: 47
2022-11-28 05:26:47,218 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42396832829297976, 'Total loss': 0.42396832829297976} | train loss {'Reaction outcome loss': 0.4540451951935643, 'Total loss': 0.4540451951935643}
2022-11-28 05:26:47,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:47,218 INFO:     Epoch: 48
2022-11-28 05:26:47,873 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4646505786235942, 'Total loss': 0.4646505786235942} | train loss {'Reaction outcome loss': 0.4575336951548692, 'Total loss': 0.4575336951548692}
2022-11-28 05:26:47,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:47,874 INFO:     Epoch: 49
2022-11-28 05:26:48,530 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4663363854552424, 'Total loss': 0.4663363854552424} | train loss {'Reaction outcome loss': 0.46305841604461434, 'Total loss': 0.46305841604461434}
2022-11-28 05:26:48,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:48,530 INFO:     Epoch: 50
2022-11-28 05:26:49,185 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4725144453519999, 'Total loss': 0.4725144453519999} | train loss {'Reaction outcome loss': 0.455606784305123, 'Total loss': 0.455606784305123}
2022-11-28 05:26:49,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:49,186 INFO:     Epoch: 51
2022-11-28 05:26:49,840 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4509346959895866, 'Total loss': 0.4509346959895866} | train loss {'Reaction outcome loss': 0.4670694746138131, 'Total loss': 0.4670694746138131}
2022-11-28 05:26:49,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:49,841 INFO:     Epoch: 52
2022-11-28 05:26:50,493 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4738636429226676, 'Total loss': 0.4738636429226676} | train loss {'Reaction outcome loss': 0.45475467221170174, 'Total loss': 0.45475467221170174}
2022-11-28 05:26:50,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:50,493 INFO:     Epoch: 53
2022-11-28 05:26:51,147 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4449668062287708, 'Total loss': 0.4449668062287708} | train loss {'Reaction outcome loss': 0.4530436620726937, 'Total loss': 0.4530436620726937}
2022-11-28 05:26:51,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:51,147 INFO:     Epoch: 54
2022-11-28 05:26:51,799 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5135016229956649, 'Total loss': 0.5135016229956649} | train loss {'Reaction outcome loss': 0.45674654969670736, 'Total loss': 0.45674654969670736}
2022-11-28 05:26:51,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:51,800 INFO:     Epoch: 55
2022-11-28 05:26:52,451 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4438875806193019, 'Total loss': 0.4438875806193019} | train loss {'Reaction outcome loss': 0.45978508468289847, 'Total loss': 0.45978508468289847}
2022-11-28 05:26:52,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:52,451 INFO:     Epoch: 56
2022-11-28 05:26:53,102 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5004937880954077, 'Total loss': 0.5004937880954077} | train loss {'Reaction outcome loss': 0.4617457959617748, 'Total loss': 0.4617457959617748}
2022-11-28 05:26:53,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:53,102 INFO:     Epoch: 57
2022-11-28 05:26:53,757 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4477296790411306, 'Total loss': 0.4477296790411306} | train loss {'Reaction outcome loss': 0.4536045751855022, 'Total loss': 0.4536045751855022}
2022-11-28 05:26:53,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:53,757 INFO:     Epoch: 58
2022-11-28 05:26:54,410 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44447842396275944, 'Total loss': 0.44447842396275944} | train loss {'Reaction outcome loss': 0.45813320332863294, 'Total loss': 0.45813320332863294}
2022-11-28 05:26:54,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:54,410 INFO:     Epoch: 59
2022-11-28 05:26:55,064 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4732574387345203, 'Total loss': 0.4732574387345203} | train loss {'Reaction outcome loss': 0.45478917438475813, 'Total loss': 0.45478917438475813}
2022-11-28 05:26:55,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:55,064 INFO:     Epoch: 60
2022-11-28 05:26:55,717 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4687090561140415, 'Total loss': 0.4687090561140415} | train loss {'Reaction outcome loss': 0.46165751421549284, 'Total loss': 0.46165751421549284}
2022-11-28 05:26:55,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:55,718 INFO:     Epoch: 61
2022-11-28 05:26:56,372 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48266305722469505, 'Total loss': 0.48266305722469505} | train loss {'Reaction outcome loss': 0.4560020067042015, 'Total loss': 0.4560020067042015}
2022-11-28 05:26:56,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:56,372 INFO:     Epoch: 62
2022-11-28 05:26:57,027 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43160393938075664, 'Total loss': 0.43160393938075664} | train loss {'Reaction outcome loss': 0.4564227453875737, 'Total loss': 0.4564227453875737}
2022-11-28 05:26:57,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:57,028 INFO:     Epoch: 63
2022-11-28 05:26:57,684 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49685493042302686, 'Total loss': 0.49685493042302686} | train loss {'Reaction outcome loss': 0.4565302239517208, 'Total loss': 0.4565302239517208}
2022-11-28 05:26:57,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:57,684 INFO:     Epoch: 64
2022-11-28 05:26:58,341 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5059674403002096, 'Total loss': 0.5059674403002096} | train loss {'Reaction outcome loss': 0.45493639813216985, 'Total loss': 0.45493639813216985}
2022-11-28 05:26:58,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:58,341 INFO:     Epoch: 65
2022-11-28 05:26:58,995 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4590802282788033, 'Total loss': 0.4590802282788033} | train loss {'Reaction outcome loss': 0.459966419966983, 'Total loss': 0.459966419966983}
2022-11-28 05:26:58,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:58,995 INFO:     Epoch: 66
2022-11-28 05:26:59,653 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4398417039666065, 'Total loss': 0.4398417039666065} | train loss {'Reaction outcome loss': 0.46474060226903585, 'Total loss': 0.46474060226903585}
2022-11-28 05:26:59,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:26:59,653 INFO:     Epoch: 67
2022-11-28 05:27:00,306 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44605995229510376, 'Total loss': 0.44605995229510376} | train loss {'Reaction outcome loss': 0.4523364847495419, 'Total loss': 0.4523364847495419}
2022-11-28 05:27:00,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:00,306 INFO:     Epoch: 68
2022-11-28 05:27:00,961 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.462292593232421, 'Total loss': 0.462292593232421} | train loss {'Reaction outcome loss': 0.44744156991116335, 'Total loss': 0.44744156991116335}
2022-11-28 05:27:00,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:00,961 INFO:     Epoch: 69
2022-11-28 05:27:01,619 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4292747582807097, 'Total loss': 0.4292747582807097} | train loss {'Reaction outcome loss': 0.45372195987672104, 'Total loss': 0.45372195987672104}
2022-11-28 05:27:01,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:01,620 INFO:     Epoch: 70
2022-11-28 05:27:02,276 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4229223197975824, 'Total loss': 0.4229223197975824} | train loss {'Reaction outcome loss': 0.4532965118157082, 'Total loss': 0.4532965118157082}
2022-11-28 05:27:02,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:02,276 INFO:     Epoch: 71
2022-11-28 05:27:02,932 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4269981997650723, 'Total loss': 0.4269981997650723} | train loss {'Reaction outcome loss': 0.450706063357533, 'Total loss': 0.450706063357533}
2022-11-28 05:27:02,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:02,932 INFO:     Epoch: 72
2022-11-28 05:27:03,584 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4511089789312939, 'Total loss': 0.4511089789312939} | train loss {'Reaction outcome loss': 0.4478813065368621, 'Total loss': 0.4478813065368621}
2022-11-28 05:27:03,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:03,584 INFO:     Epoch: 73
2022-11-28 05:27:04,238 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4339870845162591, 'Total loss': 0.4339870845162591} | train loss {'Reaction outcome loss': 0.45845106412030634, 'Total loss': 0.45845106412030634}
2022-11-28 05:27:04,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:04,238 INFO:     Epoch: 74
2022-11-28 05:27:04,896 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43790207110172097, 'Total loss': 0.43790207110172097} | train loss {'Reaction outcome loss': 0.46146144192726885, 'Total loss': 0.46146144192726885}
2022-11-28 05:27:04,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:04,896 INFO:     Epoch: 75
2022-11-28 05:27:05,553 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45692376307276794, 'Total loss': 0.45692376307276794} | train loss {'Reaction outcome loss': 0.4468765772390561, 'Total loss': 0.4468765772390561}
2022-11-28 05:27:05,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:05,553 INFO:     Epoch: 76
2022-11-28 05:27:06,209 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46483779404052467, 'Total loss': 0.46483779404052467} | train loss {'Reaction outcome loss': 0.460213179684809, 'Total loss': 0.460213179684809}
2022-11-28 05:27:06,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:06,209 INFO:     Epoch: 77
2022-11-28 05:27:06,864 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48204307777937067, 'Total loss': 0.48204307777937067} | train loss {'Reaction outcome loss': 0.45320004603413283, 'Total loss': 0.45320004603413283}
2022-11-28 05:27:06,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:06,864 INFO:     Epoch: 78
2022-11-28 05:27:07,517 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4446851940349091, 'Total loss': 0.4446851940349091} | train loss {'Reaction outcome loss': 0.45441723790508315, 'Total loss': 0.45441723790508315}
2022-11-28 05:27:07,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:07,517 INFO:     Epoch: 79
2022-11-28 05:27:08,170 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4341912983461868, 'Total loss': 0.4341912983461868} | train loss {'Reaction outcome loss': 0.4482984740103855, 'Total loss': 0.4482984740103855}
2022-11-28 05:27:08,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:08,171 INFO:     Epoch: 80
2022-11-28 05:27:08,826 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4513147899577784, 'Total loss': 0.4513147899577784} | train loss {'Reaction outcome loss': 0.45737219272089785, 'Total loss': 0.45737219272089785}
2022-11-28 05:27:08,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:08,826 INFO:     Epoch: 81
2022-11-28 05:27:09,482 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4525008114964463, 'Total loss': 0.4525008114964463} | train loss {'Reaction outcome loss': 0.4600110150507239, 'Total loss': 0.4600110150507239}
2022-11-28 05:27:09,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:09,482 INFO:     Epoch: 82
2022-11-28 05:27:10,136 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46138926647430245, 'Total loss': 0.46138926647430245} | train loss {'Reaction outcome loss': 0.45302086234947697, 'Total loss': 0.45302086234947697}
2022-11-28 05:27:10,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:10,136 INFO:     Epoch: 83
2022-11-28 05:27:10,792 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4332454824863478, 'Total loss': 0.4332454824863478} | train loss {'Reaction outcome loss': 0.4544417162532689, 'Total loss': 0.4544417162532689}
2022-11-28 05:27:10,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:10,792 INFO:     Epoch: 84
2022-11-28 05:27:11,447 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4339813787576764, 'Total loss': 0.4339813787576764} | train loss {'Reaction outcome loss': 0.4515666471885853, 'Total loss': 0.4515666471885853}
2022-11-28 05:27:11,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:11,447 INFO:     Epoch: 85
2022-11-28 05:27:12,102 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4289256396681763, 'Total loss': 0.4289256396681763} | train loss {'Reaction outcome loss': 0.45694303683570175, 'Total loss': 0.45694303683570175}
2022-11-28 05:27:12,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:12,102 INFO:     Epoch: 86
2022-11-28 05:27:12,757 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4743090213038201, 'Total loss': 0.4743090213038201} | train loss {'Reaction outcome loss': 0.45021870341457304, 'Total loss': 0.45021870341457304}
2022-11-28 05:27:12,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:12,757 INFO:     Epoch: 87
2022-11-28 05:27:13,414 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4488591652276904, 'Total loss': 0.4488591652276904} | train loss {'Reaction outcome loss': 0.4579552681047897, 'Total loss': 0.4579552681047897}
2022-11-28 05:27:13,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:13,414 INFO:     Epoch: 88
2022-11-28 05:27:14,071 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4491339176893234, 'Total loss': 0.4491339176893234} | train loss {'Reaction outcome loss': 0.455879501540397, 'Total loss': 0.455879501540397}
2022-11-28 05:27:14,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:14,071 INFO:     Epoch: 89
2022-11-28 05:27:14,726 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44580662077249483, 'Total loss': 0.44580662077249483} | train loss {'Reaction outcome loss': 0.4523463516389249, 'Total loss': 0.4523463516389249}
2022-11-28 05:27:14,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:14,727 INFO:     Epoch: 90
2022-11-28 05:27:15,385 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48532978947772537, 'Total loss': 0.48532978947772537} | train loss {'Reaction outcome loss': 0.45334551886456914, 'Total loss': 0.45334551886456914}
2022-11-28 05:27:15,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:15,386 INFO:     Epoch: 91
2022-11-28 05:27:16,039 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45086242813010546, 'Total loss': 0.45086242813010546} | train loss {'Reaction outcome loss': 0.4536790529601887, 'Total loss': 0.4536790529601887}
2022-11-28 05:27:16,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:16,039 INFO:     Epoch: 92
2022-11-28 05:27:16,693 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43947040289640427, 'Total loss': 0.43947040289640427} | train loss {'Reaction outcome loss': 0.4505137990488381, 'Total loss': 0.4505137990488381}
2022-11-28 05:27:16,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:16,693 INFO:     Epoch: 93
2022-11-28 05:27:17,345 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43410751084948695, 'Total loss': 0.43410751084948695} | train loss {'Reaction outcome loss': 0.45051308971692305, 'Total loss': 0.45051308971692305}
2022-11-28 05:27:17,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:17,345 INFO:     Epoch: 94
2022-11-28 05:27:18,003 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4509324642807938, 'Total loss': 0.4509324642807938} | train loss {'Reaction outcome loss': 0.4494536087894049, 'Total loss': 0.4494536087894049}
2022-11-28 05:27:18,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:18,003 INFO:     Epoch: 95
2022-11-28 05:27:18,660 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47752772791441095, 'Total loss': 0.47752772791441095} | train loss {'Reaction outcome loss': 0.45759968606174967, 'Total loss': 0.45759968606174967}
2022-11-28 05:27:18,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:18,660 INFO:     Epoch: 96
2022-11-28 05:27:19,315 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4394086661726929, 'Total loss': 0.4394086661726929} | train loss {'Reaction outcome loss': 0.4535608257731942, 'Total loss': 0.4535608257731942}
2022-11-28 05:27:19,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:19,316 INFO:     Epoch: 97
2022-11-28 05:27:19,974 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.462698528586432, 'Total loss': 0.462698528586432} | train loss {'Reaction outcome loss': 0.4521710671728752, 'Total loss': 0.4521710671728752}
2022-11-28 05:27:19,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:19,976 INFO:     Epoch: 98
2022-11-28 05:27:20,630 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4489306537217872, 'Total loss': 0.4489306537217872} | train loss {'Reaction outcome loss': 0.4539666672954794, 'Total loss': 0.4539666672954794}
2022-11-28 05:27:20,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:20,630 INFO:     Epoch: 99
2022-11-28 05:27:21,282 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4468330709740173, 'Total loss': 0.4468330709740173} | train loss {'Reaction outcome loss': 0.4504744877702877, 'Total loss': 0.4504744877702877}
2022-11-28 05:27:21,282 INFO:     Best model found after epoch 32 of 100.
2022-11-28 05:27:21,282 INFO:   Done with stage: TRAINING
2022-11-28 05:27:21,282 INFO:   Starting stage: EVALUATION
2022-11-28 05:27:21,411 INFO:   Done with stage: EVALUATION
2022-11-28 05:27:21,411 INFO:   Leaving out SEQ value Fold_9
2022-11-28 05:27:21,424 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 05:27:21,424 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:27:22,076 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:27:22,077 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:27:22,146 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:27:22,147 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:27:22,147 INFO:     No hyperparam tuning for this model
2022-11-28 05:27:22,147 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:27:22,147 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:27:22,147 INFO:     None feature selector for col prot
2022-11-28 05:27:22,148 INFO:     None feature selector for col prot
2022-11-28 05:27:22,148 INFO:     None feature selector for col prot
2022-11-28 05:27:22,148 INFO:     None feature selector for col chem
2022-11-28 05:27:22,148 INFO:     None feature selector for col chem
2022-11-28 05:27:22,148 INFO:     None feature selector for col chem
2022-11-28 05:27:22,148 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:27:22,148 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:27:22,150 INFO:     Number of params in model 169651
2022-11-28 05:27:22,153 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:27:22,153 INFO:   Starting stage: TRAINING
2022-11-28 05:27:22,204 INFO:     Val loss before train {'Reaction outcome loss': 1.0354497906836597, 'Total loss': 1.0354497906836597}
2022-11-28 05:27:22,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:22,204 INFO:     Epoch: 0
2022-11-28 05:27:22,869 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6323902017690919, 'Total loss': 0.6323902017690919} | train loss {'Reaction outcome loss': 0.698345194059995, 'Total loss': 0.698345194059995}
2022-11-28 05:27:22,869 INFO:     Found new best model at epoch 0
2022-11-28 05:27:22,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:22,870 INFO:     Epoch: 1
2022-11-28 05:27:23,537 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6025579111142592, 'Total loss': 0.6025579111142592} | train loss {'Reaction outcome loss': 0.5875544964425987, 'Total loss': 0.5875544964425987}
2022-11-28 05:27:23,537 INFO:     Found new best model at epoch 1
2022-11-28 05:27:23,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:23,538 INFO:     Epoch: 2
2022-11-28 05:27:24,205 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.572589098052545, 'Total loss': 0.572589098052545} | train loss {'Reaction outcome loss': 0.5554703726102749, 'Total loss': 0.5554703726102749}
2022-11-28 05:27:24,206 INFO:     Found new best model at epoch 2
2022-11-28 05:27:24,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:24,206 INFO:     Epoch: 3
2022-11-28 05:27:24,871 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5691486862911419, 'Total loss': 0.5691486862911419} | train loss {'Reaction outcome loss': 0.544138079869651, 'Total loss': 0.544138079869651}
2022-11-28 05:27:24,872 INFO:     Found new best model at epoch 3
2022-11-28 05:27:24,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:24,872 INFO:     Epoch: 4
2022-11-28 05:27:25,540 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5375497933815826, 'Total loss': 0.5375497933815826} | train loss {'Reaction outcome loss': 0.5329538602982798, 'Total loss': 0.5329538602982798}
2022-11-28 05:27:25,540 INFO:     Found new best model at epoch 4
2022-11-28 05:27:25,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:25,541 INFO:     Epoch: 5
2022-11-28 05:27:26,207 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5817592767151919, 'Total loss': 0.5817592767151919} | train loss {'Reaction outcome loss': 0.5165607279707347, 'Total loss': 0.5165607279707347}
2022-11-28 05:27:26,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:26,208 INFO:     Epoch: 6
2022-11-28 05:27:26,871 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5447032641280781, 'Total loss': 0.5447032641280781} | train loss {'Reaction outcome loss': 0.5128265643912938, 'Total loss': 0.5128265643912938}
2022-11-28 05:27:26,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:26,872 INFO:     Epoch: 7
2022-11-28 05:27:27,535 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.504735151475126, 'Total loss': 0.504735151475126} | train loss {'Reaction outcome loss': 0.5050806918091351, 'Total loss': 0.5050806918091351}
2022-11-28 05:27:27,535 INFO:     Found new best model at epoch 7
2022-11-28 05:27:27,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:27,536 INFO:     Epoch: 8
2022-11-28 05:27:28,204 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5001620474186811, 'Total loss': 0.5001620474186811} | train loss {'Reaction outcome loss': 0.5003360432963218, 'Total loss': 0.5003360432963218}
2022-11-28 05:27:28,204 INFO:     Found new best model at epoch 8
2022-11-28 05:27:28,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:28,204 INFO:     Epoch: 9
2022-11-28 05:27:28,869 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5226745273579251, 'Total loss': 0.5226745273579251} | train loss {'Reaction outcome loss': 0.4896699917773085, 'Total loss': 0.4896699917773085}
2022-11-28 05:27:28,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:28,869 INFO:     Epoch: 10
2022-11-28 05:27:29,534 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4908227087421851, 'Total loss': 0.4908227087421851} | train loss {'Reaction outcome loss': 0.4845603633251402, 'Total loss': 0.4845603633251402}
2022-11-28 05:27:29,534 INFO:     Found new best model at epoch 10
2022-11-28 05:27:29,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:29,535 INFO:     Epoch: 11
2022-11-28 05:27:30,203 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5051279772411693, 'Total loss': 0.5051279772411693} | train loss {'Reaction outcome loss': 0.4873825678782117, 'Total loss': 0.4873825678782117}
2022-11-28 05:27:30,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:30,203 INFO:     Epoch: 12
2022-11-28 05:27:30,869 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5093413286588409, 'Total loss': 0.5093413286588409} | train loss {'Reaction outcome loss': 0.48093811284390187, 'Total loss': 0.48093811284390187}
2022-11-28 05:27:30,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:30,869 INFO:     Epoch: 13
2022-11-28 05:27:31,535 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5118330703540281, 'Total loss': 0.5118330703540281} | train loss {'Reaction outcome loss': 0.47900398198755517, 'Total loss': 0.47900398198755517}
2022-11-28 05:27:31,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:31,535 INFO:     Epoch: 14
2022-11-28 05:27:32,199 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49013564600185916, 'Total loss': 0.49013564600185916} | train loss {'Reaction outcome loss': 0.4775169689749037, 'Total loss': 0.4775169689749037}
2022-11-28 05:27:32,199 INFO:     Found new best model at epoch 14
2022-11-28 05:27:32,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:32,200 INFO:     Epoch: 15
2022-11-28 05:27:32,870 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4762425212697549, 'Total loss': 0.4762425212697549} | train loss {'Reaction outcome loss': 0.4843875927430007, 'Total loss': 0.4843875927430007}
2022-11-28 05:27:32,870 INFO:     Found new best model at epoch 15
2022-11-28 05:27:32,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:32,871 INFO:     Epoch: 16
2022-11-28 05:27:33,535 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4826680216938257, 'Total loss': 0.4826680216938257} | train loss {'Reaction outcome loss': 0.48200147568939194, 'Total loss': 0.48200147568939194}
2022-11-28 05:27:33,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:33,535 INFO:     Epoch: 17
2022-11-28 05:27:34,200 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5150273980742152, 'Total loss': 0.5150273980742152} | train loss {'Reaction outcome loss': 0.47598636117313176, 'Total loss': 0.47598636117313176}
2022-11-28 05:27:34,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:34,200 INFO:     Epoch: 18
2022-11-28 05:27:34,864 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5271439755504782, 'Total loss': 0.5271439755504782} | train loss {'Reaction outcome loss': 0.47425048666134956, 'Total loss': 0.47425048666134956}
2022-11-28 05:27:34,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:34,864 INFO:     Epoch: 19
2022-11-28 05:27:35,528 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5142435539852489, 'Total loss': 0.5142435539852489} | train loss {'Reaction outcome loss': 0.47430258881180515, 'Total loss': 0.47430258881180515}
2022-11-28 05:27:35,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:35,528 INFO:     Epoch: 20
2022-11-28 05:27:36,194 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4721766005862843, 'Total loss': 0.4721766005862843} | train loss {'Reaction outcome loss': 0.4704723810596812, 'Total loss': 0.4704723810596812}
2022-11-28 05:27:36,194 INFO:     Found new best model at epoch 20
2022-11-28 05:27:36,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:36,195 INFO:     Epoch: 21
2022-11-28 05:27:36,855 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5113773691383275, 'Total loss': 0.5113773691383275} | train loss {'Reaction outcome loss': 0.4690692713784595, 'Total loss': 0.4690692713784595}
2022-11-28 05:27:36,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:36,856 INFO:     Epoch: 22
2022-11-28 05:27:37,519 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4774888174777681, 'Total loss': 0.4774888174777681} | train loss {'Reaction outcome loss': 0.4687035031496517, 'Total loss': 0.4687035031496517}
2022-11-28 05:27:37,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:37,519 INFO:     Epoch: 23
2022-11-28 05:27:38,186 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5111208646134897, 'Total loss': 0.5111208646134897} | train loss {'Reaction outcome loss': 0.4714799395371829, 'Total loss': 0.4714799395371829}
2022-11-28 05:27:38,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:38,186 INFO:     Epoch: 24
2022-11-28 05:27:38,850 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4944543486291712, 'Total loss': 0.4944543486291712} | train loss {'Reaction outcome loss': 0.46906191290866944, 'Total loss': 0.46906191290866944}
2022-11-28 05:27:38,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:38,851 INFO:     Epoch: 25
2022-11-28 05:27:39,516 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4966237846423279, 'Total loss': 0.4966237846423279} | train loss {'Reaction outcome loss': 0.478213986682315, 'Total loss': 0.478213986682315}
2022-11-28 05:27:39,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:39,516 INFO:     Epoch: 26
2022-11-28 05:27:40,186 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.503493495285511, 'Total loss': 0.503493495285511} | train loss {'Reaction outcome loss': 0.46501916637944596, 'Total loss': 0.46501916637944596}
2022-11-28 05:27:40,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:40,186 INFO:     Epoch: 27
2022-11-28 05:27:40,853 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4870213331146674, 'Total loss': 0.4870213331146674} | train loss {'Reaction outcome loss': 0.4694432669108914, 'Total loss': 0.4694432669108914}
2022-11-28 05:27:40,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:40,853 INFO:     Epoch: 28
2022-11-28 05:27:41,519 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.49121108888225123, 'Total loss': 0.49121108888225123} | train loss {'Reaction outcome loss': 0.46981587903874533, 'Total loss': 0.46981587903874533}
2022-11-28 05:27:41,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:41,520 INFO:     Epoch: 29
2022-11-28 05:27:42,190 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4868337034501813, 'Total loss': 0.4868337034501813} | train loss {'Reaction outcome loss': 0.4648309374648717, 'Total loss': 0.4648309374648717}
2022-11-28 05:27:42,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:42,190 INFO:     Epoch: 30
2022-11-28 05:27:42,857 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5150955854491754, 'Total loss': 0.5150955854491754} | train loss {'Reaction outcome loss': 0.4682547520966299, 'Total loss': 0.4682547520966299}
2022-11-28 05:27:42,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:42,857 INFO:     Epoch: 31
2022-11-28 05:27:43,523 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46366785805333743, 'Total loss': 0.46366785805333743} | train loss {'Reaction outcome loss': 0.4603415943321682, 'Total loss': 0.4603415943321682}
2022-11-28 05:27:43,523 INFO:     Found new best model at epoch 31
2022-11-28 05:27:43,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:43,524 INFO:     Epoch: 32
2022-11-28 05:27:44,189 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48666132376952603, 'Total loss': 0.48666132376952603} | train loss {'Reaction outcome loss': 0.465318244521416, 'Total loss': 0.465318244521416}
2022-11-28 05:27:44,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:44,189 INFO:     Epoch: 33
2022-11-28 05:27:44,855 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4849303232675249, 'Total loss': 0.4849303232675249} | train loss {'Reaction outcome loss': 0.4693988162062822, 'Total loss': 0.4693988162062822}
2022-11-28 05:27:44,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:44,855 INFO:     Epoch: 34
2022-11-28 05:27:45,519 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4968936128372496, 'Total loss': 0.4968936128372496} | train loss {'Reaction outcome loss': 0.4770381656144896, 'Total loss': 0.4770381656144896}
2022-11-28 05:27:45,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:45,520 INFO:     Epoch: 35
2022-11-28 05:27:46,182 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4947541369633241, 'Total loss': 0.4947541369633241} | train loss {'Reaction outcome loss': 0.46948280612066867, 'Total loss': 0.46948280612066867}
2022-11-28 05:27:46,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:46,183 INFO:     Epoch: 36
2022-11-28 05:27:46,847 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48497499457814475, 'Total loss': 0.48497499457814475} | train loss {'Reaction outcome loss': 0.4644388518025798, 'Total loss': 0.4644388518025798}
2022-11-28 05:27:46,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:46,847 INFO:     Epoch: 37
2022-11-28 05:27:47,513 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5016125135801055, 'Total loss': 0.5016125135801055} | train loss {'Reaction outcome loss': 0.46592871898845317, 'Total loss': 0.46592871898845317}
2022-11-28 05:27:47,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:47,513 INFO:     Epoch: 38
2022-11-28 05:27:48,175 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4641259840943597, 'Total loss': 0.4641259840943597} | train loss {'Reaction outcome loss': 0.46998085538225787, 'Total loss': 0.46998085538225787}
2022-11-28 05:27:48,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:48,176 INFO:     Epoch: 39
2022-11-28 05:27:48,841 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5145389444448731, 'Total loss': 0.5145389444448731} | train loss {'Reaction outcome loss': 0.4669928481622088, 'Total loss': 0.4669928481622088}
2022-11-28 05:27:48,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:48,841 INFO:     Epoch: 40
2022-11-28 05:27:49,505 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4787045724012635, 'Total loss': 0.4787045724012635} | train loss {'Reaction outcome loss': 0.4670074787591734, 'Total loss': 0.4670074787591734}
2022-11-28 05:27:49,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:49,505 INFO:     Epoch: 41
2022-11-28 05:27:50,168 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5222845893691886, 'Total loss': 0.5222845893691886} | train loss {'Reaction outcome loss': 0.46611152336962763, 'Total loss': 0.46611152336962763}
2022-11-28 05:27:50,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:50,168 INFO:     Epoch: 42
2022-11-28 05:27:50,831 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.492222206836397, 'Total loss': 0.492222206836397} | train loss {'Reaction outcome loss': 0.46165588882661635, 'Total loss': 0.46165588882661635}
2022-11-28 05:27:50,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:50,832 INFO:     Epoch: 43
2022-11-28 05:27:51,494 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4856281368569894, 'Total loss': 0.4856281368569894} | train loss {'Reaction outcome loss': 0.46363088380425205, 'Total loss': 0.46363088380425205}
2022-11-28 05:27:51,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:51,494 INFO:     Epoch: 44
2022-11-28 05:27:52,162 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48218186876990576, 'Total loss': 0.48218186876990576} | train loss {'Reaction outcome loss': 0.45685171293875865, 'Total loss': 0.45685171293875865}
2022-11-28 05:27:52,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:52,162 INFO:     Epoch: 45
2022-11-28 05:27:52,828 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4659048125825145, 'Total loss': 0.4659048125825145} | train loss {'Reaction outcome loss': 0.46395944094946306, 'Total loss': 0.46395944094946306}
2022-11-28 05:27:52,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:52,828 INFO:     Epoch: 46
2022-11-28 05:27:53,492 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47771243937313557, 'Total loss': 0.47771243937313557} | train loss {'Reaction outcome loss': 0.4588629214033004, 'Total loss': 0.4588629214033004}
2022-11-28 05:27:53,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:53,493 INFO:     Epoch: 47
2022-11-28 05:27:54,159 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4993246292526072, 'Total loss': 0.4993246292526072} | train loss {'Reaction outcome loss': 0.4684613292676307, 'Total loss': 0.4684613292676307}
2022-11-28 05:27:54,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:54,159 INFO:     Epoch: 48
2022-11-28 05:27:54,823 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47022411261092534, 'Total loss': 0.47022411261092534} | train loss {'Reaction outcome loss': 0.4667064188829353, 'Total loss': 0.4667064188829353}
2022-11-28 05:27:54,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:54,823 INFO:     Epoch: 49
2022-11-28 05:27:55,484 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4837803380055861, 'Total loss': 0.4837803380055861} | train loss {'Reaction outcome loss': 0.45777491504146206, 'Total loss': 0.45777491504146206}
2022-11-28 05:27:55,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:55,485 INFO:     Epoch: 50
2022-11-28 05:27:56,152 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4749761867252263, 'Total loss': 0.4749761867252263} | train loss {'Reaction outcome loss': 0.4548574444807826, 'Total loss': 0.4548574444807826}
2022-11-28 05:27:56,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:56,153 INFO:     Epoch: 51
2022-11-28 05:27:56,817 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5191647071730007, 'Total loss': 0.5191647071730007} | train loss {'Reaction outcome loss': 0.4640053974524621, 'Total loss': 0.4640053974524621}
2022-11-28 05:27:56,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:56,817 INFO:     Epoch: 52
2022-11-28 05:27:57,484 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.482710656455972, 'Total loss': 0.482710656455972} | train loss {'Reaction outcome loss': 0.46778562640951526, 'Total loss': 0.46778562640951526}
2022-11-28 05:27:57,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:57,485 INFO:     Epoch: 53
2022-11-28 05:27:58,153 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46687739206985995, 'Total loss': 0.46687739206985995} | train loss {'Reaction outcome loss': 0.4554681135041098, 'Total loss': 0.4554681135041098}
2022-11-28 05:27:58,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:58,153 INFO:     Epoch: 54
2022-11-28 05:27:58,822 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5080814219333909, 'Total loss': 0.5080814219333909} | train loss {'Reaction outcome loss': 0.4665918421721266, 'Total loss': 0.4665918421721266}
2022-11-28 05:27:58,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:58,822 INFO:     Epoch: 55
2022-11-28 05:27:59,488 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48244272849776526, 'Total loss': 0.48244272849776526} | train loss {'Reaction outcome loss': 0.4597652141725825, 'Total loss': 0.4597652141725825}
2022-11-28 05:27:59,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:27:59,488 INFO:     Epoch: 56
2022-11-28 05:28:00,155 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47098333456299524, 'Total loss': 0.47098333456299524} | train loss {'Reaction outcome loss': 0.45904272551377934, 'Total loss': 0.45904272551377934}
2022-11-28 05:28:00,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:00,156 INFO:     Epoch: 57
2022-11-28 05:28:00,822 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49739599803631956, 'Total loss': 0.49739599803631956} | train loss {'Reaction outcome loss': 0.4562075401866628, 'Total loss': 0.4562075401866628}
2022-11-28 05:28:00,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:00,823 INFO:     Epoch: 58
2022-11-28 05:28:01,492 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4998526346277107, 'Total loss': 0.4998526346277107} | train loss {'Reaction outcome loss': 0.4622076761217848, 'Total loss': 0.4622076761217848}
2022-11-28 05:28:01,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:01,492 INFO:     Epoch: 59
2022-11-28 05:28:02,159 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48076557977633044, 'Total loss': 0.48076557977633044} | train loss {'Reaction outcome loss': 0.4594215434645453, 'Total loss': 0.4594215434645453}
2022-11-28 05:28:02,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:02,159 INFO:     Epoch: 60
2022-11-28 05:28:02,827 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4721615385602821, 'Total loss': 0.4721615385602821} | train loss {'Reaction outcome loss': 0.45791254835503714, 'Total loss': 0.45791254835503714}
2022-11-28 05:28:02,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:02,828 INFO:     Epoch: 61
2022-11-28 05:28:03,492 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47180242159149866, 'Total loss': 0.47180242159149866} | train loss {'Reaction outcome loss': 0.47339136760321354, 'Total loss': 0.47339136760321354}
2022-11-28 05:28:03,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:03,493 INFO:     Epoch: 62
2022-11-28 05:28:04,158 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4742505533451384, 'Total loss': 0.4742505533451384} | train loss {'Reaction outcome loss': 0.4578851008367154, 'Total loss': 0.4578851008367154}
2022-11-28 05:28:04,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:04,158 INFO:     Epoch: 63
2022-11-28 05:28:04,823 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5180307213555683, 'Total loss': 0.5180307213555683} | train loss {'Reaction outcome loss': 0.4587829188113251, 'Total loss': 0.4587829188113251}
2022-11-28 05:28:04,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:04,823 INFO:     Epoch: 64
2022-11-28 05:28:05,488 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48711030320687726, 'Total loss': 0.48711030320687726} | train loss {'Reaction outcome loss': 0.4560722931017799, 'Total loss': 0.4560722931017799}
2022-11-28 05:28:05,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:05,489 INFO:     Epoch: 65
2022-11-28 05:28:06,155 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48121894692832773, 'Total loss': 0.48121894692832773} | train loss {'Reaction outcome loss': 0.46924410799458144, 'Total loss': 0.46924410799458144}
2022-11-28 05:28:06,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:06,155 INFO:     Epoch: 66
2022-11-28 05:28:06,821 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.485491105439988, 'Total loss': 0.485491105439988} | train loss {'Reaction outcome loss': 0.4617789647271556, 'Total loss': 0.4617789647271556}
2022-11-28 05:28:06,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:06,821 INFO:     Epoch: 67
2022-11-28 05:28:07,488 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48502215472134674, 'Total loss': 0.48502215472134674} | train loss {'Reaction outcome loss': 0.46489872002313215, 'Total loss': 0.46489872002313215}
2022-11-28 05:28:07,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:07,488 INFO:     Epoch: 68
2022-11-28 05:28:08,155 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4711101393808018, 'Total loss': 0.4711101393808018} | train loss {'Reaction outcome loss': 0.4607863543074458, 'Total loss': 0.4607863543074458}
2022-11-28 05:28:08,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:08,155 INFO:     Epoch: 69
2022-11-28 05:28:08,823 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48520327427170495, 'Total loss': 0.48520327427170495} | train loss {'Reaction outcome loss': 0.4563200818074326, 'Total loss': 0.4563200818074326}
2022-11-28 05:28:08,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:08,824 INFO:     Epoch: 70
2022-11-28 05:28:09,489 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4893825860186057, 'Total loss': 0.4893825860186057} | train loss {'Reaction outcome loss': 0.4640970242720458, 'Total loss': 0.4640970242720458}
2022-11-28 05:28:09,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:09,489 INFO:     Epoch: 71
2022-11-28 05:28:10,153 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4753843986175277, 'Total loss': 0.4753843986175277} | train loss {'Reaction outcome loss': 0.46413370372066576, 'Total loss': 0.46413370372066576}
2022-11-28 05:28:10,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:10,153 INFO:     Epoch: 72
2022-11-28 05:28:10,822 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46370830115946854, 'Total loss': 0.46370830115946854} | train loss {'Reaction outcome loss': 0.4573104937951411, 'Total loss': 0.4573104937951411}
2022-11-28 05:28:10,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:10,822 INFO:     Epoch: 73
2022-11-28 05:28:11,490 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.459186330776323, 'Total loss': 0.459186330776323} | train loss {'Reaction outcome loss': 0.4622749984264374, 'Total loss': 0.4622749984264374}
2022-11-28 05:28:11,490 INFO:     Found new best model at epoch 73
2022-11-28 05:28:11,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:11,491 INFO:     Epoch: 74
2022-11-28 05:28:12,157 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4673666093837131, 'Total loss': 0.4673666093837131} | train loss {'Reaction outcome loss': 0.46354290212114013, 'Total loss': 0.46354290212114013}
2022-11-28 05:28:12,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:12,157 INFO:     Epoch: 75
2022-11-28 05:28:12,821 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47075013477693906, 'Total loss': 0.47075013477693906} | train loss {'Reaction outcome loss': 0.4610674822582833, 'Total loss': 0.4610674822582833}
2022-11-28 05:28:12,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:12,821 INFO:     Epoch: 76
2022-11-28 05:28:13,491 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5423080562190576, 'Total loss': 0.5423080562190576} | train loss {'Reaction outcome loss': 0.46011805137799633, 'Total loss': 0.46011805137799633}
2022-11-28 05:28:13,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:13,491 INFO:     Epoch: 77
2022-11-28 05:28:14,156 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4957173639400439, 'Total loss': 0.4957173639400439} | train loss {'Reaction outcome loss': 0.4621194038960722, 'Total loss': 0.4621194038960722}
2022-11-28 05:28:14,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:14,156 INFO:     Epoch: 78
2022-11-28 05:28:14,821 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49500506269660866, 'Total loss': 0.49500506269660866} | train loss {'Reaction outcome loss': 0.4694303124542198, 'Total loss': 0.4694303124542198}
2022-11-28 05:28:14,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:14,822 INFO:     Epoch: 79
2022-11-28 05:28:15,491 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4860996001146056, 'Total loss': 0.4860996001146056} | train loss {'Reaction outcome loss': 0.46413835035937445, 'Total loss': 0.46413835035937445}
2022-11-28 05:28:15,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:15,491 INFO:     Epoch: 80
2022-11-28 05:28:16,158 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4824504918334159, 'Total loss': 0.4824504918334159} | train loss {'Reaction outcome loss': 0.45991833096430185, 'Total loss': 0.45991833096430185}
2022-11-28 05:28:16,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:16,158 INFO:     Epoch: 81
2022-11-28 05:28:16,829 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5440109920772639, 'Total loss': 0.5440109920772639} | train loss {'Reaction outcome loss': 0.465936946231992, 'Total loss': 0.465936946231992}
2022-11-28 05:28:16,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:16,829 INFO:     Epoch: 82
2022-11-28 05:28:17,502 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48783092268488626, 'Total loss': 0.48783092268488626} | train loss {'Reaction outcome loss': 0.4604131493176664, 'Total loss': 0.4604131493176664}
2022-11-28 05:28:17,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:17,502 INFO:     Epoch: 83
2022-11-28 05:28:18,172 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48992505771192635, 'Total loss': 0.48992505771192635} | train loss {'Reaction outcome loss': 0.4652438595169975, 'Total loss': 0.4652438595169975}
2022-11-28 05:28:18,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:18,173 INFO:     Epoch: 84
2022-11-28 05:28:18,841 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4708648279986598, 'Total loss': 0.4708648279986598} | train loss {'Reaction outcome loss': 0.46449633071859997, 'Total loss': 0.46449633071859997}
2022-11-28 05:28:18,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:18,841 INFO:     Epoch: 85
2022-11-28 05:28:19,508 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49612995101646945, 'Total loss': 0.49612995101646945} | train loss {'Reaction outcome loss': 0.4653113627385709, 'Total loss': 0.4653113627385709}
2022-11-28 05:28:19,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:19,509 INFO:     Epoch: 86
2022-11-28 05:28:20,174 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45107586918906734, 'Total loss': 0.45107586918906734} | train loss {'Reaction outcome loss': 0.46263491482503954, 'Total loss': 0.46263491482503954}
2022-11-28 05:28:20,174 INFO:     Found new best model at epoch 86
2022-11-28 05:28:20,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:20,175 INFO:     Epoch: 87
2022-11-28 05:28:20,835 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4660606133666905, 'Total loss': 0.4660606133666905} | train loss {'Reaction outcome loss': 0.45865051775810217, 'Total loss': 0.45865051775810217}
2022-11-28 05:28:20,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:20,835 INFO:     Epoch: 88
2022-11-28 05:28:21,500 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5022355622865937, 'Total loss': 0.5022355622865937} | train loss {'Reaction outcome loss': 0.4605158472193345, 'Total loss': 0.4605158472193345}
2022-11-28 05:28:21,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:21,501 INFO:     Epoch: 89
2022-11-28 05:28:22,167 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47515043954957614, 'Total loss': 0.47515043954957614} | train loss {'Reaction outcome loss': 0.4608561931959083, 'Total loss': 0.4608561931959083}
2022-11-28 05:28:22,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:22,167 INFO:     Epoch: 90
2022-11-28 05:28:22,831 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49551158025860786, 'Total loss': 0.49551158025860786} | train loss {'Reaction outcome loss': 0.4668299092520629, 'Total loss': 0.4668299092520629}
2022-11-28 05:28:22,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:22,831 INFO:     Epoch: 91
2022-11-28 05:28:23,496 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.480527594008229, 'Total loss': 0.480527594008229} | train loss {'Reaction outcome loss': 0.4604472010246208, 'Total loss': 0.4604472010246208}
2022-11-28 05:28:23,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:23,497 INFO:     Epoch: 92
2022-11-28 05:28:24,163 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4863306473601948, 'Total loss': 0.4863306473601948} | train loss {'Reaction outcome loss': 0.46180769909293423, 'Total loss': 0.46180769909293423}
2022-11-28 05:28:24,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:24,163 INFO:     Epoch: 93
2022-11-28 05:28:24,830 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4646281437440352, 'Total loss': 0.4646281437440352} | train loss {'Reaction outcome loss': 0.4638191493408334, 'Total loss': 0.4638191493408334}
2022-11-28 05:28:24,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:24,831 INFO:     Epoch: 94
2022-11-28 05:28:25,495 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.474000828509981, 'Total loss': 0.474000828509981} | train loss {'Reaction outcome loss': 0.4616836633893751, 'Total loss': 0.4616836633893751}
2022-11-28 05:28:25,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:25,496 INFO:     Epoch: 95
2022-11-28 05:28:26,160 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4795102124864405, 'Total loss': 0.4795102124864405} | train loss {'Reaction outcome loss': 0.46702402709953245, 'Total loss': 0.46702402709953245}
2022-11-28 05:28:26,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:26,161 INFO:     Epoch: 96
2022-11-28 05:28:26,827 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4924891848455776, 'Total loss': 0.4924891848455776} | train loss {'Reaction outcome loss': 0.45309773087501526, 'Total loss': 0.45309773087501526}
2022-11-28 05:28:26,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:26,828 INFO:     Epoch: 97
2022-11-28 05:28:27,492 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4773144413801757, 'Total loss': 0.4773144413801757} | train loss {'Reaction outcome loss': 0.4591337399737489, 'Total loss': 0.4591337399737489}
2022-11-28 05:28:27,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:27,493 INFO:     Epoch: 98
2022-11-28 05:28:28,158 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4996660805561326, 'Total loss': 0.4996660805561326} | train loss {'Reaction outcome loss': 0.4601904000606268, 'Total loss': 0.4601904000606268}
2022-11-28 05:28:28,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:28,159 INFO:     Epoch: 99
2022-11-28 05:28:28,821 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49210544607856055, 'Total loss': 0.49210544607856055} | train loss {'Reaction outcome loss': 0.4698263727008335, 'Total loss': 0.4698263727008335}
2022-11-28 05:28:28,821 INFO:     Best model found after epoch 87 of 100.
2022-11-28 05:28:28,821 INFO:   Done with stage: TRAINING
2022-11-28 05:28:28,821 INFO:   Starting stage: EVALUATION
2022-11-28 05:28:28,933 INFO:   Done with stage: EVALUATION
2022-11-28 05:28:28,942 INFO:   Leaving out SEQ value Fold_0
2022-11-28 05:28:28,954 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 05:28:28,954 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:28:29,594 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:28:29,594 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:28:29,664 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:28:29,664 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:28:29,664 INFO:     No hyperparam tuning for this model
2022-11-28 05:28:29,664 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:28:29,664 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:28:29,665 INFO:     None feature selector for col prot
2022-11-28 05:28:29,665 INFO:     None feature selector for col prot
2022-11-28 05:28:29,665 INFO:     None feature selector for col prot
2022-11-28 05:28:29,666 INFO:     None feature selector for col chem
2022-11-28 05:28:29,666 INFO:     None feature selector for col chem
2022-11-28 05:28:29,666 INFO:     None feature selector for col chem
2022-11-28 05:28:29,666 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:28:29,666 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:28:29,667 INFO:     Number of params in model 169651
2022-11-28 05:28:29,670 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:28:29,670 INFO:   Starting stage: TRAINING
2022-11-28 05:28:29,721 INFO:     Val loss before train {'Reaction outcome loss': 0.9693858311934904, 'Total loss': 0.9693858311934904}
2022-11-28 05:28:29,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:29,722 INFO:     Epoch: 0
2022-11-28 05:28:30,384 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.595772996544838, 'Total loss': 0.595772996544838} | train loss {'Reaction outcome loss': 0.7001678885718589, 'Total loss': 0.7001678885718589}
2022-11-28 05:28:30,384 INFO:     Found new best model at epoch 0
2022-11-28 05:28:30,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:30,385 INFO:     Epoch: 1
2022-11-28 05:28:31,050 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6317892257462848, 'Total loss': 0.6317892257462848} | train loss {'Reaction outcome loss': 0.5897102948383763, 'Total loss': 0.5897102948383763}
2022-11-28 05:28:31,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:31,050 INFO:     Epoch: 2
2022-11-28 05:28:31,715 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5451808703893964, 'Total loss': 0.5451808703893964} | train loss {'Reaction outcome loss': 0.5658549460080954, 'Total loss': 0.5658549460080954}
2022-11-28 05:28:31,715 INFO:     Found new best model at epoch 2
2022-11-28 05:28:31,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:31,716 INFO:     Epoch: 3
2022-11-28 05:28:32,377 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5183388997207988, 'Total loss': 0.5183388997207988} | train loss {'Reaction outcome loss': 0.5397126333795579, 'Total loss': 0.5397126333795579}
2022-11-28 05:28:32,377 INFO:     Found new best model at epoch 3
2022-11-28 05:28:32,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:32,378 INFO:     Epoch: 4
2022-11-28 05:28:33,040 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.576222354376858, 'Total loss': 0.576222354376858} | train loss {'Reaction outcome loss': 0.5523268790983478, 'Total loss': 0.5523268790983478}
2022-11-28 05:28:33,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:33,040 INFO:     Epoch: 5
2022-11-28 05:28:33,704 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5217066644267603, 'Total loss': 0.5217066644267603} | train loss {'Reaction outcome loss': 0.5228646228067305, 'Total loss': 0.5228646228067305}
2022-11-28 05:28:33,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:33,704 INFO:     Epoch: 6
2022-11-28 05:28:34,366 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5391106304119934, 'Total loss': 0.5391106304119934} | train loss {'Reaction outcome loss': 0.5260302149935773, 'Total loss': 0.5260302149935773}
2022-11-28 05:28:34,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:34,366 INFO:     Epoch: 7
2022-11-28 05:28:35,028 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5134347501126203, 'Total loss': 0.5134347501126203} | train loss {'Reaction outcome loss': 0.5089454025874737, 'Total loss': 0.5089454025874737}
2022-11-28 05:28:35,028 INFO:     Found new best model at epoch 7
2022-11-28 05:28:35,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:35,029 INFO:     Epoch: 8
2022-11-28 05:28:35,689 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4790245375849984, 'Total loss': 0.4790245375849984} | train loss {'Reaction outcome loss': 0.48963577887759757, 'Total loss': 0.48963577887759757}
2022-11-28 05:28:35,690 INFO:     Found new best model at epoch 8
2022-11-28 05:28:35,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:35,690 INFO:     Epoch: 9
2022-11-28 05:28:36,354 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5135883065787229, 'Total loss': 0.5135883065787229} | train loss {'Reaction outcome loss': 0.4829944166079586, 'Total loss': 0.4829944166079586}
2022-11-28 05:28:36,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:36,354 INFO:     Epoch: 10
2022-11-28 05:28:37,017 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5108473219654777, 'Total loss': 0.5108473219654777} | train loss {'Reaction outcome loss': 0.488966260361768, 'Total loss': 0.488966260361768}
2022-11-28 05:28:37,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:37,017 INFO:     Epoch: 11
2022-11-28 05:28:37,681 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4812870181419633, 'Total loss': 0.4812870181419633} | train loss {'Reaction outcome loss': 0.4886891249461695, 'Total loss': 0.4886891249461695}
2022-11-28 05:28:37,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:37,682 INFO:     Epoch: 12
2022-11-28 05:28:38,341 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5616690435192802, 'Total loss': 0.5616690435192802} | train loss {'Reaction outcome loss': 0.49032144272617, 'Total loss': 0.49032144272617}
2022-11-28 05:28:38,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:38,341 INFO:     Epoch: 13
2022-11-28 05:28:39,004 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48212269151752646, 'Total loss': 0.48212269151752646} | train loss {'Reaction outcome loss': 0.48436771206527585, 'Total loss': 0.48436771206527585}
2022-11-28 05:28:39,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:39,005 INFO:     Epoch: 14
2022-11-28 05:28:39,666 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.504926813597029, 'Total loss': 0.504926813597029} | train loss {'Reaction outcome loss': 0.47688757392166836, 'Total loss': 0.47688757392166836}
2022-11-28 05:28:39,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:39,666 INFO:     Epoch: 15
2022-11-28 05:28:40,328 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47589249299331143, 'Total loss': 0.47589249299331143} | train loss {'Reaction outcome loss': 0.47847925054158275, 'Total loss': 0.47847925054158275}
2022-11-28 05:28:40,329 INFO:     Found new best model at epoch 15
2022-11-28 05:28:40,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:40,330 INFO:     Epoch: 16
2022-11-28 05:28:40,997 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46138518066568807, 'Total loss': 0.46138518066568807} | train loss {'Reaction outcome loss': 0.4782477131618662, 'Total loss': 0.4782477131618662}
2022-11-28 05:28:40,997 INFO:     Found new best model at epoch 16
2022-11-28 05:28:40,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:40,998 INFO:     Epoch: 17
2022-11-28 05:28:41,661 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4888745868070559, 'Total loss': 0.4888745868070559} | train loss {'Reaction outcome loss': 0.477391817701249, 'Total loss': 0.477391817701249}
2022-11-28 05:28:41,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:41,661 INFO:     Epoch: 18
2022-11-28 05:28:42,319 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48008686575022613, 'Total loss': 0.48008686575022613} | train loss {'Reaction outcome loss': 0.4761991624754329, 'Total loss': 0.4761991624754329}
2022-11-28 05:28:42,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:42,320 INFO:     Epoch: 19
2022-11-28 05:28:42,983 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47487999532710423, 'Total loss': 0.47487999532710423} | train loss {'Reaction outcome loss': 0.4730238609830378, 'Total loss': 0.4730238609830378}
2022-11-28 05:28:42,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:42,983 INFO:     Epoch: 20
2022-11-28 05:28:43,646 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5115704014897346, 'Total loss': 0.5115704014897346} | train loss {'Reaction outcome loss': 0.479269663196223, 'Total loss': 0.479269663196223}
2022-11-28 05:28:43,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:43,647 INFO:     Epoch: 21
2022-11-28 05:28:44,305 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47967126389796083, 'Total loss': 0.47967126389796083} | train loss {'Reaction outcome loss': 0.4777783393739206, 'Total loss': 0.4777783393739206}
2022-11-28 05:28:44,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:44,306 INFO:     Epoch: 22
2022-11-28 05:28:44,972 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4495050642978061, 'Total loss': 0.4495050642978061} | train loss {'Reaction outcome loss': 0.47138934886000056, 'Total loss': 0.47138934886000056}
2022-11-28 05:28:44,972 INFO:     Found new best model at epoch 22
2022-11-28 05:28:44,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:44,973 INFO:     Epoch: 23
2022-11-28 05:28:45,641 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.49258086999708955, 'Total loss': 0.49258086999708955} | train loss {'Reaction outcome loss': 0.4691776370833277, 'Total loss': 0.4691776370833277}
2022-11-28 05:28:45,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:45,641 INFO:     Epoch: 24
2022-11-28 05:28:46,306 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46865295991301537, 'Total loss': 0.46865295991301537} | train loss {'Reaction outcome loss': 0.4747403548193364, 'Total loss': 0.4747403548193364}
2022-11-28 05:28:46,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:46,307 INFO:     Epoch: 25
2022-11-28 05:28:46,969 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47798933122645726, 'Total loss': 0.47798933122645726} | train loss {'Reaction outcome loss': 0.4728164225213441, 'Total loss': 0.4728164225213441}
2022-11-28 05:28:46,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:46,970 INFO:     Epoch: 26
2022-11-28 05:28:47,632 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5032975456931374, 'Total loss': 0.5032975456931374} | train loss {'Reaction outcome loss': 0.4621828230407074, 'Total loss': 0.4621828230407074}
2022-11-28 05:28:47,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:47,632 INFO:     Epoch: 27
2022-11-28 05:28:48,295 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4586101397871971, 'Total loss': 0.4586101397871971} | train loss {'Reaction outcome loss': 0.4720409565608994, 'Total loss': 0.4720409565608994}
2022-11-28 05:28:48,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:48,295 INFO:     Epoch: 28
2022-11-28 05:28:48,958 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47744711776348675, 'Total loss': 0.47744711776348675} | train loss {'Reaction outcome loss': 0.4667002240173247, 'Total loss': 0.4667002240173247}
2022-11-28 05:28:48,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:48,958 INFO:     Epoch: 29
2022-11-28 05:28:49,622 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4913283525542779, 'Total loss': 0.4913283525542779} | train loss {'Reaction outcome loss': 0.46924109473402204, 'Total loss': 0.46924109473402204}
2022-11-28 05:28:49,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:49,623 INFO:     Epoch: 30
2022-11-28 05:28:50,284 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47412175888364966, 'Total loss': 0.47412175888364966} | train loss {'Reaction outcome loss': 0.48046838733469427, 'Total loss': 0.48046838733469427}
2022-11-28 05:28:50,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:50,285 INFO:     Epoch: 31
2022-11-28 05:28:50,945 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5349497849291022, 'Total loss': 0.5349497849291022} | train loss {'Reaction outcome loss': 0.471537359270007, 'Total loss': 0.471537359270007}
2022-11-28 05:28:50,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:50,945 INFO:     Epoch: 32
2022-11-28 05:28:51,606 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4580021398988637, 'Total loss': 0.4580021398988637} | train loss {'Reaction outcome loss': 0.47509109406818745, 'Total loss': 0.47509109406818745}
2022-11-28 05:28:51,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:51,606 INFO:     Epoch: 33
2022-11-28 05:28:52,268 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46905035694891756, 'Total loss': 0.46905035694891756} | train loss {'Reaction outcome loss': 0.4699798897361224, 'Total loss': 0.4699798897361224}
2022-11-28 05:28:52,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:52,268 INFO:     Epoch: 34
2022-11-28 05:28:52,932 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45663560046391055, 'Total loss': 0.45663560046391055} | train loss {'Reaction outcome loss': 0.4690698727905026, 'Total loss': 0.4690698727905026}
2022-11-28 05:28:52,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:52,933 INFO:     Epoch: 35
2022-11-28 05:28:53,592 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46423001418059523, 'Total loss': 0.46423001418059523} | train loss {'Reaction outcome loss': 0.4803378862528666, 'Total loss': 0.4803378862528666}
2022-11-28 05:28:53,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:53,592 INFO:     Epoch: 36
2022-11-28 05:28:54,253 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4870849990031936, 'Total loss': 0.4870849990031936} | train loss {'Reaction outcome loss': 0.4742058084802589, 'Total loss': 0.4742058084802589}
2022-11-28 05:28:54,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:54,253 INFO:     Epoch: 37
2022-11-28 05:28:54,917 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4754074341194196, 'Total loss': 0.4754074341194196} | train loss {'Reaction outcome loss': 0.4701409010661517, 'Total loss': 0.4701409010661517}
2022-11-28 05:28:54,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:54,917 INFO:     Epoch: 38
2022-11-28 05:28:55,579 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45108878273855557, 'Total loss': 0.45108878273855557} | train loss {'Reaction outcome loss': 0.46524331552779624, 'Total loss': 0.46524331552779624}
2022-11-28 05:28:55,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:55,580 INFO:     Epoch: 39
2022-11-28 05:28:56,239 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45891595259308815, 'Total loss': 0.45891595259308815} | train loss {'Reaction outcome loss': 0.4669146213816245, 'Total loss': 0.4669146213816245}
2022-11-28 05:28:56,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:56,239 INFO:     Epoch: 40
2022-11-28 05:28:56,900 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5375227758830244, 'Total loss': 0.5375227758830244} | train loss {'Reaction outcome loss': 0.46938524386178143, 'Total loss': 0.46938524386178143}
2022-11-28 05:28:56,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:56,900 INFO:     Epoch: 41
2022-11-28 05:28:57,564 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49404292926192284, 'Total loss': 0.49404292926192284} | train loss {'Reaction outcome loss': 0.4769204686045164, 'Total loss': 0.4769204686045164}
2022-11-28 05:28:57,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:57,564 INFO:     Epoch: 42
2022-11-28 05:28:58,228 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5015776458789002, 'Total loss': 0.5015776458789002} | train loss {'Reaction outcome loss': 0.523148268008763, 'Total loss': 0.523148268008763}
2022-11-28 05:28:58,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:58,228 INFO:     Epoch: 43
2022-11-28 05:28:58,891 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.474041223526001, 'Total loss': 0.474041223526001} | train loss {'Reaction outcome loss': 0.47369396300450994, 'Total loss': 0.47369396300450994}
2022-11-28 05:28:58,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:58,892 INFO:     Epoch: 44
2022-11-28 05:28:59,553 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.6425673501058058, 'Total loss': 0.6425673501058058} | train loss {'Reaction outcome loss': 0.46726013020223933, 'Total loss': 0.46726013020223933}
2022-11-28 05:28:59,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:28:59,553 INFO:     Epoch: 45
2022-11-28 05:29:00,216 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49041496945375745, 'Total loss': 0.49041496945375745} | train loss {'Reaction outcome loss': 0.47099576685351396, 'Total loss': 0.47099576685351396}
2022-11-28 05:29:00,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:00,216 INFO:     Epoch: 46
2022-11-28 05:29:00,876 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4541593979705464, 'Total loss': 0.4541593979705464} | train loss {'Reaction outcome loss': 0.468884904224139, 'Total loss': 0.468884904224139}
2022-11-28 05:29:00,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:00,876 INFO:     Epoch: 47
2022-11-28 05:29:01,538 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4821436107158661, 'Total loss': 0.4821436107158661} | train loss {'Reaction outcome loss': 0.47506971596947567, 'Total loss': 0.47506971596947567}
2022-11-28 05:29:01,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:01,538 INFO:     Epoch: 48
2022-11-28 05:29:02,200 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46539672362533485, 'Total loss': 0.46539672362533485} | train loss {'Reaction outcome loss': 0.463509744809948, 'Total loss': 0.463509744809948}
2022-11-28 05:29:02,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:02,200 INFO:     Epoch: 49
2022-11-28 05:29:02,861 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46605554155328055, 'Total loss': 0.46605554155328055} | train loss {'Reaction outcome loss': 0.46710329831611774, 'Total loss': 0.46710329831611774}
2022-11-28 05:29:02,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:02,862 INFO:     Epoch: 50
2022-11-28 05:29:03,523 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46247046982700174, 'Total loss': 0.46247046982700174} | train loss {'Reaction outcome loss': 0.473845559093151, 'Total loss': 0.473845559093151}
2022-11-28 05:29:03,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:03,524 INFO:     Epoch: 51
2022-11-28 05:29:04,184 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47568287497217004, 'Total loss': 0.47568287497217004} | train loss {'Reaction outcome loss': 0.4610058837815335, 'Total loss': 0.4610058837815335}
2022-11-28 05:29:04,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:04,184 INFO:     Epoch: 52
2022-11-28 05:29:04,847 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4600302451713519, 'Total loss': 0.4600302451713519} | train loss {'Reaction outcome loss': 0.4754788619786622, 'Total loss': 0.4754788619786622}
2022-11-28 05:29:04,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:04,847 INFO:     Epoch: 53
2022-11-28 05:29:05,513 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46387897872112016, 'Total loss': 0.46387897872112016} | train loss {'Reaction outcome loss': 0.47472175835115227, 'Total loss': 0.47472175835115227}
2022-11-28 05:29:05,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:05,513 INFO:     Epoch: 54
2022-11-28 05:29:06,177 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4634118872610005, 'Total loss': 0.4634118872610005} | train loss {'Reaction outcome loss': 0.4908809281795131, 'Total loss': 0.4908809281795131}
2022-11-28 05:29:06,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:06,177 INFO:     Epoch: 55
2022-11-28 05:29:06,841 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4563694264401089, 'Total loss': 0.4563694264401089} | train loss {'Reaction outcome loss': 0.5068515828972765, 'Total loss': 0.5068515828972765}
2022-11-28 05:29:06,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:06,841 INFO:     Epoch: 56
2022-11-28 05:29:07,501 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48110674626447936, 'Total loss': 0.48110674626447936} | train loss {'Reaction outcome loss': 0.4736014571387758, 'Total loss': 0.4736014571387758}
2022-11-28 05:29:07,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:07,502 INFO:     Epoch: 57
2022-11-28 05:29:08,161 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5066951012069528, 'Total loss': 0.5066951012069528} | train loss {'Reaction outcome loss': 0.4668370151797098, 'Total loss': 0.4668370151797098}
2022-11-28 05:29:08,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:08,161 INFO:     Epoch: 58
2022-11-28 05:29:08,819 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5292821682312272, 'Total loss': 0.5292821682312272} | train loss {'Reaction outcome loss': 0.4711262712835783, 'Total loss': 0.4711262712835783}
2022-11-28 05:29:08,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:08,820 INFO:     Epoch: 59
2022-11-28 05:29:09,482 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47528793527321384, 'Total loss': 0.47528793527321384} | train loss {'Reaction outcome loss': 0.48368641498841736, 'Total loss': 0.48368641498841736}
2022-11-28 05:29:09,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:09,482 INFO:     Epoch: 60
2022-11-28 05:29:10,146 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4730141040953723, 'Total loss': 0.4730141040953723} | train loss {'Reaction outcome loss': 0.4740015411304559, 'Total loss': 0.4740015411304559}
2022-11-28 05:29:10,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:10,146 INFO:     Epoch: 61
2022-11-28 05:29:10,807 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46185136755759065, 'Total loss': 0.46185136755759065} | train loss {'Reaction outcome loss': 0.4778056548312608, 'Total loss': 0.4778056548312608}
2022-11-28 05:29:10,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:10,808 INFO:     Epoch: 62
2022-11-28 05:29:11,472 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5361742248589342, 'Total loss': 0.5361742248589342} | train loss {'Reaction outcome loss': 0.48030301608778686, 'Total loss': 0.48030301608778686}
2022-11-28 05:29:11,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:11,473 INFO:     Epoch: 63
2022-11-28 05:29:12,134 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4658769494430585, 'Total loss': 0.4658769494430585} | train loss {'Reaction outcome loss': 0.47515395247501885, 'Total loss': 0.47515395247501885}
2022-11-28 05:29:12,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:12,135 INFO:     Epoch: 64
2022-11-28 05:29:12,796 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46774725192649796, 'Total loss': 0.46774725192649796} | train loss {'Reaction outcome loss': 0.46780178864837174, 'Total loss': 0.46780178864837174}
2022-11-28 05:29:12,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:12,796 INFO:     Epoch: 65
2022-11-28 05:29:13,459 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4488253337754445, 'Total loss': 0.4488253337754445} | train loss {'Reaction outcome loss': 0.4906376564671636, 'Total loss': 0.4906376564671636}
2022-11-28 05:29:13,459 INFO:     Found new best model at epoch 65
2022-11-28 05:29:13,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:13,460 INFO:     Epoch: 66
2022-11-28 05:29:14,120 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5127058631994508, 'Total loss': 0.5127058631994508} | train loss {'Reaction outcome loss': 0.5270591599862977, 'Total loss': 0.5270591599862977}
2022-11-28 05:29:14,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:14,120 INFO:     Epoch: 67
2022-11-28 05:29:14,779 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46159461682493036, 'Total loss': 0.46159461682493036} | train loss {'Reaction outcome loss': 0.4807427197332807, 'Total loss': 0.4807427197332807}
2022-11-28 05:29:14,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:14,780 INFO:     Epoch: 68
2022-11-28 05:29:15,443 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45186295766722073, 'Total loss': 0.45186295766722073} | train loss {'Reaction outcome loss': 0.4713895773969455, 'Total loss': 0.4713895773969455}
2022-11-28 05:29:15,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:15,443 INFO:     Epoch: 69
2022-11-28 05:29:16,103 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4881763326173479, 'Total loss': 0.4881763326173479} | train loss {'Reaction outcome loss': 0.470141772316535, 'Total loss': 0.470141772316535}
2022-11-28 05:29:16,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:16,103 INFO:     Epoch: 70
2022-11-28 05:29:16,763 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45119172063740814, 'Total loss': 0.45119172063740814} | train loss {'Reaction outcome loss': 0.47020176773973804, 'Total loss': 0.47020176773973804}
2022-11-28 05:29:16,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:16,763 INFO:     Epoch: 71
2022-11-28 05:29:17,425 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4838191033764319, 'Total loss': 0.4838191033764319} | train loss {'Reaction outcome loss': 0.4634985487779927, 'Total loss': 0.4634985487779927}
2022-11-28 05:29:17,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:17,425 INFO:     Epoch: 72
2022-11-28 05:29:18,087 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45151495561003685, 'Total loss': 0.45151495561003685} | train loss {'Reaction outcome loss': 0.466186678300985, 'Total loss': 0.466186678300985}
2022-11-28 05:29:18,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:18,087 INFO:     Epoch: 73
2022-11-28 05:29:18,752 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5077772330154072, 'Total loss': 0.5077772330154072} | train loss {'Reaction outcome loss': 0.4685428074527125, 'Total loss': 0.4685428074527125}
2022-11-28 05:29:18,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:18,752 INFO:     Epoch: 74
2022-11-28 05:29:19,412 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46724117039279506, 'Total loss': 0.46724117039279506} | train loss {'Reaction outcome loss': 0.4687799909698818, 'Total loss': 0.4687799909698818}
2022-11-28 05:29:19,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:19,413 INFO:     Epoch: 75
2022-11-28 05:29:20,072 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5085318393327973, 'Total loss': 0.5085318393327973} | train loss {'Reaction outcome loss': 0.4688268223030847, 'Total loss': 0.4688268223030847}
2022-11-28 05:29:20,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:20,072 INFO:     Epoch: 76
2022-11-28 05:29:20,731 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4653358862481334, 'Total loss': 0.4653358862481334} | train loss {'Reaction outcome loss': 0.47164690295453016, 'Total loss': 0.47164690295453016}
2022-11-28 05:29:20,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:20,731 INFO:     Epoch: 77
2022-11-28 05:29:21,392 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.463591224767945, 'Total loss': 0.463591224767945} | train loss {'Reaction outcome loss': 0.4701343418856864, 'Total loss': 0.4701343418856864}
2022-11-28 05:29:21,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:21,392 INFO:     Epoch: 78
2022-11-28 05:29:22,052 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4681270532310009, 'Total loss': 0.4681270532310009} | train loss {'Reaction outcome loss': 0.4668363716438232, 'Total loss': 0.4668363716438232}
2022-11-28 05:29:22,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:22,052 INFO:     Epoch: 79
2022-11-28 05:29:22,713 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5322833731770515, 'Total loss': 0.5322833731770515} | train loss {'Reaction outcome loss': 0.463658087227026, 'Total loss': 0.463658087227026}
2022-11-28 05:29:22,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:22,713 INFO:     Epoch: 80
2022-11-28 05:29:23,377 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48676116730679164, 'Total loss': 0.48676116730679164} | train loss {'Reaction outcome loss': 0.47348151392933086, 'Total loss': 0.47348151392933086}
2022-11-28 05:29:23,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:23,377 INFO:     Epoch: 81
2022-11-28 05:29:24,040 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46611842343753035, 'Total loss': 0.46611842343753035} | train loss {'Reaction outcome loss': 0.4637180486079381, 'Total loss': 0.4637180486079381}
2022-11-28 05:29:24,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:24,041 INFO:     Epoch: 82
2022-11-28 05:29:24,700 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45140187797898595, 'Total loss': 0.45140187797898595} | train loss {'Reaction outcome loss': 0.47162353214223374, 'Total loss': 0.47162353214223374}
2022-11-28 05:29:24,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:24,701 INFO:     Epoch: 83
2022-11-28 05:29:25,363 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5084210209209811, 'Total loss': 0.5084210209209811} | train loss {'Reaction outcome loss': 0.47169621101757775, 'Total loss': 0.47169621101757775}
2022-11-28 05:29:25,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:25,363 INFO:     Epoch: 84
2022-11-28 05:29:26,027 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47499714114449243, 'Total loss': 0.47499714114449243} | train loss {'Reaction outcome loss': 0.4792454211278875, 'Total loss': 0.4792454211278875}
2022-11-28 05:29:26,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:26,027 INFO:     Epoch: 85
2022-11-28 05:29:26,692 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44969437034292653, 'Total loss': 0.44969437034292653} | train loss {'Reaction outcome loss': 0.46297268451828705, 'Total loss': 0.46297268451828705}
2022-11-28 05:29:26,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:26,692 INFO:     Epoch: 86
2022-11-28 05:29:27,353 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4829300885850733, 'Total loss': 0.4829300885850733} | train loss {'Reaction outcome loss': 0.47796648034923955, 'Total loss': 0.47796648034923955}
2022-11-28 05:29:27,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:27,353 INFO:     Epoch: 87
2022-11-28 05:29:28,016 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4617074822837656, 'Total loss': 0.4617074822837656} | train loss {'Reaction outcome loss': 0.46931541373251906, 'Total loss': 0.46931541373251906}
2022-11-28 05:29:28,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:28,017 INFO:     Epoch: 88
2022-11-28 05:29:28,679 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48021713813597505, 'Total loss': 0.48021713813597505} | train loss {'Reaction outcome loss': 0.4837373100552964, 'Total loss': 0.4837373100552964}
2022-11-28 05:29:28,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:28,680 INFO:     Epoch: 89
2022-11-28 05:29:29,343 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4556384465911172, 'Total loss': 0.4556384465911172} | train loss {'Reaction outcome loss': 0.47343847191768135, 'Total loss': 0.47343847191768135}
2022-11-28 05:29:29,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:29,343 INFO:     Epoch: 90
2022-11-28 05:29:30,003 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46098954704674805, 'Total loss': 0.46098954704674805} | train loss {'Reaction outcome loss': 0.4671601625517584, 'Total loss': 0.4671601625517584}
2022-11-28 05:29:30,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:30,003 INFO:     Epoch: 91
2022-11-28 05:29:30,667 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4996296272359111, 'Total loss': 0.4996296272359111} | train loss {'Reaction outcome loss': 0.4843014658462663, 'Total loss': 0.4843014658462663}
2022-11-28 05:29:30,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:30,668 INFO:     Epoch: 92
2022-11-28 05:29:31,332 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4840478275648572, 'Total loss': 0.4840478275648572} | train loss {'Reaction outcome loss': 0.4732806123340661, 'Total loss': 0.4732806123340661}
2022-11-28 05:29:31,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:31,332 INFO:     Epoch: 93
2022-11-28 05:29:31,994 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45013152435421944, 'Total loss': 0.45013152435421944} | train loss {'Reaction outcome loss': 0.47436041997270545, 'Total loss': 0.47436041997270545}
2022-11-28 05:29:31,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:31,995 INFO:     Epoch: 94
2022-11-28 05:29:32,654 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48939327455379744, 'Total loss': 0.48939327455379744} | train loss {'Reaction outcome loss': 0.47460960797392404, 'Total loss': 0.47460960797392404}
2022-11-28 05:29:32,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:32,654 INFO:     Epoch: 95
2022-11-28 05:29:33,315 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4868384437127547, 'Total loss': 0.4868384437127547} | train loss {'Reaction outcome loss': 0.46364957178652527, 'Total loss': 0.46364957178652527}
2022-11-28 05:29:33,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:33,315 INFO:     Epoch: 96
2022-11-28 05:29:33,975 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48723945631222293, 'Total loss': 0.48723945631222293} | train loss {'Reaction outcome loss': 0.47970879832018726, 'Total loss': 0.47970879832018726}
2022-11-28 05:29:33,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:33,975 INFO:     Epoch: 97
2022-11-28 05:29:34,638 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46945190328088676, 'Total loss': 0.46945190328088676} | train loss {'Reaction outcome loss': 0.48608403227589875, 'Total loss': 0.48608403227589875}
2022-11-28 05:29:34,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:34,638 INFO:     Epoch: 98
2022-11-28 05:29:35,304 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47038828987966885, 'Total loss': 0.47038828987966885} | train loss {'Reaction outcome loss': 0.4829782941623738, 'Total loss': 0.4829782941623738}
2022-11-28 05:29:35,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:35,305 INFO:     Epoch: 99
2022-11-28 05:29:35,967 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45955577018586075, 'Total loss': 0.45955577018586075} | train loss {'Reaction outcome loss': 0.47360744535440374, 'Total loss': 0.47360744535440374}
2022-11-28 05:29:35,967 INFO:     Best model found after epoch 66 of 100.
2022-11-28 05:29:35,967 INFO:   Done with stage: TRAINING
2022-11-28 05:29:35,967 INFO:   Starting stage: EVALUATION
2022-11-28 05:29:36,085 INFO:   Done with stage: EVALUATION
2022-11-28 05:29:36,085 INFO:   Leaving out SEQ value Fold_1
2022-11-28 05:29:36,098 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-28 05:29:36,098 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:29:36,729 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:29:36,729 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:29:36,800 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:29:36,800 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:29:36,800 INFO:     No hyperparam tuning for this model
2022-11-28 05:29:36,800 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:29:36,800 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:29:36,801 INFO:     None feature selector for col prot
2022-11-28 05:29:36,801 INFO:     None feature selector for col prot
2022-11-28 05:29:36,801 INFO:     None feature selector for col prot
2022-11-28 05:29:36,801 INFO:     None feature selector for col chem
2022-11-28 05:29:36,801 INFO:     None feature selector for col chem
2022-11-28 05:29:36,801 INFO:     None feature selector for col chem
2022-11-28 05:29:36,802 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:29:36,802 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:29:36,803 INFO:     Number of params in model 169651
2022-11-28 05:29:36,806 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:29:36,806 INFO:   Starting stage: TRAINING
2022-11-28 05:29:36,856 INFO:     Val loss before train {'Reaction outcome loss': 1.0623318331186162, 'Total loss': 1.0623318331186162}
2022-11-28 05:29:36,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:36,857 INFO:     Epoch: 0
2022-11-28 05:29:37,509 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5949901841407599, 'Total loss': 0.5949901841407599} | train loss {'Reaction outcome loss': 0.6954905313474161, 'Total loss': 0.6954905313474161}
2022-11-28 05:29:37,509 INFO:     Found new best model at epoch 0
2022-11-28 05:29:37,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:37,510 INFO:     Epoch: 1
2022-11-28 05:29:38,160 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5577546337316203, 'Total loss': 0.5577546337316203} | train loss {'Reaction outcome loss': 0.5830961139604388, 'Total loss': 0.5830961139604388}
2022-11-28 05:29:38,160 INFO:     Found new best model at epoch 1
2022-11-28 05:29:38,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:38,161 INFO:     Epoch: 2
2022-11-28 05:29:38,814 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5202408415633578, 'Total loss': 0.5202408415633578} | train loss {'Reaction outcome loss': 0.5592550766872771, 'Total loss': 0.5592550766872771}
2022-11-28 05:29:38,814 INFO:     Found new best model at epoch 2
2022-11-28 05:29:38,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:38,815 INFO:     Epoch: 3
2022-11-28 05:29:39,467 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.524658318175826, 'Total loss': 0.524658318175826} | train loss {'Reaction outcome loss': 0.532929686913765, 'Total loss': 0.532929686913765}
2022-11-28 05:29:39,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:39,467 INFO:     Epoch: 4
2022-11-28 05:29:40,120 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5303186323753623, 'Total loss': 0.5303186323753623} | train loss {'Reaction outcome loss': 0.515343433115708, 'Total loss': 0.515343433115708}
2022-11-28 05:29:40,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:40,120 INFO:     Epoch: 5
2022-11-28 05:29:40,769 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5137859399235526, 'Total loss': 0.5137859399235526} | train loss {'Reaction outcome loss': 0.510361604484511, 'Total loss': 0.510361604484511}
2022-11-28 05:29:40,770 INFO:     Found new best model at epoch 5
2022-11-28 05:29:40,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:40,770 INFO:     Epoch: 6
2022-11-28 05:29:41,422 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5553778919369675, 'Total loss': 0.5553778919369675} | train loss {'Reaction outcome loss': 0.49988461659891614, 'Total loss': 0.49988461659891614}
2022-11-28 05:29:41,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:41,422 INFO:     Epoch: 7
2022-11-28 05:29:42,074 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5391036667102991, 'Total loss': 0.5391036667102991} | train loss {'Reaction outcome loss': 0.498957836210973, 'Total loss': 0.498957836210973}
2022-11-28 05:29:42,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:42,074 INFO:     Epoch: 8
2022-11-28 05:29:42,726 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5223445885403212, 'Total loss': 0.5223445885403212} | train loss {'Reaction outcome loss': 0.4985049547849859, 'Total loss': 0.4985049547849859}
2022-11-28 05:29:42,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:42,726 INFO:     Epoch: 9
2022-11-28 05:29:43,380 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5200041872124339, 'Total loss': 0.5200041872124339} | train loss {'Reaction outcome loss': 0.4888040496366014, 'Total loss': 0.4888040496366014}
2022-11-28 05:29:43,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:43,381 INFO:     Epoch: 10
2022-11-28 05:29:44,034 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5635602896989778, 'Total loss': 0.5635602896989778} | train loss {'Reaction outcome loss': 0.48428239044829163, 'Total loss': 0.48428239044829163}
2022-11-28 05:29:44,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:44,035 INFO:     Epoch: 11
2022-11-28 05:29:44,685 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.557600396317105, 'Total loss': 0.557600396317105} | train loss {'Reaction outcome loss': 0.4906817165667137, 'Total loss': 0.4906817165667137}
2022-11-28 05:29:44,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:44,686 INFO:     Epoch: 12
2022-11-28 05:29:45,336 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5320947506400042, 'Total loss': 0.5320947506400042} | train loss {'Reaction outcome loss': 0.4795908710225619, 'Total loss': 0.4795908710225619}
2022-11-28 05:29:45,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:45,336 INFO:     Epoch: 13
2022-11-28 05:29:45,990 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.532361720883569, 'Total loss': 0.532361720883569} | train loss {'Reaction outcome loss': 0.48180523324650504, 'Total loss': 0.48180523324650504}
2022-11-28 05:29:45,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:45,990 INFO:     Epoch: 14
2022-11-28 05:29:46,643 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5108738143083661, 'Total loss': 0.5108738143083661} | train loss {'Reaction outcome loss': 0.4761770410240923, 'Total loss': 0.4761770410240923}
2022-11-28 05:29:46,643 INFO:     Found new best model at epoch 14
2022-11-28 05:29:46,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:46,644 INFO:     Epoch: 15
2022-11-28 05:29:47,298 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49650108537008597, 'Total loss': 0.49650108537008597} | train loss {'Reaction outcome loss': 0.47807947218172836, 'Total loss': 0.47807947218172836}
2022-11-28 05:29:47,298 INFO:     Found new best model at epoch 15
2022-11-28 05:29:47,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:47,299 INFO:     Epoch: 16
2022-11-28 05:29:47,953 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5032526947731195, 'Total loss': 0.5032526947731195} | train loss {'Reaction outcome loss': 0.4808383772893207, 'Total loss': 0.4808383772893207}
2022-11-28 05:29:47,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:47,953 INFO:     Epoch: 17
2022-11-28 05:29:48,604 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5107056034165759, 'Total loss': 0.5107056034165759} | train loss {'Reaction outcome loss': 0.4720669811890449, 'Total loss': 0.4720669811890449}
2022-11-28 05:29:48,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:48,605 INFO:     Epoch: 18
2022-11-28 05:29:49,253 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5039741386507832, 'Total loss': 0.5039741386507832} | train loss {'Reaction outcome loss': 0.48294981308434726, 'Total loss': 0.48294981308434726}
2022-11-28 05:29:49,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:49,254 INFO:     Epoch: 19
2022-11-28 05:29:49,903 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5475721421629883, 'Total loss': 0.5475721421629883} | train loss {'Reaction outcome loss': 0.47692007090083854, 'Total loss': 0.47692007090083854}
2022-11-28 05:29:49,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:49,904 INFO:     Epoch: 20
2022-11-28 05:29:50,556 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4861601604971775, 'Total loss': 0.4861601604971775} | train loss {'Reaction outcome loss': 0.47965785627993046, 'Total loss': 0.47965785627993046}
2022-11-28 05:29:50,556 INFO:     Found new best model at epoch 20
2022-11-28 05:29:50,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:50,557 INFO:     Epoch: 21
2022-11-28 05:29:51,206 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.551425296206807, 'Total loss': 0.551425296206807} | train loss {'Reaction outcome loss': 0.4724440075181149, 'Total loss': 0.4724440075181149}
2022-11-28 05:29:51,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:51,206 INFO:     Epoch: 22
2022-11-28 05:29:51,856 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4803081116704054, 'Total loss': 0.4803081116704054} | train loss {'Reaction outcome loss': 0.4741295154202622, 'Total loss': 0.4741295154202622}
2022-11-28 05:29:51,856 INFO:     Found new best model at epoch 22
2022-11-28 05:29:51,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:51,857 INFO:     Epoch: 23
2022-11-28 05:29:52,509 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5320273024398227, 'Total loss': 0.5320273024398227} | train loss {'Reaction outcome loss': 0.4698002804453971, 'Total loss': 0.4698002804453971}
2022-11-28 05:29:52,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:52,509 INFO:     Epoch: 24
2022-11-28 05:29:53,157 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.589649275984875, 'Total loss': 0.589649275984875} | train loss {'Reaction outcome loss': 0.4778546751342683, 'Total loss': 0.4778546751342683}
2022-11-28 05:29:53,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:53,157 INFO:     Epoch: 25
2022-11-28 05:29:53,810 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49551839883937393, 'Total loss': 0.49551839883937393} | train loss {'Reaction outcome loss': 0.47115576831401623, 'Total loss': 0.47115576831401623}
2022-11-28 05:29:53,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:53,810 INFO:     Epoch: 26
2022-11-28 05:29:54,463 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49669379446395606, 'Total loss': 0.49669379446395606} | train loss {'Reaction outcome loss': 0.47022773058694084, 'Total loss': 0.47022773058694084}
2022-11-28 05:29:54,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:54,463 INFO:     Epoch: 27
2022-11-28 05:29:55,114 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49886842799741166, 'Total loss': 0.49886842799741166} | train loss {'Reaction outcome loss': 0.4678162725741971, 'Total loss': 0.4678162725741971}
2022-11-28 05:29:55,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:55,115 INFO:     Epoch: 28
2022-11-28 05:29:55,766 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5068019167628399, 'Total loss': 0.5068019167628399} | train loss {'Reaction outcome loss': 0.47172904572614427, 'Total loss': 0.47172904572614427}
2022-11-28 05:29:55,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:55,767 INFO:     Epoch: 29
2022-11-28 05:29:56,420 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5342995274898618, 'Total loss': 0.5342995274898618} | train loss {'Reaction outcome loss': 0.46716651038377865, 'Total loss': 0.46716651038377865}
2022-11-28 05:29:56,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:56,420 INFO:     Epoch: 30
2022-11-28 05:29:57,071 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.49149502016777213, 'Total loss': 0.49149502016777213} | train loss {'Reaction outcome loss': 0.4744781122654063, 'Total loss': 0.4744781122654063}
2022-11-28 05:29:57,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:57,071 INFO:     Epoch: 31
2022-11-28 05:29:57,721 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5057500476060912, 'Total loss': 0.5057500476060912} | train loss {'Reaction outcome loss': 0.463957441748415, 'Total loss': 0.463957441748415}
2022-11-28 05:29:57,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:57,721 INFO:     Epoch: 32
2022-11-28 05:29:58,372 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4840767806352571, 'Total loss': 0.4840767806352571} | train loss {'Reaction outcome loss': 0.4624879460766482, 'Total loss': 0.4624879460766482}
2022-11-28 05:29:58,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:58,372 INFO:     Epoch: 33
2022-11-28 05:29:59,023 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5134211636559908, 'Total loss': 0.5134211636559908} | train loss {'Reaction outcome loss': 0.46382395926203746, 'Total loss': 0.46382395926203746}
2022-11-28 05:29:59,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:59,024 INFO:     Epoch: 34
2022-11-28 05:29:59,672 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5128600029058235, 'Total loss': 0.5128600029058235} | train loss {'Reaction outcome loss': 0.46464249786035516, 'Total loss': 0.46464249786035516}
2022-11-28 05:29:59,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:29:59,672 INFO:     Epoch: 35
2022-11-28 05:30:00,322 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4942274311947268, 'Total loss': 0.4942274311947268} | train loss {'Reaction outcome loss': 0.4684973281536083, 'Total loss': 0.4684973281536083}
2022-11-28 05:30:00,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:00,322 INFO:     Epoch: 36
2022-11-28 05:30:00,973 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5089677904927453, 'Total loss': 0.5089677904927453} | train loss {'Reaction outcome loss': 0.4692656456688304, 'Total loss': 0.4692656456688304}
2022-11-28 05:30:00,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:00,974 INFO:     Epoch: 37
2022-11-28 05:30:01,622 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5202201133550599, 'Total loss': 0.5202201133550599} | train loss {'Reaction outcome loss': 0.4661232510834564, 'Total loss': 0.4661232510834564}
2022-11-28 05:30:01,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:01,623 INFO:     Epoch: 38
2022-11-28 05:30:02,268 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49938778128734856, 'Total loss': 0.49938778128734856} | train loss {'Reaction outcome loss': 0.460599603782956, 'Total loss': 0.460599603782956}
2022-11-28 05:30:02,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:02,269 INFO:     Epoch: 39
2022-11-28 05:30:02,919 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.523577795472256, 'Total loss': 0.523577795472256} | train loss {'Reaction outcome loss': 0.4610978550135844, 'Total loss': 0.4610978550135844}
2022-11-28 05:30:02,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:02,919 INFO:     Epoch: 40
2022-11-28 05:30:03,568 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5566834145507147, 'Total loss': 0.5566834145507147} | train loss {'Reaction outcome loss': 0.463818920553957, 'Total loss': 0.463818920553957}
2022-11-28 05:30:03,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:03,569 INFO:     Epoch: 41
2022-11-28 05:30:04,217 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5147694678500642, 'Total loss': 0.5147694678500642} | train loss {'Reaction outcome loss': 0.46899837746051115, 'Total loss': 0.46899837746051115}
2022-11-28 05:30:04,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:04,217 INFO:     Epoch: 42
2022-11-28 05:30:04,869 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5184595207142275, 'Total loss': 0.5184595207142275} | train loss {'Reaction outcome loss': 0.45956960157970345, 'Total loss': 0.45956960157970345}
2022-11-28 05:30:04,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:04,869 INFO:     Epoch: 43
2022-11-28 05:30:05,522 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.49591986107271774, 'Total loss': 0.49591986107271774} | train loss {'Reaction outcome loss': 0.4637474188956704, 'Total loss': 0.4637474188956704}
2022-11-28 05:30:05,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:05,522 INFO:     Epoch: 44
2022-11-28 05:30:06,173 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49716213518796964, 'Total loss': 0.49716213518796964} | train loss {'Reaction outcome loss': 0.46579114344630224, 'Total loss': 0.46579114344630224}
2022-11-28 05:30:06,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:06,173 INFO:     Epoch: 45
2022-11-28 05:30:06,824 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5133531479987987, 'Total loss': 0.5133531479987987} | train loss {'Reaction outcome loss': 0.4661675788492823, 'Total loss': 0.4661675788492823}
2022-11-28 05:30:06,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:06,824 INFO:     Epoch: 46
2022-11-28 05:30:07,474 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5149685393932254, 'Total loss': 0.5149685393932254} | train loss {'Reaction outcome loss': 0.4672642921714626, 'Total loss': 0.4672642921714626}
2022-11-28 05:30:07,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:07,474 INFO:     Epoch: 47
2022-11-28 05:30:08,123 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.501866663957751, 'Total loss': 0.501866663957751} | train loss {'Reaction outcome loss': 0.46459892937921204, 'Total loss': 0.46459892937921204}
2022-11-28 05:30:08,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:08,124 INFO:     Epoch: 48
2022-11-28 05:30:08,772 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5028213349192642, 'Total loss': 0.5028213349192642} | train loss {'Reaction outcome loss': 0.4606429901387956, 'Total loss': 0.4606429901387956}
2022-11-28 05:30:08,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:08,772 INFO:     Epoch: 49
2022-11-28 05:30:09,422 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49724078317021214, 'Total loss': 0.49724078317021214} | train loss {'Reaction outcome loss': 0.45854904008990943, 'Total loss': 0.45854904008990943}
2022-11-28 05:30:09,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:09,423 INFO:     Epoch: 50
2022-11-28 05:30:10,073 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5367923503698304, 'Total loss': 0.5367923503698304} | train loss {'Reaction outcome loss': 0.4670364810115516, 'Total loss': 0.4670364810115516}
2022-11-28 05:30:10,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:10,073 INFO:     Epoch: 51
2022-11-28 05:30:10,727 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5528652006110479, 'Total loss': 0.5528652006110479} | train loss {'Reaction outcome loss': 0.4567017780287276, 'Total loss': 0.4567017780287276}
2022-11-28 05:30:10,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:10,727 INFO:     Epoch: 52
2022-11-28 05:30:11,376 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.554232269525528, 'Total loss': 0.554232269525528} | train loss {'Reaction outcome loss': 0.46305407197387133, 'Total loss': 0.46305407197387133}
2022-11-28 05:30:11,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:11,376 INFO:     Epoch: 53
2022-11-28 05:30:12,026 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4876596348923306, 'Total loss': 0.4876596348923306} | train loss {'Reaction outcome loss': 0.46190318857691415, 'Total loss': 0.46190318857691415}
2022-11-28 05:30:12,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:12,027 INFO:     Epoch: 54
2022-11-28 05:30:12,676 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5138185232184654, 'Total loss': 0.5138185232184654} | train loss {'Reaction outcome loss': 0.4637694746378518, 'Total loss': 0.4637694746378518}
2022-11-28 05:30:12,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:12,676 INFO:     Epoch: 55
2022-11-28 05:30:13,329 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5171383532673813, 'Total loss': 0.5171383532673813} | train loss {'Reaction outcome loss': 0.45680565708949245, 'Total loss': 0.45680565708949245}
2022-11-28 05:30:13,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:13,329 INFO:     Epoch: 56
2022-11-28 05:30:13,980 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5079067903895711, 'Total loss': 0.5079067903895711} | train loss {'Reaction outcome loss': 0.4598401250172054, 'Total loss': 0.4598401250172054}
2022-11-28 05:30:13,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:13,980 INFO:     Epoch: 57
2022-11-28 05:30:14,630 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5160810309787129, 'Total loss': 0.5160810309787129} | train loss {'Reaction outcome loss': 0.45874767827153695, 'Total loss': 0.45874767827153695}
2022-11-28 05:30:14,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:14,631 INFO:     Epoch: 58
2022-11-28 05:30:15,282 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4718627167302509, 'Total loss': 0.4718627167302509} | train loss {'Reaction outcome loss': 0.465929189214, 'Total loss': 0.465929189214}
2022-11-28 05:30:15,282 INFO:     Found new best model at epoch 58
2022-11-28 05:30:15,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:15,283 INFO:     Epoch: 59
2022-11-28 05:30:15,932 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4757780380720316, 'Total loss': 0.4757780380720316} | train loss {'Reaction outcome loss': 0.46735706956052975, 'Total loss': 0.46735706956052975}
2022-11-28 05:30:15,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:15,932 INFO:     Epoch: 60
2022-11-28 05:30:16,583 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4897757692392482, 'Total loss': 0.4897757692392482} | train loss {'Reaction outcome loss': 0.46166267255206167, 'Total loss': 0.46166267255206167}
2022-11-28 05:30:16,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:16,584 INFO:     Epoch: 61
2022-11-28 05:30:17,234 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4840960519951443, 'Total loss': 0.4840960519951443} | train loss {'Reaction outcome loss': 0.4563016754118994, 'Total loss': 0.4563016754118994}
2022-11-28 05:30:17,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:17,234 INFO:     Epoch: 62
2022-11-28 05:30:17,885 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4727678475684898, 'Total loss': 0.4727678475684898} | train loss {'Reaction outcome loss': 0.45594322831665046, 'Total loss': 0.45594322831665046}
2022-11-28 05:30:17,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:17,885 INFO:     Epoch: 63
2022-11-28 05:30:18,536 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4841137556142585, 'Total loss': 0.4841137556142585} | train loss {'Reaction outcome loss': 0.46313992234659784, 'Total loss': 0.46313992234659784}
2022-11-28 05:30:18,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:18,537 INFO:     Epoch: 64
2022-11-28 05:30:19,185 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47023687529009445, 'Total loss': 0.47023687529009445} | train loss {'Reaction outcome loss': 0.4647663346656556, 'Total loss': 0.4647663346656556}
2022-11-28 05:30:19,186 INFO:     Found new best model at epoch 64
2022-11-28 05:30:19,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:19,186 INFO:     Epoch: 65
2022-11-28 05:30:19,835 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47555773722571, 'Total loss': 0.47555773722571} | train loss {'Reaction outcome loss': 0.46508574583893453, 'Total loss': 0.46508574583893453}
2022-11-28 05:30:19,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:19,835 INFO:     Epoch: 66
2022-11-28 05:30:20,482 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5004120178000871, 'Total loss': 0.5004120178000871} | train loss {'Reaction outcome loss': 0.4568147100661517, 'Total loss': 0.4568147100661517}
2022-11-28 05:30:20,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:20,483 INFO:     Epoch: 67
2022-11-28 05:30:21,131 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47740813743236454, 'Total loss': 0.47740813743236454} | train loss {'Reaction outcome loss': 0.4610903445217345, 'Total loss': 0.4610903445217345}
2022-11-28 05:30:21,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:21,131 INFO:     Epoch: 68
2022-11-28 05:30:21,781 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4730899891881056, 'Total loss': 0.4730899891881056} | train loss {'Reaction outcome loss': 0.4595324696336754, 'Total loss': 0.4595324696336754}
2022-11-28 05:30:21,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:21,781 INFO:     Epoch: 69
2022-11-28 05:30:22,430 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5009043525124706, 'Total loss': 0.5009043525124706} | train loss {'Reaction outcome loss': 0.4611306436390543, 'Total loss': 0.4611306436390543}
2022-11-28 05:30:22,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:22,430 INFO:     Epoch: 70
2022-11-28 05:30:23,081 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5070910086465437, 'Total loss': 0.5070910086465437} | train loss {'Reaction outcome loss': 0.4563410127911057, 'Total loss': 0.4563410127911057}
2022-11-28 05:30:23,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:23,081 INFO:     Epoch: 71
2022-11-28 05:30:23,730 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5065694284993548, 'Total loss': 0.5065694284993548} | train loss {'Reaction outcome loss': 0.4581819050351288, 'Total loss': 0.4581819050351288}
2022-11-28 05:30:23,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:23,730 INFO:     Epoch: 72
2022-11-28 05:30:24,382 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4994142741657967, 'Total loss': 0.4994142741657967} | train loss {'Reaction outcome loss': 0.46115035143654043, 'Total loss': 0.46115035143654043}
2022-11-28 05:30:24,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:24,382 INFO:     Epoch: 73
2022-11-28 05:30:25,030 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5190166630024133, 'Total loss': 0.5190166630024133} | train loss {'Reaction outcome loss': 0.4612739611064456, 'Total loss': 0.4612739611064456}
2022-11-28 05:30:25,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:25,030 INFO:     Epoch: 74
2022-11-28 05:30:25,678 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45996063289254213, 'Total loss': 0.45996063289254213} | train loss {'Reaction outcome loss': 0.4595146042451937, 'Total loss': 0.4595146042451937}
2022-11-28 05:30:25,678 INFO:     Found new best model at epoch 74
2022-11-28 05:30:25,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:25,679 INFO:     Epoch: 75
2022-11-28 05:30:26,328 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4756962906482608, 'Total loss': 0.4756962906482608} | train loss {'Reaction outcome loss': 0.46293345614961146, 'Total loss': 0.46293345614961146}
2022-11-28 05:30:26,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:26,329 INFO:     Epoch: 76
2022-11-28 05:30:26,979 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4844946157793666, 'Total loss': 0.4844946157793666} | train loss {'Reaction outcome loss': 0.45859378548683943, 'Total loss': 0.45859378548683943}
2022-11-28 05:30:26,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:26,980 INFO:     Epoch: 77
2022-11-28 05:30:27,630 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5263919806064561, 'Total loss': 0.5263919806064561} | train loss {'Reaction outcome loss': 0.45994162676020417, 'Total loss': 0.45994162676020417}
2022-11-28 05:30:27,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:27,631 INFO:     Epoch: 78
2022-11-28 05:30:28,279 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.500323531932609, 'Total loss': 0.500323531932609} | train loss {'Reaction outcome loss': 0.4613251118257703, 'Total loss': 0.4613251118257703}
2022-11-28 05:30:28,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:28,279 INFO:     Epoch: 79
2022-11-28 05:30:28,929 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5252759390792181, 'Total loss': 0.5252759390792181} | train loss {'Reaction outcome loss': 0.4577683122682964, 'Total loss': 0.4577683122682964}
2022-11-28 05:30:28,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:28,929 INFO:     Epoch: 80
2022-11-28 05:30:29,577 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4907066094320874, 'Total loss': 0.4907066094320874} | train loss {'Reaction outcome loss': 0.4602221976582406, 'Total loss': 0.4602221976582406}
2022-11-28 05:30:29,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:29,577 INFO:     Epoch: 81
2022-11-28 05:30:30,226 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.541930495306503, 'Total loss': 0.541930495306503} | train loss {'Reaction outcome loss': 0.469878188560529, 'Total loss': 0.469878188560529}
2022-11-28 05:30:30,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:30,227 INFO:     Epoch: 82
2022-11-28 05:30:30,877 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47182380667952606, 'Total loss': 0.47182380667952606} | train loss {'Reaction outcome loss': 0.46227310732804205, 'Total loss': 0.46227310732804205}
2022-11-28 05:30:30,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:30,877 INFO:     Epoch: 83
2022-11-28 05:30:31,527 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5407782754925794, 'Total loss': 0.5407782754925794} | train loss {'Reaction outcome loss': 0.4669233832217048, 'Total loss': 0.4669233832217048}
2022-11-28 05:30:31,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:31,527 INFO:     Epoch: 84
2022-11-28 05:30:32,173 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5462975387656411, 'Total loss': 0.5462975387656411} | train loss {'Reaction outcome loss': 0.4602620593682238, 'Total loss': 0.4602620593682238}
2022-11-28 05:30:32,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:32,174 INFO:     Epoch: 85
2022-11-28 05:30:32,825 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5260156063839446, 'Total loss': 0.5260156063839446} | train loss {'Reaction outcome loss': 0.4640709960166319, 'Total loss': 0.4640709960166319}
2022-11-28 05:30:32,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:32,826 INFO:     Epoch: 86
2022-11-28 05:30:33,480 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4948229623395343, 'Total loss': 0.4948229623395343} | train loss {'Reaction outcome loss': 0.4672234758060165, 'Total loss': 0.4672234758060165}
2022-11-28 05:30:33,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:33,480 INFO:     Epoch: 87
2022-11-28 05:30:34,132 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4953440698080285, 'Total loss': 0.4953440698080285} | train loss {'Reaction outcome loss': 0.4534672676229183, 'Total loss': 0.4534672676229183}
2022-11-28 05:30:34,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:34,133 INFO:     Epoch: 88
2022-11-28 05:30:34,784 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5173302486885426, 'Total loss': 0.5173302486885426} | train loss {'Reaction outcome loss': 0.45538470216494037, 'Total loss': 0.45538470216494037}
2022-11-28 05:30:34,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:34,785 INFO:     Epoch: 89
2022-11-28 05:30:35,435 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.506118493024693, 'Total loss': 0.506118493024693} | train loss {'Reaction outcome loss': 0.4608043001144511, 'Total loss': 0.4608043001144511}
2022-11-28 05:30:35,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:35,436 INFO:     Epoch: 90
2022-11-28 05:30:36,082 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4904532931571783, 'Total loss': 0.4904532931571783} | train loss {'Reaction outcome loss': 0.45809508148780087, 'Total loss': 0.45809508148780087}
2022-11-28 05:30:36,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:36,083 INFO:     Epoch: 91
2022-11-28 05:30:36,736 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.516479124510011, 'Total loss': 0.516479124510011} | train loss {'Reaction outcome loss': 0.46039956010908745, 'Total loss': 0.46039956010908745}
2022-11-28 05:30:36,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:36,736 INFO:     Epoch: 92
2022-11-28 05:30:37,386 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49165759114331975, 'Total loss': 0.49165759114331975} | train loss {'Reaction outcome loss': 0.45830233787558206, 'Total loss': 0.45830233787558206}
2022-11-28 05:30:37,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:37,386 INFO:     Epoch: 93
2022-11-28 05:30:38,035 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.500426534303399, 'Total loss': 0.500426534303399} | train loss {'Reaction outcome loss': 0.4636695612482573, 'Total loss': 0.4636695612482573}
2022-11-28 05:30:38,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:38,035 INFO:     Epoch: 94
2022-11-28 05:30:38,682 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47665778946044834, 'Total loss': 0.47665778946044834} | train loss {'Reaction outcome loss': 0.4600163653431606, 'Total loss': 0.4600163653431606}
2022-11-28 05:30:38,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:38,683 INFO:     Epoch: 95
2022-11-28 05:30:39,331 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4845666272002597, 'Total loss': 0.4845666272002597} | train loss {'Reaction outcome loss': 0.45903651183279454, 'Total loss': 0.45903651183279454}
2022-11-28 05:30:39,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:39,331 INFO:     Epoch: 96
2022-11-28 05:30:39,981 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49917034146397615, 'Total loss': 0.49917034146397615} | train loss {'Reaction outcome loss': 0.45617266140356966, 'Total loss': 0.45617266140356966}
2022-11-28 05:30:39,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:39,981 INFO:     Epoch: 97
2022-11-28 05:30:40,631 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.489398890456488, 'Total loss': 0.489398890456488} | train loss {'Reaction outcome loss': 0.4599356862865848, 'Total loss': 0.4599356862865848}
2022-11-28 05:30:40,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:40,631 INFO:     Epoch: 98
2022-11-28 05:30:41,277 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47802774504173634, 'Total loss': 0.47802774504173634} | train loss {'Reaction outcome loss': 0.46423597621574325, 'Total loss': 0.46423597621574325}
2022-11-28 05:30:41,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:41,278 INFO:     Epoch: 99
2022-11-28 05:30:41,926 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47673845845599505, 'Total loss': 0.47673845845599505} | train loss {'Reaction outcome loss': 0.4596661593565725, 'Total loss': 0.4596661593565725}
2022-11-28 05:30:41,926 INFO:     Best model found after epoch 75 of 100.
2022-11-28 05:30:41,926 INFO:   Done with stage: TRAINING
2022-11-28 05:30:41,927 INFO:   Starting stage: EVALUATION
2022-11-28 05:30:42,061 INFO:   Done with stage: EVALUATION
2022-11-28 05:30:42,061 INFO:   Leaving out SEQ value Fold_2
2022-11-28 05:30:42,074 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 05:30:42,074 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:30:42,712 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:30:42,712 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:30:42,782 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:30:42,782 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:30:42,782 INFO:     No hyperparam tuning for this model
2022-11-28 05:30:42,782 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:30:42,782 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:30:42,783 INFO:     None feature selector for col prot
2022-11-28 05:30:42,783 INFO:     None feature selector for col prot
2022-11-28 05:30:42,783 INFO:     None feature selector for col prot
2022-11-28 05:30:42,784 INFO:     None feature selector for col chem
2022-11-28 05:30:42,784 INFO:     None feature selector for col chem
2022-11-28 05:30:42,784 INFO:     None feature selector for col chem
2022-11-28 05:30:42,784 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:30:42,784 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:30:42,786 INFO:     Number of params in model 169651
2022-11-28 05:30:42,789 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:30:42,789 INFO:   Starting stage: TRAINING
2022-11-28 05:30:42,840 INFO:     Val loss before train {'Reaction outcome loss': 0.9878022630106319, 'Total loss': 0.9878022630106319}
2022-11-28 05:30:42,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:42,840 INFO:     Epoch: 0
2022-11-28 05:30:43,500 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5893822535872459, 'Total loss': 0.5893822535872459} | train loss {'Reaction outcome loss': 0.708071484918497, 'Total loss': 0.708071484918497}
2022-11-28 05:30:43,500 INFO:     Found new best model at epoch 0
2022-11-28 05:30:43,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:43,501 INFO:     Epoch: 1
2022-11-28 05:30:44,160 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.585608499971303, 'Total loss': 0.585608499971303} | train loss {'Reaction outcome loss': 0.5933612681165034, 'Total loss': 0.5933612681165034}
2022-11-28 05:30:44,160 INFO:     Found new best model at epoch 1
2022-11-28 05:30:44,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:44,161 INFO:     Epoch: 2
2022-11-28 05:30:44,820 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5890673744407567, 'Total loss': 0.5890673744407567} | train loss {'Reaction outcome loss': 0.5684251329120324, 'Total loss': 0.5684251329120324}
2022-11-28 05:30:44,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:44,820 INFO:     Epoch: 3
2022-11-28 05:30:45,471 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5328754569319162, 'Total loss': 0.5328754569319162} | train loss {'Reaction outcome loss': 0.5495709306123305, 'Total loss': 0.5495709306123305}
2022-11-28 05:30:45,472 INFO:     Found new best model at epoch 3
2022-11-28 05:30:45,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:45,473 INFO:     Epoch: 4
2022-11-28 05:30:46,129 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5478360083970156, 'Total loss': 0.5478360083970156} | train loss {'Reaction outcome loss': 0.5351506824396095, 'Total loss': 0.5351506824396095}
2022-11-28 05:30:46,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:46,129 INFO:     Epoch: 5
2022-11-28 05:30:46,787 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5564365046606823, 'Total loss': 0.5564365046606823} | train loss {'Reaction outcome loss': 0.5233634475542575, 'Total loss': 0.5233634475542575}
2022-11-28 05:30:46,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:46,787 INFO:     Epoch: 6
2022-11-28 05:30:47,441 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5214173671874133, 'Total loss': 0.5214173671874133} | train loss {'Reaction outcome loss': 0.5252844959497451, 'Total loss': 0.5252844959497451}
2022-11-28 05:30:47,441 INFO:     Found new best model at epoch 6
2022-11-28 05:30:47,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:47,442 INFO:     Epoch: 7
2022-11-28 05:30:48,094 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5085477740927176, 'Total loss': 0.5085477740927176} | train loss {'Reaction outcome loss': 0.5197988446877927, 'Total loss': 0.5197988446877927}
2022-11-28 05:30:48,095 INFO:     Found new best model at epoch 7
2022-11-28 05:30:48,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:48,095 INFO:     Epoch: 8
2022-11-28 05:30:48,749 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49518232318488037, 'Total loss': 0.49518232318488037} | train loss {'Reaction outcome loss': 0.504874746288572, 'Total loss': 0.504874746288572}
2022-11-28 05:30:48,750 INFO:     Found new best model at epoch 8
2022-11-28 05:30:48,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:48,750 INFO:     Epoch: 9
2022-11-28 05:30:49,404 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49767528169534425, 'Total loss': 0.49767528169534425} | train loss {'Reaction outcome loss': 0.507192373853557, 'Total loss': 0.507192373853557}
2022-11-28 05:30:49,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:49,404 INFO:     Epoch: 10
2022-11-28 05:30:50,060 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4937306424094872, 'Total loss': 0.4937306424094872} | train loss {'Reaction outcome loss': 0.5028924987632402, 'Total loss': 0.5028924987632402}
2022-11-28 05:30:50,060 INFO:     Found new best model at epoch 10
2022-11-28 05:30:50,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:50,061 INFO:     Epoch: 11
2022-11-28 05:30:50,715 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5087105831639334, 'Total loss': 0.5087105831639334} | train loss {'Reaction outcome loss': 0.5016278028184054, 'Total loss': 0.5016278028184054}
2022-11-28 05:30:50,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:50,715 INFO:     Epoch: 12
2022-11-28 05:30:51,372 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.508714498444037, 'Total loss': 0.508714498444037} | train loss {'Reaction outcome loss': 0.4957966912765892, 'Total loss': 0.4957966912765892}
2022-11-28 05:30:51,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:51,372 INFO:     Epoch: 13
2022-11-28 05:30:52,026 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5020998760380528, 'Total loss': 0.5020998760380528} | train loss {'Reaction outcome loss': 0.5027947470849874, 'Total loss': 0.5027947470849874}
2022-11-28 05:30:52,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:52,026 INFO:     Epoch: 14
2022-11-28 05:30:52,679 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5256320925598795, 'Total loss': 0.5256320925598795} | train loss {'Reaction outcome loss': 0.4929261428969247, 'Total loss': 0.4929261428969247}
2022-11-28 05:30:52,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:52,679 INFO:     Epoch: 15
2022-11-28 05:30:53,331 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5150527175177227, 'Total loss': 0.5150527175177227} | train loss {'Reaction outcome loss': 0.49181420724002683, 'Total loss': 0.49181420724002683}
2022-11-28 05:30:53,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:53,331 INFO:     Epoch: 16
2022-11-28 05:30:53,988 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5057372850450602, 'Total loss': 0.5057372850450602} | train loss {'Reaction outcome loss': 0.4812523082202795, 'Total loss': 0.4812523082202795}
2022-11-28 05:30:53,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:53,989 INFO:     Epoch: 17
2022-11-28 05:30:54,641 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5105743499642069, 'Total loss': 0.5105743499642069} | train loss {'Reaction outcome loss': 0.4956783555600108, 'Total loss': 0.4956783555600108}
2022-11-28 05:30:54,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:54,641 INFO:     Epoch: 18
2022-11-28 05:30:55,297 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49491496180946176, 'Total loss': 0.49491496180946176} | train loss {'Reaction outcome loss': 0.48767561207012255, 'Total loss': 0.48767561207012255}
2022-11-28 05:30:55,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:55,297 INFO:     Epoch: 19
2022-11-28 05:30:55,953 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49258671938018367, 'Total loss': 0.49258671938018367} | train loss {'Reaction outcome loss': 0.49084455291835627, 'Total loss': 0.49084455291835627}
2022-11-28 05:30:55,953 INFO:     Found new best model at epoch 19
2022-11-28 05:30:55,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:55,953 INFO:     Epoch: 20
2022-11-28 05:30:56,609 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5185122625394301, 'Total loss': 0.5185122625394301} | train loss {'Reaction outcome loss': 0.4814123760072552, 'Total loss': 0.4814123760072552}
2022-11-28 05:30:56,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:56,609 INFO:     Epoch: 21
2022-11-28 05:30:57,265 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5254129950295795, 'Total loss': 0.5254129950295795} | train loss {'Reaction outcome loss': 0.48397663892531884, 'Total loss': 0.48397663892531884}
2022-11-28 05:30:57,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:57,265 INFO:     Epoch: 22
2022-11-28 05:30:57,920 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4957017410885204, 'Total loss': 0.4957017410885204} | train loss {'Reaction outcome loss': 0.47825358607331103, 'Total loss': 0.47825358607331103}
2022-11-28 05:30:57,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:57,922 INFO:     Epoch: 23
2022-11-28 05:30:58,575 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5037200647321615, 'Total loss': 0.5037200647321615} | train loss {'Reaction outcome loss': 0.4869960952170041, 'Total loss': 0.4869960952170041}
2022-11-28 05:30:58,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:58,576 INFO:     Epoch: 24
2022-11-28 05:30:59,232 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5147998129779642, 'Total loss': 0.5147998129779642} | train loss {'Reaction outcome loss': 0.4923806771331904, 'Total loss': 0.4923806771331904}
2022-11-28 05:30:59,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:59,232 INFO:     Epoch: 25
2022-11-28 05:30:59,891 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4862195695327087, 'Total loss': 0.4862195695327087} | train loss {'Reaction outcome loss': 0.48650163807431046, 'Total loss': 0.48650163807431046}
2022-11-28 05:30:59,891 INFO:     Found new best model at epoch 25
2022-11-28 05:30:59,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:30:59,892 INFO:     Epoch: 26
2022-11-28 05:31:00,547 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5253406332975085, 'Total loss': 0.5253406332975085} | train loss {'Reaction outcome loss': 0.48920032613131464, 'Total loss': 0.48920032613131464}
2022-11-28 05:31:00,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:00,547 INFO:     Epoch: 27
2022-11-28 05:31:01,207 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5002913183786653, 'Total loss': 0.5002913183786653} | train loss {'Reaction outcome loss': 0.485031520347206, 'Total loss': 0.485031520347206}
2022-11-28 05:31:01,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:01,207 INFO:     Epoch: 28
2022-11-28 05:31:01,864 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5262132769619877, 'Total loss': 0.5262132769619877} | train loss {'Reaction outcome loss': 0.4885502107289373, 'Total loss': 0.4885502107289373}
2022-11-28 05:31:01,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:01,864 INFO:     Epoch: 29
2022-11-28 05:31:02,521 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5093510083176873, 'Total loss': 0.5093510083176873} | train loss {'Reaction outcome loss': 0.486025474205309, 'Total loss': 0.486025474205309}
2022-11-28 05:31:02,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:02,521 INFO:     Epoch: 30
2022-11-28 05:31:03,177 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5097041035240347, 'Total loss': 0.5097041035240347} | train loss {'Reaction outcome loss': 0.4905385820233092, 'Total loss': 0.4905385820233092}
2022-11-28 05:31:03,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:03,177 INFO:     Epoch: 31
2022-11-28 05:31:03,835 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5479388971897688, 'Total loss': 0.5479388971897688} | train loss {'Reaction outcome loss': 0.475980104293142, 'Total loss': 0.475980104293142}
2022-11-28 05:31:03,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:03,835 INFO:     Epoch: 32
2022-11-28 05:31:04,492 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4888264499604702, 'Total loss': 0.4888264499604702} | train loss {'Reaction outcome loss': 0.47918656425816675, 'Total loss': 0.47918656425816675}
2022-11-28 05:31:04,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:04,492 INFO:     Epoch: 33
2022-11-28 05:31:05,148 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5027730383656241, 'Total loss': 0.5027730383656241} | train loss {'Reaction outcome loss': 0.4771220934634306, 'Total loss': 0.4771220934634306}
2022-11-28 05:31:05,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:05,148 INFO:     Epoch: 34
2022-11-28 05:31:05,802 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.518403751606291, 'Total loss': 0.518403751606291} | train loss {'Reaction outcome loss': 0.4865893384631799, 'Total loss': 0.4865893384631799}
2022-11-28 05:31:05,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:05,803 INFO:     Epoch: 35
2022-11-28 05:31:06,455 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5090454092079942, 'Total loss': 0.5090454092079942} | train loss {'Reaction outcome loss': 0.4846189222165516, 'Total loss': 0.4846189222165516}
2022-11-28 05:31:06,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:06,456 INFO:     Epoch: 36
2022-11-28 05:31:07,113 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4964067932556976, 'Total loss': 0.4964067932556976} | train loss {'Reaction outcome loss': 0.4837952136993408, 'Total loss': 0.4837952136993408}
2022-11-28 05:31:07,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:07,113 INFO:     Epoch: 37
2022-11-28 05:31:07,775 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5290410772643306, 'Total loss': 0.5290410772643306} | train loss {'Reaction outcome loss': 0.4799699315611197, 'Total loss': 0.4799699315611197}
2022-11-28 05:31:07,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:07,776 INFO:     Epoch: 38
2022-11-28 05:31:08,435 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4988669915632768, 'Total loss': 0.4988669915632768} | train loss {'Reaction outcome loss': 0.4773447581699916, 'Total loss': 0.4773447581699916}
2022-11-28 05:31:08,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:08,435 INFO:     Epoch: 39
2022-11-28 05:31:09,092 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5168799016286026, 'Total loss': 0.5168799016286026} | train loss {'Reaction outcome loss': 0.47922208753167367, 'Total loss': 0.47922208753167367}
2022-11-28 05:31:09,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:09,092 INFO:     Epoch: 40
2022-11-28 05:31:09,749 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4828890242021192, 'Total loss': 0.4828890242021192} | train loss {'Reaction outcome loss': 0.47939715583105474, 'Total loss': 0.47939715583105474}
2022-11-28 05:31:09,749 INFO:     Found new best model at epoch 40
2022-11-28 05:31:09,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:09,750 INFO:     Epoch: 41
2022-11-28 05:31:10,403 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.513623367656361, 'Total loss': 0.513623367656361} | train loss {'Reaction outcome loss': 0.47445631951701883, 'Total loss': 0.47445631951701883}
2022-11-28 05:31:10,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:10,403 INFO:     Epoch: 42
2022-11-28 05:31:11,058 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47818457233634865, 'Total loss': 0.47818457233634865} | train loss {'Reaction outcome loss': 0.48740992436603625, 'Total loss': 0.48740992436603625}
2022-11-28 05:31:11,058 INFO:     Found new best model at epoch 42
2022-11-28 05:31:11,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:11,059 INFO:     Epoch: 43
2022-11-28 05:31:11,714 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48950832235542213, 'Total loss': 0.48950832235542213} | train loss {'Reaction outcome loss': 0.4769808335571873, 'Total loss': 0.4769808335571873}
2022-11-28 05:31:11,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:11,714 INFO:     Epoch: 44
2022-11-28 05:31:12,370 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47097890282219107, 'Total loss': 0.47097890282219107} | train loss {'Reaction outcome loss': 0.4745312553279254, 'Total loss': 0.4745312553279254}
2022-11-28 05:31:12,370 INFO:     Found new best model at epoch 44
2022-11-28 05:31:12,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:12,371 INFO:     Epoch: 45
2022-11-28 05:31:13,027 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5121939202601259, 'Total loss': 0.5121939202601259} | train loss {'Reaction outcome loss': 0.47937102773968054, 'Total loss': 0.47937102773968054}
2022-11-28 05:31:13,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:13,028 INFO:     Epoch: 46
2022-11-28 05:31:13,684 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5119257528673519, 'Total loss': 0.5119257528673519} | train loss {'Reaction outcome loss': 0.4797644309851588, 'Total loss': 0.4797644309851588}
2022-11-28 05:31:13,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:13,684 INFO:     Epoch: 47
2022-11-28 05:31:14,338 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.49912472983652895, 'Total loss': 0.49912472983652895} | train loss {'Reaction outcome loss': 0.4773382377867796, 'Total loss': 0.4773382377867796}
2022-11-28 05:31:14,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:14,338 INFO:     Epoch: 48
2022-11-28 05:31:14,994 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5279520888897505, 'Total loss': 0.5279520888897505} | train loss {'Reaction outcome loss': 0.4803321698490454, 'Total loss': 0.4803321698490454}
2022-11-28 05:31:14,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:14,994 INFO:     Epoch: 49
2022-11-28 05:31:15,655 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48383523083545943, 'Total loss': 0.48383523083545943} | train loss {'Reaction outcome loss': 0.47820799764321775, 'Total loss': 0.47820799764321775}
2022-11-28 05:31:15,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:15,656 INFO:     Epoch: 50
2022-11-28 05:31:16,315 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5029715717114001, 'Total loss': 0.5029715717114001} | train loss {'Reaction outcome loss': 0.484476722959353, 'Total loss': 0.484476722959353}
2022-11-28 05:31:16,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:16,316 INFO:     Epoch: 51
2022-11-28 05:31:16,973 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5119699781591242, 'Total loss': 0.5119699781591242} | train loss {'Reaction outcome loss': 0.47293730177441423, 'Total loss': 0.47293730177441423}
2022-11-28 05:31:16,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:16,974 INFO:     Epoch: 52
2022-11-28 05:31:17,635 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49621980637311935, 'Total loss': 0.49621980637311935} | train loss {'Reaction outcome loss': 0.47900394523630335, 'Total loss': 0.47900394523630335}
2022-11-28 05:31:17,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:17,635 INFO:     Epoch: 53
2022-11-28 05:31:18,290 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4894005334512754, 'Total loss': 0.4894005334512754} | train loss {'Reaction outcome loss': 0.4721705407208326, 'Total loss': 0.4721705407208326}
2022-11-28 05:31:18,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:18,290 INFO:     Epoch: 54
2022-11-28 05:31:18,945 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4794798256321387, 'Total loss': 0.4794798256321387} | train loss {'Reaction outcome loss': 0.4691061781681314, 'Total loss': 0.4691061781681314}
2022-11-28 05:31:18,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:18,945 INFO:     Epoch: 55
2022-11-28 05:31:19,602 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5081971037116918, 'Total loss': 0.5081971037116918} | train loss {'Reaction outcome loss': 0.4764984337042789, 'Total loss': 0.4764984337042789}
2022-11-28 05:31:19,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:19,602 INFO:     Epoch: 56
2022-11-28 05:31:20,257 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5123248159546744, 'Total loss': 0.5123248159546744} | train loss {'Reaction outcome loss': 0.4690522130046572, 'Total loss': 0.4690522130046572}
2022-11-28 05:31:20,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:20,257 INFO:     Epoch: 57
2022-11-28 05:31:20,912 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5131248591298406, 'Total loss': 0.5131248591298406} | train loss {'Reaction outcome loss': 0.47972398543236205, 'Total loss': 0.47972398543236205}
2022-11-28 05:31:20,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:20,912 INFO:     Epoch: 58
2022-11-28 05:31:21,568 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49747433310205286, 'Total loss': 0.49747433310205286} | train loss {'Reaction outcome loss': 0.476469255953419, 'Total loss': 0.476469255953419}
2022-11-28 05:31:21,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:21,569 INFO:     Epoch: 59
2022-11-28 05:31:22,226 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5088757645677436, 'Total loss': 0.5088757645677436} | train loss {'Reaction outcome loss': 0.47756653865989374, 'Total loss': 0.47756653865989374}
2022-11-28 05:31:22,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:22,226 INFO:     Epoch: 60
2022-11-28 05:31:22,892 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49724136970259925, 'Total loss': 0.49724136970259925} | train loss {'Reaction outcome loss': 0.4728370354187732, 'Total loss': 0.4728370354187732}
2022-11-28 05:31:22,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:22,892 INFO:     Epoch: 61
2022-11-28 05:31:23,553 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5032114501703869, 'Total loss': 0.5032114501703869} | train loss {'Reaction outcome loss': 0.477346750211959, 'Total loss': 0.477346750211959}
2022-11-28 05:31:23,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:23,553 INFO:     Epoch: 62
2022-11-28 05:31:24,211 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5200938480821523, 'Total loss': 0.5200938480821523} | train loss {'Reaction outcome loss': 0.4797262564605596, 'Total loss': 0.4797262564605596}
2022-11-28 05:31:24,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:24,211 INFO:     Epoch: 63
2022-11-28 05:31:24,871 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4825324240055951, 'Total loss': 0.4825324240055951} | train loss {'Reaction outcome loss': 0.47161388129604104, 'Total loss': 0.47161388129604104}
2022-11-28 05:31:24,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:24,871 INFO:     Epoch: 64
2022-11-28 05:31:25,530 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4844601899385452, 'Total loss': 0.4844601899385452} | train loss {'Reaction outcome loss': 0.4724097293250415, 'Total loss': 0.4724097293250415}
2022-11-28 05:31:25,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:25,531 INFO:     Epoch: 65
2022-11-28 05:31:26,189 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45246957979080354, 'Total loss': 0.45246957979080354} | train loss {'Reaction outcome loss': 0.47526859118013964, 'Total loss': 0.47526859118013964}
2022-11-28 05:31:26,189 INFO:     Found new best model at epoch 65
2022-11-28 05:31:26,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:26,190 INFO:     Epoch: 66
2022-11-28 05:31:26,849 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4938801960511641, 'Total loss': 0.4938801960511641} | train loss {'Reaction outcome loss': 0.4718942939931033, 'Total loss': 0.4718942939931033}
2022-11-28 05:31:26,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:26,849 INFO:     Epoch: 67
2022-11-28 05:31:27,507 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5087321651252833, 'Total loss': 0.5087321651252833} | train loss {'Reaction outcome loss': 0.48654983591060247, 'Total loss': 0.48654983591060247}
2022-11-28 05:31:27,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:27,507 INFO:     Epoch: 68
2022-11-28 05:31:28,162 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5008602098307826, 'Total loss': 0.5008602098307826} | train loss {'Reaction outcome loss': 0.48006777878926726, 'Total loss': 0.48006777878926726}
2022-11-28 05:31:28,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:28,162 INFO:     Epoch: 69
2022-11-28 05:31:28,821 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5120162547311999, 'Total loss': 0.5120162547311999} | train loss {'Reaction outcome loss': 0.4753291224946781, 'Total loss': 0.4753291224946781}
2022-11-28 05:31:28,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:28,822 INFO:     Epoch: 70
2022-11-28 05:31:29,480 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4830480001189492, 'Total loss': 0.4830480001189492} | train loss {'Reaction outcome loss': 0.4880097238993158, 'Total loss': 0.4880097238993158}
2022-11-28 05:31:29,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:29,480 INFO:     Epoch: 71
2022-11-28 05:31:30,133 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5024293258108876, 'Total loss': 0.5024293258108876} | train loss {'Reaction outcome loss': 0.4812644956671462, 'Total loss': 0.4812644956671462}
2022-11-28 05:31:30,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:30,133 INFO:     Epoch: 72
2022-11-28 05:31:30,787 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4877652966163375, 'Total loss': 0.4877652966163375} | train loss {'Reaction outcome loss': 0.47883558498353374, 'Total loss': 0.47883558498353374}
2022-11-28 05:31:30,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:30,787 INFO:     Epoch: 73
2022-11-28 05:31:31,443 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5422371033240448, 'Total loss': 0.5422371033240448} | train loss {'Reaction outcome loss': 0.4820565512289806, 'Total loss': 0.4820565512289806}
2022-11-28 05:31:31,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:31,443 INFO:     Epoch: 74
2022-11-28 05:31:32,101 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4771805541081862, 'Total loss': 0.4771805541081862} | train loss {'Reaction outcome loss': 0.4766157602169076, 'Total loss': 0.4766157602169076}
2022-11-28 05:31:32,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:32,101 INFO:     Epoch: 75
2022-11-28 05:31:32,759 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4957911355251616, 'Total loss': 0.4957911355251616} | train loss {'Reaction outcome loss': 0.47803893515041895, 'Total loss': 0.47803893515041895}
2022-11-28 05:31:32,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:32,760 INFO:     Epoch: 76
2022-11-28 05:31:33,417 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49287079308520665, 'Total loss': 0.49287079308520665} | train loss {'Reaction outcome loss': 0.4804876311701171, 'Total loss': 0.4804876311701171}
2022-11-28 05:31:33,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:33,417 INFO:     Epoch: 77
2022-11-28 05:31:34,070 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4992516274479302, 'Total loss': 0.4992516274479302} | train loss {'Reaction outcome loss': 0.473467537274166, 'Total loss': 0.473467537274166}
2022-11-28 05:31:34,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:34,071 INFO:     Epoch: 78
2022-11-28 05:31:34,727 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5309326716444709, 'Total loss': 0.5309326716444709} | train loss {'Reaction outcome loss': 0.4751729418428577, 'Total loss': 0.4751729418428577}
2022-11-28 05:31:34,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:34,727 INFO:     Epoch: 79
2022-11-28 05:31:35,388 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4988384920765053, 'Total loss': 0.4988384920765053} | train loss {'Reaction outcome loss': 0.4841722631941036, 'Total loss': 0.4841722631941036}
2022-11-28 05:31:35,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:35,389 INFO:     Epoch: 80
2022-11-28 05:31:36,046 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5099413066425107, 'Total loss': 0.5099413066425107} | train loss {'Reaction outcome loss': 0.47751915558260316, 'Total loss': 0.47751915558260316}
2022-11-28 05:31:36,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:36,046 INFO:     Epoch: 81
2022-11-28 05:31:36,705 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46532446721738036, 'Total loss': 0.46532446721738036} | train loss {'Reaction outcome loss': 0.48072745307367676, 'Total loss': 0.48072745307367676}
2022-11-28 05:31:36,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:36,705 INFO:     Epoch: 82
2022-11-28 05:31:37,363 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48928285525603726, 'Total loss': 0.48928285525603726} | train loss {'Reaction outcome loss': 0.4768295992393883, 'Total loss': 0.4768295992393883}
2022-11-28 05:31:37,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:37,363 INFO:     Epoch: 83
2022-11-28 05:31:38,018 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5126987224952742, 'Total loss': 0.5126987224952742} | train loss {'Reaction outcome loss': 0.47309543548189864, 'Total loss': 0.47309543548189864}
2022-11-28 05:31:38,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:38,019 INFO:     Epoch: 84
2022-11-28 05:31:38,675 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4823213900354775, 'Total loss': 0.4823213900354775} | train loss {'Reaction outcome loss': 0.4740642166867548, 'Total loss': 0.4740642166867548}
2022-11-28 05:31:38,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:38,676 INFO:     Epoch: 85
2022-11-28 05:31:39,331 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4680973624979908, 'Total loss': 0.4680973624979908} | train loss {'Reaction outcome loss': 0.485459275330816, 'Total loss': 0.485459275330816}
2022-11-28 05:31:39,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:39,331 INFO:     Epoch: 86
2022-11-28 05:31:39,987 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.470252260227095, 'Total loss': 0.470252260227095} | train loss {'Reaction outcome loss': 0.4786717161536217, 'Total loss': 0.4786717161536217}
2022-11-28 05:31:39,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:39,987 INFO:     Epoch: 87
2022-11-28 05:31:40,644 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5211493669247086, 'Total loss': 0.5211493669247086} | train loss {'Reaction outcome loss': 0.4782127781181919, 'Total loss': 0.4782127781181919}
2022-11-28 05:31:40,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:40,644 INFO:     Epoch: 88
2022-11-28 05:31:41,301 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4711153852668675, 'Total loss': 0.4711153852668675} | train loss {'Reaction outcome loss': 0.47204023693897285, 'Total loss': 0.47204023693897285}
2022-11-28 05:31:41,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:41,301 INFO:     Epoch: 89
2022-11-28 05:31:41,957 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4631465414369648, 'Total loss': 0.4631465414369648} | train loss {'Reaction outcome loss': 0.4746564348133243, 'Total loss': 0.4746564348133243}
2022-11-28 05:31:41,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:41,957 INFO:     Epoch: 90
2022-11-28 05:31:42,612 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.473889962177385, 'Total loss': 0.473889962177385} | train loss {'Reaction outcome loss': 0.47518057336612624, 'Total loss': 0.47518057336612624}
2022-11-28 05:31:42,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:42,612 INFO:     Epoch: 91
2022-11-28 05:31:43,265 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4871276481585069, 'Total loss': 0.4871276481585069} | train loss {'Reaction outcome loss': 0.48639913955513314, 'Total loss': 0.48639913955513314}
2022-11-28 05:31:43,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:43,265 INFO:     Epoch: 92
2022-11-28 05:31:43,921 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49020994996482675, 'Total loss': 0.49020994996482675} | train loss {'Reaction outcome loss': 0.47830654565168884, 'Total loss': 0.47830654565168884}
2022-11-28 05:31:43,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:43,921 INFO:     Epoch: 93
2022-11-28 05:31:44,580 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5022348307750442, 'Total loss': 0.5022348307750442} | train loss {'Reaction outcome loss': 0.4789941765215932, 'Total loss': 0.4789941765215932}
2022-11-28 05:31:44,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:44,580 INFO:     Epoch: 94
2022-11-28 05:31:45,239 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5246448557485234, 'Total loss': 0.5246448557485234} | train loss {'Reaction outcome loss': 0.4732709212266669, 'Total loss': 0.4732709212266669}
2022-11-28 05:31:45,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:45,239 INFO:     Epoch: 95
2022-11-28 05:31:45,897 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5341488844291731, 'Total loss': 0.5341488844291731} | train loss {'Reaction outcome loss': 0.4797500114051663, 'Total loss': 0.4797500114051663}
2022-11-28 05:31:45,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:45,898 INFO:     Epoch: 96
2022-11-28 05:31:46,554 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46785578199408273, 'Total loss': 0.46785578199408273} | train loss {'Reaction outcome loss': 0.47386314522246925, 'Total loss': 0.47386314522246925}
2022-11-28 05:31:46,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:46,555 INFO:     Epoch: 97
2022-11-28 05:31:47,212 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4869335944002325, 'Total loss': 0.4869335944002325} | train loss {'Reaction outcome loss': 0.4775855674427383, 'Total loss': 0.4775855674427383}
2022-11-28 05:31:47,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:47,212 INFO:     Epoch: 98
2022-11-28 05:31:47,867 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5038119513880123, 'Total loss': 0.5038119513880123} | train loss {'Reaction outcome loss': 0.47572311272426526, 'Total loss': 0.47572311272426526}
2022-11-28 05:31:47,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:47,868 INFO:     Epoch: 99
2022-11-28 05:31:48,525 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48263250426812604, 'Total loss': 0.48263250426812604} | train loss {'Reaction outcome loss': 0.48087581864425116, 'Total loss': 0.48087581864425116}
2022-11-28 05:31:48,525 INFO:     Best model found after epoch 66 of 100.
2022-11-28 05:31:48,526 INFO:   Done with stage: TRAINING
2022-11-28 05:31:48,526 INFO:   Starting stage: EVALUATION
2022-11-28 05:31:48,648 INFO:   Done with stage: EVALUATION
2022-11-28 05:31:48,648 INFO:   Leaving out SEQ value Fold_3
2022-11-28 05:31:48,661 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 05:31:48,661 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:31:49,291 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:31:49,291 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:31:49,359 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:31:49,359 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:31:49,360 INFO:     No hyperparam tuning for this model
2022-11-28 05:31:49,360 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:31:49,360 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:31:49,360 INFO:     None feature selector for col prot
2022-11-28 05:31:49,360 INFO:     None feature selector for col prot
2022-11-28 05:31:49,361 INFO:     None feature selector for col prot
2022-11-28 05:31:49,361 INFO:     None feature selector for col chem
2022-11-28 05:31:49,361 INFO:     None feature selector for col chem
2022-11-28 05:31:49,361 INFO:     None feature selector for col chem
2022-11-28 05:31:49,361 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:31:49,361 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:31:49,363 INFO:     Number of params in model 169651
2022-11-28 05:31:49,366 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:31:49,366 INFO:   Starting stage: TRAINING
2022-11-28 05:31:49,416 INFO:     Val loss before train {'Reaction outcome loss': 1.0582999058745124, 'Total loss': 1.0582999058745124}
2022-11-28 05:31:49,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:49,416 INFO:     Epoch: 0
2022-11-28 05:31:50,072 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6074246547438882, 'Total loss': 0.6074246547438882} | train loss {'Reaction outcome loss': 0.6939000149162449, 'Total loss': 0.6939000149162449}
2022-11-28 05:31:50,072 INFO:     Found new best model at epoch 0
2022-11-28 05:31:50,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:50,072 INFO:     Epoch: 1
2022-11-28 05:31:50,727 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6123960668390448, 'Total loss': 0.6123960668390448} | train loss {'Reaction outcome loss': 0.5850106733794115, 'Total loss': 0.5850106733794115}
2022-11-28 05:31:50,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:50,727 INFO:     Epoch: 2
2022-11-28 05:31:51,381 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5409288629889488, 'Total loss': 0.5409288629889488} | train loss {'Reaction outcome loss': 0.5514726470319592, 'Total loss': 0.5514726470319592}
2022-11-28 05:31:51,382 INFO:     Found new best model at epoch 2
2022-11-28 05:31:51,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:51,382 INFO:     Epoch: 3
2022-11-28 05:31:52,040 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5301455523480069, 'Total loss': 0.5301455523480069} | train loss {'Reaction outcome loss': 0.5284795991620239, 'Total loss': 0.5284795991620239}
2022-11-28 05:31:52,040 INFO:     Found new best model at epoch 3
2022-11-28 05:31:52,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:52,041 INFO:     Epoch: 4
2022-11-28 05:31:52,695 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5189180245453661, 'Total loss': 0.5189180245453661} | train loss {'Reaction outcome loss': 0.5160245432537429, 'Total loss': 0.5160245432537429}
2022-11-28 05:31:52,695 INFO:     Found new best model at epoch 4
2022-11-28 05:31:52,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:52,696 INFO:     Epoch: 5
2022-11-28 05:31:53,353 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5274554084647786, 'Total loss': 0.5274554084647786} | train loss {'Reaction outcome loss': 0.5115070485338873, 'Total loss': 0.5115070485338873}
2022-11-28 05:31:53,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:53,353 INFO:     Epoch: 6
2022-11-28 05:31:54,010 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5480563342571259, 'Total loss': 0.5480563342571259} | train loss {'Reaction outcome loss': 0.5032013786690576, 'Total loss': 0.5032013786690576}
2022-11-28 05:31:54,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:54,010 INFO:     Epoch: 7
2022-11-28 05:31:54,666 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5318786637349562, 'Total loss': 0.5318786637349562} | train loss {'Reaction outcome loss': 0.5032167289330035, 'Total loss': 0.5032167289330035}
2022-11-28 05:31:54,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:54,666 INFO:     Epoch: 8
2022-11-28 05:31:55,324 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.533967137336731, 'Total loss': 0.533967137336731} | train loss {'Reaction outcome loss': 0.4868972283845045, 'Total loss': 0.4868972283845045}
2022-11-28 05:31:55,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:55,324 INFO:     Epoch: 9
2022-11-28 05:31:55,978 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5034351375969973, 'Total loss': 0.5034351375969973} | train loss {'Reaction outcome loss': 0.48350146206057804, 'Total loss': 0.48350146206057804}
2022-11-28 05:31:55,978 INFO:     Found new best model at epoch 9
2022-11-28 05:31:55,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:55,979 INFO:     Epoch: 10
2022-11-28 05:31:56,635 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5075727389617399, 'Total loss': 0.5075727389617399} | train loss {'Reaction outcome loss': 0.48100508573103923, 'Total loss': 0.48100508573103923}
2022-11-28 05:31:56,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:56,636 INFO:     Epoch: 11
2022-11-28 05:31:57,290 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5045851560478861, 'Total loss': 0.5045851560478861} | train loss {'Reaction outcome loss': 0.48033053169445117, 'Total loss': 0.48033053169445117}
2022-11-28 05:31:57,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:57,290 INFO:     Epoch: 12
2022-11-28 05:31:57,943 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5026300600306555, 'Total loss': 0.5026300600306555} | train loss {'Reaction outcome loss': 0.47396092925752914, 'Total loss': 0.47396092925752914}
2022-11-28 05:31:57,943 INFO:     Found new best model at epoch 12
2022-11-28 05:31:57,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:57,944 INFO:     Epoch: 13
2022-11-28 05:31:58,598 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5220369574698535, 'Total loss': 0.5220369574698535} | train loss {'Reaction outcome loss': 0.47351535327580513, 'Total loss': 0.47351535327580513}
2022-11-28 05:31:58,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:58,598 INFO:     Epoch: 14
2022-11-28 05:31:59,251 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5228180966594003, 'Total loss': 0.5228180966594003} | train loss {'Reaction outcome loss': 0.4718263179063797, 'Total loss': 0.4718263179063797}
2022-11-28 05:31:59,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:59,251 INFO:     Epoch: 15
2022-11-28 05:31:59,908 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4952048845589161, 'Total loss': 0.4952048845589161} | train loss {'Reaction outcome loss': 0.475346685793935, 'Total loss': 0.475346685793935}
2022-11-28 05:31:59,909 INFO:     Found new best model at epoch 15
2022-11-28 05:31:59,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:31:59,909 INFO:     Epoch: 16
2022-11-28 05:32:00,562 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.518421702764251, 'Total loss': 0.518421702764251} | train loss {'Reaction outcome loss': 0.469220119775558, 'Total loss': 0.469220119775558}
2022-11-28 05:32:00,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:00,563 INFO:     Epoch: 17
2022-11-28 05:32:01,217 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47715018029240047, 'Total loss': 0.47715018029240047} | train loss {'Reaction outcome loss': 0.472811491696202, 'Total loss': 0.472811491696202}
2022-11-28 05:32:01,217 INFO:     Found new best model at epoch 17
2022-11-28 05:32:01,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:01,218 INFO:     Epoch: 18
2022-11-28 05:32:01,871 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5089633136310361, 'Total loss': 0.5089633136310361} | train loss {'Reaction outcome loss': 0.4749692225334596, 'Total loss': 0.4749692225334596}
2022-11-28 05:32:01,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:01,871 INFO:     Epoch: 19
2022-11-28 05:32:02,526 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49054406075315043, 'Total loss': 0.49054406075315043} | train loss {'Reaction outcome loss': 0.47221338335348634, 'Total loss': 0.47221338335348634}
2022-11-28 05:32:02,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:02,526 INFO:     Epoch: 20
2022-11-28 05:32:03,178 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5079090148210526, 'Total loss': 0.5079090148210526} | train loss {'Reaction outcome loss': 0.4609492685721845, 'Total loss': 0.4609492685721845}
2022-11-28 05:32:03,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:03,178 INFO:     Epoch: 21
2022-11-28 05:32:03,832 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5030915127559141, 'Total loss': 0.5030915127559141} | train loss {'Reaction outcome loss': 0.4649458112157121, 'Total loss': 0.4649458112157121}
2022-11-28 05:32:03,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:03,833 INFO:     Epoch: 22
2022-11-28 05:32:04,486 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4844686009667136, 'Total loss': 0.4844686009667136} | train loss {'Reaction outcome loss': 0.4624540358173604, 'Total loss': 0.4624540358173604}
2022-11-28 05:32:04,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:04,486 INFO:     Epoch: 23
2022-11-28 05:32:05,143 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4882172102277929, 'Total loss': 0.4882172102277929} | train loss {'Reaction outcome loss': 0.45940061503527113, 'Total loss': 0.45940061503527113}
2022-11-28 05:32:05,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:05,143 INFO:     Epoch: 24
2022-11-28 05:32:05,801 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4850831021639434, 'Total loss': 0.4850831021639434} | train loss {'Reaction outcome loss': 0.4676953236059267, 'Total loss': 0.4676953236059267}
2022-11-28 05:32:05,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:05,801 INFO:     Epoch: 25
2022-11-28 05:32:06,457 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49729596891186456, 'Total loss': 0.49729596891186456} | train loss {'Reaction outcome loss': 0.46273035911881194, 'Total loss': 0.46273035911881194}
2022-11-28 05:32:06,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:06,457 INFO:     Epoch: 26
2022-11-28 05:32:07,114 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48615448583256116, 'Total loss': 0.48615448583256116} | train loss {'Reaction outcome loss': 0.46613354591690764, 'Total loss': 0.46613354591690764}
2022-11-28 05:32:07,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:07,114 INFO:     Epoch: 27
2022-11-28 05:32:07,767 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.502736954187805, 'Total loss': 0.502736954187805} | train loss {'Reaction outcome loss': 0.4667788565158844, 'Total loss': 0.4667788565158844}
2022-11-28 05:32:07,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:07,767 INFO:     Epoch: 28
2022-11-28 05:32:08,422 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4824371175332503, 'Total loss': 0.4824371175332503} | train loss {'Reaction outcome loss': 0.46676032792548744, 'Total loss': 0.46676032792548744}
2022-11-28 05:32:08,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:08,423 INFO:     Epoch: 29
2022-11-28 05:32:09,077 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4904921840537678, 'Total loss': 0.4904921840537678} | train loss {'Reaction outcome loss': 0.46823860583256705, 'Total loss': 0.46823860583256705}
2022-11-28 05:32:09,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:09,077 INFO:     Epoch: 30
2022-11-28 05:32:09,735 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4772081676531922, 'Total loss': 0.4772081676531922} | train loss {'Reaction outcome loss': 0.46146400595197873, 'Total loss': 0.46146400595197873}
2022-11-28 05:32:09,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:09,735 INFO:     Epoch: 31
2022-11-28 05:32:10,392 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49556620757688175, 'Total loss': 0.49556620757688175} | train loss {'Reaction outcome loss': 0.4580774236090329, 'Total loss': 0.4580774236090329}
2022-11-28 05:32:10,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:10,392 INFO:     Epoch: 32
2022-11-28 05:32:11,049 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45830339718271385, 'Total loss': 0.45830339718271385} | train loss {'Reaction outcome loss': 0.46217411805172354, 'Total loss': 0.46217411805172354}
2022-11-28 05:32:11,049 INFO:     Found new best model at epoch 32
2022-11-28 05:32:11,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:11,050 INFO:     Epoch: 33
2022-11-28 05:32:11,706 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47050630826164375, 'Total loss': 0.47050630826164375} | train loss {'Reaction outcome loss': 0.4644710426123775, 'Total loss': 0.4644710426123775}
2022-11-28 05:32:11,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:11,706 INFO:     Epoch: 34
2022-11-28 05:32:12,363 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4868145557967099, 'Total loss': 0.4868145557967099} | train loss {'Reaction outcome loss': 0.4600292160194747, 'Total loss': 0.4600292160194747}
2022-11-28 05:32:12,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:12,363 INFO:     Epoch: 35
2022-11-28 05:32:13,021 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.483888330784711, 'Total loss': 0.483888330784711} | train loss {'Reaction outcome loss': 0.46120798983136, 'Total loss': 0.46120798983136}
2022-11-28 05:32:13,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:13,022 INFO:     Epoch: 36
2022-11-28 05:32:13,675 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47215304015712306, 'Total loss': 0.47215304015712306} | train loss {'Reaction outcome loss': 0.46053439378738403, 'Total loss': 0.46053439378738403}
2022-11-28 05:32:13,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:13,675 INFO:     Epoch: 37
2022-11-28 05:32:14,328 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.461456183005463, 'Total loss': 0.461456183005463} | train loss {'Reaction outcome loss': 0.4604945491163098, 'Total loss': 0.4604945491163098}
2022-11-28 05:32:14,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:14,328 INFO:     Epoch: 38
2022-11-28 05:32:14,986 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5110669979317621, 'Total loss': 0.5110669979317621} | train loss {'Reaction outcome loss': 0.46263047274278135, 'Total loss': 0.46263047274278135}
2022-11-28 05:32:14,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:14,986 INFO:     Epoch: 39
2022-11-28 05:32:15,642 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4511682675643401, 'Total loss': 0.4511682675643401} | train loss {'Reaction outcome loss': 0.46153273637197456, 'Total loss': 0.46153273637197456}
2022-11-28 05:32:15,643 INFO:     Found new best model at epoch 39
2022-11-28 05:32:15,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:15,643 INFO:     Epoch: 40
2022-11-28 05:32:16,299 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4813357882878997, 'Total loss': 0.4813357882878997} | train loss {'Reaction outcome loss': 0.4681414490451618, 'Total loss': 0.4681414490451618}
2022-11-28 05:32:16,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:16,300 INFO:     Epoch: 41
2022-11-28 05:32:16,953 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48226050389083946, 'Total loss': 0.48226050389083946} | train loss {'Reaction outcome loss': 0.45196372161106185, 'Total loss': 0.45196372161106185}
2022-11-28 05:32:16,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:16,954 INFO:     Epoch: 42
2022-11-28 05:32:17,608 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4874631498347629, 'Total loss': 0.4874631498347629} | train loss {'Reaction outcome loss': 0.4631648858591002, 'Total loss': 0.4631648858591002}
2022-11-28 05:32:17,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:17,608 INFO:     Epoch: 43
2022-11-28 05:32:18,265 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45709434066983784, 'Total loss': 0.45709434066983784} | train loss {'Reaction outcome loss': 0.45208578468585503, 'Total loss': 0.45208578468585503}
2022-11-28 05:32:18,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:18,265 INFO:     Epoch: 44
2022-11-28 05:32:18,921 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48013751818375155, 'Total loss': 0.48013751818375155} | train loss {'Reaction outcome loss': 0.4625126693017629, 'Total loss': 0.4625126693017629}
2022-11-28 05:32:18,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:18,922 INFO:     Epoch: 45
2022-11-28 05:32:19,579 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48632504350759764, 'Total loss': 0.48632504350759764} | train loss {'Reaction outcome loss': 0.4674981010203459, 'Total loss': 0.4674981010203459}
2022-11-28 05:32:19,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:19,579 INFO:     Epoch: 46
2022-11-28 05:32:20,234 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44996920092539355, 'Total loss': 0.44996920092539355} | train loss {'Reaction outcome loss': 0.462193526783768, 'Total loss': 0.462193526783768}
2022-11-28 05:32:20,234 INFO:     Found new best model at epoch 46
2022-11-28 05:32:20,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:20,235 INFO:     Epoch: 47
2022-11-28 05:32:20,889 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46369629285552283, 'Total loss': 0.46369629285552283} | train loss {'Reaction outcome loss': 0.45131515830147023, 'Total loss': 0.45131515830147023}
2022-11-28 05:32:20,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:20,889 INFO:     Epoch: 48
2022-11-28 05:32:21,544 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4527089470489459, 'Total loss': 0.4527089470489459} | train loss {'Reaction outcome loss': 0.4615471567426409, 'Total loss': 0.4615471567426409}
2022-11-28 05:32:21,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:21,544 INFO:     Epoch: 49
2022-11-28 05:32:22,195 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5479926175691865, 'Total loss': 0.5479926175691865} | train loss {'Reaction outcome loss': 0.459047479653845, 'Total loss': 0.459047479653845}
2022-11-28 05:32:22,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:22,195 INFO:     Epoch: 50
2022-11-28 05:32:22,850 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47535239617255604, 'Total loss': 0.47535239617255604} | train loss {'Reaction outcome loss': 0.46025795930502367, 'Total loss': 0.46025795930502367}
2022-11-28 05:32:22,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:22,850 INFO:     Epoch: 51
2022-11-28 05:32:23,510 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4704964364116842, 'Total loss': 0.4704964364116842} | train loss {'Reaction outcome loss': 0.46547006940355107, 'Total loss': 0.46547006940355107}
2022-11-28 05:32:23,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:23,510 INFO:     Epoch: 52
2022-11-28 05:32:24,171 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5008421032266184, 'Total loss': 0.5008421032266184} | train loss {'Reaction outcome loss': 0.46256839809369066, 'Total loss': 0.46256839809369066}
2022-11-28 05:32:24,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:24,172 INFO:     Epoch: 53
2022-11-28 05:32:24,826 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4756810770116069, 'Total loss': 0.4756810770116069} | train loss {'Reaction outcome loss': 0.4616071414582583, 'Total loss': 0.4616071414582583}
2022-11-28 05:32:24,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:24,826 INFO:     Epoch: 54
2022-11-28 05:32:25,478 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48490227487954224, 'Total loss': 0.48490227487954224} | train loss {'Reaction outcome loss': 0.4555694936489572, 'Total loss': 0.4555694936489572}
2022-11-28 05:32:25,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:25,479 INFO:     Epoch: 55
2022-11-28 05:32:26,134 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47559466382319276, 'Total loss': 0.47559466382319276} | train loss {'Reaction outcome loss': 0.460056689016673, 'Total loss': 0.460056689016673}
2022-11-28 05:32:26,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:26,135 INFO:     Epoch: 56
2022-11-28 05:32:26,790 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4823024252598936, 'Total loss': 0.4823024252598936} | train loss {'Reaction outcome loss': 0.45901058833209835, 'Total loss': 0.45901058833209835}
2022-11-28 05:32:26,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:26,790 INFO:     Epoch: 57
2022-11-28 05:32:27,441 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47623321278528735, 'Total loss': 0.47623321278528735} | train loss {'Reaction outcome loss': 0.46051694179067804, 'Total loss': 0.46051694179067804}
2022-11-28 05:32:27,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:27,442 INFO:     Epoch: 58
2022-11-28 05:32:28,099 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49072554910724814, 'Total loss': 0.49072554910724814} | train loss {'Reaction outcome loss': 0.46753970640046255, 'Total loss': 0.46753970640046255}
2022-11-28 05:32:28,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:28,099 INFO:     Epoch: 59
2022-11-28 05:32:28,755 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46898625791072845, 'Total loss': 0.46898625791072845} | train loss {'Reaction outcome loss': 0.4612787645690295, 'Total loss': 0.4612787645690295}
2022-11-28 05:32:28,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:28,756 INFO:     Epoch: 60
2022-11-28 05:32:29,415 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46636841717091476, 'Total loss': 0.46636841717091476} | train loss {'Reaction outcome loss': 0.4642773165994761, 'Total loss': 0.4642773165994761}
2022-11-28 05:32:29,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:29,415 INFO:     Epoch: 61
2022-11-28 05:32:30,071 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5116994672624225, 'Total loss': 0.5116994672624225} | train loss {'Reaction outcome loss': 0.45582824343321277, 'Total loss': 0.45582824343321277}
2022-11-28 05:32:30,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:30,071 INFO:     Epoch: 62
2022-11-28 05:32:30,729 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49182963506741956, 'Total loss': 0.49182963506741956} | train loss {'Reaction outcome loss': 0.45511067430583796, 'Total loss': 0.45511067430583796}
2022-11-28 05:32:30,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:30,731 INFO:     Epoch: 63
2022-11-28 05:32:31,389 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47675506499680603, 'Total loss': 0.47675506499680603} | train loss {'Reaction outcome loss': 0.46465448621584443, 'Total loss': 0.46465448621584443}
2022-11-28 05:32:31,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:31,389 INFO:     Epoch: 64
2022-11-28 05:32:32,046 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49245250495997345, 'Total loss': 0.49245250495997345} | train loss {'Reaction outcome loss': 0.4595339543965398, 'Total loss': 0.4595339543965398}
2022-11-28 05:32:32,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:32,046 INFO:     Epoch: 65
2022-11-28 05:32:32,702 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4524278583174402, 'Total loss': 0.4524278583174402} | train loss {'Reaction outcome loss': 0.45897737108931247, 'Total loss': 0.45897737108931247}
2022-11-28 05:32:32,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:32,702 INFO:     Epoch: 66
2022-11-28 05:32:33,356 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46952127902345225, 'Total loss': 0.46952127902345225} | train loss {'Reaction outcome loss': 0.4628776990637487, 'Total loss': 0.4628776990637487}
2022-11-28 05:32:33,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:33,357 INFO:     Epoch: 67
2022-11-28 05:32:34,013 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4786193807694045, 'Total loss': 0.4786193807694045} | train loss {'Reaction outcome loss': 0.454623199573585, 'Total loss': 0.454623199573585}
2022-11-28 05:32:34,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:34,014 INFO:     Epoch: 68
2022-11-28 05:32:34,670 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45890330895781517, 'Total loss': 0.45890330895781517} | train loss {'Reaction outcome loss': 0.4582137767757688, 'Total loss': 0.4582137767757688}
2022-11-28 05:32:34,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:34,671 INFO:     Epoch: 69
2022-11-28 05:32:35,326 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48504596847024833, 'Total loss': 0.48504596847024833} | train loss {'Reaction outcome loss': 0.46683611854606744, 'Total loss': 0.46683611854606744}
2022-11-28 05:32:35,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:35,326 INFO:     Epoch: 70
2022-11-28 05:32:35,983 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48650274832140317, 'Total loss': 0.48650274832140317} | train loss {'Reaction outcome loss': 0.4595183167530566, 'Total loss': 0.4595183167530566}
2022-11-28 05:32:35,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:35,983 INFO:     Epoch: 71
2022-11-28 05:32:36,641 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4502909471365539, 'Total loss': 0.4502909471365539} | train loss {'Reaction outcome loss': 0.4633107465748884, 'Total loss': 0.4633107465748884}
2022-11-28 05:32:36,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:36,642 INFO:     Epoch: 72
2022-11-28 05:32:37,303 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4716079045425762, 'Total loss': 0.4716079045425762} | train loss {'Reaction outcome loss': 0.4592264826200446, 'Total loss': 0.4592264826200446}
2022-11-28 05:32:37,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:37,304 INFO:     Epoch: 73
2022-11-28 05:32:37,960 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48838284696367656, 'Total loss': 0.48838284696367656} | train loss {'Reaction outcome loss': 0.4578427822005992, 'Total loss': 0.4578427822005992}
2022-11-28 05:32:37,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:37,961 INFO:     Epoch: 74
2022-11-28 05:32:38,618 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47784191302277823, 'Total loss': 0.47784191302277823} | train loss {'Reaction outcome loss': 0.46045904597457576, 'Total loss': 0.46045904597457576}
2022-11-28 05:32:38,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:38,618 INFO:     Epoch: 75
2022-11-28 05:32:39,277 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4910914179953662, 'Total loss': 0.4910914179953662} | train loss {'Reaction outcome loss': 0.45570410280203333, 'Total loss': 0.45570410280203333}
2022-11-28 05:32:39,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:39,278 INFO:     Epoch: 76
2022-11-28 05:32:39,944 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5133629928935658, 'Total loss': 0.5133629928935658} | train loss {'Reaction outcome loss': 0.46131174856302687, 'Total loss': 0.46131174856302687}
2022-11-28 05:32:39,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:39,944 INFO:     Epoch: 77
2022-11-28 05:32:40,606 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4667973911220377, 'Total loss': 0.4667973911220377} | train loss {'Reaction outcome loss': 0.4658027301637494, 'Total loss': 0.4658027301637494}
2022-11-28 05:32:40,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:40,607 INFO:     Epoch: 78
2022-11-28 05:32:41,265 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46574503369629383, 'Total loss': 0.46574503369629383} | train loss {'Reaction outcome loss': 0.4636150637451483, 'Total loss': 0.4636150637451483}
2022-11-28 05:32:41,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:41,266 INFO:     Epoch: 79
2022-11-28 05:32:41,922 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44646441902626643, 'Total loss': 0.44646441902626643} | train loss {'Reaction outcome loss': 0.4650661719088652, 'Total loss': 0.4650661719088652}
2022-11-28 05:32:41,922 INFO:     Found new best model at epoch 79
2022-11-28 05:32:41,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:41,923 INFO:     Epoch: 80
2022-11-28 05:32:42,583 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4952917295423421, 'Total loss': 0.4952917295423421} | train loss {'Reaction outcome loss': 0.4640514832370135, 'Total loss': 0.4640514832370135}
2022-11-28 05:32:42,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:42,584 INFO:     Epoch: 81
2022-11-28 05:32:43,244 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4709708782082254, 'Total loss': 0.4709708782082254} | train loss {'Reaction outcome loss': 0.4571472236088344, 'Total loss': 0.4571472236088344}
2022-11-28 05:32:43,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:43,244 INFO:     Epoch: 82
2022-11-28 05:32:43,904 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4817230779338967, 'Total loss': 0.4817230779338967} | train loss {'Reaction outcome loss': 0.46089404280088386, 'Total loss': 0.46089404280088386}
2022-11-28 05:32:43,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:43,905 INFO:     Epoch: 83
2022-11-28 05:32:44,566 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48479506170207803, 'Total loss': 0.48479506170207803} | train loss {'Reaction outcome loss': 0.4609600407736642, 'Total loss': 0.4609600407736642}
2022-11-28 05:32:44,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:44,566 INFO:     Epoch: 84
2022-11-28 05:32:45,228 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45207805118777533, 'Total loss': 0.45207805118777533} | train loss {'Reaction outcome loss': 0.46321788059205427, 'Total loss': 0.46321788059205427}
2022-11-28 05:32:45,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:45,228 INFO:     Epoch: 85
2022-11-28 05:32:45,889 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4943084371360866, 'Total loss': 0.4943084371360866} | train loss {'Reaction outcome loss': 0.46182859740695176, 'Total loss': 0.46182859740695176}
2022-11-28 05:32:45,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:45,889 INFO:     Epoch: 86
2022-11-28 05:32:46,549 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4976548965681683, 'Total loss': 0.4976548965681683} | train loss {'Reaction outcome loss': 0.46009637172124823, 'Total loss': 0.46009637172124823}
2022-11-28 05:32:46,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:46,549 INFO:     Epoch: 87
2022-11-28 05:32:47,209 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44605725461786444, 'Total loss': 0.44605725461786444} | train loss {'Reaction outcome loss': 0.4563146789463199, 'Total loss': 0.4563146789463199}
2022-11-28 05:32:47,210 INFO:     Found new best model at epoch 87
2022-11-28 05:32:47,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:47,210 INFO:     Epoch: 88
2022-11-28 05:32:47,874 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.514023169875145, 'Total loss': 0.514023169875145} | train loss {'Reaction outcome loss': 0.46509736478328706, 'Total loss': 0.46509736478328706}
2022-11-28 05:32:47,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:47,874 INFO:     Epoch: 89
2022-11-28 05:32:48,536 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5037791136313569, 'Total loss': 0.5037791136313569} | train loss {'Reaction outcome loss': 0.47226134854920054, 'Total loss': 0.47226134854920054}
2022-11-28 05:32:48,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:48,536 INFO:     Epoch: 90
2022-11-28 05:32:49,199 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4486335123127157, 'Total loss': 0.4486335123127157} | train loss {'Reaction outcome loss': 0.4712798694262699, 'Total loss': 0.4712798694262699}
2022-11-28 05:32:49,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:49,200 INFO:     Epoch: 91
2022-11-28 05:32:49,863 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46503330970352347, 'Total loss': 0.46503330970352347} | train loss {'Reaction outcome loss': 0.4633683593905702, 'Total loss': 0.4633683593905702}
2022-11-28 05:32:49,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:49,863 INFO:     Epoch: 92
2022-11-28 05:32:50,525 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4772779799320481, 'Total loss': 0.4772779799320481} | train loss {'Reaction outcome loss': 0.46135899613098225, 'Total loss': 0.46135899613098225}
2022-11-28 05:32:50,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:50,526 INFO:     Epoch: 93
2022-11-28 05:32:51,185 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4986459518020803, 'Total loss': 0.4986459518020803} | train loss {'Reaction outcome loss': 0.46497721672058107, 'Total loss': 0.46497721672058107}
2022-11-28 05:32:51,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:51,186 INFO:     Epoch: 94
2022-11-28 05:32:51,847 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4690654596144503, 'Total loss': 0.4690654596144503} | train loss {'Reaction outcome loss': 0.4653211984099174, 'Total loss': 0.4653211984099174}
2022-11-28 05:32:51,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:51,848 INFO:     Epoch: 95
2022-11-28 05:32:52,509 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.496036444875327, 'Total loss': 0.496036444875327} | train loss {'Reaction outcome loss': 0.454792416399839, 'Total loss': 0.454792416399839}
2022-11-28 05:32:52,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:52,509 INFO:     Epoch: 96
2022-11-28 05:32:53,173 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4725461883301085, 'Total loss': 0.4725461883301085} | train loss {'Reaction outcome loss': 0.46185154397876893, 'Total loss': 0.46185154397876893}
2022-11-28 05:32:53,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:53,173 INFO:     Epoch: 97
2022-11-28 05:32:53,834 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47112309136851266, 'Total loss': 0.47112309136851266} | train loss {'Reaction outcome loss': 0.464702872232515, 'Total loss': 0.464702872232515}
2022-11-28 05:32:53,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:53,834 INFO:     Epoch: 98
2022-11-28 05:32:54,491 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4648677387952127, 'Total loss': 0.4648677387952127} | train loss {'Reaction outcome loss': 0.4581915838986027, 'Total loss': 0.4581915838986027}
2022-11-28 05:32:54,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:54,491 INFO:     Epoch: 99
2022-11-28 05:32:55,147 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4535382186824625, 'Total loss': 0.4535382186824625} | train loss {'Reaction outcome loss': 0.4612864238875253, 'Total loss': 0.4612864238875253}
2022-11-28 05:32:55,147 INFO:     Best model found after epoch 88 of 100.
2022-11-28 05:32:55,147 INFO:   Done with stage: TRAINING
2022-11-28 05:32:55,147 INFO:   Starting stage: EVALUATION
2022-11-28 05:32:55,270 INFO:   Done with stage: EVALUATION
2022-11-28 05:32:55,270 INFO:   Leaving out SEQ value Fold_4
2022-11-28 05:32:55,283 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 05:32:55,283 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:32:55,926 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:32:55,927 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:32:55,996 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:32:55,996 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:32:55,996 INFO:     No hyperparam tuning for this model
2022-11-28 05:32:55,997 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:32:55,997 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:32:55,997 INFO:     None feature selector for col prot
2022-11-28 05:32:55,997 INFO:     None feature selector for col prot
2022-11-28 05:32:55,997 INFO:     None feature selector for col prot
2022-11-28 05:32:55,998 INFO:     None feature selector for col chem
2022-11-28 05:32:55,998 INFO:     None feature selector for col chem
2022-11-28 05:32:55,998 INFO:     None feature selector for col chem
2022-11-28 05:32:55,998 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:32:55,998 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:32:56,000 INFO:     Number of params in model 169651
2022-11-28 05:32:56,003 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:32:56,003 INFO:   Starting stage: TRAINING
2022-11-28 05:32:56,054 INFO:     Val loss before train {'Reaction outcome loss': 0.9917000965638594, 'Total loss': 0.9917000965638594}
2022-11-28 05:32:56,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:56,054 INFO:     Epoch: 0
2022-11-28 05:32:56,717 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5606699795885519, 'Total loss': 0.5606699795885519} | train loss {'Reaction outcome loss': 0.6720321454741212, 'Total loss': 0.6720321454741212}
2022-11-28 05:32:56,717 INFO:     Found new best model at epoch 0
2022-11-28 05:32:56,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:56,717 INFO:     Epoch: 1
2022-11-28 05:32:57,380 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5640881962396882, 'Total loss': 0.5640881962396882} | train loss {'Reaction outcome loss': 0.581921053710978, 'Total loss': 0.581921053710978}
2022-11-28 05:32:57,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:57,380 INFO:     Epoch: 2
2022-11-28 05:32:58,043 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5500951795415445, 'Total loss': 0.5500951795415445} | train loss {'Reaction outcome loss': 0.5385458044677611, 'Total loss': 0.5385458044677611}
2022-11-28 05:32:58,043 INFO:     Found new best model at epoch 2
2022-11-28 05:32:58,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:58,044 INFO:     Epoch: 3
2022-11-28 05:32:58,707 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5013006769798019, 'Total loss': 0.5013006769798019} | train loss {'Reaction outcome loss': 0.5243945122934003, 'Total loss': 0.5243945122934003}
2022-11-28 05:32:58,707 INFO:     Found new best model at epoch 3
2022-11-28 05:32:58,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:58,708 INFO:     Epoch: 4
2022-11-28 05:32:59,364 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48916214907711203, 'Total loss': 0.48916214907711203} | train loss {'Reaction outcome loss': 0.5035715298614039, 'Total loss': 0.5035715298614039}
2022-11-28 05:32:59,365 INFO:     Found new best model at epoch 4
2022-11-28 05:32:59,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:32:59,365 INFO:     Epoch: 5
2022-11-28 05:33:00,028 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.6258609023961154, 'Total loss': 0.6258609023961154} | train loss {'Reaction outcome loss': 0.49238122691992325, 'Total loss': 0.49238122691992325}
2022-11-28 05:33:00,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:00,028 INFO:     Epoch: 6
2022-11-28 05:33:00,692 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5105214328928427, 'Total loss': 0.5105214328928427} | train loss {'Reaction outcome loss': 0.5040758207500705, 'Total loss': 0.5040758207500705}
2022-11-28 05:33:00,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:00,692 INFO:     Epoch: 7
2022-11-28 05:33:01,353 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5160317251628096, 'Total loss': 0.5160317251628096} | train loss {'Reaction outcome loss': 0.49591432041243505, 'Total loss': 0.49591432041243505}
2022-11-28 05:33:01,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:01,354 INFO:     Epoch: 8
2022-11-28 05:33:02,017 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.516299001195214, 'Total loss': 0.516299001195214} | train loss {'Reaction outcome loss': 0.4834277552631702, 'Total loss': 0.4834277552631702}
2022-11-28 05:33:02,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:02,017 INFO:     Epoch: 9
2022-11-28 05:33:02,682 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4856521954590624, 'Total loss': 0.4856521954590624} | train loss {'Reaction outcome loss': 0.4948797991521928, 'Total loss': 0.4948797991521928}
2022-11-28 05:33:02,682 INFO:     Found new best model at epoch 9
2022-11-28 05:33:02,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:02,683 INFO:     Epoch: 10
2022-11-28 05:33:03,348 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49911310794678604, 'Total loss': 0.49911310794678604} | train loss {'Reaction outcome loss': 0.479865226577892, 'Total loss': 0.479865226577892}
2022-11-28 05:33:03,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:03,348 INFO:     Epoch: 11
2022-11-28 05:33:04,016 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5358639623631131, 'Total loss': 0.5358639623631131} | train loss {'Reaction outcome loss': 0.46740263290250833, 'Total loss': 0.46740263290250833}
2022-11-28 05:33:04,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:04,016 INFO:     Epoch: 12
2022-11-28 05:33:04,684 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4910926917059855, 'Total loss': 0.4910926917059855} | train loss {'Reaction outcome loss': 0.47424047186910384, 'Total loss': 0.47424047186910384}
2022-11-28 05:33:04,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:04,684 INFO:     Epoch: 13
2022-11-28 05:33:05,346 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4986047318035906, 'Total loss': 0.4986047318035906} | train loss {'Reaction outcome loss': 0.4693680439400769, 'Total loss': 0.4693680439400769}
2022-11-28 05:33:05,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:05,346 INFO:     Epoch: 14
2022-11-28 05:33:06,006 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47191668301820755, 'Total loss': 0.47191668301820755} | train loss {'Reaction outcome loss': 0.4656931414657276, 'Total loss': 0.4656931414657276}
2022-11-28 05:33:06,006 INFO:     Found new best model at epoch 14
2022-11-28 05:33:06,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:06,007 INFO:     Epoch: 15
2022-11-28 05:33:06,671 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5016225691546093, 'Total loss': 0.5016225691546093} | train loss {'Reaction outcome loss': 0.46887518616340423, 'Total loss': 0.46887518616340423}
2022-11-28 05:33:06,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:06,671 INFO:     Epoch: 16
2022-11-28 05:33:07,338 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46426198360594834, 'Total loss': 0.46426198360594834} | train loss {'Reaction outcome loss': 0.4757392610148018, 'Total loss': 0.4757392610148018}
2022-11-28 05:33:07,339 INFO:     Found new best model at epoch 16
2022-11-28 05:33:07,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:07,339 INFO:     Epoch: 17
2022-11-28 05:33:08,009 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4861076579175212, 'Total loss': 0.4861076579175212} | train loss {'Reaction outcome loss': 0.46075504595934136, 'Total loss': 0.46075504595934136}
2022-11-28 05:33:08,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:08,009 INFO:     Epoch: 18
2022-11-28 05:33:08,675 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4494069987400012, 'Total loss': 0.4494069987400012} | train loss {'Reaction outcome loss': 0.4594697753016494, 'Total loss': 0.4594697753016494}
2022-11-28 05:33:08,676 INFO:     Found new best model at epoch 18
2022-11-28 05:33:08,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:08,676 INFO:     Epoch: 19
2022-11-28 05:33:09,339 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4958253028717908, 'Total loss': 0.4958253028717908} | train loss {'Reaction outcome loss': 0.4607369090140107, 'Total loss': 0.4607369090140107}
2022-11-28 05:33:09,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:09,340 INFO:     Epoch: 20
2022-11-28 05:33:10,001 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5317814363674684, 'Total loss': 0.5317814363674684} | train loss {'Reaction outcome loss': 0.47197395970296446, 'Total loss': 0.47197395970296446}
2022-11-28 05:33:10,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:10,002 INFO:     Epoch: 21
2022-11-28 05:33:10,664 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46371758864684537, 'Total loss': 0.46371758864684537} | train loss {'Reaction outcome loss': 0.4533008914817924, 'Total loss': 0.4533008914817924}
2022-11-28 05:33:10,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:10,664 INFO:     Epoch: 22
2022-11-28 05:33:11,326 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45561548322439194, 'Total loss': 0.45561548322439194} | train loss {'Reaction outcome loss': 0.45704709150289236, 'Total loss': 0.45704709150289236}
2022-11-28 05:33:11,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:11,326 INFO:     Epoch: 23
2022-11-28 05:33:11,987 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47162040356885304, 'Total loss': 0.47162040356885304} | train loss {'Reaction outcome loss': 0.46155053196165724, 'Total loss': 0.46155053196165724}
2022-11-28 05:33:11,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:11,988 INFO:     Epoch: 24
2022-11-28 05:33:12,649 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4721918160265142, 'Total loss': 0.4721918160265142} | train loss {'Reaction outcome loss': 0.4528233775725731, 'Total loss': 0.4528233775725731}
2022-11-28 05:33:12,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:12,649 INFO:     Epoch: 25
2022-11-28 05:33:13,310 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4719884226267988, 'Total loss': 0.4719884226267988} | train loss {'Reaction outcome loss': 0.4528017220830145, 'Total loss': 0.4528017220830145}
2022-11-28 05:33:13,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:13,310 INFO:     Epoch: 26
2022-11-28 05:33:13,974 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4504085911268538, 'Total loss': 0.4504085911268538} | train loss {'Reaction outcome loss': 0.4539863602955814, 'Total loss': 0.4539863602955814}
2022-11-28 05:33:13,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:13,974 INFO:     Epoch: 27
2022-11-28 05:33:14,636 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.477285602891987, 'Total loss': 0.477285602891987} | train loss {'Reaction outcome loss': 0.4529054904213318, 'Total loss': 0.4529054904213318}
2022-11-28 05:33:14,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:14,637 INFO:     Epoch: 28
2022-11-28 05:33:15,298 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48123476722023706, 'Total loss': 0.48123476722023706} | train loss {'Reaction outcome loss': 0.44467840922396884, 'Total loss': 0.44467840922396884}
2022-11-28 05:33:15,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:15,299 INFO:     Epoch: 29
2022-11-28 05:33:15,963 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5083203600211577, 'Total loss': 0.5083203600211577} | train loss {'Reaction outcome loss': 0.4476305486460929, 'Total loss': 0.4476305486460929}
2022-11-28 05:33:15,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:15,963 INFO:     Epoch: 30
2022-11-28 05:33:16,624 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47194020517847757, 'Total loss': 0.47194020517847757} | train loss {'Reaction outcome loss': 0.4571453742532112, 'Total loss': 0.4571453742532112}
2022-11-28 05:33:16,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:16,625 INFO:     Epoch: 31
2022-11-28 05:33:17,283 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4725938943976706, 'Total loss': 0.4725938943976706} | train loss {'Reaction outcome loss': 0.44827716913722787, 'Total loss': 0.44827716913722787}
2022-11-28 05:33:17,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:17,284 INFO:     Epoch: 32
2022-11-28 05:33:17,947 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4836119257590987, 'Total loss': 0.4836119257590987} | train loss {'Reaction outcome loss': 0.4520776594653424, 'Total loss': 0.4520776594653424}
2022-11-28 05:33:17,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:17,948 INFO:     Epoch: 33
2022-11-28 05:33:18,610 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4731127494438128, 'Total loss': 0.4731127494438128} | train loss {'Reaction outcome loss': 0.4461634935818703, 'Total loss': 0.4461634935818703}
2022-11-28 05:33:18,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:18,610 INFO:     Epoch: 34
2022-11-28 05:33:19,271 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45070278915491974, 'Total loss': 0.45070278915491974} | train loss {'Reaction outcome loss': 0.4551235953843606, 'Total loss': 0.4551235953843606}
2022-11-28 05:33:19,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:19,271 INFO:     Epoch: 35
2022-11-28 05:33:19,936 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4946437820114873, 'Total loss': 0.4946437820114873} | train loss {'Reaction outcome loss': 0.4445324978788349, 'Total loss': 0.4445324978788349}
2022-11-28 05:33:19,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:19,936 INFO:     Epoch: 36
2022-11-28 05:33:20,595 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4467782320624048, 'Total loss': 0.4467782320624048} | train loss {'Reaction outcome loss': 0.4467717042939383, 'Total loss': 0.4467717042939383}
2022-11-28 05:33:20,596 INFO:     Found new best model at epoch 36
2022-11-28 05:33:20,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:20,597 INFO:     Epoch: 37
2022-11-28 05:33:21,260 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4727158038453622, 'Total loss': 0.4727158038453622} | train loss {'Reaction outcome loss': 0.457259362676607, 'Total loss': 0.457259362676607}
2022-11-28 05:33:21,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:21,260 INFO:     Epoch: 38
2022-11-28 05:33:21,923 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5082339495420456, 'Total loss': 0.5082339495420456} | train loss {'Reaction outcome loss': 0.44924944928783156, 'Total loss': 0.44924944928783156}
2022-11-28 05:33:21,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:21,923 INFO:     Epoch: 39
2022-11-28 05:33:22,585 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45490304685451766, 'Total loss': 0.45490304685451766} | train loss {'Reaction outcome loss': 0.4501384795918638, 'Total loss': 0.4501384795918638}
2022-11-28 05:33:22,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:22,585 INFO:     Epoch: 40
2022-11-28 05:33:23,246 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4723755419254303, 'Total loss': 0.4723755419254303} | train loss {'Reaction outcome loss': 0.4462123410361499, 'Total loss': 0.4462123410361499}
2022-11-28 05:33:23,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:23,246 INFO:     Epoch: 41
2022-11-28 05:33:23,908 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4711271673440933, 'Total loss': 0.4711271673440933} | train loss {'Reaction outcome loss': 0.44953112883365104, 'Total loss': 0.44953112883365104}
2022-11-28 05:33:23,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:23,909 INFO:     Epoch: 42
2022-11-28 05:33:24,570 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4874789918010885, 'Total loss': 0.4874789918010885} | train loss {'Reaction outcome loss': 0.44620659894702075, 'Total loss': 0.44620659894702075}
2022-11-28 05:33:24,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:24,571 INFO:     Epoch: 43
2022-11-28 05:33:25,235 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.461037836630236, 'Total loss': 0.461037836630236} | train loss {'Reaction outcome loss': 0.44805275875064526, 'Total loss': 0.44805275875064526}
2022-11-28 05:33:25,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:25,235 INFO:     Epoch: 44
2022-11-28 05:33:25,899 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47246885943141853, 'Total loss': 0.47246885943141853} | train loss {'Reaction outcome loss': 0.4543018174632961, 'Total loss': 0.4543018174632961}
2022-11-28 05:33:25,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:25,899 INFO:     Epoch: 45
2022-11-28 05:33:26,566 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44535198782316665, 'Total loss': 0.44535198782316665} | train loss {'Reaction outcome loss': 0.44902116461442065, 'Total loss': 0.44902116461442065}
2022-11-28 05:33:26,566 INFO:     Found new best model at epoch 45
2022-11-28 05:33:26,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:26,567 INFO:     Epoch: 46
2022-11-28 05:33:27,231 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4901845380663872, 'Total loss': 0.4901845380663872} | train loss {'Reaction outcome loss': 0.4546841781752312, 'Total loss': 0.4546841781752312}
2022-11-28 05:33:27,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:27,231 INFO:     Epoch: 47
2022-11-28 05:33:27,894 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46933890879154205, 'Total loss': 0.46933890879154205} | train loss {'Reaction outcome loss': 0.45549298026542434, 'Total loss': 0.45549298026542434}
2022-11-28 05:33:27,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:27,895 INFO:     Epoch: 48
2022-11-28 05:33:28,556 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47360946847633884, 'Total loss': 0.47360946847633884} | train loss {'Reaction outcome loss': 0.44748055301455836, 'Total loss': 0.44748055301455836}
2022-11-28 05:33:28,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:28,556 INFO:     Epoch: 49
2022-11-28 05:33:29,219 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45288442921909416, 'Total loss': 0.45288442921909416} | train loss {'Reaction outcome loss': 0.45422508431832315, 'Total loss': 0.45422508431832315}
2022-11-28 05:33:29,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:29,219 INFO:     Epoch: 50
2022-11-28 05:33:29,883 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48882097378373146, 'Total loss': 0.48882097378373146} | train loss {'Reaction outcome loss': 0.44877222558928404, 'Total loss': 0.44877222558928404}
2022-11-28 05:33:29,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:29,883 INFO:     Epoch: 51
2022-11-28 05:33:30,546 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.459877839142626, 'Total loss': 0.459877839142626} | train loss {'Reaction outcome loss': 0.44409490998095347, 'Total loss': 0.44409490998095347}
2022-11-28 05:33:30,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:30,546 INFO:     Epoch: 52
2022-11-28 05:33:31,208 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4949274439026009, 'Total loss': 0.4949274439026009} | train loss {'Reaction outcome loss': 0.4410498353995775, 'Total loss': 0.4410498353995775}
2022-11-28 05:33:31,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:31,208 INFO:     Epoch: 53
2022-11-28 05:33:31,872 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47622492435303604, 'Total loss': 0.47622492435303604} | train loss {'Reaction outcome loss': 0.4483275168579117, 'Total loss': 0.4483275168579117}
2022-11-28 05:33:31,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:31,872 INFO:     Epoch: 54
2022-11-28 05:33:32,543 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46968494897538965, 'Total loss': 0.46968494897538965} | train loss {'Reaction outcome loss': 0.45413806123530814, 'Total loss': 0.45413806123530814}
2022-11-28 05:33:32,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:32,544 INFO:     Epoch: 55
2022-11-28 05:33:33,210 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45912025394764816, 'Total loss': 0.45912025394764816} | train loss {'Reaction outcome loss': 0.45438303355022, 'Total loss': 0.45438303355022}
2022-11-28 05:33:33,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:33,210 INFO:     Epoch: 56
2022-11-28 05:33:33,874 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4606083915992217, 'Total loss': 0.4606083915992217} | train loss {'Reaction outcome loss': 0.4510378375308219, 'Total loss': 0.4510378375308219}
2022-11-28 05:33:33,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:33,874 INFO:     Epoch: 57
2022-11-28 05:33:34,535 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45868871631947433, 'Total loss': 0.45868871631947433} | train loss {'Reaction outcome loss': 0.44772479281975675, 'Total loss': 0.44772479281975675}
2022-11-28 05:33:34,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:34,535 INFO:     Epoch: 58
2022-11-28 05:33:35,198 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47704651342196897, 'Total loss': 0.47704651342196897} | train loss {'Reaction outcome loss': 0.4450251308650623, 'Total loss': 0.4450251308650623}
2022-11-28 05:33:35,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:35,198 INFO:     Epoch: 59
2022-11-28 05:33:35,860 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4779652448540384, 'Total loss': 0.4779652448540384} | train loss {'Reaction outcome loss': 0.45952530277644094, 'Total loss': 0.45952530277644094}
2022-11-28 05:33:35,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:35,860 INFO:     Epoch: 60
2022-11-28 05:33:36,522 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46071606976064766, 'Total loss': 0.46071606976064766} | train loss {'Reaction outcome loss': 0.45561394891758195, 'Total loss': 0.45561394891758195}
2022-11-28 05:33:36,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:36,523 INFO:     Epoch: 61
2022-11-28 05:33:37,185 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4890074814585122, 'Total loss': 0.4890074814585122} | train loss {'Reaction outcome loss': 0.4504118137182253, 'Total loss': 0.4504118137182253}
2022-11-28 05:33:37,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:37,186 INFO:     Epoch: 62
2022-11-28 05:33:37,849 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4507556069980968, 'Total loss': 0.4507556069980968} | train loss {'Reaction outcome loss': 0.44453562420570414, 'Total loss': 0.44453562420570414}
2022-11-28 05:33:37,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:37,849 INFO:     Epoch: 63
2022-11-28 05:33:38,512 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46298913251269946, 'Total loss': 0.46298913251269946} | train loss {'Reaction outcome loss': 0.45100784754222223, 'Total loss': 0.45100784754222223}
2022-11-28 05:33:38,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:38,512 INFO:     Epoch: 64
2022-11-28 05:33:39,174 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4583582989871502, 'Total loss': 0.4583582989871502} | train loss {'Reaction outcome loss': 0.44845892918043534, 'Total loss': 0.44845892918043534}
2022-11-28 05:33:39,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:39,174 INFO:     Epoch: 65
2022-11-28 05:33:39,839 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48928118954327976, 'Total loss': 0.48928118954327976} | train loss {'Reaction outcome loss': 0.4498134625072663, 'Total loss': 0.4498134625072663}
2022-11-28 05:33:39,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:39,839 INFO:     Epoch: 66
2022-11-28 05:33:40,502 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46162309565327386, 'Total loss': 0.46162309565327386} | train loss {'Reaction outcome loss': 0.44633630931618723, 'Total loss': 0.44633630931618723}
2022-11-28 05:33:40,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:40,503 INFO:     Epoch: 67
2022-11-28 05:33:41,165 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4605240733786063, 'Total loss': 0.4605240733786063} | train loss {'Reaction outcome loss': 0.44817714866624037, 'Total loss': 0.44817714866624037}
2022-11-28 05:33:41,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:41,165 INFO:     Epoch: 68
2022-11-28 05:33:41,831 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4552691186016256, 'Total loss': 0.4552691186016256} | train loss {'Reaction outcome loss': 0.4427239752793119, 'Total loss': 0.4427239752793119}
2022-11-28 05:33:41,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:41,831 INFO:     Epoch: 69
2022-11-28 05:33:42,498 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4707127118652517, 'Total loss': 0.4707127118652517} | train loss {'Reaction outcome loss': 0.4533382299156324, 'Total loss': 0.4533382299156324}
2022-11-28 05:33:42,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:42,499 INFO:     Epoch: 70
2022-11-28 05:33:43,162 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4685696187344464, 'Total loss': 0.4685696187344464} | train loss {'Reaction outcome loss': 0.44624740640945765, 'Total loss': 0.44624740640945765}
2022-11-28 05:33:43,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:43,163 INFO:     Epoch: 71
2022-11-28 05:33:43,825 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4616155482151292, 'Total loss': 0.4616155482151292} | train loss {'Reaction outcome loss': 0.44860861914963857, 'Total loss': 0.44860861914963857}
2022-11-28 05:33:43,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:43,825 INFO:     Epoch: 72
2022-11-28 05:33:44,483 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4662426086989316, 'Total loss': 0.4662426086989316} | train loss {'Reaction outcome loss': 0.4466338968394618, 'Total loss': 0.4466338968394618}
2022-11-28 05:33:44,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:44,483 INFO:     Epoch: 73
2022-11-28 05:33:45,147 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5384142446247014, 'Total loss': 0.5384142446247014} | train loss {'Reaction outcome loss': 0.4490799278262173, 'Total loss': 0.4490799278262173}
2022-11-28 05:33:45,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:45,148 INFO:     Epoch: 74
2022-11-28 05:33:45,817 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47985042157498276, 'Total loss': 0.47985042157498276} | train loss {'Reaction outcome loss': 0.451947309589579, 'Total loss': 0.451947309589579}
2022-11-28 05:33:45,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:45,818 INFO:     Epoch: 75
2022-11-28 05:33:46,484 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45345589044419204, 'Total loss': 0.45345589044419204} | train loss {'Reaction outcome loss': 0.4538089379381675, 'Total loss': 0.4538089379381675}
2022-11-28 05:33:46,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:46,484 INFO:     Epoch: 76
2022-11-28 05:33:47,147 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48404927822676574, 'Total loss': 0.48404927822676574} | train loss {'Reaction outcome loss': 0.4521756124520591, 'Total loss': 0.4521756124520591}
2022-11-28 05:33:47,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:47,147 INFO:     Epoch: 77
2022-11-28 05:33:47,811 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4754622737792405, 'Total loss': 0.4754622737792405} | train loss {'Reaction outcome loss': 0.48645283894892405, 'Total loss': 0.48645283894892405}
2022-11-28 05:33:47,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:47,811 INFO:     Epoch: 78
2022-11-28 05:33:48,474 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49484389613975177, 'Total loss': 0.49484389613975177} | train loss {'Reaction outcome loss': 0.4664830759446691, 'Total loss': 0.4664830759446691}
2022-11-28 05:33:48,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:48,474 INFO:     Epoch: 79
2022-11-28 05:33:49,141 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5257778563960032, 'Total loss': 0.5257778563960032} | train loss {'Reaction outcome loss': 0.45516441466837276, 'Total loss': 0.45516441466837276}
2022-11-28 05:33:49,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:49,141 INFO:     Epoch: 80
2022-11-28 05:33:49,806 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47598170218142594, 'Total loss': 0.47598170218142594} | train loss {'Reaction outcome loss': 0.4564277591553294, 'Total loss': 0.4564277591553294}
2022-11-28 05:33:49,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:49,806 INFO:     Epoch: 81
2022-11-28 05:33:50,471 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48751199448650534, 'Total loss': 0.48751199448650534} | train loss {'Reaction outcome loss': 0.4434324192252719, 'Total loss': 0.4434324192252719}
2022-11-28 05:33:50,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:50,471 INFO:     Epoch: 82
2022-11-28 05:33:51,136 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.477573423223062, 'Total loss': 0.477573423223062} | train loss {'Reaction outcome loss': 0.45361165807918014, 'Total loss': 0.45361165807918014}
2022-11-28 05:33:51,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:51,136 INFO:     Epoch: 83
2022-11-28 05:33:51,802 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4440390362658284, 'Total loss': 0.4440390362658284} | train loss {'Reaction outcome loss': 0.45326234155941586, 'Total loss': 0.45326234155941586}
2022-11-28 05:33:51,802 INFO:     Found new best model at epoch 83
2022-11-28 05:33:51,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:51,803 INFO:     Epoch: 84
2022-11-28 05:33:52,466 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5046682984314181, 'Total loss': 0.5046682984314181} | train loss {'Reaction outcome loss': 0.453150840242382, 'Total loss': 0.453150840242382}
2022-11-28 05:33:52,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:52,467 INFO:     Epoch: 85
2022-11-28 05:33:53,130 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47871829535473476, 'Total loss': 0.47871829535473476} | train loss {'Reaction outcome loss': 0.47579079335517727, 'Total loss': 0.47579079335517727}
2022-11-28 05:33:53,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:53,130 INFO:     Epoch: 86
2022-11-28 05:33:53,798 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47430121356790717, 'Total loss': 0.47430121356790717} | train loss {'Reaction outcome loss': 0.4560697560730251, 'Total loss': 0.4560697560730251}
2022-11-28 05:33:53,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:53,798 INFO:     Epoch: 87
2022-11-28 05:33:54,465 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5077677541835741, 'Total loss': 0.5077677541835741} | train loss {'Reaction outcome loss': 0.45423367719056634, 'Total loss': 0.45423367719056634}
2022-11-28 05:33:54,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:54,466 INFO:     Epoch: 88
2022-11-28 05:33:55,132 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5214060802351345, 'Total loss': 0.5214060802351345} | train loss {'Reaction outcome loss': 0.4560713173165495, 'Total loss': 0.4560713173165495}
2022-11-28 05:33:55,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:55,132 INFO:     Epoch: 89
2022-11-28 05:33:55,796 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4819602637805722, 'Total loss': 0.4819602637805722} | train loss {'Reaction outcome loss': 0.45981827529848585, 'Total loss': 0.45981827529848585}
2022-11-28 05:33:55,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:55,796 INFO:     Epoch: 90
2022-11-28 05:33:56,459 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5544324012642557, 'Total loss': 0.5544324012642557} | train loss {'Reaction outcome loss': 0.4532542702278145, 'Total loss': 0.4532542702278145}
2022-11-28 05:33:56,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:56,459 INFO:     Epoch: 91
2022-11-28 05:33:57,122 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46617686646905815, 'Total loss': 0.46617686646905815} | train loss {'Reaction outcome loss': 0.4528402662666341, 'Total loss': 0.4528402662666341}
2022-11-28 05:33:57,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:57,122 INFO:     Epoch: 92
2022-11-28 05:33:57,788 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49228319051590835, 'Total loss': 0.49228319051590835} | train loss {'Reaction outcome loss': 0.45424191753270654, 'Total loss': 0.45424191753270654}
2022-11-28 05:33:57,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:57,788 INFO:     Epoch: 93
2022-11-28 05:33:58,456 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5151044607839801, 'Total loss': 0.5151044607839801} | train loss {'Reaction outcome loss': 0.45052491381966137, 'Total loss': 0.45052491381966137}
2022-11-28 05:33:58,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:58,456 INFO:     Epoch: 94
2022-11-28 05:33:59,124 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45717848193916405, 'Total loss': 0.45717848193916405} | train loss {'Reaction outcome loss': 0.44488760038667363, 'Total loss': 0.44488760038667363}
2022-11-28 05:33:59,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:59,124 INFO:     Epoch: 95
2022-11-28 05:33:59,792 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49774247204715555, 'Total loss': 0.49774247204715555} | train loss {'Reaction outcome loss': 0.4579146843448824, 'Total loss': 0.4579146843448824}
2022-11-28 05:33:59,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:33:59,792 INFO:     Epoch: 96
2022-11-28 05:34:00,455 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4694576366719874, 'Total loss': 0.4694576366719874} | train loss {'Reaction outcome loss': 0.4543270738078998, 'Total loss': 0.4543270738078998}
2022-11-28 05:34:00,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:00,455 INFO:     Epoch: 97
2022-11-28 05:34:01,121 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5690596984191374, 'Total loss': 0.5690596984191374} | train loss {'Reaction outcome loss': 0.45424820196170074, 'Total loss': 0.45424820196170074}
2022-11-28 05:34:01,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:01,121 INFO:     Epoch: 98
2022-11-28 05:34:01,786 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4781061556528915, 'Total loss': 0.4781061556528915} | train loss {'Reaction outcome loss': 0.4561630393932705, 'Total loss': 0.4561630393932705}
2022-11-28 05:34:01,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:01,787 INFO:     Epoch: 99
2022-11-28 05:34:02,452 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4938304481858557, 'Total loss': 0.4938304481858557} | train loss {'Reaction outcome loss': 0.4613410274871448, 'Total loss': 0.4613410274871448}
2022-11-28 05:34:02,452 INFO:     Best model found after epoch 84 of 100.
2022-11-28 05:34:02,452 INFO:   Done with stage: TRAINING
2022-11-28 05:34:02,452 INFO:   Starting stage: EVALUATION
2022-11-28 05:34:02,570 INFO:   Done with stage: EVALUATION
2022-11-28 05:34:02,570 INFO:   Leaving out SEQ value Fold_5
2022-11-28 05:34:02,582 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 05:34:02,582 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:34:03,231 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:34:03,231 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:34:03,301 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:34:03,302 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:34:03,302 INFO:     No hyperparam tuning for this model
2022-11-28 05:34:03,302 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:34:03,302 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:34:03,302 INFO:     None feature selector for col prot
2022-11-28 05:34:03,303 INFO:     None feature selector for col prot
2022-11-28 05:34:03,303 INFO:     None feature selector for col prot
2022-11-28 05:34:03,303 INFO:     None feature selector for col chem
2022-11-28 05:34:03,303 INFO:     None feature selector for col chem
2022-11-28 05:34:03,303 INFO:     None feature selector for col chem
2022-11-28 05:34:03,303 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:34:03,303 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:34:03,305 INFO:     Number of params in model 169651
2022-11-28 05:34:03,308 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:34:03,308 INFO:   Starting stage: TRAINING
2022-11-28 05:34:03,360 INFO:     Val loss before train {'Reaction outcome loss': 0.9719819142059847, 'Total loss': 0.9719819142059847}
2022-11-28 05:34:03,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:03,360 INFO:     Epoch: 0
2022-11-28 05:34:04,030 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5843226289884611, 'Total loss': 0.5843226289884611} | train loss {'Reaction outcome loss': 0.6943517741897414, 'Total loss': 0.6943517741897414}
2022-11-28 05:34:04,031 INFO:     Found new best model at epoch 0
2022-11-28 05:34:04,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:04,032 INFO:     Epoch: 1
2022-11-28 05:34:04,701 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5828562419522892, 'Total loss': 0.5828562419522892} | train loss {'Reaction outcome loss': 0.5777279660105705, 'Total loss': 0.5777279660105705}
2022-11-28 05:34:04,701 INFO:     Found new best model at epoch 1
2022-11-28 05:34:04,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:04,702 INFO:     Epoch: 2
2022-11-28 05:34:05,371 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5757577270269394, 'Total loss': 0.5757577270269394} | train loss {'Reaction outcome loss': 0.5496123953452033, 'Total loss': 0.5496123953452033}
2022-11-28 05:34:05,371 INFO:     Found new best model at epoch 2
2022-11-28 05:34:05,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:05,372 INFO:     Epoch: 3
2022-11-28 05:34:06,038 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5278323086147959, 'Total loss': 0.5278323086147959} | train loss {'Reaction outcome loss': 0.5287835623828634, 'Total loss': 0.5287835623828634}
2022-11-28 05:34:06,038 INFO:     Found new best model at epoch 3
2022-11-28 05:34:06,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:06,039 INFO:     Epoch: 4
2022-11-28 05:34:06,705 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5120792221277952, 'Total loss': 0.5120792221277952} | train loss {'Reaction outcome loss': 0.5161499614196439, 'Total loss': 0.5161499614196439}
2022-11-28 05:34:06,705 INFO:     Found new best model at epoch 4
2022-11-28 05:34:06,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:06,706 INFO:     Epoch: 5
2022-11-28 05:34:07,372 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5061427317559719, 'Total loss': 0.5061427317559719} | train loss {'Reaction outcome loss': 0.5152222674580351, 'Total loss': 0.5152222674580351}
2022-11-28 05:34:07,372 INFO:     Found new best model at epoch 5
2022-11-28 05:34:07,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:07,373 INFO:     Epoch: 6
2022-11-28 05:34:08,045 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5618917075070468, 'Total loss': 0.5618917075070468} | train loss {'Reaction outcome loss': 0.5003194493812418, 'Total loss': 0.5003194493812418}
2022-11-28 05:34:08,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:08,045 INFO:     Epoch: 7
2022-11-28 05:34:08,712 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5189570303667675, 'Total loss': 0.5189570303667675} | train loss {'Reaction outcome loss': 0.4985711387088222, 'Total loss': 0.4985711387088222}
2022-11-28 05:34:08,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:08,712 INFO:     Epoch: 8
2022-11-28 05:34:09,378 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5000451532277194, 'Total loss': 0.5000451532277194} | train loss {'Reaction outcome loss': 0.49668209519117107, 'Total loss': 0.49668209519117107}
2022-11-28 05:34:09,379 INFO:     Found new best model at epoch 8
2022-11-28 05:34:09,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:09,379 INFO:     Epoch: 9
2022-11-28 05:34:10,044 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5524982207200744, 'Total loss': 0.5524982207200744} | train loss {'Reaction outcome loss': 0.4940442238603869, 'Total loss': 0.4940442238603869}
2022-11-28 05:34:10,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:10,045 INFO:     Epoch: 10
2022-11-28 05:34:10,710 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4868232259018855, 'Total loss': 0.4868232259018855} | train loss {'Reaction outcome loss': 0.482072617798563, 'Total loss': 0.482072617798563}
2022-11-28 05:34:10,711 INFO:     Found new best model at epoch 10
2022-11-28 05:34:10,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:10,711 INFO:     Epoch: 11
2022-11-28 05:34:11,377 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47408399324525485, 'Total loss': 0.47408399324525485} | train loss {'Reaction outcome loss': 0.4785442328260791, 'Total loss': 0.4785442328260791}
2022-11-28 05:34:11,377 INFO:     Found new best model at epoch 11
2022-11-28 05:34:11,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:11,378 INFO:     Epoch: 12
2022-11-28 05:34:12,045 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.469926346432079, 'Total loss': 0.469926346432079} | train loss {'Reaction outcome loss': 0.4800823744266264, 'Total loss': 0.4800823744266264}
2022-11-28 05:34:12,045 INFO:     Found new best model at epoch 12
2022-11-28 05:34:12,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:12,046 INFO:     Epoch: 13
2022-11-28 05:34:12,715 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5184955918653444, 'Total loss': 0.5184955918653444} | train loss {'Reaction outcome loss': 0.4794249988251155, 'Total loss': 0.4794249988251155}
2022-11-28 05:34:12,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:12,715 INFO:     Epoch: 14
2022-11-28 05:34:13,385 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49029201811010187, 'Total loss': 0.49029201811010187} | train loss {'Reaction outcome loss': 0.47244205602234407, 'Total loss': 0.47244205602234407}
2022-11-28 05:34:13,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:13,385 INFO:     Epoch: 15
2022-11-28 05:34:14,054 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5015345032919537, 'Total loss': 0.5015345032919537} | train loss {'Reaction outcome loss': 0.4765214911632, 'Total loss': 0.4765214911632}
2022-11-28 05:34:14,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:14,054 INFO:     Epoch: 16
2022-11-28 05:34:14,723 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47456667775457556, 'Total loss': 0.47456667775457556} | train loss {'Reaction outcome loss': 0.46597266335400844, 'Total loss': 0.46597266335400844}
2022-11-28 05:34:14,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:14,724 INFO:     Epoch: 17
2022-11-28 05:34:15,394 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4869016991420226, 'Total loss': 0.4869016991420226} | train loss {'Reaction outcome loss': 0.46118309468992297, 'Total loss': 0.46118309468992297}
2022-11-28 05:34:15,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:15,394 INFO:     Epoch: 18
2022-11-28 05:34:16,063 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4782293537123637, 'Total loss': 0.4782293537123637} | train loss {'Reaction outcome loss': 0.46989299825602965, 'Total loss': 0.46989299825602965}
2022-11-28 05:34:16,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:16,064 INFO:     Epoch: 19
2022-11-28 05:34:16,730 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47276962429962377, 'Total loss': 0.47276962429962377} | train loss {'Reaction outcome loss': 0.4669274722616519, 'Total loss': 0.4669274722616519}
2022-11-28 05:34:16,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:16,730 INFO:     Epoch: 20
2022-11-28 05:34:17,398 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49109032072804193, 'Total loss': 0.49109032072804193} | train loss {'Reaction outcome loss': 0.469613290962673, 'Total loss': 0.469613290962673}
2022-11-28 05:34:17,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:17,398 INFO:     Epoch: 21
2022-11-28 05:34:18,069 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5330927920612422, 'Total loss': 0.5330927920612422} | train loss {'Reaction outcome loss': 0.4686497612105262, 'Total loss': 0.4686497612105262}
2022-11-28 05:34:18,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:18,069 INFO:     Epoch: 22
2022-11-28 05:34:18,736 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49120675027370453, 'Total loss': 0.49120675027370453} | train loss {'Reaction outcome loss': 0.46977668507925924, 'Total loss': 0.46977668507925924}
2022-11-28 05:34:18,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:18,737 INFO:     Epoch: 23
2022-11-28 05:34:19,404 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46556592698801647, 'Total loss': 0.46556592698801647} | train loss {'Reaction outcome loss': 0.45977268821649975, 'Total loss': 0.45977268821649975}
2022-11-28 05:34:19,404 INFO:     Found new best model at epoch 23
2022-11-28 05:34:19,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:19,405 INFO:     Epoch: 24
2022-11-28 05:34:20,075 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5027729306708683, 'Total loss': 0.5027729306708683} | train loss {'Reaction outcome loss': 0.46268386459879335, 'Total loss': 0.46268386459879335}
2022-11-28 05:34:20,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:20,076 INFO:     Epoch: 25
2022-11-28 05:34:20,745 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48812050677158614, 'Total loss': 0.48812050677158614} | train loss {'Reaction outcome loss': 0.4701987108996799, 'Total loss': 0.4701987108996799}
2022-11-28 05:34:20,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:20,745 INFO:     Epoch: 26
2022-11-28 05:34:21,413 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5005885328758847, 'Total loss': 0.5005885328758847} | train loss {'Reaction outcome loss': 0.4642267829828685, 'Total loss': 0.4642267829828685}
2022-11-28 05:34:21,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:21,413 INFO:     Epoch: 27
2022-11-28 05:34:22,080 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47522308135574515, 'Total loss': 0.47522308135574515} | train loss {'Reaction outcome loss': 0.45885252850430625, 'Total loss': 0.45885252850430625}
2022-11-28 05:34:22,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:22,081 INFO:     Epoch: 28
2022-11-28 05:34:22,748 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48242652754892, 'Total loss': 0.48242652754892} | train loss {'Reaction outcome loss': 0.4621456795101685, 'Total loss': 0.4621456795101685}
2022-11-28 05:34:22,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:22,748 INFO:     Epoch: 29
2022-11-28 05:34:23,419 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47781873189590196, 'Total loss': 0.47781873189590196} | train loss {'Reaction outcome loss': 0.4630937073980608, 'Total loss': 0.4630937073980608}
2022-11-28 05:34:23,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:23,420 INFO:     Epoch: 30
2022-11-28 05:34:24,085 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4688981304114515, 'Total loss': 0.4688981304114515} | train loss {'Reaction outcome loss': 0.4664151614471789, 'Total loss': 0.4664151614471789}
2022-11-28 05:34:24,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:24,085 INFO:     Epoch: 31
2022-11-28 05:34:24,753 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5223550545898351, 'Total loss': 0.5223550545898351} | train loss {'Reaction outcome loss': 0.45715189076239066, 'Total loss': 0.45715189076239066}
2022-11-28 05:34:24,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:24,753 INFO:     Epoch: 32
2022-11-28 05:34:25,420 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5189152969555422, 'Total loss': 0.5189152969555422} | train loss {'Reaction outcome loss': 0.4639310473275761, 'Total loss': 0.4639310473275761}
2022-11-28 05:34:25,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:25,420 INFO:     Epoch: 33
2022-11-28 05:34:26,086 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48727781359444966, 'Total loss': 0.48727781359444966} | train loss {'Reaction outcome loss': 0.4622690848285152, 'Total loss': 0.4622690848285152}
2022-11-28 05:34:26,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:26,086 INFO:     Epoch: 34
2022-11-28 05:34:26,752 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.480303555727005, 'Total loss': 0.480303555727005} | train loss {'Reaction outcome loss': 0.461722313696819, 'Total loss': 0.461722313696819}
2022-11-28 05:34:26,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:26,753 INFO:     Epoch: 35
2022-11-28 05:34:27,421 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46137098663232545, 'Total loss': 0.46137098663232545} | train loss {'Reaction outcome loss': 0.4599384892010881, 'Total loss': 0.4599384892010881}
2022-11-28 05:34:27,421 INFO:     Found new best model at epoch 35
2022-11-28 05:34:27,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:27,422 INFO:     Epoch: 36
2022-11-28 05:34:28,090 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4696091010489247, 'Total loss': 0.4696091010489247} | train loss {'Reaction outcome loss': 0.4616957902908325, 'Total loss': 0.4616957902908325}
2022-11-28 05:34:28,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:28,090 INFO:     Epoch: 37
2022-11-28 05:34:28,758 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4686567671597004, 'Total loss': 0.4686567671597004} | train loss {'Reaction outcome loss': 0.4659733808929882, 'Total loss': 0.4659733808929882}
2022-11-28 05:34:28,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:28,758 INFO:     Epoch: 38
2022-11-28 05:34:29,425 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4734203456477685, 'Total loss': 0.4734203456477685} | train loss {'Reaction outcome loss': 0.46020182327277237, 'Total loss': 0.46020182327277237}
2022-11-28 05:34:29,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:29,425 INFO:     Epoch: 39
2022-11-28 05:34:30,094 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4752833311530677, 'Total loss': 0.4752833311530677} | train loss {'Reaction outcome loss': 0.45745775391978605, 'Total loss': 0.45745775391978605}
2022-11-28 05:34:30,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:30,094 INFO:     Epoch: 40
2022-11-28 05:34:30,763 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5132697028192607, 'Total loss': 0.5132697028192607} | train loss {'Reaction outcome loss': 0.4572965632222833, 'Total loss': 0.4572965632222833}
2022-11-28 05:34:30,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:30,763 INFO:     Epoch: 41
2022-11-28 05:34:31,430 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5050863657485355, 'Total loss': 0.5050863657485355} | train loss {'Reaction outcome loss': 0.45410664112217003, 'Total loss': 0.45410664112217003}
2022-11-28 05:34:31,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:31,430 INFO:     Epoch: 42
2022-11-28 05:34:32,097 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47466144812378014, 'Total loss': 0.47466144812378014} | train loss {'Reaction outcome loss': 0.46186241267188904, 'Total loss': 0.46186241267188904}
2022-11-28 05:34:32,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:32,097 INFO:     Epoch: 43
2022-11-28 05:34:32,764 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4707800065251914, 'Total loss': 0.4707800065251914} | train loss {'Reaction outcome loss': 0.45544650291483246, 'Total loss': 0.45544650291483246}
2022-11-28 05:34:32,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:32,764 INFO:     Epoch: 44
2022-11-28 05:34:33,437 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.491968383165923, 'Total loss': 0.491968383165923} | train loss {'Reaction outcome loss': 0.4624605967152503, 'Total loss': 0.4624605967152503}
2022-11-28 05:34:33,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:33,437 INFO:     Epoch: 45
2022-11-28 05:34:34,110 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4755722067572854, 'Total loss': 0.4755722067572854} | train loss {'Reaction outcome loss': 0.45795257131178535, 'Total loss': 0.45795257131178535}
2022-11-28 05:34:34,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:34,110 INFO:     Epoch: 46
2022-11-28 05:34:34,786 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4888578226620501, 'Total loss': 0.4888578226620501} | train loss {'Reaction outcome loss': 0.4572747278537962, 'Total loss': 0.4572747278537962}
2022-11-28 05:34:34,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:34,786 INFO:     Epoch: 47
2022-11-28 05:34:35,461 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47174209559505637, 'Total loss': 0.47174209559505637} | train loss {'Reaction outcome loss': 0.4597056764628618, 'Total loss': 0.4597056764628618}
2022-11-28 05:34:35,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:35,462 INFO:     Epoch: 48
2022-11-28 05:34:36,131 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47230311381545936, 'Total loss': 0.47230311381545936} | train loss {'Reaction outcome loss': 0.4610730771335863, 'Total loss': 0.4610730771335863}
2022-11-28 05:34:36,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:36,131 INFO:     Epoch: 49
2022-11-28 05:34:36,800 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4558528001335534, 'Total loss': 0.4558528001335534} | train loss {'Reaction outcome loss': 0.45765816089847394, 'Total loss': 0.45765816089847394}
2022-11-28 05:34:36,800 INFO:     Found new best model at epoch 49
2022-11-28 05:34:36,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:36,800 INFO:     Epoch: 50
2022-11-28 05:34:37,465 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48331603001464496, 'Total loss': 0.48331603001464496} | train loss {'Reaction outcome loss': 0.46500825551488706, 'Total loss': 0.46500825551488706}
2022-11-28 05:34:37,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:37,465 INFO:     Epoch: 51
2022-11-28 05:34:38,133 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48630958050489426, 'Total loss': 0.48630958050489426} | train loss {'Reaction outcome loss': 0.4622347780293034, 'Total loss': 0.4622347780293034}
2022-11-28 05:34:38,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:38,133 INFO:     Epoch: 52
2022-11-28 05:34:38,807 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45500565387985925, 'Total loss': 0.45500565387985925} | train loss {'Reaction outcome loss': 0.46009213828872286, 'Total loss': 0.46009213828872286}
2022-11-28 05:34:38,808 INFO:     Found new best model at epoch 52
2022-11-28 05:34:38,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:38,808 INFO:     Epoch: 53
2022-11-28 05:34:39,485 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46529295498674567, 'Total loss': 0.46529295498674567} | train loss {'Reaction outcome loss': 0.45835500408805185, 'Total loss': 0.45835500408805185}
2022-11-28 05:34:39,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:39,485 INFO:     Epoch: 54
2022-11-28 05:34:40,160 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46825699643655255, 'Total loss': 0.46825699643655255} | train loss {'Reaction outcome loss': 0.45386004931623897, 'Total loss': 0.45386004931623897}
2022-11-28 05:34:40,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:40,160 INFO:     Epoch: 55
2022-11-28 05:34:40,830 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4557817073708231, 'Total loss': 0.4557817073708231} | train loss {'Reaction outcome loss': 0.45555321571807705, 'Total loss': 0.45555321571807705}
2022-11-28 05:34:40,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:40,830 INFO:     Epoch: 56
2022-11-28 05:34:41,504 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45046728502281685, 'Total loss': 0.45046728502281685} | train loss {'Reaction outcome loss': 0.4648691788916626, 'Total loss': 0.4648691788916626}
2022-11-28 05:34:41,504 INFO:     Found new best model at epoch 56
2022-11-28 05:34:41,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:41,505 INFO:     Epoch: 57
2022-11-28 05:34:42,177 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4819553149017421, 'Total loss': 0.4819553149017421} | train loss {'Reaction outcome loss': 0.45702391349139715, 'Total loss': 0.45702391349139715}
2022-11-28 05:34:42,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:42,178 INFO:     Epoch: 58
2022-11-28 05:34:42,843 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4840126979080113, 'Total loss': 0.4840126979080113} | train loss {'Reaction outcome loss': 0.4635410365618525, 'Total loss': 0.4635410365618525}
2022-11-28 05:34:42,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:42,843 INFO:     Epoch: 59
2022-11-28 05:34:43,509 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46390540118921886, 'Total loss': 0.46390540118921886} | train loss {'Reaction outcome loss': 0.45273259143915867, 'Total loss': 0.45273259143915867}
2022-11-28 05:34:43,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:43,509 INFO:     Epoch: 60
2022-11-28 05:34:44,176 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47818652438846504, 'Total loss': 0.47818652438846504} | train loss {'Reaction outcome loss': 0.46291222213016403, 'Total loss': 0.46291222213016403}
2022-11-28 05:34:44,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:44,176 INFO:     Epoch: 61
2022-11-28 05:34:44,841 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48429473354057834, 'Total loss': 0.48429473354057834} | train loss {'Reaction outcome loss': 0.4612539217717225, 'Total loss': 0.4612539217717225}
2022-11-28 05:34:44,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:44,842 INFO:     Epoch: 62
2022-11-28 05:34:45,507 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.480888118120757, 'Total loss': 0.480888118120757} | train loss {'Reaction outcome loss': 0.46080222371364793, 'Total loss': 0.46080222371364793}
2022-11-28 05:34:45,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:45,507 INFO:     Epoch: 63
2022-11-28 05:34:46,176 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5198934179815379, 'Total loss': 0.5198934179815379} | train loss {'Reaction outcome loss': 0.45630118383034585, 'Total loss': 0.45630118383034585}
2022-11-28 05:34:46,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:46,176 INFO:     Epoch: 64
2022-11-28 05:34:46,846 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4542733380063014, 'Total loss': 0.4542733380063014} | train loss {'Reaction outcome loss': 0.4612484265479349, 'Total loss': 0.4612484265479349}
2022-11-28 05:34:46,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:46,846 INFO:     Epoch: 65
2022-11-28 05:34:47,514 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4807639433579011, 'Total loss': 0.4807639433579011} | train loss {'Reaction outcome loss': 0.4531387313599548, 'Total loss': 0.4531387313599548}
2022-11-28 05:34:47,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:47,514 INFO:     Epoch: 66
2022-11-28 05:34:48,183 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4702191925184293, 'Total loss': 0.4702191925184293} | train loss {'Reaction outcome loss': 0.4631484102517847, 'Total loss': 0.4631484102517847}
2022-11-28 05:34:48,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:48,183 INFO:     Epoch: 67
2022-11-28 05:34:48,851 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4602141769772226, 'Total loss': 0.4602141769772226} | train loss {'Reaction outcome loss': 0.4584276431630696, 'Total loss': 0.4584276431630696}
2022-11-28 05:34:48,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:48,852 INFO:     Epoch: 68
2022-11-28 05:34:49,520 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5063902647657827, 'Total loss': 0.5063902647657827} | train loss {'Reaction outcome loss': 0.4597794377515393, 'Total loss': 0.4597794377515393}
2022-11-28 05:34:49,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:49,520 INFO:     Epoch: 69
2022-11-28 05:34:50,188 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47759395228190854, 'Total loss': 0.47759395228190854} | train loss {'Reaction outcome loss': 0.45595183698160036, 'Total loss': 0.45595183698160036}
2022-11-28 05:34:50,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:50,188 INFO:     Epoch: 70
2022-11-28 05:34:50,856 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46893288228999486, 'Total loss': 0.46893288228999486} | train loss {'Reaction outcome loss': 0.46356467740429985, 'Total loss': 0.46356467740429985}
2022-11-28 05:34:50,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:50,856 INFO:     Epoch: 71
2022-11-28 05:34:51,526 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47552227872339164, 'Total loss': 0.47552227872339164} | train loss {'Reaction outcome loss': 0.4662000193831421, 'Total loss': 0.4662000193831421}
2022-11-28 05:34:51,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:51,526 INFO:     Epoch: 72
2022-11-28 05:34:52,193 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47605389763008465, 'Total loss': 0.47605389763008465} | train loss {'Reaction outcome loss': 0.46210583569782393, 'Total loss': 0.46210583569782393}
2022-11-28 05:34:52,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:52,193 INFO:     Epoch: 73
2022-11-28 05:34:52,861 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45492018081925134, 'Total loss': 0.45492018081925134} | train loss {'Reaction outcome loss': 0.45864935928294737, 'Total loss': 0.45864935928294737}
2022-11-28 05:34:52,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:52,861 INFO:     Epoch: 74
2022-11-28 05:34:53,530 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49856094778938725, 'Total loss': 0.49856094778938725} | train loss {'Reaction outcome loss': 0.46116331466023, 'Total loss': 0.46116331466023}
2022-11-28 05:34:53,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:53,531 INFO:     Epoch: 75
2022-11-28 05:34:54,202 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4940028962763873, 'Total loss': 0.4940028962763873} | train loss {'Reaction outcome loss': 0.46254790736542595, 'Total loss': 0.46254790736542595}
2022-11-28 05:34:54,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:54,202 INFO:     Epoch: 76
2022-11-28 05:34:54,873 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4860983091321858, 'Total loss': 0.4860983091321858} | train loss {'Reaction outcome loss': 0.46517538901178107, 'Total loss': 0.46517538901178107}
2022-11-28 05:34:54,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:54,873 INFO:     Epoch: 77
2022-11-28 05:34:55,541 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4708567322655158, 'Total loss': 0.4708567322655158} | train loss {'Reaction outcome loss': 0.47259672226444366, 'Total loss': 0.47259672226444366}
2022-11-28 05:34:55,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:55,542 INFO:     Epoch: 78
2022-11-28 05:34:56,211 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4799931713125922, 'Total loss': 0.4799931713125922} | train loss {'Reaction outcome loss': 0.4614657976574475, 'Total loss': 0.4614657976574475}
2022-11-28 05:34:56,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:56,211 INFO:     Epoch: 79
2022-11-28 05:34:56,883 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47638292983174324, 'Total loss': 0.47638292983174324} | train loss {'Reaction outcome loss': 0.4599996011463865, 'Total loss': 0.4599996011463865}
2022-11-28 05:34:56,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:56,883 INFO:     Epoch: 80
2022-11-28 05:34:57,548 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49917208606546576, 'Total loss': 0.49917208606546576} | train loss {'Reaction outcome loss': 0.456880277323146, 'Total loss': 0.456880277323146}
2022-11-28 05:34:57,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:57,549 INFO:     Epoch: 81
2022-11-28 05:34:58,216 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4709828695790334, 'Total loss': 0.4709828695790334} | train loss {'Reaction outcome loss': 0.4675890544369336, 'Total loss': 0.4675890544369336}
2022-11-28 05:34:58,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:58,216 INFO:     Epoch: 82
2022-11-28 05:34:58,886 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46697592159563844, 'Total loss': 0.46697592159563844} | train loss {'Reaction outcome loss': 0.45483046902283547, 'Total loss': 0.45483046902283547}
2022-11-28 05:34:58,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:58,886 INFO:     Epoch: 83
2022-11-28 05:34:59,556 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5141602791845798, 'Total loss': 0.5141602791845798} | train loss {'Reaction outcome loss': 0.4574174333604113, 'Total loss': 0.4574174333604113}
2022-11-28 05:34:59,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:34:59,556 INFO:     Epoch: 84
2022-11-28 05:35:00,224 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45961581339890306, 'Total loss': 0.45961581339890306} | train loss {'Reaction outcome loss': 0.4639136204796453, 'Total loss': 0.4639136204796453}
2022-11-28 05:35:00,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:00,224 INFO:     Epoch: 85
2022-11-28 05:35:00,891 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48455260626294394, 'Total loss': 0.48455260626294394} | train loss {'Reaction outcome loss': 0.45436035445140255, 'Total loss': 0.45436035445140255}
2022-11-28 05:35:00,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:00,892 INFO:     Epoch: 86
2022-11-28 05:35:01,561 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4933834285898642, 'Total loss': 0.4933834285898642} | train loss {'Reaction outcome loss': 0.46174849641899907, 'Total loss': 0.46174849641899907}
2022-11-28 05:35:01,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:01,561 INFO:     Epoch: 87
2022-11-28 05:35:02,229 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49693730541250924, 'Total loss': 0.49693730541250924} | train loss {'Reaction outcome loss': 0.46486467735901954, 'Total loss': 0.46486467735901954}
2022-11-28 05:35:02,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:02,230 INFO:     Epoch: 88
2022-11-28 05:35:02,900 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48455852744254196, 'Total loss': 0.48455852744254196} | train loss {'Reaction outcome loss': 0.45818503729758725, 'Total loss': 0.45818503729758725}
2022-11-28 05:35:02,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:02,900 INFO:     Epoch: 89
2022-11-28 05:35:03,570 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47615324265577574, 'Total loss': 0.47615324265577574} | train loss {'Reaction outcome loss': 0.46258218634513115, 'Total loss': 0.46258218634513115}
2022-11-28 05:35:03,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:03,570 INFO:     Epoch: 90
2022-11-28 05:35:04,239 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4751871966502883, 'Total loss': 0.4751871966502883} | train loss {'Reaction outcome loss': 0.4579454567283392, 'Total loss': 0.4579454567283392}
2022-11-28 05:35:04,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:04,239 INFO:     Epoch: 91
2022-11-28 05:35:04,907 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5034528056328947, 'Total loss': 0.5034528056328947} | train loss {'Reaction outcome loss': 0.4628908390840215, 'Total loss': 0.4628908390840215}
2022-11-28 05:35:04,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:04,907 INFO:     Epoch: 92
2022-11-28 05:35:05,577 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4708150029182434, 'Total loss': 0.4708150029182434} | train loss {'Reaction outcome loss': 0.456339948630381, 'Total loss': 0.456339948630381}
2022-11-28 05:35:05,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:05,577 INFO:     Epoch: 93
2022-11-28 05:35:06,246 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49709546904672275, 'Total loss': 0.49709546904672275} | train loss {'Reaction outcome loss': 0.463083942030226, 'Total loss': 0.463083942030226}
2022-11-28 05:35:06,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:06,247 INFO:     Epoch: 94
2022-11-28 05:35:06,921 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5020365626974539, 'Total loss': 0.5020365626974539} | train loss {'Reaction outcome loss': 0.44895989904480593, 'Total loss': 0.44895989904480593}
2022-11-28 05:35:06,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:06,921 INFO:     Epoch: 95
2022-11-28 05:35:07,592 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48356336389075627, 'Total loss': 0.48356336389075627} | train loss {'Reaction outcome loss': 0.4574969164246032, 'Total loss': 0.4574969164246032}
2022-11-28 05:35:07,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:07,592 INFO:     Epoch: 96
2022-11-28 05:35:08,261 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4844937072220174, 'Total loss': 0.4844937072220174} | train loss {'Reaction outcome loss': 0.4564539451272257, 'Total loss': 0.4564539451272257}
2022-11-28 05:35:08,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:08,261 INFO:     Epoch: 97
2022-11-28 05:35:08,929 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47929806770248845, 'Total loss': 0.47929806770248845} | train loss {'Reaction outcome loss': 0.45349435844729025, 'Total loss': 0.45349435844729025}
2022-11-28 05:35:08,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:08,929 INFO:     Epoch: 98
2022-11-28 05:35:09,601 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5203643556345593, 'Total loss': 0.5203643556345593} | train loss {'Reaction outcome loss': 0.4584362826520397, 'Total loss': 0.4584362826520397}
2022-11-28 05:35:09,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:09,602 INFO:     Epoch: 99
2022-11-28 05:35:10,270 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47883114929903636, 'Total loss': 0.47883114929903636} | train loss {'Reaction outcome loss': 0.45200953939028327, 'Total loss': 0.45200953939028327}
2022-11-28 05:35:10,270 INFO:     Best model found after epoch 57 of 100.
2022-11-28 05:35:10,270 INFO:   Done with stage: TRAINING
2022-11-28 05:35:10,270 INFO:   Starting stage: EVALUATION
2022-11-28 05:35:10,382 INFO:   Done with stage: EVALUATION
2022-11-28 05:35:10,382 INFO:   Leaving out SEQ value Fold_6
2022-11-28 05:35:10,395 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 05:35:10,395 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:35:11,039 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:35:11,040 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:35:11,110 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:35:11,110 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:35:11,110 INFO:     No hyperparam tuning for this model
2022-11-28 05:35:11,110 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:35:11,110 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:35:11,111 INFO:     None feature selector for col prot
2022-11-28 05:35:11,111 INFO:     None feature selector for col prot
2022-11-28 05:35:11,111 INFO:     None feature selector for col prot
2022-11-28 05:35:11,112 INFO:     None feature selector for col chem
2022-11-28 05:35:11,112 INFO:     None feature selector for col chem
2022-11-28 05:35:11,112 INFO:     None feature selector for col chem
2022-11-28 05:35:11,112 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:35:11,112 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:35:11,113 INFO:     Number of params in model 169651
2022-11-28 05:35:11,116 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:35:11,116 INFO:   Starting stage: TRAINING
2022-11-28 05:35:11,168 INFO:     Val loss before train {'Reaction outcome loss': 1.0104056745767593, 'Total loss': 1.0104056745767593}
2022-11-28 05:35:11,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:11,168 INFO:     Epoch: 0
2022-11-28 05:35:11,835 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6268254511735656, 'Total loss': 0.6268254511735656} | train loss {'Reaction outcome loss': 0.6967330288382307, 'Total loss': 0.6967330288382307}
2022-11-28 05:35:11,836 INFO:     Found new best model at epoch 0
2022-11-28 05:35:11,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:11,836 INFO:     Epoch: 1
2022-11-28 05:35:12,511 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.538819333030419, 'Total loss': 0.538819333030419} | train loss {'Reaction outcome loss': 0.5895966358122325, 'Total loss': 0.5895966358122325}
2022-11-28 05:35:12,512 INFO:     Found new best model at epoch 1
2022-11-28 05:35:12,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:12,513 INFO:     Epoch: 2
2022-11-28 05:35:13,184 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5460717356340452, 'Total loss': 0.5460717356340452} | train loss {'Reaction outcome loss': 0.541764507851293, 'Total loss': 0.541764507851293}
2022-11-28 05:35:13,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:13,184 INFO:     Epoch: 3
2022-11-28 05:35:13,856 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4776105396449566, 'Total loss': 0.4776105396449566} | train loss {'Reaction outcome loss': 0.5155912936935502, 'Total loss': 0.5155912936935502}
2022-11-28 05:35:13,856 INFO:     Found new best model at epoch 3
2022-11-28 05:35:13,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:13,857 INFO:     Epoch: 4
2022-11-28 05:35:14,528 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5049171078611504, 'Total loss': 0.5049171078611504} | train loss {'Reaction outcome loss': 0.5052453976485037, 'Total loss': 0.5052453976485037}
2022-11-28 05:35:14,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:14,528 INFO:     Epoch: 5
2022-11-28 05:35:15,199 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.569520830092105, 'Total loss': 0.569520830092105} | train loss {'Reaction outcome loss': 0.4996105588732227, 'Total loss': 0.4996105588732227}
2022-11-28 05:35:15,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:15,200 INFO:     Epoch: 6
2022-11-28 05:35:15,868 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4878151474351233, 'Total loss': 0.4878151474351233} | train loss {'Reaction outcome loss': 0.4931421213212513, 'Total loss': 0.4931421213212513}
2022-11-28 05:35:15,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:15,868 INFO:     Epoch: 7
2022-11-28 05:35:16,538 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.505959729579362, 'Total loss': 0.505959729579362} | train loss {'Reaction outcome loss': 0.4856182259898032, 'Total loss': 0.4856182259898032}
2022-11-28 05:35:16,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:16,538 INFO:     Epoch: 8
2022-11-28 05:35:17,205 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4901785620234229, 'Total loss': 0.4901785620234229} | train loss {'Reaction outcome loss': 0.48956989677202317, 'Total loss': 0.48956989677202317}
2022-11-28 05:35:17,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:17,205 INFO:     Epoch: 9
2022-11-28 05:35:17,873 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4722770435566252, 'Total loss': 0.4722770435566252} | train loss {'Reaction outcome loss': 0.4880162433030144, 'Total loss': 0.4880162433030144}
2022-11-28 05:35:17,874 INFO:     Found new best model at epoch 9
2022-11-28 05:35:17,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:17,874 INFO:     Epoch: 10
2022-11-28 05:35:18,547 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4638150693340735, 'Total loss': 0.4638150693340735} | train loss {'Reaction outcome loss': 0.4810665513298685, 'Total loss': 0.4810665513298685}
2022-11-28 05:35:18,547 INFO:     Found new best model at epoch 10
2022-11-28 05:35:18,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:18,548 INFO:     Epoch: 11
2022-11-28 05:35:19,218 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47497193549167027, 'Total loss': 0.47497193549167027} | train loss {'Reaction outcome loss': 0.47553708151944224, 'Total loss': 0.47553708151944224}
2022-11-28 05:35:19,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:19,218 INFO:     Epoch: 12
2022-11-28 05:35:19,890 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48342766849832103, 'Total loss': 0.48342766849832103} | train loss {'Reaction outcome loss': 0.47548781173123467, 'Total loss': 0.47548781173123467}
2022-11-28 05:35:19,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:19,891 INFO:     Epoch: 13
2022-11-28 05:35:20,557 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47549623691222886, 'Total loss': 0.47549623691222886} | train loss {'Reaction outcome loss': 0.4792162233723267, 'Total loss': 0.4792162233723267}
2022-11-28 05:35:20,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:20,557 INFO:     Epoch: 14
2022-11-28 05:35:21,228 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46772578019987454, 'Total loss': 0.46772578019987454} | train loss {'Reaction outcome loss': 0.47506336693561846, 'Total loss': 0.47506336693561846}
2022-11-28 05:35:21,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:21,228 INFO:     Epoch: 15
2022-11-28 05:35:21,896 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4716311611912467, 'Total loss': 0.4716311611912467} | train loss {'Reaction outcome loss': 0.47548670586078395, 'Total loss': 0.47548670586078395}
2022-11-28 05:35:21,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:21,896 INFO:     Epoch: 16
2022-11-28 05:35:22,566 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4709702432155609, 'Total loss': 0.4709702432155609} | train loss {'Reaction outcome loss': 0.4745428343453715, 'Total loss': 0.4745428343453715}
2022-11-28 05:35:22,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:22,567 INFO:     Epoch: 17
2022-11-28 05:35:23,237 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.478213407099247, 'Total loss': 0.478213407099247} | train loss {'Reaction outcome loss': 0.4711233164153753, 'Total loss': 0.4711233164153753}
2022-11-28 05:35:23,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:23,237 INFO:     Epoch: 18
2022-11-28 05:35:23,907 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5099424282935533, 'Total loss': 0.5099424282935533} | train loss {'Reaction outcome loss': 0.47341582263188975, 'Total loss': 0.47341582263188975}
2022-11-28 05:35:23,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:23,908 INFO:     Epoch: 19
2022-11-28 05:35:24,575 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4683248590339314, 'Total loss': 0.4683248590339314} | train loss {'Reaction outcome loss': 0.47028177321678205, 'Total loss': 0.47028177321678205}
2022-11-28 05:35:24,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:24,576 INFO:     Epoch: 20
2022-11-28 05:35:25,246 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4521739421920343, 'Total loss': 0.4521739421920343} | train loss {'Reaction outcome loss': 0.4730148949930745, 'Total loss': 0.4730148949930745}
2022-11-28 05:35:25,246 INFO:     Found new best model at epoch 20
2022-11-28 05:35:25,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:25,247 INFO:     Epoch: 21
2022-11-28 05:35:25,921 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4641518477689136, 'Total loss': 0.4641518477689136} | train loss {'Reaction outcome loss': 0.47303555725562957, 'Total loss': 0.47303555725562957}
2022-11-28 05:35:25,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:25,922 INFO:     Epoch: 22
2022-11-28 05:35:26,592 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46535546671260486, 'Total loss': 0.46535546671260486} | train loss {'Reaction outcome loss': 0.474193251120948, 'Total loss': 0.474193251120948}
2022-11-28 05:35:26,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:26,592 INFO:     Epoch: 23
2022-11-28 05:35:27,266 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4805207912894813, 'Total loss': 0.4805207912894813} | train loss {'Reaction outcome loss': 0.47160907059667573, 'Total loss': 0.47160907059667573}
2022-11-28 05:35:27,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:27,266 INFO:     Epoch: 24
2022-11-28 05:35:27,937 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46410050378604367, 'Total loss': 0.46410050378604367} | train loss {'Reaction outcome loss': 0.47210756587165015, 'Total loss': 0.47210756587165015}
2022-11-28 05:35:27,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:27,937 INFO:     Epoch: 25
2022-11-28 05:35:28,608 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4741665338250724, 'Total loss': 0.4741665338250724} | train loss {'Reaction outcome loss': 0.46709841573911326, 'Total loss': 0.46709841573911326}
2022-11-28 05:35:28,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:28,608 INFO:     Epoch: 26
2022-11-28 05:35:29,279 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4563556242395531, 'Total loss': 0.4563556242395531} | train loss {'Reaction outcome loss': 0.4741856603612823, 'Total loss': 0.4741856603612823}
2022-11-28 05:35:29,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:29,279 INFO:     Epoch: 27
2022-11-28 05:35:29,949 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4755528887564486, 'Total loss': 0.4755528887564486} | train loss {'Reaction outcome loss': 0.47008161457075226, 'Total loss': 0.47008161457075226}
2022-11-28 05:35:29,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:29,949 INFO:     Epoch: 28
2022-11-28 05:35:30,622 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48371749608354137, 'Total loss': 0.48371749608354137} | train loss {'Reaction outcome loss': 0.468227582232606, 'Total loss': 0.468227582232606}
2022-11-28 05:35:30,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:30,622 INFO:     Epoch: 29
2022-11-28 05:35:31,293 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4648225043307651, 'Total loss': 0.4648225043307651} | train loss {'Reaction outcome loss': 0.46529802686024097, 'Total loss': 0.46529802686024097}
2022-11-28 05:35:31,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:31,294 INFO:     Epoch: 30
2022-11-28 05:35:31,967 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4860854975201867, 'Total loss': 0.4860854975201867} | train loss {'Reaction outcome loss': 0.4747888702418535, 'Total loss': 0.4747888702418535}
2022-11-28 05:35:31,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:31,967 INFO:     Epoch: 31
2022-11-28 05:35:32,638 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4607966992665421, 'Total loss': 0.4607966992665421} | train loss {'Reaction outcome loss': 0.4682240000054721, 'Total loss': 0.4682240000054721}
2022-11-28 05:35:32,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:32,638 INFO:     Epoch: 32
2022-11-28 05:35:33,307 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4479846277020194, 'Total loss': 0.4479846277020194} | train loss {'Reaction outcome loss': 0.47055251607971804, 'Total loss': 0.47055251607971804}
2022-11-28 05:35:33,308 INFO:     Found new best model at epoch 32
2022-11-28 05:35:33,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:33,308 INFO:     Epoch: 33
2022-11-28 05:35:33,977 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46250623803247104, 'Total loss': 0.46250623803247104} | train loss {'Reaction outcome loss': 0.47357663926818677, 'Total loss': 0.47357663926818677}
2022-11-28 05:35:33,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:33,977 INFO:     Epoch: 34
2022-11-28 05:35:34,648 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47498645091598685, 'Total loss': 0.47498645091598685} | train loss {'Reaction outcome loss': 0.4690256941342546, 'Total loss': 0.4690256941342546}
2022-11-28 05:35:34,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:34,648 INFO:     Epoch: 35
2022-11-28 05:35:35,320 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4572511769153855, 'Total loss': 0.4572511769153855} | train loss {'Reaction outcome loss': 0.472117381530904, 'Total loss': 0.472117381530904}
2022-11-28 05:35:35,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:35,320 INFO:     Epoch: 36
2022-11-28 05:35:35,993 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45619314299388364, 'Total loss': 0.45619314299388364} | train loss {'Reaction outcome loss': 0.47051922439206995, 'Total loss': 0.47051922439206995}
2022-11-28 05:35:35,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:35,994 INFO:     Epoch: 37
2022-11-28 05:35:36,667 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4991244670342315, 'Total loss': 0.4991244670342315} | train loss {'Reaction outcome loss': 0.4679928904459361, 'Total loss': 0.4679928904459361}
2022-11-28 05:35:36,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:36,668 INFO:     Epoch: 38
2022-11-28 05:35:37,342 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4815890294584361, 'Total loss': 0.4815890294584361} | train loss {'Reaction outcome loss': 0.46890849644137966, 'Total loss': 0.46890849644137966}
2022-11-28 05:35:37,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:37,343 INFO:     Epoch: 39
2022-11-28 05:35:38,014 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4692020744762637, 'Total loss': 0.4692020744762637} | train loss {'Reaction outcome loss': 0.47035414443141027, 'Total loss': 0.47035414443141027}
2022-11-28 05:35:38,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:38,014 INFO:     Epoch: 40
2022-11-28 05:35:38,685 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45325452427972446, 'Total loss': 0.45325452427972446} | train loss {'Reaction outcome loss': 0.4641582772376076, 'Total loss': 0.4641582772376076}
2022-11-28 05:35:38,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:38,685 INFO:     Epoch: 41
2022-11-28 05:35:39,357 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4746673811565746, 'Total loss': 0.4746673811565746} | train loss {'Reaction outcome loss': 0.46914438620930715, 'Total loss': 0.46914438620930715}
2022-11-28 05:35:39,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:39,357 INFO:     Epoch: 42
2022-11-28 05:35:40,028 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48263558135791257, 'Total loss': 0.48263558135791257} | train loss {'Reaction outcome loss': 0.45851438973219166, 'Total loss': 0.45851438973219166}
2022-11-28 05:35:40,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:40,028 INFO:     Epoch: 43
2022-11-28 05:35:40,699 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47767073728821496, 'Total loss': 0.47767073728821496} | train loss {'Reaction outcome loss': 0.46577804139064205, 'Total loss': 0.46577804139064205}
2022-11-28 05:35:40,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:40,699 INFO:     Epoch: 44
2022-11-28 05:35:41,372 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4719204479320483, 'Total loss': 0.4719204479320483} | train loss {'Reaction outcome loss': 0.470777231959566, 'Total loss': 0.470777231959566}
2022-11-28 05:35:41,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:41,372 INFO:     Epoch: 45
2022-11-28 05:35:42,039 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44988710805773735, 'Total loss': 0.44988710805773735} | train loss {'Reaction outcome loss': 0.4645354775111041, 'Total loss': 0.4645354775111041}
2022-11-28 05:35:42,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:42,040 INFO:     Epoch: 46
2022-11-28 05:35:42,709 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47471454265442764, 'Total loss': 0.47471454265442764} | train loss {'Reaction outcome loss': 0.46512189303194323, 'Total loss': 0.46512189303194323}
2022-11-28 05:35:42,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:42,709 INFO:     Epoch: 47
2022-11-28 05:35:43,374 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46411679820580914, 'Total loss': 0.46411679820580914} | train loss {'Reaction outcome loss': 0.45740802640155437, 'Total loss': 0.45740802640155437}
2022-11-28 05:35:43,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:43,375 INFO:     Epoch: 48
2022-11-28 05:35:44,041 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46787243675101886, 'Total loss': 0.46787243675101886} | train loss {'Reaction outcome loss': 0.4649102963627346, 'Total loss': 0.4649102963627346}
2022-11-28 05:35:44,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:44,041 INFO:     Epoch: 49
2022-11-28 05:35:44,705 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4599784395911477, 'Total loss': 0.4599784395911477} | train loss {'Reaction outcome loss': 0.4663114895323111, 'Total loss': 0.4663114895323111}
2022-11-28 05:35:44,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:44,705 INFO:     Epoch: 50
2022-11-28 05:35:45,371 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45360110903328116, 'Total loss': 0.45360110903328116} | train loss {'Reaction outcome loss': 0.4648722322477448, 'Total loss': 0.4648722322477448}
2022-11-28 05:35:45,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:45,371 INFO:     Epoch: 51
2022-11-28 05:35:46,036 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45899673856117507, 'Total loss': 0.45899673856117507} | train loss {'Reaction outcome loss': 0.46804103285314574, 'Total loss': 0.46804103285314574}
2022-11-28 05:35:46,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:46,036 INFO:     Epoch: 52
2022-11-28 05:35:46,702 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46251815828410064, 'Total loss': 0.46251815828410064} | train loss {'Reaction outcome loss': 0.46717257959948433, 'Total loss': 0.46717257959948433}
2022-11-28 05:35:46,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:46,702 INFO:     Epoch: 53
2022-11-28 05:35:47,367 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.482269151982936, 'Total loss': 0.482269151982936} | train loss {'Reaction outcome loss': 0.4636479429299793, 'Total loss': 0.4636479429299793}
2022-11-28 05:35:47,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:47,367 INFO:     Epoch: 54
2022-11-28 05:35:48,031 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45911620455709373, 'Total loss': 0.45911620455709373} | train loss {'Reaction outcome loss': 0.4662746991361341, 'Total loss': 0.4662746991361341}
2022-11-28 05:35:48,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:48,031 INFO:     Epoch: 55
2022-11-28 05:35:48,697 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4688481708819216, 'Total loss': 0.4688481708819216} | train loss {'Reaction outcome loss': 0.4684032060566448, 'Total loss': 0.4684032060566448}
2022-11-28 05:35:48,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:48,697 INFO:     Epoch: 56
2022-11-28 05:35:49,361 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46605389700694516, 'Total loss': 0.46605389700694516} | train loss {'Reaction outcome loss': 0.46577392022816405, 'Total loss': 0.46577392022816405}
2022-11-28 05:35:49,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:49,362 INFO:     Epoch: 57
2022-11-28 05:35:50,027 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4776937456970865, 'Total loss': 0.4776937456970865} | train loss {'Reaction outcome loss': 0.4665603840783719, 'Total loss': 0.4665603840783719}
2022-11-28 05:35:50,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:50,027 INFO:     Epoch: 58
2022-11-28 05:35:50,690 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4621143056587739, 'Total loss': 0.4621143056587739} | train loss {'Reaction outcome loss': 0.46495877915332395, 'Total loss': 0.46495877915332395}
2022-11-28 05:35:50,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:50,690 INFO:     Epoch: 59
2022-11-28 05:35:51,357 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44122109680690547, 'Total loss': 0.44122109680690547} | train loss {'Reaction outcome loss': 0.4694201318967727, 'Total loss': 0.4694201318967727}
2022-11-28 05:35:51,358 INFO:     Found new best model at epoch 59
2022-11-28 05:35:51,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:51,358 INFO:     Epoch: 60
2022-11-28 05:35:52,023 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44795581021092157, 'Total loss': 0.44795581021092157} | train loss {'Reaction outcome loss': 0.4626845974595316, 'Total loss': 0.4626845974595316}
2022-11-28 05:35:52,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:52,024 INFO:     Epoch: 61
2022-11-28 05:35:52,691 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.485334787517786, 'Total loss': 0.485334787517786} | train loss {'Reaction outcome loss': 0.46333792042588035, 'Total loss': 0.46333792042588035}
2022-11-28 05:35:52,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:52,691 INFO:     Epoch: 62
2022-11-28 05:35:53,358 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48822811686179857, 'Total loss': 0.48822811686179857} | train loss {'Reaction outcome loss': 0.4650455256924033, 'Total loss': 0.4650455256924033}
2022-11-28 05:35:53,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:53,359 INFO:     Epoch: 63
2022-11-28 05:35:54,029 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4682241231203079, 'Total loss': 0.4682241231203079} | train loss {'Reaction outcome loss': 0.46358008935086187, 'Total loss': 0.46358008935086187}
2022-11-28 05:35:54,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:54,029 INFO:     Epoch: 64
2022-11-28 05:35:54,695 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4753634055907076, 'Total loss': 0.4753634055907076} | train loss {'Reaction outcome loss': 0.4654615490787452, 'Total loss': 0.4654615490787452}
2022-11-28 05:35:54,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:54,696 INFO:     Epoch: 65
2022-11-28 05:35:55,361 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46378457884896884, 'Total loss': 0.46378457884896884} | train loss {'Reaction outcome loss': 0.4724079269855734, 'Total loss': 0.4724079269855734}
2022-11-28 05:35:55,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:55,361 INFO:     Epoch: 66
2022-11-28 05:35:56,033 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47145943479104474, 'Total loss': 0.47145943479104474} | train loss {'Reaction outcome loss': 0.46461432829739585, 'Total loss': 0.46461432829739585}
2022-11-28 05:35:56,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:56,034 INFO:     Epoch: 67
2022-11-28 05:35:56,705 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47767347673123534, 'Total loss': 0.47767347673123534} | train loss {'Reaction outcome loss': 0.46958446544745275, 'Total loss': 0.46958446544745275}
2022-11-28 05:35:56,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:56,706 INFO:     Epoch: 68
2022-11-28 05:35:57,375 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45170272344892676, 'Total loss': 0.45170272344892676} | train loss {'Reaction outcome loss': 0.4596651105750953, 'Total loss': 0.4596651105750953}
2022-11-28 05:35:57,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:57,375 INFO:     Epoch: 69
2022-11-28 05:35:58,045 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4527116377245296, 'Total loss': 0.4527116377245296} | train loss {'Reaction outcome loss': 0.4677056471907323, 'Total loss': 0.4677056471907323}
2022-11-28 05:35:58,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:58,045 INFO:     Epoch: 70
2022-11-28 05:35:58,715 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4463027559898116, 'Total loss': 0.4463027559898116} | train loss {'Reaction outcome loss': 0.46659608702025107, 'Total loss': 0.46659608702025107}
2022-11-28 05:35:58,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:58,715 INFO:     Epoch: 71
2022-11-28 05:35:59,382 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46842841973358934, 'Total loss': 0.46842841973358934} | train loss {'Reaction outcome loss': 0.46108771926693376, 'Total loss': 0.46108771926693376}
2022-11-28 05:35:59,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:35:59,382 INFO:     Epoch: 72
2022-11-28 05:36:00,050 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45012382384050975, 'Total loss': 0.45012382384050975} | train loss {'Reaction outcome loss': 0.46772231275756515, 'Total loss': 0.46772231275756515}
2022-11-28 05:36:00,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:00,050 INFO:     Epoch: 73
2022-11-28 05:36:00,716 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48440823365341534, 'Total loss': 0.48440823365341534} | train loss {'Reaction outcome loss': 0.4617507183744061, 'Total loss': 0.4617507183744061}
2022-11-28 05:36:00,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:00,716 INFO:     Epoch: 74
2022-11-28 05:36:01,385 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4598021354864944, 'Total loss': 0.4598021354864944} | train loss {'Reaction outcome loss': 0.4622938995880465, 'Total loss': 0.4622938995880465}
2022-11-28 05:36:01,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:01,386 INFO:     Epoch: 75
2022-11-28 05:36:02,055 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4601805013689128, 'Total loss': 0.4601805013689128} | train loss {'Reaction outcome loss': 0.46395329313893474, 'Total loss': 0.46395329313893474}
2022-11-28 05:36:02,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:02,055 INFO:     Epoch: 76
2022-11-28 05:36:02,721 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45591914789243176, 'Total loss': 0.45591914789243176} | train loss {'Reaction outcome loss': 0.4621271642465745, 'Total loss': 0.4621271642465745}
2022-11-28 05:36:02,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:02,721 INFO:     Epoch: 77
2022-11-28 05:36:03,391 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4576631168072874, 'Total loss': 0.4576631168072874} | train loss {'Reaction outcome loss': 0.4613759809684369, 'Total loss': 0.4613759809684369}
2022-11-28 05:36:03,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:03,391 INFO:     Epoch: 78
2022-11-28 05:36:04,062 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4488267989998514, 'Total loss': 0.4488267989998514} | train loss {'Reaction outcome loss': 0.4627923044946886, 'Total loss': 0.4627923044946886}
2022-11-28 05:36:04,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:04,062 INFO:     Epoch: 79
2022-11-28 05:36:04,727 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4549214514819058, 'Total loss': 0.4549214514819058} | train loss {'Reaction outcome loss': 0.46378012554299447, 'Total loss': 0.46378012554299447}
2022-11-28 05:36:04,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:04,727 INFO:     Epoch: 80
2022-11-28 05:36:05,399 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4790880923921412, 'Total loss': 0.4790880923921412} | train loss {'Reaction outcome loss': 0.46318987210191065, 'Total loss': 0.46318987210191065}
2022-11-28 05:36:05,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:05,399 INFO:     Epoch: 81
2022-11-28 05:36:06,070 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4531956098296426, 'Total loss': 0.4531956098296426} | train loss {'Reaction outcome loss': 0.4640955403447151, 'Total loss': 0.4640955403447151}
2022-11-28 05:36:06,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:06,070 INFO:     Epoch: 82
2022-11-28 05:36:06,742 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49323002181269904, 'Total loss': 0.49323002181269904} | train loss {'Reaction outcome loss': 0.4659201945929277, 'Total loss': 0.4659201945929277}
2022-11-28 05:36:06,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:06,743 INFO:     Epoch: 83
2022-11-28 05:36:07,410 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4516310607167808, 'Total loss': 0.4516310607167808} | train loss {'Reaction outcome loss': 0.46314119148038085, 'Total loss': 0.46314119148038085}
2022-11-28 05:36:07,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:07,410 INFO:     Epoch: 84
2022-11-28 05:36:08,077 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45362687043168326, 'Total loss': 0.45362687043168326} | train loss {'Reaction outcome loss': 0.46435941899976424, 'Total loss': 0.46435941899976424}
2022-11-28 05:36:08,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:08,078 INFO:     Epoch: 85
2022-11-28 05:36:08,743 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4739279625090686, 'Total loss': 0.4739279625090686} | train loss {'Reaction outcome loss': 0.4598794466545505, 'Total loss': 0.4598794466545505}
2022-11-28 05:36:08,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:08,744 INFO:     Epoch: 86
2022-11-28 05:36:09,407 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49577672305432235, 'Total loss': 0.49577672305432235} | train loss {'Reaction outcome loss': 0.46300669531187705, 'Total loss': 0.46300669531187705}
2022-11-28 05:36:09,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:09,407 INFO:     Epoch: 87
2022-11-28 05:36:10,073 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4607016268101605, 'Total loss': 0.4607016268101605} | train loss {'Reaction outcome loss': 0.4669076761591338, 'Total loss': 0.4669076761591338}
2022-11-28 05:36:10,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:10,073 INFO:     Epoch: 88
2022-11-28 05:36:10,739 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4891857626763257, 'Total loss': 0.4891857626763257} | train loss {'Reaction outcome loss': 0.46283406980576053, 'Total loss': 0.46283406980576053}
2022-11-28 05:36:10,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:10,739 INFO:     Epoch: 89
2022-11-28 05:36:11,406 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4869299300692298, 'Total loss': 0.4869299300692298} | train loss {'Reaction outcome loss': 0.46503540296708384, 'Total loss': 0.46503540296708384}
2022-11-28 05:36:11,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:11,407 INFO:     Epoch: 90
2022-11-28 05:36:12,071 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44609640775756404, 'Total loss': 0.44609640775756404} | train loss {'Reaction outcome loss': 0.4699245192591221, 'Total loss': 0.4699245192591221}
2022-11-28 05:36:12,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:12,071 INFO:     Epoch: 91
2022-11-28 05:36:12,743 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.452391732822765, 'Total loss': 0.452391732822765} | train loss {'Reaction outcome loss': 0.46022334094009093, 'Total loss': 0.46022334094009093}
2022-11-28 05:36:12,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:12,744 INFO:     Epoch: 92
2022-11-28 05:36:13,411 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4637868810783733, 'Total loss': 0.4637868810783733} | train loss {'Reaction outcome loss': 0.46683324068304033, 'Total loss': 0.46683324068304033}
2022-11-28 05:36:13,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:13,411 INFO:     Epoch: 93
2022-11-28 05:36:14,080 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47041247988289053, 'Total loss': 0.47041247988289053} | train loss {'Reaction outcome loss': 0.46243989728992024, 'Total loss': 0.46243989728992024}
2022-11-28 05:36:14,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:14,080 INFO:     Epoch: 94
2022-11-28 05:36:14,752 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4941909143870527, 'Total loss': 0.4941909143870527} | train loss {'Reaction outcome loss': 0.4666198387501701, 'Total loss': 0.4666198387501701}
2022-11-28 05:36:14,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:14,753 INFO:     Epoch: 95
2022-11-28 05:36:15,421 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44887127388607373, 'Total loss': 0.44887127388607373} | train loss {'Reaction outcome loss': 0.469433824802118, 'Total loss': 0.469433824802118}
2022-11-28 05:36:15,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:15,421 INFO:     Epoch: 96
2022-11-28 05:36:16,087 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46342000128193334, 'Total loss': 0.46342000128193334} | train loss {'Reaction outcome loss': 0.46114287952021243, 'Total loss': 0.46114287952021243}
2022-11-28 05:36:16,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:16,088 INFO:     Epoch: 97
2022-11-28 05:36:16,758 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4631190530278466, 'Total loss': 0.4631190530278466} | train loss {'Reaction outcome loss': 0.46739626237221304, 'Total loss': 0.46739626237221304}
2022-11-28 05:36:16,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:16,758 INFO:     Epoch: 98
2022-11-28 05:36:17,428 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4687492156570608, 'Total loss': 0.4687492156570608} | train loss {'Reaction outcome loss': 0.46736289299423656, 'Total loss': 0.46736289299423656}
2022-11-28 05:36:17,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:17,429 INFO:     Epoch: 99
2022-11-28 05:36:18,095 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4615447714247487, 'Total loss': 0.4615447714247487} | train loss {'Reaction outcome loss': 0.4657156064265197, 'Total loss': 0.4657156064265197}
2022-11-28 05:36:18,095 INFO:     Best model found after epoch 60 of 100.
2022-11-28 05:36:18,096 INFO:   Done with stage: TRAINING
2022-11-28 05:36:18,096 INFO:   Starting stage: EVALUATION
2022-11-28 05:36:18,208 INFO:   Done with stage: EVALUATION
2022-11-28 05:36:18,208 INFO:   Leaving out SEQ value Fold_7
2022-11-28 05:36:18,221 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 05:36:18,221 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:36:18,868 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:36:18,868 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:36:18,940 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:36:18,940 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:36:18,940 INFO:     No hyperparam tuning for this model
2022-11-28 05:36:18,940 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:36:18,940 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:36:18,941 INFO:     None feature selector for col prot
2022-11-28 05:36:18,941 INFO:     None feature selector for col prot
2022-11-28 05:36:18,941 INFO:     None feature selector for col prot
2022-11-28 05:36:18,942 INFO:     None feature selector for col chem
2022-11-28 05:36:18,942 INFO:     None feature selector for col chem
2022-11-28 05:36:18,942 INFO:     None feature selector for col chem
2022-11-28 05:36:18,942 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:36:18,942 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:36:18,944 INFO:     Number of params in model 169651
2022-11-28 05:36:18,947 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:36:18,947 INFO:   Starting stage: TRAINING
2022-11-28 05:36:18,998 INFO:     Val loss before train {'Reaction outcome loss': 1.0273385914889248, 'Total loss': 1.0273385914889248}
2022-11-28 05:36:18,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:18,998 INFO:     Epoch: 0
2022-11-28 05:36:19,665 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6221961165693674, 'Total loss': 0.6221961165693674} | train loss {'Reaction outcome loss': 0.6853329232226499, 'Total loss': 0.6853329232226499}
2022-11-28 05:36:19,665 INFO:     Found new best model at epoch 0
2022-11-28 05:36:19,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:19,666 INFO:     Epoch: 1
2022-11-28 05:36:20,334 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5671023936434225, 'Total loss': 0.5671023936434225} | train loss {'Reaction outcome loss': 0.5825839499350984, 'Total loss': 0.5825839499350984}
2022-11-28 05:36:20,334 INFO:     Found new best model at epoch 1
2022-11-28 05:36:20,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:20,335 INFO:     Epoch: 2
2022-11-28 05:36:21,003 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.639739375222813, 'Total loss': 0.639739375222813} | train loss {'Reaction outcome loss': 0.5603130038088633, 'Total loss': 0.5603130038088633}
2022-11-28 05:36:21,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:21,003 INFO:     Epoch: 3
2022-11-28 05:36:21,668 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5332125682722438, 'Total loss': 0.5332125682722438} | train loss {'Reaction outcome loss': 0.5460264906588836, 'Total loss': 0.5460264906588836}
2022-11-28 05:36:21,668 INFO:     Found new best model at epoch 3
2022-11-28 05:36:21,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:21,669 INFO:     Epoch: 4
2022-11-28 05:36:22,333 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5282518206672235, 'Total loss': 0.5282518206672235} | train loss {'Reaction outcome loss': 0.5157324259399403, 'Total loss': 0.5157324259399403}
2022-11-28 05:36:22,333 INFO:     Found new best model at epoch 4
2022-11-28 05:36:22,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:22,334 INFO:     Epoch: 5
2022-11-28 05:36:23,000 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5392766784537922, 'Total loss': 0.5392766784537922} | train loss {'Reaction outcome loss': 0.5136801547140848, 'Total loss': 0.5136801547140848}
2022-11-28 05:36:23,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:23,001 INFO:     Epoch: 6
2022-11-28 05:36:23,666 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5142212455922907, 'Total loss': 0.5142212455922907} | train loss {'Reaction outcome loss': 0.4951722972766168, 'Total loss': 0.4951722972766168}
2022-11-28 05:36:23,666 INFO:     Found new best model at epoch 6
2022-11-28 05:36:23,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:23,667 INFO:     Epoch: 7
2022-11-28 05:36:24,333 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5306172286244956, 'Total loss': 0.5306172286244956} | train loss {'Reaction outcome loss': 0.4910159667855815, 'Total loss': 0.4910159667855815}
2022-11-28 05:36:24,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:24,333 INFO:     Epoch: 8
2022-11-28 05:36:24,999 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5064282857558944, 'Total loss': 0.5064282857558944} | train loss {'Reaction outcome loss': 0.4915901249357563, 'Total loss': 0.4915901249357563}
2022-11-28 05:36:24,999 INFO:     Found new best model at epoch 8
2022-11-28 05:36:25,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:25,000 INFO:     Epoch: 9
2022-11-28 05:36:25,665 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5212421735579317, 'Total loss': 0.5212421735579317} | train loss {'Reaction outcome loss': 0.49407185427090416, 'Total loss': 0.49407185427090416}
2022-11-28 05:36:25,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:25,665 INFO:     Epoch: 10
2022-11-28 05:36:26,328 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5068377310579474, 'Total loss': 0.5068377310579474} | train loss {'Reaction outcome loss': 0.5001959294563363, 'Total loss': 0.5001959294563363}
2022-11-28 05:36:26,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:26,328 INFO:     Epoch: 11
2022-11-28 05:36:26,988 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5145941065116362, 'Total loss': 0.5145941065116362} | train loss {'Reaction outcome loss': 0.49517818929454094, 'Total loss': 0.49517818929454094}
2022-11-28 05:36:26,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:26,989 INFO:     Epoch: 12
2022-11-28 05:36:27,654 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5292779410427267, 'Total loss': 0.5292779410427267} | train loss {'Reaction outcome loss': 0.491980478589834, 'Total loss': 0.491980478589834}
2022-11-28 05:36:27,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:27,655 INFO:     Epoch: 13
2022-11-28 05:36:28,320 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4866054809906266, 'Total loss': 0.4866054809906266} | train loss {'Reaction outcome loss': 0.49122787987896305, 'Total loss': 0.49122787987896305}
2022-11-28 05:36:28,320 INFO:     Found new best model at epoch 13
2022-11-28 05:36:28,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:28,321 INFO:     Epoch: 14
2022-11-28 05:36:28,989 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48685700277035887, 'Total loss': 0.48685700277035887} | train loss {'Reaction outcome loss': 0.48751688673187366, 'Total loss': 0.48751688673187366}
2022-11-28 05:36:28,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:28,989 INFO:     Epoch: 15
2022-11-28 05:36:29,655 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49712447889826517, 'Total loss': 0.49712447889826517} | train loss {'Reaction outcome loss': 0.4825586704952031, 'Total loss': 0.4825586704952031}
2022-11-28 05:36:29,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:29,655 INFO:     Epoch: 16
2022-11-28 05:36:30,321 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48392886973240157, 'Total loss': 0.48392886973240157} | train loss {'Reaction outcome loss': 0.4739396347577574, 'Total loss': 0.4739396347577574}
2022-11-28 05:36:30,321 INFO:     Found new best model at epoch 16
2022-11-28 05:36:30,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:30,322 INFO:     Epoch: 17
2022-11-28 05:36:30,989 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5182519074190747, 'Total loss': 0.5182519074190747} | train loss {'Reaction outcome loss': 0.4807620521499078, 'Total loss': 0.4807620521499078}
2022-11-28 05:36:30,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:30,989 INFO:     Epoch: 18
2022-11-28 05:36:31,655 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5088985535231504, 'Total loss': 0.5088985535231504} | train loss {'Reaction outcome loss': 0.4775551375951844, 'Total loss': 0.4775551375951844}
2022-11-28 05:36:31,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:31,656 INFO:     Epoch: 19
2022-11-28 05:36:32,323 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4745032340288162, 'Total loss': 0.4745032340288162} | train loss {'Reaction outcome loss': 0.47828529835471256, 'Total loss': 0.47828529835471256}
2022-11-28 05:36:32,323 INFO:     Found new best model at epoch 19
2022-11-28 05:36:32,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:32,324 INFO:     Epoch: 20
2022-11-28 05:36:32,991 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4781170568682931, 'Total loss': 0.4781170568682931} | train loss {'Reaction outcome loss': 0.4667888716888814, 'Total loss': 0.4667888716888814}
2022-11-28 05:36:32,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:32,991 INFO:     Epoch: 21
2022-11-28 05:36:33,656 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4720261117274111, 'Total loss': 0.4720261117274111} | train loss {'Reaction outcome loss': 0.46651710491431386, 'Total loss': 0.46651710491431386}
2022-11-28 05:36:33,656 INFO:     Found new best model at epoch 21
2022-11-28 05:36:33,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:33,657 INFO:     Epoch: 22
2022-11-28 05:36:34,319 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46978501484475355, 'Total loss': 0.46978501484475355} | train loss {'Reaction outcome loss': 0.46734081934157173, 'Total loss': 0.46734081934157173}
2022-11-28 05:36:34,319 INFO:     Found new best model at epoch 22
2022-11-28 05:36:34,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:34,320 INFO:     Epoch: 23
2022-11-28 05:36:34,986 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5062802701511167, 'Total loss': 0.5062802701511167} | train loss {'Reaction outcome loss': 0.47029940844306095, 'Total loss': 0.47029940844306095}
2022-11-28 05:36:34,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:34,986 INFO:     Epoch: 24
2022-11-28 05:36:35,654 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5119436572898518, 'Total loss': 0.5119436572898518} | train loss {'Reaction outcome loss': 0.4697940946228591, 'Total loss': 0.4697940946228591}
2022-11-28 05:36:35,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:35,654 INFO:     Epoch: 25
2022-11-28 05:36:36,319 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4630889811299064, 'Total loss': 0.4630889811299064} | train loss {'Reaction outcome loss': 0.46835407916350885, 'Total loss': 0.46835407916350885}
2022-11-28 05:36:36,319 INFO:     Found new best model at epoch 25
2022-11-28 05:36:36,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:36,320 INFO:     Epoch: 26
2022-11-28 05:36:36,985 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5015762488950383, 'Total loss': 0.5015762488950383} | train loss {'Reaction outcome loss': 0.4766396970642723, 'Total loss': 0.4766396970642723}
2022-11-28 05:36:36,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:36,986 INFO:     Epoch: 27
2022-11-28 05:36:37,651 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49088581414385274, 'Total loss': 0.49088581414385274} | train loss {'Reaction outcome loss': 0.4860605228888361, 'Total loss': 0.4860605228888361}
2022-11-28 05:36:37,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:37,651 INFO:     Epoch: 28
2022-11-28 05:36:38,313 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4630340717055581, 'Total loss': 0.4630340717055581} | train loss {'Reaction outcome loss': 0.4747768087606681, 'Total loss': 0.4747768087606681}
2022-11-28 05:36:38,313 INFO:     Found new best model at epoch 28
2022-11-28 05:36:38,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:38,314 INFO:     Epoch: 29
2022-11-28 05:36:38,978 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47750209949233313, 'Total loss': 0.47750209949233313} | train loss {'Reaction outcome loss': 0.47801213967896666, 'Total loss': 0.47801213967896666}
2022-11-28 05:36:38,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:38,978 INFO:     Epoch: 30
2022-11-28 05:36:39,644 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4812504974278537, 'Total loss': 0.4812504974278537} | train loss {'Reaction outcome loss': 0.48228629301434106, 'Total loss': 0.48228629301434106}
2022-11-28 05:36:39,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:39,644 INFO:     Epoch: 31
2022-11-28 05:36:40,310 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5103306191211398, 'Total loss': 0.5103306191211398} | train loss {'Reaction outcome loss': 0.4835252837251555, 'Total loss': 0.4835252837251555}
2022-11-28 05:36:40,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:40,311 INFO:     Epoch: 32
2022-11-28 05:36:40,981 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4731015754355626, 'Total loss': 0.4731015754355626} | train loss {'Reaction outcome loss': 0.4643263721665149, 'Total loss': 0.4643263721665149}
2022-11-28 05:36:40,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:40,982 INFO:     Epoch: 33
2022-11-28 05:36:41,649 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4877954911101948, 'Total loss': 0.4877954911101948} | train loss {'Reaction outcome loss': 0.4672677723261026, 'Total loss': 0.4672677723261026}
2022-11-28 05:36:41,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:41,649 INFO:     Epoch: 34
2022-11-28 05:36:42,322 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.49840912832455203, 'Total loss': 0.49840912832455203} | train loss {'Reaction outcome loss': 0.47645278389637286, 'Total loss': 0.47645278389637286}
2022-11-28 05:36:42,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:42,323 INFO:     Epoch: 35
2022-11-28 05:36:42,989 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47680774466557935, 'Total loss': 0.47680774466557935} | train loss {'Reaction outcome loss': 0.47805392440514044, 'Total loss': 0.47805392440514044}
2022-11-28 05:36:42,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:42,989 INFO:     Epoch: 36
2022-11-28 05:36:43,653 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4673278206451373, 'Total loss': 0.4673278206451373} | train loss {'Reaction outcome loss': 0.4791382146388413, 'Total loss': 0.4791382146388413}
2022-11-28 05:36:43,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:43,653 INFO:     Epoch: 37
2022-11-28 05:36:44,320 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5460497973994776, 'Total loss': 0.5460497973994776} | train loss {'Reaction outcome loss': 0.4726395749671739, 'Total loss': 0.4726395749671739}
2022-11-28 05:36:44,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:44,320 INFO:     Epoch: 38
2022-11-28 05:36:44,983 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47642417082732375, 'Total loss': 0.47642417082732375} | train loss {'Reaction outcome loss': 0.4674641444736164, 'Total loss': 0.4674641444736164}
2022-11-28 05:36:44,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:44,983 INFO:     Epoch: 39
2022-11-28 05:36:45,649 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.509129442951896, 'Total loss': 0.509129442951896} | train loss {'Reaction outcome loss': 0.4697619669350535, 'Total loss': 0.4697619669350535}
2022-11-28 05:36:45,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:45,650 INFO:     Epoch: 40
2022-11-28 05:36:46,317 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4842979125678539, 'Total loss': 0.4842979125678539} | train loss {'Reaction outcome loss': 0.47115995363909224, 'Total loss': 0.47115995363909224}
2022-11-28 05:36:46,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:46,318 INFO:     Epoch: 41
2022-11-28 05:36:46,981 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5303033715621992, 'Total loss': 0.5303033715621992} | train loss {'Reaction outcome loss': 0.47086774241857926, 'Total loss': 0.47086774241857926}
2022-11-28 05:36:46,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:46,981 INFO:     Epoch: 42
2022-11-28 05:36:47,652 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4886065260930495, 'Total loss': 0.4886065260930495} | train loss {'Reaction outcome loss': 0.46853097392668425, 'Total loss': 0.46853097392668425}
2022-11-28 05:36:47,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:47,653 INFO:     Epoch: 43
2022-11-28 05:36:48,320 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48933669653805817, 'Total loss': 0.48933669653805817} | train loss {'Reaction outcome loss': 0.47280609914052646, 'Total loss': 0.47280609914052646}
2022-11-28 05:36:48,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:48,320 INFO:     Epoch: 44
2022-11-28 05:36:48,989 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5337787355211648, 'Total loss': 0.5337787355211648} | train loss {'Reaction outcome loss': 0.4627092334664302, 'Total loss': 0.4627092334664302}
2022-11-28 05:36:48,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:48,989 INFO:     Epoch: 45
2022-11-28 05:36:49,654 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5342095223340121, 'Total loss': 0.5342095223340121} | train loss {'Reaction outcome loss': 0.4689191008808642, 'Total loss': 0.4689191008808642}
2022-11-28 05:36:49,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:49,654 INFO:     Epoch: 46
2022-11-28 05:36:50,320 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5257022042166103, 'Total loss': 0.5257022042166103} | train loss {'Reaction outcome loss': 0.4705628171140848, 'Total loss': 0.4705628171140848}
2022-11-28 05:36:50,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:50,320 INFO:     Epoch: 47
2022-11-28 05:36:50,987 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48479675637050107, 'Total loss': 0.48479675637050107} | train loss {'Reaction outcome loss': 0.4728874817626317, 'Total loss': 0.4728874817626317}
2022-11-28 05:36:50,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:50,987 INFO:     Epoch: 48
2022-11-28 05:36:51,653 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47448076036843384, 'Total loss': 0.47448076036843384} | train loss {'Reaction outcome loss': 0.46612749411630244, 'Total loss': 0.46612749411630244}
2022-11-28 05:36:51,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:51,653 INFO:     Epoch: 49
2022-11-28 05:36:52,317 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46584593470801006, 'Total loss': 0.46584593470801006} | train loss {'Reaction outcome loss': 0.4681894934452459, 'Total loss': 0.4681894934452459}
2022-11-28 05:36:52,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:52,318 INFO:     Epoch: 50
2022-11-28 05:36:52,982 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5162857872518626, 'Total loss': 0.5162857872518626} | train loss {'Reaction outcome loss': 0.4755093772643008, 'Total loss': 0.4755093772643008}
2022-11-28 05:36:52,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:52,983 INFO:     Epoch: 51
2022-11-28 05:36:53,646 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48721176284280693, 'Total loss': 0.48721176284280693} | train loss {'Reaction outcome loss': 0.47254776645466867, 'Total loss': 0.47254776645466867}
2022-11-28 05:36:53,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:53,647 INFO:     Epoch: 52
2022-11-28 05:36:54,309 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48549737374890933, 'Total loss': 0.48549737374890933} | train loss {'Reaction outcome loss': 0.46357178967069035, 'Total loss': 0.46357178967069035}
2022-11-28 05:36:54,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:54,309 INFO:     Epoch: 53
2022-11-28 05:36:54,977 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4939151849936355, 'Total loss': 0.4939151849936355} | train loss {'Reaction outcome loss': 0.4758000027554238, 'Total loss': 0.4758000027554238}
2022-11-28 05:36:54,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:54,978 INFO:     Epoch: 54
2022-11-28 05:36:55,642 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5058180811730298, 'Total loss': 0.5058180811730298} | train loss {'Reaction outcome loss': 0.46884558322699926, 'Total loss': 0.46884558322699926}
2022-11-28 05:36:55,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:55,642 INFO:     Epoch: 55
2022-11-28 05:36:56,308 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4703812897205353, 'Total loss': 0.4703812897205353} | train loss {'Reaction outcome loss': 0.4743434028466221, 'Total loss': 0.4743434028466221}
2022-11-28 05:36:56,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:56,308 INFO:     Epoch: 56
2022-11-28 05:36:56,984 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48652882196686487, 'Total loss': 0.48652882196686487} | train loss {'Reaction outcome loss': 0.4743548594867652, 'Total loss': 0.4743548594867652}
2022-11-28 05:36:56,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:56,984 INFO:     Epoch: 57
2022-11-28 05:36:57,658 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47990307211875916, 'Total loss': 0.47990307211875916} | train loss {'Reaction outcome loss': 0.47754115318721124, 'Total loss': 0.47754115318721124}
2022-11-28 05:36:57,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:57,659 INFO:     Epoch: 58
2022-11-28 05:36:58,337 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48755436085841874, 'Total loss': 0.48755436085841874} | train loss {'Reaction outcome loss': 0.4941428847882429, 'Total loss': 0.4941428847882429}
2022-11-28 05:36:58,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:58,338 INFO:     Epoch: 59
2022-11-28 05:36:59,024 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47132920439947734, 'Total loss': 0.47132920439947734} | train loss {'Reaction outcome loss': 0.4696844299512384, 'Total loss': 0.4696844299512384}
2022-11-28 05:36:59,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:59,025 INFO:     Epoch: 60
2022-11-28 05:36:59,706 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4648019888184287, 'Total loss': 0.4648019888184287} | train loss {'Reaction outcome loss': 0.47309150863514254, 'Total loss': 0.47309150863514254}
2022-11-28 05:36:59,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:36:59,707 INFO:     Epoch: 61
2022-11-28 05:37:00,384 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46584316376935353, 'Total loss': 0.46584316376935353} | train loss {'Reaction outcome loss': 0.47715439057724196, 'Total loss': 0.47715439057724196}
2022-11-28 05:37:00,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:00,384 INFO:     Epoch: 62
2022-11-28 05:37:01,057 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46065441925417294, 'Total loss': 0.46065441925417294} | train loss {'Reaction outcome loss': 0.46449498487787266, 'Total loss': 0.46449498487787266}
2022-11-28 05:37:01,057 INFO:     Found new best model at epoch 62
2022-11-28 05:37:01,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:01,058 INFO:     Epoch: 63
2022-11-28 05:37:01,718 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5041584135456518, 'Total loss': 0.5041584135456518} | train loss {'Reaction outcome loss': 0.47031865950658736, 'Total loss': 0.47031865950658736}
2022-11-28 05:37:01,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:01,718 INFO:     Epoch: 64
2022-11-28 05:37:02,383 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4729464589194818, 'Total loss': 0.4729464589194818} | train loss {'Reaction outcome loss': 0.47883886201420295, 'Total loss': 0.47883886201420295}
2022-11-28 05:37:02,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:02,383 INFO:     Epoch: 65
2022-11-28 05:37:03,043 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4702818265015429, 'Total loss': 0.4702818265015429} | train loss {'Reaction outcome loss': 0.475411031711922, 'Total loss': 0.475411031711922}
2022-11-28 05:37:03,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:03,043 INFO:     Epoch: 66
2022-11-28 05:37:03,707 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48329551450230857, 'Total loss': 0.48329551450230857} | train loss {'Reaction outcome loss': 0.4764074867794871, 'Total loss': 0.4764074867794871}
2022-11-28 05:37:03,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:03,707 INFO:     Epoch: 67
2022-11-28 05:37:04,373 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4934397746216167, 'Total loss': 0.4934397746216167} | train loss {'Reaction outcome loss': 0.46823622594749637, 'Total loss': 0.46823622594749637}
2022-11-28 05:37:04,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:04,373 INFO:     Epoch: 68
2022-11-28 05:37:05,037 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4616912627084689, 'Total loss': 0.4616912627084689} | train loss {'Reaction outcome loss': 0.47094051663524394, 'Total loss': 0.47094051663524394}
2022-11-28 05:37:05,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:05,037 INFO:     Epoch: 69
2022-11-28 05:37:05,699 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5079363606531512, 'Total loss': 0.5079363606531512} | train loss {'Reaction outcome loss': 0.4752337543467278, 'Total loss': 0.4752337543467278}
2022-11-28 05:37:05,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:05,700 INFO:     Epoch: 70
2022-11-28 05:37:06,361 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5278376306999814, 'Total loss': 0.5278376306999814} | train loss {'Reaction outcome loss': 0.48453353200605526, 'Total loss': 0.48453353200605526}
2022-11-28 05:37:06,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:06,362 INFO:     Epoch: 71
2022-11-28 05:37:07,022 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5101651176810265, 'Total loss': 0.5101651176810265} | train loss {'Reaction outcome loss': 0.47320064335216877, 'Total loss': 0.47320064335216877}
2022-11-28 05:37:07,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:07,022 INFO:     Epoch: 72
2022-11-28 05:37:07,688 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4964167553592812, 'Total loss': 0.4964167553592812} | train loss {'Reaction outcome loss': 0.4641915151947423, 'Total loss': 0.4641915151947423}
2022-11-28 05:37:07,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:07,688 INFO:     Epoch: 73
2022-11-28 05:37:08,346 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47206440872766753, 'Total loss': 0.47206440872766753} | train loss {'Reaction outcome loss': 0.47001697662237446, 'Total loss': 0.47001697662237446}
2022-11-28 05:37:08,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:08,346 INFO:     Epoch: 74
2022-11-28 05:37:09,007 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5029973455450751, 'Total loss': 0.5029973455450751} | train loss {'Reaction outcome loss': 0.46835100596491624, 'Total loss': 0.46835100596491624}
2022-11-28 05:37:09,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:09,008 INFO:     Epoch: 75
2022-11-28 05:37:09,669 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5080531347881664, 'Total loss': 0.5080531347881664} | train loss {'Reaction outcome loss': 0.4729788363703832, 'Total loss': 0.4729788363703832}
2022-11-28 05:37:09,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:09,669 INFO:     Epoch: 76
2022-11-28 05:37:10,337 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49411613697355444, 'Total loss': 0.49411613697355444} | train loss {'Reaction outcome loss': 0.4855045539888776, 'Total loss': 0.4855045539888776}
2022-11-28 05:37:10,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:10,337 INFO:     Epoch: 77
2022-11-28 05:37:11,000 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4623746228489009, 'Total loss': 0.4623746228489009} | train loss {'Reaction outcome loss': 0.47456469450161043, 'Total loss': 0.47456469450161043}
2022-11-28 05:37:11,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:11,001 INFO:     Epoch: 78
2022-11-28 05:37:11,670 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4765519134022973, 'Total loss': 0.4765519134022973} | train loss {'Reaction outcome loss': 0.468998508535416, 'Total loss': 0.468998508535416}
2022-11-28 05:37:11,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:11,670 INFO:     Epoch: 79
2022-11-28 05:37:12,333 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.466814612461762, 'Total loss': 0.466814612461762} | train loss {'Reaction outcome loss': 0.48074736984574845, 'Total loss': 0.48074736984574845}
2022-11-28 05:37:12,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:12,334 INFO:     Epoch: 80
2022-11-28 05:37:12,993 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5009841200980273, 'Total loss': 0.5009841200980273} | train loss {'Reaction outcome loss': 0.4740114351998457, 'Total loss': 0.4740114351998457}
2022-11-28 05:37:12,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:12,993 INFO:     Epoch: 81
2022-11-28 05:37:13,654 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4860336750068448, 'Total loss': 0.4860336750068448} | train loss {'Reaction outcome loss': 0.4714364743063807, 'Total loss': 0.4714364743063807}
2022-11-28 05:37:13,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:13,655 INFO:     Epoch: 82
2022-11-28 05:37:14,316 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4762913483110341, 'Total loss': 0.4762913483110341} | train loss {'Reaction outcome loss': 0.4716137579318441, 'Total loss': 0.4716137579318441}
2022-11-28 05:37:14,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:14,317 INFO:     Epoch: 83
2022-11-28 05:37:14,976 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4936466244134036, 'Total loss': 0.4936466244134036} | train loss {'Reaction outcome loss': 0.4756019386926643, 'Total loss': 0.4756019386926643}
2022-11-28 05:37:14,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:14,977 INFO:     Epoch: 84
2022-11-28 05:37:15,640 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4900906505909833, 'Total loss': 0.4900906505909833} | train loss {'Reaction outcome loss': 0.4760270470429046, 'Total loss': 0.4760270470429046}
2022-11-28 05:37:15,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:15,641 INFO:     Epoch: 85
2022-11-28 05:37:16,307 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5431197705593976, 'Total loss': 0.5431197705593976} | train loss {'Reaction outcome loss': 0.4765850572209609, 'Total loss': 0.4765850572209609}
2022-11-28 05:37:16,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:16,307 INFO:     Epoch: 86
2022-11-28 05:37:16,970 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45958702215416863, 'Total loss': 0.45958702215416863} | train loss {'Reaction outcome loss': 0.46784475216498744, 'Total loss': 0.46784475216498744}
2022-11-28 05:37:16,970 INFO:     Found new best model at epoch 86
2022-11-28 05:37:16,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:16,971 INFO:     Epoch: 87
2022-11-28 05:37:17,630 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46865688873962924, 'Total loss': 0.46865688873962924} | train loss {'Reaction outcome loss': 0.4704817197462808, 'Total loss': 0.4704817197462808}
2022-11-28 05:37:17,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:17,631 INFO:     Epoch: 88
2022-11-28 05:37:18,292 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4754879484799775, 'Total loss': 0.4754879484799775} | train loss {'Reaction outcome loss': 0.47281787809934694, 'Total loss': 0.47281787809934694}
2022-11-28 05:37:18,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:18,292 INFO:     Epoch: 89
2022-11-28 05:37:18,952 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5083140967921778, 'Total loss': 0.5083140967921778} | train loss {'Reaction outcome loss': 0.4695283820935589, 'Total loss': 0.4695283820935589}
2022-11-28 05:37:18,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:18,952 INFO:     Epoch: 90
2022-11-28 05:37:19,613 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49332934550263663, 'Total loss': 0.49332934550263663} | train loss {'Reaction outcome loss': 0.4846056530832762, 'Total loss': 0.4846056530832762}
2022-11-28 05:37:19,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:19,614 INFO:     Epoch: 91
2022-11-28 05:37:20,273 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4816374910826033, 'Total loss': 0.4816374910826033} | train loss {'Reaction outcome loss': 0.46735374438048527, 'Total loss': 0.46735374438048527}
2022-11-28 05:37:20,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:20,273 INFO:     Epoch: 92
2022-11-28 05:37:20,935 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49056132408705627, 'Total loss': 0.49056132408705627} | train loss {'Reaction outcome loss': 0.47674545048460787, 'Total loss': 0.47674545048460787}
2022-11-28 05:37:20,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:20,935 INFO:     Epoch: 93
2022-11-28 05:37:21,595 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46880690719593654, 'Total loss': 0.46880690719593654} | train loss {'Reaction outcome loss': 0.47752706145468027, 'Total loss': 0.47752706145468027}
2022-11-28 05:37:21,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:21,596 INFO:     Epoch: 94
2022-11-28 05:37:22,256 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4789535210213878, 'Total loss': 0.4789535210213878} | train loss {'Reaction outcome loss': 0.47736426608765176, 'Total loss': 0.47736426608765176}
2022-11-28 05:37:22,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:22,256 INFO:     Epoch: 95
2022-11-28 05:37:22,916 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47861785323105077, 'Total loss': 0.47861785323105077} | train loss {'Reaction outcome loss': 0.47502116183279014, 'Total loss': 0.47502116183279014}
2022-11-28 05:37:22,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:22,916 INFO:     Epoch: 96
2022-11-28 05:37:23,580 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4959883232685653, 'Total loss': 0.4959883232685653} | train loss {'Reaction outcome loss': 0.4719474967192059, 'Total loss': 0.4719474967192059}
2022-11-28 05:37:23,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:23,580 INFO:     Epoch: 97
2022-11-28 05:37:24,243 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5254464640536092, 'Total loss': 0.5254464640536092} | train loss {'Reaction outcome loss': 0.46927190351824044, 'Total loss': 0.46927190351824044}
2022-11-28 05:37:24,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:24,243 INFO:     Epoch: 98
2022-11-28 05:37:24,903 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4730611511252143, 'Total loss': 0.4730611511252143} | train loss {'Reaction outcome loss': 0.4741266766178463, 'Total loss': 0.4741266766178463}
2022-11-28 05:37:24,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:24,904 INFO:     Epoch: 99
2022-11-28 05:37:25,568 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5049275308847427, 'Total loss': 0.5049275308847427} | train loss {'Reaction outcome loss': 0.4775970538310812, 'Total loss': 0.4775970538310812}
2022-11-28 05:37:25,568 INFO:     Best model found after epoch 87 of 100.
2022-11-28 05:37:25,568 INFO:   Done with stage: TRAINING
2022-11-28 05:37:25,568 INFO:   Starting stage: EVALUATION
2022-11-28 05:37:25,686 INFO:   Done with stage: EVALUATION
2022-11-28 05:37:25,686 INFO:   Leaving out SEQ value Fold_8
2022-11-28 05:37:25,698 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 05:37:25,699 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:37:26,344 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:37:26,344 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:37:26,415 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:37:26,416 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:37:26,416 INFO:     No hyperparam tuning for this model
2022-11-28 05:37:26,416 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:37:26,416 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:37:26,417 INFO:     None feature selector for col prot
2022-11-28 05:37:26,417 INFO:     None feature selector for col prot
2022-11-28 05:37:26,417 INFO:     None feature selector for col prot
2022-11-28 05:37:26,417 INFO:     None feature selector for col chem
2022-11-28 05:37:26,417 INFO:     None feature selector for col chem
2022-11-28 05:37:26,418 INFO:     None feature selector for col chem
2022-11-28 05:37:26,418 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:37:26,418 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:37:26,419 INFO:     Number of params in model 169651
2022-11-28 05:37:26,422 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:37:26,422 INFO:   Starting stage: TRAINING
2022-11-28 05:37:26,474 INFO:     Val loss before train {'Reaction outcome loss': 1.0248886550014669, 'Total loss': 1.0248886550014669}
2022-11-28 05:37:26,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:26,474 INFO:     Epoch: 0
2022-11-28 05:37:27,138 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5552680501714349, 'Total loss': 0.5552680501714349} | train loss {'Reaction outcome loss': 0.6805168403654682, 'Total loss': 0.6805168403654682}
2022-11-28 05:37:27,138 INFO:     Found new best model at epoch 0
2022-11-28 05:37:27,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:27,139 INFO:     Epoch: 1
2022-11-28 05:37:27,796 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.562829275700179, 'Total loss': 0.562829275700179} | train loss {'Reaction outcome loss': 0.5760978489506001, 'Total loss': 0.5760978489506001}
2022-11-28 05:37:27,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:27,796 INFO:     Epoch: 2
2022-11-28 05:37:28,454 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49453584545037965, 'Total loss': 0.49453584545037965} | train loss {'Reaction outcome loss': 0.54417422699685, 'Total loss': 0.54417422699685}
2022-11-28 05:37:28,454 INFO:     Found new best model at epoch 2
2022-11-28 05:37:28,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:28,455 INFO:     Epoch: 3
2022-11-28 05:37:29,118 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46126325462352147, 'Total loss': 0.46126325462352147} | train loss {'Reaction outcome loss': 0.5344082949112873, 'Total loss': 0.5344082949112873}
2022-11-28 05:37:29,119 INFO:     Found new best model at epoch 3
2022-11-28 05:37:29,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:29,119 INFO:     Epoch: 4
2022-11-28 05:37:29,781 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4818682838231325, 'Total loss': 0.4818682838231325} | train loss {'Reaction outcome loss': 0.5137121122102348, 'Total loss': 0.5137121122102348}
2022-11-28 05:37:29,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:29,781 INFO:     Epoch: 5
2022-11-28 05:37:30,440 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4699104326692494, 'Total loss': 0.4699104326692494} | train loss {'Reaction outcome loss': 0.5063400385027029, 'Total loss': 0.5063400385027029}
2022-11-28 05:37:30,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:30,440 INFO:     Epoch: 6
2022-11-28 05:37:31,097 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4745987301523035, 'Total loss': 0.4745987301523035} | train loss {'Reaction outcome loss': 0.49952582692613406, 'Total loss': 0.49952582692613406}
2022-11-28 05:37:31,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:31,097 INFO:     Epoch: 7
2022-11-28 05:37:31,753 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48804151808673685, 'Total loss': 0.48804151808673685} | train loss {'Reaction outcome loss': 0.4944642099494837, 'Total loss': 0.4944642099494837}
2022-11-28 05:37:31,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:31,753 INFO:     Epoch: 8
2022-11-28 05:37:32,409 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44724138732999563, 'Total loss': 0.44724138732999563} | train loss {'Reaction outcome loss': 0.4864765582035999, 'Total loss': 0.4864765582035999}
2022-11-28 05:37:32,409 INFO:     Found new best model at epoch 8
2022-11-28 05:37:32,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:32,410 INFO:     Epoch: 9
2022-11-28 05:37:33,068 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4775782452726906, 'Total loss': 0.4775782452726906} | train loss {'Reaction outcome loss': 0.48692017513878494, 'Total loss': 0.48692017513878494}
2022-11-28 05:37:33,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:33,068 INFO:     Epoch: 10
2022-11-28 05:37:33,723 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4627177935432304, 'Total loss': 0.4627177935432304} | train loss {'Reaction outcome loss': 0.4814974643746201, 'Total loss': 0.4814974643746201}
2022-11-28 05:37:33,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:33,723 INFO:     Epoch: 11
2022-11-28 05:37:34,380 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4785524918274446, 'Total loss': 0.4785524918274446} | train loss {'Reaction outcome loss': 0.48340421422403684, 'Total loss': 0.48340421422403684}
2022-11-28 05:37:34,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:34,380 INFO:     Epoch: 12
2022-11-28 05:37:35,036 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5155771411955357, 'Total loss': 0.5155771411955357} | train loss {'Reaction outcome loss': 0.48227806985378263, 'Total loss': 0.48227806985378263}
2022-11-28 05:37:35,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:35,036 INFO:     Epoch: 13
2022-11-28 05:37:35,694 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4834491197358478, 'Total loss': 0.4834491197358478} | train loss {'Reaction outcome loss': 0.4763962760567665, 'Total loss': 0.4763962760567665}
2022-11-28 05:37:35,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:35,695 INFO:     Epoch: 14
2022-11-28 05:37:36,352 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45062466067346657, 'Total loss': 0.45062466067346657} | train loss {'Reaction outcome loss': 0.47989639116793265, 'Total loss': 0.47989639116793265}
2022-11-28 05:37:36,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:36,353 INFO:     Epoch: 15
2022-11-28 05:37:37,009 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4456540352918885, 'Total loss': 0.4456540352918885} | train loss {'Reaction outcome loss': 0.46998520767202184, 'Total loss': 0.46998520767202184}
2022-11-28 05:37:37,009 INFO:     Found new best model at epoch 15
2022-11-28 05:37:37,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:37,010 INFO:     Epoch: 16
2022-11-28 05:37:37,669 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4290794662453912, 'Total loss': 0.4290794662453912} | train loss {'Reaction outcome loss': 0.4720534805132418, 'Total loss': 0.4720534805132418}
2022-11-28 05:37:37,670 INFO:     Found new best model at epoch 16
2022-11-28 05:37:37,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:37,670 INFO:     Epoch: 17
2022-11-28 05:37:38,329 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4828549540517005, 'Total loss': 0.4828549540517005} | train loss {'Reaction outcome loss': 0.472587842418223, 'Total loss': 0.472587842418223}
2022-11-28 05:37:38,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:38,330 INFO:     Epoch: 18
2022-11-28 05:37:38,984 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4429784501818093, 'Total loss': 0.4429784501818093} | train loss {'Reaction outcome loss': 0.4747674794221411, 'Total loss': 0.4747674794221411}
2022-11-28 05:37:38,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:38,984 INFO:     Epoch: 19
2022-11-28 05:37:39,644 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5005810436877337, 'Total loss': 0.5005810436877337} | train loss {'Reaction outcome loss': 0.4744242360397261, 'Total loss': 0.4744242360397261}
2022-11-28 05:37:39,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:39,645 INFO:     Epoch: 20
2022-11-28 05:37:40,305 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47465434399518097, 'Total loss': 0.47465434399518097} | train loss {'Reaction outcome loss': 0.4748568753502807, 'Total loss': 0.4748568753502807}
2022-11-28 05:37:40,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:40,305 INFO:     Epoch: 21
2022-11-28 05:37:40,966 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4502230178226124, 'Total loss': 0.4502230178226124} | train loss {'Reaction outcome loss': 0.47714640333944436, 'Total loss': 0.47714640333944436}
2022-11-28 05:37:40,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:40,966 INFO:     Epoch: 22
2022-11-28 05:37:41,621 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4290230968459086, 'Total loss': 0.4290230968459086} | train loss {'Reaction outcome loss': 0.4707017812193656, 'Total loss': 0.4707017812193656}
2022-11-28 05:37:41,622 INFO:     Found new best model at epoch 22
2022-11-28 05:37:41,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:41,623 INFO:     Epoch: 23
2022-11-28 05:37:42,279 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4816325618462129, 'Total loss': 0.4816325618462129} | train loss {'Reaction outcome loss': 0.4674651163573168, 'Total loss': 0.4674651163573168}
2022-11-28 05:37:42,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:42,280 INFO:     Epoch: 24
2022-11-28 05:37:42,940 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42429162765091116, 'Total loss': 0.42429162765091116} | train loss {'Reaction outcome loss': 0.4701813946573102, 'Total loss': 0.4701813946573102}
2022-11-28 05:37:42,940 INFO:     Found new best model at epoch 24
2022-11-28 05:37:42,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:42,941 INFO:     Epoch: 25
2022-11-28 05:37:43,604 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46246602487835015, 'Total loss': 0.46246602487835015} | train loss {'Reaction outcome loss': 0.4694513399990238, 'Total loss': 0.4694513399990238}
2022-11-28 05:37:43,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:43,604 INFO:     Epoch: 26
2022-11-28 05:37:44,265 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45377339016307483, 'Total loss': 0.45377339016307483} | train loss {'Reaction outcome loss': 0.4634950427680599, 'Total loss': 0.4634950427680599}
2022-11-28 05:37:44,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:44,265 INFO:     Epoch: 27
2022-11-28 05:37:44,924 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46510165252468805, 'Total loss': 0.46510165252468805} | train loss {'Reaction outcome loss': 0.4719125810934573, 'Total loss': 0.4719125810934573}
2022-11-28 05:37:44,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:44,924 INFO:     Epoch: 28
2022-11-28 05:37:45,583 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4584371156313203, 'Total loss': 0.4584371156313203} | train loss {'Reaction outcome loss': 0.4737315486280286, 'Total loss': 0.4737315486280286}
2022-11-28 05:37:45,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:45,584 INFO:     Epoch: 29
2022-11-28 05:37:46,245 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4656905382871628, 'Total loss': 0.4656905382871628} | train loss {'Reaction outcome loss': 0.4764689338146424, 'Total loss': 0.4764689338146424}
2022-11-28 05:37:46,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:46,245 INFO:     Epoch: 30
2022-11-28 05:37:46,899 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43313639746470883, 'Total loss': 0.43313639746470883} | train loss {'Reaction outcome loss': 0.4643104955249903, 'Total loss': 0.4643104955249903}
2022-11-28 05:37:46,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:46,900 INFO:     Epoch: 31
2022-11-28 05:37:47,555 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4440588873218406, 'Total loss': 0.4440588873218406} | train loss {'Reaction outcome loss': 0.4701102431331362, 'Total loss': 0.4701102431331362}
2022-11-28 05:37:47,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:47,555 INFO:     Epoch: 32
2022-11-28 05:37:48,212 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45827570523728023, 'Total loss': 0.45827570523728023} | train loss {'Reaction outcome loss': 0.47264412823988466, 'Total loss': 0.47264412823988466}
2022-11-28 05:37:48,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:48,213 INFO:     Epoch: 33
2022-11-28 05:37:48,869 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45870527489618823, 'Total loss': 0.45870527489618823} | train loss {'Reaction outcome loss': 0.4604055287886639, 'Total loss': 0.4604055287886639}
2022-11-28 05:37:48,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:48,870 INFO:     Epoch: 34
2022-11-28 05:37:49,528 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4399967251176184, 'Total loss': 0.4399967251176184} | train loss {'Reaction outcome loss': 0.4756798877399795, 'Total loss': 0.4756798877399795}
2022-11-28 05:37:49,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:49,528 INFO:     Epoch: 35
2022-11-28 05:37:50,185 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4353112690150738, 'Total loss': 0.4353112690150738} | train loss {'Reaction outcome loss': 0.45955936622862914, 'Total loss': 0.45955936622862914}
2022-11-28 05:37:50,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:50,185 INFO:     Epoch: 36
2022-11-28 05:37:50,841 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4645859934389591, 'Total loss': 0.4645859934389591} | train loss {'Reaction outcome loss': 0.4688583039507574, 'Total loss': 0.4688583039507574}
2022-11-28 05:37:50,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:50,842 INFO:     Epoch: 37
2022-11-28 05:37:51,498 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.454762072048404, 'Total loss': 0.454762072048404} | train loss {'Reaction outcome loss': 0.4731086137343426, 'Total loss': 0.4731086137343426}
2022-11-28 05:37:51,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:51,498 INFO:     Epoch: 38
2022-11-28 05:37:52,156 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48562114042314614, 'Total loss': 0.48562114042314614} | train loss {'Reaction outcome loss': 0.46934550209921233, 'Total loss': 0.46934550209921233}
2022-11-28 05:37:52,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:52,156 INFO:     Epoch: 39
2022-11-28 05:37:52,816 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43841528486121784, 'Total loss': 0.43841528486121784} | train loss {'Reaction outcome loss': 0.47162335411626466, 'Total loss': 0.47162335411626466}
2022-11-28 05:37:52,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:52,816 INFO:     Epoch: 40
2022-11-28 05:37:53,475 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4261800650168549, 'Total loss': 0.4261800650168549} | train loss {'Reaction outcome loss': 0.46896675259483106, 'Total loss': 0.46896675259483106}
2022-11-28 05:37:53,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:53,476 INFO:     Epoch: 41
2022-11-28 05:37:54,130 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4684266905215653, 'Total loss': 0.4684266905215653} | train loss {'Reaction outcome loss': 0.46818986322198597, 'Total loss': 0.46818986322198597}
2022-11-28 05:37:54,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:54,130 INFO:     Epoch: 42
2022-11-28 05:37:54,791 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.461319581351497, 'Total loss': 0.461319581351497} | train loss {'Reaction outcome loss': 0.47272586962398216, 'Total loss': 0.47272586962398216}
2022-11-28 05:37:54,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:54,791 INFO:     Epoch: 43
2022-11-28 05:37:55,452 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46450310708446935, 'Total loss': 0.46450310708446935} | train loss {'Reaction outcome loss': 0.4719331172047829, 'Total loss': 0.4719331172047829}
2022-11-28 05:37:55,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:55,452 INFO:     Epoch: 44
2022-11-28 05:37:56,114 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4347298165613955, 'Total loss': 0.4347298165613955} | train loss {'Reaction outcome loss': 0.4663103048290525, 'Total loss': 0.4663103048290525}
2022-11-28 05:37:56,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:56,114 INFO:     Epoch: 45
2022-11-28 05:37:56,771 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4555718556723811, 'Total loss': 0.4555718556723811} | train loss {'Reaction outcome loss': 0.467545811254151, 'Total loss': 0.467545811254151}
2022-11-28 05:37:56,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:56,771 INFO:     Epoch: 46
2022-11-28 05:37:57,427 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45119799741289834, 'Total loss': 0.45119799741289834} | train loss {'Reaction outcome loss': 0.4686131762606757, 'Total loss': 0.4686131762606757}
2022-11-28 05:37:57,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:57,427 INFO:     Epoch: 47
2022-11-28 05:37:58,083 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43763453377918765, 'Total loss': 0.43763453377918765} | train loss {'Reaction outcome loss': 0.4682729132321416, 'Total loss': 0.4682729132321416}
2022-11-28 05:37:58,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:58,084 INFO:     Epoch: 48
2022-11-28 05:37:58,744 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4367428015578877, 'Total loss': 0.4367428015578877} | train loss {'Reaction outcome loss': 0.47270774567613794, 'Total loss': 0.47270774567613794}
2022-11-28 05:37:58,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:58,744 INFO:     Epoch: 49
2022-11-28 05:37:59,403 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4576362694867633, 'Total loss': 0.4576362694867633} | train loss {'Reaction outcome loss': 0.46756214651526234, 'Total loss': 0.46756214651526234}
2022-11-28 05:37:59,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:37:59,403 INFO:     Epoch: 50
2022-11-28 05:38:00,059 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5017129623077132, 'Total loss': 0.5017129623077132} | train loss {'Reaction outcome loss': 0.4649319781028495, 'Total loss': 0.4649319781028495}
2022-11-28 05:38:00,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:00,059 INFO:     Epoch: 51
2022-11-28 05:38:00,715 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43185372007164086, 'Total loss': 0.43185372007164086} | train loss {'Reaction outcome loss': 0.4697599320995564, 'Total loss': 0.4697599320995564}
2022-11-28 05:38:00,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:00,716 INFO:     Epoch: 52
2022-11-28 05:38:01,372 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4750624271956357, 'Total loss': 0.4750624271956357} | train loss {'Reaction outcome loss': 0.4678823366457102, 'Total loss': 0.4678823366457102}
2022-11-28 05:38:01,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:01,372 INFO:     Epoch: 53
2022-11-28 05:38:02,029 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4258281321010806, 'Total loss': 0.4258281321010806} | train loss {'Reaction outcome loss': 0.47217411021797023, 'Total loss': 0.47217411021797023}
2022-11-28 05:38:02,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:02,030 INFO:     Epoch: 54
2022-11-28 05:38:02,684 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4767117459665645, 'Total loss': 0.4767117459665645} | train loss {'Reaction outcome loss': 0.47218618575407534, 'Total loss': 0.47218618575407534}
2022-11-28 05:38:02,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:02,685 INFO:     Epoch: 55
2022-11-28 05:38:03,342 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.491868101737716, 'Total loss': 0.491868101737716} | train loss {'Reaction outcome loss': 0.4678309958808276, 'Total loss': 0.4678309958808276}
2022-11-28 05:38:03,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:03,342 INFO:     Epoch: 56
2022-11-28 05:38:03,997 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.462395389649001, 'Total loss': 0.462395389649001} | train loss {'Reaction outcome loss': 0.47302750379455333, 'Total loss': 0.47302750379455333}
2022-11-28 05:38:03,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:03,997 INFO:     Epoch: 57
2022-11-28 05:38:04,653 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4477738118307157, 'Total loss': 0.4477738118307157} | train loss {'Reaction outcome loss': 0.47111567468667515, 'Total loss': 0.47111567468667515}
2022-11-28 05:38:04,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:04,654 INFO:     Epoch: 58
2022-11-28 05:38:05,313 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4369827584278854, 'Total loss': 0.4369827584278854} | train loss {'Reaction outcome loss': 0.4711971634200641, 'Total loss': 0.4711971634200641}
2022-11-28 05:38:05,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:05,313 INFO:     Epoch: 59
2022-11-28 05:38:05,971 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4462735307487575, 'Total loss': 0.4462735307487575} | train loss {'Reaction outcome loss': 0.47184242016198685, 'Total loss': 0.47184242016198685}
2022-11-28 05:38:05,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:05,971 INFO:     Epoch: 60
2022-11-28 05:38:06,632 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4447498707608743, 'Total loss': 0.4447498707608743} | train loss {'Reaction outcome loss': 0.46824621558189394, 'Total loss': 0.46824621558189394}
2022-11-28 05:38:06,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:06,632 INFO:     Epoch: 61
2022-11-28 05:38:07,292 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4420695731585676, 'Total loss': 0.4420695731585676} | train loss {'Reaction outcome loss': 0.472468796220361, 'Total loss': 0.472468796220361}
2022-11-28 05:38:07,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:07,292 INFO:     Epoch: 62
2022-11-28 05:38:07,953 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46943778883327136, 'Total loss': 0.46943778883327136} | train loss {'Reaction outcome loss': 0.46892467305368307, 'Total loss': 0.46892467305368307}
2022-11-28 05:38:07,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:07,953 INFO:     Epoch: 63
2022-11-28 05:38:08,613 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4253070784563368, 'Total loss': 0.4253070784563368} | train loss {'Reaction outcome loss': 0.473190219730747, 'Total loss': 0.473190219730747}
2022-11-28 05:38:08,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:08,613 INFO:     Epoch: 64
2022-11-28 05:38:09,269 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45303808051076805, 'Total loss': 0.45303808051076805} | train loss {'Reaction outcome loss': 0.46921627162670604, 'Total loss': 0.46921627162670604}
2022-11-28 05:38:09,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:09,269 INFO:     Epoch: 65
2022-11-28 05:38:09,925 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4483824339271946, 'Total loss': 0.4483824339271946} | train loss {'Reaction outcome loss': 0.4683071056799013, 'Total loss': 0.4683071056799013}
2022-11-28 05:38:09,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:09,925 INFO:     Epoch: 66
2022-11-28 05:38:10,581 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4424688643352552, 'Total loss': 0.4424688643352552} | train loss {'Reaction outcome loss': 0.47431934792168284, 'Total loss': 0.47431934792168284}
2022-11-28 05:38:10,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:10,581 INFO:     Epoch: 67
2022-11-28 05:38:11,238 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46758849681778386, 'Total loss': 0.46758849681778386} | train loss {'Reaction outcome loss': 0.4662951401910003, 'Total loss': 0.4662951401910003}
2022-11-28 05:38:11,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:11,238 INFO:     Epoch: 68
2022-11-28 05:38:11,894 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4395579167387702, 'Total loss': 0.4395579167387702} | train loss {'Reaction outcome loss': 0.4701444821698325, 'Total loss': 0.4701444821698325}
2022-11-28 05:38:11,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:11,895 INFO:     Epoch: 69
2022-11-28 05:38:12,549 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4403143636882305, 'Total loss': 0.4403143636882305} | train loss {'Reaction outcome loss': 0.46541613510676794, 'Total loss': 0.46541613510676794}
2022-11-28 05:38:12,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:12,549 INFO:     Epoch: 70
2022-11-28 05:38:13,206 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4471269219436429, 'Total loss': 0.4471269219436429} | train loss {'Reaction outcome loss': 0.468000935839147, 'Total loss': 0.468000935839147}
2022-11-28 05:38:13,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:13,207 INFO:     Epoch: 71
2022-11-28 05:38:13,862 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4594610860063271, 'Total loss': 0.4594610860063271} | train loss {'Reaction outcome loss': 0.46586657190809444, 'Total loss': 0.46586657190809444}
2022-11-28 05:38:13,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:13,862 INFO:     Epoch: 72
2022-11-28 05:38:14,517 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43728871762075205, 'Total loss': 0.43728871762075205} | train loss {'Reaction outcome loss': 0.4671380834311855, 'Total loss': 0.4671380834311855}
2022-11-28 05:38:14,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:14,517 INFO:     Epoch: 73
2022-11-28 05:38:15,173 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.450773687525229, 'Total loss': 0.450773687525229} | train loss {'Reaction outcome loss': 0.46882543642910157, 'Total loss': 0.46882543642910157}
2022-11-28 05:38:15,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:15,173 INFO:     Epoch: 74
2022-11-28 05:38:15,828 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4414114782756025, 'Total loss': 0.4414114782756025} | train loss {'Reaction outcome loss': 0.47268728808480864, 'Total loss': 0.47268728808480864}
2022-11-28 05:38:15,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:15,828 INFO:     Epoch: 75
2022-11-28 05:38:16,481 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46453840691934933, 'Total loss': 0.46453840691934933} | train loss {'Reaction outcome loss': 0.46551629821864926, 'Total loss': 0.46551629821864926}
2022-11-28 05:38:16,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:16,482 INFO:     Epoch: 76
2022-11-28 05:38:17,138 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4776972539045594, 'Total loss': 0.4776972539045594} | train loss {'Reaction outcome loss': 0.4623297857994936, 'Total loss': 0.4623297857994936}
2022-11-28 05:38:17,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:17,139 INFO:     Epoch: 77
2022-11-28 05:38:17,795 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.455250123007731, 'Total loss': 0.455250123007731} | train loss {'Reaction outcome loss': 0.4668058330915412, 'Total loss': 0.4668058330915412}
2022-11-28 05:38:17,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:17,795 INFO:     Epoch: 78
2022-11-28 05:38:18,455 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44548457403751934, 'Total loss': 0.44548457403751934} | train loss {'Reaction outcome loss': 0.468711868901642, 'Total loss': 0.468711868901642}
2022-11-28 05:38:18,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:18,455 INFO:     Epoch: 79
2022-11-28 05:38:19,109 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46402008391239424, 'Total loss': 0.46402008391239424} | train loss {'Reaction outcome loss': 0.46619994664678766, 'Total loss': 0.46619994664678766}
2022-11-28 05:38:19,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:19,110 INFO:     Epoch: 80
2022-11-28 05:38:19,765 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47607680748809467, 'Total loss': 0.47607680748809467} | train loss {'Reaction outcome loss': 0.47472311507682413, 'Total loss': 0.47472311507682413}
2022-11-28 05:38:19,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:19,766 INFO:     Epoch: 81
2022-11-28 05:38:20,421 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4612201093272729, 'Total loss': 0.4612201093272729} | train loss {'Reaction outcome loss': 0.4674621718878649, 'Total loss': 0.4674621718878649}
2022-11-28 05:38:20,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:20,422 INFO:     Epoch: 82
2022-11-28 05:38:21,079 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45308730615810916, 'Total loss': 0.45308730615810916} | train loss {'Reaction outcome loss': 0.47273268851698663, 'Total loss': 0.47273268851698663}
2022-11-28 05:38:21,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:21,080 INFO:     Epoch: 83
2022-11-28 05:38:21,736 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43244820968671277, 'Total loss': 0.43244820968671277} | train loss {'Reaction outcome loss': 0.47916584969783316, 'Total loss': 0.47916584969783316}
2022-11-28 05:38:21,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:21,736 INFO:     Epoch: 84
2022-11-28 05:38:22,393 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4402384615757249, 'Total loss': 0.4402384615757249} | train loss {'Reaction outcome loss': 0.4685542907033648, 'Total loss': 0.4685542907033648}
2022-11-28 05:38:22,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:22,393 INFO:     Epoch: 85
2022-11-28 05:38:23,048 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4454504989764907, 'Total loss': 0.4454504989764907} | train loss {'Reaction outcome loss': 0.46833452704001444, 'Total loss': 0.46833452704001444}
2022-11-28 05:38:23,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:23,048 INFO:     Epoch: 86
2022-11-28 05:38:23,706 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43096864655275235, 'Total loss': 0.43096864655275235} | train loss {'Reaction outcome loss': 0.47274234471272447, 'Total loss': 0.47274234471272447}
2022-11-28 05:38:23,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:23,706 INFO:     Epoch: 87
2022-11-28 05:38:24,364 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47380830855532124, 'Total loss': 0.47380830855532124} | train loss {'Reaction outcome loss': 0.46782733408772215, 'Total loss': 0.46782733408772215}
2022-11-28 05:38:24,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:24,364 INFO:     Epoch: 88
2022-11-28 05:38:25,019 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4467548504471779, 'Total loss': 0.4467548504471779} | train loss {'Reaction outcome loss': 0.4688621009490928, 'Total loss': 0.4688621009490928}
2022-11-28 05:38:25,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:25,019 INFO:     Epoch: 89
2022-11-28 05:38:25,675 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49584990672089835, 'Total loss': 0.49584990672089835} | train loss {'Reaction outcome loss': 0.4729797697188903, 'Total loss': 0.4729797697188903}
2022-11-28 05:38:25,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:25,675 INFO:     Epoch: 90
2022-11-28 05:38:26,329 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43872514604167506, 'Total loss': 0.43872514604167506} | train loss {'Reaction outcome loss': 0.4683651337210013, 'Total loss': 0.4683651337210013}
2022-11-28 05:38:26,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:26,329 INFO:     Epoch: 91
2022-11-28 05:38:26,986 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43806359070268547, 'Total loss': 0.43806359070268547} | train loss {'Reaction outcome loss': 0.46623556893699025, 'Total loss': 0.46623556893699025}
2022-11-28 05:38:26,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:26,987 INFO:     Epoch: 92
2022-11-28 05:38:27,643 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46897144547917624, 'Total loss': 0.46897144547917624} | train loss {'Reaction outcome loss': 0.4733274592428791, 'Total loss': 0.4733274592428791}
2022-11-28 05:38:27,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:27,643 INFO:     Epoch: 93
2022-11-28 05:38:28,296 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44609852423044766, 'Total loss': 0.44609852423044766} | train loss {'Reaction outcome loss': 0.47049838000414324, 'Total loss': 0.47049838000414324}
2022-11-28 05:38:28,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:28,297 INFO:     Epoch: 94
2022-11-28 05:38:28,951 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4232024909420447, 'Total loss': 0.4232024909420447} | train loss {'Reaction outcome loss': 0.4674050335981408, 'Total loss': 0.4674050335981408}
2022-11-28 05:38:28,951 INFO:     Found new best model at epoch 94
2022-11-28 05:38:28,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:28,952 INFO:     Epoch: 95
2022-11-28 05:38:29,609 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46109118312597275, 'Total loss': 0.46109118312597275} | train loss {'Reaction outcome loss': 0.4661436041398924, 'Total loss': 0.4661436041398924}
2022-11-28 05:38:29,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:29,609 INFO:     Epoch: 96
2022-11-28 05:38:30,263 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42218733045526524, 'Total loss': 0.42218733045526524} | train loss {'Reaction outcome loss': 0.4675377032586506, 'Total loss': 0.4675377032586506}
2022-11-28 05:38:30,263 INFO:     Found new best model at epoch 96
2022-11-28 05:38:30,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:30,264 INFO:     Epoch: 97
2022-11-28 05:38:30,920 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42913366413929244, 'Total loss': 0.42913366413929244} | train loss {'Reaction outcome loss': 0.4671225144546859, 'Total loss': 0.4671225144546859}
2022-11-28 05:38:30,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:30,920 INFO:     Epoch: 98
2022-11-28 05:38:31,575 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43623636883090844, 'Total loss': 0.43623636883090844} | train loss {'Reaction outcome loss': 0.4694140914143348, 'Total loss': 0.4694140914143348}
2022-11-28 05:38:31,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:31,576 INFO:     Epoch: 99
2022-11-28 05:38:32,231 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49131017279895867, 'Total loss': 0.49131017279895867} | train loss {'Reaction outcome loss': 0.47066997417381834, 'Total loss': 0.47066997417381834}
2022-11-28 05:38:32,232 INFO:     Best model found after epoch 97 of 100.
2022-11-28 05:38:32,232 INFO:   Done with stage: TRAINING
2022-11-28 05:38:32,232 INFO:   Starting stage: EVALUATION
2022-11-28 05:38:32,355 INFO:   Done with stage: EVALUATION
2022-11-28 05:38:32,355 INFO:   Leaving out SEQ value Fold_9
2022-11-28 05:38:32,368 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 05:38:32,368 INFO:   Starting stage: FEATURE SCALING
2022-11-28 05:38:33,015 INFO:   Done with stage: FEATURE SCALING
2022-11-28 05:38:33,016 INFO:   Starting stage: SCALING TARGETS
2022-11-28 05:38:33,087 INFO:   Done with stage: SCALING TARGETS
2022-11-28 05:38:33,087 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:38:33,087 INFO:     No hyperparam tuning for this model
2022-11-28 05:38:33,087 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 05:38:33,087 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 05:38:33,088 INFO:     None feature selector for col prot
2022-11-28 05:38:33,088 INFO:     None feature selector for col prot
2022-11-28 05:38:33,088 INFO:     None feature selector for col prot
2022-11-28 05:38:33,089 INFO:     None feature selector for col chem
2022-11-28 05:38:33,089 INFO:     None feature selector for col chem
2022-11-28 05:38:33,089 INFO:     None feature selector for col chem
2022-11-28 05:38:33,089 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 05:38:33,089 INFO:   Starting stage: BUILD MODEL
2022-11-28 05:38:33,090 INFO:     Number of params in model 169651
2022-11-28 05:38:33,093 INFO:   Done with stage: BUILD MODEL
2022-11-28 05:38:33,094 INFO:   Starting stage: TRAINING
2022-11-28 05:38:33,145 INFO:     Val loss before train {'Reaction outcome loss': 0.9994087977842852, 'Total loss': 0.9994087977842852}
2022-11-28 05:38:33,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:33,145 INFO:     Epoch: 0
2022-11-28 05:38:33,805 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6713269576430321, 'Total loss': 0.6713269576430321} | train loss {'Reaction outcome loss': 0.6913895494783455, 'Total loss': 0.6913895494783455}
2022-11-28 05:38:33,805 INFO:     Found new best model at epoch 0
2022-11-28 05:38:33,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:33,806 INFO:     Epoch: 1
2022-11-28 05:38:34,465 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5359546454115347, 'Total loss': 0.5359546454115347} | train loss {'Reaction outcome loss': 0.5663200392414202, 'Total loss': 0.5663200392414202}
2022-11-28 05:38:34,465 INFO:     Found new best model at epoch 1
2022-11-28 05:38:34,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:34,466 INFO:     Epoch: 2
2022-11-28 05:38:35,124 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5246968594464388, 'Total loss': 0.5246968594464388} | train loss {'Reaction outcome loss': 0.5349091559739007, 'Total loss': 0.5349091559739007}
2022-11-28 05:38:35,124 INFO:     Found new best model at epoch 2
2022-11-28 05:38:35,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:35,125 INFO:     Epoch: 3
2022-11-28 05:38:35,782 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.536188811741092, 'Total loss': 0.536188811741092} | train loss {'Reaction outcome loss': 0.5281820029533102, 'Total loss': 0.5281820029533102}
2022-11-28 05:38:35,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:35,783 INFO:     Epoch: 4
2022-11-28 05:38:36,440 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49664684622125194, 'Total loss': 0.49664684622125194} | train loss {'Reaction outcome loss': 0.5134273987067374, 'Total loss': 0.5134273987067374}
2022-11-28 05:38:36,440 INFO:     Found new best model at epoch 4
2022-11-28 05:38:36,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:36,440 INFO:     Epoch: 5
2022-11-28 05:38:37,102 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.6154104647311297, 'Total loss': 0.6154104647311297} | train loss {'Reaction outcome loss': 0.5105540819978907, 'Total loss': 0.5105540819978907}
2022-11-28 05:38:37,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:37,103 INFO:     Epoch: 6
2022-11-28 05:38:37,768 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5390690328045324, 'Total loss': 0.5390690328045324} | train loss {'Reaction outcome loss': 0.49933157754149515, 'Total loss': 0.49933157754149515}
2022-11-28 05:38:37,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:37,768 INFO:     Epoch: 7
2022-11-28 05:38:38,431 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5296061133796518, 'Total loss': 0.5296061133796518} | train loss {'Reaction outcome loss': 0.500206336469544, 'Total loss': 0.500206336469544}
2022-11-28 05:38:38,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:38,431 INFO:     Epoch: 8
2022-11-28 05:38:39,091 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5045411854305051, 'Total loss': 0.5045411854305051} | train loss {'Reaction outcome loss': 0.4886356800311973, 'Total loss': 0.4886356800311973}
2022-11-28 05:38:39,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:39,091 INFO:     Epoch: 9
2022-11-28 05:38:39,751 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5033384456553243, 'Total loss': 0.5033384456553243} | train loss {'Reaction outcome loss': 0.48982891775215204, 'Total loss': 0.48982891775215204}
2022-11-28 05:38:39,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:39,751 INFO:     Epoch: 10
2022-11-28 05:38:40,411 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.492761375551874, 'Total loss': 0.492761375551874} | train loss {'Reaction outcome loss': 0.48177098132941404, 'Total loss': 0.48177098132941404}
2022-11-28 05:38:40,411 INFO:     Found new best model at epoch 10
2022-11-28 05:38:40,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:40,412 INFO:     Epoch: 11
2022-11-28 05:38:41,070 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49527213790199975, 'Total loss': 0.49527213790199975} | train loss {'Reaction outcome loss': 0.48690758416285884, 'Total loss': 0.48690758416285884}
2022-11-28 05:38:41,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:41,070 INFO:     Epoch: 12
2022-11-28 05:38:41,731 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47027800943363796, 'Total loss': 0.47027800943363796} | train loss {'Reaction outcome loss': 0.48548189019746624, 'Total loss': 0.48548189019746624}
2022-11-28 05:38:41,731 INFO:     Found new best model at epoch 12
2022-11-28 05:38:41,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:41,732 INFO:     Epoch: 13
2022-11-28 05:38:42,393 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5076070048592307, 'Total loss': 0.5076070048592307} | train loss {'Reaction outcome loss': 0.4836969749647596, 'Total loss': 0.4836969749647596}
2022-11-28 05:38:42,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:42,393 INFO:     Epoch: 14
2022-11-28 05:38:43,056 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5205754305828701, 'Total loss': 0.5205754305828701} | train loss {'Reaction outcome loss': 0.47920168791463985, 'Total loss': 0.47920168791463985}
2022-11-28 05:38:43,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:43,057 INFO:     Epoch: 15
2022-11-28 05:38:43,720 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49805385822599585, 'Total loss': 0.49805385822599585} | train loss {'Reaction outcome loss': 0.4737235048582197, 'Total loss': 0.4737235048582197}
2022-11-28 05:38:43,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:43,721 INFO:     Epoch: 16
2022-11-28 05:38:44,380 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5011194256896322, 'Total loss': 0.5011194256896322} | train loss {'Reaction outcome loss': 0.4821945112726466, 'Total loss': 0.4821945112726466}
2022-11-28 05:38:44,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:44,380 INFO:     Epoch: 17
2022-11-28 05:38:45,037 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4805381047454747, 'Total loss': 0.4805381047454747} | train loss {'Reaction outcome loss': 0.482154331890195, 'Total loss': 0.482154331890195}
2022-11-28 05:38:45,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:45,037 INFO:     Epoch: 18
2022-11-28 05:38:45,697 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.504915289580822, 'Total loss': 0.504915289580822} | train loss {'Reaction outcome loss': 0.46790510066125074, 'Total loss': 0.46790510066125074}
2022-11-28 05:38:45,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:45,697 INFO:     Epoch: 19
2022-11-28 05:38:46,361 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5113904381340201, 'Total loss': 0.5113904381340201} | train loss {'Reaction outcome loss': 0.479064495276343, 'Total loss': 0.479064495276343}
2022-11-28 05:38:46,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:46,362 INFO:     Epoch: 20
2022-11-28 05:38:47,021 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4795075675303286, 'Total loss': 0.4795075675303286} | train loss {'Reaction outcome loss': 0.4645242468898867, 'Total loss': 0.4645242468898867}
2022-11-28 05:38:47,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:47,021 INFO:     Epoch: 21
2022-11-28 05:38:47,680 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45825080471959984, 'Total loss': 0.45825080471959984} | train loss {'Reaction outcome loss': 0.46991238794346085, 'Total loss': 0.46991238794346085}
2022-11-28 05:38:47,680 INFO:     Found new best model at epoch 21
2022-11-28 05:38:47,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:47,681 INFO:     Epoch: 22
2022-11-28 05:38:48,337 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4865878011015328, 'Total loss': 0.4865878011015328} | train loss {'Reaction outcome loss': 0.4685691132281835, 'Total loss': 0.4685691132281835}
2022-11-28 05:38:48,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:48,338 INFO:     Epoch: 23
2022-11-28 05:38:49,000 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48126258328557014, 'Total loss': 0.48126258328557014} | train loss {'Reaction outcome loss': 0.45742480725291285, 'Total loss': 0.45742480725291285}
2022-11-28 05:38:49,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:49,000 INFO:     Epoch: 24
2022-11-28 05:38:49,660 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5610516972162507, 'Total loss': 0.5610516972162507} | train loss {'Reaction outcome loss': 0.4600444617059067, 'Total loss': 0.4600444617059067}
2022-11-28 05:38:49,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:49,660 INFO:     Epoch: 25
2022-11-28 05:38:50,318 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5007937305014242, 'Total loss': 0.5007937305014242} | train loss {'Reaction outcome loss': 0.47742529461529815, 'Total loss': 0.47742529461529815}
2022-11-28 05:38:50,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:50,319 INFO:     Epoch: 26
2022-11-28 05:38:50,981 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4706236943602562, 'Total loss': 0.4706236943602562} | train loss {'Reaction outcome loss': 0.46736261646757243, 'Total loss': 0.46736261646757243}
2022-11-28 05:38:50,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:50,981 INFO:     Epoch: 27
2022-11-28 05:38:51,643 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4670527729798447, 'Total loss': 0.4670527729798447} | train loss {'Reaction outcome loss': 0.4554495738464811, 'Total loss': 0.4554495738464811}
2022-11-28 05:38:51,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:51,643 INFO:     Epoch: 28
2022-11-28 05:38:52,302 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5226073813709345, 'Total loss': 0.5226073813709345} | train loss {'Reaction outcome loss': 0.46484057979303817, 'Total loss': 0.46484057979303817}
2022-11-28 05:38:52,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:52,303 INFO:     Epoch: 29
2022-11-28 05:38:52,963 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5101213617758318, 'Total loss': 0.5101213617758318} | train loss {'Reaction outcome loss': 0.47008150514320807, 'Total loss': 0.47008150514320807}
2022-11-28 05:38:52,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:52,963 INFO:     Epoch: 30
2022-11-28 05:38:53,622 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4620430977507071, 'Total loss': 0.4620430977507071} | train loss {'Reaction outcome loss': 0.46548086072993183, 'Total loss': 0.46548086072993183}
2022-11-28 05:38:53,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:53,622 INFO:     Epoch: 31
2022-11-28 05:38:54,285 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5108184469017115, 'Total loss': 0.5108184469017115} | train loss {'Reaction outcome loss': 0.45545975311926984, 'Total loss': 0.45545975311926984}
2022-11-28 05:38:54,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:54,285 INFO:     Epoch: 32
2022-11-28 05:38:54,948 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.510860613123937, 'Total loss': 0.510860613123937} | train loss {'Reaction outcome loss': 0.47047467645906244, 'Total loss': 0.47047467645906244}
2022-11-28 05:38:54,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:54,948 INFO:     Epoch: 33
2022-11-28 05:38:55,609 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48795462907715276, 'Total loss': 0.48795462907715276} | train loss {'Reaction outcome loss': 0.46477783658364524, 'Total loss': 0.46477783658364524}
2022-11-28 05:38:55,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:55,610 INFO:     Epoch: 34
2022-11-28 05:38:56,267 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5145812732252207, 'Total loss': 0.5145812732252207} | train loss {'Reaction outcome loss': 0.4674574021506406, 'Total loss': 0.4674574021506406}
2022-11-28 05:38:56,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:56,268 INFO:     Epoch: 35
2022-11-28 05:38:56,925 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49999018894000485, 'Total loss': 0.49999018894000485} | train loss {'Reaction outcome loss': 0.4587411616555592, 'Total loss': 0.4587411616555592}
2022-11-28 05:38:56,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:56,925 INFO:     Epoch: 36
2022-11-28 05:38:57,590 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5382060760801489, 'Total loss': 0.5382060760801489} | train loss {'Reaction outcome loss': 0.47265893444117263, 'Total loss': 0.47265893444117263}
2022-11-28 05:38:57,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:57,590 INFO:     Epoch: 37
2022-11-28 05:38:58,253 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48050971871072595, 'Total loss': 0.48050971871072595} | train loss {'Reaction outcome loss': 0.46942945399325386, 'Total loss': 0.46942945399325386}
2022-11-28 05:38:58,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:58,254 INFO:     Epoch: 38
2022-11-28 05:38:58,912 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4809549491513859, 'Total loss': 0.4809549491513859} | train loss {'Reaction outcome loss': 0.4565610652195614, 'Total loss': 0.4565610652195614}
2022-11-28 05:38:58,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:58,912 INFO:     Epoch: 39
2022-11-28 05:38:59,573 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4860906492580067, 'Total loss': 0.4860906492580067} | train loss {'Reaction outcome loss': 0.4660653040069438, 'Total loss': 0.4660653040069438}
2022-11-28 05:38:59,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:38:59,574 INFO:     Epoch: 40
2022-11-28 05:39:00,233 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5139116184277968, 'Total loss': 0.5139116184277968} | train loss {'Reaction outcome loss': 0.4593466015557121, 'Total loss': 0.4593466015557121}
2022-11-28 05:39:00,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:00,233 INFO:     Epoch: 41
2022-11-28 05:39:00,892 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4797566287558187, 'Total loss': 0.4797566287558187} | train loss {'Reaction outcome loss': 0.4659098775714244, 'Total loss': 0.4659098775714244}
2022-11-28 05:39:00,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:00,892 INFO:     Epoch: 42
2022-11-28 05:39:01,551 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47302915155887604, 'Total loss': 0.47302915155887604} | train loss {'Reaction outcome loss': 0.4696022833769138, 'Total loss': 0.4696022833769138}
2022-11-28 05:39:01,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:01,551 INFO:     Epoch: 43
2022-11-28 05:39:02,212 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4786756810816852, 'Total loss': 0.4786756810816852} | train loss {'Reaction outcome loss': 0.46416702631272766, 'Total loss': 0.46416702631272766}
2022-11-28 05:39:02,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:02,212 INFO:     Epoch: 44
2022-11-28 05:39:02,872 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5127734284509312, 'Total loss': 0.5127734284509312} | train loss {'Reaction outcome loss': 0.47087919488850877, 'Total loss': 0.47087919488850877}
2022-11-28 05:39:02,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:02,873 INFO:     Epoch: 45
2022-11-28 05:39:03,532 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49513802982189437, 'Total loss': 0.49513802982189437} | train loss {'Reaction outcome loss': 0.4663436503907447, 'Total loss': 0.4663436503907447}
2022-11-28 05:39:03,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:03,532 INFO:     Epoch: 46
2022-11-28 05:39:04,191 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47649006071415817, 'Total loss': 0.47649006071415817} | train loss {'Reaction outcome loss': 0.47787671201383536, 'Total loss': 0.47787671201383536}
2022-11-28 05:39:04,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:04,191 INFO:     Epoch: 47
2022-11-28 05:39:04,848 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.51464297961105, 'Total loss': 0.51464297961105} | train loss {'Reaction outcome loss': 0.4658537998433538, 'Total loss': 0.4658537998433538}
2022-11-28 05:39:04,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:04,848 INFO:     Epoch: 48
2022-11-28 05:39:05,507 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49443456598303537, 'Total loss': 0.49443456598303537} | train loss {'Reaction outcome loss': 0.4659828908952624, 'Total loss': 0.4659828908952624}
2022-11-28 05:39:05,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:05,507 INFO:     Epoch: 49
2022-11-28 05:39:06,168 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4831281060522253, 'Total loss': 0.4831281060522253} | train loss {'Reaction outcome loss': 0.4633209883925403, 'Total loss': 0.4633209883925403}
2022-11-28 05:39:06,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:06,168 INFO:     Epoch: 50
2022-11-28 05:39:06,827 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.585140885277228, 'Total loss': 0.585140885277228} | train loss {'Reaction outcome loss': 0.4583765432419565, 'Total loss': 0.4583765432419565}
2022-11-28 05:39:06,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:06,827 INFO:     Epoch: 51
2022-11-28 05:39:07,485 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48225692998279224, 'Total loss': 0.48225692998279224} | train loss {'Reaction outcome loss': 0.4903303445561936, 'Total loss': 0.4903303445561936}
2022-11-28 05:39:07,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:07,485 INFO:     Epoch: 52
2022-11-28 05:39:08,141 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.508435751565478, 'Total loss': 0.508435751565478} | train loss {'Reaction outcome loss': 0.4741473822941182, 'Total loss': 0.4741473822941182}
2022-11-28 05:39:08,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:08,141 INFO:     Epoch: 53
2022-11-28 05:39:08,793 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4817684736441482, 'Total loss': 0.4817684736441482} | train loss {'Reaction outcome loss': 0.47563067072557536, 'Total loss': 0.47563067072557536}
2022-11-28 05:39:08,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:08,794 INFO:     Epoch: 54
2022-11-28 05:39:09,451 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4613636427304961, 'Total loss': 0.4613636427304961} | train loss {'Reaction outcome loss': 0.4691055288787192, 'Total loss': 0.4691055288787192}
2022-11-28 05:39:09,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:09,451 INFO:     Epoch: 55
2022-11-28 05:39:10,109 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45963589880954137, 'Total loss': 0.45963589880954137} | train loss {'Reaction outcome loss': 0.4725987189694455, 'Total loss': 0.4725987189694455}
2022-11-28 05:39:10,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:10,109 INFO:     Epoch: 56
2022-11-28 05:39:10,768 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4793508899482814, 'Total loss': 0.4793508899482814} | train loss {'Reaction outcome loss': 0.46280457151616333, 'Total loss': 0.46280457151616333}
2022-11-28 05:39:10,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:10,768 INFO:     Epoch: 57
2022-11-28 05:39:11,429 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4757685143161904, 'Total loss': 0.4757685143161904} | train loss {'Reaction outcome loss': 0.46384023582404443, 'Total loss': 0.46384023582404443}
2022-11-28 05:39:11,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:11,429 INFO:     Epoch: 58
2022-11-28 05:39:12,091 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.523159382018176, 'Total loss': 0.523159382018176} | train loss {'Reaction outcome loss': 0.478098820940203, 'Total loss': 0.478098820940203}
2022-11-28 05:39:12,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:12,091 INFO:     Epoch: 59
2022-11-28 05:39:12,753 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47362584925510665, 'Total loss': 0.47362584925510665} | train loss {'Reaction outcome loss': 0.4763659418594499, 'Total loss': 0.4763659418594499}
2022-11-28 05:39:12,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:12,753 INFO:     Epoch: 60
2022-11-28 05:39:13,414 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4882341691038825, 'Total loss': 0.4882341691038825} | train loss {'Reaction outcome loss': 0.46474428529198836, 'Total loss': 0.46474428529198836}
2022-11-28 05:39:13,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:13,414 INFO:     Epoch: 61
2022-11-28 05:39:14,076 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4786807596683502, 'Total loss': 0.4786807596683502} | train loss {'Reaction outcome loss': 0.4634899166431504, 'Total loss': 0.4634899166431504}
2022-11-28 05:39:14,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:14,076 INFO:     Epoch: 62
2022-11-28 05:39:14,736 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.480636013333093, 'Total loss': 0.480636013333093} | train loss {'Reaction outcome loss': 0.4648608045298078, 'Total loss': 0.4648608045298078}
2022-11-28 05:39:14,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:14,736 INFO:     Epoch: 63
2022-11-28 05:39:15,394 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47321774370291014, 'Total loss': 0.47321774370291014} | train loss {'Reaction outcome loss': 0.46806751933657686, 'Total loss': 0.46806751933657686}
2022-11-28 05:39:15,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:15,395 INFO:     Epoch: 64
2022-11-28 05:39:16,054 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46885368126359855, 'Total loss': 0.46885368126359855} | train loss {'Reaction outcome loss': 0.4584886448126501, 'Total loss': 0.4584886448126501}
2022-11-28 05:39:16,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:16,054 INFO:     Epoch: 65
2022-11-28 05:39:16,713 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46793233281509444, 'Total loss': 0.46793233281509444} | train loss {'Reaction outcome loss': 0.45212287217499275, 'Total loss': 0.45212287217499275}
2022-11-28 05:39:16,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:16,713 INFO:     Epoch: 66
2022-11-28 05:39:17,372 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46180176870389417, 'Total loss': 0.46180176870389417} | train loss {'Reaction outcome loss': 0.45637263288261437, 'Total loss': 0.45637263288261437}
2022-11-28 05:39:17,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:17,373 INFO:     Epoch: 67
2022-11-28 05:39:18,032 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45640726726163516, 'Total loss': 0.45640726726163516} | train loss {'Reaction outcome loss': 0.4601880110996334, 'Total loss': 0.4601880110996334}
2022-11-28 05:39:18,033 INFO:     Found new best model at epoch 67
2022-11-28 05:39:18,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:18,033 INFO:     Epoch: 68
2022-11-28 05:39:18,692 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4637190062891353, 'Total loss': 0.4637190062891353} | train loss {'Reaction outcome loss': 0.46339761975564453, 'Total loss': 0.46339761975564453}
2022-11-28 05:39:18,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:18,693 INFO:     Epoch: 69
2022-11-28 05:39:19,351 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4687121005898172, 'Total loss': 0.4687121005898172} | train loss {'Reaction outcome loss': 0.4555679411902601, 'Total loss': 0.4555679411902601}
2022-11-28 05:39:19,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:19,352 INFO:     Epoch: 70
2022-11-28 05:39:20,011 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4407230425964702, 'Total loss': 0.4407230425964702} | train loss {'Reaction outcome loss': 0.45854123745128694, 'Total loss': 0.45854123745128694}
2022-11-28 05:39:20,011 INFO:     Found new best model at epoch 70
2022-11-28 05:39:20,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:20,012 INFO:     Epoch: 71
2022-11-28 05:39:20,670 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4937788871201602, 'Total loss': 0.4937788871201602} | train loss {'Reaction outcome loss': 0.4600018293630739, 'Total loss': 0.4600018293630739}
2022-11-28 05:39:20,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:20,670 INFO:     Epoch: 72
2022-11-28 05:39:21,327 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44676816785200074, 'Total loss': 0.44676816785200074} | train loss {'Reaction outcome loss': 0.4625502240199309, 'Total loss': 0.4625502240199309}
2022-11-28 05:39:21,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:21,328 INFO:     Epoch: 73
2022-11-28 05:39:21,986 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4868600788441571, 'Total loss': 0.4868600788441571} | train loss {'Reaction outcome loss': 0.4613837593721475, 'Total loss': 0.4613837593721475}
2022-11-28 05:39:21,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:21,987 INFO:     Epoch: 74
2022-11-28 05:39:22,648 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4566104171628302, 'Total loss': 0.4566104171628302} | train loss {'Reaction outcome loss': 0.4589223712079438, 'Total loss': 0.4589223712079438}
2022-11-28 05:39:22,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:22,648 INFO:     Epoch: 75
2022-11-28 05:39:23,309 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4635221009904688, 'Total loss': 0.4635221009904688} | train loss {'Reaction outcome loss': 0.46011190170701216, 'Total loss': 0.46011190170701216}
2022-11-28 05:39:23,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:23,309 INFO:     Epoch: 76
2022-11-28 05:39:23,973 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46242361583492975, 'Total loss': 0.46242361583492975} | train loss {'Reaction outcome loss': 0.46043771212762186, 'Total loss': 0.46043771212762186}
2022-11-28 05:39:23,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:23,974 INFO:     Epoch: 77
2022-11-28 05:39:24,632 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48514115099202504, 'Total loss': 0.48514115099202504} | train loss {'Reaction outcome loss': 0.4681876086128446, 'Total loss': 0.4681876086128446}
2022-11-28 05:39:24,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:24,632 INFO:     Epoch: 78
2022-11-28 05:39:25,293 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46036781099709595, 'Total loss': 0.46036781099709595} | train loss {'Reaction outcome loss': 0.4518285666098479, 'Total loss': 0.4518285666098479}
2022-11-28 05:39:25,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:25,293 INFO:     Epoch: 79
2022-11-28 05:39:25,957 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46107215976173227, 'Total loss': 0.46107215976173227} | train loss {'Reaction outcome loss': 0.4539153203368187, 'Total loss': 0.4539153203368187}
2022-11-28 05:39:25,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:25,957 INFO:     Epoch: 80
2022-11-28 05:39:26,617 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45997531373392453, 'Total loss': 0.45997531373392453} | train loss {'Reaction outcome loss': 0.45501352617373836, 'Total loss': 0.45501352617373836}
2022-11-28 05:39:26,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:26,617 INFO:     Epoch: 81
2022-11-28 05:39:27,279 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5305000028826974, 'Total loss': 0.5305000028826974} | train loss {'Reaction outcome loss': 0.45785136110628183, 'Total loss': 0.45785136110628183}
2022-11-28 05:39:27,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:27,279 INFO:     Epoch: 82
2022-11-28 05:39:27,948 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4472226273607124, 'Total loss': 0.4472226273607124} | train loss {'Reaction outcome loss': 0.4607042529684329, 'Total loss': 0.4607042529684329}
2022-11-28 05:39:27,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:27,948 INFO:     Epoch: 83
2022-11-28 05:39:28,611 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48423352532766084, 'Total loss': 0.48423352532766084} | train loss {'Reaction outcome loss': 0.4416153498393623, 'Total loss': 0.4416153498393623}
2022-11-28 05:39:28,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:28,611 INFO:     Epoch: 84
2022-11-28 05:39:29,271 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48852222446690907, 'Total loss': 0.48852222446690907} | train loss {'Reaction outcome loss': 0.46797068869536707, 'Total loss': 0.46797068869536707}
2022-11-28 05:39:29,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:29,271 INFO:     Epoch: 85
2022-11-28 05:39:29,930 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47624076157808304, 'Total loss': 0.47624076157808304} | train loss {'Reaction outcome loss': 0.48431128540985013, 'Total loss': 0.48431128540985013}
2022-11-28 05:39:29,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:29,930 INFO:     Epoch: 86
2022-11-28 05:39:30,592 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5042905492538755, 'Total loss': 0.5042905492538755} | train loss {'Reaction outcome loss': 0.46901375721944005, 'Total loss': 0.46901375721944005}
2022-11-28 05:39:30,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:30,592 INFO:     Epoch: 87
2022-11-28 05:39:31,252 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4739105728539554, 'Total loss': 0.4739105728539554} | train loss {'Reaction outcome loss': 0.49500068397777763, 'Total loss': 0.49500068397777763}
2022-11-28 05:39:31,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:31,253 INFO:     Epoch: 88
2022-11-28 05:39:31,911 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47621211426501925, 'Total loss': 0.47621211426501925} | train loss {'Reaction outcome loss': 0.45269177811831113, 'Total loss': 0.45269177811831113}
2022-11-28 05:39:31,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:31,911 INFO:     Epoch: 89
2022-11-28 05:39:32,570 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.463263716887344, 'Total loss': 0.463263716887344} | train loss {'Reaction outcome loss': 0.4547756826316538, 'Total loss': 0.4547756826316538}
2022-11-28 05:39:32,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:32,570 INFO:     Epoch: 90
2022-11-28 05:39:33,228 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46461520970545034, 'Total loss': 0.46461520970545034} | train loss {'Reaction outcome loss': 0.4492637370317149, 'Total loss': 0.4492637370317149}
2022-11-28 05:39:33,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:33,228 INFO:     Epoch: 91
2022-11-28 05:39:33,887 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46173462170091545, 'Total loss': 0.46173462170091545} | train loss {'Reaction outcome loss': 0.46360445342324524, 'Total loss': 0.46360445342324524}
2022-11-28 05:39:33,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:33,888 INFO:     Epoch: 92
2022-11-28 05:39:34,547 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4684664278545163, 'Total loss': 0.4684664278545163} | train loss {'Reaction outcome loss': 0.47283899729792406, 'Total loss': 0.47283899729792406}
2022-11-28 05:39:34,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:34,548 INFO:     Epoch: 93
2022-11-28 05:39:35,204 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4538819854232398, 'Total loss': 0.4538819854232398} | train loss {'Reaction outcome loss': 0.45510105474999074, 'Total loss': 0.45510105474999074}
2022-11-28 05:39:35,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:35,205 INFO:     Epoch: 94
2022-11-28 05:39:35,863 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46211038597605447, 'Total loss': 0.46211038597605447} | train loss {'Reaction outcome loss': 0.4584584045808325, 'Total loss': 0.4584584045808325}
2022-11-28 05:39:35,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:35,863 INFO:     Epoch: 95
2022-11-28 05:39:36,524 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48902191391045396, 'Total loss': 0.48902191391045396} | train loss {'Reaction outcome loss': 0.4567048339105328, 'Total loss': 0.4567048339105328}
2022-11-28 05:39:36,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:36,524 INFO:     Epoch: 96
2022-11-28 05:39:37,185 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4590168541127985, 'Total loss': 0.4590168541127985} | train loss {'Reaction outcome loss': 0.46056784242994875, 'Total loss': 0.46056784242994875}
2022-11-28 05:39:37,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:37,185 INFO:     Epoch: 97
2022-11-28 05:39:37,846 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4529710188508034, 'Total loss': 0.4529710188508034} | train loss {'Reaction outcome loss': 0.46250023801437756, 'Total loss': 0.46250023801437756}
2022-11-28 05:39:37,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:37,846 INFO:     Epoch: 98
2022-11-28 05:39:38,506 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43382060891863977, 'Total loss': 0.43382060891863977} | train loss {'Reaction outcome loss': 0.46751467527648216, 'Total loss': 0.46751467527648216}
2022-11-28 05:39:38,506 INFO:     Found new best model at epoch 98
2022-11-28 05:39:38,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-28 05:39:38,507 INFO:     Epoch: 99
2022-11-28 05:39:39,166 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.450521761382168, 'Total loss': 0.450521761382168} | train loss {'Reaction outcome loss': 0.4557709026900742, 'Total loss': 0.4557709026900742}
2022-11-28 05:39:39,167 INFO:     Best model found after epoch 99 of 100.
2022-11-28 05:39:39,167 INFO:   Done with stage: TRAINING
2022-11-28 05:39:39,167 INFO:   Starting stage: EVALUATION
2022-11-28 05:39:39,284 INFO:   Done with stage: EVALUATION
2022-11-28 05:39:39,285 INFO: Done with stage: RUNNING SPLITS
2022-11-28 05:39:39,285 INFO: Starting stage: COMPUTE METRICS
2022-11-28 05:39:40,444 INFO: Done with stage: COMPUTE METRICS
2022-11-28 05:39:40,445 INFO: Starting stage: EXPORT RESULTS
2022-11-28 05:39:40,461 INFO:   Final results averaged over 50 folds: 
2022-11-28 05:39:40,465 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.186586           NaN  0.311505       NaN
2022-11-28 05:39:42,088 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-11-28 05:39:42,094 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-11-28 05:39:42,095 DEBUG:   interactive is False
2022-11-28 05:39:42,096 DEBUG:   platform is linux
2022-11-28 05:39:42,096 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.sql.naming', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-11-28 05:39:42,266 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-11-28 05:39:42,268 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-11-28 05:39:42,699 DEBUG:   Loaded backend agg version unknown.
2022-11-28 05:39:42,701 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-28 05:39:42,701 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,701 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,701 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,701 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 05:39:42,701 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 05:39:42,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 05:39:42,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 05:39:42,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 05:39:42,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 05:39:42,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 05:39:42,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,702 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-28 05:39:42,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 05:39:42,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 05:39:42,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-28 05:39:42,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,703 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 05:39:42,704 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 05:39:42,704 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,704 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,704 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,704 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 05:39:42,704 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,704 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-28 05:39:42,740 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-11-28 05:39:42,740 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,740 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,740 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,740 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 05:39:42,740 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 05:39:42,740 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 05:39:42,740 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,740 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,741 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,741 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,741 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 05:39:42,741 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 05:39:42,741 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,741 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,741 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,741 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 05:39:42,741 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,741 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 05:39:42,741 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,741 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,741 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-28 05:39:42,741 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 05:39:42,741 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 05:39:42,741 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,741 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,742 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,742 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,742 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,742 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,742 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,742 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,742 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,742 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-28 05:39:42,742 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,742 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,742 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,742 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,742 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 05:39:42,742 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 05:39:42,742 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,742 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,743 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,743 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 05:39:42,743 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,743 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-28 05:39:42,751 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-28 05:39:42,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 05:39:42,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 05:39:42,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 05:39:42,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 05:39:42,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 05:39:42,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 05:39:42,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 05:39:42,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-28 05:39:42,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 05:39:42,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 05:39:42,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,769 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,769 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,769 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,769 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,769 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-28 05:39:42,769 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,769 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,769 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,769 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,769 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 05:39:42,769 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 05:39:42,769 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,769 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,769 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 05:39:42,769 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 05:39:42,769 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 05:39:42,769 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-28 05:39:43,120 INFO: Done with stage: EXPORT RESULTS
2022-11-28 05:39:43,120 INFO: Starting stage: SAVE MODEL
2022-11-28 05:39:43,178 INFO: Done with stage: SAVE MODEL
2022-11-28 05:39:43,178 INFO: Wall time for program:  3356.81 seconds
